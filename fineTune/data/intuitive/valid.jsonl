{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nKemeny constant (KC), introduced by Kemeny and Snell [22], is a\nfundamental metric closely related to hitting time, which is a key\nquantity associated with random walks. Formally, KC is defined\nas the expected steps of a random walk that starts from a fixed\ninitial node and stops until reaching a randomly chosen target node\naccording to the stationary distribution. A notable property of KC\nis that it remains invariant regardless the choice of the starting\nnode [22]. Intuitively, a smaller KC value suggests better overall\nconnectivity of the graph, as nodes are easily reachable from one another. As a unique global network invariant, the Kemeny constant\nhas been applied extensively in various domains of network analysis, including serving as an indicator of network robustness [37],\nanalyzing the disease transmission [56], and quantifying global\nperformance costs in road networks [12]. In recent years, due to\n\nits intrinsic connection to hitting times, KC has also been widely\nused in graph data management, such as network centrality representation [2, 47], graph clustering [9, 34], and recommendation\nsystems [24, 57], among others.\nIt is well known that the computation of KC can be reformulated\nas an eigenvalue problem involving the Laplacian or transition\nmatrix of a graph [13, 20, 22, 24]. However, classical methods for\ncomputing eigenvalues require a time complexity of _\ud835\udc42_ ( _\ud835\udc5b_ [3] ), making\nthem impractical for large-scale graphs. To overcome this limitation, various sampling-based approaches have been developed to\nestimate KC with improved scalability at the cost of some accuracy. Random walk-based methods, such as DynamicMC [25] and\nRefinedMC [51], approximate KC by simulating truncated random\nwalks. Although they avoid the unacceptable computational cost of\neigenvalues, these methods still require a large number of samples\nto achieve acceptable accuracy. More recent methods, including\nLEwalk [29] and ForestMC [51], leverage the connection between\nKC and loop-erased random walks (LERWs) to improve sampling\nefficiency. While these methods may offer some improvements over\nstandard random walks, they still lack strong theoretical guarantees, because the number of steps of a LERWs can be unbounded in\nworst case, making it difficult to bound sampling size for all kind\nof graphs. Consequently, LERW-based methods may fail to provide\nreliable estimates with great efficiency on real-life large graphs.\nRecent studies increasingly focus on exploring the connection\nbetween spanning trees or spanning forests with the Laplacian\nmatrix, to address classic random walk-related problems, such as the\ncomputation of PageRank [27, 30] and effective resistance [28, 31].\nSince the scale of a tree or forest can be bounded by the graph\ndiameter, which is more stable on various graphs compared to the\nlength of random walks. This advantage offers the potential for\ntighter theoretical guarantees about the sample size. Motivated\nby this insight, we propose a novel formula of KC expressed by\nthe volume of 2-forests. Specifically, a 2-forest is a spanning forest\nconsisting of exactly two disjoint trees, and the volume of a 2-forest\nis related to the sum of the degrees, in the underlying graph, of all\nnodes in one of its two trees (see Theorem 3.1).\nBuilding on the proposed 2-forest formula of KC, we develop a\ntheoretical framework and an efficient algorithm to estimate KC\nvia sampling 2-forests. A key technique of our approach is _path_\n_mapping_ that maps a spanning tree to a set of 2-forests, enabling us\nto construct an unbiased estimator for KC in terms of spanning trees.\nAs a result, we can estimate KC by sampling spanning trees and then\nderiving 2-forests from them, effectively bypassing the challenges\nassociated with directly sampling 2-forests. To calculate the volume\nof 2-forests obtained from each spanning tree, we design a depthfirst search (DFS) algorithm and optimize it using Binary Indexed\nTrees (BIT) [14]. Compared to the naive spanning tree traversal\n\nmethod used in similar tasks [28, 29], our approach reduces the\ntime complexity from _\ud835\udc42_ ( _\ud835\udc5b_ \u0394) to _\ud835\udc42_ ( _\ud835\udc5b_ - min(\u0394 _,_ log _\ud835\udc5b_ )), where \u0394 is\nthe diameter. This significantly improves performance on largescale graphs. Finally, we provide theoretical guarantees for both\nthe correctness and computational complexity of the proposed\nalgorithm. The results show that our method computes the Kemeny\n\n\u0394 [2][ \u00af] _\ud835\udc51_ [2]\nconstant with relative error _\ud835\udf16_ in _\ud835\udc42_ \ufffd _\ud835\udf16_ [2] [(] _[\ud835\udf19]_ [+] _[ \ud835\udc5b]_ [min][(][log] _[\ud835\udc5b,]_ [ \u0394][))] \ufffd time,\n\nwhere _\ud835\udf19_ is the time to sample a spanning tree, _\ud835\udc51_ [\u00af] is the average\ndegree, and \u0394 is the diameter of the graph. This complexity is\nnear-linear in practical scenarios.\nMoreover, most existing methods for estimating KC are designed\nfor static graphs, while real-world networks are often dynamically\nchanging. To address this gap, we develop two sample maintenance\nstrategies that support efficient updates without requiring full recomputation on dynamic graphs. Benefit from the introduction of\nspanning trees, we can selectively adjust an amount of spanning\ntree samples according to the change of the entire sample space\ncaused by updates, thereby indirectly preserving the correctness\nof the induced 2-forests. Specifically, when an edge is inserted, the\nbasic maintenance method replaces a portion of samples by trees\nthat include the new edge. When an edge is deleted, all spanning\ntrees containing the deleted edge are substituted with newly sampled spanning trees from the updated graph. To further enhance\nefficiency, we introduce an improved sample maintenance method\nincorporating _link-cut_ and _cut-link_ operations. These operations\nenable the transformation of spanning trees that lack a specific edge\ninto ones that contain it, significantly reducing update overhead.\nAlthough the resulting spanning trees may not follow a uniform\ndistribution, we derive a correction mechanism that computes the\ndeviation from uniformity and adjusts the weight of the samples\naccordingly. This ensures accurate KC estimation while achieving\nsubstantial computational efficiency on dynamic graphs. Both two\nmethods are faster than resampling from scratch. The correctness\nand time complexity of two methods are discussed.\nWe conduct extensive experiments to evaluate the performance\nof the proposed methods. The results show that, for static graphs,\nour new algorithm outperforms SOTA methods, with significant improvements on some graphs. For evolving graphs, the two proposed\nmaintenance strategies achieve significant speed-ups compared to\nstatic algorithm recalculations. Specifically, the basic maintenance\nalgorithm provides up to an improvement of more than one order\nof magnitude, while the improved maintenance algorithm achieves\na larger speedup, but with a slight sacrifice in accuracy. In summary,\nthe main contributions of this paper are as follows.\n\n**Novel Approximate Algorithm.** We propose a novel forest formula of Kemeny constant and design an unbiased estimator by\nintroducing a technique called _path mapping_, which establishes a\ndirect connection between spanning trees and 2-forests. Based on\nthis, we propose a sampling-based algorithm for approximating\nKemeny constant and optimize the data structure with Binary Index\nTrees, which enables nearly linear time complexity and makes it\neasy to extend to dynamic graphs. A detailed theoretical analysis\nof the proposed algorithm is also provided.\n\n**New Sample Maintenance Methods.** We propose two novel\nmethods, BSM and ISM, to maintain the correctness of spanning\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n**Table 1: Frequently used notations.**\n\n|Notation|Description|\n|---|---|\n|_\ud835\udc3a_= (_\ud835\udc49, \ud835\udc38_)|An undirected graph_ \ud835\udc3a_with node set_ \ud835\udc49_and edge<br>set_ \ud835\udc38_|\n|_\ud835\udc5b,\ud835\udc5a_|The number of nodes and edges in_ \ud835\udc3a_,<br>respectively|\n|_\ud835\udc51_(_\ud835\udc63_)|The degree of node_ \ud835\udc63_|\n|_\ud835\udf05_(_\ud835\udc3a_)|The Kemeny constant of thegraph_ \ud835\udc3a_|\n|_\ud835\udc47_1 \u222a_\ud835\udc47_2|A 2-forest consisting of two trees, where_ \ud835\udc47_1 and<br>_\ud835\udc47_2 denote the node sets of the two trees|\n|_\ud835\udf0f_|A spanning tree of thegraph|\n|\u0393_,_ F|The set of all spanning trees and 2-forests of the<br>graph, respectively|\n|vol(_\ud835\udc47_1)|The volume of node set_ \ud835\udc47_1, defned as<br>vol(_\ud835\udc47_1) = \u00cd<br>_\ud835\udc63_\u2208_\ud835\udc47_1 _\ud835\udc51_(_\ud835\udc63_)|\n|P_,_ P~~\u2032~~|A simple, directedpath P and its reversepath P~~\u2032~~|\n|_\ud835\udc46\ud835\udc62\ud835\udc4f_(_\ud835\udf0f,\ud835\udc62_)|The node set of the subtree rooted at_ \ud835\udc62_in tree_ \ud835\udf0f_|\n|_\ud835\udf16_|The relative errorparameter|\n\ntree samples as the graph updates, substantially reducing computational cost compared to rerunning static algorithms after each\nupdate. BSM adjusts the spanning tree samples by pre-computing\nchanges in the sample space, while ISM further enhances efficiency\nby reusing prior computations. We provide theoretical analysis\nshowing that, even in the worst case, our algorithms are faster than\nre-sampling methods, with only a slight sacrifice in accuracy.\n\n**Extensive Experiments.** We conduct comprehensive experiments\non 10 real-world graphs to evaluate our algorithms. On static graphs,\nour method achieves up to an order of magnitude speedup over\nstate-of-the-art algorithms while maintaining the same level of estimation accuracy. For example, on the road network roadNet-PA,\nour algorithm reaches a relative error of 0.03 in just 26 seconds,\nwhereas two SOTA methods ForestMC and SpanTree require 297\nseconds and 676 seconds, respectively, to achieve similar accuracy.\nOn dynamic graphs, we further demonstrate the efficiency of our\nsample maintenance strategies. For the large social networks Orkut,\nwhich contains 3 million nodes and 11 million edges, ISM completes\neach deletion and insertion update in an average of 1.6 seconds\nand 4.3 seconds, respectively. In contrast, the fast re-sampling algorithm requires 109 seconds, demonstrating an improvement of\napproximately one order of magnitude speedup."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism replaces the complex probabilistic random walk calculation of the Kemeny Constant (KC) with a combinatorial counting problem involving '2-forests'. Instead of directly sampling these 2-forests, they use a 'path mapping' technique that enables them to sample *spanning trees* uniformly (which is a well-understood and efficient problem). These sampled spanning trees are then deterministically transformed into sets of 2-forests, and their 'volume' (sum of degrees in one component) is computed. To optimize this volume calculation, they integrate Depth-First Search (DFS) with Binary Indexed Trees (BIT), acting like a highly efficient accounting system to quickly aggregate degree sums within subtrees. For dynamic graphs, the mechanism shifts to intelligent sample reuse. The 'Improved Sample Maintenance' method (ISM) employs 'link-cut' and 'cut-link' operations, which are like pointer manipulations in a tree data structure, allowing them to rapidly transform existing spanning tree samples to reflect graph changes (edge insertions/deletions) without full re-sampling. A critical 'correction mechanism' then adjusts sample weights to account for any non-uniformity introduced by these transformations, ensuring accuracy.\n\n**Explanation:** Traditionally, calculating Kemeny Constant involved solving an eigenvalue problem, which is like trying to find specific 'vibration frequencies' of a system and scales poorly (O(n^3)). Earlier sampling methods used random walks, which are like simulating many paths, but struggled with unbounded path lengths or required too many simulations. This paper cleverly redefines KC in terms of '2-forests', which are graph partitions. The breakthrough is that instead of the hard task of directly sampling these 2-forests, they found a 'path mapping' that lets them derive them from easier-to-sample 'spanning trees' (like a minimal set of connections that link all nodes without loops, analogous to a linked list or tree data structure where every node has one unique parent except the root). The DFS combined with BIT for volume calculation is essentially a smart way to traverse the spanning tree (a loop) and sum up node degrees efficiently (like prefix sums in an array) to quickly get the 'volume' of a tree component after a split. For dynamic graphs, the innovation is not to re-compute everything. BSM simply swaps out affected spanning tree samples. ISM is more sophisticated: 'link-cut' and 'cut-link' operations are fast, pointer-based tree restructuring techniques (similar to operations on splay trees or link-cut trees in competitive programming) that allow an existing spanning tree to be rapidly modified to include or exclude an edge, minimizing computational overhead. The 'correction mechanism' is a weighting function, ensuring the statistical average remains correct even if the sample distribution isn't perfectly uniform post-modification."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Formalizing Cognitive Foundations for Reasoning** **4**\n\n2.1 Reasoning Invariants: Computational Constraints . . . . . . . . . . . . . . . . . . . . . . . . . 6\n\n2.2 Meta-Cognitive Controls: Executive Regulation . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n\n2.3 Reasoning Representations: Organizational Structures . . . . . . . . . . . . . . . . . . . . . . 8\n\n1\n\n2.4 Reasoning Operations: Transformation Procedures . . . . . . . . . . . . . . . . . . . . . . . . 10"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a structured approach to defining and executing computational 'thought' processes. It breaks down reasoning into fundamental components: fixed rules, supervisory control, data organization, and transformation functions.\n\n**Explanation:** This section outlines a foundational API for intelligent decision-making, moving from vague concepts to concrete computational constructs. 'Reasoning Invariants' are like preconditions or immutable properties that any reasoning step must adhere to, preventing invalid states similar to type safety or database constraints. They define the legal moves within the system. 'Meta-Cognitive Controls' are analogous to an operating system's scheduler or a high-level state machine; they don't perform reasoning but allocate resources and prioritize tasks, acting as the flow control for the reasoning process, deciding which operation to invoke next or when to stop. 'Reasoning Representations' refers to the choice of data structures for storing knowledge, like using a graph for relationships or a hash map for quick lookups, optimizing access and modification. 'Reasoning Operations' are the actual algorithms or functions that manipulate these representations. They take existing data structures, apply the defined invariants, and transform them into new data, using constructs like loops to iterate over data, and pointers to navigate structures, much like map, filter, or reduce operations. In essence, it defines the 'software architecture' for an intelligent agent's internal 'thinking'."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**63**\nA.1 Basic Sum-of-Squares inequalities . . . . . . . . . . . . . . . . . . . . . . . . . 63\nA.2 Sum-of-Squares certificate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nA.3 Sum-of-Squares subset sum . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n\n**B** **Spectral bounds**"}, {"role": "assistant", "content": "**Mechanism:** This section outlines the application of Sum-of-Squares (SoS) methods, which is a technique to prove that a polynomial is non-negative by expressing it as a sum of squares of other polynomials. This provides rigorous lower bounds for optimization problems.\n\n**Explanation:** This is essentially an outline for a mathematical toolkit. 'Sum-of-Squares inequalities' means establishing basic rules or bounds for certain mathematical expressions using the SoS technique, ensuring they don't go below a certain value. A 'Sum-of-Squares certificate' is a formal proof, like a function that returns true, indicating that a polynomial is indeed non-negative. 'Sum-of-Squares subset sum' would apply this proof technique to the classic subset sum problem, likely showing how SoS can be used to find or prove properties about subsets of numbers that sum to a target. 'Spectral bounds' refers to using properties of matrices (specifically, their eigenvalues and eigenvectors) to determine limits or ranges of behavior for systems, which often complements or provides an alternative approach to SoS methods, especially when problems can be formulated as matrix problems."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe foundational framework for Reinforcement Learning\nis the Markov Decision Process (MDP), roughly _M_ =\n( _S, A, P, r, \u03b3, \u03c1_ ), where _S_ is the state space, _A_ the action\nset, _P_ ( _s_ _[\u2032]_ _| s, a_ ) the transition kernel, _r_ ( _s, a_ ) _\u2208_ [0 _, R_ max]\nthe bounded one-step reward, _\u03b3 \u2208_ [0 _,_ 1) the discount factor,\nand _\u03c1_ the initial state distribution. At each step, the agent\nobserves the current state _st_ and takes an action _at_ . The environment then transits the next state _st_ +1 according to the\ntransition kernel _P_ ( _\u00b7|st, at_ ), and receiving an immediate reward _r_ ( _st, at_ ). A parameterized Markov policy is a mapping\n_\u03c0\u03b8_ : _S \u2192_ \u2206( _A_ ) [1] that captures the probability of taking\nactions under each state, for some parameter _\u03b8 \u2208_ \u0398. A policy _\u03c0\u03b8_ can randomly induce a trajectory _\u03c4_ = ( _s_ 0 _, a_ 0 _, s_ 1 _, ..._ )\nunder the MDP, whose return is defined as the accumulated\nreward along the trajectory: _G_ ( _\u03c4_ ) = [\ufffd] _[\u221e]_ _t_ =0 _[\u03b3][t][ r]_ [(] _[s][t][, a][t]_ [)] _[.]_ [ The]\n\n1\u2206( _\u00b7_ ) is the probability simplex over the space _\u00b7_ .\n\nvalue function of a policy _\u03c0\u03b8_ is then defined as the expectation of returns: _V_ _[\u03c0]_ ( _s_ ) \u225c E[ _G_ ( _\u03c4_ ) _| s_ 0 = _s_ ]. The goal is to\nfind a policy _\u03c0_, following which the agent can get the highest\ncumulative reward:\n\n_\u03b8_ _[\u2217]_ = arg max _\u03b8\u2208_ \u0398 _[J]_ [(] _[\u03b8]_ [)] _[,]_ [ where] _[ J]_ [(] _[\u03b8]_ [)][ \u225c] [E][[] _[V][ \u03c0][\u03b8]_ [(] _[s]_ [)] _[|][s][ \u223c]_ _[\u03c1]_ []] _[,]_ [ (1)]\n\nfor some initial distribution _\u03c1_ .\nPolicy gradient algorithms optimize _J_ ( _\u03b8_ ) through gradient ascent, based on the Policy Gradient Theorem (Sutton et al. 1999): _\u2207\u03b8J_ ( _\u03b8_ ) = E _\u03c4_ _\u223c\u03c0\u03b8_ _\u221et_ =0 _[\u2207][\u03b8]_ [ log] _[ \u03c0][\u03b8]_ [(] _[a][t][ |]_\n\ufffd\ufffd\n\n_st_ ) _Q_ _[\u03c0][\u03b8]_ ( _st, at_ ), where the action-value function is defined\n\ufffd\n\nas _Q_ _[\u03c0]_ ( _s, a_ ) \u225c E[ _G_ ( _\u03c4_ ) _|s_ 0 = _s, a_ 0 = _a_ ].\nIn practice, as the value functions are unknown, one needs\nto replace them with the (Monte-Carlo) estimation, resulting\nin the straightforward REINFORCE algorithm (Sutton, Barto\net al. 1998). However, REINFORCE suffers from variances in\ngradient estimation and unstable performance; hence, modern\napproaches employ distinct stabilization mechanisms through\nconstrained optimization and off-policy learning. Among onpolicy methods, TRPO maximizes a surrogate-advantage\nobjective subject to a hard KL-constraint (Schulman et al.\n2015):\n\nsafeguard on the quality of the policy selection. Under the\nreward profiling framework, this update contributes only if\nit improves the performance. In the ideal case, we exactly\nknow the value functions of _J_ ( _\u03b8_ 1) and _J_ ( _\u03b8_ 2), then we will\nonly accept the update _\u03b8_ 1 _\u2192_ _\u03b8_ 2 if _J_ ( _\u03b8_ 2) _\u2265_ _J_ ( _\u03b8_ 1), which\nresults in a monotonically increasing performance and stabilizes training. In practice, however, we do not know _J_ ( _\u03b8_ )\nand need to make the comparison based on estimation. It is\nclear that the performance and stability highly depend on the\naccuracy of the comparison. To handle this, we provide our\n**high-confidence comparison** scheme.\nIn general, for two candidate parameterized policies _\u03c0j_\nwith _j \u2208{_ 1 _,_ 2 _}_, a number ( _E_ ) of _i.i.d._ trajectories are\nsampled from each policy forming evaluation sample sets\n_Dj_ = _{\u03c4i_ [(] _[j]_ [)] _}_ _[E]_ _i_ =1 _[\u223c]_ _[\u03c0][j]_ [. The empirical return estimate for] _[ \u03c0][j]_\nis computed as\n\n\u02c6 1\n_J_ ( _\u03c0j_ ) = _|Dj|_\n\n\ufffd _G_ ( _\u03c4_ ) _,_ (2)\n\n_\u03c4_ _\u2208Dj_\n\nmax _\u03b8_ _L_ [TRPO] ( _\u03b8_ ) = E _\u03c4_ _\u223c\u03c0\u03b8_ old\n\n_rt_ ( _\u03b8_ ) _A_ [\u02c6] _[\u03c0][\u03b8]_ [old] ( _st, at_ ) _,_\n\ufffd \ufffd\n\ns.t. E _\u03c4_ _\u223c\u03c0\u03b8_ old \ufffdD _KL_ \ufffd _\u03c0\u03b8_ old( _\u00b7| st_ ) _\u2225_ _\u03c0\u03b8_ ( _\u00b7| st_ )\ufffd\ufffd _\u2264_ _\u03b4,_\n\n_\u03c0\u03b8_ ( _at|st_ )\nwhere _rt_ ( _\u03b8_ ) = _\u03c0\u03b8_ old ( _at|st_ ) [, and][ \u02c6] _[A]_ [ being an advantage esti-]\nmator. TRPO enjoys a theoretical guarantee of (approximate)\nmonotonic policy improvement with the KL constraint. PPO\nreplaces TRPO\u2019s hard constraint with a clipped surrogate\nthat is cheaper to compute, still discourages large updates\n(Schulman et al. 2017). Unlike TRPO\u2019s KL-based trust region, PPO does not admit the same theoretical assurance of\nmonotonic improvement, yet a practical heuristic that works\nwell in large-scale implementations. Meanwhile, DDPG has\nremained a standard off-policy PG algorithm, training a deterministic actor _\u00b5\u03b8_ : _S \u2192A_ and a critic _Q\u03d5_ off-policy\nusing a replay buffer _D_ and slowly-updated target networks\n(Lillicrap et al. 2015) ( _\u00b5\u03b8\u2032, Q\u03d5\u2032_ ):\n\n2\n_L_ ( _\u03d5_ ) = E( _s,a,r,s\u2032_ ) _\u223cD_ \ufffd _r_ + _\u03b3 Q\u03d5\u2032_ [\ufffd] _s_ _[\u2032]_ _, \u00b5\u03b8\u2032_ ( _s_ _[\u2032]_ )\ufffd _\u2212_ _Q\u03d5_ ( _s, a_ )\ufffd _,_\n\n_\u2207\u03b8J_ _\u2248_ E _s\u223cD_ \ufffd _\u2207aQ\u03d5_ ( _s, a_ )\ufffd\ufffd _a_ = _\u00b5\u03b8_ ( _s_ ) _[\u2207][\u03b8][\u00b5][\u03b8]_ [(] _[s]_ [)] \ufffd _._\n\nTwin Delayed DDPG (TD3) (Fujimoto, van Hoof, and Meger\n2018) further stabilizes DDPG by (i) using two critics and\ntaking the minimum to reduce overestimation bias, (ii) delaying policy and target network updates, and (iii) adding\nclipped noise to target actions for policy smoothing."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is gradient ascent on an expected cumulative reward function. You define a 'world' (MDP) as a state machine with probabilities for transitions and rewards. A 'policy' is a parameterized function (like a lookup table or a small program with tunable settings) that decides actions based on the current state. The goal is to tune these parameters to maximize the average total reward received over many runs. The Policy Gradient Theorem provides a 'direction' (a gradient vector) in the parameter space that, if followed, will increase this average reward. It essentially says: make actions that led to high future rewards more probable, and actions that led to low future rewards less probable. Subsequent algorithms like TRPO and PPO refine this by putting 'speed limits' on parameter changes to prevent instability: TRPO uses a strict mathematical constraint (KL divergence) to ensure the new policy is not too 'different' from the old one, guaranteeing progress. PPO simplifies this by 'clipping' the updates to prevent extreme changes. DDPG and TD3 introduce 'off-policy' learning by storing experiences in a 'replay buffer' (like a database of past events) and learning from randomly sampled batches, breaking the sequential correlation of experiences. They use an 'actor' network to choose actions and a 'critic' network to evaluate those actions, with 'target networks' (slowly updated copies) to provide stable learning targets. TD3 further stabilizes DDPG by using redundant critics (taking the minimum to avoid overestimating good outcomes) and delaying actor updates.\n\n**Explanation:** An MDP is like describing a game: what the board looks like (states), what moves you can make (actions), what happens when you make a move (transitions), and what points you get (rewards). A 'policy' is your strategy for playing the game, like a detailed 'if-then-else' program where the 'if' is the current state and the 'then' is the action to take. The 'parameters' are the tunable parts of this program. We want to adjust these parameters to get the highest average score. The Policy Gradient Theorem gives us a mathematical compass: it tells us how to slightly tweak our strategy to likely get a higher score. It works by looking at actions we took in the past. If an action led to a good outcome (high 'Q-value'), the compass tells us to make that action more likely in similar situations. If it led to a bad outcome, it tells us to make it less likely. REINFORCE is the simplest way to follow this compass, but it's like a compass that swings wildly, making it hard to steer. TRPO and PPO are like adding a gyroscope and power steering: they ensure your steering adjustments aren't too drastic, so you move steadily towards the best strategy. TRPO uses a mathematical leash to keep the new strategy close to the old one, while PPO uses a clever trick of 'clipping' how much an action's probability can change to achieve a similar stabilizing effect with less computational overhead. DDPG and TD3 are different: they're like recording all your practice games and then watching them back later to learn. This lets them learn from many different plays, not just the very latest one, which is more efficient. They use two 'brains': one ('actor') to decide what to do and another ('critic') to judge how good that decision was. TD3 makes this even smarter by using two critics (like getting a second opinion) and letting the 'judging brain' get really good before the 'deciding brain' changes its strategy too much, preventing it from getting too optimistic about its own skills."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**14 end for**\n\n**15** redundant **return** NULL ; /* either one or both subflows unavailable */\n\nThe theoretical aspects of _ReMP TCP_ packet scheduling algorithm are provided in 2.2.6.\n\n**B** **Congestion Control Algorithms**\n\n**Algorithm 7:** CUBIC (v2.2)\n\nInitialization:\n\n_\ud835\udc61\ud835\udc50\ud835\udc5d_ _ _\ud835\udc53\ud835\udc5f\ud835\udc56\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60_ \u2190\u2212 1 _, \ud835\udefd_ \u2190\u2212 0 _._ 2\n\n_\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc52_ \u2190\u2212 1 _, \ud835\udc36_ \u2190\u2212 0 _._ 4\n\n_\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc52\ud835\udc61_ ()\n\nOn each ACK:\n\n**begin**"}, {"role": "assistant", "content": "**Mechanism:** The CUBIC algorithm functions as a feedback-driven control loop, adjusting network throughput based on acknowledgments. It initializes several state variables that define its operational parameters, and then continuously updates its state and output (likely congestion window) upon receiving each ACK.\n\n**Explanation:** The 'return NULL' line acts as an early exit condition, similar to an 'if-guard' in programming, ensuring the subsequent algorithm only runs if underlying resources (subflows) are available. CUBIC's 'Initialization' sets up its initial constants and configuration flags, such as its aggressiveness ('C'), how it reacts to packet loss ('beta'), and how quickly it adapts ('fast_convergence'). The core mechanism, triggered 'On each ACK', represents an event-driven loop. Each ACK signals a successful packet delivery, prompting the algorithm to execute an update function. This function uses the initialized parameters to calculate changes to the sending rate or congestion window, effectively probing for available bandwidth while attempting to maintain fairness and stability in the network. It's a continuous, reactive adjustment process, much like an embedded system's control loop."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**LLM Reasoning Data.** We analyze 14 open-weight **text reasoning models** spanning multiple architecture families and training paradigms. These include: Qwen3 hybrid models with thinking mode, R1Distilled models built on Qwen 2.5, R1-Distilled models built on Llama 3, several community-developed\nreasoning-tuned models (DeepScaleR-1.5B-Preview, s1.1-32B, OpenThinker-32B, DeepHermes-3-Llama-38B-Preview), and the frontier DeepSeek-R1 (671B), which also serves as the teacher model for R1-Distilled\nvariants. **Text-only reasoning problems** consist of 10,612 questions sampled from the `GeneralThought`\n(Taylor, 2024) and `ClaimSpect` (Kargupta et al., 2025) datasets. The `task` label in the dataset is used\n\n11\n\nto down-sample extremely common tasks (e.g., arithmetic, simple logic) to maintain a balanced representation. We use released DeepSeek-R1 traces from GeneralThought due to compute constraints. While\n`GeneralThought` provides a wide variety of tasks and domains, the dataset primarily focuses on verifiable\ntasks and consequently lacks problems of the type `Dilemma` [2] . Thus, we convert 290 real-world biomedical\nand geopolitical \"nuanced\" claims from ClaimSpect into questions to supplement the text-reasoning category.\n\n**Audio reasoning** is evaluated on BLAB for long-form reasoning (Ahia et al., 2025), MMAR for diverse task\ncoverage (Ma et al., 2025) and MMAU-Pro for diverse skill coverage (Kumar et al., 2025). Our final selection\nincludes 417 problems from BLAB, 888 from MMAR and 3,612 from MMAU-Pro. We analyze Qwen3-Omni30B as its the only open-weight audio-language model with thinking mode. We exclude commercial models\nsuch as Gemini and GPT-4 because they produce summarized traces that are not sufficiently reflective of\nthe underlying reasoning process.\n\nFor **image reasoning problems**, we directly use the reasoning traces in `Zebra-CoT` due to its comprehensive\ntask type coverage and curated reasoning traces. In Zebra-CoT, real-world traces are sourced from online\nmath, physics, coding, and chess datasets. Synthetic traces are created by generating or sourcing images\nonline and writing reasoning templates, then using frontier VLMs (Gemini-2.5 and GPT-4.1) to refine them\ninto more diverse and coherent reasoning traces (Li et al., 2025a). Additionally, this allows us to analyze\ncognitive elements in synthetic training data beyond raw model reasoning outputs. We sample 1,000 questionreasoning pairs from each task type to obtain 18,000 curated reasoning traces. Across all three modalities,\nwe collect 171,485 model reasoning traces for detailed analysis.\n\n**Human Reasoning Data.** We collected a small set of human reasoning traces, as qualitative reference\npoints for comparison with LLM-generated reasoning. We recruited 18 human participants to solve a small\nsubset of the `GeneralThought` dataset while recording their reasoning. These human traces overlap with a\nsubset of the LLM evaluation set and are intended to illustrate how key behaviors manifest in natural human\nreasoning, rather than to establish a full human benchmark.\n\nReasoning was recorded using a think-aloud protocol in which they recorded their verbal reasoning (later\ntranscribed with Evernote). Since some tasks require domain-specific facts or state tracking, we allow\nparticipants to use _tools_, including web search and note-taking. In such cases, participants were instructed\nto verbalize the tool usage, e.g., speaking the search keyword aloud.\n\nEach reasoning trace was annotated separately by two different human annotators, giving each reasoning trace\na score from a three-level scoring rubric (0=absent, 1=partially present, 2=present) across each behavior\nin our 28-behavior taxonomy. Scores from different annotators were aggregated via min-pooling, ensuring\nthat estimates of cognitive elements are conservative. These annotation data were later used for iteratively\nrefining the automatic span annotation prompts.\n\n**3.1.2** **Fine-Grained Cognitive Element Annotation**\n\nEach reasoning trace is annotated for the presence of behaviors that embody the cognitive elements from the\n28-behavior taxonomy introduced in Section 2 on the span-level. The annotation process identifies specific\ntext segments that demonstrate each cognitive capability, enabling precise localization of behaviors within\nreasoning processes.\n\nFor each cognitive element, we develop annotation guidelines that include: (1) operational definitions\ngrounded in cognitive science literature, (2) concrete behavioral indicators specifying how the capability\nmanifests in text, (3) three-level scoring rubrics, (4) manually curated in-context examples with explanations, and (5) span identification requirements using character indices. The annotation protocol requires\nmarking exact text boundaries using 0-based character positions, ensuring that identified spans can be\nprogrammatically extracted and verified.\n\nTo ensure psychological precision and annotation consistency, we iteratively refined the prompts human-inthe-loop, using the manual annotation data as the seed (Section 3.1.1) and collecting the same annotators\u2019\n\n2 `Dilemma` type: _resolving situations with contradictory positions and no clear satisfactory solution_ (Appendix A.2).\n\n12\n\nfeedback for each round. See Appendix A.1 for exact prompts used for the analysis. Using these refined\nprompts, full-scale annotation was then performed using **GPT-4.1** with temperature 0.6.\n\n**3.1.3** **Problem Type Classification & Response Evaluation**\n\n**Jonassen\u2019s Problem Taxonomy.** We extend the problem-solving taxonomy in Jonassen (2000) to classify\ncognitive tasks in our dataset. Jonassen (2000) defines problem solving as a goal-directed cognitive activity\nthat transforms an _initial state_ into a _desired goal state_ through systematic reasoning, proposing a typology of\n11 problem types: logical problems, algorithms, story problems, rule-using, decision-making, troubleshooting,\ndiagnosis-solution, strategic performance, case analysis, design, and dilemmas. Jonassen & Hung (2015)\nfurther characterizes ten out of the eleven problems types along a continuum from well-structured (clear\ngoals, known solution paths, predictable outcomes) to ill-structured (ambiguous goals, multiple solution\npaths, uncertain outcomes). However, not all tasks in the `GeneralThought` dataset require goal-directed\ntransformation. We add two categories to capture tasks outside this paradigm: factual recall (retrieving\nstored knowledge without reasoning) and creative/expressive tasks (generating novel content judged by\noriginality or aesthetic quality rather than convergence to a predetermined solution). This yields a **13-**\n**category taxonomy** (Appendix A.2) spanning the full spectrum of cognitive demands in our datasets.\n\n**Problem Classification.** For each problem, we determine its type through majority voting across three\nfrontier models: `4o-mini`, `Gemini-2.5-Pro`, and `Claude-Sonnet-4.5` . Each model independently classifies\nthe problem based on the Jonassen (2000) definitions. Three-way disagreements occur in under 3% of cases;\nwe adjudicate these manually using Jonassen\u2019s structural criteria (goal clarity, solution determinacy, domain\nconstraints). This multi-model approach mitigates individual model biases while maintaining scalability.\n\n**Response Correctness.** AlpacaEval (Dubois et al., 2024) with `GPT-4o` as the judge is used to assess\nresponse correctness. For each problem-response pair, the LLM judge receives the original problem, the\nmodel\u2019s response, and a reference response. Ground truth answer is used as the reference for verifiable tasks\nand `Claude-Sonnet-4.5` \u2019s response (selected for strong benchmark performance) for non-verifiable tasks.\n\n**3.1.4** **Cognitive Structure Extraction**\n\nBeyond assessing each behavior\u2019s presence within a reasoning trace, our span-level annotation approach enables fine-grained, quantitative analysis of behaviors and their interdependencies. Specifically, we seek to\nanalyze how a reasoner subconsciously structures and sequences specific behaviors throughout their reasoning process. In order to extract this structure, we choose to encode the reasoning trace _t_ as a heterogeneous\ntransition graph _G_, where each node represents a single behavior from our 28-behavior taxonomy, and each\nedge can either represent a _hierarchical_ ( `CONTAINS` ), _sequential_ ( `NEXT` ), or _parallel_ ( `PAR` ) behavior relationships. We compute a weight _w_ for each node and edge based on its normalized pointwise mutual information\n(NPMI) score. We calculate the NPMI using the individual and joint probabilities of _**(a)**_ behavior _b_ occurring\nin a reasoning trace _t_ and _**(b)**_ trace _t_ successfully resulting in a correct answer.\n\nIn order to construct _G_, we first sort all annotated behavior spans within trace _t_ by their start positions, with\nties broken by span length in descending order. For each pair of behaviors ( _ba, bb_ ) with corresponding spans\n\n[ _sa, ea_ ] and [ _sb, eb_ ] where _sa \u2264_ _sb_, we determine their relationship type through a multi-stage classification\n\nprocess:\n\n1. `PAR` : Whether the Manhattan distance between the spans ( _|sb \u2212_ _sa|_ + _|eb \u2212_ _ea|_ ) falls below a threshold\n_\u03c4par_ ( _ba_ and _bb_ occur nearly simultaneously).\n\n2. `CONTAINS` : If _sb \u2264_ _ea \u2264_ _eb_, we compute the overlap ratio _\u03c1_ = _eeab\u2212\u2212ssbb_ [; when] _[ \u03c1]_ [ exceeds threshold]\n_\u03c4overlap_ ( _ba_ hierarchically encompasses _bb_ ).\n\n3. `NEXT` : If _ea < sb_, _ea < eb_ and the overlap is below _\u03c4overlap_, or if _ea > eb_ but their overlap ratio\n_eb\u2212sb_\n_ea\u2212sa_ _[< \u03c4][overlap]_ [ (] _[b][a]_ [ is followed by] _[ b][b]_ [).]\n\n13\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-13-0.png)\n\n(a) Problem Type Distribution by Modality\n\n(b) Accuracy by Problem Type and Model\n\nFigure 3: Dataset composition and model performance across problem types. (a) Problem distribution\nacross modalities, organized by Jonassen\u2019s problem structuredness continuum, shows coverage decreases for\nless structured problems. (b) Accuracy decreases as problems become less structured, with models showing\nconsistent performance on algorithmic tasks (63.8%) but high variance on dilemmas (3.3-99.1%).\n\nWe set _\u03c4par_ = 20 (characters) and _\u03c4overlap_ = 0 _._ 8. To ensure graph sparsity and capture only direct sequential\ndependencies, we apply a refinement step: for each behavior _ba_, we retain only the first `NEXT` edge to\nan immediately subsequent non-overlapping behavior, filtering out transitive connections to more distant\nbehaviors. This process yields a directed graph that preserves both the hierarchical decomposition and\ntemporal ordering of reasoning behaviors within each trace.\n\n**3.2** **Experimental Setup**\n\n**3.2.1** **Dataset Composition**\n\n**Problem Type.** The distribution of problem types (Figure 3a) varies substantially across modalities but\ndecrease as the problem becomes less structured. Algorithmic problems dominate with 6,300 text, 8,400\nimage, and 800 audio samples. Among structured types, Rule-Using shows strong concentration in images\n(4,447 samples) versus text (521) and audio (248). Notably, Strategic Performance has zero instances across\nall modalities, while the LLM classifiers frequently considered this category with explanations including \" _I_\n_considered Strategic Performance but rejected it because this is an offline planning problem under perfect_\n_information, not real-time execution_ .\" Strategic Performance necessitates interactive benchmarking, which is\nnot feasible under our experimental constraint to generate reasoning traces to the same input across models,\nbut the lack of this problem type in the single-turn, static benchmarks echos the call for interactive evaluation\nof models (Hofmann et al., 2025; Li et al., 2024). Three problem types fall outside the structuredness ranking:\nFactual Recall is the most prevalent, showing balanced representation across modalities (2,841 text, 2,663\nimage, 3,307 audio) and representing the second-largest category overall. Logical problems, involving abstract\nreasoning, are heavily image-focused (2,215 samples) but rare in text (57) and audio (152). Overall, text\nreasoning shows the broadest distribution across problem types, while image and audio concentrate on\nAlgorithmic, Rule-Using, Logical, and Factual Recall.\n\n**Success Rate.** Success rates vary substantially by problem structure (Figure 3b). Well-structured problems achieve higher correctness overall (algorithms: 63.8%, story problems: 79.5%), while ill-structured\nproblems average lower success (design: 46.6%). Dilemma tasks show polarization (3.2-99.1%) depending on\nthe model size. Detailed model-specific performance breakdowns appear in Appendix A.3.\n\n14\n\n**3.2.2** **Analysis Dimensions**\n\nTo thoroughly examine the manifestation of behaviors within reasoning traces, we organize our analysis\naround three interconnected research questions:\n\n1. _**Which behaviors are most prevalent in reasoning traces, and how does their frequency**_\n_**relate to reasoning success?**_ We investigate the distribution of reasoning behaviors across different\nmodels and problem types, examining whether prevalence patterns vary along Jonassen\u2019s well-structured\nto ill-structured problem continuum. Critically, we distinguish between behaviors that are frequently\nexhibited and those that are most strongly correlated with correct outcomes, as these sets may not align.\nThis analysis reveals whether models consistently employ the behaviors most conducive to success or\ninstead are biased towards alternative strategies.\n\n2. _**What structural dependencies exist between reasoning behaviors?**_ Beyond examining individual behavior presence, we analyze their temporal and hierarchical interdependencies within reasoning\ntraces. The mere presence of success-correlated behaviors does not guarantee effective reasoning; rather,\nthe _ordering and composition_ of behaviors critically influences problem-solving efficacy. For instance,\nwhen resolving a dilemma, failure to employ `conceptual processing` to `decompose` the problem into\nconstituent considerations early in the reasoning process may fundamentally compromise the efficiency\nand quality of the eventual judgment, even if these behaviors appear later. To identify optimal behavior sequences, we leverage our transition graph representation (Section 3.1.4) to extract consensus\nsubgraphs\u2014common structural patterns that maximize collective NPMI scores across successful traces,\nthereby revealing the behavioral scaffolding most strongly associated with correct reasoning.\n\n3. _**How do behavioral structures differ between LLMs and human reasoners?**_ We conduct a\ncomparative study examining both the distributional characteristics of behaviors exhibited by LLMs\nversus humans on a shared problem set, and perform fine-grained, span-level qualitative analysis to\nunderstand how they differ in their reasoning processes and behavior utilization strategies.\n\n**3.3** **Results & Analyses**\n\n**3.3.1** **Distribution of Cognitive Elements**\n\nThe first phase of our analysis investigates the misalignment between cognitive elements that models frequently deploy (through behavioral manifestation) versus those that correlate most strongly with success.\nFigure 4 presents this contrast: the left heatmap shows behavioral prevalence across all traces for each\nproblem type, while the right displays the positive pointwise mutual information (PPMI) between behavior\noccurrence and trace success.\n\n**Models deploy behaviors inversely to what success requires.** The contrasting patterns between the\ntwo heatmaps reveal a fundamental misalignment in how models adapt their reasoning strategies. On wellstructured problems (e.g., algorithmic, rule-using), models deploy a broad repertoire of behaviors at high\nfrequencies, where the average presence across all behaviors is 0 _._ 3652 _\u00b1_ 0 _._ 2598 for algorithmic, story, and\nrule-using problems. As problems become ill-structured and non-verifiable, however, models _narrow_ their\nbehavioral repertoire: ill-structured problems like case analysis, design, and dilemma have a 0 _._ 2787 _\u00b1_ 0 _._ 2672\naverage presence across all behaviors, with usage concentrating heavily on `sequential organization`,\n\n`logical coherence`, and `forward chaining` .\n\nThis narrowing strategy is the opposite of what is reflected in successful traces. The right heatmap reveals\nthat _overall success on ill-structured problems demands greater behavioral diversity_ . As we move from wellstructured to ill-structured problem types, the PPMI scores become more uniformly elevated across a wider\nrange of behaviors, particularly diverse `representations` (hierarchical, network, spatial, temporal) and\nvaried `operations` (backward chaining, representational restructuring, pattern recognition). Specifically,\nalgorithmic, story, and rule-using problems have an average PPMI score of 0 _._ 052 _\u00b1_ 0 _._ 067 across all behaviors,\nwhile the last four ill-structured problems (from diagnosis-solution to dilemma) have an average score of\n0 _._ 224 _\u00b1_ 0 _._ 182.\n\n15\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-15-0.png)\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-15-1.png)\n\nFigure 4: _**(Left)**_ Presence rate of each reasoning behavior for each problem type (ranging from well-structured\nto ill-structured). _**(Right)**_ Positive Pointwise Mutual Information (PPMI) between the problem type and\nreasoning behavior (correlation between the behavior occurrence and reasoning trace success).\n\nThus, while well-structured problems, which are more tolerant of uniform approaches, receive broad behavioral engagement, ill-structured problems, which critically require a diverse repertoire of reasoning behaviors,\nonly receive a subset dominated by `sequential processing` and `forward chaining` . This inverse relationship between behavioral deployment and success reflects that models have learned to apply their most\ndiverse reasoning behaviors where they are the least necessary, _**while defaulting to limited, inflexible**_\n_**strategies precisely where adaptability matters most**_ .\n\n**Models frequently attempt core reasoning behaviors but struggle to execute them effectively.**\nReasoning invariants\u2014particularly `logical coherence` and `compositionality` \u2014appear ubiquitously\nacross problem types, yet show surprisingly weak correlation with success. For example, logical coherence\u2019s average NPMI across all problem types is 0 _._ 0984, whereas knowledge alignment features an average\nscore of 0 _._ 301. Manual inspection of traces by human annotators reveals a systematic pattern. While models\nfrequently attempt to identify logical inconsistencies and contradictions, they consistently fail to recognize or\neffectively respond to them, unlike human reasoners. This execution gap explains the discrepancy between\nhigh prevalence and low predictive value of these foundational behaviors.\n\n**Models show limited meta-cognitive success, especially on problems lacking clear ground truth.**\nThe `evaluation` element similarly demonstrates high prevalence but negligible success correlation, with\nits frequency declining sharply for ill-structured problems (case analysis, dilemma). This pattern suggests\nmodels struggle particularly with self-assessment on non-verifiable problems where ground truth is ambiguous\nor absent.\n\n**Default sequential organization hampers performance when problems require alternative rep-**\n**resentations.** Models exhibit strong preference for `sequential` and `causal organization` regardless\nof problem type. However, the success patterns indicate that as the problem type becomes less structured\n(algorithmic _\u2192_ dilemma), diverse organizational strategies\u2014including hierarchical, network, ordinal, temporal, and spatial representations\u2014become increasingly critical. This reflects a fundamental challenge of\nill-defined problems: when problem descriptions lack inherent structure, successful reasoners must actively\nconstruct appropriate organizational frameworks rather than defaulting to sequential processing.\n\n**Operational rigidity limits models\u2019 ability to adapt reasoning strategies to problem de-**\n**mands.** Similar rigidity emerges in reasoning operations. Models consistently favor `selective attention`,\n\n16\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-16-1.png)\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-16-0.png)\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-16-2.png)\n\nFigure 5: The _most successful_ vs. _most common_ 7-node behavioral pattern across all _**Diagnosis-Solution**_\nreasoning trace with the correlation to success (NPMI) and the probability of each node.\n\n`decomposition and integration`, and `forward chaining`, the latter being a natural consequence of\ntheir sequential organizational bias. Successful traces, however, demonstrate substantially greater operational diversity, adapting their reasoning strategies to problem characteristics rather than applying uniform\napproaches.\n\nThese findings reveal a fundamental misalignment: models seem to deploy behavioral strategies based on\nlearned priors rather than adapting to problem-specific demands, resulting in systematic gaps between frequently used behaviors and those that actually drive success.\n\n**Model-Specific Behavior Distribution** To complement our problem-type analysis, we examine how\nbehavioral deployment varies across different model architectures and modalities. Figure 6 displays the\npresence rate of each reasoning behavior across eleven models, including text-only systems (the majority),\naudio-capable models (Qwen3-Omni), and vision-language models (Zebra-CoT).\n\nSeveral behaviors exhibit consistently high presence rates across nearly all models, suggesting core reasoning primitives that emerge regardless of architecture or training methodology. `Backtracking]` appears\nfrequently across all models (presence rates exceeding 0.8 across all models), indicating that iterative refinement and error correction are prominent components of model reasoning processes.\n\nWith respect to the different modalities, we observe that the audio and image models have overall less\npresence of reasoning behaviors, exhibiting certain behaviors frequently (e.g., `evaluation`, `productivity` )\nand others minimally, relative to the textual models. This indicates that there may be lower diversity of\nreasoning behaviors present in multimodal models.\n\n**3.3.2** **Behavioral Structures**\n\nOur analysis in Section 3.3.1 demonstrated that successful reasoning traces exhibit diverse behaviors, adapting their selection to problem-specific demands. However, behavioral presence alone provides an incomplete\npicture. Thus, we ask: does the _temporal and hierarchical organization_ of these behaviors also differ between\nsuccessful and unsuccessful traces? To address this question, we extract optimal behavioral structures for\neach problem type by analyzing the transition graphs constructed from all model traces _T_ .\n\n**Behavioral consensus subgraph extraction.** We leverage the graph construction methodology detailed\nin Section 3.1.4 to encode and aggregate reasoning traces for each problem type, yielding a complete transition\ngraph _G_ where each node represents a behavior and each edge captures their relationship (hierarchical,\n\n17\n\nsequential, or parallel). Each node and edge is weighted by its NPMI score, quantifying the strength of\nassociation between that behavioral element and trace success.\n\nGiven graph _G_, we extract a consensus subgraph _G_ _[\u2217]_ _\u2286_ _G_ that represents the prototypical successful reasoning\nstructure through a greedy forward search procedure. First, we identify the starting behavior by selecting\nthe node with highest NPMI among behaviors that initiate successful traces (i.e., behaviors with the earliest\ntemporal spans). We denote this initial node as _b_ start. From the current behavior _b_ curr, we iteratively expand\nthe consensus structure by selecting the outgoing edge ( _b_ curr _, b_ next _, e_ type) with the maximum NPMI score,\nwhere _e_ type _\u2208{_ `CONTAINS` _,_ `NEXT` _,_ `PAR` _}_ . To ensure acyclicity and prevent redundant paths, we maintain a\nvisited set and exclude any target behaviors already present in _G_ _[\u2217]_ . This process continues until either: (1)\nwe reach a predefined maximum number of nodes _|V_ max _|_, (2) no valid outgoing edges exist from _b_ curr, or (3)\nwhen operating in dynamic mode, all remaining edges have non-positive NPMI scores, indicating they do\nnot positively correlate with success.\n\nThe resulting consensus subgraph _G_ _[\u2217]_ represents\nthe behavioral scaffolding most strongly associated\nwith successful reasoning for the given problem\ntype. Critically, this structure captures not merely\nwhich behaviors appear, but _how they are sequenced_\n_and composed_ \u2014revealing the temporal dependencies and hierarchical decompositions that characterize effective problem-solving strategies. By comparing _G_ _[\u2217]_ across problem types, we can identify\nwhether optimal reasoning structures remain consistent or adapt fundamentally to different levels of\nproblem structure.\n\n**Analysis.** Figure 5 illustrates the consensus subgraph constructed for Algorithmic problems. We\nobserve that successful traces begin with selective\nattention to identify relevant problem features, followed by sequential organization and forward chain- Figure 6: Presence rate of each reasoning behavior\ning to execute solution steps. This structure con- for each model (how often is the behavior occurring\ntrasts sharply with the most common pattern, which across all reasoning traces for a model), including all\nprioritizes logical coherence and compositionality modalities (Qwen3-Omni: audio; Zebra-CoT: image).\nearly but achieves lower success correlation. The\ndivergence suggests that immediate focus on abstract reasoning principles without first attending to problemspecific constraints leads to less effective problem-solving on algorithmic tasks.\n\n**3.4** **Comparison with Humans**\n\n**Distribution of Elements.** To complement our analysis of cognitive element presence and structure\nacross models and problem types, we compare 30 manually annotated reasoning traces from both humans\nand LLMs. Figure 7 presents elements annotated as _strongly_ present, excluding partial occurrences. Human traces exhibit significantly higher rates of abstract cognitive elements, such as self-awareness (49% vs.\n19%), abstraction (54% vs. 36%). Notably, reasoning representations were frequently marked as partially\npresent across both groups, particularly for humans, likely reflecting the more implicit nature of their internal knowledge representations and reasoning processes. Conversely, LLMs demonstrate greater reliance on\nbackward chaining (navigating a problem by reasoning from goals to prerequisites; less common in human\nproblem-solving), and higher productivity scores (potentially attributable to LLMs\u2019 tendency to externalize\nintermediate reasoning steps that humans often leave implicit).\n\n**Qualitative comparative analysis.** Table 3 illustrates the difference between human and LLM reasoning\ntraces. As shown, Humans are quicker to invoke conceptual processing and abstraction in logical problem\nsolving, leading to significantly shorter reasoning traces. LLM\u2019s on the other hand, often resort to surface level\n\n18\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-17-0.png)\nTable 3: Illustrative examples of differences between human and LLM reasoning traces. This table shows\npartial (for brevity) reasoning traces of both humans and DeepSeek-R1 on the same problems for both\nLogical and Design problems. Spans containing behaviororal manifestation of cognitive elements, or lack\nthereof are annotated, with the cognitive element added using <> tags.\n\n|Problem|Annotator|ReasoningTraceExcerpt|\n|---|---|---|\n|Logical|Human<br>(166 tokens)|...<br>So here\u2019s how we do it.<br>It is eight square right and we painted the board with black and white just<br>like, you know, chessboard.<br>I\u2019m not sure but what you will fnd out is that the two corner you throw<br>away is both black or...<br>Anyway, let\u2019s frst paint the upper left corner black and any cell near it white.<br>`And then the cell near white cell is black and so on and what you will find is that the two...`<br>`the two corners are always both black`**` <abstraction>`** . But every domino covers exactly white and black.<br>So you cannot do that because you have` more white cells than the black cells`**` <conceptual processing>`** .<br>`Okay.`<br>`So this is it, I think`**` <no verbalized verification>`** .|\n|Logical|DeepSeek-R1<br>(7,632 tokens)|...<br>In<br>an<br>8x8<br>checkerboard,<br>each<br>diagonal<br>has<br>squares<br>of<br>alternating<br>colors.<br>...<br>`Wait, let\u2019s count.`<br>`(1,1) is black, (2,2) is white, (3,3) black, (4,4) white, (5,5) black, (6,6)`<br>`white, (7,7) black, (8,8) white`**` <no abstraction>`** .<br>So<br>the<br>diagonal<br>from<br>(1,1)<br>to<br>(8,8)<br>would<br>have<br>squares<br>that<br>alternate<br>colors.<br>[...]<br>`Wait, maybe the diagonally opposite corners`<br>`are the same color`**` <`****_`slight`_****` abstraction>`** .<br>Let<br>me<br>check<br>again.<br>[...]<br>`Wait, maybe there\u2019s`<br>`another reason`**` <verification>`** . Maybe the parity or the arrangement. [...] For example, if the board is split<br>into regions that can\u2019t be covered by dominoes. But how?... Therefore, even though the black and white counts<br>are balanced, theparity based on i+j is not, leading to impossibility.|\n|Design|Human<br>(2,071 tokens)|`For this task is to decide on a comprehensive policy reform for healthcare that integrates three`<br>`goals.`<br>**`<decomposition>`**<br>...<br>`And the approach I\u2019m going to to take here is`**`<strategy selection>`**<br>...<br>`I will pick the system that has the best rank overall over those three trade-offs.`<br>**`<ordinal organization>`**<br>...<br>So<br>searching<br>with<br>Google,<br>...<br>the<br>sec-<br>ond<br>result<br>I<br>get<br>is<br>from<br>Columbia<br>University,<br>their<br>school<br>of<br>public<br>health.<br>`So that seems like a reliable source.`<br>**`<context awareness>`**<br>`And it says,`<br>`I go to this page, it says types of healthcare systems.`<br>**`<selective attention>`**<br>It says there are<br>four diferent types of healthcare models.<br>`All right, so that sounds pretty promising.`<br>**`<evaluation>`**<br>...<br>I\u2019m gonna say one aspect of quality of care is access.<br>...<br>I think the one where the government<br>pays but you get to pick your own doctor, that was going to have the best access.<br>So I\u2019m going to say<br>the single payer model is going to be number one.<br>...<br>And then in the Bismarck model, there\u2019s still<br>public<br>and<br>private<br>actors.<br>`So I\u2019m going to give that number two, and then Beveridge is going`<br>`to get number three.`<br>**`<knowledge alignment>`**<br>...<br>So<br>what<br>I\u2019m<br>going<br>to<br>do<br>is<br>I\u2019m<br>going<br>to<br>`calculate the composite score by summing the ranks.`**`<abstraction>`**<br>...<br>And so this surprised me<br>by my ranking out of pocket is the best system. You know, ... where you pay your doctor a fee directly ...<br>without an insurance company.` So this surprises me a bit.`<br>**`<self-awareness>`**|\n|Design|DeepSeek-R1<br>(747 tokens)|Okay, so I need to come up with a comprehensive policy reform for the U.S. healthcare payment system. The<br>goal is to integrate payment systems to reduce waste and fraud, improve quality, and make healthcare more<br>patient-centered.<br>`Let me start by breaking down the problem.`<br>**`<decomposition>`** First, the current sys-<br>tem is fragmented.<br>There are multiple payers\u2014Medicare, Medicaid, private insurers, etc.\u2014each with their<br>own payment structures. This fragmentation probably leads to administrative inefciencies. Providers have to<br>deal with diferent billing systems, which is time-consuming and costly.<br>`Also, patients might get confused`<br>`with varying coverage and out-of-pocket costs.`<br>**`<causal organization>`**<br>...<br>So, putting this all to-<br>gether, the policy should have components like standardized payment systems, value-based reimbursement, cen-<br>tralized fraud detection, patient empowerment through transparency, and integration of social services. Also,<br>regulatory support andphased implementation to manage the transition.|\n\nreiteration and enumeration. While LLMs try to reason abstractly and verify their reasoning, our Human\nannotators have repeatedly observed that they fail at learning from previous verifications in subsequent\nproblem solving attempts, and they often repeat verification and backtracking on claims and paths that\nhave already been explored. On more open ended questions, or questions that require complex factual recall,\nhumans tend to invoke higher order behaviors such as self-awareness and strategy selection, leading to longer\ntraces then LLMs, which seem to rely more on factual recall of relevant infromation."}, {"role": "assistant", "content": "**Mechanism:** The core idea is to reverse-engineer how intelligence solves problems by observing 'thinking actions' (behaviors) and mapping their sequence and interaction. Imagine each distinct 'thinking step' (like 'breaking down the problem' or 'checking my work') is a function call or a subroutine in a program. For both human and AI 'reasoning programs', we record a 'trace' \u2013 a log of these function calls, noting *when* they started and *when* they ended (using character indices, like memory addresses for code segments). This log is then converted into a directed graph, much like a control flow graph or a finite state machine. Each node is a thinking step, and an edge shows how steps connect: one step can `CONTAIN` another (a subroutine calls another), one can come `NEXT` after another (sequential execution), or they can run in `PAR`allel (simultaneous execution, within a small time window). We then 'weight' these nodes and edges with an NPMI score \u2013 intuitively, this is like a 'signal-to-noise' ratio: if a particular thinking step or sequence of steps appears much more often in *successful* problem-solving runs than you'd expect by chance, it gets a high positive weight. This allows us to statistically identify the 'critical path' of thinking, or the most effective 'design patterns' for solving different kinds of problems, without needing to know the internal black box of the LLM or human brain. It's essentially building a 'performance profile' of cognitive strategies.\n\n**Explanation:** At its heart, this work is trying to understand the 'source code' of reasoning, even for systems we can't directly inspect like human brains or large language models (LLMs). First, they gathered a massive dataset of 'reasoning traces' \u2013 essentially detailed step-by-step logs of how different LLMs and a small group of humans solved problems. These problems were diverse: text-based logic puzzles, audio comprehension tasks, and image-based reasoning. For humans, they literally asked them to 'think aloud' while solving problems, like printing debug statements during program execution. The crucial part is the 'annotation'. They defined 28 specific 'cognitive behaviors' \u2013 like 'decomposition' (breaking a complex problem into smaller parts, like a function splitting a big task) or 'forward chaining' (step-by-step deduction, like iterating through a list). Human experts then meticulously marked *exactly* which parts of the text (or transcribed speech) corresponded to *which* behavior, down to specific character ranges. This is like assigning 'tags' to specific lines of code indicating their purpose. Then, they built what they call a 'transition graph'. Imagine each cognitive behavior is a data structure, a node in a graph. If 'behavior A' happens and then 'behavior B' happens right after, they draw a 'NEXT' edge. If 'behavior A' involves 'behavior B' as a sub-process, they draw a 'CONTAINS' edge. If two behaviors happen almost at the same time, a 'PAR' (parallel) edge. Each node and edge is given a 'score' using something called Normalized Pointwise Mutual Information (NPMI). Think of NPMI as a measure of how 'predictive' a behavior or a sequence of behaviors is for *successful* problem-solving. If a behavior is much more likely to show up in a correct answer trace than in an incorrect one, it gets a high NPMI score. This lets them identify not just *what* behaviors are present, but *which ones truly matter for getting the right answer*. What they found is quite interesting: LLMs often default to a limited set of sequential reasoning 'algorithms' (like 'forward chaining' or simply 'enumerating facts'), even for complex, 'ill-structured' problems (like design challenges) where humans would use a much more diverse and adaptive set of strategies, like 'abstraction' or 'self-awareness'. It's like a program having a great sorting algorithm but trying to use it for every single problem, even when a hash map or a recursive search would be more appropriate. They also noted LLMs often *attempt* core behaviors like 'logical coherence' (checking for internal consistency) but frequently *fail* at effective execution, which is like a `try-catch` block that always catches but never fixes the error. This suggests a gap in how LLMs *deploy* their capabilities versus what actually leads to success."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each node \ud835\udc62_ \u2208 _\ud835\udc49_ **do**\n\n**8** vol[ _\ud835\udc62_ ] \u2190 the volume of _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f\ud835\udc56,\ud835\udc62_ );\n\n**9** _\ud835\udf05_ \u02dc \u2190 _\ud835\udf05_ \u02dc + DFS ( _\ud835\udc5f_, _\ud835\udf0f\ud835\udc56_, _\ud835\udf0f_ 0);\n\n**10 return** \u02dc _\ud835\udf05_ /(2 _\ud835\udc5a_ - _\ud835\udf14_ );\n\n**11 Function** DFS _(\ud835\udc63, \ud835\udf0f, \ud835\udf0f_ 0 _)_ **:**\n\n**12** Let _\ud835\udc5d_ ( _\ud835\udc63_ ) be the parent node of _\ud835\udc63_ in _\ud835\udf0f_ ;"}, {"role": "assistant", "content": "**Mechanism:** The mechanism involves iterating through each node in a graph, performing a localized 'volume' calculation for a subtree associated with that node, and then cumulatively summing results from multiple Depth-First Search (DFS) traversals. The DFS function itself leverages a parent-pointer lookup to navigate the tree structure.\n\n**Explanation:** This segment first loops through every node in the graph, much like a `for-each` loop in programming. For each node `u`, it computes a `vol[u]`, which can be thought of as storing a pre-calculated property (like a sum of weights or count of nodes) of a specific subtree `Sub(\u03c4i,u)` rooted at `u` within a given tree `\u03c4i`. This is akin to populating an array or hash map with precomputed values. Subsequently, it repeatedly calls a recursive `DFS` function, adding its return value to an accumulator `\u03ba\u0303`. This `DFS` function is a standard tree traversal algorithm, starting from a root `r` within the tree `\u03c4i`. The key part in the `DFS` is identifying `p(v)`, the parent of the current node `v` in `\u03c4i`. This parent lookup is fundamental for navigating a tree, allowing algorithms to move upwards, trace paths, or understand local connectivity. The process efficiently aggregates specific metrics across different subtrees or traversals. Finally, `\u03ba\u0303` is normalized by a factor involving `m` (likely total edges) and `\u03c9`, yielding a scaled metric."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this work, we introduce a new task in the area of _Dataset Distillation_ : learning a tiny set of synthetic\nimages designed to train **linear probes** on top of **pre-trained self-supervised vision models** . Our\nproposed solution, _Linear Gradient Matching_, optimizes a meta gradient objective to ensure that our\nsynthetic images induce training updates similar to those obtained from the real data. Quantitatively,\nour method outperforms all baselines, enabling, for example, a DINO-v2 linear probe to reach 75%\ntest accuracy on ImageNet-1k while only having ever seen **one labeled image** per class.\n\nWe also showcase the importance of secondary aspects of our Linear Gradient Matching method, such\nas the pyramid representation and differentiable augmentations, and highlight their importance in\nlearning highly efficacious distilled datasets. Furthermore, we evaluate our method on challenging finegrained datasets and show that it out-performs the real-image baselines by an even larger margin than\non the standard ImageNet benchmarks. Lastly, our method yields several interesting interpretability\nresults, such as giving insights into how these pre-trained models \u201csee,\u201d predicting how well different\nmodels align, or elucidating a model\u2019s ability to generalize beyond its training distribution.\n\nWe hope our work brings to light the interesting set of problems posed by this new task and inspires\n[others to continue in this area. Code and distilled datasets can be found on our project page.](http://georgecazenavette.github.io/linear-gm)\n\n10\n\n**Acknowledgments**\n\nThis work was supported by the National Science Foundation under Grant No. 2211259, by the\nSingapore DSTA under DST00OECI20300823 (New Representations for Vision, 3D Self-Supervised\nLearning for Label-Efficient Vision), by the Intelligence Advanced Research Projects Activity\n(IARPA) via Department of Interior/Interior Business Center (DOI/IBC) under 140D0423C0075, by\nONR MURI grant #033697-00007, by the Amazon Science Hub, by the MIT-Google Program for\nComputing Innovation, by Sony Interactive Entertainment, and by a 2025 MIT ORCD Seed Fund\nCompute Grant.\n\n11\n\n**References**\n\n[[1] Adam McLean. The surrealism website. https://surrealism.website/. 16](https://surrealism.website/)\n\n[2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski,\nG. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong,\nM. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang,\nY. Lu, C. K. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, S. Zhang,\nM. Suo, P. Tillet, X. Zhao, E. Wang, K. Zhou, R. Zou, X. Wang, A. Mathews, W. Wen, G. Chanan, P. Wu,\nand S. Chintala. Pytorch 2: Faster machine learning through dynamic python bytecode transformation and\ngraph compilation. In _Proceedings of the 29th ACM International Conference on Architectural Support for_\n_Programming Languages and Operating Systems, Volume 2_, ASPLOS \u201924, New York, NY, USA, 2024.\nAssociation for Computing Machinery. 15, 16\n\n[3] L. Bossard, M. Guillaumin, and L. Van Gool. Food-101 \u2013 mining discriminative components with random\nforests. In _ECCV_, 2014. 16, 17, 36\n\n[4] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke,\nJ. VanderPlas, S. Wanderman-Milne, and Q. Zhang. JAX: composable transformations of Python+NumPy\nprograms, 2018. 15\n\n[5] M. Caron, H. Touvron, I. Misra, H. J\u00e9gou, J. Mairal, P. Bojanowski, and A. Joulin. Emerging properties in\nself-supervised vision transformers. In _ICCV_, 2021. 3, 10, 16\n\n[6] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros, and J.-Y. Zhu. Dataset distillation by matching training\ntrajectories. In _CVPR_, 2022. 1, 2, 3, 4, 6\n\n[7] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros, and J.-Y. Zhu. Generalizing dataset distillation via\ndeep generative prior. In _CVPR_, 2023. 1, 3, 4, 6, 7\n\n[8] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual\nrepresentations. In _ICML_, 2020. 3\n\n[9] X. Chen, H. Fan, R. Girshick, and K. He. Improved baselines with momentum contrastive learning. _arXiv_\n_preprint arXiv:2003.04297_, 2020.\n\n[10] X. Chen, S. Xie, and K. He. An empirical study of training self-supervised vision transformers. In _ICCV_,\n2021. 3, 5, 8, 17, 21\n\n[11] J. Cui, R. Wang, S. Si, and C.-J. Hsieh. Scaling up dataset distillation to imagenet-1k with constant memory.\nIn _ICML_, 2023. 1, 3\n\n[12] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image\ndatabase. In _CVPR_, 2009. 2, 5, 8, 10, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31\n\n[13] Y. Fang, Q. Sun, X. Wang, T. Huang, X. Wang, and Y. Cao. Eva-02: A visual representation for neon\ngenesis. _Image and Vision Computing_, 2024. 3, 16, 20\n\n[14] Y. Fang, W. Wang, B. Xie, Q. Sun, L. Wu, X. Wang, T. Huang, X. Wang, and Y. Cao. Eva: Exploring the\nlimits of masked visual representation learning at scale. In _CVPR_, 2023. 3, 5, 17\n\n[15] S. Fort and J. Whitaker. Direct ascent synthesis: Revealing hidden generative capabilities in discriminative\nmodels. _arXiv preprint arXiv:2502.07753_, 2025. 4\n\n[16] Z. Guo, K. Wang, G. Cazenavette, H. LI, K. Zhang, and Y. You. Towards lossless dataset distillation via\ndifficulty-aligned trajectory matching. In _ICLR_, 2024. 1, 3\n\n[17] K. He, X. Chen, S. Xie, Y. Li, P. Doll\u00e1r, and R. Girshick. Masked autoencoders are scalable vision learners.\nIn _CVPR_, 2022. 3\n\n[18] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation\nlearning. In _CVPR_, 2020. 3\n\n[[19] Hugging Face. Hugging Face: The AI community building the future. https://huggingface.co,](https://huggingface.co)\n2016. 16\n\n[20] M. Huh, B. Cheung, T. Wang, and P. Isola. Position: The platonic representation hypothesis. In _ICML_,\n2024. 2, 3, 9\n\n12\n\n[21] A. Khosla, N. Jayadevaprakash, B. Yao, and L. Fei-Fei. Novel dataset for fine-grained image categorization.\nIn _CVPR_, 2011. 5, 9, 16, 17, 32\n\n[22] D. Kingma and J. Ba. Adam: A method for stochastic optimization. In _ICLR_, 2015. 15\n\n[23] P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L.\nPhillips, I. Gao, T. Lee, E. David, I. Stavness, W. Guo, B. A. Earnshaw, I. S. Haque, S. Beery, J. Leskovec,\nA. Kundaje, E. Pierson, S. Levine, C. Finn, and P. Liang. WILDS: A benchmark of in-the-wild distribution\nshifts. In _ICML_, 2021. 16\n\n[24] P. Liao, X. Li, X. Liu, and K. Keutzer. The artbench dataset: Benchmarking generative models with\nartworks. _arXiv preprint arXiv:2206.11404_, 2022. 5, 10, 16\n\n[25] D. Liu, J. Gu, H. Cao, C. Trinitis, and M. Schulz. Dataset distillation by automatic training trajectories. In\n_ECCV_, 2024. 1\n\n[26] A. Lynch, G. J.-S. Dovonon, J. Kaddour, and R. Silva. Spawrious: A benchmark for fine control of spurious\ncorrelation biases, 2023. 5, 8, 16\n\n[27] T. Nguyen, Z. Chen, and J. Lee. Dataset meta-learning from kernel ridge-regression. In _ICLR_, 2020. 1, 2\n\n[28] T. Nguyen, R. Novak, L. Xiao, and J. Lee. Dataset distillation with infinitely wide convolutional networks.\nIn _NeurIPS_, 2021. 1\n\n[29] M.-E. Nilsback and A. Zisserman. Automated flower classification over a large number of classes. In\n_Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP)_,\nKolkata, India, 2008. 16, 17, 35\n\n[30] C. Olah, A. Mordvintsev, and L. Schubert. Feature visualization. _Distill_, 2017.\nhttps://distill.pub/2017/feature-visualization. 4, 7\n\n[31] M. Oquab, T. Darcet, T. Moutakanni, H. V. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. HAZIZA,\nF. Massa, A. El-Nouby, M. Assran, N. Ballas, W. Galuba, R. Howes, P.-Y. Huang, S.-W. Li, I. Misra,\nM. Rabbat, V. Sharma, G. Synnaeve, H. Xu, H. Jegou, J. Mairal, P. Labatut, A. Joulin, and P. Bojanowski.\nDINOv2: Learning robust visual features without supervision. _TMLR_, 2024. 3, 5, 6, 8, 16, 17, 19, 22, 23,\n24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36\n\n[32] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and\nA. Lerer. Automatic differentiation in pytorch. In _ICLR Workshop_, 2017. 3\n\n[33] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,\nL. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,\nL. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance deep learning library. In\n_NeurIPS_ . 2019. 15, 16\n\n[34] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin,\nJ. Clark, et al. Learning transferable visual models from natural language supervision. In _ICML_, 2021. 3,\n5, 16, 17, 18\n\n[[35] J. Resig. Ukiyo-e search. https://ukiyo-e.org/, 2012. 16](https://ukiyo-e.org/)\n\n[36] E. Riba, D. Mishkin, D. Ponsa, E. Rublee, and G. Bradski. Kornia: an open source differentiable computer\nvision library for pytorch. In _WACV_, 2020. 16\n\n[37] C. Ryali, Y.-T. Hu, D. Bolya, C. Wei, H. Fan, P.-Y. Huang, V. Aggarwal, A. Chowdhury, O. Poursaeed,\nJ. Hoffman, et al. Hiera: A hierarchical vision transformer without the bells-and-whistles. In _ICML_, 2023.\n3\n\n[38] S. Sagawa, P. W. Koh*, T. B. Hashimoto, and P. Liang. Distributionally robust neural networks. In _ICLR_,\n2020. 5, 8, 16\n\n[39] S. Sagawa, P. W. Koh, T. Lee, I. Gao, S. M. Xie, K. Shen, A. Kumar, W. Hu, M. Yasunaga, H. Marklund,\nS. Beery, E. David, I. Stavness, W. Guo, J. Leskovec, K. Saenko, T. Hashimoto, S. Levine, C. Finn, and\nP. Liang. Extending the wilds benchmark for unsupervised adaptation. In _ICLR_, 2022. 16\n\n[40] B. Son, Y. Oh, D. Baek, and B. Ham. Fyi: Flip your images for dataset distillation. In _ECCV_, 2024. 1, 3\n\n[41] Q. Sun, Y. Fang, L. Wu, X. Wang, and Y. Cao. Eva-clip: Improved training techniques for clip at scale.\n_arXiv preprint arXiv:2303.15389_, 2023. 3\n\n13\n\n[42] Y. Tian, D. Krishnan, and P. Isola. Contrastive multiview coding. In _ECCV_, 2020. 5, 16, 17, 18, 19, 20, 21\n\n[[43] TorchVision maintainers and contributors. Torchvision: Pytorch\u2019s computer vision library. https:](https://github.com/pytorch/vision)\n[//github.com/pytorch/vision, 2016. 16](https://github.com/pytorch/vision)\n\n[44] M. Tschannen, A. Gritsenko, X. Wang, M. F. Naeem, I. Alabdulmohsin, N. Parthasarathy, T. Evans,\nL. Beyer, Y. Xia, B. Mustafa, et al. Siglip 2: Multilingual vision-language encoders with improved semantic\nunderstanding, localization, and dense features. _arXiv preprint arXiv:2502.14786_, 2025. 3\n\n[45] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. Caltech-UCSD birds 200. Technical Report\nCNS-TR-2011-001, California Institute of Technology, 2011. 5, 9, 17, 33, 34\n\n[46] K. Wang, B. Zhao, X. Peng, Z. Zhu, S. Yang, S. Wang, G. Huang, H. Bilen, X. Wang, and Y. You. Cafe:\nLearning to condense dataset by aligning features. _CVPR_, 2022. 1\n\n[47] T. Wang, J.-Y. Zhu, A. Torralba, and A. A. Efros. Dataset distillation. _arXiv preprint arXiv:1811.10959_,\n2018. 1, 2\n\n[[48] R. Wightman. Pytorch image models. https://huggingface.co/timm, 2019. 16](https://huggingface.co/timm)\n\n[[49] WikiArt.org. WikiArt Visual Art Encyclopedia. https://www.wikiart.org/, 2024. 16](https://www.wikiart.org/)\n\n[50] Z. Yin and Z. Shen. Dataset distillation via curriculum data synthesis in large data era. 2024. 2\n\n[51] Z. Yin, E. Xing, and Z. Shen. Squeeze, recover and relabel: Dataset condensation at imagenet scale from a\nnew perspective. In _NeurIPS_, 2023. 1, 2\n\n[52] X. Zhai, B. Mustafa, A. Kolesnikov, and L. Beyer. Sigmoid loss for language image pre-training. In _ICCV_,\n2023. 3\n\n[53] B. Zhao and H. Bilen. Dataset condensation with differentiable siamese augmentation. In _ICML_, 2021. 1,\n\n4, 7\n\n[54] B. Zhao and H. Bilen. Dataset condensation with distribution matching. _WACV_, 2023. 1, 2\n\n[55] B. Zhao, K. R. Mopuri, and H. Bilen. Dataset condensation with gradient matching. In _ICLR_, 2020. 2, 3, 4\n\n[56] Y. Zhou, E. Nezhadarya, and J. Ba. Dataset distillation using neural feature regression. _NeurIPS_, 2022. 1, 2\n\n14\n\n**Appendix**\n\nTo begin the appendix, we first speak on our method\u2019s limitations, broader impact, and compute\nbudget. In the following sections, we include more information that was omitted from the main\npaper due to space constraints. In Section A, we provide a more detailed description of our method\u2019s\nimplementation details. In Section C, we include visualizations of complete distilled datasets.\n\n**Limitations** Our method is largely limited by memory and data loading. For example, we were limited in our ImageNet-1k experiments to only using 3 rounds of augmentations per batch due to a data\nloading bottleneck. We hope to eventually develop a method that does not require the loading of thousands of real images per step. Additionally, due to the bi-level optimization, we are limited to using Pytorch\u2019s [2, 33] nn.DistributedParallel, rather than nn.DistributedDataParallel,\nwhich causes significant slowdowns due to our very large batch sizes. Using a different automatic\ndifferentiation framework, such as Jax [4], might alleviate this issue, but this would also require\nporting all our self-supervised backbones to the new framework.\n\n**Broader Impact** While our method quantitatively out-performs the real image baselines, the\nbroader impacts likely lie in the introduction of this new task as well as the resulting images acting as\nan interpretability tool. As shown in the paper, the distilled images offer insights into things such as\nmodel alignment and how different networks see the world in varying ways.\n\nFurthermore, the ultimate goal of dataset distillation is the reduction of training time, which equates\nto less energy spent. A linear probe trained on our distilled datasets can be trained to convergence in\njust a few minutes while training on the full dataset can take up to an entire day.\n\n**Compute Budget** We used a variety of GPUs for this work depending on what was available on\nthe shared cluster. Specifically, we used a combination of H200, A100, L40s, Ada6000, and 4090\nGPUs. Distilling ImageNet-100 with the default settings takes about 3 hours using 1 H200 GPU, and\nImageNet-1k takes about 12 hours using 4 H200 GPUs.\n\n**A** **Implementation Details**\n\nIn this section, we provide a more detailed explanation of our methodological and experimental\nimplementation details.\n\n**A.1** **Distillation**\n\n[We implement our method in Pytorch [2, 33], which has a unique license to which we comply.](https://github.com/pytorch/pytorch/tree/main?tab=License-1-ov-file#readme)\n\nWe optimize our pyramid representations using Adam [22] with a learning rate of 0.002.\n\nWe distill for 5000 iterations and add a new level to the pyramids every 200 iterations until we reach\nthe maximum resolution (256).\n\nEach level of the pyramid is initialized with _N_ (0 _,_ 1) normalized by the current number of levels in\nthe pyramid. When a new level is added, the existing levels are appropriately re-normalized.\n\nAt each distillation iteration, we first sample a new linear classifier consisting of a weight matrix _W_\nand bias vector **b** using the default initialization for Pytorch\u2019s nn.Linear. For simplicity, we omit\nthe bias in the main paper.\n\nThen, we reconstruct the synthetic images from their pyramid representations using the following\nequation (copied from the main paper for convenience):\n\n\ufffd\n\n_X_ = [1]\n\n[1]\n\n2 [+ 1]\n\n2 [tanh]\n\n(4)\n\n\ufffd\ufffd _r\u2208\u03c1_\n\nresize256( _Pr_ )\n\n_r\u2208\u03c1_\n\nThe synthetic images are then augmented several (10 by default) _different_ (not sequential) times and\nconcatenated together to form the full synthetic batch. We obtain our synthetic loss ( _\u2113_ syn) by passing\nthis batch through the feature extractor _\u03d5_ and linear classifier ( _W,_ **b** ) and then compute the gradient of\nthe synthetic loss with respect to the linear classifier (and bias). These gradients are then vectorized.\n\n15\n\nFor our real batch, we sample a number of real images equal to the length of the _full_ synthetic batch\n(i.e., after the different augmentations and concatenation) and augment them once (since the batch\nsize already matches that of the full synthetic batch). We then get the real loss and gradients via the\nsame procedure. The meta loss is then calculated as the cosine distance between the real and synthetic\nvectorized gradients.\n\n**A.2** **Augmentation**\n\nFor our differentiable augmentations, we use a custom re-implementation of torchvision transforms that run on GPU and support different random transforms for each element in a batch. We initially used the Kornia [36] implementations, but found that they cause CPU bottlenecks with very large\nbatch sizes. We use RandomHorizontalFlip with default parameters, RandomResizedCrop\nwith size=(224, 224), and RandomGaussianNoise with std=0.2.\n\n**A.3** **Evaluation**\n\n**Linear Probes.** To evaluate a given distilled dataset (or selected coreset for the real baselines) on\na given target model, we first randomly initialize a new linear classifier. We then train the linear\nclassifier for 1000 epochs with a batch size of 100. We use an Adam optimizer with a learning rate of\n0 _._ 001 _/_ 256 (taken from the DINO-v1 [5] evaluation protocol) along with a cosine decay learning rate\nschedule. We stop training early if the test accuracy has not improved over the last 50 epochs. For the\ntraining set, we perform the same set of augmentations as during distillation (horizontal flip, random\nresized crop, and Gaussian noise). The output of the random resized crop is of size 224 _\u00d7_ 224. For the\ntest set, we resize the shortest side to 256 and then do a center crop of 224 _\u00d7_ 224.\n\n**Nearest Neighbors.** For our nearest neighbor evaluation, we first find the train set embeddings\nby resizing the shortest side of each test image to 256, taking a 224 _\u00d7_ 224 center crop, and passing\nthrough the feature extractor. We then do the same for the test set and find the training embedding\nclosest to each test embedding (by cosine distance) and report the class of said neighbor. We only do\none nearest neighbor since we distill down to one image per class.\n\n**A.4** **Datasets**\n\nFor ImageNet [12] and ImageNet [42], we build on the Torchvision [43] implementation as part of the\n[Pytorch [2, 33] ecosystem. ImageNet has a unique non-commercial license, to which we have agreed.](https://image-net.org/download.php)\n\n[Spawrious [26] is taken from the paper\u2019s official GitHub repository and uses a CC0-1.0 license.](https://github.com/aengusl/spawrious)\n\nWaterbirds [38] is taken from the WILDS [23, 39] benchmark. Both the Waterbirds and WILDS\nrepositories use an MIT license.\n\n[Stanford Dogs [21] is taken from the project website. It presumably uses the same license as](http://vision.stanford.edu/aditya86/ImageNetDogs)\nImageNet [12].\n\n[Caltech-UCSD-200-2011 is taken from the project website. No license is given.](http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz)\n\n[ArtBench [24] is taken from the paper\u2019s GitHub repository. The repository itself uses an MIT license.](https://github.com/liaopeiyuan/artbench)\nThe data is sourced from WikiArt [49], Ukiyo-e Search [35], and The Surrealism Website [1], all of\nwhich have Fair Use licenses.\n\nFlowers-102 [29] is taken from Torchvision. No license is given.\n\nFood-101 [3] is taken from Torchvision. No license is given.\n\n**A.5** **Models**\n\n[For CLIP [34], we use the official GitHub repository which has an MIT license.](https://github.com/openai/CLIP)\n\n[For DINO-v1 [5], we use the official GitHub repository which has an Apache-2.0 license.](https://github.com/facebookresearch/dino)\n\n[For DINO-v2 [31], we use the official GitHub repository which has an Apache-2.0 license.](https://github.com/facebookresearch/dinov2)\n\n[For EVA-02 [13], we use the Pytorch Image Models [48] implementation hosted on Hugging Face [19]](https://huggingface.co/timm/eva02_base_patch14_224.mim_in22k)\nwhich has an MIT license.\n\n16\n\nTrain Set Flowers-102 Food-101\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **79.5** _\u00b1_ **1.2 99.6** _\u00b1_ **0.0 97.8** _\u00b1_ **0.1 56.4** _\u00b1_ **3.1 83.3** _\u00b1_ **1.1 78.7** _\u00b1_ **1.6 83.7** _\u00b1_ **0.3 83.9** _\u00b1_ **0.2 31.6** _\u00b1_ **3.2 69.5** _\u00b1_ **1.3**\nNeighbors 69.4 _\u00b1_ 0.8 99.4 _\u00b1_ 0.2 90.8 _\u00b1_ 0.2 48.6 _\u00b1_ 1.8 77.0 _\u00b1_ 0.7 58.8 _\u00b1_ 1.3 73.8 _\u00b1_ 0.4 71.5 _\u00b1_ 0.3 25.2 _\u00b1_ 1.3 57.3 _\u00b1_ 0.8\nCentroids 77.5 _\u00b1_ 0.7 99.4 _\u00b1_ 0.1 95.6 _\u00b1_ 0.3 48.2 _\u00b1_ 2.6 80.2 _\u00b1_ 0.9 74.1 _\u00b1_ 0.6 75.6 _\u00b1_ 0.1 76.4 _\u00b1_ 0.4 22.7 _\u00b1_ 2.0 62.2 _\u00b1_ 0.8\n\nRandom 67.9 _\u00b1_ 1.1 98.8 _\u00b1_ 0.4 91.0 _\u00b1_ 0.8 36.8 _\u00b1_ 2.2 73.6 _\u00b1_ 1.1 48.5 _\u00b1_ 1.0 52.8 _\u00b1_ 1.9 49.9 _\u00b1_ 0.6 13.5 _\u00b1_ 1.7 41.2 _\u00b1_ 1.3\n\nFull Dataset 93.4 _\u00b1_ 0.1 99.7 _\u00b1_ 0.0 98.9 _\u00b1_ 0.0 82.2 _\u00b1_ 0.1 93.5 _\u00b1_ 0.1 91.9 _\u00b1_ 0.0 92.7 _\u00b1_ 0.1 92.0 _\u00b1_ 0.0 78.3 _\u00b1_ 0.0 88.7 _\u00b1_ 0.0\n\nTable B.1: **Additional Datasets:** Distilling Flowers-102 [29] and Food-101 [3] show similar results; our distilled\ndataset consistently out-perform the real-image baselines.\n\n[For MoCo-v3 [10], we use the official GitHub repository which has a Creative Commons Attribution-](https://github.com/facebookresearch/moco-v3)\nNonCommercial 4.0 International Public License.\n\n**B** **Additional Results**\n\nIn Table B.1, we include results for Flowers-102 [29] and Food-102 [3]. We see results following the\nsame trends as the rest of the paper; the distilled datasets out-perform the real-image baselines across\nthe board.\n\n**C** **Visualizing Full Datasets**\n\nIn Figures C.1, C.2, C.3, and C.4 we present the entirety of ImageNet-100 [42] distilled with\nCLIP [34], DINO-v2 [31], EVA-02 [14], and MoCo-v3 [10] respectively. In Figures C.5\u2013C.14, we\nshow ImageNet-1k [12] distilled with DINO-v2 and omit the other models for the sake of brevity\n(and ink).\n\nWe also include Stanford Dogs [21] (Figure C.15), CUB-200-2011 [45] (Figures C.16 and C.17),\nFlowers-102 [29] (Figure C.18), and Food-101 [3] (Figure C.19) distilled with DINO-v2 and once\nagain omit the other models. All distilled datasets, including those not inculded here, can be viewed\n[on our project page.](http://georgecazenavette.github.io/linear-gm)\n\n17\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-17-0.png)\n\nFigure C.1: ImageNet-100 [42] distilled using CLIP [34]\n\n18\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-18-0.png)\n\nFigure C.2: ImageNet-100 [42] distilled using DINO-v2 [31]\n\n19\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-19-0.png)\n\nFigure C.3: ImageNet-100 [42] distilled using EVA-02 [13]\n\n20\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-20-0.png)\n\nFigure C.4: ImageNet-100 [42] distilled using MoCo-v3 [10]\n\n21\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-21-0.png)\n\nFigure C.5: ImageNet-1k [12] distilled with DINO-v2 [31] classes [0-99]\n\n22\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-22-0.png)\n\nFigure C.6: ImageNet-1k [12] distilled with DINO-v2 [31] classes [100-199]\n\n23\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-23-0.png)\n\nFigure C.7: ImageNet-1k [12] distilled with DINO-v2 [31] classes [200-299]\n\n24\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-24-0.png)\n\nFigure C.8: ImageNet-1k [12] distilled with DINO-v2 [31] classes [300-399]\n\n25\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-25-0.png)\n\nFigure C.9: ImageNet-1k [12] distilled with DINO-v2 [31] classes [400-499]\n\n26\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-26-0.png)\n\nFigure C.10: ImageNet-1k [12] distilled with DINO-v2 [31] classes [500-599]\n\n27\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-27-0.png)\n\nFigure C.11: ImageNet-1k [12] distilled with DINO-v2 [31] classes [600-699]\n\n28\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-28-0.png)\n\nFigure C.12: ImageNet-1k [12] distilled with DINO-v2 [31] classes [700-799]\n\n29\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-29-0.png)\n\nFigure C.13: ImageNet-1k [12] distilled with DINO-v2 [31] classes [800-899]\n\n30\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-30-0.png)\n\nFigure C.14: ImageNet-1k [12] distilled with DINO-v2 [31] classes [900-999]\n\n31\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-31-0.png)\n\nFigure C.15: Stanford Dogs [21] distilled using DINO-v2 [31]\n\n32\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-32-0.png)\n\nFigure C.16: CUB-200-2011 [45] distilled using DINO-v2 [31] classes [0-99]\n\n33\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-33-0.png)\n\nFigure C.17: CUB-200-2011 [45] distilled using DINO-v2 [31] classes [100-200]\n\n34\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-34-0.png)\n\nFigure C.18: Flowers-102 [29] distilled using DINO-v2 [31]\n\n35\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-35-0.png)\n\nFigure C.19: Food-101 [3] distilled using DINO-v2 [31]\n\n36"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is 'Linear Gradient Matching,' which involves a bi-level optimization to synthesize images. The outer loop adjusts the synthetic images, while the inner loop implicitly trains a linear classifier (probe) on top of fixed, pre-trained self-supervised vision model features. The objective is to minimize the cosine distance between the gradient vector produced by the synthetic images and the gradient vector produced by a real batch of data, both with respect to the linear classifier's weights.\n\n**Explanation:** Think of a pre-trained vision model as a highly optimized 'feature extractor' that turns raw images into a set of descriptive numbers (like a compressed, meaningful representation). A 'linear probe' is a simple layer, essentially a weighted sum of these descriptive numbers, followed by a decision (like a single 'if-then' statement on a score). When you train this probe, you're only adjusting these 'weights' and 'decision points.' The innovation here is to create synthetic images such that when you 'backpropagate' (calculate how to adjust those weights to reduce error) on them, the required adjustments (the 'gradients') are almost identical to what you'd get from backpropagating on a large batch of real images. This ensures the synthetic data effectively 'teaches' the linear probe the same information as the real data, but with a drastically smaller data footprint. The 'pyramid representation' allows the synthetic images to be optimized at multiple resolutions, and 'differentiable augmentations' ensure that common data transformations (like flipping or cropping) can be factored into this gradient matching process, making the synthetic images more robust."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6** `BeenCheated` _\u2190_ true; `/*` _i_ `was cheated by` opp( _i_ ) `*/`\n\n**7** _Ri \u2190{_ 1 _}_ _[c]_ [ log] _[ n]_ ; `/* as` _i_ `does not have signed message from` opp( _i_ ) `, its`\n`neighbors will assign this rank to` _i_ `*/`\n\n17\n\n**Algorithm 7:** Calculate Ranks of Neighbors\n\n**1 if** _any j \u2208_ `UndecidedNeighbors` _has output_ 1 _or \u22a5_ **then**\n\n**2** From this point onward, disregard the rest of the algorithm and output _\u22a5_ in every\nround where node _i_ is still Undecided;\n\n**3 else**\n\n**4** Remove all _j \u2208_ `UndecidedNeighbors` that output 0 from `UndecidedNeighbors` ;\n\n**5 foreach** _j \u2208_ _`UndecidedNeighbors`_ **do**"}, {"role": "assistant", "content": "**Mechanism:** This mechanism outlines a distributed state update and consensus protocol where a node detects a breach (cheating), updates its own status, and then propagates this information to its neighbors to influence their collective decision-making. It utilizes a state flag for cheating detection, a rank assignment for status communication, and a decision-propagation loop for neighbors.\n\n**Explanation:** When node `i` detects it was 'cheated' (e.g., its `opp(i)` failed to provide a cryptographically signed message, a condition for agreement), it flips a boolean flag `BeenCheated` to `true`. Concurrently, `i` sets its own 'rank' (`Ri`) to a very low value, defined by a logarithmic function of `n` (likely the network size or a similar scaling factor), signaling its compromised or low-trust status. The critical part is that `i`'s neighbors are expected to adopt this low rank for `i`. The 'Calculate Ranks of Neighbors' algorithm (`Algorithm 7`) then dictates how `i` processes the status of its own `UndecidedNeighbors`. It first checks for an early exit condition: if any neighbor `j` has already returned a definitive 'success' (1) or an 'undecided/failure' (\"\") then `i`'s ability to further resolve its *own* neighbors' ranks is nullified, and it outputs \"\", effectively short-circuiting its local decision process. This is like a `return` or `break` statement in a loop, propagating an indeterminate state. If no such definitive state exists, `i` filters out neighbors that have explicitly output `0` (meaning they are resolved and not contributing to the 'undecided' state) from its `UndecidedNeighbors` set. Finally, it iterates through the remaining truly `UndecidedNeighbors` to continue the rank calculation for them, propagating information iteratively. This combines local state management, status broadcasting, and a neighbor-centric iterative decision process with early termination."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_\ud835\udc4e\ud835\udc59\ud835\udc59_\ud835\udc46\ud835\udc39\ud835\udc60_ _< \ud835\udc4f\ud835\udc64_\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc56_ **then**\n\n**13** _\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ = _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc56_ ;\n\n**14** _\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e\ud835\udc5c\ud835\udc59\ud835\udc51_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc53\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc5d\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc46\ud835\udc39_ = _\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ \u2217(1 \u2212 100 _\ud835\udefd_ [)][ ;]"}, {"role": "assistant", "content": "**Mechanism:** This algorithm first iteratively determines the maximum bandwidth value among a set of service functions (SFs). Then, it calculates a dynamically adjusting threshold by applying a scaling factor to this maximum value.\n\n**Explanation:** The initial conditional statement and assignment are implementing a 'find maximum' operation, similar to a loop that iterates through an array of bandwidths, comparing each element to a 'current_max' variable and updating 'current_max' whenever a larger value is found. Once the highest bandwidth is identified, the subsequent calculation uses this maximum as a reference point. The term '(1 - 100 * \u03b2)' acts as a percentage multiplier (assuming \u03b2 is a small fraction). For instance, if \u03b2 = 0.001, then 100 * \u03b2 = 0.1, making the multiplier 0.9. This means the threshold is set at 90% of the highest observed bandwidth. This dynamic threshold ensures that the 'cut-off' for 'slow' SFs is relative to the current best performance, allowing for adaptive resource management rather than fixed limits. This mechanism is common for load balancing or resource autoscaling, where underperforming units need to be identified and potentially retired or replaced."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61.\ud835\udc5f\ud835\udc61\ud835\udc61_ \u2265 0 **and** ( _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61.\ud835\udc5f\ud835\udc61\ud835\udc61_ \u2264 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ **or** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc56\ud835\udc5f\ud835\udc52\ud835\udc51_ ) **then**\n\n**94** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ = _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61.\ud835\udc5f\ud835\udc61\ud835\udc61_ ;\n\n**95** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () ;\n\n**96** BBR_Check_Probe_RTT():"}, {"role": "assistant", "content": "**Mechanism:** This code implements a minimum tracking mechanism for network Round-Trip Time (RTT) with an expiry condition. It maintains a 'lowest known RTT' value and periodically re-evaluates it.\n\n**Explanation:** Think of a variable, `BBR.RTprop`, that stores the smallest RTT observed so far, similar to how you'd track a `min_value` in a loop. When a new `packet.rtt` arrives, the system first ensures it's a valid measurement (non-negative). It then checks if this new RTT is *smaller* than the currently stored `BBR.RTprop`. Crucially, it also checks if the previously recorded `BBR.RTprop` has become 'stale' or 'expired' (meaning too much time has passed since it was last updated). If the new RTT is smaller, OR if the old RTT is expired, then `BBR.RTprop` is updated to this new, potentially faster RTT. A timestamp (`BBR.rtprop_stamp`) is recorded for this update. Finally, `BBR_Check_Probe_RTT()` is called, which likely uses this information to manage when to actively 'probe' the network for new RTT measurements. This ensures the system continuously maintains an up-to-date and accurate baseline for the network's inherent propagation delay, even if no explicit smaller value has been seen for a while, preventing reliance on outdated information."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**1**\n\n1.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n\n1.2 Previous work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n1.3 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5"}, {"role": "assistant", "content": "**Mechanism:** This section functions as a high-level index or a structured navigation system. It establishes a mapping between conceptual categories (Results, Previous work, Organization) and their physical locations within the document (page numbers).\n\n**Explanation:** From a first-principles perspective, this is essentially a `map` or `dictionary` data structure. Each key is a section heading, and its corresponding value is a page number, acting as a pointer to where that content resides. It's not about the content itself, but about creating an efficient lookup mechanism for the reader to quickly access specific information blocks. It defines the 'interface' or 'API' for navigating the document's structure."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe rapid progress of artificial intelligence (AI) has placed unprecedented demands on efficient GEMM computations. In GEMM,\nwe perform matrix multiplication _\ud835\udc36_ = _\ud835\udc34_ \u00d7 _\ud835\udc35_, where _\ud835\udc34_ \u2208 R _[\ud835\udc40]_ [\u00d7] _[\ud835\udc3e]_,\n_\ud835\udc35_ \u2208 R _[\ud835\udc3e]_ [\u00d7] _[\ud835\udc41]_, and _\ud835\udc36_ \u2208 R _[\ud835\udc40]_ [\u00d7] _[\ud835\udc41]_, with _\ud835\udc40_, _\ud835\udc41_, and _\ud835\udc3e_ denoting the number\nof rows of _\ud835\udc34_, the number of columns of _\ud835\udc35_, and the reduction dimension, respectively. GEMM efficiency relies critically on effective\ntiling strategies, which increase arithmetic intensity by reusing\ndata to reduce total data movement to and from memory. As a\nresult, tiling has become a standard practice across CPUs, GPUs,\nand domain-specific accelerators, enabling high performance while\nrespecting tight memory-bandwidth constraints.\nConventional practice is to employ _symmetric tile buffering_, in\nwhich the buffered tile size of input _\ud835\udc34_ along the _\ud835\udc40_ dimension and\ninput _\ud835\udc35_ along the _\ud835\udc41_ dimension are the same as the output tile\nsize of _\ud835\udc36_ . This uniform mapping, defined by the three parameters ( _\ud835\udc47\ud835\udc40,\ud835\udc47\ud835\udc3e,\ud835\udc47\ud835\udc41_ ), simplifies scheduling and implementation and is\nwidely adopted in CPU, GPU, and NPU software libraries, as well\nas hardware accelerator designs [19\u201321, 23]. Despite its ubiquity,\nsymmetric buffering increases buffer requirements and leaves arithmetic intensity below the theoretical maximum (Fig. 1, right), a\nlimitation that is particularly restrictive when targeting narrow\nmemories such as L1 caches or scratchpads.\nHowever, we show that this symmetry is unnecessary for tiling.\nIn principle, the buffer lifetime of input _\ud835\udc34_ is only as long as it takes\nto accumulate a single row of _\ud835\udc36_ ; once that row is complete, the\ncorresponding row of _\ud835\udc34_ can be safely evicted. This observation\nimplies that the input and output tile buffers do not need to share\nthe same _\ud835\udc40_ dimension, opening the opportunity to reduce the\nbuffering requirements for _\ud835\udc34_ and allocate more capacity to _\ud835\udc35_ and\n\n![](papers/images/Can-Asymmetric-Tile-Buffering-Be-Beneficial.pdf-0-0.png)\n\n**Figure 1: Architecture and Roofline: AMD AIE XDNA2\u2122spa-**\n**tial architecture (left) and the roofline view illustrating the**\n**performance impact of kernel and tiling strategies (right).**\n\n_\ud835\udc36_ . This insight raises the central question of this work: _When and_\n_how can asymmetric tile buffering be beneficial?_ To answer it:\n\n  - We introduce ATB, a general tiling strategy that decouples\nthe buffered _\ud835\udc40_ dimensions of _\ud835\udc34_ and _\ud835\udc36_, reducing input buffer\npressure and increasing arithmetic intensity.\n\n  - We develop an analytical performance model that captures\nboth the benefits of ATB (higher reuse and arithmetic intensity) and its costs (more kernel switching overheads),\nproviding principled guidance for selecting tiling factors.\n\n  - We present the first case study applying ATB to AMD NPU,\nachieving a speedup of up to 4.54\u00d7 over the state of the art.\n\n  - We analyze ATB\u2019s performance on AIE and show that it\nimproves GEMM throughput by up to 40% even over highly\noptimized symmetric kernels."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism exploits the differential buffer lifetime of input matrices A and B within a tile-based GEMM operation. Conventionally, the 'M' dimension (row count) of the buffered tile for input A is often constrained to be equal to the 'M' dimension of the output C tile (symmetric tiling). However, to compute a row of C, only a single row of A (and all columns of B) is required for that specific output row. Once an output row is completed, the corresponding row of A is no longer needed for *that* output tile.\n\n**Explanation:** Asymmetric Tile Buffering (ATB) decouples these dimensions. By allowing the M-dimension of A's buffered tile to be smaller than C's output tile M-dimension, buffer space allocated to A can be significantly reduced. This freed-up capacity can then be reallocated to buffer larger tiles of B (and potentially C). Buffering larger portions of B increases data reuse and arithmetic intensity because more computations can be performed on B's data once it's brought into the faster, smaller memory (like a cache or scratchpad), reducing the number of costly memory accesses to slower main memory. This is akin to a `for` loop where you need a small `A_row` to iterate through many `B_columns` to build a `C_row`. Instead of keeping a big block of `A` that includes `A_row` plus many other rows, you only keep `A_row` and free up the rest for more `B` data. The trade-off is potential increased overhead from more frequent 'swapping' of A's smaller tiles, which the analytical model helps manage."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_j \u2208_ _`UndecidedNeighbors`_ **do**\n\n**6** Choose strategy _si_ ( _j_ ) _\u2208{_ r _,_ p _,_ s _}_ uniformly at random and send to _j_ ;\n\n```\n   /* Round 2: Join MIS if possible */\n```"}, {"role": "assistant", "content": "**Mechanism:** This segment implements a distributed, randomized choice and communication step. Each node (j) in the 'UndecidedNeighbors' set independently generates a random value (one of 'r', 'p', 's') and then transmits this value to itself (or broadcasts it, with j as the recipient). This functions as a loop over a collection of entities, each performing a random number generation and a message-passing operation.\n\n**Explanation:** The core behavior here is that individual agents, without a central coordinator, make a temporary, arbitrary decision. By having each 'undecided' node randomly select a strategy from a predefined set, we introduce asymmetry. This randomness is critical in distributed algorithms to break ties or avoid deadlocks where all nodes might otherwise make the exact same choice simultaneously, leading to no progress. It's akin to each computer 'rolling a dice' to pick a temporary 'priority' or 'intention'. This chosen strategy then becomes input for the next round (Round 2, aiming to 'Join MIS'), where nodes will likely compare these strategies with their neighbors to decide whether to become part of a specific group, like a Maximum Independent Set, often by selecting the 'winner' based on these random choices."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nS( _\u20d7\u03b3k_ ) _\u0338_ = _\u2205_ **then** Continue\n**else** Stop\n\n**4** Compute **E** _k_ and _\u20d7\u03b1k_ from S( _\u20d7\u03b3k_ ) and _v_\n\n**5** Determine **Q** _k_ and **a** _k_ from **E** _k_ and _\u20d7\u03b1k_\n\n**6** Calculate by Formula (3.15) **x**\n\n**7** _k \u2190\u2212_ _k_ + 1\n\n**8** _\u20d7\u03b3k_ +1 _\u2190\u2212_ **x**\n\n**9** Determine S( _\u20d7\u03b3k_ +1)\n**until** S( _\u20d7\u03b3k_ +1) = S( _\u20d7\u03b3k_ )\n\n**end**\n\nMeinhardt (2013, Theorem 8.1.2) establishes that this iterative procedure converges toward a pre-kernel\npoint. In view of Meinhardt (2013, Theorem 9.1.2), we even know that at most \ufffd _n_ 2\ufffd _\u2212_ 1-iteration steps are\nsufficient to successfully terminate the search process. However, we have some empirical evidence that\ngenerically a maximum of _n_ + 1-iteration steps are needed to determine an element from the pre-kernel\n\nset.\n\n### 4 CHARACTERIZATION OF EFFICIENTLY SOLVABLE PROBLEMS\n\nResume that an algorithm is called to be of polynomial-time if its running time is upper bounded by a\npolynomial expression in the size of the input, as _O_ ( _n_ _[k]_ ), where _k_ is a constant. This means that the\nalgorithm can be considered efficient or tractable. In contrast, an algorithm is said to be of exponentialtime if the running time is upper bounded by _O_ (2 _[poly]_ [(] _[n]_ [)] ). For instance, if _poly_ ( _n_ ) = _n_, then we have\n_O_ (2 _[n]_ )\n\nTo measure the input, at least the data of a cooperative game in the total number of players must be\nsupplied to the model. Depending on the required precision and analysis of the model, more input data\nmust be provided. For instance, arbitrary precision is required for a rational number model to encode the\ninput as a finite string of bits. This implies that the number of elementary bit operations must be counted\nfor a rational number model to grasp the underlying bit complexity. This is not needed for a real Random\nAccess Machine (RAM) model, where it is assumed that the real number can be represented by infinite\nprecision so that each operation on a real number takes constant time, regardless of precision.\n\nFor estimating the computational complexity of an optimization problem, we also have to care about\nstrongly polynomial-time algorithms, for which it is stated that\n\n1. it consists of the basic operations, viz., addition, subtraction, multiplication, division, as well as\ncomparison; and\n\n2. these basic operations are carried out on rationals/integers of size polynomially bounded in the\ndimension of the input; and\n\n11\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\n3. the number of these operations is polynomially bounded in the dimension of the input.\n\nRoughly speaking, an algorithm is called strongly polynomial whenever its running time is a polynomial function of the number of _n_ the size of the input and independent of the magnitude of the input\nvalues.\n\nMoreover, an algorithm is called **NP** -hard if it refers to a problem that is at least as difficult to solve\nas the hardest problems in the complexity class **NP** (class of nondeterministic polynomial-time problems).\nIn particular, computing the (pre-)nucleolus or a (pre-)kernel point is **NP** -hard in general. This is due to\nthe fact that the best-known general algorithms for computing the (pre-)nucleolus involve, for instance,\nsolving a sequence of linear programming problems, which have a running time that is exponential in the\nnumber of players _n_, since there are 2 _[n]_ possible coalitions (exponential complexity).\n\n### 5 ELLIPSOID METHOD OF COMPUTING THE NUCLEOLUS\n\nFaigle et al. (2001) proposed a first polynomial-time algorithm for computing the nucleolus of a TU game\nwhile attacking an allocation in the intersection of the least-core with the pre-kernel. For TU games for\nwhich the pre-kernel contains exactly one core element, one can conclude that even the nucleolus was\ncomputed due to the following result:\n\n**Theorem 5.1** (Single Point Intersection of Core and Per-Kernel) **.** _Let \u27e8_ _N, v \u27e9_ _be a TU game. If_ C( _N, v_ ) _\u2229_\nPK( _N, v_ ) = _{_ **x** _[\u2217]_ _} is satisfied, i.e., the intersection of the core and pre-kernel just consists of a single point,_\n_then it holds \u03bd_ ( _N, v_ ) = **x** _[\u2217]_ _. Hence, the single intersection point is the nucleolus of the game \u27e8_ _N, v \u27e9._\n\nThus, the method of Faigle et al. (2001) for computing the nucleolus of a TU game can be applied to\nconvex games, where the pre-kernel is a singleton, or minimum cost spanning tree games, where the core\nconsists of a single point. But not to the class of permutation games, where the pre-kernel is inscribed in\nthe least-core of the game (for more details, we refer the reader to Solymosi (2014); Meinhardt (2014)).\n\nIn order to determine this exposed point in the intersection of the core with the pre-kernel of a TU\ngame, Faigle et al. (2001) imposed a combination of the ellipsoid method for solving sequences of linear programming problems with an approximation scheme for a (pre-)kernel point. This approximation\nscheme was first postulated by M. Maschler at the 1965 Jerusalem Conference on Game Theory, where\nthe convergence was given as an open problem. In the context of the ellipsoid method, sufficiently many\nsteps of Maschler\u2019s approximation scheme must be invoked to find suitable separating hyperplanes to apply the ellipsoid method. Stearns (1968) provided for Maschler\u2019s approximation scheme of the kernel a\nconvergence proof using topological arguments while imposing the crucial condition that there exists an\ninfinite number of transfers between a pair of players that are maximal. The required boundedness on the\ntransfer to assure convergence was inherited by the compactness of the imputation set and the definition of\nthe kernel. By Faigle et al. (2001, Theorem 4.1), this result was extended to the pre-kernel without using\nany topological argument. Here, it was sufficient to establish that the imposed transfer scheme is bounded\non the pre-imputation set, which is not a compact set. Nevertheless, their proof is logically flawed since\nthe authors confound a proof by contradiction with a proof by contraposition (for further details, we refer\nto Meinhardt (2021)). Fortunately for them, their proof works out.\n\nNotice that the main result of Faigle et al. in establishing a polynomial-time computation of the nucleolus relies on the crucial assumption that there exists a polynomial-time algorithm for computing all\nsurpluses _sij_ ( **x** _, v_ ) over all distinct pairs of players for any allocation **x** _\u2208_ R _[n]_ . This is equivalent to imposing the assumption that the minimum excess _e_ _[v]_ min [(] **[x]** [)][ for any allocation] **[ x]** _[ \u2208]_ [R] _[n]_ [ can also be efficiently]\n\n12\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\ncomputed by an algorithm, viz., in polynomial-time. This allows the authors to disregard the problematic\nissue of **NP** -hardness.\n\nDue to the known drawback of numerical instability in a real data model (unboundness of complexity;\nsee below for more details) of the ellipsoid method, Faigle et al. studied the ellipsoid method in the field\nof rational numbers. This imposes several requirements on the input data that must be considered for\na rational number model. Firstly, the imposed arbitrary precision of a rational number model requires\nknowledge of the encoding length of the largest number in the model that imposes an upper bound on the\ninput size. In addition, it requires that the authors need to estimate the facet complexity of the polyhedron\nspanned by the system of linear inequalities of the linear programming problem that represents the leastcore or core of the TU game. The facet complexity indicates the total number of bits required to encode\nthe system of linear constraints (polyhedron) in the model. Moreover, the computational efficiency of\nthe ellipsoid method stems from its ability to deal implicitly with an exponential number of constraints\nof a linear programming problem through a compact separation oracle. A separation oracle is a routine\nthat, given a point, either confirms that the point is in the feasible set or provides a separating hyperplane.\nFor real-valued linear programming problems, the separation oracle is just a matter of checking all the\nconstraints, which is done efficiently. The complexity of the separation oracle needs to be accounted for\nin the overall runtime. In this respect, an oracle must query to compute and output the coalitional value as\na rational number.\n\nHowever, because of numerical instability issues of the ellipsoid method with floating-point arithmetic,\nthe approach of Faigle et al. has practical limitations with floating-point arithmetic (for more details, see\nbelow).\n\n### 6 SKETCH OF THE ELLIPSOID METHOD\n\nThe algorithm for the ellipsoid method, pioneered by Khachiyan (1979) for linear programming problems,\nworks through iteratively creating smaller ellipsoids that contain a convex body like a polyhedron (feasible\nregion). The process is started with an ellipsoid that contains the feasible region. In each subsequent step,\nthe volume of the ellipsoid is reduced by a constant factor. This is done by calculating in a first step\nfor each current ellipsoid its center of gravity. In the second step, all objective values that direct in the\ndirection where all of them are becoming worse off are thrown away since the bad region cannot contain\nthe optimum. By contrast, all of those objective values that are becoming better off are put in a new\nellipsoid containing still the polyhedron, allowing the volume to be reduced by a constant factor.\n\nIn case the center of gravity of the current ellipsoid is feasible for the original linear programming\nproblem, the bad values are thrown away as before. Otherwise, the center of gravity is not feasible; there\nis still a region with bad values. The bad region of the current ellipsoid is removed as before. A new\nellipsoid is created that is smaller than the current ellipsoid. The number of iterations is governed by how\nmany such reductions are needed to guarantee that the ellipsoid is either empty or contains a point in the\nfeasible region (for more details, see Gr\u00f6tschel et al. (2012, Chapter 3)).\n\nBy the work of Gr\u00f6tschel et al. (1981, Thm. 3.1), Gr\u00f6tschel et al. (2012, Chapter 6), it has been established that the problems of separation and optimization for any given polyhedron P are computationally\nequivalent since there is a polynomial-time algorithm to solve the separation problem of a polyhedron\nP if, and only if, there is a polynomial-time algorithm to solve the linear optimization problem for the\npolyhedron P. In fact, they provide a sharpened separation result to even deal with non-full-dimensional\npolyhedrons. Thus, the problem of strictly separating any given polyhedron P by a point **x** _\u0338\u2208_ P s.t.\n**b** _[\u22a4]_ _\u00b7_ **x** _<_ **b** _[\u22a4]_ _\u00b7_ **y** for all **y** _\u2208_ P with **b** _\u2208_ Q _[n]_ holds true is computationally equivalent to solving the linear\n\n13\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\noptimization problem related to polyhedron P.\n\n### 7 APPROXIMATION SCHEME OF THE KERNEL\n\nThe reader may confront our Approach 3.1 based on the Fenchel-Moreau conjugation with the Standard\nMethod 7.1 from the literature for computing a kernel element while iteratively carrying out a sequence\nof side-payments between pairs of players to reduce the differences in the maximum surpluses between\nthem. Thus, the algorithm is based on the idea to iteratively carrying out bilateral maximal transfers\nbetween pairs of players to approximate a kernel element, instead of a transfer scheme that simultaneously\nadjust the payoffs of all players involved in the game.\n\n**Algorithm 7.1:** Stearns\u2019 Transfer Scheme to converge to a Kernel Element\n\n**Data:** Arbitrary TU Game _\u27e8_ _N, v \u27e9_, and a payoff vector _\u20d7\u03b3_ 0 _\u2208_ _dom h_ .\n**Result:** A payoff vector s.t. _\u20d7\u03b3k_ +1 _\u2208_ K( _v_ ).\n**begin**\n\n**0** _k \u2190\u2212_ 0\n\n**1** Select an arbitrary starting point _\u20d7\u03b3_ 0.\n\n**2** Pre-specify a tolerance value _\u03f5_ .\n**repeat**\n\n**if** _\u20d7\u03b3k \u2208_ _dom h_ **then** Continue\n**else** Stop\n\n**3** Compute the maximum surplus _sij_ ( _\u20d7\u03b3k_ ) for all _i, j \u2208_ _N, i \u0338_ = _j_ by (2.5).\n\n**4** _\u03b4_ _[\u2217]_ _\u2190\u2212_ max _ij\u2208N,i_ = _\u0338_ _j {sij_ ( _\u20d7\u03b3k_ ) _\u2212_ _sji_ ( _\u20d7\u03b3k_ ) _}_ .\n\n**5** Select a player pair ( _i_ _[\u2217]_ _, j_ _[\u2217]_ ) s.t. ( _i_ _[\u2217]_ _, j_ _[\u2217]_ ) _\u2208{i, j \u2208_ _N | \u03b4_ _[\u2217]_ = _sij_ ( _\u20d7\u03b3k_ ) _\u2212_ _sji_ ( _\u20d7\u03b3k_ ) _}_ .\n\n_\u0338_"}, {"role": "assistant", "content": "**Mechanism:** The iterative procedure to find a pre-kernel point is a `do-while` loop. It starts with an initial `gamma_k` and in each iteration, computes intermediate values (E_k, alpha_k, Q_k, a_k) to derive a new potential solution `x`. This `x` then updates `gamma_k+1`. The loop continues until the set S(gamma) stabilizes, meaning S(gamma_k+1) equals S(gamma_k), indicating a fixed point or convergence. The Ellipsoid Method for optimization also uses an iterative, volume-reduction mechanism. It maintains an ellipsoid that is guaranteed to contain the optimal solution. In each step, it probes the center of the current ellipsoid. If this center is not feasible or optimal, a 'separation oracle' (a function) identifies a hyperplane that cuts the ellipsoid, removing a region that cannot contain the solution. A new, smaller ellipsoid is then constructed to enclose the remaining feasible half, reducing its volume by a constant factor. This process repeats, analogous to a multi-dimensional binary search, until the ellipsoid's volume is below a certain threshold. Stearns' Transfer Scheme is a greedy iterative algorithm. In each step, it calculates the 'surplus difference' (s_ij - s_ji) for all player pairs. It then identifies the pair (i*, j*) with the maximal surplus difference and performs a 'transfer' (payoff adjustment) *only* between those two players to reduce that specific imbalance. This repeats until the maximum surplus difference across all pairs falls below a tolerance, signifying local equilibrium.\n\n**Explanation:** The algorithms discussed aim to find 'fair' allocations (like the nucleolus or pre-kernel) in cooperative games. The initial 'iterative procedure' (Algorithm 3.1) functions like a programming `while` loop that refines a solution. You start with a guess (`\u03b30`), then repeatedly calculate new adjustments based on your current guess. The `S(\u03b3k) != \u2205` check is a simple guard condition. The loop terminates when `S(\u03b3k+1) = S(\u03b3k)`, meaning the system has reached a stable state where further adjustments based on the current rules don't change the outcome. This is a common pattern in numerical convergence. Computational complexity is key here. 'Polynomial-time' (`O(n^k)`) means an algorithm's runtime grows reasonably with input size (`n`), similar to iterating through a list or performing a quick sort. 'Exponential-time' (`O(2^n)`) implies runtime explodes very rapidly, making problems with even moderately large `n` practically unsolvable, often due to examining all possible `2^n` combinations, like checking every possible subset of players. Problems designated 'NP-hard' generally fall into this exponential category, meaning no known fast polynomial-time solution exists. The 'Strongly polynomial-time' concept is critical because it ensures efficiency even if the *values* within the input become very large, as long as the *number of variables* (`n`) remains manageable. The 'Ellipsoid Method' is a sophisticated search technique. Imagine you have a complex multi-faceted shape (the feasible region of solutions). Instead of meticulously checking every corner, this method starts with a big, simple shape (an ellipsoid) that's guaranteed to contain your solution. It then systematically 'shrinks' and 'repositions' this ellipsoid. At each step, it asks an 'oracle' (a helper function): 'Is the center of my current ellipsoid a good enough solution, or is it outside the feasible region?' If it's outside, the oracle tells it which way to cut the ellipsoid, effectively discarding half of its volume that couldn't possibly contain the solution. This iterative cutting and shrinking efficiently zeros in on the optimal point. However, a major hurdle is 'numerical instability' with standard floating-point numbers (like `double` in programming). Small rounding errors can accumulate over many iterations, leading to incorrect results or non-convergence. This often necessitates using 'rational number models' (exact fractions), which, while precise, are much slower and more memory-intensive to compute. Stearns' 'Approximation Scheme' is a simpler, greedy iterative method. It continuously identifies the two players who have the most unequal 'surpluses' (a measure of satisfaction or gain) and makes a direct, compensatory 'transfer' between just those two to reduce that specific inequality. This process is repeated until no pair has a significant surplus difference, leading to a state of relative balance. It's like repeatedly finding the two most imbalanced buckets and pouring water between them until they are all level."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nously answered correctly and in- **0**\ncorrectly. This sampling strategy\nserves two critical purposes: (1)\nverifying that guidance does not\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|T|Col9|Col10|ype<br>LLM<br>Human|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||||\n\ndegrade performance on problems **Element**\nthe model already solves success\nFigure 7: Presence rate of each reasoning element for humans and ran\nfully, and (2) measuring improve\ndomly sampled LLMs. We filtered the presence judgments for\n\nment on previously failed instances.\n\n_present_ elements. X-axis is sorted based on the presence gap between\n\nWe quantify effectiveness by com\nhumans and LLMs.\n\nputing the percentage change in accuracy after applying cognitive structure guidance relative to the model\u2019s baseline performance.\n\nDistribution of Cognitive Elements Considered by Humans vs ~~.~~ LLMs"}, {"role": "assistant", "content": "**Mechanism:** The mechanism involves a targeted differential evaluation strategy. Instead of a general performance benchmark, the system explicitly samples two distinct sets of problems: those the model previously answered correctly (to act as a regression test for existing capabilities) and those it answered incorrectly (to measure targeted improvement). This dual sampling allows for an isolated measurement of 'guidance' efficacy, ensuring it doesn't introduce errors on previously mastered tasks while quantifying its additive value on challenging ones.\n\n**Explanation:** To understand if a new 'guidance' mechanism truly improves an LLM, we don't just test it on random problems. We strategically set up two buckets of problems, much like a software test suite. The first bucket contains 'unit tests' for functionality the model already performs correctly; if the guidance causes a drop in performance here, it's a regression, indicating a flaw in the guidance. The second bucket contains 'integration tests' for problems the model previously failed. This is where we expect to see the positive impact of the guidance. The 'effectiveness' is then quantified as a percentage change in accuracy, which is essentially a ratio calculation: (performance with guidance - baseline performance) / baseline performance. This gives a normalized measure of improvement or degradation, showing how much better (or worse) the model got relative to its starting point on the failed tasks, while ensuring no fundamental capabilities were broken on the solved tasks. Figure 7 then further breaks down the 'why' by showing which internal reasoning 'elements' are more present when humans solve problems versus how the LLM approaches them, providing insight into the 'gap' the guidance aims to bridge."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe design of the computational pipeline is driven by three primary considerations: 1) the dis\ntribution of matrix\u2013vector multiplications, which dominate the computational workload; 2) the\n\nimplementation of activation functions; and 3) the scheduling of computations according to the\n\nmodel\u2019s dataflow.\n\nOur implementation aims to explore the capabilities of the AI Engine as a real-time inference\n\ndevice. In this context, a forward pass of the model processes a **single batch**, and all kernels execute\n\nwithin an **infinite** while **loop** .\n\nTo implement the matrix vector multiplication, we leverage the vectorized Multiply Accumulate\n\n(MAC) operation available within each AI Engine tile. In this process, the input or hidden-state\n\nvector is streamed into the vector registers, while the matrix parameters are loaded from the tile\u2019s\n\nlocal memory. The efficiency of this computation depends primarily on two factors: the data\nstreaming bandwidth and the MAC pipeline. There are two principal approaches for executing this\n\noperation.\n\n**1. Column-wise Cascade:** This method represents the most hardware-compliant, or \u201clawful,\u201d\n\nimplementation in that it fully exploits the AI Engine\u2019s most efficient data transfer mechanism; the\n\ncascade stream. The matrix parameters are partitioned into column blocks, and each tile performs a\n\nMAC operation between a column of the matrix and the corresponding element of the input vector\n\n(which is broadcasted to match the vector width). The number of rows processed in each operation\n\ncorresponds to the number of vector lanes of the chosen data type.\n\nThe distribution occurs along the columns, which correspond to the input-vector dimension **x** _\ud835\udc61_\n\nin the GRU model. This can be problematic for architectures with large input feature vectors (on\n\nthe order of thousands of features) and comparatively modest hidden state sizes (on the order of\n\nhundreds). Furthermore, unless significant implementation complexity is introduced, distributing\n\ncomputation in this fashion obliges each participating tile to process all assigned rows. In practice,\n\nonce the columns corresponding to the input-vector dimension are consumed - each spanning a\n\nnumber of rows equal to the vector lane width - the operation must restart from the next block of\n\nrows and continue iteratively until the entire matrix has been processed.\n\n**2. Row-wise Streams:** This method addresses the limitations of the column-wise cascade by\n\ntransposing the computation. Instead of performing the MAC operation along the columns, we now\n\naccumulate across the rows of the matrix. In this configuration, each tile Multiply Accumulates\n\nacross an entire row, progressing through the columns at a rate determined by the vector-lane width.\n\nThis approach accelerates traversal through the matrix but requires the complete input (or hidden\nstate) vector to be streamed to all participating tiles, rather than partitioned into smaller segments.\n\n\u2013 4 \u2013\n\n![](papers/images/A-LatencyConstrained-Gated-Recurrent-Unit-GRU-Implementation-in-the-Versal-AI-Engine.pdf-4-0.png)\n\n(a) MAC the first part of the row\nwith first part of the vector, store\n\nthe result.\n\n![](papers/images/A-LatencyConstrained-Gated-Recurrent-Unit-GRU-Implementation-in-the-Versal-AI-Engine.pdf-4-1.png)\n\n(b) MAC the rest of the row with\n\nrest of the vector, accumulate on\n\nprevious result.\n\n(c) When the whole row and vector\n\nhave been consumed, reduce the vec\ntor, Finally, apply activation function,\nthe element that corresponds on the\nrow of the matrix (here is the first) of\nthe resulting vector is computed.\n\n**Figure 2** : Column-wise implementation of the matrix\u2013vector multiplication within the AI Engine.\n\nIn hindsight, this introduces certain inefficiencies in data movement since we cannot stream fast\n\nenough to exploit the best possible pipeline frequency of a tile. Thankfully, this limitation applies\n\nonly for the first rows computed in a tile. All next rows can benefit by the vector being kept in\n\nmemory and now we are only limited by how fast we can load from memory.\n\nTo distribute the full vector efficiently, we exploit the streaming interface\u2019s capability to broad\ncast the same data stream from a single interface tile to multiple destinations. With this broadcast\n\nmechanism incurs a latency penalty.\n\nIn operation, once an entire row has been processed, the resulting vector elements must be\n\nsummed to produce a single scalar element of the output vector corresponding to that row. This\n\nstrategy allows using streams to move only one 32b number and for extensive utilization of AI\n\nEngine resources, enabling multiple rows to be processed concurrently and improving latency\n\nthrough parallelization. Furthermore, it introduces the possibility of a \u201crow reuse\u201d factor, wherein\n\neach tile computes several consecutive rows, enhancing overall compute density and reducing idle\n\ncycles.\n\n**Aggregation of Partial Results.**\n\nThe distributed partial results are then aggregated to reconstruct the output vector. One\n\napproach is to perform this reduction directly within the AI Engine using packet streams combined\n\nthrough the merge construct. However, the arrival order of the packets is difficult to predict before\n\nimplementation. To manage this, we assign unique identifiers to each packet. These IDs are\n\nthen used to reorder the packets, reconstruct the output vector, and broadcast it to the subsequent\n\nprocessing stage (e.g., the next GRU gate).\n\nWhile functionally correct, this approach breaks pipeline continuity: downstream kernels\n\nmust wait for the entire vector to be reassembled before proceeding, thereby introducing a latency\n\nbottleneck. This leads to a natural question: can aggregation be achieved faster?\n\nWe introduce a \u201chybrid\u201d solution in which the interface tiles are used as a data-path to a PL\n\naggregation kernel. To the best of our knowledge, this is the first application of multiple interface\n\ntiles in such a role for a machine-learning workload. In this configuration, the partial results are\n\nstreamed directly from the AI Engine into the programmable logic (PL) fabric. From the AIE side,\n\neach interface tile connects to a three-way packet-merge construct, allowing partial results from\n\nall three GRU gates to share the same interface tile. The corresponding PL kernel, implemented\n\nin High-Level Synthesis (HLS) [11], operates as a finite-state machine that performs the following\n\nsequence: 1) Perform blocking reads from all interface tiles; 2) Decode packet identifiers, extract\n\nLUT indices for the activation function; 3) Apply the appropriate activation function; 4) Write\n\n\u2013 5 \u2013\n\nthe output as a properly formatted vector, padding with zeros when necessary to meet hardware\n\nalignment requirements."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves optimizing matrix-vector multiplications and subsequent aggregation of results on a specialized hardware array (AI Engine) by leveraging vectorized Multiply-Accumulate (MAC) units and careful dataflow management, specifically introducing a hybrid AI Engine-to-Programmable Logic (PL) aggregation to maintain pipeline continuity.\n\n**Explanation:** At its heart, the process is about performing `Y = M * X` (matrix times vector) as fast as possible on hardware designed for parallel computation. Each AI Engine tile contains MAC units that can perform multiple `(A * B) + C` operations simultaneously. The challenge is feeding data to these MAC units efficiently. The 'Column-wise Cascade' method partitions the matrix `M` by columns. Each tile effectively calculates `M_col_i * X_i`, broadcasting the scalar `X_i` to match the vector width. Data streams between tiles using a 'cascade' mechanism, similar to passing a token in a loop. The 'Row-wise Streams' method transposes this, with each tile calculating `M_row_j * X`. This requires broadcasting the *entire* `X` vector to all participating tiles, much like passing a pointer to a shared array. While the row-wise approach can finish individual row calculations faster, broadcasting the full vector introduces initial latency. Finally, the aggregation of partial results, which is a summation or reduction operation, is a bottleneck. The traditional method uses packet IDs to reorder asynchronously arriving partial results (like a hash map `packet_id -> partial_result`). This 'breaks pipeline continuity' meaning subsequent computational stages must block, waiting for the full output vector to be reassembled (a `join` operation). The 'hybrid' solution offloads this reordering and post-processing (e.g., applying an activation function) to a dedicated kernel in the Programmable Logic (PL). This PL kernel acts as a finite-state machine, performing non-blocking reads from multiple AI Engine output streams, decoding packet IDs, applying a function, and streaming the result. This effectively moves the aggregation and post-processing from a sequential blocking operation within the AI Engine array to a concurrently executing, dedicated hardware accelerator, thereby eliminating a pipeline stall and improving end-to-end latency."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_j has output_ 1 _or \u22a5_ **then**\n\n**11** From this point onward, disregard the rest of the algorithm and Output _\u22a5_ in\nevery round where node _i_ is still Undecided;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism acts as a conditional early exit or a 'short-circuit' for a processing node. If a dependency or peer node 'j' enters a terminal state (either a definite '1' or an explicit 'undecided' '\u22a5'), node 'i' ceases its iterative computation and permanently adopts an 'undecided' state itself.\n\n**Explanation:** Think of it like a function `process_node_i()` running in a loop. Inside the loop, it checks the status of `node_j`. If `node_j.output` is either `1` or `null` (representing '\u22a5'), a boolean flag `stop_processing` for `node_i` is set to `true`, and subsequent iterations of `node_i`'s loop will immediately return `null` without executing any further logic. This prevents `node_i` from performing redundant work if a critical upstream or peer process has already concluded or signaled its inability to decide."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**9** Node _i_ sets _Rj \u2190{_ 1 _}_ _[c]_ [ log] _[ n]_, `BeenCheated` _\u2190_ true; `/* as` _j_ `deviated */`\n\n**10 if** _Ri < Rj for all j \u2208_ `UndecidedNeighbors` **then**\n\n**11** Output 1 (join MIS);\n\n**Algorithm 8:** Reacting to Neighbor Decisions\n\n**1 if** _any node in_ `UndecidedNeighbors` _has output_ 1 **then**"}, {"role": "assistant", "content": "**Mechanism:** This describes a local minimum selection protocol for a distributed system, where nodes are trying to elect themselves into a Maximum Independent Set (MIS). A node 'i' declares itself an MIS member if its own unique value, Ri, is strictly smaller than the Ri values of all its undecided neighbors. This ensures that no two adjacent nodes can simultaneously join the MIS, as one would always have a smaller value.\n\n**Explanation:** When a neighbor 'j' deviates (misbehaves), node 'i' sets a local 'BeenCheated' flag for 'j' and stores or updates 'j's value, Rj, with a specific penalty or assigned score related to the network size 'n' (the `log(n)` term helps ensure good distribution of values in larger networks). The core decision (lines 10-11) is a simple loop iterating through `UndecidedNeighbors` (like checking elements in a list) to find if 'i' has the minimum 'R' value. If 'i' wins this local comparison, it 'outputs 1' (decides to join the MIS). Line 1 of Algorithm 8 is a reactive step: if any neighboring node has already successfully joined the MIS, node 'i' must acknowledge this, likely preventing itself from joining to maintain the independent set property."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**2.1** **Notations and Concepts**\n\nLet _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ) be a simple, connected, undirected graph with\n_\ud835\udc5b_ = | _\ud835\udc49_ | nodes and _\ud835\udc5a_ = | _\ud835\udc38_ | edges. The adjacency matrix _\ud835\udc34_ of _\ud835\udc3a_ is a\n_\ud835\udc5b_ \u00d7 _\ud835\udc5b_ matrix whose ( _\ud835\udc56, \ud835\udc57_ ) entry is 1 if and only if edge ( _\ud835\udc56, \ud835\udc57_ ) \u2208 _\ud835\udc38_ and\n0, otherwise. The degree matrix _\ud835\udc37_ of _\ud835\udc3a_ is a diagonal matrix where\neach entry _\ud835\udc37\ud835\udc56\ud835\udc56_ = _\ud835\udc51\ud835\udc56_ = [\ufffd] _[\ud835\udc5b]_ _\ud835\udc57_ =1 _[\ud835\udc34][\ud835\udc56\ud835\udc57]_ [represents the degree of node] _[ \ud835\udc56]_ [.]\nA random walk on graph _\ud835\udc3a_ is a stochastic process. At each step,\nthe walker moves to a randomly chosen neighbor of the current\nnode. The transition probability is described by the matrix _\ud835\udc43_ =\n( _\ud835\udc5d\ud835\udc56\ud835\udc57_ ) = _\ud835\udc37_ [\u2212][1] _\ud835\udc34_, where _\ud835\udc5d\ud835\udc56\ud835\udc57_ is the probability of moving from node _\ud835\udc56_\nto node _\ud835\udc57_ . It is well known that the stationary distribution _\ud835\udf0b_ of a\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\nrandom walk on undirected graphs is proportional to node degrees,\ni.e., _\ud835\udf0b\ud835\udc56_ = _\ud835\udc51\ud835\udc56_ /2 _\ud835\udc5a_ . Table 1 lists the notations that are frequently used\nin this paper.\nThe hitting time _\ud835\udc3b_ ( _\ud835\udc56, \ud835\udc57_ ) is a fundamental measure in the study\nof random walks [11, 33], defined as the expected number of steps\nrequired to visit the node _\ud835\udc57_ for the first time, starting from a node\n_\ud835\udc56_ . For an arbitrarily fixed node _\ud835\udc56_, the expected hitting time from _\ud835\udc56_\nto any other node _\ud835\udc57_, where _\ud835\udc57_ is chosen according to the stationary\ndistribution, is a constant regardless of the choice of _\ud835\udc56_ . This constant\nis known as Kemeny constant [22], denoted as _\ud835\udf05_ ( _\ud835\udc3a_ ), and is given\nby _\ud835\udf05_ ( _\ud835\udc3a_ ) = [\ufffd] _\ud835\udc57_ _[\ud835\udf0b]_ _\ud835\udc57_ _[\ud835\udc3b]_ [(] _[\ud835\udc56, \ud835\udc57]_ [)][.]\nThe Kemeny constant can also be expressed in terms of the\npseudo-inverse of the normalized Laplacian matrix. The Laplacian matrix _\ud835\udc3f_ and the normalized Laplacian matrix L is defined as\n_\ud835\udc3f_ = _\ud835\udc37_ \u2212 _\ud835\udc34_ and L = _\ud835\udc37_ [\u2212][1][/][2] _\ud835\udc3f\ud835\udc37_ [\u2212][1][/][2] = _\ud835\udc3c_ \u2212 _\ud835\udc37_ [\u2212][1][/][2] _\ud835\udc34\ud835\udc37_ [\u2212][1][/][2], respectively.\nLet 0 = _\ud835\udf0e_ 1 \u2264\u00b7 \u00b7 \u00b7 \u2264 _\ud835\udf0e\ud835\udc5b_ be the eigenvalues of L, with the corresponding eigenvectors _\ud835\udc62_ 1 _,_ - \u00b7 \u00b7 _,\ud835\udc62\ud835\udc5b_ . The pseudo-inverse of L is defined as\nL [\u2020] = [\ufffd] _[\ud835\udc5b]_ _\ud835\udc56_ =2 _\ud835\udf0e_ 1 _\ud835\udc56_ _[\ud835\udc62][\ud835\udc56][\ud835\udc62]_ _\ud835\udc56_ [\u22a4][. According to [][33][], the Kemeny constant can be]\nrepresented as the trace of the pseudo-inverse of the normalized\nLaplacian matrix, i.e.,\n\n**Truncated Random Walk Based Methods.** DynamicMC [25]\nand RefinedMC [51] utilize truncated random walks to approximate\nKC. This kind of approach takes advantage of the relationship\nbetween KC and the transition matrix _\ud835\udc43_, that is,\n\n_\ud835\udf05_ ( _\ud835\udc3a_ ) = _\ud835\udc5b_ \u2212 1 +\n\n\u221e\n\u2211\ufe01[Tr( _\ud835\udc43_ _[\ud835\udc58]_ ) \u2212 1] _._ (2)\n\n_\ud835\udc58_ =1\n\nThe _\ud835\udc56_ -th diagonal entry of _\ud835\udc43_ _[\ud835\udc58]_ represents the transition probability\nfrom _\ud835\udc56_ to itself after _\ud835\udc58_ steps, which becomes negligible when _\ud835\udc58_ is\nlarge. Therefore, by choosing a sufficiently large truncation length\n_\ud835\udc58_ and estimating the diagonal entry of _\ud835\udc43_ _[\ud835\udc58]_ using truncated random walks initiated from each node, these methods can achieve a\nsmall approximation error. To improve performance, DynamicMC\nemploys GPU acceleration to parallelize walk simulations, while\nRefinedMC improves sampling efficiency by optimizing sample\nsize, truncation length, and the number of starting nodes. However,\nbecause of the lack of strong theoretical guarantees, the improvement effect of these optimizations is limited. As a result, these\nmethods has been proven less efficient compared to LERW-based\nmethods as shown in [51].\n\n**Loop-Erased Random Walk (LERW) Based Methods.** Recently,\nthe relationship between L [\u2212][1] with ( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc63_ ) [\u2212][1] has been independently explored by [51] and [29] from the perspective of resistance\ndistance and the inverse of the Laplacian submatrix _\ud835\udc3f\ud835\udc63_ [\u2212][1][, respec-]\ntively. Specifically, KC can be expressed as:\n\n_\ud835\udf05_ ( _\ud835\udc3a_ ) = Tr(L [\u2020] ) = Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc63_ ) [\u2212][1] + [(][L][\u2020][)] _[\ud835\udc63\ud835\udc63]_ _._ (3)\n\n_\ud835\udf0b\ud835\udc63_\n\nBoth methods, ForestMC proposed in [51] and LEwalk proposed\nin [29], employ loop-erased random walks (LERWs) to approximate Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc63_ ) [\u2212][1], but differ in their computation of (L [\u2020] ) _\ud835\udc63\ud835\udc63_ / _\ud835\udf0b\ud835\udc63_ :\nForestMC [51] uses truncated random walks, while LEwalk [29]\nutilizes _\ud835\udc63_ -absorbed random walks. The LERW technique itself is\nwell-established, most notably forming the basis of Wilson\u2019s algorithm for uniform random spanning trees sampling [48].\nThe Wilson algorithm constructs a spanning tree through an\niterative process: it begins with a single-node tree and sequentially\nadds LERWs trajectory starting from remaining nodes in arbitrary\norder. Each LERW terminates upon hitting the current tree, and its\nacyclic path is incorporated into the tree. Crucially, the expected\ntotal length of these LERWs is equal to Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc63_ ) [\u2212][1], allowing an\nefficient approximation of the first term in Eq. (3). By leveraging\nLERWs, we can obtain diagonal-related information of the matrix\ninverse in nearly linear time, significantly improving efficiency\ncompared to performing _\ud835\udc5b_ independent random walk from each\nnode. As a result, this technique has been widely adopted in recent studies on single-source problems or tasks involving matrix\ndiagonals [4, 28, 30], offering a practical alternative to traditional\nrandom walk based methods.\n\nHowever, analyzing the variance of LERW-based methods remains challenging, primarily due to the unbounded length of looperased random walks. In the worst case, the number of steps can\ngrow arbitrarily large, causing such methods to fail on certain\ngraphs. Although ForestMC provides a theoretical guarantee by\nbounding the absolute error with high probability as the time complexity of algorithm is _\ud835\udc42_ ( _\ud835\udf16_ [\u2212][2] \u0394 [2] _\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65_ [2][\u0394] [log][3] _[ \ud835\udc5b]_ [\u00b7][ Tr][(] _[\ud835\udc3c]_ [\u2212] _[\ud835\udc43][\ud835\udc63]_ [)] [\u2212][1][)][, the term]\n\n_\ud835\udf05_ ( _\ud835\udc3a_ ) = Tr(L [\u2020] ) =\n\n_\ud835\udc5b_\n\u2211\ufe01\n\n_\ud835\udc56_ =2\n\n1\n_._ (1)\n_\ud835\udf0e\ud835\udc56_\n\nFrom Eq. (1), we see that the Kemeny constant can be computed\nexactly by finding the eigenvectors of the normalized Laplacian matrix, an _\ud835\udc42_ ( _\ud835\udc5b_ [3] ) operation. While theoretically sound, this approach\nbecomes prohibitively expensive for large-scale graphs. Moreover,\nreal-world networks often evolve dynamically, making the challenge of efficiently tracking the Kemeny constant over time even\nmore acute. To address these limitations, we aim to develop scalable\nalgorithms to approximate the Kemeny constant on both static and\nevolving graphs. Below, we provide a concise overview of the SOTA\nmethods for approximating KC on large graphs.\n\n**2.2** **Existing** SOTA **Methods and Their Defects**\n\nIn this section, we provide an overview of algorithms for computing\nKC, which can be broadly categorized into three classes: matrixrelated methods, truncated random walk-based methods, and looperased random walk-based methods. For each category, we briefly\ndiscuss their underlying principles and limitations.\n\n**Matrix Related Methods.** As shown in Eq. (1), KC can be expressed by eigenvalues of the normalized Laplacian matrix L. A\nnaive solution is solving eigenvalues in _\ud835\udc42_ ( _\ud835\udc5b_ [3] ) time, which is impractical for large-scale graphs. Xu et al. [52] proposed ApproxKemeny\nbased on Hutchinson\u2019s Monte Carlo [21]. It approximates the trace\n\n_\ud835\udc40_\n\nof L [\u2020], and thus KC as: _\ud835\udf05_ ( _\ud835\udc3a_ ) = Tr(L [\u2020] ) \u2248 _\ud835\udc40_ [1] \ufffd _\ud835\udc56_ =1 _[\ud835\udc65]_ _\ud835\udc56_ [\u22a4][L][\u2020] _[\ud835\udc65][\ud835\udc56][,]_ [ where] _[ \ud835\udc65][\ud835\udc56]_\n\nare Rademacher random vectors, with each entry independently\ntaking a value of 1 or \u22121 with equal probability. To compute the\nquadratic forms of L [\u2020], ApproxKemeny transforms the problem\ninto solving Laplacian linear systems: _\ud835\udc65\ud835\udc56_ [\u22a4][L][\u2020] _[\ud835\udc65][\ud835\udc56]_ [=][ \u2225] _[\ud835\udc35\ud835\udc3f]_ [\u2020] _[\ud835\udc66][\ud835\udc56]_ [\u2225][2][, where]\n_\ud835\udc66\ud835\udc56_ = _\ud835\udc37_ [1][/][2] ( _\ud835\udc3c_ \u2212 2 _\ud835\udc5a_ 1 _[\ud835\udc37]_ [1][/][2][11][\u22a4] _[\ud835\udc37]_ [1][/][2][)][. By using a Laplacian Solver to com-]\npute _\ud835\udc3f_ [\u2020] _\ud835\udc66\ud835\udc56_, KC can be approximated. However, the efficiency and\naccuracy of ApproxKemeny are limited by the performance of the\nspecific Laplacian solver used.\n\n_\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65_ [2][\u0394] [makes it impractical for most real-world graphs. There is still]\nno good theoretical guarantee for this type of method. Moreover, all\naforementioned methods are designed for static graphs and cannot\nhandle dynamic updates efficiently. Even minor modifications to\nthe graph require complete recomputation, significantly limiting\ntheir applicability in evolving graph scenarios.\n\n**3** KC **ESTIMATION ALGORITHM**\n\nIn this section, we propose a novel sampling-based algorithm for\napproximating the Kemeny constant. We begin by a new formulation of KC based on 2-forests. Next, we introduce a technique\nthat can maps spanning trees to 2-forests, and we leverage this\nto design an unbiased estimator for KC. Based on this framework,\nwe develop a sampling algorithm that estimates KC via sampling\nuniform random spanning trees (UST), and further optimize it using\na Binary Index Tree and depth-first search. The correctness and\ncomplexity analysis for proposed algorithm are also discussed.\n\n**3.1** **New Forest Formula of** KC\n\nFirst, we derive a new expression for KC using 2-forests. Given two\nfixed nodes _\ud835\udc62_ and _\ud835\udc63_, we consider the set of 2-forests in which _\ud835\udc62_ and\n_\ud835\udc63_ belong to different trees, denoted as F _\ud835\udc62_ | _\ud835\udc63_ . Utilizing _\ud835\udc5b_ \u2212 1 such sets\nF _\ud835\udc62_ | _\ud835\udc63_, we present a new formula for computing KC.\n\nTheorem 3.1 (Forest Formula of KC).\n\n1\n_\ud835\udf05_ ( _\ud835\udc3a_ ) =\n2 _\ud835\udc5a_ |\u0393|\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_ _\ud835\udc47_ \u222a _\ud835\udc47_\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F _\ud835\udc5f_ | _\ud835\udc62_\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\n\u2211\ufe01\n\nvol( _\ud835\udc47_ 1) _,_ (4)\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n_For any given 2-forest, we denote the node set of the tree containing_\n_the root \ud835\udc5f_ _as \ud835\udc47_ 1 _, and the other as \ud835\udc47_ 2 _. For example, in_ F1 _, we have_\n_\ud835\udc47_ 1 = { _\ud835\udc63_ 1} _and \ud835\udc47_ 2 = { _\ud835\udc63_ 2 _, \ud835\udc63_ 3} _. Hence,_ vol( _\ud835\udc47_ 1) = _\ud835\udc51_ ( _\ud835\udc63_ 1) = 2 _. Note that_\n_this degree refers to \ud835\udc63_ 1 _\u2019s degree in the graph \ud835\udc3a, not in the forest._\n\nTheorem 3.1 expresses KC in terms of _\ud835\udc5b_ \u2212 1 specific subsets of\nF, denoted as F _\ud835\udc5f_ | _\ud835\udc62_ . To design an unbiased estimator based on this\nformulation, it is crucial to establish a relationship between spanning trees and F _\ud835\udc5f_ | _\ud835\udc62_, as the normalization factor in Eq. (4) involves \u0393.\nTo bridge this gap, we introduce a technique called _path mapping_,\nwhich constructs a special correspondence between spanning trees\nand 2-forests by fixing a path.\nAn interesting observation about the 2-forests in F _\ud835\udc5f_ | _\ud835\udc62_ is that\nthey can be obtained from a spanning tree by deleting any edge\nalong the path between _\ud835\udc62_ to _\ud835\udc63_, thereby ensuring that _\ud835\udc62_ and _\ud835\udc63_ lie in\ndifferent components. Consequently, a single spanning tree yields\n| _\ud835\udc43\ud835\udc62_ \u2192 _\ud835\udc63_ | valid 2-forests, where | _\ud835\udc43\ud835\udc62_ \u2192 _\ud835\udc63_ | is the number of edges on the\n_\ud835\udc62_ \u2013 _\ud835\udc63_ path.\nHowever, the sets of 2-forests generated from different spanning\ntrees overlap. For example, in Fig. 1, both _\ud835\udf0f_ 1 and _\ud835\udf0f_ 2 can produce\nF1 by deleting one edge. This redundancy prevents a direct correspondence between F _\ud835\udc5f_ | _\ud835\udc62_ and \u0393. To resolve this issue, we propose a\nnovel key technique called Path Mapping which can systematically\navoids such overlaps. The formal definition of Path Mapping is\nprovided below.\n\n_Definition 3.2 (Path Mapping)._ Let P be a simple path from node\n_\ud835\udc62_ to node _\ud835\udc5f_ in the graph. We define _path mapping_ that associates\neach spanning tree _\ud835\udf0f_ \u2208 \u0393 with a subset of F _\ud835\udc5f_ | _\ud835\udc62_, i.e., P : \u0393 \u21a6\u2192 2 [F] _[\ud835\udc5f]_ [|] _[\ud835\udc62]_,\nwhere 2 _[\ud835\udc46]_ denotes the power set of _\ud835\udc46_ . For any spanning tree _\ud835\udf0f_,\nthere exists a unique path between _\ud835\udc62_ and _\ud835\udc5f_, denoted by P _\ud835\udc62_ [(] _[\ud835\udf0f]_ \u2192 [)] _\ud835\udc5f_ [. By]\nremoving all edges shared by both P and P _\ud835\udc62_ [(] _[\ud835\udf0f]_ \u2192 [)] _\ud835\udc5f_ [, we obtain a set of]\n2-forests. Depending on the relative direction of the overlapping\nedges, we define two types of path mappings:\n\n- _Forward Path Mapping_ : if the removed edge has same direction\nin two path, the obtained 2-forest set is denoted as F _[\ud835\udc43]_ ( _\ud835\udf0f_ ), i.e.,\n\n_\ud835\udf0f_ )\nF [P] ( _\ud835\udf0f_ ) = \ufffd _\ud835\udf0f_ \\ ( _\ud835\udc56, \ud835\udc57_ ) \ufffd\ufffd ( _\ud835\udc56, \ud835\udc57_ ) \u2208P \u2227( _\ud835\udc56, \ud835\udc57_ ) \u2208P _\ud835\udc62_ (\u2192 _\ud835\udc5f_ \ufffd _,_\n\n- _Reverse Path Mapping_ : if the removed edge has opposite direction\nin two path, the obtained 2-forest set is denoted as F _[\ud835\udc43]_ [\u2032] ( _\ud835\udf0f_ ), i.e.,\n\n_\ud835\udf0f_ )\nF [P][\u2032] ( _\ud835\udf0f_ ) = \ufffd _\ud835\udf0f_ \\ ( _\ud835\udc56, \ud835\udc57_ ) \ufffd\ufffd ( _\ud835\udc56, \ud835\udc57_ )) \u2208P \u2227( _\ud835\udc57,\ud835\udc56_ ) \u2208P _\ud835\udc62_ (\u2192 _\ud835\udc5f_ \ufffd _._\n\nExample 2. _Fig. 3 illustrates an example of path mapping. To_\n_convert a spanning tree into forests in_ F _\ud835\udc63_ 2 | _\ud835\udc63_ 1 _, we first identify a simple_\n_path from \ud835\udc63_ 2 _to \ud835\udc63_ 1 _, such as_ P _\ud835\udc63_ 2 : _\ud835\udc63_ 2 \u2192 _\ud835\udc63_ 3 \u2192 _\ud835\udc63_ 1 _. Then, for a given_\n_spanning tree, e.g., \ud835\udf0f_ 1 _, we locate the path from \ud835\udc63_ 2 _to \ud835\udc63_ 1 _within \ud835\udf0f_ 1 _, that_\n_is_ P _\ud835\udc63_ [(] 2 _[\ud835\udf0f]_ \u2192 [1] [)] _\ud835\udc63_ 1 [:] _[ \ud835\udc63]_ 2 [\u2192] _[\ud835\udc63]_ 3 [\u2192] _[\ud835\udc63]_ 1 _[. We observe that two edges in]_ [ P] _\ud835\udc63_ [ (] 2 _[\ud835\udf0f]_ \u2192 [1] [)] _\ud835\udc63_ 1\n_also appear in_ P _\ud835\udc63_ 2 _and have the same direction. We can obtain two_\n_2-forests,_ F3 _and_ F1 _, by removing_ ( _\ud835\udc63_ 2 _, \ud835\udc63_ 3) _and_ ( _\ud835\udc63_ 3 _, \ud835\udc63_ 1) _respectively._\n_As for \ud835\udf0f_ 3 _, the path from \ud835\udc63_ 2 _to \ud835\udc63_ 1 _is_ P _\ud835\udc63_ [(] 2 _[\ud835\udf0f]_ \u2192 [3] [)] _\ud835\udc63_ 1 [:] _[ \ud835\udc63]_ 2 [\u2192] _[\ud835\udc63]_ 1 _[. Although the]_\n_edge_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 3) _also exists in_ P _\ud835\udc63_ 2 _and \ud835\udf0f_ 3 _, it is not part of_ P _\ud835\udc63_ [(] 2 _[\ud835\udf0f]_ \u2192 [3] [)] _\ud835\udc63_ 1 _[, and]_\n_thus cannot produce a 2-forest. Therefore, applying path mapping_\n_with_ P _\ud835\udc63_ 2 _to \ud835\udf0f_ 3 _results in an empty set._\n\nWith Path Mapping, we restrict the deletable edges of a spanning\ntree to a specific path to reduce redundancy, yet this remains insufficient. To further address this, we distinguish two cases depending\n\n_where_ \u0393 _denotes the set of all spanning trees of \ud835\udc3a, \ud835\udc5f_ _is an arbitrarily_\n_fixed node,_ vol( _\ud835\udc47_ 1) = [\ufffd] _\ud835\udc62_ \u2208 _\ud835\udc47_ 1 _[\ud835\udc51]_ [(] _[\ud835\udc62]_ [)] _[ represents the volume of the tree]_\n_containing \ud835\udc5f_ _, and_ F _\ud835\udc5f_ | _\ud835\udc62_ _is the set of 2-forests in which \ud835\udc5f_ _and \ud835\udc62_ _belong_\n_to different trees._\n\nProof.\n\n1\n_\ud835\udf05_ ( _\ud835\udc3a_ ) =\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_ _\ud835\udc47_ \u222a _\ud835\udc47_\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F _\ud835\udc5f_ | _\ud835\udc62_\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1)vol( _\ud835\udc47_ 2)\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F\n\n\u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\nvol( _\ud835\udc47_ 1) \u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ )\n\n_\ud835\udc62_ \u2208 _\ud835\udc47_ 2\n\n\u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\n\u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1 _,\ud835\udc62_ \u2208 _\ud835\udc47_ 2\n\nvol( _\ud835\udc47_ 1) _\ud835\udc51_ ( _\ud835\udc62_ )\n\n\u2211\ufe01\n\nvol( _\ud835\udc47_ 1) _._\n\nThe first equality follows from Corollary 1.7 in [10], which expresses\nKC in terms of all 2-forests, where F denotes the set of all 2-forests\nin _\ud835\udc3a_ . Note that for any given 2-forest _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2, the designation of\nwhich tree is _\ud835\udc47_ 1 or _\ud835\udc47_ 2 does not affect anything. Therefore, we deduce\nthe second equation by simply treating the tree containing _\ud835\udc5f_ as _\ud835\udc47_ 1,\nand utilizing the definition of vol( _\ud835\udc47_ ). \n\nExample 1. _As shown in Fig. 1, (a) illustrates a graph \ud835\udc3a, (b) dis-_\n_plays all its spanning trees, and (c) shows all its 2-forests. Assume_\n_node \ud835\udc63_ 1 _is selected as \ud835\udc5f_ _. Then,_ F _\ud835\udc63_ 2 | _\ud835\udc63_ 1 = {F1 _,_ F3} _and_ F _\ud835\udc63_ 3 | _\ud835\udc63_ 1 = { _\ud835\udc39_ 1 _, \ud835\udc39_ 2} _._\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-1.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-2.png)\n\n\ud835\udc6e\ud835\udc6e\n\n(a) Graph G (b) \u0393 = \ud835\udf0f\ud835\udf0f1, \ud835\udf0f\ud835\udf0f2, \ud835\udf0f\ud835\udf0f3 \u2236\ud835\udc60\ud835\udc60et of all spanning trees in G (c) \ud835\udd3d\ud835\udd3d= \u21311, \u21312, \u21313 \u2236 set of all 2-forests in G\n\n**Figure 1: An example graph, its spanning trees and 2-forests**\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-5.png)\n\n\ud835\udd3d\ud835\udd3d\ud835\udc63\ud835\udc631|\ud835\udc63\ud835\udc632\n\n\ud835\udcab\ud835\udcab\ud835\udc63\ud835\udc632: \ud835\udc63\ud835\udc632 \u2192\ud835\udc63\ud835\udc633 \u2192\ud835\udc63\ud835\udc631 \ud835\udf0f\ud835\udf0f1\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-11.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-6.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-7.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-4-8.png)\n\n**Figure 2: Proof of Lemma 3.5**\n\non whether the deleted edge aligns with the path orientation, introducing forward and reverse Path Mapping. This refinement further\neliminates redundancy and ultimately enables our goal: establishing a precise correspondence between \u0393 and F _\ud835\udc5f_ | _\ud835\udc62_ through Path\nMapping.\nThe following theorem formalizes this connection by showing\nthat, given any simple path from _\ud835\udc62_ to _\ud835\udc5f_, the set of 2-forests obtained\nfrom all spanning trees in \u0393 via forward Path Mapping, minus those\nobtained via reverse Path Mapping, is exactly F _\ud835\udc5f_ | _\ud835\udc62_ .\n\nTheorem 3.3. _Let_ P _be a simple path from \ud835\udc62_ _to \ud835\udc5f_ _, then_\n\n\ud835\udcab\ud835\udcab\ud835\udc63\ud835\udc633: \ud835\udc63\ud835\udc633 \u2192\ud835\udc63\ud835\udc631\n\nF _\ud835\udc5f_ | _\ud835\udc62_ = \u2211\ufe01\n\n_\ud835\udf0f_ \u2208\u0393\n\nF [P] ( _\ud835\udf0f_ ) \u2212 F [P][\u2032] ( _\ud835\udf0f_ ) _._\n\ufffd \ufffd\n\nProof Sketch. The forward path mapping covers all of F _\ud835\udc5f_ | _\ud835\udc62_,\nsince there must be an edge in P connecting two trees in any 2forests. Moreover, for each 2-forest, forward mapping produces\nexactly one more instance than reverse mapping, as P contains\nprecisely one additional edge from the tree of _\ud835\udc62_ to that of _\ud835\udc5f_ . \n\nLemma 3.4. _Given an arbitrary simple path_ P _from \ud835\udc62_ _to \ud835\udc5f_ _, the_\n_following equation holds:_\n\ufffd F [P] ( _\ud835\udf0f_ ) = F _\ud835\udc5f_ | _\ud835\udc62_ _._\n\n_\ud835\udf0f_ \u2208\u0393\n\nProof. The proof idea is to prove that for any 2-forest, there\nmust be a spanning tree that can be mapped to it by a feasible path.\nFor each 2-forest _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 F _\ud835\udc5f_ | _\ud835\udc62_, the node set _\ud835\udc49_ is divided into two\ndistinct sets, _\ud835\udc47_ 1 and _\ud835\udc47_ 2, and we assume that the tree contains _\ud835\udc5f_ is _\ud835\udc47_ 1.\nSince _\ud835\udc43_ starts from _\ud835\udc62_ and ends at _\ud835\udc5f_, there must be at least one edge\n_\ud835\udc52_ in _\ud835\udc43_ which leaves from the node in _\ud835\udc47_ 2 and enters to the node in\n_\ud835\udc47_ 1. Otherwise, _\ud835\udc62_ and _\ud835\udc5f_ are in the same one connected component,\nor path _\ud835\udc43_ fails to connect _\ud835\udc62_ and _\ud835\udc5f_ . Adding the edge accrossing two\ncomponents to the 2-forest can get a spanning tree _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u222a _\ud835\udc52_, which\nmeans this 2-forest _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 is an element of F [P] ( _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u222a _\ud835\udc52_ ). \n\nLemma 3.5. _For any 2-forest \ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 F _\ud835\udc5f_ | _\ud835\udc62_ _, we have_\n\ufffd\ufffd{ _\ud835\udf0f_ | _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 FP ( _\ud835\udf0f_ )}\ufffd\ufffd \u2212 \ufffd\ufffd\ufffd{ _\ud835\udf0f_ | _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 FP\u2032 ( _\ud835\udf0f_ )}\ufffd\ufffd\ufffd = 1 _._\n\n(a) \ud835\udcab\ud835\udcab\ud835\udc63\ud835\udc63\ud835\udc56\ud835\udc56 \u2236 path from \ud835\udc63\ud835\udc63\ud835\udc56\ud835\udc56 to \ud835\udc63\ud835\udc631 (b) Mapping \u0393 to \ud835\udd3d\ud835\udd3d\ud835\udc63\ud835\udc631|\ud835\udc63\ud835\udc632(\ud835\udd3d\ud835\udd3d\ud835\udc63\ud835\udc631|\ud835\udc63\ud835\udc633) by using \ud835\udcab\ud835\udcab\ud835\udc63\ud835\udc632 (\ud835\udcab\ud835\udcab\ud835\udc63\ud835\udc633)\n\n**Figure 3: Illustration of Transforming Spanning Trees to 2-**\n**Forests Using Path Mapping**\n\nProof. for each 2-forest _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 F _\ud835\udc5f_ | _\ud835\udc62_, we assume _\ud835\udc5f_ is in _\ud835\udc47_ 1. As\nproved in Lemma 3.4, if a spanning tree _\ud835\udf0f_ is composed of _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2\nand an edge _\ud835\udc52_ in P, which leaves from _\ud835\udc47_ 2 and enters to _\ud835\udc47_ 1 (as the\nred edges in Fig. 2). Then _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 appears in the set obtained by\npath mapping _\ud835\udf0f_, i.e., _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 F [P] ( _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u222a( _\ud835\udc52_ 1 _,\ud835\udc52_ 2)), for each\n( _\ud835\udc52_ 1 _,\ud835\udc52_ 2) \u2208P, satisfying _\ud835\udc52_ 1 \u2208 _\ud835\udc47_ 2 _,\ud835\udc52_ 2 \u2208 _\ud835\udc47_ 1. Similarly F [P][\u2032] ( _\ud835\udf0f_ [\u2032] ) has _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2\nif _\ud835\udf0f_ [\u2032] is composed of _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 and the edge that is pointed to _\ud835\udc47_ 2 from\n_\ud835\udc47_ 1 (see the blue edge in Fig. 2). Therefore\n\ufffd\ufffd{ _\ud835\udf0f_ | _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 FP ( _\ud835\udf0f_ )}\ufffd\ufffd \u2212 \ufffd\ufffd\ufffd{ _\ud835\udf0f_ | _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 \u2208 FP\u2032 ( _\ud835\udf0f_ )}\ufffd\ufffd\ufffd\n\n= |( _\ud835\udc52_ 1 _,\ud835\udc52_ 2) \u2208P | _\ud835\udc52_ 1 \u2208 _\ud835\udc47_ 2 \u2227 _\ud835\udc52_ 2 \u2208 _\ud835\udc47_ 1|\n\n\u2212|( _\ud835\udc52_ 1 _,\ud835\udc52_ 2) \u2208P | _\ud835\udc52_ 1 \u2208 _\ud835\udc47_ 1 \u2227 _\ud835\udc52_ 2 \u2208 _\ud835\udc47_ 2|\n\n=1 _._\n\nThe last equality holds because P is a simple path from _\ud835\udc62_ \u2208 _\ud835\udc47_ 2 to\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1, which makes the edges from _\ud835\udc47_ 2 to _\ud835\udc47_ 1 exactly one more than\nthe edge from _\ud835\udc47_ 1 to _\ud835\udc47_ 2 in P. \n\nProof of Theorem 3.3. According to Lemma 3.4 and Lemma 3.5,\nwe can know that [\ufffd] _\ud835\udf0f_ \u2208\u0393 [F][P][ (] _[\ud835\udf0f]_ [)][ includes all elements in][ F] _\ud835\udc5f_ | _\ud835\udc62_ [, while]\n\n\u2212 [\ufffd]\n_\ud835\udf0f_ \u2208\u0393 [F][P][\u2032][ (] _[\ud835\udf0f]_ [)][ eliminates the excess. Therefore, the right term of]\nequation precisely matches F _\ud835\udc5f_ | _\ud835\udc62_ . \n\nExample 3. _Fig. 3 illustrates the mapping from the spanning tree_\n_set_ \u0393 _to the 2-forest set_ F _\ud835\udc63_ | _\ud835\udc5f_ _. By selecting a root node and fixing a_\n_path from another node to the root, each spanning tree in_ \u0393 _can be_\n_mapped to one or more 2-forests in_ F _\ud835\udc63_ | _\ud835\udc5f_ _by removing edges along_\n_the path. For instance, in \ud835\udf0f_ 1 _, removing edges along the fixed path_\n_generates_ F1 _and_ F3 _, while \ud835\udf0f_ 2 _and \ud835\udf0f_ 3 _yield no mappings. Combining_\n_the mappings from all trees exactly recovers_ F _\ud835\udc63_ 1 | _\ud835\udc63_ 2 _, ensuring that_\n_sampling a tree uniformly from_ \u0393 _induces a uniform distribution over_\n_the corresponding 2-forests._\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n**Discussion.** In this way, we successfully establish a connection\nbetween \u0393 and F _\ud835\udc5f_ | _\ud835\udc62_ through path mapping, which lays the foundation for designing a feasible sampling algorithm. Previously, it\nwas difficult to directly sample 2-forests. Now, we can first sample uniform random spanning trees (USTs) and then apply path\nmapping to transform each spanning tree sample into multiple\n(or possibly zero) 2-forests. As a result, each sampled 2-forest is\nobtained with probability 1/|\u0393|. In the next section, we will present\nthe sampling algorithm in detail and provide the corresponding\ntheoretical analysis.\n\n**3.2** **The Tree-To-Forest Algorithm**\n\nIn this section, we introduce TTF (Tree-To-Forest), a new samplingbased algorithm for estimating the Kemeny constant. The key idea is\nto first sample USTs and then transform UST samples into 2-forests\nby path mapping, which allow us to estimate KC according to Eq. (4).\nWe begin by outlining the algorithmic intuition and establish its\ncorrectness, and then present the pseudo-code, implementation\ndetails, and complexity analysis.\n\n**High-Level Idea of** TTF **. (1) Identify the root and paths.** We\nselect an arbitrary node _\ud835\udc5f_ as the root and construct a breadth-first\nsearch (BFS) tree rooted at _\ud835\udc5f_ . This BFS tree provides a set of simple\npaths P _\ud835\udc62_ from each node _\ud835\udc62_ to _\ud835\udc5f_ . **(2) Sample USTs.** We efficiently\nsample USTs using Wilson\u2019s algorithm [48], which form the basis of\nour estimator. **(3) From tree to forest.** Each sampled UST is then\nconverted into 2-forests using forward and reverse path mapping\nwith {P _\ud835\udc62_ | _\ud835\udc62_ \u2260 _\ud835\udc5f_ }. **(4) Estimate** KC **.** Finally, we estimate KC using\nEq. (4) based on the obtained 2-forests.\nThe core of our algorithm lies in steps (3) and (4). Importantly,\nwe do not need to explicitly transform sampled USTs into 2-forests.\nInstead, it suffices to compute the contributions that these 2-forests\nwould make to KC. Therefore, we merge the two steps and directly\nestimate KC from the sampled USTs. We propose two approaches\nfor this task: a naive method and an optimized method.\n\n**Traverse Each Path (Naive Method).** For each sampled UST _\ud835\udf0f_, we\ntraverse the path from each node _\ud835\udc62_ to the root _\ud835\udc5f_ within the sampled\ntree, and compare its edges with the pre-determined path P _\ud835\udc62_ from\nstep (1). Each matching edge with same orientation indicates a valid\n2-forest in F [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) (or F [P] _[\ud835\udc62]_ [\u2032] ( _\ud835\udf0f_ ) when edge has opposite orientation).\nFor each valid 2-forest, we accumulate the volume of the component\ncontaining _\ud835\udc5f_, i.e. vol( _\ud835\udc47_ 1), and multiply it by _\ud835\udc51_ ( _\ud835\udc62_ ) to contribute to\nthe KC estimate. Repeating this process for all nodes _\ud835\udc62_ \u2260 _\ud835\udc5f_ yields\nthe contribution of _\ud835\udf0f_, denoted by _\ud835\udc53_ ( _\ud835\udf0f_ )\n\nTheorem 3.6 (Correctness of Naive Method). _Given \ud835\udf14_ _UST_\n_samples and a fixed root \ud835\udc5f_ _with paths_ {P _\ud835\udc62_ | _\ud835\udc62_ \u2260 _\ud835\udc5f_ } _. Let_ \u02c6 _\ud835\udf0f\ud835\udc56_ _denote the_\n_\ud835\udc56-th sampled UST. Then,_ \u02dc _\ud835\udf05_ = 2 _\ud835\udc5a\ud835\udf14_ 1 \ufffd _\ud835\udc56\ud835\udf14_ =1 _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [ \u02c6] _[\ud835\udc56]_ [)] _[ is an unbiased estimator]_\n_of \ud835\udf05_ ( _\ud835\udc3a_ ) _, where_\n\nas:\n\n1\n_\ud835\udf05_ ( _\ud835\udc3a_ ) =\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n1\n\n=\n2 _\ud835\udc5a_ |\u0393|\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ ) _._\n\n_\ud835\udf0f_ \u2208\u0393\n\n\u2211\ufe01\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_ _\ud835\udc47_ \u222a _\ud835\udc47_ \u2208F\n\nvol( _\ud835\udc47_ 1)\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F _\ud835\udc5f_ | _\ud835\udc62,\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\n\u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P ] ( _\ud835\udf0f_ )\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\n\u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P ] ( _\ud835\udf0f_ )\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\n\u2211\ufe01\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_ _\ud835\udf0f_ \u2208\u0393\n\nvol( _\ud835\udc47_ 1) \u2212 \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P\u2032 ] ( _\ud835\udf0f_ )\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\nvol( _\ud835\udc47_ 1) \u2212 \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P\u2032 ] ( _\ud835\udf0f_ )\n_\ud835\udc5f_ \u2208 _\ud835\udc47_ 1\n\nvol( _\ud835\udc47_ 1)\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\n\nvol( _\ud835\udc47_ 1)\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\n\n  \n\n_\ud835\udf0f_ \u2208\u0393\n\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\n\n\u2211\ufe01\n\n_\ud835\udf0f_ \u2208\u0393\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_ \ufffd\n\n**Traverse by Depth-First Search (Optimized Method).** We further enhance traversal efficiency by maintaining an auxiliary variable vol_sum for each node and performing a DFS on the sampled\nUST _\ud835\udf0f_ . When visiting a node _\ud835\udc63_, we update vol_sum by adding or\nsubtracting 2 _\ud835\udc5a_ \u2212vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ )) if the edge connecting _\ud835\udc63_ to its parent\n_\ud835\udc5d_ ( _\ud835\udc63_ ) in _\ud835\udf0f_ also appears in the BFS tree obtained in step(1), where\n_Sub_ ( _\ud835\udf0f, \ud835\udc63_ ) denotes the subtree rooted at _\ud835\udc63_ in _\ud835\udf0f_ . After the update, we\nquery the vol_sum at _\ud835\udc63_, multiply it by _\ud835\udc51_ ( _\ud835\udc63_ ) to contribute to the KC\nestimate, recursively continue the DFS on its children, and finally\nrestore the affected vol_sum values by undoing the update.\n\nTheorem 3.7 (Correctness of Optimized Method). _Given an_\n_arbitrary spanning tree \ud835\udf0f_ _and a fixed spanning tree \ud835\udf0f_ 0 _, let \ud835\udc5f_ _be the_\n_root of both trees. Let_ P _\ud835\udc62_ _denote the path from node \ud835\udc62_ _to \ud835\udc5f_ _in \ud835\udf0f_ 0 _. Then,_\n_the following equality holds:_\n\u2211\ufe01 \u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01 (2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _,_ (5)\n\n\u2211\ufe01\n\n(2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _,_ (5)\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\n\u2211\ufe01\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) ( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_ 1\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P\u2032] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) ( _\ud835\udc5d_ ( _\ud835\udc63_ ) _,\ud835\udc63_\n\n( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_ )) \u2208 _\ud835\udf0f_ 0\n_\ud835\udc62_ \u2208 _\ud835\udc46_ 1\n\n( _\ud835\udc5d_ ( _\ud835\udc63_ ) _,\ud835\udc63_ ) \u2208 _\ud835\udf0f_ 0\n_\ud835\udc62_ \u2208 _\ud835\udc46_ 2\n\n\u2211\ufe01\n\n(2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _,_ (6)\n\n_where Sub_ ( _\ud835\udf0f, \ud835\udc63_ ) _is the node set in the subtree rooted at \ud835\udc63_ _within \ud835\udf0f, and_\n_\ud835\udc46_ 1 = _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ) \u2229 _Sub_ ( _\ud835\udf0f_ 0 _, \ud835\udc63_ ) _,\ud835\udc46_ 2 = _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ) \u2229 _Sub_ ( _\ud835\udf0f_ 0 _, \ud835\udc5d_ ( _\ud835\udc63_ )) _. \ud835\udc5d_ ( _\ud835\udc63_ ) _is_\n_the parent node of \ud835\udc63_ _in \ud835\udf0f_ _and therefore each edge_ ( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) _is directed_\n_towards the root \ud835\udc5f_ _in \ud835\udf0f._\n\nProof. For each node _\ud835\udc62_, we apply the forward path mapping\nP _\ud835\udc62_, which gives\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01 \ufffd2 _\ud835\udc5a_ \u2212 vol( _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f, \ud835\udc63_ ))\ufffd _._\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) ( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_ )) \u2208\n\n\ufffd2 _\ud835\udc5a_ \u2212 vol( _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f, \ud835\udc63_ ))\ufffd _._\n\n( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_ )) \u2208 _\ud835\udf0f_ 0\u2229 _\ud835\udf0f_\n_\ud835\udc62_ \u2208 _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f,\ud835\udc63_ )\u2229 _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f_ 0 _,\ud835\udc63_ )\n\n\u2211\ufe01 _\ud835\udc51_ ( _\ud835\udc62_ ) \ufffd\ufffd\ufffd\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\ufffd\n\n_\ud835\udc53_ ( _\ud835\udf0f_ ) = \u2211\ufe01\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) \u2212 \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) _\ud835\udc47_ \u222a _\ud835\udc47_ \u2208F\n\n\u2211\ufe01\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1)\ufffd\ufffd\ufffd\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P\u2032] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) \ufffd\n\n_._\n\nProof. Based on Theorem 3.1 and Theorem 3.3, we can represent the set F _\ud835\udc5f_ | _\ud835\udc62_ by applying the path mapping technique to the\nspanning tree set \u0393. With this representation, KC can be expressed\n\nBy the definition of path mapping, to obtain a valid 2-forest in\nF [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ), the deleted edge ( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) in _\ud835\udf0f_ must appear on both paths\nfrom _\ud835\udc62_ to _\ud835\udc5f_ in the two spanning trees _\ud835\udf0f_ and _\ud835\udf0f_ 0. This implies that\n_\ud835\udc62_ must belong to the intersection of the subtrees of _\ud835\udc63_ in _\ud835\udf0f_ and _\ud835\udf0f_ 0,\ndenoted as _\ud835\udc46_ 1 = _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f,\ud835\udc63_ ) \u2229 _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f_ 0 _, \ud835\udc63_ ). Therefore, summing over all\n_\ud835\udc62_ \u2260 _\ud835\udc5f_, we obtain\n\u2211\ufe01 \u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01 (2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _._\n\n\u2211\ufe01\n\n(2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _._\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) ( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_ )) \u2208\n\n( _\ud835\udc63,\ud835\udc5d_ ( _\ud835\udc63_ )) \u2208 _\ud835\udf0f_ \u2229 _\ud835\udf0f_ 0\n_\ud835\udc62_ \u2208 _\ud835\udc46_ 1\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n**Algorithm 1:** TTF\n\n**Input:** A graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ), the sample size _\ud835\udf14_, the root node _\ud835\udc5f_\n**Output:** \u02dc _\ud835\udf05_ as the estimation of Kemeny Constant\n\n**1** \u02dc _\ud835\udf05_ \u2190 0;\n\n**2** Generate _\ud835\udf0f_ 0 using BFS with root _\ud835\udc5f_ ;\n\n**3** DFSin, DFSout \u2190 _\ud835\udf0f_ 0;\n\n**4** vol_sum \u2190 BIT(| _\ud835\udc49_ |);\n\n**5 for** _\ud835\udc56_ \u2190 1 **to** _\ud835\udf14_ **do**\n\n**6** _\ud835\udf0f\ud835\udc56_ \u2190 wilson ( _\ud835\udc3a,\ud835\udc5f_ );"}, {"role": "assistant", "content": "**Mechanism:** The paper reformulates the Kemeny Constant (KC) using '2-forests' (graphs with exactly two connected components). The key mechanism, 'path mapping,' establishes a precise correspondence between Uniform Spanning Trees (USTs), which are efficiently samplable, and the set of 2-forests required by the new KC formula. Specifically, theorems prove that summing contributions from 'forward path mappings' of all spanning trees and subtracting 'reverse path mappings' precisely yields the required sum over specific 2-forests. This allows the complex problem of sampling or summing over 2-forests to be converted into the more tractable problem of sampling USTs and processing them efficiently. The optimized algorithm further enhances this by using a Depth-First Search (DFS) on the sampled UST, employing auxiliary variables and a Binary Index Tree (BIT) to cumulatively calculate contributions from node subtrees, avoiding redundant computations inherent in a naive path traversal.\n\n**Explanation:** The Kemeny Constant (KC) is a metric that tells you how quickly a random process mixes on a graph. Calculating it exactly for large graphs is computationally prohibitive, like trying to invert an enormous matrix, which takes an `n`-cubed amount of time (imagine `n` being the number of nodes). Previous approximation methods were either too slow, lacked strong mathematical guarantees, or struggled with graphs that change over time. This paper introduces a breakthrough by creating a new formula for KC that expresses it not with matrix operations, but with sums over '2-forests' \u2013 which are essentially spanning trees where one edge has been removed, leaving two connected components. The core insight is 'path mapping.' Instead of trying to directly generate or count these 2-forests (which is hard), they figured out a way to get the exact contributions to the KC formula by working with *spanning trees*. They show that by generating many random spanning trees (which can be done efficiently using well-known algorithms like Wilson's, similar to a clever loop that builds a connected structure), and then applying a specific 'cutting rule' (path mapping), they can implicitly count the 2-forests needed. This 'cutting rule' involves looking at paths within the sampled tree and a pre-computed BFS tree; an edge shared by these paths, and its orientation, dictates whether a contribution is added or subtracted. To make this process even faster, they use a Depth-First Search (DFS) when processing each sampled spanning tree. Imagine a recursive function that traverses the tree, and at each node, it maintains a running total (like an accumulator variable) of the 'volume' (sum of degrees) of the subtree beneath it. This allows them to quickly sum up the required terms from the new KC formula without repeatedly calculating 'volumes' from scratch, significantly speeding up the estimation process."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udf0f_ _is updated_ **then**\n\n**11** _\ud835\udc64_ ( _\ud835\udf0f_ ) \u2190 _\ud835\udc64_ ( _\ud835\udf0f_ )/ _\ud835\udc64\ud835\udc60\ud835\udc62\ud835\udc5a_ ( _\ud835\udf0f\ud835\udc60\ud835\udc52\ud835\udc59\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc52\ud835\udc51_ ) \u00b7 _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ );"}, {"role": "assistant", "content": "**Mechanism:** This line describes an update rule for an item's 'weight' (w(\ud835\udf0f)). The system first calculates how much this specific item (\ud835\udf0f) contributed proportionally to the total importance of a chosen group (w(\ud835\udf0f) / wsum(\ud835\udf0fselected)). This fraction represents \ud835\udf0f's 'share of voice' among the selected. This proportional share is then scaled by an external 'reward' or 'performance score' (R(u,v)) obtained from using the chosen group. The new weight for \ud835\udf0f becomes its old proportional contribution, amplified or diminished by the reward.\n\n**Explanation:** Intuitively, this mechanism ensures that items contributing to successful outcomes (high R) are given increased importance (higher w(\ud835\udf0f)), while those involved in less successful outcomes see their importance diminish. It's a positive feedback loop: if \ud835\udf0f was part of a selection that yielded a good R, and \ud835\udf0f had a significant relative weight within that selection, its absolute weight will grow. This is akin to a learning algorithm trying to reinforce 'good' choices. In programming terms, think of 'w' as a dictionary or hash map mapping '\ud835\udf0f' (an identifier) to a floating-point value. '\ud835\udf0fselected' is a list of keys, and 'wsum' is simply iterating through that list and summing their corresponding dictionary values. This update happens within a larger iterative loop, continuously refining these weights."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Simulated Gymnasium Environments**\n\nWe benchmarked our reward-profiling wrapper by performing extensive experiments to stress-test policy learning across\nthe major flavors of policy-gradient methods. We wrapped\nthree canonical algorithms. **TRPO**, the trusted \u201dsecondorder\u201d method with hard KL-constraints, **PPO**, its \u201dfirstorder\u201d surrogate-clipping successor and current on-policy\nworkhorse, and **DDPG**, an off-policy, replay buffer actorcritic known for sample-efficient continuous control but notoriously unstable, in our profiling layer.\n**Profiling framework integration.** We built a modular profiling wrapper atop Stable-Baselines3 (v1.9) and SB3-Contrib\n(Raffin et al. 2021), leveraging Gymnasium and PyBullet (Ellenberger 2018\u20132019; Towers et al. 2024) for simulation.\n\nEach variant ran for 100k environment steps across five random seeds. Each profiling round consumes the same 10k\nenvironment steps as the baseline; samples used for improvement checks are _reused_ for training updates. Thus, no additional interactions are collected. All variants share the same\nper-round evaluation schedule and count. Every candidate\nset is scored with short episodes ( _E_ = 5), and averages are\ncomputed on the identical rollouts for all baselines for fair\ncomparison. The policy network in SB3 is actor-critic, which\nwas used throughout the experiments.\n\n**Benchmark environments.** We evaluate reward profiling\non two complementary families of continuous control tasks:\n**Box2D Suite** where the BipedalWalker environment challenges agents to navigate uneven terrain using 24D lidar/joint\nobservations and 4D torque actions, with sparse rewards for\nforward progress. CarRacing provides pixel-based control\n(96\u00d796 RGB input) for lap completion, while LunarLanderContinuous tests precise thruster control (8D state, 2D\nactions) under sparse landing rewards. **MuJoCo/PyBul-**\n**let Suite**, where we experimented with high-dimensional\nlocomotion with Ant, HalfCheetah, Hopper, Humanoid,\nWalker2D, with observation state and action both having\nseveral dimensions, ranging from torque control, actions for\nbalance, or even for forward gait.\n\n**Observation.** The most significant gain is in terms of variance performance overall as shown in Figure 2. In cases it\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-0.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-1.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-2.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-3.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-4.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-5.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-6.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-7.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-8.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-9.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-10.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-5-11.png)\n\nFigure 2: Average Return vs. timesteps (up to 100K) for 3 policy-gradient methods, PPO (top row), TRPO (middle row), and DDPG (bottom\nrow), on 4 continuous-control benchmarks: LunarLanderContinuous, Ant, Hopper, Walker2D, and under variants: Vanilla, Lookback,\nMixup, Three-Points, with _E_ = 5 for minimal overhead. Extra rollouts tuning gets convergence gains in complex environments.\n\ntransforms catastrophic failures into viable policies across\nkey benchmarks. The CarRacing agent, both with TRPO and\nPPO, average large negative returns, crashing before completing a lap. The variants turn them into positive-return drivers.\nThe training recovers stable driving behavior by modifying\nupdates that worsen lap scores. DDPG remains unstable under an MLP policy, but profiling still raises the worst runs.\nFor BipedalWalker, where vanilla TRPO already performs\nwell (105 _._ 0 _\u00b1_ 57 _._ 0), profiling yields minimal gains due to\ninherent conservatism, though DDPG+Mixup still improves\nfrom _\u2212_ 116 _._ 1 _\u00b1_ 13 _._ 5 to _\u2212_ 47 _._ 0 _\u00b1_ 27 _._ 1. It still provides competitive performance in precision tasks. Among our highDOF benchmarks, Ant DDPG+Mixup gives modest bumps\nover the baseline with earlier convergence behavior, while\nits Three-Point variant provides superior variance characteristics (11% reduction from the baseline) with moderate\nfinal return over time. It also augments the training behavior\nwith TRPO and PPO on several metrics, offering moderate\nimprovement in variance. On HalfCheetah, DDPG+Mixup\ndominates (1137 _._ 8 _\u00b1_ 185 _._ 6 vs 576 _._ 3 _\u00b1_ 749 _._ 9) with usual variance performance in PPO. The performance on Walker2D\nand Humanoid remain challenging in variance stability; even\n\nwith profiling, TRPO and PPO show limited gains while\nbaselines also show very similar results. The profiling framework improves most metrics with strong to moderate gains,\nexcept for the setups that remain challenging to learn with\noff-the-shelf algorithms without careful tuning.\n\n**6.2** **Experiment with Multi-robot Task**\n\nFor a realistic and domain-specific evaluation, we deployed\nit in a multi-agent robotic setting on the Unity ML-Agents\nReacher task (Juliani et al. 2020; Cohen et al. 2022). Unity\nprovides a flexible, visually realistic, and customizable simulation environment; see Figure 3. Here, the environment\nsimulates 20 robotic arms operating in parallel, each receiving a 33-dimensional state vector (joint angles, velocities,\nand target position) and outputting 4D continuous torques.\nAgents earn a dense reward of +0 _._ 1 per timestep for maintaining their fingertip in a moving target zone. We plugged\nour profiling wrapper (the TP variant) into the platform atop\na decentralized DDPG architecture, with policy updates evaluated every 50 episodes through 5-agent consensus voting.\n**Observation.** Three-Point profiling (TP) demonstrates sub\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-6-0.png)\n\nFigure 3: Multi-agent Reacher task in UnityML: multiple robotic\narms must coordinate to reach and manipulate randomly placed targets (spheres) on a raised platform, testing control under interaction.\n\nFigure 5: Sensitivity to evaluation rollouts _E_ for DDPG+ThreePoints on HopperBulletEnv-v0. Curves show mean selected returns (\u00b11 std). Small _E_ (10\u201320) yields noisy, unstable updates; large\n_E_ (200) improves stability but slows progress; mid-range _E_ (50\u2013100)\nbalances both.\n\nstantially more stable learning than vanilla DDPG, as evidenced by the training performance in Figure 4. TP-enhanced\nagent achieves a higher return from early training with fewer\nfluctuations, achieving smoother progression. Only five sampled returns ( _E_ = 5) make the computation overhead minimal while solving for the optimal policy at early training iterations. This implies the suitability of a reward-profiling framework for physical deployment, where stable, predictable\nlearning behavior is a requirement."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a selective update filter. Instead of directly applying every proposed policy gradient update, a 'profiling layer' acts as an intermediary. It evaluates the potential new policy (or several candidate policies) against the current policy using a small, fixed set of already collected environmental samples. This is effectively a rapid 'test suite' running on cached data.\n\n**Explanation:** Think of it like a developer's workflow with a robust version control system. When you're about to 'commit' a change (a policy update) to your main codebase (the current policy), you first run a quick battery of unit tests and integration tests (the short episode evaluations) using data you already have (reused samples). If those tests show the proposed change introduces regressions or 'bugs' (catastrophic failures or decreased returns), that 'commit' is either rejected, modified, or a safer alternative is chosen. If the tests pass, indicating an improvement or at least no degradation, then the 'commit' is accepted and the policy is updated. This prevents 'bad commits' from polluting the main branch and causing instability. By reusing samples, it's akin to having an extremely efficient CI/CD pipeline that doesn't require spinning up new environments for every test, ensuring minimal overhead while providing a crucial stability check."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nTo conclude, TLT alleviates the critical long-tail bottleneck\nin reasoning RL training through an adaptive drafter. The\nadaptivity operates on two folds: during training, it adapts to\ntarget model updates; during inference, it adapts to varying\nbatchsizes. As a result, TLT achieves substantial throughput\nimprovements while preserving model quality.\n\n**Acknowledgements**\n\nWe thank MIT-IBM Watson AI Lab, MIT AI Hardware Program, MIT Amazon Science Hub, Hyundai Motor Company,\nand National Science Foundation for supporting this work.\n\n**References**\n\n[1] Arash Ahmadian, Chris Cremer, Matthias Gall\u00e9, Marzieh Fadaee, Julia\nKreutzer, Olivier Pietquin, Ahmet \u00dcst\u00fcn, and Sara Hooker. 2024. Back\nto Basics: Revisiting REINFORCE Style Optimization for Learning from\nHuman Feedback in LLMs. In _Proceedings of the 62nd Annual Meeting_\n_of the Association for Computational Linguistics (ACL \u201924)_ .\n\n[2] Zachary Ankner, Rishab Parthasarathy, Aniruddha Nrusimha, Christopher Rinard, Jonathan Ragan-Kelley, and William Brandon. 2024. Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding. In\n_Conference on Language Modeling (COLM \u201924)_ .\n\n[3] ByteDance. 2025. W&B trace of DAPO Reproduction on\nverl. [https://wandb.ai/verl-org/DAPO%20Reproduction%20on%](https://wandb.ai/verl-org/DAPO%20Reproduction%20on%20verl?nw=u7n2j5sht28)\n[20verl?nw=u7n2j5sht28](https://wandb.ai/verl-org/DAPO%20Reproduction%20on%20verl?nw=u7n2j5sht28)\n\n[4] Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D.\nLee, Deming Chen, and Tri Dao. 2024. Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads. _CoRR_\n[abs/2401.10774 (2024). https://arxiv.org/abs/2401.10774](https://arxiv.org/abs/2401.10774)\n\n[5] Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste\nLespiau, Laurent Sifre, and John Jumper. 2023. Accelerating Large\nLanguage Model Decoding with Speculative Sampling. _CoRR_\n[abs/2302.01318 (2023). https://arxiv.org/abs/2302.01318](https://arxiv.org/abs/2302.01318)\n\n[6] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan,\nPeng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wanxiang Che.\n2025. Towards Reasoning Era: A Survey of Long Chain-of-Thought\nfor Reasoning Large Language Models. _CoRR_ abs/2503.09567 (2025).\n[https://arxiv.org/abs/2503.09567](https://arxiv.org/abs/2503.09567)\n\n[[7] Codeforces. 2025. CodeForces Online Judge. https://codeforces.com/](https://codeforces.com/)\n\n[8] Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, Jiarui Yuan,\nHuayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu\nHan, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou,\nand Ning Ding. 2025. Process Reinforcement through Implicit Rewards.\n_CoRR_ [abs/2502.01456 (2025). https://arxiv.org/abs/2502.01456](https://arxiv.org/abs/2502.01456)\n\n[9] DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song,\nRuoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi,\nXiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong\nShao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang,\nBochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng,\nChenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang\nLi, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen,\nGuowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui\nDing, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi\nLi, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong\nLi, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao,\nKang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang\nZhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang,\nMinghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming\nLi, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu\nChen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang,\nR. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou,\nShuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao\nYun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao,\nWen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang,\nW. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen,\nXiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang,\nXinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin\nShen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song,\nXinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X.\nWei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui\nWang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi\nPiao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang\nGuo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X.\n\n13\n\nZhu, Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu,\nYunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren,\nZhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen\nHao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang,\nZhipeng Xu, Zhongyu Zhang, and Zhen Zhang. 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.\n_CoRR_ [abs/2501.12948 (2025). https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)\n\n[10] Hugging Face. 2025. Open R1: A fully open reproduction of DeepSeek[R1. https://github.com/huggingface/open-r1](https://github.com/huggingface/open-r1)\n\n[11] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.\n2023. GPTQ: Accurate Post-Training Quantization for Generative\nPre-trained Transformers. _CoRR_ abs/2210.17323 (2023). [https:](https://arxiv.org/abs/2210.17323)\n[//arxiv.org/abs/2210.17323](https://arxiv.org/abs/2210.17323)\n\n[12] Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He,\nShusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang\nYuan, and Yi Wu. 2025. AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning. _CoRR_ abs/2505.24298\n[(2025). https://arxiv.org/abs/2505.24298](https://arxiv.org/abs/2505.24298)\n\n[13] Yichao Fu, Peter Bailis, Ion Stoica, and Hao Zhang. 2024. Break the\nsequential dependency of llm inference using lookahead decoding.\n_arXiv preprint arXiv:2402.02057_ (2024).\n\n[14] Xiangxiang Gao, Weisheng Xie, Yiwei Xiang, and Feng Ji. 2025. Falcon:\nFaster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding\nTree. In _Proceedings of the AAAI Conference on Artificial Intelligence_\n_(AAAI \u201925)_ .\n\n[15] Gemini. 2025. Gemini 2.5 Pro Technical Report. [https:](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n[//blog.google/technology/google-deepmind/gemini-model-thinking-](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n[updates-march-2025/#gemini-2-5-pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n\n[16] Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D. Lee, and Di He. 2024.\nREST: Retrieval-Based Speculative Decoding. _CoRR_ abs/2311.08252\n[(2024). https://arxiv.org/abs/2311.08252](https://arxiv.org/abs/2311.08252)\n\n[17] Pieter Hintjens. 2013. _ZeroMQ: messaging for many applications_ . \"\nO\u2019Reilly Media, Inc.\".\n\n[18] Jian Hu, Jason Klein Liu, and Shen Wei. 2025. REINFORCE++: An\nEfficient RLHF Algorithm with Robustness to Both Prompt and Reward\nModels. _CoRR_ [abs/2501.03262 (2025). https://arxiv.org/abs/2501.03262](https://arxiv.org/abs/2501.03262)\n\n[19] Diederik P Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In _International Conference on Learning Representa-_\n_tions (ICLR \u201915)_ .\n\n[20] Mario Michael Krell, Matej Kosec, Sergio P. Perez, and Andrew Fitzgibbon. 2022. Efficient Sequence Packing without Cross-contamination:\nAccelerating Large Language Models without Impacting Performance.\n_CoRR_ [abs/2107.02027 (2022). https://arxiv.org/abs/2107.02027](https://arxiv.org/abs/2107.02027)\n\n[21] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin\nZheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica.\n2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In _Proceedings of the ACM SIGOPS 29th Sym-_\n_posium on Operating Systems Principles (SOSP \u201923)_ .\n\n[22] Yaniv Leviathan, Matan Kalman, and Yossi Matias. 2023. Fast Inference\nfrom Transformers via Speculative Decoding. In _Proceedings of the 40th_\n_International Conference on Machine Learning (ICML \u201923)_ . 19274\u201319286.\n\n[23] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer,\nHenryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil,\nImanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur,\nGuy Gur-Ari, and Vedant Misra. 2022. Solving Quantitative Reasoning\nProblems with Language Models. In _Advances in Neural Information_\n_Processing Systems (NeurIPS \u201922)_ .\n\n[24] Jia LI, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi,\nShengyi Costa Huang, Kashif Rasul, Longhui Yu, Albert Jiang, Ziju\nShen, Zihan Qin, Bin Dong, Li Zhou, Yann Fleureau, Guillaume Lample,\n[and Stanislas Polu. 2025. NuminaMath. https://huggingface.co/AI-](https://huggingface.co/AI-MO/NuminaMath-CoT)\n[MO/NuminaMath-CoT.](https://huggingface.co/AI-MO/NuminaMath-CoT)\n\n[25] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2024.\nEAGLE-2: Faster Inference of Language Models with Dynamic Draft\nTrees. In _Proceedings of the 2024 Conference on Empirical Methods in_\n_Natural Language Processing (EMNLP \u201924)_ .\n\n[26] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2024. EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty.\nIn _Proceedings of the 41st International Conference on Machine Learning_\n_(ICML \u201924)_ .\n\n[27] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2025.\nEAGLE-3: Scaling up Inference Acceleration of Large Language Models\nvia Training-Time Test. _CoRR_ [abs/2503.01840 (2025). https://arxiv.org/](https://arxiv.org/abs/2503.01840)\n[abs/2503.01840](https://arxiv.org/abs/2503.01840)\n\n[28] Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang,\nQinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming\nChen, Sean Lai, Xupeng Miao, and Zhihao Jia. 2025. AdaServe: SLOCustomized LLM Serving with Fine-Grained Speculative Decoding.\n_CoRR_ [abs/2501.12162v1 (2025). https://arxiv.org/abs/2501.12162](https://arxiv.org/abs/2501.12162)\n\n[29] Baohao Liao, Yuhui Xu, Hanze Dong, Junnan Li, Christof Monz,\nSilvio Savarese, Doyen Sahoo, and Caiming Xiong. 2025. RewardGuided Speculative Decoding for Efficient LLM Reasoning. _CoRR_\n[abs/2501.19324 (2025). https://arxiv.org/abs/2501.19324](https://arxiv.org/abs/2501.19324)\n\n[30] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen,\nWei-Chen Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, and\nSong Han. 2024. AWQ: Activation-aware Weight Quantization for\nLLM Compression and Acceleration. _CoRR_ abs/2306.00978 (2024).\n[https://arxiv.org/abs/2306.00978](https://arxiv.org/abs/2306.00978)\n\n[31] Xiaoxuan Liu, Lanxiang Hu, Peter Bailis, Alvin Cheung, Zhijie Deng,\nIon Stoica, and Hao Zhang. 2024. Online Speculative Decoding. In\n_International Conference on Learning Representations (ICML \u201924)_ .\n\n[32] Alexander Lyzhov, Yuliya Molchanova, Arsenii Ashukha, Dmitry\nMolchanov, and Dmitry Vetrov. 2020. Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation. In _Proceedings of_\n_the 36th Conference on Uncertainty in Artificial Intelligence (UAI \u201920)_ .\n\n1308\u20131317.\n\n[33] Xinyin Ma, Gongfan Fang, and Xinchao Wang. 2023-12-15. LLMPruner: On the Structural Pruning of Large Language Models. In _Ad-_\n_vances in Neural Information Processing Systems (NeurIPS \u201923)_ .\n\n[34] MAA. 2024. American Invitational Mathematics Examination [AIME. https://artofproblemsolving.com/wiki/index.php/American_](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination)\n[Invitational_Mathematics_Examination](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination)\n\n[35] Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, and\nYi Wu. 2024. ReaLHF: Optimized RLHF Training for Large Language\nModels through Parameter Reallocation. _CoRR_ abs/2406.14088 (2024).\n[https://arxiv.org/abs/2406.14088](https://arxiv.org/abs/2406.14088)\n\n[36] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu\nWang, Zhengxin Zhang, Rae Ying Yee Wong, Alan Zhu, Lijie Yang, Xiaoxiang Shi, Chunan Shi, Zhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao Jia. 2024. SpecInfer: Accelerating Large Language\nModel Serving with Tree-based Speculative Inference and Verification.\nIn _Proceedings of the 29th ACM International Conference on Architectural_\n_Support for Programming Languages and Operating Systems, Volume 3_\n_(ASPLOS \u201924)_ . Association for Computing Machinery.\n\n[37] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov,\nRichard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul,\nMichael I. Jordan, and Ion Stoica. 2018. Ray: A Distributed Framework\nfor Emerging AI Applications. In _13th USENIX Symposium on Operating_\n_Systems Design and Implementation (OSDI \u201918)_ .\n\n[38] Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li FeiFei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel\nCand\u00e8s, and Tatsunori Hashimoto. 2025. s1: Simple test-time scaling.\n_arXiv preprint arXiv:2501.19393_ (2025).\n\n[[39] NVIDIA Corporation. 2025. NVIDIA DGX H100. https://www.nvidia.](https://www.nvidia.com/en-gb/data-center/dgx-h100/)\n[com/en-gb/data-center/dgx-h100/.](https://www.nvidia.com/en-gb/data-center/dgx-h100/)\n\n14\n\n[40] OpenAI, Ahmed El-Kishky, Alexander Wei, Andre Saraiva, Borys\nMinaiev, Daniel Selsam, David Dohan, Francis Song, Hunter Lightman, Ignasi Clavera, Jakub Pachocki, Jerry Tworek, Lorenz Kuhn,\nLukasz Kaiser, Mark Chen, Max Schwarzer, Mostafa Rohaninejad, Nat\nMcAleese, o3 contributors, Oleg M\u00fcrk, Rhythm Garg, Rui Shu, Szymon Sidor, Vineet Kosaraju, and Wenda Zhou. 2025. Competitive\nProgramming with Large Reasoning Models. _CoRR_ abs/2502.06807\n[(2025). https://arxiv.org/abs/2502.06807](https://arxiv.org/abs/2502.06807)\n\n[41] OpenThoughts. 2025. open-thoughts/OpenThoughts2-1M.\nhttps://huggingface.co/datasets/open-thoughts/OpenThoughts2-1M.\n\n[42] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina\nSlama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models\nto follow instructions with human feedback. In _Advances in Neural_\n\n_Information Processing Systems (NeurIPS \u201922)_ .\n\n[43] Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, and\nRavi Netravali. 2025. SpecReason: Fast and Accurate Inference-Time\nCompute via Speculative Reasoning. _CoRR_ pdf/2504.07891 (2025).\n[https://arxiv.org/abs/2504.07891](https://arxiv.org/abs/2504.07891)\n\n[[44] PyTorch Team. 2025. PyTorch FSDP2. https://docs.pytorch.org/docs/](https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html)\n[stable/distributed.fsdp.fully_shard.html.](https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html)\n\n[[45] PyTorch Team. 2025. Torch Distributed Checkpoint Document. https:](https://pytorch.org/docs/stable/distributed.checkpoint.html)\n[//pytorch.org/docs/stable/distributed.checkpoint.html](https://pytorch.org/docs/stable/distributed.checkpoint.html)\n\n[46] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo\nZheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran\nWei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin\nBao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui\nMen, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren,\nXuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong\nLiu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2025. Qwen2.5 Technical\nReport. _CoRR_ [abs/2412.15115 (2025). https://arxiv.org/abs/2412.15115](https://arxiv.org/abs/2412.15115)\n\n[47] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He.\n2020. ZeRO: Memory Optimizations toward Training Trillion Parameter Models. In _Proceedings of the International Conference for High_\n_Performance Computing, Networking, Storage and Analysis (SC \u201920)_ .\n\n[[48] Apoorv Saxena. 2023. Prompt Lookup Decoding. https://github.com/](https://github.com/apoorvumang/prompt-lookup-decoding/)\n[apoorvumang/prompt-lookup-decoding/](https://github.com/apoorvumang/prompt-lookup-decoding/)\n\n[[49] John Schulman. 2020. Approximating KL Divergence. http://joschu.](http://joschu.net/blog/kl-app rox.html)\n[net/blog/kl-approx.html](http://joschu.net/blog/kl-app rox.html)\n\n[50] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and\nOleg Klimov. 2017. Proximal Policy Optimization Algorithms. _CoRR_\n(2017).\n\n[51] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao\nBi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo.\n2024. DeepSeekMath: Pushing the Limits of Mathematical Reasoning\nin Open Language Models. _CoRR_ [abs/2402.03300 (2024). https://arxiv.](https://arxiv.org/abs/2402.03300)\n[org/abs/2402.03300](https://arxiv.org/abs/2402.03300)\n\n[52] Gerald Shen, Zhilin Wang, Olivier Delalleau, Jiaqi Zeng, Yi Dong,\nDaniel Egert, Shengyang Sun, Jimmy J. Zhang, Sahil Jain, Ali\nTaghibakhshi, Markel Sanz Ausin, Ashwath Aithal, and Oleksii\nKuchaiev. 2024. NeMo-Aligner: Scalable Toolkit for Efficient Model\nAlignment. In _Conference on Language Modeling (COLM \u201924)_ .\n\n[53] Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang,\nRu Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. 2025. HybridFlow: A Flexible and Efficient RLHF Framework. In _Proceedings of_\n_the Twentieth European Conference on Computer Systems (EuroSys \u201925)_ .\nAssociation for Computing Machinery.\n\n[54] Aleksandrs Slivkins et al. 2019. Introduction to multi-armed bandits.\n_Foundations and Trends\u00ae in Machine Learning_ 12, 1-2 (2019), 1\u2013286.\n\n[[55] Chang Su. 2025. https://github.com/sgl-project/sglang/pull/4732.](https://github.com/sgl-project/sglang/pull/4732)\n\n[56] Qwen Team. 2025. QwQ-32B: Embracing the Power of Reinforcement\n[Learning. https://qwenlm.github.io/blog/qwq-32b/](https://qwenlm.github.io/blog/qwq-32b/)\n\n[57] Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\nJordan, Ken Goldberg, and Joseph E. Gonzalez. 2021. Resource Allocation in Multi-armed Bandit Exploration: Overcoming Sublinear\nScaling with Adaptive Parallelism. In _Proceedings of the 38th Interna-_\n_tional Conference on Machine Learning (ICML \u201921)_ .\n\n[58] Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou\nDai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng\nXie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen,\nYu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, and Jianfeng Gao.\n2025. A Survey on Post-training of Large Language Models. _CoRR_\n[abs/2503.06072 (2025). https://arxiv.org/abs/2503.06072](https://arxiv.org/abs/2503.06072)\n\n[59] Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching,\nTristan Thrush, Nathan Lambert, Shengyi Huang, Kashif Rasul, and\nQuentin Gallou\u00e9dec. 2025. TRL: Transformer Reinforcement Learning.\n[https://github.com/huggingface/trl.](https://github.com/huggingface/trl)\n\n[60] Hanjing Wang, Man-Kit Sit, Congjie He, Ying Wen, Weinan Zhang,\nJun Wang, Yaodong Yang, and Luo Mai. 2023. GEAR: A GPU-Centric\nExperience Replay System for Large Reinforcement Learning Models.\nIn _Proceedings of the 40th International Conference on Machine Learning_\n_(ICML \u201923)_ .\n\n[61] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. _Machine learning_\n(1992).\n\n[62] Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, and Yiming Yang.\n2025. Inference Scaling Laws: An Empirical Analysis of ComputeOptimal Inference for Problem-Solving with Language Models. _CoRR_\n[abs/2408.00724 (2025). https://arxiv.org/abs/2408.00724](https://arxiv.org/abs/2408.00724)\n\n[63] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike\nLewis. 2024. Efficient Streaming Language Models with Attention\nSinks. In _International Conference on Learning Representations (ICLR_\n_\u201924)_ .\n\n[64] Youshao Xiao, Zhenglei Zhou, Fagui Mao, Weichang Wu, Shangchun\nZhao, Lin Ju, Lei Liang, Xiaolu Zhang, and Jun Zhou. 2024. An Adaptive\nPlacement and Parallelism Framework for Accelerating RLHF Training.\n_CoRR_ [pdf/2312.11819 (2024). https://arxiv.org/abs/2312.11819](https://arxiv.org/abs/2312.11819)\n\n[65] Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang,\nConglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly\nSmith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, and Yuxiong He. 2023. DeepSpeed-Chat: Easy, Fast\nand Affordable RLHF Training of ChatGPT-like Models at All Scales.\n_CoRR_ [abs/2308.01320 (2023). https://arxiv.org/abs/2308.01320](https://arxiv.org/abs/2308.01320)\n\n[66] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu\nYue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi\nLin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan\nZhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen,\nChengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng Wei,\nHao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao,\nYonghui Wu, and Mingxuan Wang. 2025. DAPO: An Open-Source\nLLM Reinforcement Learning System at Scale. _CoRR_ pdf/2503.14476\n[(2025). https://arxiv.org/abs/2503.14476](https://arxiv.org/abs/2503.14476)\n\n[67] Lefan Zhang, Xiaodan Wang, Yanhua Huang, and Ruiwen Xu. 2025.\nLearning Harmonized Representations for Speculative Sampling. In\n_International Conference on Learning Representations (ICLR \u201925)_ .\n\n[68] Yao Zhao, Zhitian Xie, Chen Liang, Chenyi Zhuang, and Jinjie Gu.\n2024. Lookahead: An Inference Acceleration Framework for Large\nLanguage Model with Lossless Generation Accuracy. In _Proceedings of_\n_the 30th ACM SIGKDD Conference on Knowledge Discovery and Data_\n_Mining (KDD \u201924)_ . Association for Computing Machinery.\n\n[69] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P\n\n15\n\nXing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging\nLLM-as-a-judge with MT-Bench and Chatbot Arena. _CoRR_ (2023).\n\n[70] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Sun, Jeff\nHuang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica,\nJoseph E. Gonzalez, Clark Barrett, and Ying Sheng. 2024. SGLang:\nEfficient Execution of Structured Language Model Programs. In _Ad-_\n_vances in Neural Information Processing Systems (NeurIPS \u201924)_ .\n\n[71] Yinmin Zhong, Zili Zhang, Xiaoniu Song, Hanpeng Hu, Chao Jin,\nBingyang Wu, Nuo Chen, Yukun Chen, Yu Zhou, Changyi Wan,\n\nHongyu Zhou, Yimin Jiang, Yibo Zhu, and Daxin Jiang. 2025. StreamRL:\nScalable, Heterogeneous, and Elastic RL for LLMs with Disaggregated\nStream Generation. _CoRR_ [abs/2504.15930 (2025). https://arxiv.org/](https://arxiv.org/abs/2504.15930)\n[abs/2504.15930](https://arxiv.org/abs/2504.15930)\n\n[72] Yinmin Zhong, Zili Zhang, Bingyang Wu, Shengyu Liu, Yukun Chen,\nChangyi Wan, Hanpeng Hu, Lei Xia, Ranchen Ming, Yibo Zhu, and\nXin Jin. 2025. Optimizing RLHF Training for Large Language Models\nwith Stage Fusion. In _22nd USENIX Symposium on Networked Systems_\n_Design and Implementation (NSDI \u201925)_ .\n\n16"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an 'adaptive drafter' that generates preliminary outputs or action sequences for the main Reinforcement Learning (RL) model. This drafter is 'adaptive' in two key ways: it learns from the main model during training and dynamically scales its operations during inference.\n\n**Explanation:** The 'long-tail bottleneck' in reasoning RL training means the model spends a disproportionate amount of time learning from rare or complex scenarios. TLT's adaptive drafter acts like a continually refined 'speculative execution' unit. During training, as the main RL model updates its internal states and policies ('target model updates'), the drafter's own predictive logic is quickly adjusted to match the main model's improving intelligence. This is similar to a smart cache that learns the patterns of expensive computations and provides highly accurate predictions, allowing the main model to primarily 'verify' or 'correct' a draft rather than generating an entire solution from scratch. During inference, the drafter dynamically adjusts its resource allocation and computational strategy based on the current workload ('varying batchsizes'). For example, it might employ vectorized operations or parallel processing tailored to the batch size, ensuring that its overhead doesn't grow linearly with the number of parallel requests. This efficient pre-computation and verification loop significantly reduces the overall computational cycles required, leading to higher throughput."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**8 end for**\n\nThe theoretical aspects of _RR_ packet scheduling algorithm are provided in 2.2.4.\n\n46 D. Dimopoulos, et al.\n\n**Algorithm 5:** LLHD\n\n**Input:** Set of subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R\n\n**Output:** Best subflow, _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2208S\n\n**Initialization:**\n\n_\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ = _\ud835\udc41\ud835\udc48\ud835\udc3f\ud835\udc3f_ ;\n\n_\ud835\udefe\ud835\udc5a\ud835\udc4e\ud835\udc65_ = 0 ;\n\n_\ud835\udefd_ = 0 _._ 001 ; /* _\ud835\udefd_ = 0 _._ 001 in paper [67]; however, actual value in code is _\ud835\udefd_ = 10 [66] */\n\n_\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc5a\ud835\udc4e\ud835\udc65_ = 9999999 ;\n\n_\ud835\udc3a\ud835\udc43\ud835\udc5a\ud835\udc4e\ud835\udc65_ = 9999 ;\n\nUpon reception of ACK:\n\n**1 for** _each \ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S **do**"}, {"role": "assistant", "content": "**Mechanism:** The algorithm employs a 'best-so-far' search pattern, initializing key variables with sentinel values to establish a baseline. 'sfbest' starts as null, representing no optimal path yet, while 'gamma_max' is set to zero for a metric likely to be maximized. Conversely, 'RTTmax' and 'GPmax' are set to extremely large numbers, acting as initial 'worst-case' values. This guarantees that any real measurement obtained from the first subflow will immediately become the current 'best' candidate. The core mechanism then iterates through each subflow, comparing its characteristics to the current 'best-so-far' values. A critical insight is the 'beta' parameter's differing values between the paper and the code, indicating practical empirical tuning often deviates from theoretical models.\n\n**Explanation:** This code sets up a standard iterative search (like a 'for each' loop) to find the best 'subflow' or data path. Before it starts comparing paths, it initializes variables: 'sfbest' is set to a null pointer, meaning no best path has been identified yet. 'gamma_max' starts at zero, likely because we're looking for the highest possible 'gamma' score. For metrics we want to minimize, like 'Round Trip Time' ('RTTmax') or 'GPmax', they are given extremely high starting values (like `9999999`). This acts as a 'worst possible' baseline, ensuring that the first actual measurement from any subflow will always be 'better' than this initial, artificially bad value. The algorithm is triggered by an 'ACK' (acknowledgement of data) and then begins to check each available subflow systematically. The 'beta' variable acts as a weighting or tuning factor, and its documented discrepancy between the paper's theory and the code's reality highlights that real-world network conditions often necessitate practical adjustments beyond pure mathematical models."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n`UndecidedNeighbors` _is empty_ **then**\n\n**29** From this point onward, disregard the rest of the algorithm and Output 1 in\nevery round where node _i_ is still Undecided;\n\n11\n\n  - In Round 2, node _i_ outputs 1 only if no neighbor has yet output 1 or _\u22a5_, and _i_ has won\nthe RPS game against all its undecided neighbors. Since all neighbors also follow the\nalgorithm, any neighbor that loses to _i_ in the RPS game will not output 1. Thus, no\nneighbor of _i_ can simultaneously output 1.\n\n  - In Round 3, node _i_ outputs 1 only if all of its neighbors have already output 0. Hence, it\nis impossible for a neighbor to output 1 in this case.\n\nTherefore, Case 2 cannot occur. Combined with the fact that Case 1 is also impossible, we\nconclude that by following Algorithm 1, node _i_ \u2019s utility is never less than 0.\n\n**Theorem 3.5.** _The strategy corresponding to Algorithm 1 constitutes a Belief-Independent Se-_\n_quential Equilibrium._\n\n_Proof._ Consider an arbitrary history _h_ with _i \u2208_ _P_ ( _h_ ). Let _hi_ denote the local history of node\n_i_, which implies _h \u2208_ _Ii_ ( _hi_ ) _\u2208Ii_ . We show that the continuation strategy prescribed for _i_ by\nAlgorithm 1 from information set _Ii_ ( _hi_ ) is sequentially rational irrespective of the _i_ \u2019s belief over\n_Ii_ ( _hi_ ), i.e., it gives the maximum expected payoff when all other nodes also follow Algorithm 1\nfrom _h_ . It follows that the strategy constitutes a sequential equilibrium for any belief system\nof _i_ . and it follows that the strategy constitutes a Belief-Independent Sequential Equilibrium.\nAs we mentioned in Section 2, we do not consider internal deviations except for randomness\ngeneration. We distinguish deviations as:\n\n  - _Undetectable deviations:_ for example, choosing RPS moves with nonuniform probabilities.\nSince every sequence of moves is still possible under the prescribed uniform strategy (albeit\nwith small probability), neighbors can never rule out a deviation with certainty, even after\nmany observations. Similarly, voluntarily outputting 0 or _\u22a5_ earlier than prescribed may\nalso be indistinguishable, since it could be a valid response to another neighbor having\noutput 1, which remaining neighbors may not observe.\n\n  - _Detectable deviations:_ e.g., failing to send a required/valid message, sending inconsistent\nmessages, or outputting 1 when not eligible. Such deviations are caught by at least one\nneighbor, upon which the neighbor sets its `BeenCheated` flag to 1.\n\n**Case analysis.**\n\n_Case A: At h, i has a decided neighbor with output_ 1 _or \u22a5._ Then the maximum attainable\npayoff for _i_ is 0. By Lemma 3.4, following the algorithm yields a payoff of at least 0. Hence, no\nprofitable deviation exists, so the prescribed action is a best response.\n\n_Case B: At h, i do not have a decided neighbor with output_ 1 _or \u22a5_ _and there exists an_\n_undecided neighbor that i has cheated._ If the remaining undecided neighbors follow the algorithm,\nLemma 3.3 implies the most _i_ can obtain is 0; following the algorithm also yields payoff 0. Thus,\nno profitable deviation exists.\n\n_Case C: At h, i does not have a decided neighbor with output_ 1 _or \u22a5_ _and i has not cheated_\n_any undecided neighbor._\n\n  - _Detectable deviation by i:_ Some neighbor detects it and sets `BeenCheated` = 1. By\nLemma 3.3, the best payoff _i_ can then secure is 0. By Lemma 3.4, sticking to the algorithm yields a payoff of at least 0, so no profitable deviation exists.\n\n  - _Undetectable deviation by i:_ (i) Changing the probabilities with which _i_ plays rock, paper, scissors does not improve _i_ \u2019s win probability against neighbors who pick each move\nuniformly at random. Therefore, _i_ \u2019s chance of joining the MIS is unchanged, and so is the\nexpected payoff. (ii) Voluntarily outputting 0 or _\u22a5_ can yield a payoff at most 0, whereas\nLemma 3.4 guarantees that following the algorithm yields payoff at least 0. Hence, no\nstrictly profitable deviation exists.\n\n12\n\nTherefore, we have shown that for every history _h_ with _i \u2208_ _P_ ( _h_ ), the prescribed strategy for\n_i_ based on _hi_ = proj _i_ ( _h_ ) gives maximum expected utility possible from _h_ when all other node\nare following the algorithm from _h_, which proves the theorem.\n\nWe have shown that Algorithm 1 forms a Belief-Independent Sequential Equilibrium. To\ncomplete the proof of Theorem 3.2, we now assume that all nodes follow the algorithm without\ndeviation and, under this honest execution, we analyze the simplified version of the algorithm\n(with deviation-handling logic removed) and proceed to prove its correctness, termination, and\nnonzero inclusion probability.\n\n**3.2** **Strategy Algorithm under No Deviations**\n\nSince we have established in Theorem 3.5 that Strategy Algorithm 1 constitutes a BeliefIndependent Sequential Equilibrium, no node has a unilateral incentive to deviate. When no\nnode deviates from the Strategy Algorithm 1, its execution is equivalent to running Algorithm 2,\nwhich is simply Strategy Algorithm 1 with the deviation handling logic removed.\n\n**Algorithm 2:** RPS based MIS strategy algorithm for node _i_ without deviations\n\n**1 Initialization**\n\n**2** Initialize node _i_ as undecided;\n\n**3** `UndecidedNeighbors` _\u2190_ _N_ ( _i_ );\n\n**4 while** _true_ **do**\n\n```\n   /* Round 1: Play RPS with Undecided Neighbors */\n```"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a game-theoretic equilibrium where each node's optimal strategy is to follow the protocol, regardless of its beliefs about others' actions. This is enforced through an RPS-like probabilistic game for tie-breaking and an explicit 'BeenCheated' flag for detecting and punishing rule violations. The proof explores various states (cases) to demonstrate that any deviation, whether overt or covert, yields an outcome no better than following the prescribed algorithm, often leading to a maximum payoff of zero for the deviator.\n\n**Explanation:** This section rigorously proves that Algorithm 1 establishes a 'Belief-Independent Sequential Equilibrium'. This means, akin to a stable Nash Equilibrium but extended across sequential decisions, that at any decision point, a node's best response is always to follow the algorithm, *even if* it doesn't know what other nodes are thinking or planning. The strategy is robust because deviations are either immediately punished by neighbors (who set a 'BeenCheated' flag, effectively limiting future gains to zero, much like an error state in a program), or they are inconsequential (like trying to rig a truly random Rock-Paper-Scissors game, which doesn't improve win probability). Since no node can unilaterally improve its outcome by deviating, the system naturally converges to all nodes executing the protocol faithfully, which simplifies its operation to a less complex 'deviation-handling-logic-removed' version (Algorithm 2)."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**2.1** **Reasoning and Reinforcement Learning**\n\n**Reasoning LLMs** . Large Language Models (LLMs) have\nrecently shown remarkable performance in complex reasoning domains such as mathematics, logic, and programming.\n\n20K\n\n15K\n\n10K\n\n2\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-2.png)\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|\n|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|\n|Target Model<br><br><br>|||\u2460|\u2460|\u2460|\u2460|\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-1.png)\n\n|Open<br>s1|AI-o1|\n|---|---|\n|||\n|||\n|||\n\n**Figure 3. Test-time scaling of reasoning models** . (a) Performance of OpenAI-o1 [40] and Stanford s1-32B [38] on the\nAIME Competition-level Math Benchmark [34]. (b) Example\nof self-reflection correcting an error within the reasoning.\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||Vanil<br>Spec|la Dec.<br>. Dec.|\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|\n|ndidate response|ndidate response|ndidate response|ndidate response|\n\n|Col1|Pha Dse c1 o: dR ino gllout<br>e<br>ReM spo od ne sl<br>es<br>R1<br>\ud83d\udd25<br>Model R2<br>\u2026<br>Rn|P Rh ea ss pe n2 s: I n Pf re er fe iln linc ge<br>o e<br>\u2744<br>Ref Model<br>\ud83d\udd25<br>Model<br>R Pe ow lia cr yd|Col4|Col5|Ph Mas oe e3 : T pr da ain teing<br>d l U<br>KL<br>Diverge nce Update<br>\ud83d\udd25<br>FL uo nss Model<br>c|\n|---|---|---|---|---|---|\n||R1<br>R2<br>\u2026<br>Rn<br>Model<br>Responses<br>Model<br>\ud83d\udd25<br>**Phase 1: Rollout**<br>_Decoding_|||||\n|Prompt<br>(Question)|Prompt<br>(Question)|||||\n|Prompt<br>(Question)|Prompt<br>(Question)||Reward<br>Policy|Reward<br>Policy|Reward<br>Policy|\n|Prompt<br>(Question)|Prompt<br>(Question)|||||\n\n**Figure 4.** Overview of the GRPO [51] RL training process.\n\nPowerful models such as OpenAI-o1 [40] and DeepSeekR1 [9] achieve impressive accuracy on challenging reasoning\nbenchmarks, including competition-level math and coding\nchallenges. A key factor in their success is _test-time scaling_\n\n[32, 62], an inference paradigm that enhances accuracy by\naffording models more generation time to explore complex\nreasoning paths. These reasoning LLMs typically feature:\n(1) _Long Chain-of-Thought_, generating extended intermediate reasoning steps before reaching a final answer; (2) _Self-_\n_Reflection_, the capacity to evaluate, refine, and correct their\nown reasoning during inference to improve accuracy. As\nillustrated in Figure 3 (a), allowing extended generation time\nenables these models to explore deeper and wider thinking\ntraces [6], thereby enhancing accuracy without additional\ntraining costs. More importantly, unlike traditional LLMs,\nthese reasoning models can automatically revisit their generated responses and exhibit self-reflection capabilities (e.g.,\n\" _wait_ \" in Figure 3 (b) reasoning trace), which are typically\nacquired during their RL training stage [9] and are key to\nperformance enhancements.\n**Reinforcement Learning for Reasoning** . Recently, RL algorithm variants such as Group Relative Policy Optimization\n(GRPO) [51] have proven their success in training reasoning LLMs. Unlike standard Policy Optimization (PPO) [50],\nwhich relies on an extensive critic model, GRPO employs a\ngroup-based baseline estimation to streamline the optimization process, significantly reducing training overhead while\npreserving the robustness of policy updates [58].\n\n**Figure 5. Overview of Speculative Decoding.** (a & b)\nComparison between Vanilla and Speculative Decoding. (c)\nSpeculative decoding achieves peak compute throughput\n(TFLOPS) at significantly smaller batch sizes (gray arrow).\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-3.png)\n\nFigure 4 illustrates a single training step in GRPO, which\ncomprises three main stages: (1) _**Rollout Stage**_, the target\nmodel generates multiple candidate responses for each input\nprompt; (2) _**Inference Stage**_, the generated responses are\nprocessed by both the _target model_ (the model undergoing\nRL training) and a fixed _reference model_ (the initial target\nmodel, i.e., RL step=0). This processing yields logits used\nto compute a KL divergence penalty [49], which serves to\nconstrain model updates, ensuring stability and preventing\nexcessive deviation from the reference model. Concurrently\nwithin this stage, a reward is calculated with a _rule-based_\npolicy regarding response characteristics (e.g., correctness),\nrather than relying on a separate value model; (3) _**Training**_\n_**Stage**_, a loss function is constructed using the reward value\nand KL divergence. The target model\u2019s weights are then\nupdated according to this loss.\n\n**2.2** **Speculative Decoding for Efficient Reasoning RL**\n\nAs mentioned in \u00a71, the long-tail rollout stage in reasoning\nRL frequently becomes a performance bottleneck. Consequently, tailored system optimizations for decoding acceleration are essential to improve throughput and resource efficiency. To this end, we identify speculative decoding [5, 22]\nas a key approach well-suited to tackle these challenges.\n**Why Speculative Decoding** . Among numerous methods accelerating LLM decoding, speculative decoding (SD) appears\nparticularly advantageous for the reasoning RL scenario. Its\nprimary benefit lies in its _lossless_ nature, mathematically ensuring the output distribution remains identical to that of\nthe original target model. This fidelity is paramount in reasoning tasks where the correctness and logical coherence of\ngenerated steps are critical for effective reinforcement learning. It directly tackles the throughput bottleneck identified\nin the long-tail rollout stage by speeding up generation, enhancing sample efficiency without compromising the crucial\naccuracy needed for reliable reasoning RL training.\n\n3\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-3-0.png)\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|||\n||Spot<br>Drafter<br>Training|\n|||\n|||\n|||\n\n**Figure 6.** Overview of TLT architecture and workflow.\n\n**Mechanism of Speculative Decoding** . In speculative decoding (Figure 5 (b)), a lightweight draft model rapidly generates a sequence of candidate tokens. These candidates are\nthen efficiently verified in parallel by the much larger target model in a single forward pass. The system accepts the\ndrafted sequence up to the first token that mismatches the\ntarget model\u2019s prediction, also keeping the single correct\ntoken that the target model generated at that position. As\nshown in the roofline analysis in Figure 5 (c), this process improves throughput by shifting the typically memory-bound\nautoregressive generation towards a more compute-bound\noperation, more effectively saturating the GPU resources.\n**Challenges in Reasoning RL** . Despite its effectiveness in\nalleviating the memory-bound issue and enhancing decoding\nthroughput, adapting existing speculative decoding methods\nto the context of RL training is fundamentally non-trivial.\nWe identify three key challenges:\n**C1. Evolving Target Model** . Unlike standard inference\nscenarios where models are fixed, RL training involves continuous target model updates. This constant evolution renders the draft model used in SD progressively \"stale\", diminishing the acceptance rate of speculated tokens and significantly undermining SD\u2019s effectiveness.\n**C2. Draft Model Training Costs** . Achieving high SD\nefficiency often requires dedicated draft models (e.g., singledecoder-layer models like Eagle [26], HASS [67]), rather than\narbitrary smaller models. Training a specialized drafter for\nthe target model introduces substantial additional cost.\n**C3. Fluctuating Batch Sizes** . As shown in Figure 5 (c),\nSD is typically optimized for small batch sizes. In contrast,\nRL rollouts often involve dynamically varying generation\nbatch sizes. Applying SD efficiently in this scenario is challenging, as performance can degrade with larger batches if\nnot managed properly, impacting overall throughput.\n\nTo address these challenges, TLT leverages the unique\ncharacteristics of the reasoning RL training process. Specifically, we introduce the Adaptive Drafter (\u00a74) to mitigate\nperformance degradation from dynamic model weights ( **C1** ),\nutilizing spare GPU resources for efficient draft model updates and thereby removing training overhead ( **C2** ). Furthermore, we design a specialized scheduling strategy (\u00a75)\nwithin the reasoning RL system to effectively manage the\nchallenges posed by varying batch sizes ( **C3** )."}, {"role": "assistant", "content": "**Mechanism:** Reasoning LLMs use an iterative inference process akin to a program executing a series of chained functions, where each step builds upon the previous one. This 'chain-of-thought' generation is coupled with 'self-reflection,' which is like an internal `assert` statement or a `try-catch` block: the model evaluates its own intermediate outputs and can backtrack or correct them. Reinforcement Learning (RL) trains these models by having them 'rollout' multiple candidate solutions (exploring a search space, similar to generating multiple paths in a decision tree). Instead of a complex value-function critic (as in PPO), GRPO simplifies this by using 'group-based baseline estimation' and a 'rule-based policy' for rewards. This is like using a simpler heuristic function and direct comparison within a batch of generated outcomes rather than a sophisticated learned reward predictor. The core mechanism of Speculative Decoding (SD) addresses the bottleneck of autoregressive generation, which is memory-bound (waiting for data fetches). SD introduces a smaller, faster 'draft model' that quickly predicts a sequence of `N` future tokens. The larger, more accurate 'target model' then verifies these `N` tokens in a *single parallel forward pass*. This parallel verification is significantly faster than sequential token generation. The system accepts the longest prefix of tokens where the draft and target models agree. If a mismatch occurs at token `k`, tokens `1` to `k-1` are accepted, and the target model's prediction for `k` is taken, then the process restarts. This effectively shifts the computational profile from many small, sequential memory operations to fewer, larger, parallel compute operations, thus increasing throughput.\n\n**Explanation:** The efficiency challenge in training reasoning Large Language Models (LLMs) comes from two main areas: the models' inherent multi-step reasoning processes and the training method itself. Reasoning in LLMs is like a program iteratively solving a problem; it generates a series of logical steps (chain-of-thought) and has an internal feedback loop (self-reflection) to correct errors, similar to unit tests during development. This process makes inference slow because each token depends on the previous one. Training these models with Reinforcement Learning (RL) involves generating many possible solutions (rollouts) and then evaluating them. Standard RL methods often use a complex 'critic' to estimate the value of states, which adds significant computational overhead. This paper uses GRPO, which simplifies this by using simpler, rule-based reward functions and group-based comparisons, reducing the need for a separate, expensive critic network during training. The primary bottleneck, however, is the 'rollout' phase\u2014generating these candidate solutions. This is where Speculative Decoding (SD) comes in. Autoregressive generation (token-by-token) is inefficient because it often waits for data to be fetched from memory. SD speeds this up by using a small, fast 'draft model' to predict multiple tokens ahead of time, like a look-ahead buffer. The main, powerful 'target model' then checks all these predicted tokens *simultaneously* in one go. This means instead of doing many small computations one after another, it does one big, efficient batch computation. If the draft model guessed correctly, many tokens are accepted at once. If it made a mistake, the system only discards the incorrect part and restarts from there, ensuring the final output is identical to what the target model would have produced normally. This 'lossless' property is crucial for RL because it doesn't distort the policy being learned. The challenges lie in the fact that the target model is constantly changing during RL training (making the draft model quickly outdated), the cost of training a good draft model, and managing varying batch sizes which can undermine SD's efficiency."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ \u2265 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ **then**\n\n**55** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_ _ _\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ ;\n\n**56** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ + + ;\n\n**57** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ = _\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc52_ ;"}, {"role": "assistant", "content": "**Mechanism:** This snippet defines the core logic for advancing a 'round' in a network congestion control algorithm, likely BBR. A 'round' is conceptually a single round-trip time (RTT) cycle. The mechanism determines if enough data has been acknowledged as delivered to signify the completion of one such RTT period.\n\n**Explanation:** At its heart, this is a simple conditional check, much like an `if` statement in programming. It compares the current cumulative `_packet.delivered_` count (how many bytes have been successfully acknowledged by the receiver) against a stored threshold, `_BBR.next_round_delivered_`. This threshold represents the cumulative delivery count that marked the *start* of the current network round. If the current delivered count meets or exceeds this threshold, it means all the data that was 'in flight' at the beginning of this round has likely been delivered and acknowledged. Consequently, we update `_BBR.next_round_delivered_` to the *current* total `_BBR.delivered_` to define the start of the *next* round, increment a `_BBR.round_count_` (a simple counter), and set a boolean flag `_BBR.round_start_` to `true`, indicating that the algorithm should now consider itself in a new RTT measurement cycle."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**23** _\ud835\udc3e_ \u2190\u2212 0\n\n**24** _\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b_ _ _\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_\n\n**25** _\ud835\udc4e\ud835\udc50\ud835\udc58_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 1\n\n**26** _\ud835\udc4a\ud835\udc61\ud835\udc50\ud835\udc5d_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_\n\n**27** _\ud835\udc61_ \u2190\u2212 _\ud835\udc61\ud835\udc50\ud835\udc5d_ _ _\ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ + _\ud835\udc51\ud835\udc40\ud835\udc56\ud835\udc5b_ \u2212 _\ud835\udc52\ud835\udc5d\ud835\udc5c\ud835\udc50\u210e_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_\n\n**28** _\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61_ \u2190\u2212 _\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b_ _ _\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61_ + _\ud835\udc36_ ( _\ud835\udc61_ \u2212 _\ud835\udc3e_ ) [3]"}, {"role": "assistant", "content": "**Mechanism:** This snippet initializes a set of state variables and then computes a future 'target' value. The mechanism is a linear projection: it captures a baseline state (`origin_point` from `cwnd`), establishes a relative time reference (`t`), and then calculates a future state (`target`) by adding a growth factor (`C`) multiplied by the elapsed time from that baseline. `K` being zero simplifies the time component to just `t`.\n\n**Explanation:** Think of `cwnd` as a counter for how much data you can send. This code first takes a snapshot of that counter (`origin_point` and `Wtcp`). It also sets up a simple counter for acknowledgments (`ack_cnt`). The most interesting part is how `t` is calculated: it's a normalized timestamp, giving us an elapsed time since some reference point. Then, `target` is computed. This isn't just a fixed goal; it's a dynamic target. It's saying, 'From where we are right now (`origin_point`), we want to be `C` units further along for every unit of time `t` that passes.' So, it's a simple predictive model, essentially a linear function `y = mx + b` where `origin_point` is `b`, `C` is `m`, and `t` is `x`."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n|0|1|0|0|\n|---|---|---|---|\n|**1**<br>**4**<br>**2**<br>**3**<br>|**1**<br>**4**<br>**2**<br>**3**<br>|**1**<br>**4**<br>**2**<br>**3**<br>|**1**<br>**4**<br>**2**<br>**3**<br>|\n\n_The same procedure applies to \ud835\udc63_ 2 _and \ud835\udc63_ 3 _. For \ud835\udc63_ 2 _, since both edges_\n( _\ud835\udc63_ 2 _, \ud835\udc63_ 4) _and_ ( _\ud835\udc63_ 4 _, \ud835\udc63_ 1) _appear in both trees and lie on the path from_\n_\ud835\udc63_ 2 _to the root. Thus,_ vol_sum[2] _is influenced by both the update_\n_for_ ( _\ud835\udc63_ 2 _, \ud835\udc63_ 4) _and the earlier update for_ ( _\ud835\udc63_ 4 _, \ud835\udc63_ 1) _. In contrast, the path_\n_from \ud835\udc63_ 3 _to the root in \ud835\udf0f_ _does not include_ ( _\ud835\udc63_ 2 _, \ud835\udc63_ 4) _. Therefore, before DFS_\n_backtracks from \ud835\udc63_ 2 _, we must remove its contribution (third step), to_\n_ensure the correctness of query_ vol_sum[3] _in the fourth step._\n\nTheorem 3.8 (Time Complexity of Algorithm 1). _The time_\n_complexity of Algorithm 1 is_\n\n_\ud835\udc42_ [\ufffd] _\ud835\udf14_     - [\ufffd] Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc5f_ ) [\u2212][1] + _\ud835\udc5b_ min(\u0394 _,_ log _\ud835\udc5b_ ) [\ufffd\ufffd] _._\n\nProof. The time complexity of Wilson Algorithm for generating\na UST is _\ud835\udc42_ [\ufffd] Tr [\ufffd] ( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc5f_ ) [\u2212][1][\ufffd\ufffd], where _\ud835\udc43\ud835\udc5f_ is the transition probability\nmatrix with its _\ud835\udc5f_ -th column and row removed. Calculating the\nvolume of each subtree requires _\ud835\udc42_ ( _\ud835\udc5b_ ) time. For the DFS function,\ntraversing all nodes takes _\ud835\udc42_ ( _\ud835\udc5b_ ) time. For each node, updating and\nquerying the vol_sum incurs an additional _\ud835\udc42_ (log _\ud835\udc5b_ ) cost, due to\nthe properties of the Binary Indexed Tree. Consequently, the time\ncomplexity of each iteration is _\ud835\udc42_ ( _\ud835\udc5b_ log _\ud835\udc5b_ ).\nHowever, if the graph has a small diameter \u0394 such that \u0394 _<_\nlog _\ud835\udc5b_, the computation of vol_sum can be limited to within \u0394 steps\nfrom each node to the root, effectively reducing the complexity\nto _\ud835\udc42_ ( _\ud835\udc5b_ \u0394). Therefore, we use _\ud835\udc42_ ( _\ud835\udc5b_ - min(\u0394 _,_ log _\ud835\udc5b_ )) to capture both\nscenarios. Multiplying by the number of samples _\ud835\udc47_, the overall time\ncomplexity of the algorithm is as stated in the theorem. \n\nTheorem 3.9 (Error Bound of Algorithm 1). _If the sample size_\n\n8 _\ud835\udc5a_ [2] \u0394 _\ud835\udc3a_ [2] [log][(][2][/] _[\ud835\udc5d]_ _[\ud835\udc53]_ [)]\n_satisfies \ud835\udf14_ \u2265 _\ud835\udc5b_ [2] _\ud835\udf00_ [2] _, then Algorithm 1 outputs an estimate_ \u02dc _\ud835\udf05_\n\n_such that_ | _\ud835\udf05_ \u02dc \u2212 _\ud835\udf05_ | \u2264 _\ud835\udf00\ud835\udf05_ _with probability at least_ 1 \u2212 _\ud835\udc5d_ _\ud835\udc53_ _._\n\nProof. For each sampled tree _\ud835\udf0f_, the number of 2-forests mapped\nby _\ud835\udf0f_ 0 for a node _\ud835\udc62_ is bounded by the distance from _\ud835\udc62_ to the root _\ud835\udc5f_ .\nIf we construct _\ud835\udf0f_ 0 such that its depth is minimized, this distance is\nat most \u0394, the diameter of the graph. Additionally, for each forest,\nthe volume vol( _\ud835\udc47_ 1) is bounded by 2 _\ud835\udc5a_ . Consequently, _\ud835\udc53_ ( _\ud835\udf0f_ ) can be\nbounded as _\ud835\udc53_ ( _\ud835\udf0f_ ) \u2264 [\ufffd] _\ud835\udc62_ _[\ud835\udc51]_ [(] _[\ud835\udc62]_ [) \u00b7][ 2] _[\ud835\udc5a]_ [\u0394][ \u2264] [4] _[\ud835\udc5a]_ [2][\u0394] _[.]_\n\nApplying Hoeffding\u2019s inequality [18], we derive the following\nbound on the probability of deviation:\n\nThis completes the proof. \n\nBy combining Theorem 3.8 and Theorem 3.9, we conclude that\n\n\u0394 [2]\nTTF can compute KC in _\ud835\udc42_ \ufffd _\ud835\udf16_ [2] [(] _[\ud835\udf19]_ [+] _[ \ud835\udc5b]_ [min][(][log] _[\ud835\udc5b,]_ [ \u0394][))] \ufffd time to achieve\n\na relative error _\ud835\udf16_, where _\ud835\udf19_ = Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc5f_ ) [\u2212][1] is the time required for\nUST sampling. Our experiments indicates that time complexity is\nnear-linear in practice. Algorithm 1 details the optimized estimation in _\ud835\udc42_ ( _\ud835\udc5b_ log _\ud835\udc5b_ ) time. For low-diameter graphs, a naive _\ud835\udc42_ ( _\ud835\udc5b_ \u0394)\nimplementation can also be used, which matches the computational\ncost of SpanTree [29]. As shown in Section 5, our method consistently outperforms SpanTree across all tested graphs, validating\nthe effectiveness of the _\ud835\udc42_ ( _\ud835\udc5b_ log _\ud835\udc5b_ ) design over the _\ud835\udc42_ ( _\ud835\udc5b_ \u0394) baseline\nin real-world datasets.\n\n**Discussion.** Compared to prior SOTA methods, our approach\noffers stronger theoretical guarantees, particularly over LERWbased methods. Although ForestMC [51] provides an error bound,\nit requires _\ud835\udc42_ ( _\ud835\udf16_ [\u2212][2] \u0394 [2] _\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65_ [2][\u0394] _[\ud835\udf19]_ [log][3] _[ \ud835\udc5b]_ [)][ samples to achieve a relative error]\n_\ud835\udf16_, where the factor _\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65_ [2][\u0394] [is impractical for most real-world datasets.]\nFor instance, the diameter of DBLP used in our experiments is 21,\nand its maximum degree is 343, which results in an astronomical\nsample size of _\ud835\udc42_ ( _\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65_ [2][\u0394] [)][ =] _[ \ud835\udc42]_ [(][343][42][) \u2248] [10][106][, rendering the bound]\nmeaningless. The fundamental reason LERW-based methods lack\nstrong theoretical guarantees lies in the high variance of LERWs.\nConsider a line graph: if a random walk starts at one endpoint and\nterminates upon reaching the other, the number of steps ranges\nfrom at least _\ud835\udc5b_ \u2212 1 to potentially infinity. This makes it challenging\nto establish tight bounds for arbitrary graphs, and performance\nbecomes highly dependent on the graph structure. In contrast, our\nbound depends on the graph diameter, which is typically small in\nreal-world networks, as demonstrated in our experiments.\nWe identify two closely related works [10, 29]. Chung and Zeng [10]\nrepresent entries of the Laplacian pseudoinverse and normalized\nLaplacian pseudoinverse using rooted 2-forests, which further leads\n\n\u2265 _\ud835\udf00\ud835\udf05_\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n\ufffd\n\n\u2265 _\ud835\udf00_ - _\ud835\udc5b_\n\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\n\nPr\n\n1\n\n2 _\ud835\udc5a\ud835\udc47_\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc47_\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc56_ ) \u2212 _\ud835\udf05_\n\n_\ud835\udc56_ =1\n\n_\ud835\udc47_\n\u2211\ufe01\n\n\u2264 Pr\n\n1\n\n2 _\ud835\udc5a\ud835\udc47_\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc47_\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc56_ ) \u2212 _\ud835\udf05_\n\n_\ud835\udc56_ =1\n\n\u2264 2 exp \u2212 [2] _[\ud835\udf00]_ [2] _[\ud835\udc5b]_ [2] _[\ud835\udc47]_\n\ufffd (4 _\ud835\udc5a_ \u0394) [2]\n\n\ufffd\n\n2 _\ud835\udf00_ [2] _\ud835\udc5b_ [2]     - 8 _\ud835\udc5a_ [2] \u0394 [2] log( _\ud835\udc5d_ [2]\n\u2264 2 exp [\ufffd] \ufffd\ufffd\u2212 16 _\ud835\udc5a_ [2] \u0394 [2] - _\ud835\udf00_ [2] _\ud835\udc5b_ [2]\n\n\u2264 2 exp [\ufffd] \ufffd\ufffd\u2212 2 _\ud835\udf00_ [2] _\ud835\udc5b_ 16 [2] - _\ud835\udc5a_ 8 _\ud835\udc5a_ [2] \u0394 [2][2] \u0394\u00b7 [2] _\ud835\udf00_ log [2] _\ud835\udc5b_ [2] ( _\ud835\udc5d_ [2] _\ud835\udc53_ [)] \ufffd\ufffd\ufffd\n\n\u2264 _\ud835\udc5d_ _\ud835\udc53_ _._\n\n_\ud835\udc5d_ _\ud835\udc53_ [)]\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-8-0.png)\n\nto a series of forest-based formulas, including KC. Our Theorem 3.1\nis derived as a direct extension of their Corollary 1.7. Liao et al. [29]\npropose the SpanTree method, which to the best of our knowledge\nis the only existing approach that also estimates the Kemeny constant via UST sampling, and its computational framework is similar\nto our TTF. We next highlight the distinctions and innovations of\nour approach compared with these two works.\n\n**Comparison to [10].** Corollary 1.7 in [10] provides a clean and\nelegant forest formula for KC, offering a combinatorial interpretation in terms of enumerating 2-forests. However, its practical\nutility is limited, since uniformly sampling 2-forests is computationally intractable on large-scale graphs. Unlike spanning trees, a\n2-forest requires an exact partition of the node set into two disjoint\nconnected components, and a naive strategy that first partitions\nthe nodes and then generates a spanning tree in each part incurs\nexponential overhead with _\ud835\udc42_ (2 [|] _[\ud835\udc49]_ [|] ) possible partitions. To the best\nof our knowledge, no efficient method for direct sampling of 2forests currently exists, which prevents this formula from being\nused in practice. This limitation actually motivates our work: by\nintroducing a new formula for KC (Eq. (4)) together with the path\nmapping technique, we make the theoretical result of [10] practically computable and enable efficient estimation through sampling.\n\n**Comparison to** SpanTree **[29].** While our method also leverages\nUSTs, similar to SpanTree proposed in [29], the foundational principles differ significantly. SpanTree estimates KC based on Eq. (3)\nvia an electrical interpretation, aggregating current flow across\nsampled USTs. In contrast, our approach is built upon the forest\nformulas of KC (Eq. (4)) and introduces a novel path mapping technique to convert trees into 2-forests, which further allows us to\nincorporate the optimization of BIT to enhance computational efficiency. Experimental results confirm that our method dominates\nSpanTree across all tested scenarios.\n\n**4** KC **COMPUTATION ON DYNAMIC GRAPHS**\n\nIn this section, we focus on the problem of calculating KC on dynamic graphs. Our algorithms are improved based on the static\nalgorithm presented in Section 3, where we store needed information for those sampled spanning trees and maintain the correctness\nof samples to efficiently update KC. In Section 4.1, we first present a\nbasic maintenance method, and in Section 4.2, we introduce an improved method that more efficiently maintains samples. Theoretical\nanalysis of both algorithms is proved respectively.\n\n**4.1** **Basic Samples Maintenance (BSM)**\n\nAfter a new edge is added or removed from the graph, the spanning\ntrees of the updated graph _\ud835\udc3a_ [\u2032] largely overlap with those of the\noriginal graph, with the only difference being the additional (or\nmissing) spanning trees that involve the updated edge _\ud835\udc52_, assuming\nboth graphs remain connected. Hence, a natural idea is to adapt the\nsampled USTs by supplementing or removing the spanning trees\nthat differ between _\ud835\udc3a_ and _\ud835\udc3a_ [\u2032] . The resulting set of \u201cvalid\u201d spanning\ntrees can then be directly used to estimate the KC.\n\n**Insertion Case.** We first consider the scenario where a new edge\n_\ud835\udc52_ = ( _\ud835\udc62, \ud835\udc63_ ) is inserted into the graph. Let \u0393 denote the spanning tree\nset of the original graph _\ud835\udc3a_, and let \u0393 [\u2032] represent the corresponding\n\n**Figure 5: Illustration of Basic Samples Maintenance for Edge**\n**Insertion**\n\nset of the updated graph _\ud835\udc3a_ [\u2032] after inserting the edge _\ud835\udc52_ . The set \u0393 [\u2032]\n\ncomprises all spanning trees in \u0393, along with additional spanning\ntrees that include the newly inserted edge _\ud835\udc52_ . We define the subset\nof all these new spanning trees in \u0393 [\u2032] that contain _\ud835\udc52_ as \u0393 _\ud835\udc52_ [\u2032][.]\nA well-established fact states that the proportion of spanning\ntrees containing a given edge is equal to the effective resistance\nof that edge, i.e., |\u0393 _\ud835\udc52_ [\u2032][|/|][\u0393][\u2032][|][ =] _[ \ud835\udc45]_ [(] _[\ud835\udc52]_ [)][ [][17][,][ 33][]. Here,] _[ \ud835\udc45]_ [(] _[\ud835\udc52]_ [)][ denotes the]\neffective resistance between nodes _\ud835\udc62_ and _\ud835\udc63_ for edge _\ud835\udc52_ = ( _\ud835\udc62, \ud835\udc63_ ) in _\ud835\udc3a_ [\u2032] .\nBefore the update, we already have some sampled spanning trees\nthat are uniformly distributed in \u0393. Our goal is to incorporate the\nadditional spanning trees in \u0393 _\ud835\udc52_ [\u2032] [that appear after the update. Using]\nthe relationship described above, we can determine the expected\nproportion of these new spanning trees in the samples for _\ud835\udc3a_ [\u2032] . By\nreplacing part of the old samples with these added USTs, we obtain\nan unbiased estimation on the updated graph.\n\nExample 5. _Fig. 5 illustrates the process of maintaining the UST-_\n_samples when an edge is inserted. When the edge_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 2) _is added_\n_to \ud835\udc3a_ 1 _, we first compute its effective resistance in the updated graph_\n_\ud835\udc3a_ 2 _, which is \ud835\udc45_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 2) = [2] 3 _[. According to the properties of effective]_\n\n_resistance, in the new graph, the edge_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 2) _should appear in ap-_\n_proximately_ [2] 3 _[of the USTs. To update the sample set accordingly, we]_\n\n_randomly select_ [2] 3 _[of the USTs from the original samples][ \ud835\udc46]_ [1] _[ and replace]_\n\n_them with the same number of new USTs that include_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 2) _. This_\n_process is performed using a modified version of Wilson\u2019s algorithm._\n_Finally, we utilize the updated samples \ud835\udc46_ 2 _to estimate the_ KC _of \ud835\udc3a_ 2 _._\n\nTheorem 4.1 (Correctness of BSM for Insertion Case).\n\nE _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393\u2032 ) [ _\ud835\udc53_ ( _\ud835\udf0f_ )] =(1 \u2212 _\ud835\udc45_ ( _\ud835\udc52_ ))E _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) [ _\ud835\udc53_ ( _\ud835\udf0f_ )]\n\n+ _\ud835\udc45_ ( _\ud835\udc52_ )E _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 _\ud835\udc52_ [\u2032] ) [ _\ud835\udc53_ ( _\ud835\udf0f_ )] _,_ (7)\n\n_where \ud835\udc48_ (\u0393) _represents the uniform distribution over the set_ \u0393 _, i.e.,_\n1\n_\ud835\udf0f_ _is sampled with probability_ |\u0393 | _[for all][ \ud835\udf0f]_ [\u2208] [\u0393] _[. The function][ \ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]\n_corresponds to the calculation performed on the given tree \ud835\udf0f. In this_\n_paper, it refers to the definition in Theorem 3.6._\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-9-0.png)\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n**Algorithm 2:** BSM\n\n**Input:** A graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ), root _\ud835\udc5f_, an updated edge (u, v), original\nsample set _\ud835\udc46_\n**Output:** \u02dc _\ud835\udf05_ [\u2032] as an updated estimation, updated sample set _\ud835\udc46_ [\u2032]\n\n**1** \u02dc _\ud835\udf05_ [\u2032] \u2190 _\ud835\udf05_ \u02dc ( _\ud835\udc3a_ ), _\ud835\udc46_ [\u2032] \u2190 _\ud835\udc46_ ;\n\n**2 if** _Update is_ Ins ( _\ud835\udc62, \ud835\udc63_ ) **then**\n\n**3** Calculate _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ) in _\ud835\udc3a_ \u222a( _\ud835\udc62, \ud835\udc63_ );\n\n**4** Randomly select \u2308 _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ) \u00b7 | _\ud835\udc46_ |\u2309 trees from _\ud835\udc46_ ;"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism for static graphs involves two key ideas: First, transforming the problem of sampling hard-to-sample 2-forests into sampling Uniform Spanning Trees (USTs), which is computationally tractable via Wilson's algorithm. This is achieved through a novel 'path mapping technique' that implicitly derives 2-forest properties from USTs. Second, efficiently computing path-related sums (vol_sum) within each sampled UST using a Binary Indexed Tree (BIT) during a Depth-First Search (DFS). The BIT acts like an efficient prefix sum array, allowing O(log n) updates and queries, which significantly speeds up the aggregation process compared to repeated linear scans. For dynamic graphs, the Basic Samples Maintenance (BSM) mechanism exploits the property that the proportion of USTs containing a new edge is equal to its effective resistance. When an edge `e` is added, instead of resampling all `T` trees, the algorithm calculates `R(e)` and probabilistically replaces `R(e) * T` existing samples with `R(e) * T` new samples that are specifically generated to include `e`. This rebalances the sample distribution to reflect the new graph without a full recalculation, preserving an unbiased estimation.\n\n**Explanation:** Think of it this way: the Kemeny Constant needs us to count specific structures called '2-forests', which are incredibly difficult to directly sample. The genius here is to bypass that direct sampling. We can efficiently sample 'spanning trees' using a random walk process (Wilson's algorithm, like a pointer following random links). The trick is a 'path mapping' that takes properties from these easy-to-get spanning trees and mathematically 'maps' them to the properties of the hard-to-get 2-forests. So, we're not sampling 2-forests directly; we're cleverly inferring their contribution from something we *can* sample. To make calculations on each sampled tree super fast, they use a Binary Indexed Tree (BIT). Imagine an array where each index stores a sum, but it's structured so that updating a single value or querying a range sum takes only logarithmic time \u2013 much faster than iterating through the whole array. This is critical when traversing the tree (like a recursive loop) to aggregate values along paths. When the graph changes, say a new edge is added, we don't throw away all our previous samples. Instead, we use a fundamental result from graph theory: the 'effective resistance' of the new edge tells us exactly what fraction of all possible spanning trees in the *new* graph will contain this edge. So, if the resistance is 2/3, we know 2/3 of our samples should now include this edge. We then randomly 'swap out' 2/3 of our old samples and replace them with new ones that *do* contain the new edge. This keeps our sample set statistically representative without a full, expensive resample, akin to partially updating a cache when relevant data changes."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this work, we introduce a new task in the area of _Dataset Distillation_ : learning a tiny set of synthetic\nimages designed to train **linear probes** on top of **pre-trained self-supervised vision models** . Our\nproposed solution, _Linear Gradient Matching_, optimizes a meta gradient objective to ensure that our\nsynthetic images induce training updates similar to those obtained from the real data. Quantitatively,\nour method outperforms all baselines, enabling, for example, a DINO-v2 linear probe to reach 75%\ntest accuracy on ImageNet-1k while only having ever seen **one labeled image** per class.\n\nWe also showcase the importance of secondary aspects of our Linear Gradient Matching method, such\nas the pyramid representation and differentiable augmentations, and highlight their importance in\nlearning highly efficacious distilled datasets. Furthermore, we evaluate our method on challenging finegrained datasets and show that it out-performs the real-image baselines by an even larger margin than\non the standard ImageNet benchmarks. Lastly, our method yields several interesting interpretability\nresults, such as giving insights into how these pre-trained models \u201csee,\u201d predicting how well different\nmodels align, or elucidating a model\u2019s ability to generalize beyond its training distribution.\n\nWe hope our work brings to light the interesting set of problems posed by this new task and inspires\n[others to continue in this area. Code and distilled datasets can be found on our project page.](http://georgecazenavette.github.io/linear-gm)\n\n10\n\n**Acknowledgments**\n\nThis work was supported by the National Science Foundation under Grant No. 2211259, by the\nSingapore DSTA under DST00OECI20300823 (New Representations for Vision, 3D Self-Supervised\nLearning for Label-Efficient Vision), by the Intelligence Advanced Research Projects Activity\n(IARPA) via Department of Interior/Interior Business Center (DOI/IBC) under 140D0423C0075, by\nONR MURI grant #033697-00007, by the Amazon Science Hub, by the MIT-Google Program for\nComputing Innovation, by Sony Interactive Entertainment, and by a 2025 MIT ORCD Seed Fund\nCompute Grant.\n\n11\n\n**References**\n\n[[1] Adam McLean. The surrealism website. https://surrealism.website/. 16](https://surrealism.website/)\n\n[2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski,\nG. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong,\nM. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang,\nY. Lu, C. K. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, S. Zhang,\nM. Suo, P. Tillet, X. Zhao, E. Wang, K. Zhou, R. Zou, X. Wang, A. Mathews, W. Wen, G. Chanan, P. Wu,\nand S. Chintala. Pytorch 2: Faster machine learning through dynamic python bytecode transformation and\ngraph compilation. In _Proceedings of the 29th ACM International Conference on Architectural Support for_\n_Programming Languages and Operating Systems, Volume 2_, ASPLOS \u201924, New York, NY, USA, 2024.\nAssociation for Computing Machinery. 15, 16\n\n[3] L. Bossard, M. Guillaumin, and L. Van Gool. Food-101 \u2013 mining discriminative components with random\nforests. In _ECCV_, 2014. 16, 17, 36\n\n[4] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke,\nJ. VanderPlas, S. Wanderman-Milne, and Q. Zhang. JAX: composable transformations of Python+NumPy\nprograms, 2018. 15\n\n[5] M. Caron, H. Touvron, I. Misra, H. J\u00e9gou, J. Mairal, P. Bojanowski, and A. Joulin. Emerging properties in\nself-supervised vision transformers. In _ICCV_, 2021. 3, 10, 16\n\n[6] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros, and J.-Y. Zhu. Dataset distillation by matching training\ntrajectories. In _CVPR_, 2022. 1, 2, 3, 4, 6\n\n[7] G. Cazenavette, T. Wang, A. Torralba, A. A. Efros, and J.-Y. Zhu. Generalizing dataset distillation via\ndeep generative prior. In _CVPR_, 2023. 1, 3, 4, 6, 7\n\n[8] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual\nrepresentations. In _ICML_, 2020. 3\n\n[9] X. Chen, H. Fan, R. Girshick, and K. He. Improved baselines with momentum contrastive learning. _arXiv_\n_preprint arXiv:2003.04297_, 2020.\n\n[10] X. Chen, S. Xie, and K. He. An empirical study of training self-supervised vision transformers. In _ICCV_,\n2021. 3, 5, 8, 17, 21\n\n[11] J. Cui, R. Wang, S. Si, and C.-J. Hsieh. Scaling up dataset distillation to imagenet-1k with constant memory.\nIn _ICML_, 2023. 1, 3\n\n[12] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image\ndatabase. In _CVPR_, 2009. 2, 5, 8, 10, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31\n\n[13] Y. Fang, Q. Sun, X. Wang, T. Huang, X. Wang, and Y. Cao. Eva-02: A visual representation for neon\ngenesis. _Image and Vision Computing_, 2024. 3, 16, 20\n\n[14] Y. Fang, W. Wang, B. Xie, Q. Sun, L. Wu, X. Wang, T. Huang, X. Wang, and Y. Cao. Eva: Exploring the\nlimits of masked visual representation learning at scale. In _CVPR_, 2023. 3, 5, 17\n\n[15] S. Fort and J. Whitaker. Direct ascent synthesis: Revealing hidden generative capabilities in discriminative\nmodels. _arXiv preprint arXiv:2502.07753_, 2025. 4\n\n[16] Z. Guo, K. Wang, G. Cazenavette, H. LI, K. Zhang, and Y. You. Towards lossless dataset distillation via\ndifficulty-aligned trajectory matching. In _ICLR_, 2024. 1, 3\n\n[17] K. He, X. Chen, S. Xie, Y. Li, P. Doll\u00e1r, and R. Girshick. Masked autoencoders are scalable vision learners.\nIn _CVPR_, 2022. 3\n\n[18] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation\nlearning. In _CVPR_, 2020. 3\n\n[[19] Hugging Face. Hugging Face: The AI community building the future. https://huggingface.co,](https://huggingface.co)\n2016. 16\n\n[20] M. Huh, B. Cheung, T. Wang, and P. Isola. Position: The platonic representation hypothesis. In _ICML_,\n2024. 2, 3, 9\n\n12\n\n[21] A. Khosla, N. Jayadevaprakash, B. Yao, and L. Fei-Fei. Novel dataset for fine-grained image categorization.\nIn _CVPR_, 2011. 5, 9, 16, 17, 32\n\n[22] D. Kingma and J. Ba. Adam: A method for stochastic optimization. In _ICLR_, 2015. 15\n\n[23] P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L.\nPhillips, I. Gao, T. Lee, E. David, I. Stavness, W. Guo, B. A. Earnshaw, I. S. Haque, S. Beery, J. Leskovec,\nA. Kundaje, E. Pierson, S. Levine, C. Finn, and P. Liang. WILDS: A benchmark of in-the-wild distribution\nshifts. In _ICML_, 2021. 16\n\n[24] P. Liao, X. Li, X. Liu, and K. Keutzer. The artbench dataset: Benchmarking generative models with\nartworks. _arXiv preprint arXiv:2206.11404_, 2022. 5, 10, 16\n\n[25] D. Liu, J. Gu, H. Cao, C. Trinitis, and M. Schulz. Dataset distillation by automatic training trajectories. In\n_ECCV_, 2024. 1\n\n[26] A. Lynch, G. J.-S. Dovonon, J. Kaddour, and R. Silva. Spawrious: A benchmark for fine control of spurious\ncorrelation biases, 2023. 5, 8, 16\n\n[27] T. Nguyen, Z. Chen, and J. Lee. Dataset meta-learning from kernel ridge-regression. In _ICLR_, 2020. 1, 2\n\n[28] T. Nguyen, R. Novak, L. Xiao, and J. Lee. Dataset distillation with infinitely wide convolutional networks.\nIn _NeurIPS_, 2021. 1\n\n[29] M.-E. Nilsback and A. Zisserman. Automated flower classification over a large number of classes. In\n_Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP)_,\nKolkata, India, 2008. 16, 17, 35\n\n[30] C. Olah, A. Mordvintsev, and L. Schubert. Feature visualization. _Distill_, 2017.\nhttps://distill.pub/2017/feature-visualization. 4, 7\n\n[31] M. Oquab, T. Darcet, T. Moutakanni, H. V. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. HAZIZA,\nF. Massa, A. El-Nouby, M. Assran, N. Ballas, W. Galuba, R. Howes, P.-Y. Huang, S.-W. Li, I. Misra,\nM. Rabbat, V. Sharma, G. Synnaeve, H. Xu, H. Jegou, J. Mairal, P. Labatut, A. Joulin, and P. Bojanowski.\nDINOv2: Learning robust visual features without supervision. _TMLR_, 2024. 3, 5, 6, 8, 16, 17, 19, 22, 23,\n24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36\n\n[32] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and\nA. Lerer. Automatic differentiation in pytorch. In _ICLR Workshop_, 2017. 3\n\n[33] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,\nL. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,\nL. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance deep learning library. In\n_NeurIPS_ . 2019. 15, 16\n\n[34] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin,\nJ. Clark, et al. Learning transferable visual models from natural language supervision. In _ICML_, 2021. 3,\n5, 16, 17, 18\n\n[[35] J. Resig. Ukiyo-e search. https://ukiyo-e.org/, 2012. 16](https://ukiyo-e.org/)\n\n[36] E. Riba, D. Mishkin, D. Ponsa, E. Rublee, and G. Bradski. Kornia: an open source differentiable computer\nvision library for pytorch. In _WACV_, 2020. 16\n\n[37] C. Ryali, Y.-T. Hu, D. Bolya, C. Wei, H. Fan, P.-Y. Huang, V. Aggarwal, A. Chowdhury, O. Poursaeed,\nJ. Hoffman, et al. Hiera: A hierarchical vision transformer without the bells-and-whistles. In _ICML_, 2023.\n3\n\n[38] S. Sagawa, P. W. Koh*, T. B. Hashimoto, and P. Liang. Distributionally robust neural networks. In _ICLR_,\n2020. 5, 8, 16\n\n[39] S. Sagawa, P. W. Koh, T. Lee, I. Gao, S. M. Xie, K. Shen, A. Kumar, W. Hu, M. Yasunaga, H. Marklund,\nS. Beery, E. David, I. Stavness, W. Guo, J. Leskovec, K. Saenko, T. Hashimoto, S. Levine, C. Finn, and\nP. Liang. Extending the wilds benchmark for unsupervised adaptation. In _ICLR_, 2022. 16\n\n[40] B. Son, Y. Oh, D. Baek, and B. Ham. Fyi: Flip your images for dataset distillation. In _ECCV_, 2024. 1, 3\n\n[41] Q. Sun, Y. Fang, L. Wu, X. Wang, and Y. Cao. Eva-clip: Improved training techniques for clip at scale.\n_arXiv preprint arXiv:2303.15389_, 2023. 3\n\n13\n\n[42] Y. Tian, D. Krishnan, and P. Isola. Contrastive multiview coding. In _ECCV_, 2020. 5, 16, 17, 18, 19, 20, 21\n\n[[43] TorchVision maintainers and contributors. Torchvision: Pytorch\u2019s computer vision library. https:](https://github.com/pytorch/vision)\n[//github.com/pytorch/vision, 2016. 16](https://github.com/pytorch/vision)\n\n[44] M. Tschannen, A. Gritsenko, X. Wang, M. F. Naeem, I. Alabdulmohsin, N. Parthasarathy, T. Evans,\nL. Beyer, Y. Xia, B. Mustafa, et al. Siglip 2: Multilingual vision-language encoders with improved semantic\nunderstanding, localization, and dense features. _arXiv preprint arXiv:2502.14786_, 2025. 3\n\n[45] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. Caltech-UCSD birds 200. Technical Report\nCNS-TR-2011-001, California Institute of Technology, 2011. 5, 9, 17, 33, 34\n\n[46] K. Wang, B. Zhao, X. Peng, Z. Zhu, S. Yang, S. Wang, G. Huang, H. Bilen, X. Wang, and Y. You. Cafe:\nLearning to condense dataset by aligning features. _CVPR_, 2022. 1\n\n[47] T. Wang, J.-Y. Zhu, A. Torralba, and A. A. Efros. Dataset distillation. _arXiv preprint arXiv:1811.10959_,\n2018. 1, 2\n\n[[48] R. Wightman. Pytorch image models. https://huggingface.co/timm, 2019. 16](https://huggingface.co/timm)\n\n[[49] WikiArt.org. WikiArt Visual Art Encyclopedia. https://www.wikiart.org/, 2024. 16](https://www.wikiart.org/)\n\n[50] Z. Yin and Z. Shen. Dataset distillation via curriculum data synthesis in large data era. 2024. 2\n\n[51] Z. Yin, E. Xing, and Z. Shen. Squeeze, recover and relabel: Dataset condensation at imagenet scale from a\nnew perspective. In _NeurIPS_, 2023. 1, 2\n\n[52] X. Zhai, B. Mustafa, A. Kolesnikov, and L. Beyer. Sigmoid loss for language image pre-training. In _ICCV_,\n2023. 3\n\n[53] B. Zhao and H. Bilen. Dataset condensation with differentiable siamese augmentation. In _ICML_, 2021. 1,\n\n4, 7\n\n[54] B. Zhao and H. Bilen. Dataset condensation with distribution matching. _WACV_, 2023. 1, 2\n\n[55] B. Zhao, K. R. Mopuri, and H. Bilen. Dataset condensation with gradient matching. In _ICLR_, 2020. 2, 3, 4\n\n[56] Y. Zhou, E. Nezhadarya, and J. Ba. Dataset distillation using neural feature regression. _NeurIPS_, 2022. 1, 2\n\n14\n\n**Appendix**\n\nTo begin the appendix, we first speak on our method\u2019s limitations, broader impact, and compute\nbudget. In the following sections, we include more information that was omitted from the main\npaper due to space constraints. In Section A, we provide a more detailed description of our method\u2019s\nimplementation details. In Section C, we include visualizations of complete distilled datasets.\n\n**Limitations** Our method is largely limited by memory and data loading. For example, we were limited in our ImageNet-1k experiments to only using 3 rounds of augmentations per batch due to a data\nloading bottleneck. We hope to eventually develop a method that does not require the loading of thousands of real images per step. Additionally, due to the bi-level optimization, we are limited to using Pytorch\u2019s [2, 33] nn.DistributedParallel, rather than nn.DistributedDataParallel,\nwhich causes significant slowdowns due to our very large batch sizes. Using a different automatic\ndifferentiation framework, such as Jax [4], might alleviate this issue, but this would also require\nporting all our self-supervised backbones to the new framework.\n\n**Broader Impact** While our method quantitatively out-performs the real image baselines, the\nbroader impacts likely lie in the introduction of this new task as well as the resulting images acting as\nan interpretability tool. As shown in the paper, the distilled images offer insights into things such as\nmodel alignment and how different networks see the world in varying ways.\n\nFurthermore, the ultimate goal of dataset distillation is the reduction of training time, which equates\nto less energy spent. A linear probe trained on our distilled datasets can be trained to convergence in\njust a few minutes while training on the full dataset can take up to an entire day.\n\n**Compute Budget** We used a variety of GPUs for this work depending on what was available on\nthe shared cluster. Specifically, we used a combination of H200, A100, L40s, Ada6000, and 4090\nGPUs. Distilling ImageNet-100 with the default settings takes about 3 hours using 1 H200 GPU, and\nImageNet-1k takes about 12 hours using 4 H200 GPUs.\n\n**A** **Implementation Details**\n\nIn this section, we provide a more detailed explanation of our methodological and experimental\nimplementation details.\n\n**A.1** **Distillation**\n\n[We implement our method in Pytorch [2, 33], which has a unique license to which we comply.](https://github.com/pytorch/pytorch/tree/main?tab=License-1-ov-file#readme)\n\nWe optimize our pyramid representations using Adam [22] with a learning rate of 0.002.\n\nWe distill for 5000 iterations and add a new level to the pyramids every 200 iterations until we reach\nthe maximum resolution (256).\n\nEach level of the pyramid is initialized with _N_ (0 _,_ 1) normalized by the current number of levels in\nthe pyramid. When a new level is added, the existing levels are appropriately re-normalized.\n\nAt each distillation iteration, we first sample a new linear classifier consisting of a weight matrix _W_\nand bias vector **b** using the default initialization for Pytorch\u2019s nn.Linear. For simplicity, we omit\nthe bias in the main paper.\n\nThen, we reconstruct the synthetic images from their pyramid representations using the following\nequation (copied from the main paper for convenience):\n\n\ufffd\n\n_X_ = [1]\n\n[1]\n\n2 [+ 1]\n\n2 [tanh]\n\n(4)\n\n\ufffd\ufffd _r\u2208\u03c1_\n\nresize256( _Pr_ )\n\n_r\u2208\u03c1_\n\nThe synthetic images are then augmented several (10 by default) _different_ (not sequential) times and\nconcatenated together to form the full synthetic batch. We obtain our synthetic loss ( _\u2113_ syn) by passing\nthis batch through the feature extractor _\u03d5_ and linear classifier ( _W,_ **b** ) and then compute the gradient of\nthe synthetic loss with respect to the linear classifier (and bias). These gradients are then vectorized.\n\n15\n\nFor our real batch, we sample a number of real images equal to the length of the _full_ synthetic batch\n(i.e., after the different augmentations and concatenation) and augment them once (since the batch\nsize already matches that of the full synthetic batch). We then get the real loss and gradients via the\nsame procedure. The meta loss is then calculated as the cosine distance between the real and synthetic\nvectorized gradients.\n\n**A.2** **Augmentation**\n\nFor our differentiable augmentations, we use a custom re-implementation of torchvision transforms that run on GPU and support different random transforms for each element in a batch. We initially used the Kornia [36] implementations, but found that they cause CPU bottlenecks with very large\nbatch sizes. We use RandomHorizontalFlip with default parameters, RandomResizedCrop\nwith size=(224, 224), and RandomGaussianNoise with std=0.2.\n\n**A.3** **Evaluation**\n\n**Linear Probes.** To evaluate a given distilled dataset (or selected coreset for the real baselines) on\na given target model, we first randomly initialize a new linear classifier. We then train the linear\nclassifier for 1000 epochs with a batch size of 100. We use an Adam optimizer with a learning rate of\n0 _._ 001 _/_ 256 (taken from the DINO-v1 [5] evaluation protocol) along with a cosine decay learning rate\nschedule. We stop training early if the test accuracy has not improved over the last 50 epochs. For the\ntraining set, we perform the same set of augmentations as during distillation (horizontal flip, random\nresized crop, and Gaussian noise). The output of the random resized crop is of size 224 _\u00d7_ 224. For the\ntest set, we resize the shortest side to 256 and then do a center crop of 224 _\u00d7_ 224.\n\n**Nearest Neighbors.** For our nearest neighbor evaluation, we first find the train set embeddings\nby resizing the shortest side of each test image to 256, taking a 224 _\u00d7_ 224 center crop, and passing\nthrough the feature extractor. We then do the same for the test set and find the training embedding\nclosest to each test embedding (by cosine distance) and report the class of said neighbor. We only do\none nearest neighbor since we distill down to one image per class.\n\n**A.4** **Datasets**\n\nFor ImageNet [12] and ImageNet [42], we build on the Torchvision [43] implementation as part of the\n[Pytorch [2, 33] ecosystem. ImageNet has a unique non-commercial license, to which we have agreed.](https://image-net.org/download.php)\n\n[Spawrious [26] is taken from the paper\u2019s official GitHub repository and uses a CC0-1.0 license.](https://github.com/aengusl/spawrious)\n\nWaterbirds [38] is taken from the WILDS [23, 39] benchmark. Both the Waterbirds and WILDS\nrepositories use an MIT license.\n\n[Stanford Dogs [21] is taken from the project website. It presumably uses the same license as](http://vision.stanford.edu/aditya86/ImageNetDogs)\nImageNet [12].\n\n[Caltech-UCSD-200-2011 is taken from the project website. No license is given.](http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz)\n\n[ArtBench [24] is taken from the paper\u2019s GitHub repository. The repository itself uses an MIT license.](https://github.com/liaopeiyuan/artbench)\nThe data is sourced from WikiArt [49], Ukiyo-e Search [35], and The Surrealism Website [1], all of\nwhich have Fair Use licenses.\n\nFlowers-102 [29] is taken from Torchvision. No license is given.\n\nFood-101 [3] is taken from Torchvision. No license is given.\n\n**A.5** **Models**\n\n[For CLIP [34], we use the official GitHub repository which has an MIT license.](https://github.com/openai/CLIP)\n\n[For DINO-v1 [5], we use the official GitHub repository which has an Apache-2.0 license.](https://github.com/facebookresearch/dino)\n\n[For DINO-v2 [31], we use the official GitHub repository which has an Apache-2.0 license.](https://github.com/facebookresearch/dinov2)\n\n[For EVA-02 [13], we use the Pytorch Image Models [48] implementation hosted on Hugging Face [19]](https://huggingface.co/timm/eva02_base_patch14_224.mim_in22k)\nwhich has an MIT license.\n\n16\n\nTrain Set Flowers-102 Food-101\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **79.5** _\u00b1_ **1.2 99.6** _\u00b1_ **0.0 97.8** _\u00b1_ **0.1 56.4** _\u00b1_ **3.1 83.3** _\u00b1_ **1.1 78.7** _\u00b1_ **1.6 83.7** _\u00b1_ **0.3 83.9** _\u00b1_ **0.2 31.6** _\u00b1_ **3.2 69.5** _\u00b1_ **1.3**\nNeighbors 69.4 _\u00b1_ 0.8 99.4 _\u00b1_ 0.2 90.8 _\u00b1_ 0.2 48.6 _\u00b1_ 1.8 77.0 _\u00b1_ 0.7 58.8 _\u00b1_ 1.3 73.8 _\u00b1_ 0.4 71.5 _\u00b1_ 0.3 25.2 _\u00b1_ 1.3 57.3 _\u00b1_ 0.8\nCentroids 77.5 _\u00b1_ 0.7 99.4 _\u00b1_ 0.1 95.6 _\u00b1_ 0.3 48.2 _\u00b1_ 2.6 80.2 _\u00b1_ 0.9 74.1 _\u00b1_ 0.6 75.6 _\u00b1_ 0.1 76.4 _\u00b1_ 0.4 22.7 _\u00b1_ 2.0 62.2 _\u00b1_ 0.8\n\nRandom 67.9 _\u00b1_ 1.1 98.8 _\u00b1_ 0.4 91.0 _\u00b1_ 0.8 36.8 _\u00b1_ 2.2 73.6 _\u00b1_ 1.1 48.5 _\u00b1_ 1.0 52.8 _\u00b1_ 1.9 49.9 _\u00b1_ 0.6 13.5 _\u00b1_ 1.7 41.2 _\u00b1_ 1.3\n\nFull Dataset 93.4 _\u00b1_ 0.1 99.7 _\u00b1_ 0.0 98.9 _\u00b1_ 0.0 82.2 _\u00b1_ 0.1 93.5 _\u00b1_ 0.1 91.9 _\u00b1_ 0.0 92.7 _\u00b1_ 0.1 92.0 _\u00b1_ 0.0 78.3 _\u00b1_ 0.0 88.7 _\u00b1_ 0.0\n\nTable B.1: **Additional Datasets:** Distilling Flowers-102 [29] and Food-101 [3] show similar results; our distilled\ndataset consistently out-perform the real-image baselines.\n\n[For MoCo-v3 [10], we use the official GitHub repository which has a Creative Commons Attribution-](https://github.com/facebookresearch/moco-v3)\nNonCommercial 4.0 International Public License.\n\n**B** **Additional Results**\n\nIn Table B.1, we include results for Flowers-102 [29] and Food-102 [3]. We see results following the\nsame trends as the rest of the paper; the distilled datasets out-perform the real-image baselines across\nthe board.\n\n**C** **Visualizing Full Datasets**\n\nIn Figures C.1, C.2, C.3, and C.4 we present the entirety of ImageNet-100 [42] distilled with\nCLIP [34], DINO-v2 [31], EVA-02 [14], and MoCo-v3 [10] respectively. In Figures C.5\u2013C.14, we\nshow ImageNet-1k [12] distilled with DINO-v2 and omit the other models for the sake of brevity\n(and ink).\n\nWe also include Stanford Dogs [21] (Figure C.15), CUB-200-2011 [45] (Figures C.16 and C.17),\nFlowers-102 [29] (Figure C.18), and Food-101 [3] (Figure C.19) distilled with DINO-v2 and once\nagain omit the other models. All distilled datasets, including those not inculded here, can be viewed\n[on our project page.](http://georgecazenavette.github.io/linear-gm)\n\n17\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-17-0.png)\n\nFigure C.1: ImageNet-100 [42] distilled using CLIP [34]\n\n18\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-18-0.png)\n\nFigure C.2: ImageNet-100 [42] distilled using DINO-v2 [31]\n\n19\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-19-0.png)\n\nFigure C.3: ImageNet-100 [42] distilled using EVA-02 [13]\n\n20\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-20-0.png)\n\nFigure C.4: ImageNet-100 [42] distilled using MoCo-v3 [10]\n\n21\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-21-0.png)\n\nFigure C.5: ImageNet-1k [12] distilled with DINO-v2 [31] classes [0-99]\n\n22\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-22-0.png)\n\nFigure C.6: ImageNet-1k [12] distilled with DINO-v2 [31] classes [100-199]\n\n23\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-23-0.png)\n\nFigure C.7: ImageNet-1k [12] distilled with DINO-v2 [31] classes [200-299]\n\n24\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-24-0.png)\n\nFigure C.8: ImageNet-1k [12] distilled with DINO-v2 [31] classes [300-399]\n\n25\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-25-0.png)\n\nFigure C.9: ImageNet-1k [12] distilled with DINO-v2 [31] classes [400-499]\n\n26\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-26-0.png)\n\nFigure C.10: ImageNet-1k [12] distilled with DINO-v2 [31] classes [500-599]\n\n27\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-27-0.png)\n\nFigure C.11: ImageNet-1k [12] distilled with DINO-v2 [31] classes [600-699]\n\n28\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-28-0.png)\n\nFigure C.12: ImageNet-1k [12] distilled with DINO-v2 [31] classes [700-799]\n\n29\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-29-0.png)\n\nFigure C.13: ImageNet-1k [12] distilled with DINO-v2 [31] classes [800-899]\n\n30\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-30-0.png)\n\nFigure C.14: ImageNet-1k [12] distilled with DINO-v2 [31] classes [900-999]\n\n31\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-31-0.png)\n\nFigure C.15: Stanford Dogs [21] distilled using DINO-v2 [31]\n\n32\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-32-0.png)\n\nFigure C.16: CUB-200-2011 [45] distilled using DINO-v2 [31] classes [0-99]\n\n33\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-33-0.png)\n\nFigure C.17: CUB-200-2011 [45] distilled using DINO-v2 [31] classes [100-200]\n\n34\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-34-0.png)\n\nFigure C.18: Flowers-102 [29] distilled using DINO-v2 [31]\n\n35\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-35-0.png)\n\nFigure C.19: Food-101 [3] distilled using DINO-v2 [31]\n\n36"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism, 'Linear Gradient Matching', involves a bi-level optimization where the synthetic images are generated to mimic the training behavior of real images. A pre-trained feature extractor (a fixed function `phi(x)` that produces a vector representation of an image `x`) is used. A simple linear classifier (`W*phi(x) + b`) is trained on top of these features. The method works by continuously adjusting the pixel values (or their pyramid representation) of the synthetic images such that the 'direction of learning' (the gradient `dLoss/dW` for the linear classifier) derived from these synthetic images is as close as possible to the 'direction of learning' derived from a batch of real images. This matching is quantified using cosine distance between the vectorized gradients. Differentiable augmentations allow the synthetic images to be robust to common transformations, as the augmentation process itself is 'gradient-aware'.\n\n**Explanation:** Think of the pre-trained vision model as a highly efficient `feature_extractor` function that takes an image and returns a compact `vector` of its key characteristics. We then attach a very simple `linear_classifier` function (essentially a matrix multiplication and addition) to these feature vectors to make a final prediction. The goal is to make a tiny set of fake images that, when used to train this `linear_classifier`, cause the classifier's internal `weights` to update in the exact same direction and magnitude as if it were trained on a massive set of real images. This is achieved by continuously generating and refining the fake images. In each step, we calculate how the `linear_classifier`'s weights *should* change if it saw real images (the 'real gradient'), and then we calculate how they *would* change if it saw our fake images (the 'synthetic gradient'). The `optimizer` then tweaks the fake images so that their 'synthetic gradient' perfectly matches the 'real gradient'. This process is like having a `loop` that iteratively refines the fake images until they are perfect teaching proxies for the real data, even enabling the synthetic images to encode robustness to common `image_transformations` because those transformations are integrated into the gradient calculation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section provides details on the methodology followed which laid the groundwork for conducting the experiments.\n\nIt initially presents the multipath test-environment\u2019s topology, the tools used, and the configuration applied; it then\n\ncontinues with the experimentation campaign\u2019s design and the set of experiments executed. Finally, it delineates the\n\nmain performance metrics against which the packet scheduling and congestion control algorithms have been assessed.\n\n**3.1** **Multipath Environment Setup & Configuration**\n\nFig. 4. Multipath test environment topology\n\n_Mininet topology._ Figure 4 depicts our Mininet-based multipath topology comprising two multipath-capable hosts (A,\n\nB) which are connected via an intermediate router (R). More specifically, source host (i.e., Host A) is connected to R\n\nover two disjoint paths (L1, L2), and R is then connected to the destination host (i.e., Host B) over path L3. The MPTCP\n\nconnection established between Hosts A and B, comprises two subflows (SF1, SF2), that is, one subflow is established\n\nover paths L1, L3 (i.e., SF1), and another subflow over paths L2, L3 (i.e., SF2). The two subflows are partially disjoint,\n\nsince both are eventually traversing the same path L3 towards destination host (Host B).\n\nThe aforementioned topology has been selected based on the _hybrid-access_ network as depicted within [3] (Fig.2: _Hy-_\n\n_brid Access Network_ ), in an attempt to have a simple and explainable configuration that guarantees reliable performance\n\nresults for the algorithms under study. In our hybrid-access topology, subflows SF1 (over paths L1, L3) and SF2 (over\n\npaths L2, L3) are established between the two interfaces available in Host A (e.g., eth0, eth1) and the single interface in\n\nHost B (e.g., eth0).\n\n_HW/OS details._ The above-mentioned multipath topology is emulated using Mininet v2.3.0 [21, 25, 62] and Python\n\nv3.10 [77]. The Mininet environment is instantiated on top of Linux 22.04.5 LTS (Jammy Jellyfish) OS [7] [10], which is in\n\nturn running on a Dell OptiPlex-7050 server, equipped with an Intel Core i5-6500 CPU @ 3.20 GHz, 16 GiB RAM, and\n\n238 GiB SSD. To be able to execute Mininet with MPTCP capabilities, we loaded the out-of-tree MPTCP linux kernel\n\nv5.4.230 [38] (MPTCP v0.96 [18]) which we have further customized in order to be able to collect kernel parameter\n\nvalues, such as the MPTCP out-of-order queue [19, 20]. Another reason that forced us patch the legacy MPTCP kernel,\n\nwas the fact that we needed to port all packet scheduling and congestion control algorithms to the same MPTCP version\n\n10Noteworthy here is the fact that the deployment and execution of Mininet in a VM produced weird results, non-deterministic under identical test\niterations, which forced us to execute Mininet directly on the OS.\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-21-0.png)\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 23\n\n(v0.96) for compatibility and fair comparison purposes; to this end, some modifications were also required to the legacy\n\nkernel code basis.\n\n_MPTCP version._ The MPTCPv0 linux kernel version, which we selected to use for our experiments, has been recently\n\nfrozen. MPTCPv1 efforts are ongoing to develop MPTCP in compliance with the latest IETF RFC [36]. The reason\n\nbehind selecting the older MPCTP linux kernel version was the fact that the out-of-tree version (MPCTPv0 [22]) was\n\nmature enough and already included most of the MPTCP packet scheduling and congestion control schemes as loadable\n\nkernel modules. The new upstream version (MPTCPv1 [23]) facilitates algorithms\u2019 development in user- rather than\n\nkernel-space (e.g., via eBPF); thus, MPTCPv1 lacked the needed algorithms, offering only the default minRTT packet\n\nscheduler.\n\n_MPTCP configuration._ Delving into TCP configuration details, MPTCP can be enabled via the mptcp_enabled parame\n\nter, and the desired packet scheduling and congestion control algorithm can be adjusted using the mptcp_scheduler and\n\ntcp_congestion_control linux parameters, respectively [6]. In our setup, the MPTCP default path manager, _fullmesh_\n\nhas been used throughout the entire experimentation campaign (configured via mptcp_path_manager parameter). In\n\naddition, we have disabled mptcp_checksum since our Mininet experimentation platform operates in a controlled envi\n\nronment, absent any middleboxes which could potentially alter the payload [36]. Furthermore, tcp_no_metrics_save\n\nhas been enabled, flushing metrics from the route cache once a connection is closed [43, 75]. Except these, all the\n\nremaining TCP parameters maintained their default values, allowing a performance evaluation as closest to a normal\n\nsetup as possible; thus, TCP autotuning, and selective acknowledgement (SACK) features have been kept enabled.\n\nNoteworthy here is the fact that autotuning has been experimentally associated with MPTCP performance degradation\n\nand lower aggregation benefit, as well as with slower congestion window increase within slow-start phase, when\n\ncompared to the equivalent manual setup to the same maximum buffer limit [72]; however, we have selected to keep it\n\nenabled in our environment to emulate the default setup\u2019s use case. Another important condition to be considered in\n\nany such multipath performance evaluation scenario, either emulated or real-world, is to guarantee that the end-hosts\n\nare not receive-window limited. This means that the send and receive buffers should be allocated enough memory\n\nso that flow control is not the limiting factor in the experiment, but rather the congestion control algorithm via the\n\ncongestion-window. Thus, it has been suggested that, for MPTCP, the maximum send and receive buffer size be set to a\n\nvalue of 2 \u2217 _\ud835\udc35\ud835\udc37\ud835\udc43_, that is, 2 \u2217 [\ufffd] _[\ud835\udc5b]_ _\ud835\udc56_ =1 _[\ud835\udc4f\ud835\udc64][\ud835\udc56]_ [\u2217] _[\ud835\udc45\ud835\udc47\ud835\udc47][\ud835\udc5a\ud835\udc4e\ud835\udc65]_ [, where] _[ \ud835\udc4f\ud835\udc64][\ud835\udc56]_ [is the bandwidth of subflow] _[ \ud835\udc56]_ [, and] _[ \ud835\udc45\ud835\udc47\ud835\udc47][\ud835\udc5a\ud835\udc4e\ud835\udc65]_ [the highest RTT]\n\nvalue measured across all subflows [1, 72, 79]. The logic behind this formula is that one BDP of memory is required\n\nto keep sending while waiting for a packet sent on the slowest path to be delivered; to keep sending when a path is\n\nused for fast retransmission, another BDP of buffer size is required [79]. In our system, where autotuning has been\n\nenabled, the maximum send and receive buffer size (wmem and rmem, respectively) have been set by default to 16MiB\n\nwhich is considered to be sufficient for our experiments and in accordance with the proposed value of _at least_ 2 \u2217 _\ud835\udc35\ud835\udc37\ud835\udc43_\n\n[1]. Details on the exact bandwidth, delay, and packet loss rate value ranges of each scenario is provided later in this\n\nsection, but for a quick calculation, our experiments consider two subflows with a maximum capacity of 100 Mbps each,\n\nan _\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc5a\ud835\udc4e\ud835\udc65_ of 50ms, and a maximum packet loss rate of 2%; these values require a buffer size of at least 1.25 MiB, which\n\nis covered by the existing autotuning upper limit.\n\n_Loadable modules._ The packet scheduling and congestion control algorithms can be loaded in the linux kernel at\n\nruntime using insmod or modprobe commands, without the need to modify, rebuild, and install a new kernel. As a\n\nresult, some work was initially required to port all algorithms to the common running-kernel basis (i.e., MPTCP v0.96\n\n24 D. Dimopoulos, et al.\n\n[18]). Consequently, we had to modify the legacy code for LLHD packet scheduler [66], and C-MPBBR congestion\n\ncontrol algorithm [55].\n\n_Additional tools._ Concerning the set of tools used to conduct the experiments, we have exploited iperf v2.1.5 to\n\ngenerate traffic between the two Mininet hosts [49, 50], matplotlib v3.10.0 for visualization of the collected results\n\n[45], as well as the tcp_probe linux feature which allowed us to record the MPTCP connection state and retrieve kernel\n\nmetrics during test execution [15, 37].\n\n**3.2** **Traffic methodology**\n\nUsing iperf tool, Host A (i.e., the iperf client) establishes a MPTCP connection with Host B (i.e., the iperf server).\n\nAfterwards, Host A sends traffic over the two subflows (SF1, and SF2) toward Host B, for a predetermined duration\n\nof 30 sec., trying to fill in the available link bandwidth; this type of traffic emulates bulk data transfer between two\n\nhosts. While this method would be considered equivalent to _timed transfers_ (i.e., performance tests measuring the time\n\nneeded to complete a 10MB tranfer between two end nodes), there have been some deviations reported in literature [4].\n\nHowever, in this work we focus on _\"length transfers\"_ [4], leaving \"timed transfer\" verification for future work.\n\n**3.3** **Design of Experimentation Scenarios**\n\nThe main idea behind the design of the experimentation scenarios has been the quest for a universally superior\n\ncongestion control and packet scheduling algorithm combination, which could potentially be suitable for generic use,\n\nregardless of the underlying path conditions. And if the experimentation campaign would not come up with such a\n\ndistinguishable combination, it would still be of interest to identify which packet scheduling and congestion control\n\nalgorithm combination is the most appropriate under specific network conditions.\n\nIn an attempt to assess the various packet scheduling and congestion control algorithm combinations under various\n\npath heterogeneity conditions, the Mininet emulator has been used. Execution in Mininet is performed over the real\n\nprotocol stack instead of a simulated protocol model. Furthermore, each test iteration has been executed using a static\n\nnetwork configuration for the entire test duration (30 sec.), which in addition to the absence of background traffic, made\n\nour simple network setup ideal for assessing the combined use of algorithms, eliminating the effect of other factors on\n\nthe performance outcome. This allowed us to repeat identical experiments and yet expect deterministic results, while\n\nproviding us with the flexibility to modify the underlying path conditions and cover a wide range of path heterogeneity\n\nscenarios.\n\nOur experimentation campaign included scenarios of variable path heterogeneity and severity in terms of capacity,\n\nround-trip delay, and packet loss rate, as well as all possible combinations of the packet scheduling and congestion\n\ncontrol algorithms included in 1 [11] and 2. This has been in accordance with the qualitative and quantitative factors that\n\nshould be considered in such experiments, as mentioned in [72].\n\nThe entire set of experiments is depicted in Table 3.\n\nIn Table 3, SF1 and SF2 traffic characteristics are referred to the underlying Mininet link conditions (L1 and L2,\n\nrespectively) over which the subflows have been established. Link L3 is statically configured to a _\ud835\udc35\ud835\udc4a_ / _\ud835\udc45\ud835\udc47\ud835\udc47_ / _\ud835\udc43\ud835\udc3f\ud835\udc45_\n\nvalue of 2 _\ud835\udc3a\ud835\udc4f\ud835\udc5d\ud835\udc60_ /0 _\ud835\udc5a\ud835\udc60_ /0% across the entire set of experiments. Based on the range of values described in Table 3\n\nwhich determine the underlying path characteristics, we have initially divided our experimentation campaign in five\n\n11ReMP TCP has been excluded from our experiments since, by duplicating packets, it clearly incurs sub-optimal performance in terms of goodput and\noverall flow completion time.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 25\n\nTable 3. Experimentation Scenarios\n\nSubflow Capacity (Mbps) Round-trip delay (ms) Packet loss rate (%)\n\nSF1 [100] [0, 5, 10] [0, 1, 2]\nSF2 [100, 75, 50, 5] [0, 2, 5, 20, 50] [0, 0.05, 0.5, 2]\n\nmajor scenario families: _homogeneous_, _mild_heterogeneity_, _intense_heterogeneity_, _very_intense_heterogeneity_, and finally\n\n_mixed_heterogeneity_ . Each scenario family, is composed of up to seven scenarios, where heterogeneity is assessed over\n\nindividual traffic characteristics (i.e., only bandwidth-induced heterogeneity, while round-trip delay and packet loss\n\nmaintain equal values among the two subflows), as well as over combinations of them. In all scenario families except\n\nthe last one, one subflow (i.e., SF1) maintains static path configuration across all scenarios of the scenario family, while\n\nheterogeneity is induced by degrading path conditions of the second subflow (i.e., SF2 is inferior to SF1); in the scenarios\n\nbelonging to the mixed_heterogeneity scenario family, both subflows experience mixed path characteristics, thus not\n\npermitting any a priori assumption as to which subflow is expected to perform better and how the applied algorithms\n\nwould react (e.g., SF1 is established over a bottleneck link of _\ud835\udc35\ud835\udc4a_ / _\ud835\udc45\ud835\udc47\ud835\udc47_ / _\ud835\udc43\ud835\udc3f\ud835\udc45_ equal to 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /10 _\ud835\udc5a\ud835\udc60_ /0%, while SF2 is\n\nover a 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /2 _\ud835\udc5a\ud835\udc60_ /0 _._ 5%). These five scenario families produced twenty-nine (29) scenarios in total. Each scenario\n\nis executed against all combinations of five selected MPTCP packet schedulers (minRTT, BLEST, ECF, RR [12], LLHD)\n\nand seven congestion control algorithms (LIA, OLIA, BALIA, wVegas, Cubic, BBR, C-MPBBR); for each specific packet\n\nscheduling and congestion control algorithm combination, we execute the same scenario five times, to ensure that the\n\noutcome of each test is not affected by any transient issues. The total number of test iterations is given by the following\n\nformula:\n\n#_ _\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc60_ = (#_ _\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc60_ ) \u2217(#_ _\ud835\udc60\ud835\udc50\u210e\ud835\udc52\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc52\ud835\udc5f\ud835\udc60_ ) \u2217(#_ _\ud835\udc36\ud835\udc36\ud835\udc34\ud835\udc60_ ) \u2217(#_ _\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60_ _ _\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c_ ) (17)\n\nwhich produces 5,075 test instances; as mentioned earlier, each test instance has a duration of 30 sec.\n\n**3.4** **Performance Metrics**\n\nInspired by the work performed in [13], we selected to provide a combined view of the per-subflow goodput, the\n\nper-subflow smoothed RTT (SRTT), the MPTCP out-of-order (OFO) queue size, as well as the per-subflow number of\n\nretransmissions for each packet scheduling algorithm.\n\n_Goodput and Retransmissions._ Our performance evaluation results illustrate, among others, the achieved goodput\n\nwhich is essentially derived by subtracting the protocol overhead (i.e., packet headers) from throughput computation.\n\nWhile iperf tool provides a metric of the achieved goodput, this suffers two limitations: i) iperf tool provides the\n\naggregate goodput achieved over both subflows of the MPTCP connection, while our intention was to depict how each\n\npacket scheduler performs, hence how traffic is actually distributed among the two subflows, and ii) iperf\u2019s goodput\n\nscale is calculated based on divisions by a factor of 1000. For these reasons, we have selected to analyze the per-subflow\n\ngoodput, as well as to retrieve the per-subflow number of retransmissions by capturing and analyzing every single\n\npacket. The python-based pyshark tool [24] has been used for this purpose, allowing us to calculate goodput based on\n\neach individual packet\u2019s payload; our extracted per-subflow goodput scale has been calculated through divisions by\n\na factor of 1024 (e.g., 1 _\ud835\udc3e\ud835\udc56\ud835\udc35_ = 1024 _\ud835\udc4f\ud835\udc56\ud835\udc61\ud835\udc60_ ). For instance, iperf goodput expressed in Mbps using SI units (e.g., KB, MB)\n\n12Round-robin packet scheduling algorithm maintained its default parameter values throughout the entire experimentation trial; that is, the number of\nconsecutive segments sent on a subflow before switching to the other subflow is kept by default to one (num_segments = 1), and the scheduler tries to fill\nin the congestion window (cwnd_limited=true), which means that upon filling up the congestion window, becomes _ack-clocked_ [6].\n\n26 D. Dimopoulos, et al.\n\nwould be calculated by the formula: _\ud835\udc3a\ud835\udc43_ ( _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ ) = ( _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ / _\ud835\udc51\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ ) \u2217 8/(1000 \u2217 1000), while our calculations based\n\non binary units (e.g., KiB, MiB) are given by the formula: _\ud835\udc3a\ud835\udc43_ ( _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ ) = ( _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ / _\ud835\udc51\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ ) \u2217 8/(1024 \u2217 1024), where _\ud835\udc3a\ud835\udc43_\n\nstands for _goodput_, and _duration_ denotes the duration of each test instance (30 sec.). Thus, our goodput results might\n\nbe even more conservative than those iperf produced. _Pyshark_ allows the distinction between subflows via common\n\ntshark filters; this makes the calculation of per-subflow goodput and the respective number of retransmissions easy.\n\n_SRTT and OFO queue._ The SRTT [81] as well as the OFO queue size values have been collected by tracing the\n\nrespective linux kernel parameters. Noteworthy here is mentioning that for as long as the kernel tracing feature has\n\nbeen enabled (that is, for the 30 sec. duration of each test instance\u2019s execution), a huge amount of kernel logs containing\n\nmetrics had been produced; thus, as part of a post-processing step, we randomly sampled the collected metrics in order\n\nto limit, for instance, the out-of-order queue value samples to two per millisecond, that is, 1 _\ud835\udc60\ud835\udc4e\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52_ / 500 _\ud835\udc62\ud835\udc60_ . Part of the\n\ncollected metrics has also been the congestion window value of each subflow; however, we have selected to skip any\n\ncongestion window plots and to focus on basic performance metrics.\n\nBesides providing a direct performance comparison between the packet scheduling algorithms under a specific traffic\n\nscenario and under the presence of a single congestion control algorithm, the main focus of this work has been to\n\nassess the packet scheduling and congestion control algorithms across all traffic scenarios. For this reason, as it will be\n\nexplained in detail within Section 4, a couple of additional assessment metrics have been used, such as the _normalized_\n\n_goodput_ achieved by each packet scheduler across a scenario family; a _score_ definition is also provided within Section 4,\n\nwherever deemed necessary. Finally, despite the fact that our traffic pattern resembles bulk transfer, we considered it\n\nuseful to provide an overview of the per-packet delay which is an important metric in case of interactive applications.\n\nAs such, we calculate the per-packet delay based on the following formulas:\n\ni. we first calculate the number of packets-per-second (pps):\n\n_\ud835\udc5d\ud835\udc5d\ud835\udc60_ = _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ /( _\ud835\udc40\ud835\udc46\ud835\udc46_ \u2217 _\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc51\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ ) (18)\n\nwhere _\ud835\udc40\ud835\udc46\ud835\udc46_ = 1514 _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ and test duration is 30 _\ud835\udc60\ud835\udc52\ud835\udc50._\n\nii. then, the per-packet-delay in milliseconds is given by:\n\n_\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66_ ( _\ud835\udc5a\ud835\udc60_ ) = (1/ _\ud835\udc5d\ud835\udc5d\ud835\udc60_ ) \u2217 1000 (19)\n\nAnother performance metric to be also explained in detail within Section 4, is the _coefficient of variation (CV)_ which is\n\ngiven by _[\ud835\udf0e]_ _\ud835\udf07_ [, and is used when calculating the congestion control algorithm scores as a measurement of the extent of]\n\nvariability in relation to the mean."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is simulating a network environment with controllable, heterogeneous path conditions to systematically test and compare the performance of different Multipath TCP (MPTCP) packet scheduling and congestion control algorithms. This is done by emulating a specific two-subflow topology on a real Linux kernel with MPTCP enabled, collecting detailed per-subflow metrics, and repeating experiments across a wide range of network impairments.\n\n**Explanation:** Think of it like building a miniature, but fully functional, test track in a lab to test different components of a new car engine under various road conditions. The 'network topology' is a simplified track using Mininet, a virtual lab environment for networks. Host A (source) sends data via two distinct 'lanes' (L1, L2) to a 'router' (R), which then connects to Host B (destination) via a single 'highway' (L3). MPTCP allows Host A to split data across both lanes simultaneously, similar to a program having two pointers to different network interfaces. We're running the actual Linux networking stack on a powerful server, not just simulating packets. They even had to patch the Linux kernel (the core operating system) to use an older MPTCP version (v0) and to expose internal 'gauges' (kernel parameters) for detailed metrics, akin to adding custom logging hooks to a core library. The experimentation is a massive set of nested loops: for each type of network condition (e.g., bumpy, slow, fast), for each combination of how packets are sent (scheduler) and how fast the data goes (congestion control), they run the test multiple times. During each test, traffic is generated (iperf acts like a data generator), and metrics are collected (tcp_probe and pyshark are like custom data collection agents, looking at every packet and kernel variable). They don't just look at overall speed; they custom-process data to get per-subflow goodput and retransmissions, which is like looking at individual threads' performance rather than just total CPU usage."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Robust boosting algorithm for bisection** **35**\n8.1 Algorithm and constraint systems . . . . . . . . . . . . . . . . . . . . . . . . 35\n8.2 Feasibility and time complexity . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n8.3 SoS guarantees for robust bisection boosting . . . . . . . . . . . . . . . . . . 38\n8.4 Algorithmic guarantees for robust bisection boosting . . . . . . . . . . . . . 46"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an iterative refinement of the binary search algorithm, fortified against errors. Imagine a standard `binary_search` function where you repeatedly halve a sorted array to find an item. Now, picture that the comparison (`item > middle` or `item < middle`) can sometimes return an incorrect answer due to noise or adversarial interference. 'Boosting' acts as an outer loop that trains multiple 'weak' bisection decision-makers. Each weak learner makes a simple 'left or right' decision. If a decision leads to an error, the boosting mechanism assigns a higher 'weight' or focus to that specific problematic region or data point for the subsequent weak learners. This is akin to a `for` loop where each iteration builds a slightly better 'if-else' logic for bisection, learning from the previous iteration's mistakes. 'Robustness' means this learning and refinement process is designed to succeed even if a significant percentage of those `if-else` comparisons are intentionally faulty. The 'constraint systems' define the legal bounds and valid splitting criteria, similar to input validation or boundary checks in programming. The 'SoS guarantees' are not code, but powerful mathematical proofs confirming that this error-correcting, iterative bisection process will converge to a correct solution even under these challenging robust conditions.\n\n**Explanation:** The core idea is to make the highly efficient `binary_search` algorithm resilient. 'Boosting' is like an iterative refinement process: you have many simple 'guess-and-check' steps (weak learners, similar to basic `if/else` decisions in bisection). Each step tries to narrow down the search. If a step makes a mistake (e.g., misidentifies which half the solution is in due to noisy data), the system learns from it. Subsequent steps are then 'boosted' to pay more attention to those error-prone regions, effectively re-weighting the decision problem. This is similar to a `while` loop that continues until a certain error threshold is met, refining the search boundaries. 'Robustness' means this process works reliably even when a certain percentage of the input data or feedback is deliberately misleading. 'Constraint systems' are the predefined rules or boundaries that define what constitutes a valid 'cut' in the bisection, like data types or range limits. The 'SoS guarantees' are sophisticated mathematical proofs that ensure this error-correcting, iterative bisection will indeed find the correct solution within certain bounds, even under adversarial conditions, providing a strong theoretical underpinning for its reliability."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_j \u2208_ `UndecidedNeighbors` _which broadcasted_ opp( _j_ ) = _i in previous round_\n**do**\n\n**10** Draw a random _c_ log _n_ bit _ri\u2192j \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly at random and broadcast\nsigned message ( `iteration` `number` _, i, ri\u2192j_ ) to all neighbors;\n\n```\n   /* Round 3: Forward Opponent\u2019s random input */\n```\n\n**11** _Ri \u2190{ri\u2192i \u2295_ _r_ opp( _i_ ) _\u2192i}_\nBroadcast message ( `iteration` ~~`n`~~ `umber` _,_ opp( _i_ ) _, r_ opp( _i_ ) _\u2192i_ ) signed by opp( _i_ ) to all\nneighbors\n```\n   /* Round 4: Calculate Ranks of Neighbors */\n```"}, {"role": "assistant", "content": "**Mechanism:** This section outlines a protocol for secure, verifiable random input exchange between paired nodes in a distributed system, essential for decentralized ranking. The mechanism involves nodes generating cryptographically random bit strings, broadcasting them with digital signatures for authenticity, and then combining their own random input with their opponent's using an XOR operation. A critical step is the re-broadcast of the opponent's signed random input to all neighbors, acting as a notarized relay.\n\n**Explanation:** The process ensures fairness and prevents manipulation by leveraging cryptographically secure random numbers and verifiable communication. When node 'i' draws a random `ri\u2192j`, it's like generating a unique, unpredictable nonce. Broadcasting this with a signature (`iteration number, i, ri\u2192j`) ensures all neighbors know 'i' produced that specific random value, similar to a digitally signed transaction. The XOR operation (`Ri \u2190 {ri\u2192i \u2295 ropp(i)\u2192i}`) creates a new, combined random value from both 'i' and its opponent. Because XOR is commutative and difficult to reverse without knowing both inputs, it prevents either party from unilaterally dictating the combined value for the subsequent ranking. The act of 'i' re-broadcasting its opponent's signed `ropp(i)\u2192i` is crucial: it acts as a 'proof of receipt' that 'i' truly received that specific value from `opp(i)`, preventing 'i' from later claiming a different value was sent. This ensures all nodes have a consistent, verifiable view of each paired node's random contribution, which then feeds into the 'Round 4: Calculate Ranks' to establish an unbiased order."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_|Bi,hi_ +1 _|_ = _\u03b3_ **then**\n\n**10** update _hi \u2190_ _hi_ + 1\n\n**11** initialize _Bi,hi_ +1 _\u2190\u2205_ as the new \u201ccharging\u201d batch.\n\n/* consumer _t_ with choice model _\u03d5t_ arrives. */\n\n/* some sold units of products are returned to inventory due to\n\nendogenous shocks (i.e., restocking). */\n\n**12** update normalized inventory levels _{fi,j,t}_ of \u201cready\u201d batches.\n\n**13** solve _St \u2190_ arg max _S\u2208S_ \ufffd\n\n_i\u2208S_ _[r][i]_ [\u03a8(max] _[j][\u2208]_ [[] _[h][i]_ []] _[ f][i,j,t]_ [)] _[ \u00b7][ \u03d5][t]_ [(] _[S,i]_ [)][ with offline assortment oracle.]\n\n**14** offer assortment _St_ to consumer _t_ .\n\n/* suppose consumer _t_ chooses product _i_ _[\u2217]_ . */\n\n**15** allocate an available unit of product _i_ _[\u2217]_ from batch _Bi\u2217,j\u2217_ with _j_ _[\u2217]_ = arg max _j\u2208_ [ _hi_ ] _fi\u2217,j,t_ .\n\n**3.3. Corollaries and Implications of Theorem 1**\n\nBased on Theorem 1, it can be verified that the competitive ratio of the BIB algorithm is asymptotically\n\noptimized by selecting the exponential penalty function \u03a8( _x_ ) = _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_ and _\u03b3_ = \u0398( _[\u221a]_ ~~_c_~~ 0 ~~)~~, which approaches\n\n(1 _\u2212_ [1] _/e_ ) _\u2248_ 63% as _c_ 0 goes to infinity. This bound, which is now obtained in the presence of endogenous and\n\nexogenous shocks, is the asymptotic optimal bound even for the special cases of the online assortment (Gol\n\nrezaei et al., 2014) and the online vertex-weighted b-matching (Karp et al., 1990; Birnbaum and Mathieu,\n\n2008; Aggarwal et al., 2011) without inventory shocks.\n\nIn addition to establishing the asymptotic optimality of the BIB algorithm under the exponential penalty\n\nfunction, the competitive ratio bound for a general concave penalty function \u03a8 in Theorem 1 has three key\n\nimplications. First, when compared with the competitive ratio bound of the vanilla IB algorithm with an\n\narbitrary concave penalty function \u03a8\u2014as proved in Golrezaei et al. (2014) for the special case of online\n\nassortment optimization _without_ inventory shocks\u2014we show that the BIB algorithm achieves the _exact same_\n\nasymptotic competitive ratio as IB for _any_ choice of concave penalty function \u03a8, even in the presence of both\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n10\n\nexogenous and endogenous shocks. [9] This result highlights the robustness and power of inventory-balancing\n\nstyle algorithms in online resource allocation: when properly adapted, they preserve their performance even\n\nunder dynamic inventory environments with endogenous and exogenous shocks. Second, the precise com\n\npetitive ratio bound in Theorem 1 also characterizes the dependence on the initial (finite) inventory levels,\n\noffering a sharper perspective beyond the asymptotic regime potentially useful for practitioners. Lastly, The\n\norem 1 provides a best-of-both-worlds guarantee: it ensures robust performance under arbitrary concave\n\npenalty functions in general settings, while allowing practitioners to leverage application-specific structures\n\nby tailoring the penalty function for potentially stronger guarantees (e.g., Feng and Niazadeh, 2025).\n\n### **4. Competitive Ratio Analysis: Proof of Theorem 1**\n\nAs mentioned earlier in the introduction, our goal is to use the primal\u2013dual analysis to prove Theorem 1. In\n\ncontrast to prior work that employs similar approaches, our analysis faces two main technical challenges:\n\n(i) different units of the same product require distinct dual assignments, since the times at which they are\n\nadded to the inventory due to exogenous shocks may differ; and (ii) the inventory level of an arbitrary\n\nbatch is no longer monotonically decreasing because of both endogenous and exogenous shocks\u2014a property\n\nthat was crucial for the success of prior primal\u2013dual analyses in both the online matching problem and its\n\ngeneralizations to online assortment.\n\n**Overview of the analysis.** To address the challenge (i), we come up with a batch-specified LP revenue\n\nbenchmark that relies on the execution path of the BIB algorithm (Section 4.1), and our primal-dual anal\n\nysis designs a dual construction at the batch level rather than at the product level (Section 4.2). To address\n\nthe challenge (ii), roughly speaking, the dual construction uses a transformed version of inventory levels\n\nof \u201cready\u201d batches using a particular mapping. The mapping is combinatorial and constructing it is rather\n\ninvolved; it uses a chain of techniques to reduce the problem of finding an appropriate inventory mapping for\n\nour purpose to solving a sub-problem called _Interval Assignment Problem (IAP)_ (Lemma 2 and Section 4.3).\n\nGiven the solution to IAP, our final dual construction uses transformed inventory levels and incorporates ran\n\ndomness in a specific fashion to provide a certificate for the approximate optimality of the primal algorithm.\n\n**4.1. Batch-Specified Assortment and LP Revenue Benchmark**\n\nWe first define the revenue benchmark used in analyzing the competitive ratio of the BIB algorithm (Algo\n\nrithm 1). Recall that the BIB algorithm views different units of the same product as separate entities rather\n\nthan identical ones. This distinction is important, as different units may become available at different times\n\ndue to replenishments. Therefore, to make the comparison meaningful, the benchmark should also distin\n\nguish between units of a fixed product. With this motivation, we extend the standard concept of an assortment\n\n9 In Section EC.3, we examine several natural generalizations of the vanilla Inventory Balancing (IB) algorithm that are considerably\nsimpler than BIB. We construct specific instances demonstrating that these generalizations fail to achieve the asymptotic optimal\ncompetitive ratio of 1 _\u2212_ 1 _/e_, even in the special case with only exogenous inventory shocks. In particular, we establish competitive\nratio upper bounds of 0 _._ 552, 0 _._ 53, and 0 _._ 5 for these simple IB variants in Section EC.3.1.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n11\n\n(which is defined over products) to the notion of _batch-specified assortments_ . Building on this, we then intro\n\nduce the _batch-specified LP benchmark_, where both concepts are defined with respect to the product batches\n\ngenerated by the BIB algorithm.\n\n**Batch-specified assortments.** Though all units of a fixed product _i_ have the same price _ri_ and are identical\n\nfrom the consumers\u2019 perspective, it is useful to consider them separately. [10] More precisely, our analysis\n\npartitions all units of each product _i_ based on their assigned batches in the BIB algorithm, and units in each\n\nbatch are considered separately.\n\nWe introduce an important auxiliary concept, which we term as _batch-specified assortment_, defined as\n\nfollows. A batch-specified assortment _L_ = _{_ ( _i,ji_ ) : _i \u2208_ _S}_ encodes a subset of products _S_ (same as a typ\n\nical assortment) together with a specific batch _Bi,ji_ for each product _i \u2208_ _S_ . With slight abuse of notation,\n\nwe define _\u03d5t_ ( _L,i_ ) \u225c _\u03d5t_ ( _S,i_ ) for every batch-specified assortment _L_ = _{_ ( _i,ji_ ) : _i \u2208_ _S}_ . By offering batch\n\nspecified assortment _L_ to consumer _t_, a unit from batch _Bi,ji_ of each product _i \u2208_ _S_ is selected with probability\n\n_\u03d5t_ ( _L,i_ ).\n\nRecall the (dynamic) construction of batches in the BIB algorithm, described formally in Algorithm 1.\n\nWhen the algorithm terminates at the end of the horizon _T_, there are _hi_ \u201cready\u201d batches for each product\n\n_i \u2208_ [ _n_ ]. We denote by _\u03c4i,j_ as the time period when batch _Bi,j_ is switched from \u201ccharging\u201d to \u201cready\u201d. As a\n\nsanity check, _\u03c4i,_ 1 = 1 and _\u03c4i,j_ is weakly increasing in _j_ . We say a batch-specified assortment _L_ = _{_ ( _i,ji_ ) :\n\n_i \u2208_ _S}_ is _feasible_ in time period _t_ if its encoded assortment _S_ is feasible (i.e., _S \u2208S_ ) and _\u03c4i,ji \u2264_ _t_ for\n\nevery product _i \u2208_ _S_ . We use _Lt_ to denote the set of all feasible batch-specified assortments in time period _t_ .\n\nMoreover, we use _Li,j,t_ to denote all feasible batch-specified assortments in time period _t_ that contain batch\n\n_Bi,j_ of product _i_ . As a sanity check, the BIB algorithm is essentially offering batch-specified assortment\n\n_Lt_ = _{_ ( _i,ji_ ) : _i \u2208_ _St,ji_ = arg max _j fi,j,t}_ for each consumer _t \u2208_ [ _T_ ] and each batch-specified assortment _Lt_\n\nis feasible in time period _t_, i.e., _Lt \u2208Lt_ .\n\n**Batch-specified LP benchmark.** Similar to the batch-specified assortment introduced above, the revenue\n\nbenchmark for our competitive ratio analysis also relies on the execution of the BIB algorithm, and in\n\nparticular, the batch formulation. Consider the following linear program that knows the exact sequence of\n\n_{\u03d5t,\u03bei,t}i\u2208_ [ _n_ ] _,t\u2208_ [ _T_ ], but not the realization of consumers\u2019 choices:\n\n_L\u2208L_ ( _t_ )\n\nmax\n_X\u2265_ **0**\n\n_T_\n\ufffd _t_ =1\n\n\ufffd\n\n_n_\n\ns.t.\n\n\ufffd _i_ =1 _[r][i][\u03d5][t]_ [(] _[L,i]_ [)] _[X][L,t]_\n\n\ufffd _tt_ _[\u2020]_ =+ _t_ _[\u2020]_ _di\u2212_ 1 \ufffd\n\n\ufffd _tt_ _[\u2020]_ =+ _t_ _[\u2020]_ _di\u2212_ 1\n\n\ufffd _t_ _[\u2020]_ + _[\u2020]_ _di\u2212_ 1\n\n_i \u2208_ [ _n_ ] _, t_ _[\u2020]_ _\u2208_ [ _\u03c4i,_ 1 : _T_ ]\n_L\u2208Li,_ 1 _,t_ _[\u03d5][t]_ [(] _[L,i]_ [)] _[X][L,t][ \u2264]_ _[c][i]_ [ +] _[ \u03b3]_\n\n( _P_ OPT( _\u03b3_ ))\n\n_t_ = _t_ _[\u2020]_ \ufffd\n\n\ufffd _t_ = _t_ _[\u2020]_ \ufffd _L\u2208Li,j,t_ _[\u03d5][t]_ [(] _[L,i]_ [)] _[X][L,t][ \u2264]_ _[\u03b3]_ _i \u2208_ [ _n_ ] _, j \u2208_ [2 : _hi_ ] _, t_ _[\u2020]_ _\u2208_ [ _\u03c4i,j_ : _T_ ]\n\n\ufffd _[X][L,t][ \u2264]_ [1] _t \u2208_ [ _T_ ] _._\n\n_t \u2208_ [ _T_ ] _._\n_L\u2208Lt_ _[X][L,t][ \u2264]_ [1]\n\n10 In fact, ignoring endogenous effects of return, one can think of the inventory at each time being formed by the initial inventory\nand added inventory due to exogenous shocks at different times. With this view, considering units separately (as will be clear later)\nhelps with keeping track of the time they are added for the first time to the inventory.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n12\n\nIt can be observed that program _P_ OPT( _\u03b3_ ) depends on the definition of BIB algorithm. Specifically, _\u03b3_ is the\n\nbatch-size threshold of the BIB algorithm, _{hi}i\u2208_ [ _n_ ] is the number of \u201cready\u201d batches in the algorithm, and\n\n_{\u03c4i,j,_ _Lt,_ _Li,j,t}_ are all induced by the BIB algorithm. To highlight this dependence on the BIB algorithm,\n\nwe parameterized program _P_ OPT( _\u03b3_ ) by _\u03b3_ .\n\nIn program _P_ OPT( _\u03b3_ ), each variable _XL,t_ can be interpreted as the probability of offering a batch-specified\n\nassortment _L_ for consumer _t_ . With this interpretation, the objective captures the expected revenue. Further\n\nmore, the first (second) set of constraints captures a _relaxed_ inventory feasibility constraint for all units in\n\nthe first batch (second and later batches) of each product. [11] The third set of constraints ensures that the sum\n\nof allocation probabilities is at most one for each consumer.\n\nAs the main technical lemma in this subsection, we formally show that for any execution of the BIB\n\nalgorithm, its induced program _P_ OPT( _\u03b3_ ) is an upper bound on the revenue of the clairvoyant optimum policy\n\nthat knows the adversarial sequence of consumer choice models and amounts of exogenous inventory shocks\n\n(and hence a relaxation to any feasible policy):\n\nLEMMA 1. _For any sequence {\u03d5t,\u03bei,t}i\u2208_ [ _n_ ] _,t\u2208_ [ _T_ ] _, the expected revenue of the clairvoyant optimum policy_\n\n_(and hence any online algorithm) is at most the optimal objective value in program P_ OPT( _\u03b3_ ) _with any choice_\n\n_of batch-size threshold \u03b3 \u2208_ N _._\n\n_Proof._ _Proof._ Given any _\u03b3 \u2208_ N, we partition all units of each product into batches based on the batch\n\nconstruction/assignment of the BIB algorithm (with batch-size threshold _\u03b3_ ) and equivalently consider the\n\nbatch-specified assortment as we defined above. In the following, we construct a feasible solution for pro\n\ngram _P_ OPT( _\u03b3_ ) using the execution path of the clairvoyant optimum policy.\n\nFor each time period _t_, let _L_ [\u02dc] _t_ denote the batch-specified assortment offered by the clairvoyant policy,\n\nwhere _L_ [\u02dc] _t_ is a sample-path dependent random subset. For each unit allocation of product _i_ in batch _Bi,j_ by the\n\nclairvoyant policy, we reassign it to the earlier batch _Bi,j\u2212_ 1 (with _Bi,_ 0 interpreted as _Bi,_ 1). Let _L_ [\u02dc] _[\u2020]_ _t_ [denote the]\n\nbatch-specified assortment obtained by applying this batch-shifting operation to _L_ [\u02dc] _t_, i.e., for each ( _i,j_ ) _\u2208_ _L_ [\u02dc] _t_,\n\ninclude ( _i,j \u2212_ 1 _\u2228_ 1) in _L_ [\u02dc] _[\u2020]_ _t_ [. We then set] _[ X]_ _L_ \u02dc _[\u2020]_ _t_ _[,t]_ [ = 1][ for all] _[ t]_ [, and] _[ X][L,t]_ [ = 0][ for all other] _[ L][ \u2208L][t]_ [. We next verify]\n\nthe constructed solution is feasible and finally analyze its objective value.\n\n_First set of constraints._ Consider any product _i_ and any interval of length _di_ . The clairvoyant policy can\n\nallocate at most _ci_ units from the initial inventory plus those from the first exogenous batch. By construction,\n\nsuch allocations are shifted to _Bi,_ 1 in our constructed solution. Since _Bi,_ 1 has total size _ci_ + _\u03b3_, the number of\n\nshifted allocations never exceeds this amount. Hence, the first family of constraints in _P_ OPT( _\u03b3_ ) is satisfied.\n\n11 Fixing a product, the first constraint is an aggregated capacity constraint for all the units in the initial ready batch and the batch\nright after that (imagine those units are merged with the first batch). Therefore, the right-hand side is _ci_ + _\u03b3_ . Then the constraint\ncorresponding to each index _j \u2208_ [2 : _hi_ ] is a capacity constraint for units in batch _j_ + 1 (imagine that those units are shifted to batch\n_j_, as if they have arrived earlier). As shifting units to arrive earlier makes the problem more relaxed, this program is a relaxation. See\nthe proof of Lemma 1 for a formal argument.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n13\n\n_Second set of constraints._ For each _j \u2265_ 2, each allocation of a unit from _Bi,j_ +1 in the clairvoyant policy is\n\nshifted to _Bi,j_ in our constructed solution. As each batch has size at most _\u03b3_, in any interval of length _di_ there\n\ncan be at most _\u03b3_ such effective allocations. Thus, the second family of constraints in _P_ OPT( _\u03b3_ ) holds.\n\n_Third set of constraints._ For each time _t_, we set _XL_ \u02dc _\u2020t_ _[,t]_ [ = 1][ and all other allocations at time] _[ t]_ [ to zero. Therefore,]\n\ufffd _L\u2208Lt_ _[X][L,t]_ [ = 1][ for each] _[ t]_ [, which satisfies the third family of constraints.]\n\n_Objective value._ Finally, note that for every period _t_, the shifted assortment _L_ [\u02dc] _[\u2020]_ _t_ [yields the same choice proba-]\n\nbilities as the clairvoyant assortment _L_ [\u02dc] _t_ . Therefore, the expected objective value of our constructed solution\n\nmatches that of the clairvoyant policy. \n\n**4.2. Competitive Ratio Analysis of Batched Inventory Balancing**\n\nIn this section, we present the competitive ratio analysis of the BIB algorithm using a primal-dual framework.\n\nBefore delving into analysis, we introduce a key combinatorial construct underpinning our dual construction.\n\n**Interval assignment problem (IAP).** Consider a sequence of _s_ intervals indexed by [ _s_ ] \u225c _{_ 1 _,_ 2 _,...,s}_,\n\ndenoted _{_ [ _ai,bi_ ] _}i\u2208_ [ _s_ ], whose left endpoints satisfy _a_ 1 _< a_ 2 _< \u00b7\u00b7\u00b7 < as_ . For each interval index _i \u2208_ [ _s_ ], define\n\nthe _coverage set Ni_ = _{j \u2208_ [ _s_ ] : _ai \u2208_ [ _aj,bj_ ] _}_, i.e., the set of interval indices whose intervals cover the left\n\nendpoint _ai_, and let _|Ni|_ denote its cardinality. The _Interval Assignment Problem (IAP)_ asks to assign a\n\npositive integer _I_ [\u02c6] _i \u2208_ N to each interval index _i_ such that the resulting assignment ( _I_ [\u02c6] 1 _,...,_ _I_ [\u02c6] _s_ ) satisfies the\n\nfollowing three structural properties:\n\n(i) _(_ LOCAL-DOMINANCE _):_ For each interval index _i \u2208_ [ _s_ ], there exists a bijection _\u03c1i_ : _Ni \u2192_\n\n_{_ 1 _,_ 2 _,...,_ _|Ni|}_ such that _I_ [\u02c6] _j \u2265_ _\u03c1i_ ( _j_ ) for all _j \u2208Ni_ .\n\n_(_ GLOBAL-DOMINANCE _):_ For every decreasing and concave function \u03a8 [\u00af], we have [\ufffd] _i\u2208_ [ _s_ ] [\u00af\u03a8(\u02c6] _[I][i]_ [)] _[ \u2265]_\n\n~~\ufffd~~ _i_ _s_ [\u00af\u03a8(] _[|N][i][|]_ [)] _[.]_\n\n(ii) _(_ GLOBAL-DOMINANCE _):_ For every decreasing and concave function \u03a8 [\u00af], we have [\ufffd]\n\n_i\u2208_ [ _s_ ] [\u00af\u03a8(] _[|N][i][|]_ [)] _[.]_\n\n(iii) _(_ PARTITION-MONOTONICITY _):_ The interval index set can be partitioned into disjoint subgroups\n\n_A_ 1 _,...,A\u03ba_ such that for each _\u2113_ _\u2208_ [ _\u03ba_ ], _{I_ [\u02c6] _i_ : _i \u2208_ _A\u2113}_ = _{_ 1 _,_ 2 _,...,_ _|A\u2113|}._\n\nWe now state our main result about the IAP: a polynomial-time algorithm exists that always produces a valid\n\nassignment satisfying all three properties. Illustrative examples for the IAP can be found in Section EC.4.\n\nLEMMA 2. _For any input instance of the IAP as defined above, there exists a polynomial-time algorithm_\n\n_(Algorithm 2; see Section 4.3 for details) that computes an assignment_ ( _I_ [\u02c6] 1 _,...,_ _I_ [\u02c6] _s_ ) _\u2208_ N _[s]_ _satisfying_ LOCAL\n\nDOMINANCE _,_ GLOBAL-DOMINANCE _, and_ PARTITION-MONOTONICITY _._\n\n**Overview of the solution to IAP and its applications.** In the primal-dual analysis of the BIB algorithm, a\n\ncentral difficulty arises because the actual number of units that have been allocated from a batch\u2014but not yet\n\nreturned\u2014may increase and decrease over time due to overlapping rental periods. This non-monotonicity\n\nprevents a direct application of standard dual constructions, which rely on inventory trajectories that only\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n14\n\ndecrease. [12] To resolve this, for each \u201cready\u201d batch, we construct a _transformed_ inventory trajectory by solving\n\nan instance of IAP. In this instance, each allocation from the batch corresponds to an interval spanning from\n\nits allocation time to its return time. The IAP maps these intervals to integer labels that serve as surrogate\n\ninventory levels. These labels are carefully designed to satisfy three key properties, each of which enables\n\na critical step in the primal-dual analysis: LOCAL-DOMINANCE ensures that, at the moment any unit is\n\nallocated, the transformed inventory levels of all units currently in use are sufficiently large to support the\n\ndual feasibility condition. Intuitively, it guarantees that the dual variables can be set high enough to \u201ccover\u201d\n\nthe primal revenue of the allocation. GLOBAL-DOMINANCE guarantees that the total penalty (i.e., the sum\n\nof \u03a8 evaluated at the transformed inventory levels) is no worse than if we had used the real, non-monotone\n\nconsumption levels. This allows us to relate the algorithm\u2019s actual revenue to the dual objective without loss.\n\nPARTITION-MONOTONICITY reorganizes the allocations into groups where the transformed inventory levels\n\nbehave like those in the classic setting\u2014strictly decreasing by one after each allocation. This structure is\n\nessential for recovering the tight competitive ratio for general penalty function \u03a8 in Golrezaei et al. (2014).\n\nThe details of how to solve IAP and the proof of Lemma 2 are deferred to Section 4.3.\n\nWe now present our primal-dual analysis for the BIB algorithm using the key Lemma 2.\n\n_Proof._ _Proof of Theorem 1._ We start our analysis by writing down the dual program of our LP bench\n\nmark _P_ OPT( _\u03b3_ ):\n\n_T_\n+ s.t.\n\ufffd _t_ =1 _[\u03bb][t]_\n\ufffd\n\n_T_\n\n_t_\n\n\ufffd\ufffd\n\n_Tt_ = _\u03c4i,_ 1 [(] _[c][i]_ [ +] _[ \u03b3]_ [)] _[\u03b8][i,]_ [1] _[,t]_ [ +] \ufffd _hj_ _i_\n\n_j_ =2\n\nmin\n_**\u03b8**_ _,_ _**\u03bb**_ _\u2265_ **0**\n\n\ufffd _ni_ =1\n\n_T_\n\ufffd _t_ = _\u03c4i,j_ _[\u03b3\u03b8][i,j,t]_\n\n_t \u2208_ [ _T_ ] _, L \u2208Lt ._\n( _i,j_ ) _\u2208L_ _[r][i][\u03d5][t]_ [(] _[L,i]_ [)]\n\n_\u03bbt_ +\n\ufffd\n\n( _i,j_ ) _\u2208L_\n\n\ufffd _tt_ _[\u2032]_ = _t\u2212di_ +1 _[\u03d5][t]_ [(] _[L,i]_ [)] _[\u03b8][i,j,t][\u2032][ \u2265]_ \ufffd\n\nWe construct a randomized dual assignment based on the execution path of the BIB algorithm together with\n\nthe random realization of consumers\u2019 choices as follows. First, set _\u03bbt \u2190_ 0 and _\u03b8i,j,t \u2190_ 0 for all _t \u2208_ [ _T_ ] _,i \u2208_\n\n[ _n_ ] _,j \u2208_ [ _hi_ ]. For each time period _t \u2208_ [ _T_ ], suppose consumer _t_ chooses a unit of product _i_ from batch _Bi,j_,\n\nupdate dual variables as follows:\n\n_\u03bbt \u2190_ _ri_ \u03a8( _fi,j,t_ ) and _\u03b8i,j,t \u2190_ _ri_ (\u03a8( _gi,j,t_ ) _\u2212_ \u03a8( _gi,j,t \u2212_ (1 _/|Bi,j|_ ))) _._\n\nHere _{gi,j,t}i\u2208_ [ _n_ ] _,j\u2208_ [ _hi_ ] _,t\u2208_ [ _T_ ] is a sequence of values constructed based on the interval assignment problem\n\n(IAP) (Lemma 2). Specifically, for each product _i \u2208_ [ _n_ ] and its \u201cready\u201d batch _Bi,j_ with _j \u2208_ [ _hi_ ], let _Ti,j_ =\n\n_{t_ 1 _,t_ 2 _,...,ts}_ be the time periods when a unit of product _i_ from _Bi,j_ is chosen by consumers. Consider\n\nan instance of IAP with _s_ intervals [ _t_ 1 _,t_ 1 + _di_ ] _,...,_ [ _ts,ts_ + _di_ ] _}_ . Let _{I_ [\u02c6] _k}k\u2208_ [ _s_ ] be the assignment solved\n\nin IAP for this batch. With slight abuse of notation, we also denote the assignment solved in this IAP\n\ninstance as _{I_ [\u02c6] _i,j,t}t\u2208Ti,j_ to emphasize its connection to the BIB algorithm\u2019s execution. We set _gi,j,t_ \u225c 1 _\u2212_\n\n( _I_ [\u02c6] _i,j,t \u2212_ 1) _/|Bi,j|_ for every time _t \u2208Ti,j_ and _gi,j,t_ \u225c 0 for all the remaining time _t \u2208_ [ _T_ ] _\\Ti,j_ .\n\n12 cf. Example EC.1, where the naive assignment based on real consumption fails.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n15\n\nThe analysis proceeds in two steps. First, we show that the randomized dual assignments are feasible\n\nin expectation. Second, we show that the expected dual objective provides a \u0393(\u03a8 _,\u03b3_ ) approximation to the\n\nexpected revenue of the BIB algorithm. Combining these two results with the strong duality establishes the\n\ncompetitive ratio of the algorithm, as stated in Theorem 1.\n\n_\u00b7_\n\n[ _Step i_ ] _Checking the feasibility of dual in expectation._ Since penalty function \u03a8( ) of the BIB algorithm\n\nis non-negative and monotone non-decreasing, the constructed dual assignment is non-negative. We next\n\nshow that the dual constraints corresponding to each _XL,t_ is satisfied in expectation. Note that this is enough,\n\nbecause we can later use the expectation of the dual variables as the actual dual certificate. First, we establish\n\nthe following inequality for every product _i \u2208_ [ _n_ ], batch _j \u2208_ [ _hi_ ], and time _t \u2208_ [ _\u03c4i,j_ : _T_ ]:\n\n_t\u2212_ 1\n_ri_ \u03a8( _fi,j,t_ ) + \ufffd _t_ _[\u2032]_ = _t\u2212di_ +1 _[\u03b8][i,j,t][\u2032][ \u2265]_ _[r][i][ .]_ (1)\n\nTo prove inequality (1), consider on-hand units together with units of product _i_ that have not yet returned\n\nin batch _Bi,j_ at time _t_ . Since the normalized inventory level of batch _Bi,j_ at time _t_ is _fi,j,t_, there are _m_ \u225c\n\n(1 _\u2212_ _fi,j,t_ ) _|Bi,j|_ units of product _i_ in this batch that have not yet returned at time _t_ . Suppose that these units\n\nwere sold at times _t_ _[\u2032]_ 1 _[\u2264]_ _[t][\u2032]_ 2 _[\u2264\u00b7\u00b7\u00b7 \u2264]_ _[t][\u2032]_ _m_ [. By construction, all these time periods are between] _[ t]_ _[\u2212]_ _[d][i]_ [+1][ and] _[ t]_ _[\u2212]_ [1]\n\nand belong to _Ti,j_ . We now show inequality (1) as follows:\n\n_t\u2212_ 1\n_ri_ \u03a8( _fi,j,t_ ) + \ufffd _[\u2032]_\n\n_k_ =1 _[\u03b8][i,j,t]_ _k_ _[\u2032]_\n\n_\u2212_ ( _a_ ) _m_\n\n_t_ _[\u2032]_ = _t\u2212di_ +1 _[\u03b8][i,j,t][\u2032]_ = _ri_ \u03a8( _fi,j,t_ ) + \ufffd _k_\n\n( _b_ ) _m_\n= _ri_ \u03a8( _fi,j,t_ ) + \ufffd _k_ =1 _[r][i]_ \ufffd\u03a8 \ufffd _gi,j,t\u2032k_\n\n\ufffd _\u2212_ \u03a8 \ufffd _gi,j,t\u2032k_ _[\u2212]_ [(1] _[/][|][B][i,j][|]_ [)] \ufffd\ufffd\n\n(= _c_ ) _ri_ \u03a8( _fi,j,t_ ) + \ufffd _mk_ =1 _[r][i]_ \ufffd\u03a8 \ufffd1 _\u2212_ (( _I_ [\u02c6] _i,j,t\u2032k_ _[\u2212]_ [1)] _[/][|][B][i,j][|]_ [)] \ufffd _\u2212_ \u03a8 \ufffd1 _\u2212_ ( _I_ [\u02c6] _i,j,t\u2032k_ _[/][|][B][i,j][|]_ [)] \ufffd\ufffd\n\n( _d_ ) _m_ ( _e_ ) ( _f_ )\n_\u2265_ _ri_ \u03a8(1 _\u2212_ ( _m/|Bi,j|_ )) + \ufffd _k_ =1 _[r][i]_ [ (\u03a8(1] _[ \u2212]_ [((] _[k][ \u2212]_ [1)] _[/][|][B][i,j][|]_ [))] _[ \u2212]_ [\u03a8(1] _[ \u2212]_ [(] _[k/][|][B][i,j][|]_ [)))] = _ri_ \u03a8(1) = _ri ._\n\nHere, equality (a) holds due to the definition of _m_, _{t_ _[\u2032]_ _k_ _[}][k][\u2208]_ [[] _[m]_ []] [and the dual assignment construction; Equal-]\n\nity (b) holds due to the dual construction; Equality (c) holds due to the construction of _{gi,j,t\u2032k_ _[}]_ [. For inequal-]\n\nity (d), we use the definition of _m_, and the rest of inequality holds due to LOCAL-DOMINANCE of IAP\n\n(Lemma 2) at time _t_ _[\u2032]_ _m_ [, and the concavity of the penalty function][ \u03a8][.][13][ Finally, equality (e) holds due to the]\n\ntelescopic sum and equality (f) holds since \u03a8(1) = 1.\n\nFixing an arbitrary time period _t_ and a feasible batch-specified assortment _L \u2208Lt_, we establish the fol\n\nlowing inequality for every time period _t_, which takes the expectation over the randomized choice of the\n\n13 Let _m_ = (1 _\u2212fi,j,t_ ) _|Bi,j|_ be the number of units from batch _Bi,j_ in use at time _t_, allocated at times _t\u2032_ 1 _[<][ \u00b7\u00b7\u00b7][ < t][\u2032]_ _m_ [. Consider the last]\nsuch time _I_ \u02c6( _k_ ) _\u2265_ _k_ for all _t_ _[\u2032]_ _m_ [; the coverage set] _k \u2208_ [ _m_ ], where \u02c6 _[ N]_ _I_ ( _kt_ _[\u2032]_ _m_ ) is the [includes all] _k_ -th smallest label. Since _[ m]_ [ intervals, so] _[ |N]_ \u03a8 _t_ _[\u2032]_ _m_ is concave and non-decreasing, its marginal difference is non- _[|]_ [ =] _[ m]_ [. By][ L][OCAL][-D][OMINANCE][, the IAP assignment satisfy]\nincreasing. Thus, replacing the IAP assignment _I_ [\u02c6] _i,j,t\u2032k_ [with the smaller values] _[ k]_ [ can only increase each marginal term. Consequently,]\nthe sum on the LHS\u2014using the IAP assignment\u2014is at least as large as the RHS\u2014using the idealized sequence _k_ = 1 _,...,m_ . This\njustifies inequality (d).\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n16\n\nconsumer _t_ \u2019, while conditioning on the realized sample path _Ft\u2212_ 1 up to the end of time period _t_ and the\n\nrealization of the batch-specified assortment _Lt_ displayed to consumer _t_ :\n\n(2)\n( _i,j_ ) _\u2208L_ _[r][i][\u03d5][t]_ [(] _[L,i]_ [)\u03a8(] _[f][i,j,t]_ [)] _[ .]_\n\n( _a_ )\nE[ _\u03bbt | Ft\u2212_ 1 _,Lt_ ] = \ufffd\n\n( _b_ )\n_\u2265_\n( _i,j_ ) _\u2208Lt_ _[r][i][\u03d5][t]_ [(] _[L][t][,i]_ [)\u03a8(] _[f][i,j,t]_ [)] \ufffd\n\nHere, equality (a) holds due to the dual assignment construction and the expectation over consumer _t_ \u2019s\n\nchoice; and inequality (b) holds due to the greedy decision for selecting _Lt_ in BIB.\n\nCombining inequalities (1) and (2), we are able to verify the feasibility of the dual constraint corresponding\n\nto primal variable _XL,t_ as follows:\n\nE _\u03bbt_ +\n\ufffd\n\ufffd\n\n\ufffd _tt_ _[\u2032]_ = _t\u2212di_ +1 _[\u03d5][t]_ [(] _[L,i]_ [)] _[\u03b8][i,j,t][\u2032]_ \ufffd\n\n( _i,j_ ) _\u2208L_\n\n_t_ ( _a_ )\n\n_\u2265_ E\n\n\ufffd _t_ _[\u2032]_ = _t\u2212di_ +1 _[\u03d5][t]_ [(] _[L,i]_ [)] _[\u03b8][i,j,t][\u2032]_ \ufffd \ufffd\ufffd\n\n( _i,j_ ) _\u2208L_ _[r][i][\u03d5][t]_ [(] _[L,i]_ [)\u03a8(] _[f][i,j,t]_ [) +] \ufffd\n\n( _i,j_ ) _\u2208L_\n\n( _b_ )\n_\u2265_\n\ufffd\n\n_t_ ( _c_ )\n( _i,j_ ) _\u2208L_ _[\u03d5][t]_ [(] _[L,i]_ [)][E] \ufffd _ri_ \u03a8( _fi,j,t_ ) + \ufffd _t_ _[\u2032]_ = _t\u2212di_ +1 _[\u03b8][i,j,t][\u2032]_ \ufffd _\u2265_ \ufffd\n\n( _i,j_ ) _\u2208L_ _[r][i][\u03d5][t]_ [(] _[L,i]_ [)] _[,]_\n\nwhere inequality (a) holds due to inequality (2); inequality (b) holds due to the linearity of expectation; and\n\ninequality (c) holds due to inequality (1).\n\n[ _Step ii_ ] _Comparing objective values of primal and dual._ We compare the contribution of batch _Bi,j_ in the\n\nBIB algorithm and the contribution in the dual objective for each \u201cready\u201d batch _Bi,j_ separately. Recall _Ti,j_ is\n\nthe set of time periods when a unit of product _i_ from batch _Bi,j_ has been selected. The revenue contribution\n\nin the BIB algorithm (aka., primal) corresponding to batch _Bi,j_ can be expressed as Primal _i,j_ = _ri|Ti,j|_ .\n\nMeanwhile, the contribution of the dual objective based on the constructed dual assignment can be upper\n\nbounded as\n\n( _a_ )\nDual _i,j_ = _ri_ \ufffd\n\n_t\u2208Ti,j_ [(\u03a8(] _[f][i,j,t]_ [) + (] _[c][i][ \u00b7]_ [ 1] _[{][j]_ [ = 1] _[}]_ [ +] _[ \u03b3]_ [)(\u03a8(] _[g][i,j,t]_ [)] _[ \u2212]_ [\u03a8(] _[g][i,j,t][ \u2212]_ [(1] _[/][|][B][i,j][|]_ [))))]\n\n(3)\n_t\u2208Ti,j_ [(\u03a8(] _[g][i,j,t]_ [) + (] _[c][i][ \u00b7]_ [ 1] _[{][j]_ [ = 1] _[}]_ [ +] _[ \u03b3]_ [)(\u03a8(] _[g][i,j,t]_ [)] _[ \u2212]_ [\u03a8(] _[g][i,j,t][ \u2212]_ [(1] _[/][|][B][i,j][|]_ [))))] _[,]_\n\n( _b_ )\n_\u2264_ _ri_\n\ufffd\n\nwhere equality (a) holds due to the constructed dual assignment; and inequality (b) holds due to the con\n\nstruction of _{gi,j,t}_ and GLOBAL-DOMINANCE of IAP (Lemma 2). [14]\n\nNow, we partition time periods in _Ti,j_ into subgroups _Ai,j,_ 1 _,Ai,j,_ 2 _,...,Ai,j,\u03ba_ induced by PARTITION\n\nMONOTONICITY of IAP (Lemma 2). Our remaining analysis compares the contribution of batch _Bi,j_ from\n\ntime periods _Ai,j,\u2113_ in the BIB algorithm (denoted by Primal _i,j,\u2113_ ) and the corresponding dual assignments\u2019\n\ncontribution in the dual objective (denoted by Dual _i,j,\u2113_ ) for each _\u2113_ _\u2208_ [ _\u03ba_ ] separately. Define auxiliary notation\n\n\u02dc\n_ci,j_ \u225c _ci \u00b7_ 1 _{j_ = 1 _}_ + _\u03b3_ . Note that Primal _i,j,\u2113_ = _ri|Ai,j,\u2113|_ and\n\n_t\u2208Ai,j,\u2113_ [(\u03a8(] _[g][i,j,t]_ [) + \u02dc] _[c][i,j]_ [ (\u03a8(] _[g][i,j,t]_ [)] _[ \u2212]_ [\u03a8(] _[g][i,j,t][ \u2212]_ [(1] _[/][|][B][i,j][|]_ [))))]\n\nDual _i,j,\u2113_\n\n( _a_ )\n_\u2264_ _ri_\n\ufffd\n\n14\nRecall that _fi,j,t_ = 1 _\u2212_ _mt/|Bi,j|_, where _mt_ is the number of units from batch _Bi,j_ in use at time _t_, and _gi,j,t_ = 1 _\u2212_ (\u02c6 _Ii,j,t \u2212_\n1) _/|Bi,j|_, where _I_ [\u02c6] _i,j,t_ is the IAP assignment. Define \u03a8( [\u00af] _x_ ) \u225c \u03a8(1 _\u2212_ ( _x \u2212_ 1) _/|Bi,j|_ ), which is decreasing and concave because\n\u03a8 is concave and non-decreasing. Since _mt_ + 1 = _|Nt|_ (the coverage size at the allocation time _t_ ), we have \u03a8( _fi,j,t_ ) = \u03a8( [\u00af] _|Nt|_ )\nand \u03a8( _gi,j,t_ ) = \u03a8( [\u00af] _I_ [\u02c6] _i,j,t_ ). GLOBAL-DOMINANCE then implies [\ufffd] _t\u2208Ti,j_ [\u00af\u03a8(\u02c6] _[I][i,j,t]_ [)] _[ \u2265]_ [\ufffd] _t\u2208Ti,j_ [\u00af\u03a8(] _[|N][t][|]_ [)][, i.e.,][ \ufffd] _t\u2208Ti,j_ [\u03a8(] _[g][i,j,t]_ [)] _[ \u2265]_\n\n\ufffd _t_ [\u03a8(] _[f][i,j,t]_ [)][, which justifies inequality (b).]\n\n_t\u2208Ti,j_ [\u03a8(] _[f][i,j,t]_ [)][, which justifies inequality (b).]\n\n_t\u2208Ti,j_ [\u00af\u03a8(\u02c6] _[I][i,j,t]_ [)] _[ \u2265]_ [\ufffd]\n\n_t\u2208Ti,j_ [\u00af\u03a8(] _[|N][t][|]_ [)][, i.e.,][ \ufffd]\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n17\n\n( _b_ )\n_\u2264_ _ri_\n\ufffd _t\u2208Ai,j,\u2113_\n\n\u03a8 1 _\u2212_ (( _I_ [\u02c6] _i,j,t \u2212_ 1) _/|Bi,j|_ ) + \u02dc _ci,j_ \u03a8 1 _\u2212_ (( _I_ [\u02c6] _i,j,t \u2212_ 1) _/|Bi,j|_ ) _\u2212_ \u03a8 1 _\u2212_ ( _I_ [\u02c6] _i,j,t/|Bi,j|_ )\n\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\ufffd\n\n( _c_ ) _|Ai,j,\u2113|_\n= _ri_ \ufffd _k_ =1 (\u03a8(1 _\u2212_ (( _k \u2212_ 1) _/|Bi,j|_ )) + \u02dc _ci,j_ (\u03a8(1 _\u2212_ (( _k \u2212_ 1) _/|Bi,j|_ )) _\u2212_ \u03a8(1 _\u2212_ ( _k/|Bi,j|_ ))))\n\n_|Bi,j_ _|_\n= _ri_\n\ufffd _k_ = _|Bi,j_ _|\u2212|Ai,j,\u2113|_ +1 [(\u03a8(] _[k/][|][B][i,j][|]_ [) + \u02dc] _[c][i,j]_ [ (\u03a8(] _[k/][|][B][i,j][|]_ [)] _[ \u2212]_ [\u03a8((] _[k][ \u2212]_ [1)] _[/][|][B][i,j][|]_ [)))]\n\n( _d_ ) _|Bi,j_ _|_\n= _ri_\n\ufffd _k_ = _|Bi,j_ _|\u2212|Ai,j,\u2113|_ +1 [\u03a8(] _[k/][|][B][i,j][|]_ [) +] _[ r][i][c]_ [\u02dc] _[i,j]_ [ (\u03a8(1)] _[ \u2212]_ [\u03a8(1] _[ \u2212]_ [(] _[|][A][i,j,\u2113][|][/][|][B][i,j][|]_ [)))]\n\n( _e_ )\n_\u2264_ _ri_ + _ri_\n\n1\n\n\u02dc\n\u03a8( _y_ ) d _y_ + _rici,j_ (1 _\u2212_ \u03a8(1 _\u2212_ ( _|Ai,j,\u2113|/|Bi,j|_ )))\n\n\ufffd1 _\u2212_ (( _|Ai,j,\u2113|\u2212_ 1) _/|Bi,j_ _|_ )\n\nwhere inequality (a) holds due to inequality (3); inequality (b) holds due to the construction of _gi,j,t_ ; equal\n\nity (c) holds due to PARTITION-MONOTONICITY of IAP (Lemma 2); equality (d) holds due to the telescopic\n\nsum; and inequality (e) holds since \u03a8 is weakly increasing and \u03a8(1) = 1.\n\nNote that by setting _x_ \u225c 1 _\u2212_ ( _|Ai,j,\u2113|/|Bi,j|_ ), the ratio between Primal _i,j,\u2113_ and Dual _i,j,\u2113_ has the same closed\n\nform as \u03931(\u03a8 _,\u03b3_ ) for \u201cready\u201d batch _Bi,_ 1, and \u03932(\u03a8 _,\u03b3_ ) for \u201cready\u201d batch _Bi,j_ with _j \u2208_ [2 : _hi_ ]. Thus, we\n\nconclude that for every sample path, the revenue in the BIB algorithm is a \u0393(\u03a8 _,\u03b3_ ) approximation of the dual\n\nobjective value of the constructed dual assignment. \n\n**4.3. Interval Assignment Problem**\n\nWe now prove Lemma 2 by explicitly constructing an assignment that satisfies all three required properties.\n\nWe first describe its core idea and then verify the properties using its structural invariants. A reference imple\n\nmentation is provided in Algorithm 2, and illustrative executions (Figures EC.2 and EC.3) of the algorithm\n\non representative IAP instances (Examples EC.1 and EC.2) can be found in Section EC.4.\n\n**Algorithmic idea.** The assignment is constructed by processing intervals in a specific order dictated by their\n\n_current coverage size_ : at each step, among all unassigned intervals (denoted by _W \u2286_ [ _s_ ]), we identify the\n\none (denoted by _i_ ) that is covered by the _largest_ number of still-unassigned intervals (i.e., _Ni \u2229W_ ), and\n\nassign the _leftmost_ interval _j_ in that coverage set a label equal to the current coverage size _|Ni \u2229W|_ ). This\n\ngreedy rule ensures that intervals appearing earlier (with smaller indices) are never \u201cstarved\u201d of large labels,\n\nwhich is essential for LOCAL-DOMINANCE. Moreover, because the algorithm always assigns labels based\n\non maximal coverage sets, the resulting assignment incurs no more penalty (under any decreasing concave\n\nfunction \u03a8( [\u00af] _\u00b7_ )) than the real consumption levels, i.e., satisfies GLOBAL-DOMINANCE.\n\nTo enable PARTITION-MONOTONICITY, the algorithm also builds a predecessor mapping during execu\ntion. Specifically: (i) mapping _qj_ records which interval\u2019s coverage set triggered the assignment of _I_ [\u02c6] _j_ . This\n\nis used to determine which intervals overlap in a way that justifies linking them into a partition group; (ii)\n\nmapping _pk_ records a predecessor link: when interval _j_ is assigned label _m_, it becomes the predecessor of\n\nany previously assigned interval _k_ with _I_ [\u02c6] _k_ = _m_ + 1 that overlaps appropriately with _j_ \u2019s coverage context\n\n(i.e., _j \u2208Nqk_ ). These links induce a forest of chains, each forming a valid partition group. These mappings\n\nare not used during assignment decisions\u2014they exist solely to support the analysis.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n18\n\n**Algorithm 2:** INTERVAL ASSIGNMENT SOLVER\n\n**Input:** sequence of _s_ intervals _{_ [ _a_ 1 _,b_ 1] _,...,_ [ _as,bs_ ] _}_\n\n**Output:** assignment ( _I_ [\u02c6] 1 _,...,_ _I_ [\u02c6] _s_ )\n\n**1** initialize assignment _I_ [\u02c6] _i \u2190_ 0, mapping _pi \u2190\u2212_ 1, and mapping _qi \u2190\u2212_ 1 for all _i \u2208_ [ _s_ ].\n\n**2** initialize remaining interval set _W \u2190{_ 1 _,_ 2 _,...,s}_ . /* define _Ni_ _[W]_ = _Ni \u2229W_ */\n\n**3 while** _W is not empty_ **do**\n\n**4** find interval _i_ with the largest index in remaining interval set _W_ where _|Ni_ _[W][|]_ [ is maximized, i.e.,]\n\n_i \u2190_ arg max _i\u2208W |Ni_ _[W][|]_ [.]\n\n**5** find interval _j_ with the smallest index in remaining interval set _W_ which covers position _ai_, i.e.,\n\n_j \u2190_ min _Ni_ _[W]_ [.]\n\n**6** set assignment _I_ [\u02c6] _j \u2190|Ni_ _[W][|]_ [ and mapping] _[ q][j]_ _[\u2190]_ _[i]_ [.]"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is transforming a non-monotonic, physically observed inventory state into a monotonically decreasing, abstract 'transformed' inventory state through the Interval Assignment Problem (IAP). Traditional online allocation analyses often rely on inventory levels strictly decreasing with allocations. However, with endogenous (returns) and exogenous (restocking) shocks, actual inventory can fluctuate. The IAP assigns an integer label to each allocation event (interval from allocation to return) such that these labels, when viewed inversely, create a sequence that behaves like a decreasing counter. This 'fictional' inventory then allows the application of standard primal-dual analysis techniques. The greedy algorithm for IAP ensures that earlier allocations in overlapping usage periods receive higher 'transformed' inventory labels, which is critical for maintaining dual feasibility (LOCAL-DOMINANCE) and relating the algorithm's performance to the ideal benchmark (GLOBAL-DOMINANCE and PARTITION-MONOTONICITY).\n\n**Explanation:** Imagine you're managing items in a store. Normally, when an item is sold, the inventory count goes down. Easy. But what if items are returned, or new stock arrives at different times, making the inventory count go up and down randomly? This 'non-monotonicity' breaks many mathematical proofs that rely on counts always decreasing. This paper solves that by introducing 'batches' for inventory (like separate storage bins for items arriving at different times) and a crucial step called the Interval Assignment Problem (IAP). The IAP doesn't just count items; it re-labels each 'use' of an item (from when it's taken to when it's returned) with a special number. It's like converting a messy, fluctuating real-world timeline into a clean, ordered sequence of 'used' slots. The IAP ensures three things: (1) 'LOCAL-DOMINANCE' ensures that at any point, the special numbers assigned reflect enough 'room' to satisfy the mathematical 'payments' (dual variables) for the items. (2) 'GLOBAL-DOMINANCE' guarantees that the total 'penalty' from these special numbers isn't worse than the actual, messy reality, keeping the approximation bounds valid. (3) 'PARTITION-MONOTONICITY' essentially re-groups these special numbers into neat, sequential 'chains' that look just like the simple decreasing counts in older, simpler models, allowing their established competitive ratios to still apply. Algorithm 2 is a greedy loop that finds the 'most covered' interval (most active usage period) and assigns a number to the 'earliest' overlapping allocation, ensuring higher numbers for older items, which is key for satisfying the dual conditions."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**HLS as Reference**\n\nThe overall workflow of the proposed HDL Design Agent is shown\nin Fig. 4. Given a C/C++ program with its specification and a corresponding C/C++ testbench from the HLS benchmark suite [52, 53],\nthe agent executes a three-stage process to produce a functionally\ncorrect HDL design. The agent interacts with a toolkit comprising tool APIs (HLS, RTL simulation, logic synthesis), a knowledge\nbase of HDL syntax rules, and automation scripts for simulation\nand comparison. In stage (1), described in Section 3.1, the C/C++\nprogram is decomposed into submodules according to the rules in\nSection 3.1.1. For each submodule, the LLM generates a corresponding HDL module (Design Under Test, DUT), and syntax errors are\nrepaired through the RAG mechanism. In stage (2), described in\nSection 3.2, each C/C++ submodule is synthesized by the HLS tool\ninto a functionally correct HDL as the golden reference. The DUT\nand the golden reference are then simulated under the same stimuli. During this process, HLS tools can automatically translate the\noriginal C/C++-based testbench into an equivalent HDL testbench\nto validate the HLS-generated HDL design, whereas the testbench\nfor the LLM-generated HDL design is adapted from the original\nC/C++ testbench using the LLM and then verified by humans. Any\ndetected functional mismatches are fed back to the LLM for iterative\n\nenhancement. In stage (3), described in Section 3.3, all verified LLMgenerated submodules are instantiated into a top-level design, and\ndifferential verification is repeated to ensure integration correctness.\n\n**3.1** **LLM-Assisted HDL Design Generation**\n\n_3.1.1_ _C/C++ Program Decomposition._ Directly feeding an entire\nC/C++ program with long context into the LLM tends to dilute attention, preventing it from capturing fine-grained hardware semantics,\ne.g., customized bit widths, type conversions, etc. This often leads\nto deep functional errors that are difficult to debug. To mitigate this\nissue, a divide-and-conquer strategy based on C/C++ decomposition\nis adopted before HDL generation. The original C/C++ program is\ndecomposed into smaller, LLM-friendly C/C++ submodules, thereby\nimproving the quality of the initial HDL design generation.\n\n**Figure 6: Syntax repair for LLM-generated HDL using RAG.**\n\nThe decomposition follows three strict rules: (1) Function-Level\nGranularity: Decomposition is performed along function boundaries,\nrather than by arbitrary line-level splitting. (2) Explicit I/O definition:\nEach submodule uses fixed-width scalars or static arrays as interfaces (e.g., int8_t state[16]), with all bit widths explicitly specified.\n(3) Single and Clear Semantics: Each submodule should have clear\nsemantics (e.g., SubBytes() performs only SBox substitution).\nTo ensure correctness after decomposition, a differential verification step is performed. All decomposed C/C++ submodules are\nre-integrated into a top-level C/C++ program and verified against\nthe original C/C++ testbench. The decomposition is considered successful only when the output results match exactly.\n_3.1.2_ _LLM-Assisted HDL Design Generation._ After decomposition,\nthe agent proceeds to the HDL generation phase as shown in Fig. 5.\nFor each C/C++ submodule, we generate two specification files in natural language using the LLM. (1) Functional Specification: A detailed\ndescription of the functionality and expected hardware behavior\nof the C/C++ submodule. (2) Interface Definition: Precisely maps\nC/C++ parameters to Verilog ports, including names, directions, and\nexact bit widths. With these two specification files, the LLM can\nbetter understand the design constraints of individual submodules\nand produce valid HDL designs from the C/C++ snippet effectively.\nTo guide the LLM toward producing effective HDL designs, we\nalso define the design, and formatting constraints as follows: (1)\nSeparating control logic from the datapath and using synchronous\nreset conventions; (2) Optimization strategies for the circuits, e.g.,\ninserting pipeline stages; (3) Formatting constraints such as enclosing the resulting HDL between triple backticks to facilitate HDL\nextraction from the output of the LLM using a script. The C/C++\nsubmodule code, functional specification, interface definition, design\nand formatting constraints are jointly provided to the LLM, guiding\nit to generate the corresponding HDL design of a submodule.\nDue to LLM hallucinations, the HDL design generated for a submodule often fails syntax compilation. As shown in Fig. 5, these\nerrors can be repaired by a retrieval-augmented generation (RAG)\nmechanism, which involves three stages: First, an external rule library is created containing HDL syntax rule templates. Each template includes error logs that may be triggered during syntax compilation, and a summary of the corresponding repair rule extracted\nfrom the user manual. Second, when an LLM-generated HDL design fails compilation, the error log is embedded and then matched\nagainst the templates in a rule library using a sentence transformer\n\nTABLE 1: Typical Functional Discrepancies in LLM-Generated HDL\nand the Corresponding Corrections Driven by _CorrectHDL_ .\n\n**Task** **DUT Output** **HLS Reference** **Functional Discrepancy Corresponding Correction**\n\n|< / > C/C++ Program SubBytes() \u2026 ShiftRows() \u2026 MixColumns() \u2026 AddRoundKey() \u2026<br>SameTestStimulus|Col2|\n|---|---|\n|LLM\u2013Generated HDL (DUT)<br>**DUT Path**|HLS\u2013Generated HDL (Golden Reference)<br>**Golden Path**|\n\nEdge [-3, 66, \u2026, -250, 108] [-31, 664, \u2026, -2479, 1081] Numeric scaling bug\n\nCorrect shift scaling\n\nMarkov [5, 22, 17, \u2026, 9, 14, 14] [5, 22, 17, \u2026, 9, 14, 15] Boundary write-back bug Commit delayed by\n\none cycle\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-3-0.png)\n\n**Figure 7: Differential verification for LLM-generated HDL.**\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-3-1.png)\n\n**Figure 8: Functional enhancement in LLM-generated HDL.**\n\n[50]. The retrieval process can be formalized as follows:\n\n_\ud835\udc38_ = embed(error_log) _,_ _\ud835\udc45\ud835\udc56_ = embed(rule_template _\ud835\udc56_ ) _,_ (1)\n\nwhere _\ud835\udc38_ and _\ud835\udc45\ud835\udc56_ denote the embedding vectors of the error log and\nthe _\ud835\udc56_ th rule template. Given an error log _\ud835\udc38_ and a template _\ud835\udc45_, the rule\ntemplate with the highest similarity is selected as follows:\n\n_\ud835\udc38_          - _\ud835\udc45_\nsim( _\ud835\udc38, \ud835\udc45_ ) = _\ud835\udc45_ [\u2217] = arg max sim( _\ud835\udc38, \ud835\udc45\ud835\udc56_ ) _,_ (2)\n\u2225 _\ud835\udc38_ \u2225\u2225 _\ud835\udc45_ \u2225 _[,]_ _\ud835\udc45\ud835\udc56_ \u2208R\n\nwhere R denotes all templates in the library, _\ud835\udc45_ [\u2217] represents the template with the highest similarity. Third, once the most relevant rule\ntemplate is retrieved, it is incorporated into the LLM prompt to guide\nthe repair of the HDL design into a syntactically correct version.\nAn example of repairing an LLM-generated HDL design is given in\nFig. 6. The agent uses compiler logs to retrieve repair rules and then\nprompts the LLM to repair the HDL, and repeats this process until\ncompilation succeeds or the predefined iteration limit is reached.\n\n**3.2** **Differential Verification and Functional**\n**Enhancement**\n\nAfter syntax errors in LLM-generated HDL designs are corrected as\ndescribed in Section 3.1.2, we leverage the HLS-generated HDL as a\ngolden functional reference to enhance its functional correctness, as\nshown in Fig. 7. For each C/C++ submodule, the HLS tool synthesizes\na bit-accurate and functionally correct HDL design as a reference.\nDespite its suboptimal area/power efficiency and limited readability,\nits functional behavior is highly reliable [2\u20135] and thus serves as an\neffective golden reference for verifying LLM-generated design.\n\nDMM [262144, 0, 4096, \u2026] [262144, 4096, 133120,\u2026] Reset or delay bug Decouple load and compute\n\nAES 1: [xx, xx, xx, ..., xx, xx] 1: [8e, a2, b7, ..., 60, 89] Lag due to synchronous Align output register with\n2: [8e, a2, b7, ..., 60, 89] 2: [6b, c1, be, ..., ef, 63] assignment timing bug next state or delay valid\n\nKMP [0, 8, 0, \u2026, 8, 0, 8] [7, 64, 9, \u2026, 59, 0, 560] Prefix skipped by slicing Compare full constant\n\nN-body [1, 0, 1, 1, 1,\u2026, 0, 1, 1] [1, 1, 0, 1, 1\u2026, 1, 0, 1] Inter-beat misalignment Use local blocking temps\n\nBFS [1, 0, 3, 0, 2, 1, 0, 1, \u2026] [1, 1, 4, 4, 6, 7, 7, 8\u2026] State retention across calls Add per-call initialization\n\nTo enable bit-accurate comparison, the LLM-generated HDL design as DUT and the HLS-generated HDL design as golden reference are simulated under identical test stimuli derived from the\n\nC/C++ testbench. Modern HLS tools can automatically translate\nthe C/C++ testbench into an equivalent HDL testbench to test the\nHLS-generated HDL. The corresponding HDL testbench for the LLMgenerated HDL is adapted from the same C/C++ testbench via the\nLLM with human verification to ensure its correctness in validating\nthe LLM-generated HDL design. The new testbench is examined by\nhuman engineers to ensure its quality.\nThe agent then initiates a parallel simulation flow shown in Fig. 7,\nwhere in the DUT Path, the LLM-generated HDL design is simulated\nin an RTL simulation environment, and in the Golden Path, the\nHLS-generated HDL design is simulated in the HLS simulation environment. During both simulations, all output ports are recorded and\ndumped into result files. A comparison script conducts automated\ndifferential checking between these files. If all outputs match, the\nDUT is considered functionally correct and collected for subsequent\nintegration. If any mismatch is observed, the DUT is marked as\nfunctionally incorrect, and the functional repair loop is triggered.\nThe repair loop uses the mismatched results as precise feedback\nto guide the LLM in the functional repair of the DUT. A structured\nprompt is constructed that contains the current (incorrect) Verilog\ncode of the DUT, the C/C++ program that defines the intended\nfunctional behavior, and a mismatch log produced by differential\ncomparison. This mismatch log explicitly records the test stimulus, the actual DUT output, and the expected golden reference for\neach failing test case. In addition, a step-wise reasoning method inspired by Chain-of-Thought is adopted to repair the LLM-generated\nHDL design. As shown in Fig. 8, the prompt explicitly instructs\nthe LLM to strengthen functional understanding by analyzing the\nC/C++ program and summarizing the intended behavior. It then\nconducts behavior and difference analysis through reviewing the\nHDL design, correlating it with the expected functionalities, and\nidentifying the source of the mismatches. The root cause of errors\nis identified and fixed by explaining the simulation discrepancy.\nWith such concrete feedback, the LLM can then perform targeted\ndebugging rather than blind editing. If mismatches remain, the verification\u2013feedback\u2013repair iteration is repeated until functional equivalence is achieved or the predefined iteration limit is reached.\nA concrete example of the LLM-driven reasoning chain is shown\nin Fig. 8. Guided by this structured prompt, the LLM first identifies\nthe small value differences stemming from inconsistent rounding\nsemantics between the DUT and the golden fixed-point implementation. It then proposes a revised HDL version that corrects the\nrounding behavior. In the second check, the LLM observes that the\nfirst test case is almost correct but the second is completely wrong,\nand traces this to a missing state retention in the control logic. It\nproposes latching the intermediate result in the ST_WAIT_LBL state\n\nTABLE 2: Comparison of _CorrectHDL_ with Baselines in Simulation Pass Rate, and with HLS in Area and Power Efficiency.\n\n|Benchmark|FunctionalSimulationPassRate(%)|Col3|Col4|Col5|Col6|Col7|HDL<br>Readability<br>(CodeLines)|Col9|AreaOverhead(\u00b5m\u00b2)|Col11|Col12|PowerConsumption(mW)|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|**Benchmark**|**LLM**<br>**\u2192**<br>**(NL as**<br>**HDL**<br>[29]<br>**Input)**|<br>**LLM\u2192**<br>**HDL**<br>**(C as**<br>**Input)**<br>**(**<br>**S**|**LLM\u2192HDL**<br>**w/ Task Decomp.**|**LLM\u2192HDL**<br>**w/ Task Decomp.**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|\n|**Benchmark**|**LLM**<br>**\u2192**<br>**(NL as**<br>**HDL**<br>[29]<br>**Input)**|<br>**LLM\u2192**<br>**HDL**<br>**(C as**<br>**Input)**<br>**(**<br>**S**|**LLM\u2192HDL**<br>**w/ Task Decomp.**|**LLM\u2192HDL**<br>**w/ Task Decomp.**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|** )**<br>**Proposed**<br>**CorrectHDL**<br>**(w/ HLS as Refer.)**|**HLS-**<br>**Gen**<br>**HDL**|**Prop.**<br>**Correct-**<br>**HDL**|**HLS-Gen**<br>**HDL**[54]|**Prop.**<br>**Correct-**<br>**HDL**|**(%)**|**HLS-Gen**<br>**HDL**[54]|**Prop.**<br>**Correct-**<br>**HDL**|**(%)**|\n|**Benchmark**|**LLM**<br>**\u2192**<br>**(NL as**<br>**HDL**<br>[29]<br>**Input)**|<br>**LLM\u2192**<br>**HDL**<br>**(C as**<br>**Input)**<br>**(**<br>**S**|**ubmod.**|**Top**|**Submod.**|**Top**|**Top**|**Top**|**Top**|**Top**|**Top**|**Top**|**Top**|**Top**|\n|AdvancedEncryptionStandard|6.25|12.5|48.44|18.75|76.56|62.5|1879|386|9591|7836|18.30|4.30|2.92|32.09|\n|Breadth-First Search|12.5|6.25|28.13|12.5|65.63|56.25|1392|234|29181|24101|17.41|9.98|8.08|19.04|\n|Edge Detection Algorithm|0|0|27.08|6.25|64.58|37.5|4753|388|35422|30543|13.77|16.04|13.67|14.78|\n|Median Filter|18.75|25|53.13|31.25|90.63|75|1351|213|11207|8249|26.39|4.84|3.61|25.41|\n|Dense Matrix Multiplication|12.5|31.25|46.88|37.5|78.13|62.5|568|179|33044|21061|36.26|16.32|13.01|20.28|\n|Knuth-Morris-Pratt|25|18.75|40.63|31.25|81.25|56.25|966|238|32631|20320|37.73|3.84|2.39|37.76|\n|MIPS Processor|0|0|35.42|6.25|58.33|31.25|3033|397|30698|24483|20.25|14.35|10.53|26.62|\n|N-body Molecular Dynamics|6.75|18.75|39.58|18.75|75.08|50|1086|270|25444|16007|37.09|5.89|3.41|42.11|\n|Dynamic Sequence Alignment|12.5|12.5|33.33|25|60.42|43.75|2998|325|23138|18104|21.76|10.05|7.69|23.48|\n|Secure Hash Algorithm|0|6.25|41.67|18.75|79.17|50|4421|420|22729|20898|8.06|9.40|7.81|16.91|\n|Spam Filtering|12.5|18.75|43.75|31.25|84.38|56.25|1396|183|17571|11475|34.69|6.40|4.18|34.69|\n|Markov Model Probabilities|6.25|6.25|34.38|12.5|65.63|37.5|1388|292|38598|28487|26.20|18.86|13.1|30.54|\n\n - The simulation pass rate is calculated based on 16 independent generation rounds by the LLM for each task.\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-4-0.png)\n\n**Figure 9: Design integration.**\nand reusing the stored value in subsequent calculations. After resimulation, the repaired DUT matches the golden outputs on all test\ncases, demonstrating how the agent can systematically analyze and\nrepair functional discrepancies with reliable functional references.\nTo better describe the types of functional errors handled by our\nframework, Table 1 summarizes several typical functional discrepancies observed between the DUT and the golden reference. For each\ntask, the table lists representative DUT and HLS golden outputs and\nhighlights how the LLM identifies the underlying root cause, such as\nnumeric scaling errors, reset or lag issues, or state-retention faults,\nand generates the corresponding fixes, including correcting fixedpoint scaling, decoupling load and compute operations, or adding\nper-call initialization. These examples indicate that the encountered\nbugs are not simple syntactic issues but functional errors that are\ndifficult to debug without a golden functional reference, highlighting\nits essential role in the repair process.\n\n**3.3** **Design Integration**\n\nAfter the LLM-generated HDL designs of all submodules pass differential verification, they are integrated into a functionally correct\ntop-level HDL design. To enable correct instantiation and wiring,\nthe LLM is prompted with the original C/C++ program from Section 3.1.1 and all verified HDL designs from Section 3.2 together\nwith their interface definitions from Section 3.1.2. Using this information, function calls and variable transfers in the C/C++ code are\nsystematically mapped to HDL module instances and signal connections, ensuring that data dependencies and interface contracts are\npreserved. The result is an LLM-generated top-level HDL design\nthat implements the behavior of the original C/C++ program.\nAs shown in Fig. 9, the integrated top-level HDL design may still\ncontain errors that are not exposed at the submodule level, such as\nmisconnected ports or misaligned valid signals. To validate the toplevel behavior, the original C/C++ program is then synthesized by\nthe HLS tool into an HLS-generated top HDL design, which serves\nas the golden reference. Differential verification is then performed\nat the top level, as in Section 3.2, to detect integration errors.\n\nTo efficiently locate integration errors, boundary signal instrumentation is inserted at all submodule interfaces in the top-level\ndesign. During verification, the agent compares not only the final\noutputs but also these internal boundary signals against the golden\nreference. Guided by this structured feedback, the LLM performs\ntargeted repair by using the backward slicing technique to trace the\norigin of the discrepancy [51]. The repair process is repeated until\nfunctional equivalence is achieved or the iteration limit is reached."}, {"role": "assistant", "content": "**Mechanism:** The system translates high-level C/C++ into low-level Hardware Description Language (HDL) via a Large Language Model (LLM). It uses a 'divide and conquer' strategy for the input, then employs a Retrieval-Augmented Generation (RAG) mechanism for syntax correction and an iterative differential verification loop against High-Level Synthesis (HLS) generated 'golden' designs for functional correctness.\n\n**Explanation:** At its core, the problem is that LLMs struggle with the precise constraints of hardware design when given large inputs (analogous to a programmer trying to write a huge function without breaking it down). So, the C/C++ code is first decomposed into smaller, modular submodules, much like breaking a complex program into functions. This improves the LLM's initial HDL generation quality. When the LLM generates HDL, it often makes syntax errors (hallucinations). The RAG mechanism addresses this: compilation error messages are converted into 'embedding vectors' (like unique numerical fingerprints). These vectors are then compared using cosine similarity (a measure of how 'alike' two vectors are, ranging from -1 to 1) against a library of pre-embedded syntax rules and their known fixes. The rule with the highest similarity is retrieved and fed back to the LLM as explicit guidance to fix the error, akin to a smart auto-corrector. For functional correctness, a crucial step is 'differential verification'. A High-Level Synthesis (HLS) tool, known for generating functionally correct (though not necessarily optimal) HDL from C/C++, is used to create a 'golden reference' design for each submodule. Both the LLM-generated design (DUT) and the HLS-generated golden design are simulated with identical test inputs. Their outputs are compared bit-by-bit. Any mismatch (a 'functional discrepancy') provides precise feedback to the LLM. This feedback, along with the C/C++ source and the incorrect Verilog, is structured into a prompt that guides the LLM through a 'chain-of-thought' reasoning process. It's like a debugger pointing out exactly where an array value or state variable differs from the expected, allowing the LLM to identify the root cause (e.g., incorrect rounding, missing state retention) and propose a targeted fix. This iterative process continues until the outputs match, ensuring the LLM-generated design behaves identically to the trusted HLS reference. Finally, verified submodules are integrated into a top-level design, and the entire process of differential verification, potentially with 'boundary signal instrumentation' (like adding print statements at function call boundaries), is repeated to catch integration-specific errors."}]}
