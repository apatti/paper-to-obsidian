{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**General bound** **6**\n\n3.1 Algorithm for locally _\u2113_ -colorable graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.2 Reduction to the subproblem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3 Base case for the subproblem ( _\ud835\udc51_ = _\u2113_ \u2212 1) . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n3.4 Inductive step on level _\ud835\udc51_ : Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.5 Inductive step on level _\ud835\udc51_ : Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.6 The improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.7 Comparison with Kierstead\u2019s algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.8 The competitive ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a recursive, divide-and-conquer strategy. It breaks a complex graph coloring problem into a hierarchy of smaller, self-similar subproblems. The process establishes a 'base case' where the problem is trivially solvable (e.g., a very small graph or a specific structural property is met). Then, an 'inductive step' describes how to solve a problem of a given 'level d' by leveraging solutions to problems of 'level d-1' or simpler. This is analogous to a recursive function call, where a function solves a problem by calling itself on a smaller input and then combining the results.\n\n**Explanation:** Think of it like a nested loop structure or a recursive function in programming. To color a large graph where local areas ('neighborhoods') have a limited number of required colors (\u2113-colorable), the algorithm doesn't try to solve it all at once. Instead, it defines a simplified version of the problem (the 'subproblem'). It finds the simplest possible version of this subproblem (the 'base case'), like assigning colors to a very small, basic graph structure. Then, for more complex graphs (the 'inductive step'), it uses the solutions from those simpler cases. It's like having a blueprint for a small part, and then using that blueprint repeatedly and systematically to build and color a much larger, more intricate structure. The 'improvement' likely refers to refining this recursive step or the color assignment logic to be more efficient, and the 'competitive ratio' measures how close this algorithmic coloring comes to the absolute minimum number of colors possible, in the worst-case scenario."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ == _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ **then**\n\n**170** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51, \ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc40\ud835\udc56\ud835\udc5b\ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ ) ;\n\n**Packet-transmission function definitions:**\n\n**171** BBR_Handle_Restart_From_Idle():"}, {"role": "assistant", "content": "**Mechanism:** During the 'ProbeRTT' state, the system intentionally limits its outgoing data flow (congestion window, 'cwnd') to a very small, fixed amount, typically 4 packets. The 'min' function acts as a hard cap, ensuring 'cwnd' never exceeds this value. The underlying mechanism is to purposefully undershoot the network capacity to drain any standing queues in intermediate routers. By clearing these queues, the measured Round Trip Time (RTT) will drop to its absolute minimum value, reflecting the true propagation delay without any waiting. This minimum RTT is a crucial measurement for BBR to accurately estimate the network's maximum available bandwidth. The 'BBR_Handle_Restart_From_Idle()' function implies a specific procedure to safely re-engage data transmission after a period of inactivity, ensuring a controlled startup.\n\n**Explanation:** This code snippet describes a specific, temporary adjustment to how much data a sender can put onto the network. Imagine a program managing a queue of tasks. When the network's state machine (like a 'switch' statement or a series of 'if/else if' blocks) enters a 'ProbeRTT' mode, it's akin to a diagnostic phase. During this phase, the program explicitly sets a hard limit on the 'cwnd' variable. The 'min' function ensures 'cwnd' is capped at 'BBRMinPipeCwnd' (usually a very small constant like 4 packets), regardless of its previous value. This mechanism is crucial because by sending very little data, any data already buffered in the network's intermediate queues gets flushed. This allows the system to measure the true 'pipe RTT' \u2013 the time it takes for a packet to travel without any queuing delays \u2013 which is essential for BBR to accurately calculate the network's capacity. 'BBR_Handle_Restart_From_Idle()' is a separate routine, analogous to a 'reset_state()' function, which is called when the connection, after a period of inactivity, begins sending data again, ensuring a controlled restart rather than an uncontrolled burst."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Introduction**\n\nHumans are capable of extrapolating from their existing knowledge to unfamiliar scenarios and generating\nnew knowledge\u2014a process that constitutes reasoning (Lombrozo, 2024). In contrast, large language models\n(LLMs) exhibit a form of cognitive dissonance unprecedented in human cognition: they master complex skills\n(Chervonyi et al., 2025; Jiang et al., 2024) while lacking simpler prerequisite ones (McCoy et al., 2024; Dziri\net al., 2023; Berglund et al., 2023), and solve challenging problems while failing on trivial variants (Shao et al.,\n2025; Li et al., 2025b). This dissociation between high benchmark performance and the lack of generalization\nsuggests that models may be achieving correct outputs through mechanisms fundamentally different from\nthe robust cognitive structures underlying human reasoning. Current training and evaluation paradigms\nreward reasoning outcomes without examining the cognitive processes that produce them (Lambert et al.,\n2024), and therefore cannot distinguish between genuine reasoning and memorization (Wu et al., 2025). This\ncreates a measurement crisis: we lack the conceptual framework to characterize what reasoning behaviors\nshould manifest in models and the empirical methods to assess whether they do.\n\nTo understand how cognitive elements manifest in reasoning behaviors, consider a child playing with LEGO\nblocks. Figure 1 illustrates how the child orchestrates multiple cognitive elements: establishing goals, decomposing the task into parts, verifying connections, monitoring progress, and reformulating failed approaches.\nThis flexible coordination of diverse cognitive processes characterizes reasoning. However, contemporary\nresearch on LLM reasoning only attempts scattered investigations of specific behaviors such as verification\n(Gandhi et al., 2025), decomposition (Xu et al., 2025), and self-monitoring (Marjanovi\u0107 et al., 2025). Our\nmeta-analysis of 1,598 arXiv LLM reasoning papers on LLM reasoning reveals this fragmentation quantita\n\n2\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-2-0.png)\n\n**Reasoning Representation**\n\nSpatial representation\n\n**Reasoning Operations**\n\n**Reasoning Invariants**\n\nConceptual processing Productivity\n\n**Meta-Cognitive Control**\n\nGoal management\n\nEvaluation\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-2-1.png)\n\nVerification Adaptive detail management Backtracking\n\nFigure 1: An example of reasoning behaviors present in a reasoning trace for building a LEGO spaceship.\nWe organize the different behaviors along the four dimensions of our taxonomy, as shown in Table 1.\n\ntively (Figure 2): 55% examine sequential organization (e.g. reasoning step-by-step), while only 8% study\nbackward chaining (e.g. reverse engineering the solution from the answer). This concentration on easily\nquantifiable behaviors creates a striking asymmetry when compared with human reasoning research, which\nencompasses diverse phenomena, including analogical transfer (Gentner, 1983; Holyoak & Thagard, 1989),\ncausal inference (Sloman & Sloman, 2009; Gopnik et al., 2004), representational flexibility (Ohlsson, 1992;\nKnoblich et al., 1999), and meta-cognitive control (Nelson, 1990; Flavell, 1979). Each of these captures\ndifferent facets of how humans navigate uncertainty, integrate knowledge, and adapt to novel situations.\nWithout a comprehensive framework spanning this range of cognitive elements, we risk optimizing what we\nmeasure rather than what matters, potentially mistaking narrow competence for broad reasoning capability.\n\nTo address this gap, we **introduce** **a** Distribution of Cognitive Elements Considered by LLM Reasoning Papers\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-2-2.png)\n**unified taxonomy of cognitive foun-** **70** ~~Score~~\n**dations** by synthesizing established theo- **60** ~~Present~~\nries of problem-solving, mental represen- **50** Partially Present\ntation, and meta-cognition (Sweller, 1988; **40**\nJohnson-Laird, 1983; Fodor, 1975). The **3020**\ntaxonomy includes four dimensions: **1)**"}, {"role": "assistant", "content": "**Mechanism:** Large Language Models (LLMs) demonstrate a peculiar 'split personality' in their performance: they can execute highly complex tasks, yet fail at simpler, foundational elements necessary for human-like reasoning. This suggests their success often stems from interpolating vast amounts of memorized data patterns rather than deriving solutions from first principles or employing robust, generalized internal algorithms. Consider it like a vast lookup table or a very complex pattern matcher rather than a general-purpose function f(x). When the input x deviates even slightly from the learned patterns or requires a truly novel combination, the 'lookup' fails because the underlying generalized 'logic' (like an if-else statement or a loop) isn't present or isn't being invoked appropriately.\n\n**Explanation:** The core issue is that current evaluation often rewards the output of a process without inspecting the process itself. If a model correctly answers a complex question, we don't differentiate if it reasoned to that answer (using a sequence of logical steps, much like a human debugging a program or following an algorithm) or if it merely recalled a similar answer from its training data (akin to a hash map returning a pre-computed value). This creates a 'measurement crisis' because we lack a standardized 'API' or 'interface definition' for what constitutes true reasoning components. Human cognition, illustrated by the LEGO example, involves a coordinated system of 'subroutines' like goal management, task decomposition, verification, and adaptive control. LLM research often focuses on isolated 'subroutines' (e.g., just sequential processing) without understanding how these should integrate or if they are truly generalizable. The paper proposes a 'unified taxonomy' which acts like a comprehensive architectural blueprint, defining these cognitive 'modules' and their expected interactions, to guide future development and evaluation towards genuine, generalizable reasoning."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nOver the past year, we have witnessed the emergence of\nreasoning LLMs, such as OpenAI-o1 [40], DeepSeek-R1 [9]\nand Gemini-2.5Pro [15], exhibiting remarkable capability improvements in mathematical reasoning, programming, and\nmultidisciplinary knowledge tasks [6]. A key driver behind\nthese improvements is the use of reinforcement learning\n(RL), which has become the standard approach for endowing LLMs with strong reasoning capabilities [9, 51, 56, 66].\nHowever, this RL approach faces efficiency challenges due to\nthe unique workload characteristics involved. Our analysis\nof self-collected traces (Figure 1) and production traces from\nByteDance (Figure 2) identifies the following key characteristics of reasoning RL process:\n\n\u2217 Equal Contribution. Part of the work was done while Shang Yang was\ninterning at NVIDIA.\n\n|Rollout|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|||Other|Other|Other|\n||||||\n||||||\n||||||\n\n|Rollou|t Inference&Train|Col3|Col4|Col5|Col6|TrainDrafter|Col8|Col9|Col10|Col11|Col12|Col13|Col14|AdaptiveSD|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||**Next Step**|**Next Step**|\n||||||||||||||||\n||**Idle**||||||||||||||\n||||||||||||||||\n||||||||||||||||\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-0-0.png)\n\n**(b)** Illustration of the time line of RL reasoning step w./wo. TLT.\n**Figure 1.** Observed issues of long-tail generation (rollout)\nand workload imbalance in reasoning RL. TLT system effectively addresses these challenges with adaptive drafter.\n\n**(1) Unbalanced Rollout and Training Time** . During RL,\nthe first and most time-consuming stage is _rollout_, where\nthe model generates numerous candidate responses. These\nresponses are then used in subsequent _inference_ and _training_\nstages to update the model. As shown in Figure 1 (a), the\nrollout phase consumes a disproportionately large fraction\n\n\u223c\n( 85%) of the total step time, becoming a primary bottleneck.\n**(2) Persistent Long-Tail Distribution** . A major source of\nRL training inefficiency arises from the _long-tail distribu-_\n_tion_ of rollout response lengths. As shown in Figure 1(a),\nalthough most generated sequences are relatively short, a\nsmall fraction extends to extreme lengths. Crucially, this inefficiency is not an occasional occurrence but a persistent pattern observed throughout long-term training, as evidenced\nby ByteDance\u2019s production traces (Figure 2). In most RL steps,\na few responses reach the maximum configured length, while\nthe majority remain substantially shorter. The pronounced\ngap between this maximum length and the 75th percentile\n(p75) underscores significant resource under-utilization.\n**(3) Substantial Time and Resource Demands** . Figure 2\nshows that reasoning RL training for a 32B model took 11\ndays to complete only 385 steps, even using 128 GPUs. Individual training steps averaged approximately 40 minutes,\nwhile periodic evaluations (conducted every 5 steps) required\nroughly 20 minutes each, demonstrating the process is extremely time and resource-intensive.\n\n1\n\nVeRL Ours\n\nTime Breakdown\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n3\n\n2\n\n1\n\n0\n\n0 10K 20K 30K\nRollout Response Length (tokens)\n\n**(a)** Distribution of response length and RL step time breakdown.\n\n_W1_\n\n_W2_\n\n_W3_\n\n_W4_\n\n_W5_\n\n_Time_ **Vanilla** **Ours**\n\nExisting systems [35, 52, 53, 60, 64, 65, 72] for RLHF (RL\nfrom Human Feedback) primarily focus their optimization\nefforts on managing multiple models, optimizing data transfer, and orchestrating device allocation across the different\nphases. However, they neglect tackling the rollout bottleneck,\nthereby remaining inefficient for reasoning RL tasks. Critically, reasoning rollouts are often over an order of magnitude\nlonger than typical RLHF outputs [42, 53, 72], giving reasoning RL fundamentally different workload characteristics and\ndemanding distinct system-level optimizations.\nWhile various acceleration techniques exist for LLM serving, many are ill-suited for the RL training context. Methods\nlike quantization [11, 30] and model sparsity [33, 63], despite\noffering speedups, are typically _lossy_, risking model accuracy\ndegradation and altering output probabilities. We identify\nSpeculative Decoding (SD) [5, 22] as a highly suitable approach. SD utilizes a lightweight draft model to generate\ntoken sequences speculatively, which are then verified in\nparallel by the main target model. SD is particularly wellsuited for RL training due to two primary merits: (1) _Mathe-_\n_matically Lossless_ . The output distribution remains identical\nto the target model\u2019s original distribution; (2) _Efficient for_\n_Long-Tail_ . SD enhances throughput by shifting the process\nfrom being memory-bound towards compute-bound, which\nis particularly effective for the long-tail phase of RL rollouts,\nwhere effective batch sizes are typically small.\nHowever, existing speculative decoding techniques [4, 14,\n16, 26, 36, 67] are designed for static inference scenarios,\nwhere the target model is fixed. Applying them within the\ndynamic reasoning RL training is fundamentally non-trivial,\npresenting significant challenges: (1) _Evolving Target Model_ :\nthe target model\u2019s weights are constantly updated during\nRL training, making the draft model progressively stale, severely undermining the effectiveness of SD. (2) _Draft Model_\n_Training Costs_ : Effective SD often relies on specialized draft\nmodels [2, 14, 25\u201327, 67], which require extra training to\nalign with the target model, introducing additional overhead\nand complexity for users. (3) _Scheduling Complexity_ : SD performance is sensitive to batch size and hyperparameters\n(e.g., draft depth). Reasoning RL rollouts, however, are characterized by dynamically fluctuating effective batch sizes\nas sequences complete at different times, necessitating an\neffective strategy selector for efficient SD deployment.\nTo address these challenges, we introduce TLT, an efficient\nsystem for reasoning RL training featuring adaptive speculative decoding. TLT aims to mitigate the long-tail rollout\nbottleneck while guaranteeing mathematical losslessness.\nThe core design of TLT derives from the following insights:\nFirst, _Exploiting Rollout Bubbles_ . The characteristically long\nduration of RL rollouts provides ample time to utilize GPU\nresources that progressively become available due to the\nlong-tail nature. Resources freed as sequences complete can\nthus be repurposed for other tasks, such as draft model training, without additional costs. Second, _Non-Blocking Drafter_\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-1-0.png)\n\n5K\n\n0\n\n0 50 100 150 200 250 300 350\nRL Training Steps (11 days over 128 GPUs)\n\n**Figure 2. RL Training trace from ByteDance** [3], based\non the Qwen2.5-32B model [46] and executed on H20 96GB\nGPUs. \"p75\" denotes the 75th percentile and more granular\npercentile data were not provided in the original source.\n\n_Training_ . Draft model training can be decoupled from full\nrollout completion; training asynchronously on partial or\nreadily available data allows its computation to be effectively\noverlapped with ongoing rollouts.\nIncorporating aforementioned insights, we build TLT with\nmultiple system optimizations: (1) Adaptive Drafter (\u00a74): We\nadopt a lightweight draft model continuously adapted via\nour spot trainer, innovatively addressing the evolving target model challenge arising from RL training. This trainer\nleverages idle GPU resources during long-tail rollouts for opportunistic, preemptible drafter updates, ensuring alignment\nwith the evolving target model without adding overhead.\n(2) Adaptive Rollout Engine (\u00a75): TLT maintains a memoryefficient pool of pre-captured CUDAGraphs and leverages the\nBEG-MAB tuner to adaptively select suitable SD strategies\nfor each input batch. It also supports model-free speculative\ndecoding for early rollout steps. Figure 1(b) presents an intuitive illustration of the TLT workflow, where the system\nautomatically leverages idle resources (e.g., workers W3-W5)\nfor opportunistic draft model training (blue blocks), counteracting performance dips caused by target model updating\nwithout additional costs. Meanwhile, TLT adaptively enables\nspeculative decoding (blue hatched blocks) during these periods of resource under-utilization for better efficiency.\nBy synergistically combining an adaptive draft model with\ncoordinated scheduling, TLT effectively mitigates the longtail issue inherent to RL training. We evaluated TLT on various model architectures and real-world datasets. Experiments demonstrate that TLT significantly accelerates endto-end training throughput, while preserving model output\nquality and minimizing resource waste. Furthermore, the\nprocess yields an effective draft model suitable for future\ndeployment as a free byproduct."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is opportunistic compute cycle reclamation for 'just-in-time' draft model training and adaptive speculative decoding. During the rollout phase of RL, sequences complete asynchronously, leading to a 'long-tail' where a few long sequences dictate the batch completion time, leaving GPU resources idle as shorter sequences finish. TLT identifies these 'rollout bubbles' of idle GPU time and dynamically assigns them to train a lightweight draft model in a non-blocking, asynchronous manner. This ensures the draft model remains relevant despite the evolving target model weights. Subsequently, an adaptive engine uses this refreshed draft model with Speculative Decoding to accelerate token generation, specifically benefiting the long-tail sequences by transforming memory-bound operations into compute-bound ones.\n\n**Explanation:** Reinforcement Learning (RL) for Large Language Models (LLMs) is bottlenecked by the 'rollout' phase, where the model generates many candidate responses. This phase consumes around 85% of the total time due to a persistent 'long-tail' distribution of response lengths; most responses are short, but a few are extremely long. Standard batch processing means resources wait for the longest sequence, leading to significant GPU under-utilization (like a 'map' function where the longest key processing determines the overall time). Speculative Decoding (SD) can speed this up by using a small 'draft' model to guess tokens, then having the main model verify them in parallel. However, in RL, the main model constantly changes its weights, making a static draft model quickly 'stale' (like a cached lookup table that's no longer valid). TLT tackles this by creating a 'spot trainer' that acts like a background thread. When GPU resources become idle because short sequences in a batch have finished (the 'rollout bubbles' or 'idle cycles'), this spot trainer immediately uses those cycles to update the draft model. This keeps the draft model perpetually aligned with the evolving target model without *additional* dedicated training time. Then, an 'adaptive rollout engine' dynamically selects the best SD strategy (like an 'if-else' logic or a small decision tree) for each sub-batch, ensuring optimal throughput even as effective batch sizes fluctuate. By continuously updating the draft model using 'free' cycles and intelligently applying SD, TLT effectively shortens the critical long-tail sequences, reducing overall rollout time while guaranteeing the final output distribution is mathematically identical to the original target model's."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _< \ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ __\ud835\udc5a\ud835\udc4e\ud835\udc65_ **then**\n\n~~[\u221a]~~ 3\n**20** _\ud835\udc3e_ \u2190\u2212\n\n_\ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc36_ \u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_\n\n**21** _\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b_ _ _\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61_ \u2190\u2212 _\ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a conditional branch, an 'if' statement, comparing two numerical states: a 'current value' (`cwnd`) and a 'historical maximum' (`Wlast_max`). If the current value is strictly less than the historical maximum, a specific set of operations is triggered. These operations involve a subtraction (`Wlast_maxC - cwnd`) to calculate a 'delta' or 'gap' (`K`), and a direct assignment of the `historical_maximum` to a 'reference point' variable (`origin_point`).\n\n**Explanation:** This snippet effectively implements a state-dependent adjustment or a 'reset' trigger. If a system's current capacity (`cwnd`) falls below a recorded peak (`Wlast_max`), it signals that the system is not operating at its historical best. The calculation for `K` then quantifies the difference between a potential new target maximum (`Wlast_maxC`) and the current state, providing a value that could be used for scaling up or recovery. Simultaneously, `origin_point` acts like a `pointer` or a `snapshot` of the `Wlast_max` at the moment the condition was met. This allows a larger algorithm to remember the previous peak when making adjustments, ensuring that recovery or expansion isn't based solely on the current, possibly depressed, state. It's a fundamental conditional logic, analogous to checking `if (current_count < max_ever_count)` in a loop, then updating variables based on that fact."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_there exits a node in_ `UndecidedNeighbors` _has output \u22a5_ **then**\n\n**21** From this point onward, disregard the rest of the algorithm and output _\u22a5_"}, {"role": "assistant", "content": "**Mechanism:** This is a 'fail-fast' mechanism, essentially a critical early exit condition for the algorithm.\n\n**Explanation:** Think of `UndecidedNeighbors` as a collection (like a hash set) of sub-problems or states that need resolution. The 'output \u22a5' signifies an unresolvable or invalid state for a particular node. When this condition is met, the algorithm immediately short-circuits. It's akin to a boolean check in a loop: if 'any(node.output == invalid for node in UndecidedNeighbors)' is true, then break and return 'invalid'. This prevents further, potentially costly, computation on a path that is guaranteed to lead to an ultimately invalid result, ensuring that resources aren't wasted processing what is already known to be a dead end."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this paper, we have proposed _CorrectHDL_, an agentic LLM-assisted\nHDL design framework that leverages HLS-generated HDL as a\nfunctional reference. Starting from a C/C++ program, complex algorithms are decomposed into LLM-friendly submodules whose HDL\nimplementations are generated by the LLM. Syntax errors are corrected via RAG, and functional discrepancies are resolved through\ndifferential verification against the HLS-generated golden reference.\nExperimental results on 12 real-world benchmarks show that _Correc-_\n_tHDL_ significantly improves both syntax and functional pass rates\nof LLM-generated HDL, while achieving lower area and power than\nHLS-generated designs and approaching the efficiency of manually\ncrafted designs. Future work will integrate C/C++ program generation from natural language to establish a complete LLM-assisted\nworkflow from natural language to HDL design. The LLM-generated\ncircuits will also be optimized further to explore their potential in\nmatching and even surpassing human-engineered designs.\n\n**References**\n\n[1] Tinghuan Chen, Grace Li Zhang, Bei Yu, Bing Li, Ulf Schlichtmann, \u201cMachine\nLearning in Advanced IC Design: A Methodological Survey,\u201d Design & Test, 2023.\n\n[2] Jason Cong, Jason Lau, Gai Liu, Stephen Neuendorffer, Peichen Pan, Kees Vissers,\nZhiru Zhang, \u201cFPGA HLS Today: Successes, Challenges, and Opportunities,\u201d ACM\nTransactions on Reconfigurable Technology and Systems (TRETS), 2022.\n\n[3] Jason Cong, Bin Liu, Stephen Neuendorffer, Juanjo Noguera, Kees Vissers, Zhiru\nZhang, \u201cHigh-Level Synthesis for FPGAs: From Prototyping to Deployment,\u201d IEEE\nTransactions on CAD of Integrated Circuits and Systems (TCAD), 2011.\n\n[4] Jason Cong, Zhenman Fang, Muhuan Huang, Libo Wang, and Di Wu, \"CPU-FPGA\nCoscheduling for Big Data Applications,\" IEEE Design & Test, 2018.\n\n[5] Atefeh Sohrabizadeh, Cody Hao Yu, Min Gao, and Jason Cong, \u201cAutoDSE: Enabling\nSoftware Programmers to Design Efficient FPGA Accelerators,\u201d ACM Transactions\non Design Automation of Electronic Systems (TODAES), 2022.\n\n[6] Shailja Thakur, Jason Blocklove, Hammond Pearce, Benjamin Tan, Siddharth Garg,\nRamesh Karri, \u201cAutoChip: Automating HDL Generation Using LLM Feedback,\u201d\nArxiv Preprint: 2311.04887, 2023.\n\n[7] Jason Blocklove, Siddharth Garg, Ramesh Karri, Hammond Pearce, \u201cChip-Chat:\nChallenges and Opportunities in Conversational Hardware Design,\u201d ACM/IEEE\nInternational Symposium on Machine Learning for CAD (MLCAD), 2023.\n\n[8] Andre Nakkab, Sai Qian Zhang, Ramesh Karri, Siddharth Garg, \u201cRome was Not\nBuilt in a Single Step: Hierarchical Prompting for LLM-based Chip Design,\u201d IEEE\nInternational Symposium on Machine Learning for CAD (MLCAD), 2024.\n\n[9] Yonggan Fu, Yongan Zhang, Zhongzhi Yu, Sixu Li, Zhifan Ye, Chaojian Li, Cheng\nWan, Yingyan Celine Lin, \u201cGPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models,\u201d IEEE/ACM International\nConference on Computer Aided Design (ICCAD), 2023.\n\n[10] Yun-Da Tsai, Mingjie Liu, Haoxing Ren, \u201cAutomatically Fixing RTL Syntax Errors\nwith Large Language Model,\u201d ACM Design Automation Conference (DAC), 2024.\n\n[11] Kangwei Xu, Denis Schwachhofer, Jason Blocklove, Ilia Polian, Peter Domanski,\nDirk Pfl\u00fcger, Siddharth Garg, Ramesh Karri, Ozgur Sinanoglu, Johann Knechtel,\nZhuorui Zhao, Ulf Schlichtmann, Bing Li, \u201cLarge Language Models (LLMs) for\nElectronic Design Automation (EDA),\" IEEE SOCC, 2025.\n\n[12] Chandan K. Jha, M. Hassan, K. Qayyum, S. Ahmadi-Pour, K. Xu, R. Qiu, J. Blocklove,\nL. Collini, A. Nakkab, U. Schlichtmann, Grace L. Zhang, R. Karri, B. Li, S. Garg, R.\nDrechsler, \u201cLarge Language Models (LLMs) for Verification, Testing, and Design,\u201d\nIEEE European Test Symposium (ETS), 2025.\n\n[13] Bing-Yue Wu, Utsav Sharma, Austin Rovinski, Vidya A Chhabria, \u201cOpenROAD\nAgent: An Intelligent Self-Correcting Script Generator for OpenROAD,\u201d IEEE International Conference on LLM-Aided Design (ICLAD), 2025.\n\n[14] Yuan Pu, Zhuolun He, Shutong Lin, Jiajun Qin, Xinyun Zhang, Hairuo Han,\nHaisheng Zheng, Yuqi Jiang, Cheng Zhuo, Qi Sun, David Z. Pan, Bei Yu, \u201cA MultiModal EDA Tool Documentation QA Framework Leveraging Retrieval Augmented\nGeneration,\u201d IEEE/ACM International Conference on CAD (ICCAD), 2025.\n\n[15] Yingbing Huang, Lily Jiaxin Wan, Hanchen Ye, Manvi Jha, Jinghua Wang, Yuhong\nLi, Xiaofan Zhang, Deming Chen, \u201cNew solutions on LLM acceleration, optimization,\nand application,\u201d IEEE/ACM Design Automation Conference (DAC), 2024.\n\n[16] Zesong Jiang, Yuqi Sun, Qing Zhong, Mahathi Krishna, Deepak Patil, Cheng Tan,\nSriram Krishnamoorthy, Jeff Zhang, \u201cMACO: A Multi-Agent LLM-Based Hardware/Software Co-Design Framework for CGRAs,\u201d arXiv: 2509.13557, 2025.\n\n[17] Bing-Yue Wu, Utsav Sharma, Sai Rahul Dhanvi Kankipati, Ajay Yadav, Bintu Kappil\nGeorge, Sai Ritish Guntupalli, Austin Rovinski, Vidya A Chhabria, \u201cEDA Corpus: A\nLarge Language Model Dataset for Enhanced Interaction with OpenROAD,\u201d IEEE\nInternational Conference on LLM-Aided Design (ICLAD), 2024.\n\n[18] Zeng Wang, Minghao Shao, Rupesh Karn, Likhitha Mankali, Jitendra Bhandari,\nRamesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel, \u201cSALAD:\nSystematic Assessment of Machine Unlearning on LLM-Aided Hardware Design,\u201d\nIEEE International Symposium on Machine Learning for CAD (MLCAD), 2023.\n\n[19] Lakshmi Likhitha Mankali, Jitendra Bhandari, Manaar Alam, Ramesh Karri, Michail\nManiatakos, Ozgur Sinanoglu, Johann Knechtel, \u201cRTL-breaker: Assessing the Security of LLMs Against Backdoor Attacks on HDL Code Generation,\u201d ACM Design,\nAutomation & Test in Europe Conference & Exhibition (DATE), 2025.\n\n[20] Muhammad Hassan, Sallar Ahmadi-Pour, Khushboo Qayyum, Chandan Kumar Jha,\nRolf Drechsler, \u201cLLM-guided Formal Verification Coupled with Mutation Testing,\"\nIEEE Design, Automation & Test in Europe Conference (DATE), 2024.\n\n[21] Kangwei Xu, Ruidi Qiu, Zhuorui Zhao, Grace Li Zhang, Ulf Schlichtmann, Bing Li,\n\u201cLLM-Aided Efficient Hardware Design Automation,\u201d arXiv: 2410.18582, 2024.\n\n[22] Yongan Zhang, Yonggan Fu, Zhongzhi Yu, Kevin Zhao, Cheng Wan, Chaojian\nLi, Yingyan Celine Lin, \u201cAn Automated Data Generation and Validation Flow for\nLLM-Assisted Hardware Design,\" Design Automation Conference (DAC), 2024.\n\n[23] Shailja Thakur, Baleegh Ahmad, Hammond Pearce, Benjamin Tan, B. D. Gavitt,\nRamesh Karri, Siddharth Garg, \u201cA Large Language Model for Verilog Code Generation,\u201d ACM Transactions on Design Automation of Electronic Systems, 2024.\n\n[24] Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, Haoxing Ren, \u201cVerilogEval:\nEvaluating large language models for verilog code generation,\u201d IEEE/ACM International Conference on Computer Aided Design (ICCAD), 2023.\n\n[25] Zhuorui Zhao, Ruidi Qiu, Ing-Chao Lin, Grace Li Zhang, Bing Li, Ulf Schlichtmann, \u201cEnhancing Verilog Code Generation from Large Language Models via\nSelf-Consistency,\u201d International Symposium on Quality Electronic Design, 2025.\n\n[26] Zhuorui Zhao, Bing Li, Grace Li Zhang, Ulf Schlichtmann, \u201cVFocus: Better Verilog\nGeneration from Large Language Model via Focused Reasoning,\u201d IEEE SOCC, 2025.\n\n[27] Shailja Thakur, Baleegh Ahmad, Zhenxing Fan, Hammond Pearce, Benjamin Tan,\nRamesh Karri, Brendan Dolan-Gavitt, Siddharth Garg, \u201cBenchmarking Large Language Models for Automated Verilog RTL Code Generation,\" IEEE/ACM Design,\nAutomation & Test in Europe Conference & Exhibition (DATE), 2023.\n\n[28] Matthew DeLorenzo, Animesh Basak Chowdhury, Vasudev Gohil, Shailja Thakur,\nRamesh Karri, Siddharth Garg, Jeyavijayan Rajendran, \u201cLLM-based High-Quality\nRTL Code Generation Using MCTS,\u201d arXiv preprint: 2402.03289, 2024.\n\n[29] Prithwish Basu Roy, Akashdeep Saha, Manaar Alam, Johann Knechtel, Michail\nManiatakos, Ozgur Sinanoglu, Ramesh Karri, \u201cVeritas: Deterministic Verilog Code\nSynthesis from LLM-Generated Conjunctive Normal Form,\u201d arXiv: 2506.00005.\n\n[30] Wenhao Sun, Bing Li, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann, \u201cParadigm-Based Automatic HDL Code Generation Using LLMs,\u201d ACM/IEEE\nInternational Symposium on Quality Electronic Design (ISQED), 2025.\n\n[31] Zhiyuan Yan, Wenji Fang, Mengming Li, Min Li, Shang Liu, Zhiyao Xie, Hongce\nZhang, \u201cAssertLLM: Generating and Evaluating Hardware Verification Assertions\nfrom Design Specifications via Multi-LLMs,\u201d IEEE/ACM ASP-DAC, 2025.\n\n[32] Ruidi Qiu, Grace Li Zhang, Rolf Drechsler, Ulf Schlichtmann, Bing Li, \u201cAutoBench:\nAutomatic Testbench Generation and Evaluation Using LLMs for HDL Design,\u201d\nIEEE International Symposium on Machine Learning for CAD (MLCAD), 2024.\n\n[33] Ruidi Qiu, Grace Li Zhang, Rolf Drechsler, Ulf Schlichtmann, Bing Li, \u201cCorrectBench: Automatic Testbench Generation with Functional Self-Correction using\nLLMs for HDL Design,\u201d Design, Automation & Test in Europe Conference, 2025.\n\n[34] Luca Collini, Siddharth Garg, Ramesh Karri, \u201cC2HLSC: Can LLMs Bridge the\nSoftware-to-Hardware Design Gap?,\u201d IEEE ICLAD, 2024.\n\n[35] Luca Collini, Siddharth Garg, Ramesh Karri, \u201cLeveraging Large Language Models\nto Bridge the Software-to-Hardware Design Gap,\u201d ACM TODAES, 2025.\n\n[36] Luca Collini, Andrew Hennessee, Ramesh Karri, Siddharth Garg, \u201cCan reasoning models reason about hardware? an agentic HLS perspective,\u201d arXiv\npreprint:2503.12721, 2025.\n\n[37] Kangwei Xu, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann, Bing\nLi, \u201cAutomated C/C++ Program Repair for High-Level Synthesis via Large Language\nModels,\u201d International Symposium on Machine Learning for CAD, 2024.\n\n[38] Chenwei Xiong, Cheng Liu, Huawei Li, Xiaowei Li, \u201cHLSPilot: LLM-based HighLevel Synthesis,\u201d ACM/IEEE International Conference on CAD (ICCAD), 2024.\n\n[39] Kangwei Xu, Bing Li, Grace Li Zhang, Ulf Schlichtmann, \u201cHLSTester: Efficient Testing of Behavioral Discrepancies with LLMs for High-Level Synthesis,\u201d IEEE/ACM\nInternational Conference on Computer Aided Design (ICCAD), 2025.\n\n[40] Stefan Abi-Karam, Cong Hao, \u201cHLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level Synthesis Design Tasks,\u201d IEEE ICLAD, 2025.\n\n[41] Zhaojian Yu, Yilun Zhao, Arman Cohan, Xiao-Ping Zhang, \u201cHumanEval Pro and\nMBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation,\u201d\nAssociation for Computational Linguistics (ACL), 2025.\n\n[42] Wenpin Hou, Zhicheng Ji, \u201cComparing large language models and human programmers for generating programming code,\u201d Advanced Science, 2025.\n\n[43] Kangwei Xu, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann, Bing\nLi, \u201cHLSRewriter:Efficient Refactoring and Optimization of C/C++ Code with LLMs\nfor HLS,\u201d ACM Transactions on Design Automation of Electronic Systems, 2025.\n\n[44] Sakari Lahti, Panu Sj\u00f6vall, Jarno Vanne, T. H\u00e4m\u00e4l\u00e4inen, \"Are We There Yet? A\nStudy on the State of High-Level Synthesis,\" IEEE TCAD, 2019.\n\n[45] Yifan Zhang, Q. Cao, Jie Yao, Hong Jiang, \"R-LDPC: Refining Behavior Descriptions\nin HLS to Implement High-throughput LDPC Decoder,\" IEEE/ACM DATE, 2023.\n\n[46] Lan Huang, Da-Lin Li, Kang-Ping Wang, Teng Gao, Adriano Tavares, \"A Survey\non Performance Optimization of High-Level Synthesis Tools,\" JCST, 2020.\n\n[47] K. Xu, et al., \u201cLogic Design of Neural Networks for High-Throughput and LowPower Applications,\u201d IEEE/ACM Asia and South Pacific Design Automation Conference (ASP-DAC), 2024.\n\n[48] R. Nane, V. Sima, C. Pilato, J. Choi, B. Fort, A. Canis, Y. Chen, H. Hsiao, S. Brown,\nF. Ferrandi, J. Anderson, K. Bertels, \"A Survey and Evaluation of FPGA HLS Tools,\"\nIEEE Transactions on CAD of Integrated Circuits and Systems, 2016\n\n[49] \u201cOpenAI API,\u201d Accessed: 2025. [Online]. Available: https://platform.openai.com/.\n\n[50] N. Reimers, I. Gurevych, \u201cSentence-BERT: Sentence Embeddings using Siamese\nBERT-Networks,\u201d Empirical Methods in Natural Language Processing, 2019.\n\n[51] W. Eric Wong, Ruizhi Gao, Yihao Li, Rui Abreu, Franz Wotawa, \u201cA Survey on\nSoftware Fault Localization,\u201d IEEE Transactions on Software Engineering, 2016.\n\n[52] Brandon Reagen, Robert Adolf, Yakun Sophia Shao, Gu-Yeon Wei, David Brooks,\n\"MachSuite: Benchmarks for accelerator design and customized architectures,\" IEEE\nInternational Symposium on Workload Characterization (IISWC), 2014.\n\n[53] Yuko Hara, Hiroyuki Tomiyama, Shinya Honda, Hiroaki Takada and Katsuya Ishii,\n\"CHStone: A benchmark program suite for practical C-based high-level synthesis,\"\nIEEE International Symposium on Circuits and Systems (ISCAS), 2008.\n\n[54] \u201cSiemens EDA Catapult High-Level Synthesis Tools,\u201d Accessed: 2023. [Online].\nAvailable: https://eda.sw.siemens.com/en-US/ic/catapult-high-level-synthesis/hls/.\n\n[55] \u201cSiemens EDA QuestaSIM RTL Simulator,\u201d Accessed: 2023. [Online]. Available:\nhttps://eda.sw.siemens.com/en-US/ic/questa-one/simulation/questa-one-sim/.\n\n[56] \u201cOpenCores Manual HDL Designs,\u201d Accessed: 2025. [Online]. Available:\nhttps://opencores.org/.\n\n[57] \u201cGitHub Manual HDL Designs,\u201d Accessed: 2025. [Online]. Available:\nhttps://github.com/."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a multi-stage, iterative refinement loop driven by a Large Language Model (LLM) for both syntax and functional correctness. It starts with a 'divide and conquer' strategy, breaking down a complex C/C++ program into manageable submodules, similar to how a large software project is structured into smaller functions or classes.\n\n**Explanation:** For each submodule, the LLM generates an initial Hardware Description Language (HDL) implementation. Syntactic errors are addressed first: the system uses Retrieval Augmented Generation (RAG) by taking the error message or problematic code snippet, querying a corpus of correct HDL examples (like looking up solutions in a documentation database), and feeding that context back to the LLM to guide corrections. This acts as an intelligent 'syntax linter' with a self-correction loop. Functional correctness is then ensured by a differential verification step. A 'golden reference' HDL for the same C/C++ submodule is generated by a reliable, but often suboptimal, High-Level Synthesis (HLS) tool. Both the LLM-generated HDL and the HLS-generated golden reference are simulated. Their outputs are then compared cycle-by-cycle or for a set of inputs. Any discrepancy between the LLM's output and the golden reference is precisely identified and presented as feedback to the LLM. This feedback, similar to a unit test failure with specific expected vs. actual values, prompts the LLM to iteratively revise its HDL until it functionally matches the golden reference. The LLM's flexibility, combined with this robust verification feedback, allows it to explore a wider design space than fixed HLS algorithms, resulting in hardware with lower area and power consumption once functional correctness is established."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nBLAB (Ahia et al., 2025) 417 Qwen/Qwen3-Omni-30B-A3B-Thinking 1 4,917\nYang et al. (2025)\n\nMMAR (Ma et al., 2025) 888\nMMAU-Pro (Kumar et al., 2025) 3,612\n**Total (Audio Data)** **4,917** **Total (Audio Models)**"}, {"role": "assistant", "content": "**Mechanism:** The mechanism is a straightforward data aggregation and summation. It's like a simple ledger system where named entries are associated with specific counts or quantities, which are then summed into category totals.\n\n**Explanation:** Think of this as a software inventory list, similar to an array of objects or records in a database. Each line item (like 'BLAB' or 'MMAR') acts as a record with an identifier and a numerical attribute, representing a quantity of 'audio data'. For example, BLAB provides 417 units of data. The system then iterates through these records, summing the quantities associated with 'Audio Data' into a running total, much like a `for` loop accumulating values into a `sum` variable. Separately, specific 'Audio Models' are identified, like the 'Qwen/Qwen3-Omni-30B-A3B-Thinking' model, which has a count of '1'. The '30B' in the model name signifies its parameter count, indicating a specific computational scale, rather than a quantity of models itself. The final 'Total' lines are merely the output of these summation operations, providing an aggregated count of categorized resources."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc61\ud835\udc50\ud835\udc5d_\ud835\udc53\ud835\udc5f\ud835\udc56\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60_ **then** _\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc61\ud835\udc50\ud835\udc5d_ _ _\ud835\udc53\ud835\udc5f\ud835\udc56\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60_ ()\n\n**32** _\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc61\ud835\udc50\ud835\udc5d_ _ _\ud835\udc53\ud835\udc5f\ud835\udc56\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60_ () :\n**begin**\n\n**33** _\ud835\udc4a\ud835\udc61\ud835\udc50\ud835\udc5d_ \u2190\u2212 _\ud835\udc4a\ud835\udc61\ud835\udc50\ud835\udc5d_ + 23\u2212 _\ud835\udefd\ud835\udefd_ [\u2217] _[\ud835\udc4e\ud835\udc50\ud835\udc58]_ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [_] _[\ud835\udc50\ud835\udc5b\ud835\udc61]_\n\n**34** _\ud835\udc4e\ud835\udc50\ud835\udc58_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 0"}, {"role": "assistant", "content": "**Mechanism:** This code implements an additive increase mechanism for a 'TCP-friendly' window (`Wtci`) within the Cubic congestion control algorithm. It increments `Wtci` based on the number of acknowledgments received (`ack_cwnd_cnt`), scaled by a factor `(2^3 - beta)`. After the update, `ack_cwnd_cnt` is reset.\n\n**Explanation:** The `cubic_tcp_friendliness()` function aims to ensure that Cubic TCP doesn't aggressively dominate bandwidth, especially during the congestion avoidance phase. It introduces a separate 'TCP-friendly' window `Wtci` which grows additively. For each acknowledged packet (represented by `ack_cwnd_cnt`), `Wtci` is increased by a small, controlled amount derived from `2^3 - beta`. The `beta` parameter acts as a dampening factor, preventing overly aggressive growth. By doing this, Cubic's overall window growth (which is primarily cubic-shaped) is influenced to behave more like a standard TCP's linear increase, particularly when the Cubic window is small or when competing with traditional TCP flows. This ensures fair resource sharing. The `ack_cnt` is then zeroed out, similar to an event counter being reset after its value has been processed and integrated into a cumulative sum."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn its simplicity, our reward profiling framework compares\nthe performance of two policies _\u03c0\u03b8_ 1 _, \u03c0\u03b8_ 2. Within any PG\nmethod step, a potential update on the policy is made:\n_\u03b8_ 1 _\u2192_ _\u03b8_ 2. This updated, as mentioned, is based on the inaccurate gradient estimation, which is the key source of high\nvariance, leading to occasional updates that _decrease_ the true\nperformance _J_ ( _\u03c0_ ), slow overall convergence, and provide no\n\nwhere _G_ ( _\u03c4_ ) denotes the cumulative (discounted) return of trajectory _\u03c4_ . Based on the comparison of these return estimates,\nthe corresponding parameters are selected for the policy. We\nrefer to this scheme as the \u201d _lookback_ \u201d framework, where we\ncompare the performance of the policies from two successive\nsteps: _\u03b8_ new _,_ _J_ \u02c6( _\u03c0_ new) _\u2265_ _J_ \u02c6( _\u03c0_ old) _,_\n\n_\u03b8t_ +1 = (3)\n\ufffd _\u03b8_ old _,_ otherwise _._\n\nIf the noise masks genuine improvements in the noisy estimates, the agent might get stuck. To address this, we draw\ninspiration from the method _mixup_, a classic data augmentation technique used in supervised learning (Zhang et al.\n2017), where inputs and labels are convexly combined to\nreduce inductive bias, widely used in computer vision applications (Dutta et al. 2024). Specifically, we consider an\nintermediate policy defined by\n\n_\u03b8_ mix = _\u03bb \u03b8_ new + (1 _\u2212_ _\u03bb_ ) _\u03b8_ old _,_\n\nwhere _\u03bb \u2208_ [0 _,_ 1] is a mixing parameter. Similarly, we compare their performance and accept the update if it results from\na higher reward:\n\n\u02c6\n_\u03b8t_ +1 = arg max _J_ ( _\u03c0\u03b8_ ) _._\n_\u03b8\u2208{\u03b8t,\u03b8_ mix _}_\n\nWe also highlight that, as _\u03b8_ mix lies closer to _\u03b8t_ in parameter space (when _\u03bb_ is small), this step functions as a cheap\ntrust region, yet without any Hessian computation or KL\nconstraint as in TRPO (Schulman et al. 2015, 2017). This\nstep is expected to result in a better performance. Finally, the\nlast modification unifies the best of the first two cases. The\n_Three-Points_ variant considers all candidates _{\u03b8t, \u03b8_ _[\u2032]_ _, \u03b8_ mix _}_\nand selects the best:\n\n\u02c6\n_\u03b8t_ +1 = arg max _J_ ( _\u03c0\u03b8_ ) _._\n_\u03b8\u2208{\u03b8_ old _,\u03b8_ new _,\u03b8_ mix _}_\n\nBy design, this technique ensures that _\u03c0_ mostly improves\nover the training process and provides enough room for exploration. We summarize the entire procedure in Algorithm\n1, noting that it can be wrapped around any first-order PG\nmethod without altering its core update logic.\n\n**Algorithm 1:** Reward Profiling Framework\n\n**Input:** initial _\u03b8_ 0; iterations _T_ ; rollouts _E_ ; mix-weight _\u03bb_ ;\nvariant _\u2208{_ LB _,_ MU _,_ TP _}_\n**for** _t_ = 0 _, . . ., T \u2212_ 1 **do**\n\ni\n\nUpdate the policy following any PG\nmethod to the new parameter _\u03b8_ _[\u2032]_\n_\u03b8_ Estimatemix _\u2190_ _\u03bb \u03b8_ _[\u2032]_ + (1 _J_ \u02c6old _\u2212,_ \u02c6 _J\u03bb_ new) _\u03b8,t_ \u02c6 _J_ mix with (Eq. (4))(Eq. (5))\n_\u03b8t_ +1 _\u2190_\n\uf8f1arg max _{\u03b8t,\u03b8\u2032}_ _J,_ [\u02c6] _\\\\_ Lookback _\\\\_\n\uf8f2arg max _{\u03b8t,\u03b8_ mix _}_ _J,_ [\u02c6] _\\\\_ Mix-up _\\\\_\n\n[\u02c6]\n\ni\n\n\uf8f1arg max _{\u03b8t,\u03b8\u2032}_ _J,_ [\u02c6] _\\\\_ Lookback _\\\\_\n\uf8f2arg max _{\u03b8t,\u03b8_ mix _}_ _J,_ [\u02c6] _\\\\_ Mix-up _\\\\_\n\n\uf8f3arg max _{\u03b8t,\u03b8\u2032,\u03b8_ mix _}_ _J,_ [\u02c6] _\\\\_ Three-points _\\\\_\n\n(Eqs. (5),(6))\n**end**\n\ni\n\n\uf8f3\n\ni"}, {"role": "assistant", "content": "**Mechanism:** The mechanism involves a selective policy update rule. Instead of blindly accepting a policy generated by a noisy gradient estimate, it evaluates a small set of candidate policies (the old policy, the new policy from the gradient step, and an interpolated 'mix-up' policy) by estimating their rewards, and then deterministically chooses the best performing one. This acts as a 'filter' against detrimental updates.\n\n**Explanation:** Policy gradient methods compute a direction to update policy parameters based on sampled interactions. However, these samples are noisy, meaning the 'gradient' might point in a direction that locally appears to improve performance but actually leads to a worse true policy. This is like having a compass that sometimes points slightly off true North; following it strictly could lead you astray. The 'lookback' mechanism is a simple conditional check, an `if/else` statement: `if estimated_reward(new_policy) >= estimated_reward(old_policy) then policy = new_policy else policy = old_policy`. This ensures that at least on average, we don't regress. The 'mix-up' introduces a convex combination of policy parameters, `\u03b8_mix = \u03bb \u03b8_new + (1 - \u03bb) \u03b8_old`. This creates an intermediate policy that's a 'blend' of the old and new. When `\u03bb` is small, `\u03b8_mix` is very close to `\u03b8_old`, effectively exploring a small step in the direction of `\u03b8_new`. This implicitly acts as a 'cheap trust region,' constraining the step without the computational burden of second-order methods or KL divergence. It's like taking a small, cautious step rather than a full stride when the ground is uncertain. The 'Three-Points' variant then combines these, essentially creating three pointers to policy configurations (`\u03b8_old`, `\u03b8_new`, `\u03b8_mix`) and then performing an `arg max` operation across their estimated rewards to pick the globally best option among these three candidates for the next iteration. This robustifies the learning process against the inherent variance of policy gradient estimates by ensuring each update is a 'safe' improvement."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_\ud835\udc5f\ud835\udc61\ud835\udc61_\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ **and** _\ud835\udc41\ud835\udc5c\ud835\udc64_ () _> \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_\ud835\udc5f\ud835\udc61\ud835\udc61_\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ **then**\n\n**118** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () ;\n\n**119** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc45\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc52_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ () ;\n\n**120** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc38\ud835\udc65\ud835\udc56\ud835\udc61_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**121** BBR_Exit_Probe_RTT():"}, {"role": "assistant", "content": "**Mechanism:** This code block handles the exit condition for BBR's 'Probe RTT' state. Probe RTT is a specific phase where BBR deliberately reduces the congestion window (Cwnd) to a minimal value for a short duration (typically 200ms) to measure the true Round Trip Time (RTT) under minimal queueing. The goal is to estimate the Round Trip Propagation Time (rtprop), which is the RTT without queuing delays. The condition checks if the Probe RTT measurement round has completed AND if the minimum duration for the low-Cwnd state has elapsed. If both are true, the system records the current time as the latest rtprop measurement, restores the Cwnd to its normal operating value, and transitions out of the Probe RTT state.\n\n**Explanation:** Think of it like a logical AND operation between a flag and a timer. `BBR.probe_rtt_round_done` is a boolean flag indicating that a complete packet round trip was observed during the probing phase. `Now() > BBR.probe_rtt_done_stamp` is a time comparison, ensuring a minimum holding period in the low-Cwnd state (like a timeout variable). If both conditions are met, `BBR.rtprop_stamp = Now()` is like updating a `last_updated_timestamp` variable, marking when the best RTT was observed. `BBR_Restore_Cwnd()` is similar to restoring a configuration setting from a default or previous value after a temporary change. `BBR_Exit_Probe_RTT()` is a function call that triggers a state machine transition, moving BBR out of its 'Probe RTT' mode and allowing it to operate in another state, such as 'Probe BW' or 'Drain', analogous to calling a function to change the active process state."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**28**\n\nii\n\n### **1 Introduction**\n\nGraph Laplacians have been a central subject of study in computer science over the past few\ndecades due to their many connections to graphs and random walks. The seminal work of [ST14]\npresented the first near-linear time (in number of nonzeros of the matrix) algorithm for computing\nthe solution of system _**Lx**_ = _**b**_, where _**L**_ is a graph Laplacian or more generally a principal submatrix\nof a graph Laplacian, i.e., symmetric diagonally dominant M-matrices (SDDM). Many followup works contributed to improving many aspects of such near-linear solvers such as simplifying\nthe algorithm [KOSZ13, LS13, KS16], improving the polylogarithmic factors in the running time\n\n[KMST10, KMP11, LS13, PS14, KMP14, CKM [+] 14, JS21, KS16], and developing parallel solvers with\npolylogarithmic depth and near-linear work [BGK [+] 11, PS14, KLP [+] 16].\n\nAll of these algorithms have focused on normwise error bounds and output a solution \ufffd _**x**_ such\nthat\n_**x**_ _\u2212_ _**L**_ _\u2020_ _**b**_ _**L**_ _\u2020_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd _**L**_ _[\u2264]_ _[\u03f5][ \u00b7]_ \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd _**L**_ _[.]_\n\nAs pointed out recently by [GNY26], since the entries of the solution can vary exponentially, such\nnormwise error bounds cannot recover small entries unless the error parameter _\u03f5_ is exponentially\nsmall in _n_, the size of the matrix. Since these algorithms are all iterative preconditioning approaches,\nthey require about log(1 _/\u03f5_ ) iterations and the numbers used in the algorithm need log( _\u03ba/\u03f5_ ) bits\nof precision to guarantee convergence, where _\u03ba_ is the condition number of the matrix. Taking _\u03f5_\nexponentially small means the number of bit operations, which we refer to as the running time\nthroughout the paper, of the algorithm is about _O_ ( _mn_ [2] ). [GNY26] improved on this by presenting\nan algorithm with a running time of _O_ [\ufffd] ( _m_ _[\u221a]_ ~~_n_~~ log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] )), where _U_ is a bound on the magnitude\nof entries and 1 _\u2212_ _\u03b4_ is the probability of success, that for any invertible SDDM matrix _**L**_ produces\n\n\ufffd\n_**x**_ such that\n_e_ _[\u2212][\u03f5]_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i \u2264_ _**x**_ \ufffd _i \u2264_ _e_ _[\u03f5]_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i,_ for all _i \u2208_ [ _n_ ] _,_\n\nwhich we denote by \ufffd _**x**_ ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_ . This raises the question of whether solving a linear system with\nthe stronger notion of entrywise approximation is possible in almost-linear time. We answer this\nquestion in the affirmative.\n\n**Theorem 1.1.** _There exists a randomized algorithm_ SDDMSolve _such that, for any \u03b4 \u2208_ (0 _,_ 1)\n_and any \u03f5 >_ ( _nU_ ) _[\u2212]_ [2] _\u221a_ log _n (i.e., not exponentially small), any invertible SDDM matrix_ _**L**_ _\u2208_ Z _n\u00d7n_\n\n_with m nonzero integer entries in_ [ _\u2212U, U_ ] _and a nonnegative vector_ _**b**_ _\u2208_ Z _[n]_ _with integer entries in_\n\n[0 _, U_ ] _, with probability at least_ 1 _\u2212_ _\u03b4, computes the entrywise approximate solution_\n\n_**x**_ \ufffd ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_\n\n_whose entries are represented by O_ (log( _nU/\u03f5_ )) _-bit floating points, using_ [1]\n\n\ufffd\n_O_ ( _m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _U_ ) log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] ))\n\n_bit operations._\n\nOur algorithm first constructs a low-diameter cover by solving a collection of linear systems\nwith normwise error bounds on random right-hand side vectors. We then use this low-diameter\ncover to _predict_ the scale of the entries of the solution in an adaptive manner, thereby achieving\nan entrywise approximate solution.\n\n1 \ufffd _O_ suppresses the log log( _U\u03f5\u2212_ 1 _\u03b4\u2212_ 1) factors.\n\n1\n\nIn the next subsection, we introduce our notation and review the relevant results from the\nliterature. Equipped with these preliminaries, we provide an overview of our algorithm and the\nmain ideas behind the proof of Theorem 1.1 in Section 1.2. We discuss related work in Section 1.3.\nIn Section 2, we define our low-diameter cover and present an algorithm for constructing it with\nhigh probability. Finally, Section 3 presents our almost-linear\u2013time algorithm for solving SDDM\nlinear systems with entrywise approximation guarantees, together with the proofs of correctness\nand bit-complexity bounds. We conclude in Section 4 with a discussion of open problems and future\ndirections.\n\n**1.1** **Preliminaries**\n\n**Notation.** We denote _{_ 1 _,_ 2 _, . . ., n}_ by [ _n_ ]. For an undirected graph _G_ = ( _V, E, w_ ) and a vertex\n_v \u2208_ _V_, let _N_ ( _v_ ) denote the set of neighbors of _v_ . For a subset of vertices _S \u2286_ _V_, we denote by\n_G_ ( _S_ ) the subgraph of _G_ induced by _S_ . We use _O_ [\ufffd] notation to suppress polylogarithmic factors in\n_n_ and polyloglog factors in _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] . Formally, _O_ [\ufffd] ( _f_ ) = _O_ ( _f \u00b7_ log( _n \u00b7_ log( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] ))). We also note\nthat poly log _n_ factors are at most 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] .\n\nWe use bold lowercase letters to denote vectors and bold uppercase letters to denote matrices.\nThe vector of all ones is denoted by **1**, and the _i_ -th standard basis vector by _**e**_ [(] _[i]_ [)] . We do not\nexplicitly specify their dimensions when they are clear from context. For a matrix _**M**_, we denote\nits ( _i, j_ )-entry by _**M**_ _ij_ . If _S_ and _T_ are subsets of its row and column indices, respectively, then\n_**M**_ _ST_ denotes the submatrix formed by the entries _{_ ( _i, j_ ) : _i \u2208_ _S, j \u2208_ _T_ _}_ .\n\nFor _**v**_ _\u2208_ R _[n]_, let diag( _**v**_ ) _\u2208_ R _[n][\u00d7][n]_ denote the diagonal matrix with the entries of _**v**_ on its diagonal.\nFor _**M**_ _\u2208_ R _[n][\u00d7][n]_, let diag( _**M**_ ) _\u2208_ R _[n][\u00d7][n]_ denote the diagonal matrix obtained from _**M**_ by zeroing out\nall off-diagonal entries. The Moore\u2013Penrose pseudoinverse of _**M**_ is denoted by _**M**_ _[\u2020]_ .\n\n**Definition 1.1** (RDDL and SDDM Matrices) **.** _A matrix_ _**M**_ _\u2208_ R _[n][\u00d7][n]_ _is called an L-matrix if_\n_**M**_ _ij \u2264_ 0 _for all i \u0338_ = _j and_ _**M**_ _ii >_ 0 _for all i \u2208_ [ _n_ ] _. It is_ row diagonally dominant _(RDD) if for_\n_every i \u2208_ [ _n_ ] _,_\n_|_ _**M**_ _ii| \u2265_ \ufffd _|_ _**M**_ _ij|._\n\n_j\u2208_ [ _n_ ] _\\{i}_\n\n_We call_ _**M**_ RDDL _if it is both an L-matrix and row diagonally dominant. An_ SDDM matrix _is an_\n_invertible symmetric RDDL matrix._\n\nIn this paper, we focus exclusively on SDDM matrices. An equivalent characterization is that\nsuch matrices are principal submatrices of undirected graph Laplacians. We refer to the corresponding graph as the _associated graph_ of the SDDM matrix, defined as follows.\n\n**Definition 1.2** (Associated Graph of an RDDL Matrix) **.** _For an RDDL matrix_ _**M**_ _\u2208_ R _[n][\u00d7][n]_ _, we_\n_define the associated weighted graph G_ = ([ _n_ +1] _, E, w_ ) _by adding a dummy vertex n_ +1 _. For every_\n_pair i, j \u2208_ [ _n_ ] _with i \u0338_ = _j, we set the edge weight w_ ( _i, j_ ) = _\u2212_ _**M**_ _ij. Additionally, we set the edge_\n_weight w_ ( _i, n_ + 1) = [\ufffd] _j\u2208_ [ _n_ ] _**[M]**_ _[ ij][.]_\n\nThe associated graph of an SDDM matrix is defined analogously. The solution of a linear\nsystem with an SDDM matrix is closely connected to random walks on its associated graph, which\nwe define next.\n\n**Random walks.** Given an undirected weighted graph _G_ = ([ _n_ ] _, E, w_ ) with edge weights _w \u2208_ R _[E]_ _\u2265_ 0 [,]\na random walk on _G_ moves from a vertex to one of its neighbors independently of all previous steps.\n\n2\n\nIf the walk is currently at vertex _i_, it moves to _j \u2208_ _N_ ( _i_ ) in the next step with probability\n\n_w_ ( _i,_ _j_ )\n_**A**_ _ij_ := ~~\ufffd~~ _k\u2208N_ ( _i_ ) _[w]_ [(] _[i, k]_ [)] _[.]_\n\nIn other words, _**A**_ is the transition matrix of the Markov chain associated with _G_ . For unweighted\ngraphs, this simplifies to a uniform transition probability 1 _/|N_ ( _i_ ) _|_ for each neighbor.\n\n**Definition 1.3** (Escape Probability) **.** _The_ escape probability P( _s, t, p_ ) _denotes the probability that_\n_a random walk starting at vertex s visits vertex t before vertex p._\n\nThe following result characterizes the relationship between the entries of the inverse of an\ninvertible SDDM matrix and the escape probabilities in its associated graph.\n\n**Lemma 1.4** (Lemma 2.7 of [GNY26]) **.** _Let_ _**L**_ _\u2208_ R _[n][\u00d7][n]_ _be an invertible RDDL matrix. Then, for_\n_all s, t \u2208_ [ _n_ ] _,_\n\n( _**L**_ _[\u2212]_ [1] ) _st_\nP( _s, t, n_ + 1) = _._\n_**L**_ _tt_ ( _**L**_ _[\u2212]_ [1] ) _tt_\n\n_Furthermore,_ ( _**L**_ _[\u2212]_ [1] ) _tt >_ 0 _for every t \u2208_ [ _n_ ] _._\n\nWe next recall a few linear algebraic notations and definitions that we use throughout the paper.\n\n**Norms.** The _\u2113_ 1-norm and _\u2113\u221e_ -norm of a vector _**v**_ _\u2208_ R _[n]_ are defined as _\u2225_ _**v**_ _\u2225_ 1 := [\ufffd] _i\u2208_ [ _n_ ] _[|]_ _**[v]**_ _[ i][|]_ [ and]\n_\u2225_ _**v**_ _\u2225\u221e_ := max _i\u2208_ [ _n_ ] _|_ _**v**_ _i|_, respectively. The induced _\u2113_ 1 and _\u2113\u221e_ norms for a matrix _**M**_ _\u2208_ R _[n][\u00d7][n]_ are\ndefined as\n\n_\u2225_ _**M**_ _\u2225_ 1 := max\n_**v**_ _\u2208_ R _[n]_ : _\u2225_ _**v**_ _\u2225_ 1=1 _[\u2225]_ _**[M v]**_ _[\u2225]_ [1] _[,]_\n\n_\u2225_ _**M**_ _\u2225\u221e_ := _**v**_ _\u2208_ R _[n]_ max: _\u2225_ _**v**_ _\u2225\u221e_ =1 _[\u2225]_ _**[M v]**_ _[\u2225][\u221e]_ _[.]_\n\nBoth vector and induced norms satisfy the triangle inequality and consistency property; for example,\n_\u2225_ _**AB**_ _\u2225\u221e_ _\u2264\u2225_ _**A**_ _\u2225\u221e_ _\u00b7 \u2225_ _**B**_ _\u2225\u221e_ . We also define _\u2225_ _**A**_ _\u2225_ max := max _i,j |_ _**A**_ _ij|_ . The _energy norm_ with respect\nto a positive definite matrix _**L**_ is defined as\n\n_\u2225_ _**v**_ _\u2225_ _**L**_ := _\u221a_\n\n**Schur complement.** Given a block matrix\n\n_**v**_ _[\u22a4]_ _**Lv**_ _._\n\n_**A**_ _**B**_\n_**M**_ =\n_**C**_ _**D**_\n\ufffd\n\n_,_\n\ufffd\n\nthe _Schur complement_ of _**M**_ with respect to _**A**_ is Sc( _**M**_ _,_ _**A**_ ) = _**D**_ _\u2212_ _**CA**_ _[\u2212]_ [1] _**B**_, assuming _**A**_ is\ninvertible. If both _**S**_ := Sc( _**M**_ _,_ _**A**_ ) and _**A**_ are invertible, then _**M**_ is invertible and\n\n_**A**_ _\u2212_ 1 + _**A**_ _\u2212_ 1 _**BS**_ _\u2212_ 1 _**CA**_ _\u2212_ 1 _\u2212_ _**A**_ _[\u2212]_ [1] _**BS**_ _[\u2212]_ [1]\n_**M**_ _[\u2212]_ [1] =\n\n_\u2212_ _**S**_ _[\u2212]_ [1] _**CA**_ _[\u2212]_ [1] _**S**_ _[\u2212]_ [1]\n\n\ufffd\n\n3\n\n_._ (1)\n\ufffd\n\n**Solving SDDM linear systems with normwise error bounds.** The following result by\nSpielman and Teng [ST14] was a breakthrough, providing a near-linear\u2013time algorithm for solving\nSDDM linear systems with normwise error guarantees.\n\n**Lemma 1.5** (Theorem 5.5 of [ST14]) **.** _Let_ _**L**_ _\u2208_ R _[n][\u00d7][n]_ _be an SDDM matrix with m nonzero entries,_\n_and let_ _**b**_ _\u2208_ R _[n]_ _have integer entries in_ [ _\u2212U, U_ ] _. For any \u03f5 >_ 0 _and \u03b4 \u2208_ (0 _,_ 1) _, there exists an_\n_algorithm that, with probability at least_ 1 _\u2212_ _\u03b4 and using_ _O_ [\ufffd] ( _m_ log( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] ) log( _\u03f5_ _[\u2212]_ [1] )) _bit operations,_\n_computes a vector_ \ufffd _**x**_ _such that_\n_**x**_ _\u2212_ _**L**_ _\u2020_ _**b**_ _**L**_ _\u2020_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd _**L**_ _[\u2264]_ _[\u03f5][ \u00b7]_ \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd _**L**_ _[.]_\n\n_Moreover, the entries of_ \ufffd _**x**_ _can be represented using O_ ( _n_ log( _U\u03f5_ _[\u2212]_ [1] )) _bits in fixed-point arithmetic._\n\nThe above result bounds the error with respect to the energy norm. For our purposes, it is\noften more convenient to work with the Euclidean norm. Corollary 1.7, which follows directly\nfrom Lemma 1.5 together with the following bound on the condition number of invertible SDDM\nmatrices, provides such an error guarantee in the Euclidean norm.\n\n**Lemma 1.6** (Corollary 2.5 of [GNY26]) **.** _Let_ _**L**_ _be an n \u00d7 n invertible SDDM matrix with integer_\n_entries in_ [ _\u2212U, U_ ] _. Then_\n\ufffd\ufffd _**L**_ _\u2212_ 1\ufffd\ufffd2 [=] 1\n_\u03bb_ min( _**L**_ ) _[< n]_ [2] _[.]_\n\n**Corollary 1.7** (Corollary 3.2 of [GNY26]) **.** _Let_ _**L**_ _\u2208_ R _[n][\u00d7][n]_ _be an invertible SDDM matrix with m_\n_nonzero entries, and let_ _**b**_ _\u2208_ R _[n]_ _have integer entries in_ [ _\u2212U, U_ ] _. For any \u03f5 >_ 0 _and \u03b4 \u2208_ (0 _,_ 1) _, there_\n_exists an algorithm that, with probability at least_ 1 _\u2212\u03b4 and using_ _O_ [\ufffd] ( _m_ log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] )) _bit operations,_\n_computes a vector_ \ufffd _**x**_ _such that_\n_**x**_ _\u2212_ _**L**_ _\u2020_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5][ \u2225]_ _**[b]**_ _[\u2225]_ [2] _[ .]_\n\n_Moreover, the entries of_ \ufffd _**x**_ _can be represented using O_ (log( _nU\u03f5_ _[\u2212]_ [1] )) _bits in fixed-point arithmetic._\n\n**1.2** **Technical Overview**\n\nOur approach builds on the _threshold decay (TD)_ framework introduced in [GNY26]. We first recall\nthe main components of this framework and then explain how we adapt it to obtain an almostlinear-time algorithm for solving SDDM linear systems with entrywise approximation guarantees.\n\n**Threshold decay (TD) framework.** The TD framework relies on three key observations:\n\n1. A solution with normwise error guarantees (for a polynomially small error parameter) also\nprovides entrywise approximations for the large coordinates of the solution. Moreover, every\nsolution to a linear system has at least one large entry.\n\n2. Given a subset of entries _F \u2286_ [ _n_ ], if we substitute an entrywise approximation for the entries in\n_F_ into the system, the resulting smaller linear system is only mildly affected. More precisely,\nsubstituting an exp( _\u03f5_ )-entrywise approximation for _F_ changes the solution on [ _n_ ] _\\ F_ by at\nmost a multiplicative factor of exp( _\u03f5_ ).\n\n3. Removing small entries of the solution introduces only a limited error. Specifically, if _C \u2286_ [ _n_ ]\nsatisfies ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i < \u03b8_ for all _i \u2208_ _C_, then with _F_ = [ _n_ ] _\\ C_,\n\n\ufffd( _**L**_ _FF_ ) _[\u2212]_ [1] _**b**_ _F_ ; **0** \ufffd _\u2212_ _**L**_ _[\u2212]_ [1] _**b**_\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[\u2264]_ _[n]_ [3] _[U\u03b8.]_\n\n4\n\nThe first two observations imply that normwise guarantees can be leveraged to recover entrywise approximations for some coordinates of the solution, which can then be substituted back to\nform a smaller system. Repeating this process allows us to iteratively recover approximations for\nprogressively smaller entries. The third observation shows that if we knew in advance which entries\nwere small, we could safely remove them and focus computation on a reduced system that preserves\naccuracy for the large entries.\n\nThese insights naturally motivate the following iterative algorithm. We maintain three disjoint\nsubsets of indices partitioning [ _n_ ]: _(i)_ a _solved set P_ containing entries whose entrywise approximations have been computed, _(ii)_ an _inactive set Q_ of entries deemed small enough to omit, and _(iii)_\nan _active set R_ of remaining entries participating in the current linear system. At each iteration,\nthe algorithm maintains a threshold parameter _\u03b8_ and proceeds as follows:\n\n1. Add to _R_ all entries in _Q_ whose magnitude is at least _\u03b8_ . Update _Q_ as _Q \u2190_ [ _n_ ] _\\_ ( _R \u222a_ _P_ ).\n\n2. Solve the linear system with coefficient matrix _**L**_ _RR_ and recover entrywise approximations for\nthe entries in _R_ that are large relative to _\u03b8_ . Move these entries from _R_ to _P_ .\n\n3. Substitute the newly solved entries into the system to obtain an updated right-hand-side\nvector _**b**_ .\n\n4. Reduce the threshold _\u03b8_ by a polynomial factor in _nU_ and repeat.\n\nWe remark that the first step is the most technically challenging and constitutes our main contribution. To make the algorithm efficient, we must restrict the system solve to the active set\n_R_ . However, this restriction provides no direct information about the large entries in _Q_ . The core\ndifficulty is to identify these large entries without explicitly solving on _Q_ . Our key idea is to achieve\nthis through carefully designed _predictions_ .\n\n**TD with prediction.** Achieving almost-linear running time requires keeping the active set small\non average across iterations. This, in turn, depends on having good _a priori_ predictions for the\nmagnitudes of the solution entries. A notable instance where such predictions are available is the\ncomputation of the inverse of an SDDM matrix (see [GNY26]). Specifically, for any pair ( _i, j_ ) with\n_**L**_ _ij \u0338_ = 0, one has\n1\n_nU_ _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[j]_ [)] _[ \u2264]_ _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[i]_ [)] _[ \u2264]_ _[nU]_ _**[ L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[j]_ [)] _[,]_\n\nimplying that the _i_ -th column of _**L**_ _[\u2212]_ [1] provides reliable predictions for the _j_ -th column. Using\nthis property, [GNY26] obtained an _O_ [\u02dc] ( _mn_ )-time algorithm for computing the inverse of an SDDM\nmatrix. Once one column of _**L**_ _[\u2212]_ [1] is computed, each subsequent column can be obtained in _O_ [\u02dc] ( _m_ )\ntime.\n\nHowever, this prediction only applies when inverting the entire matrix, i.e., solving _O_ ( _n_ ) systems. For a single system, we must establish an _upper bound_ on the small entries in order to identify\nwhich entries can be safely ignored when extracting the large ones. Directly using the inequality\ngives only _lower bounds_ on the small entries, making it useless here.\n\n**Low-diameter (LD) cover.** Obtaining accurate predictions for a single linear system requires\na more sophisticated approach. In this paper, we obtain such predictions by first computing a\n_low-diameter cover_ for the graph associated with _**L**_, where we define the distance between two\nvertices _i_ and _j_ in terms of their corresponding entry in the inverse:\n\n_D_ _**L**_ ( _i, j_ ) := _\u2212_ log _nU_ \ufffd( _**L**_ _[\u2212]_ [1] ) _ij_ \ufffd + 2 _._\n\n5\n\nAn important property of this distance function is that it satisfies the triangle inequality.\n\nWe construct a collection of pairs ( _V, W_ ) of _inner and outer balls_, where _V \u2286_ _W \u2286_ [ _n_ ], satisfying\nthe following properties:\n\n(i) Every vertex is contained in at least one inner ball.\n\n(ii) Each vertex is contained in at most _n_ _[o]_ [(1)] outer balls.\n\n(iii) For any pair _i, j_ within the same outer ball, _D_ _**L**_ ( _i, j_ ) _\u2264_ _n_ _[o]_ [(1)] .\n\n(iv) If _i_ lies in an inner ball and _j_ lies outside its corresponding outer ball, then _D_ _**L**_ ( _i, j_ ) _\u2265_ _n_ _[\u03c9]_ [(1)] .\n\nWe next explain how such a low-diameter cover can be leveraged to solve the linear system in\nalmost-linear time, and subsequently describe how to compute such a cover efficiently.\n\n**Almost linear-time solver using LD cover.** In iteration _t_ of the TD framework, let _P_ [(] _[t]_ [)]\n\ndenote the solved set where the entrywise approximations of the entries have been computed. We\nnow solve on the reduced system on [ _n_ ] _\\ P_ [(] _[t]_ [)] (obtained by plugging in the solved entries in _P_ [(] _[t]_ [)] )\n\n( _t_ )\n_**L**_ [ _n_ ] _\\P_ ( _t_ ) _,_ [ _n_ ] _\\P_ ( _t_ ) _**x**_ = _**b**_ [\ufffd]\n\nwhere _**b**_ [\ufffd] ( _t_ ) ~~_\u2248_~~ _**b**_ [ _n_ ] _\\P_ ( _t_ ) _\u2212_ _**L**_ [ _n_ ] _\\P_ ( _t_ ) _, P_ ( _t_ ) \ufffd _**x**_ ( _t_ ) is the right-hand-side vector of the reduced system.\n\nIt can be shown that (see Lemma 3.8 of [GNY26]) the nonzero entries of _**b**_ [\ufffd] ( _t_ ) differ by at most a\npolynomial (in _U_ ) factor. This allows us to invoke the near-linear-time solver of [ST14] to compute\na solution with normwise error guarantees in each iteration.\n\nLet _I_ [(] _[t]_ [)] denote the set of nonzero entries of _**b**_ [\ufffd] ( _t_ ). The entries indexed by _I_ ( _t_ ) in the solution\n\n( _t_ )\n( _**L**_ [ _n_ ] _\\P_ ( _t_ ) _,_ [ _n_ ] _\\P_ ( _t_ )) _[\u2212]_ [1] _**b**_ [\ufffd] are large\u2014this follows directly from a simple application of Lemma 1.4. We\nuse _I_ [(] _[t]_ [)] as a seed to construct the active set, ensuring that the inactive set contains only small\nentries of the solution.\n\nWe define the _boundary-expanded set_ (see Definition 3.4) of _I_ [(] _[t]_ [)] as the union of inner balls whose\ncorresponding outer balls intersect _I_ [(] _[t]_ [)] . Due to the definition of the LD cover, if a vertex _u \u2208_ [ _n_ ]\ndoes not belong to the boundary-expanded set of _I_ [(] _[t]_ [)], the corresponding outer ball of the inner ball\nthat contains _u_ does not intersect _I_ [(] _[t]_ [)], then the probability distance between _u_ and any _v \u2208_ _I_ [(] _[t]_ [)] is\nat least _n_ _[\u03c9]_ [(1)] . This implies that the entry at _u_ is small and can be omitted in iteration _t_ of the TD\nframework. Therefore, the active set in iteration _t_, denoted by _H_ [(] _[t]_ [)], is defined as the intersection\nof [ _n_ ] _\\ P_ [(] _[t]_ [)] and the boundary-expanded set of _I_ [(] _[t]_ [)] .\n\nMoreover, we show that the total size of all _H_ [(] _[t]_ [)] \u2019s satisfies\n\n\ufffd _|H_ [(] _[t]_ [)] _| \u2264_ _n_ [1+] _[o]_ [(1)] _._\n\n_t_\n\nBy properties of the TD framework, every vertex is added to and deleted from the active set exactly\nonce. When a vertex _u_ is added to the active set, the distance _d_ to the solved set is bounded by the\nradius of an outer ball in the LD cover, i.e., _n_ _[o]_ [(1)] . This gives a lower bound on the _u_ -th entry of\nthe solution ( _**L**_ _[\u2212]_ [1] _**b**_ ) _u \u2265_ _\u03b8 \u00b7_ ( _nU_ ) _[\u2212][d]_, where _\u03b8_ is the current threshold. Since the threshold is reduced\nby a polynomial factor in _nU_ in each iteration, the vertex will be removed from the active set and\nadded to the solved set after _O_ ( _d_ ) = _n_ _[o]_ [(1)] iterations, concluding the bound on total size of _H_ [(] _[t]_ [)] \u2019s.\n\nMaintaining the sets _I_ [(] _[t]_ [)] and _H_ [(] _[t]_ [)] requires additional care to ensure almost-linear running time:\n\n6\n\n1. It can be shown that the right-hand-side vector _**b**_ [\ufffd] ( _t_ ) undergoes only _O_ ( _m_ + _n_ ) updates in\ntotal. Hence, the sets _I_ [(] _[t]_ [)] can be maintained in _O_ ( _m_ + _n_ ) time overall.\n\n2. The set _H_ [(] _[t]_ [)] is maintained by keeping a counter for each pair in the LD cover that tracks the\nnumber of vertices in _I_ [(] _[t]_ [)] contained in the corresponding outer ball. Then _H_ [(] _[t]_ [)] is the union\nof the inner balls of all pairs with nonzero counters. Since the number of updates to _I_ [(] _[t]_ [)] is\nbounded and each vertex is covered by a limited number of outer balls, these counters can be\nupdated in almost-linear time. Moreover, since\n\n\ufffd _|H_ [(] _[t]_ [)] _| \u2264_ _n_ [1+] _[o]_ [(1)] _,_\n\n_t_\n\nand each vertex is covered by at most _n_ _[o]_ [(1)] outer balls, using the property of our TD framework, the total time to construct all sets _H_ [(] _[t]_ [)] is at most _n_ [1+] _[o]_ [(1)] over the course of the\nalgorithm.\n\n**Constructing the LD cover.** To explain the high-level ideas of our algorithm for constructing\nthe LD cover, we assume exact solutions to linear systems. However, in Section 2, we carefully\naddress bit complexity and the errors introduced when solving linear systems approximately.\n\nConsider the solution to the linear system _**Lx**_ = _**e**_ [(] _[i]_ [)] . Let\n\n_V_ = _{j \u2208_ [ _n_ ] : ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[i]_ [)] ) _j \u2265_ 2 _[\u2212\u221a]_ [log] _[ n]_ _}_ and _W_ = _{j \u2208_ [ _n_ ] : ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[i]_ [)] ) _j \u2265_ 4 _[\u2212\u221a]_ [log] _[ n]_ _}._\n\nThen _V \u2286_ _W_ . By the triangle inequality for _D_ _**L**_, one can verify that for the inner ball _V_ and the\nouter ball _W_, properties (iii) and (iv) of the LD cover are satisfied. Moreover, _i_ is contained in _V_,\nand therefore property (i) is satisfied for _i_ . Thus, one may construct a pair of balls for each _i \u2208_ [ _n_ ]\nby considering the large entries of the solution to _**Lx**_ = _**e**_ [(] _[i]_ [)] .\n\nThis na\u00a8\u0131ve approach encounters two main issues: (1) it requires solving _n_ different linear systems;\nand (2) each vertex may belong to too many outer balls. To address these issues, we instead attempt\nto construct outer/inner ball pairs for multiple vertices simultaneously by solving a linear system\nwith right-hand side **1** _S_ = [\ufffd] _i\u2208S_ _**[e]**_ [(] _[i]_ [)][. By linearity, the large entries of the solution] _**[ Lx]**_ [ =] **[ 1]** _[S]_ [ roughly]\ngive the _union_ of balls for _i \u2208_ _S_ . An important observation is that if _i_ is far (in _D_ _**L**_ distance) from\nall _j \u2208_ _S \\{i}_, then the pair of balls corresponding to _i_ form an isolated connected component from\nthe union of the rest, and therefore can be recovered from the solution.\n\nTo obtain such an _S_, we select a random subset of [ _n_ ], where each vertex is included independently. Moreover, instead of using the fixed thresholds 2 _[\u2212\u221a]_ [log] _[ n]_ and 4 _[\u2212\u221a]_ [log] _[ n]_ for the inner and outer\nballs, we consider multiple thresholds that are exponential in a set of distance parameters _di_ to\nensure that vertices in _S_ remain sufficiently far from one another.\n\nTherefore, we construct the LD cover by solving a _collection of linear systems_ with coefficient\nmatrix _**L**_ and random right-hand-side vectors, and by recovering inner/outer balls from the large\nentries of the resulting solutions. We consider _O_ ( _[\u221a]_ log _n_ ) different probabilities _pj_ (for selecting vertices to set _S_ ) and _O_ ( _[\u221a]_ log _n_ ) different distance thresholds _di_ in a nested loop. For each pair ( _di, pj_ ),\nwe run _n_ _[o]_ [(1)] independent iterations. In each iteration, every vertex _u_ is included in _S_ independently with probability _pj_, forming a random subset _S_ . We then compute a normwise approximate\nsolution with error parameter exponential in _di_ to the linear system\n\n_**Lx**_ = **1** _S._\n\nLet _T_ denote the set of vertices corresponding to the _large_ entries (i.e., entries larger than\nexp( _\u2212di/_ 2)) in the resulting solution. If a connected component of the subgraph induced by _T_\n\n7\n\ncontains exactly one vertex of _S_, then we construct a pair of inner and outer balls ( _V, W_ ) on that\nconnected component such that the distance between any vertex inside the inner ball and any vertex\noutside the outer ball is at least _n_ _[\u03c9]_ [(1)], and the distance between any two vertices within the outer\nball is at most _n_ _[o]_ [(1)] . We construct inner/outer ball pairs only from such connected components\nand add them to our cover.\n\nThis constraint on the connected components ensures that the vertex in _S_ contained in that\ncomponent is far from all other vertices in _S_ . Consequently, the construction satisfies properties (iii)\nand (iv) of the LD cover.\n\nWe show that for every vertex _u \u2208_ [ _n_ ], there exists a pair ( _di, pj_ ) such that, with probability\nat least _n_ _[\u2212][o]_ [(1)], the random set _S_ contains a vertex near _u_ (that is, within its corresponding inner\nball) and that vertex is the unique element of _S_ in its connected component of the subgraph\ninduced by _T_, which is our requirement for constructing inner/outer balls as explained above. The\nrepeated iterations in the inner loop amplify the probability of this event. Consequently, with high\nprobability, every vertex is contained in at least one inner ball. Moreover, since in each iteration\nwe only include disjoint outer balls, each vertex is covered by at most _n_ _[o]_ [(1)] outer balls. Hence,\nproperties (i) and (ii) also hold.\n\n**1.3** **Related Work**\n\nSolving linear systems with entrywise approximation guarantees dates back to the 1980s and 1990s.\nFrom a theoretical point of view, Higham [Hig90] observed that fast matrix multiplication methods\nsuch as Strassen\u2019s [Str69] cannot achieve entrywise approximations for matrix multiplication (which,\nvia standard reductions, can be used for solving linear systems) due to their inherent reliance on\nsubtractions, even when applied to nonnegative matrices.\n\nOn the other hand, empirical studies demonstrated that Gaussian elimination is significantly\nmore stable when computing the stationary distribution of Markov chains [Hey87, GTH85, HP84]\ncompared to its application to general matrices. These studies attributed the improved stability to\nthe fact that Gaussian elimination, when applied to SDDM matrices, does not require subtractions\nand is therefore highly compatible with floating-point arithmetic.\n\nSubsequent works further analyzed the error bounds and the number of floating-point operations required for computing the stationary distribution [O\u2019C93] and for performing LU factorization [O\u2019C96] with entrywise approximation guarantees. All of these algorithms require cubic time.\nVery recently, [GNY26] studied this problem for both SDDM and RDDL matrices with the goal\nof designing subcubic-time algorithms. In particular, for solving a linear system with an SDDM\nmatrix, they presented an algorithm with running time _O_ [\ufffd] ( _m_ _[\u221a]_ ~~_n_~~ log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] )). Moreover, for\ninverting an SDDM matrix, they provided an algorithm with running time _O_ [\ufffd] ( _mn_ log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] )).\n\nThe recent work of Gao, Kyng, and Spielman [GKS23] has demonstrated the superior practical\nperformance of near-linear\u2013time Laplacian solvers. We hope that our approach can further advance\npractical solvers, particularly in settings where edge weights vary widely\u2014for example, in solving\nlinear systems that arise as subroutines in interior-point methods for flow problems.\n\nThere also exist algorithms in the literature for decomposing graphs into components with small\ndiameter or covering them with low-diameter components, with applications to shortest-path problems and parallel SDDM solvers [Coh98, BGK [+] 11]. However, these low-diameter decompositions\nand covers differ substantially from ours. To begin with, our covers are defined using pairs of inner\nand outer balls, with the guarantee that vertices inside an inner ball are far from those outside the\ncorresponding outer ball. In contrast, the decompositions and covers in the literature are defined\nusing single clusters or balls of small diameter. Moreover, our notion of distance is based on the\n\n8\n\n_probability distance_\n_D_ _**L**_ ( _i, j_ ) := _\u2212_ log _nU_ \ufffd( _**L**_ _[\u2212]_ [1] ) _ij_ \ufffd + 2 _,_\n\nas opposed to the standard (weighted or unweighted) graph distance. Most importantly, our access\nto the distance _D_ _**L**_ ( _\u00b7, \u00b7_ ) is highly restricted since it requires computing entries of the inverse. We\naddress this limitation via a carefully designed oracle query, obtained by solving the system on a\nrandom vector with normwise error guarantees.\n\n### **2 Low-Diameter Cover**\n\nIn this section, we introduce our definition of a low-diameter cover and present an algorithm\nfor constructing it with high probability using SDDM solvers with normwise error bounds as a\nsubroutine. We note that the existence of such low-diameter covers is nontrivial, and the proof of\ncorrectness of our algorithm also serves as a constructive proof of their existence.\n\nThe diameters of the components in our cover are measured with respect to a distance function\nthat we call the _probability distance_ . We define this notion and establish some of its useful properties\nin Section 2.1. In Section 2.2, we formally define our low-diameter cover and present an algorithm\nfor constructing it.\n\n**2.1** **Probability Distance**\n\nThe following distance function, defined in terms of the entries of the inverse of an SDDM matrix,\nforms the backbone of our low-diameter cover construction.\n\n**Definition 2.1** (Probability distance) **.** _Let_ _**L**_ _\u2208_ Z _[n][\u00d7][n]_ _be an invertible SDDM matrix with integer_\n_entries in_ [ _\u2212U, U_ ] _. We define the_ probability distance _with respect to_ _**L**_ _as_\n\n_D_ _**L**_ ( _i, j_ ) := _\u2212_ log _nU_ \ufffd( _**L**_ _[\u2212]_ [1] ) _ij_ \ufffd + 2 _,_ _for all i, j \u2208_ [ _n_ ] _._\n\nThe following result establishes some basic properties of the probability distance, including the\ntriangle inequality and the fact that the distance between two adjacent vertices is small.\n\n**Claim 2.2** (Properties of the probability distance) **.** _Let_ _**L**_ _\u2208_ Z _[n][\u00d7][n]_ _be an invertible SDDM matrix_\n_with integer entries in_ [ _\u2212U, U_ ] _. Then, for all i, j, k \u2208_ [ _n_ ] _, the probability distance D_ _**L**_ _satisfies:_\n\n_1. D_ _**L**_ ( _i, i_ ) _\u2265_ 0 _._\n\n_2. D_ _**L**_ ( _i, j_ ) = _D_ _**L**_ ( _j, i_ ) _._\n\n_3. D_ _**L**_ ( _i, k_ ) _\u2264_ _D_ _**L**_ ( _i, j_ ) + _D_ _**L**_ ( _j, k_ ) _._\n\n_4. For adjacent vertices i, j (i.e.,_ _**L**_ _ij \u0338_ = 0 _), we have D_ _**L**_ ( _i, j_ ) _\u2264_ 4 _._\n\n_Proof._ The first property follows from Lemma 1.6 which states that the largest eigenvalue of _**L**_ _[\u2212]_ [1]\n\nis at most _n_ [2] . The second property holds because _**L**_ is symmetric. For the fourth property, let\n_**D**_ := diag( _**L**_ ) and _**A**_ = _**D**_ _[\u2212]_ [1] ( _**D**_ _\u2212_ _**L**_ ) and _i, j_ be adjacent. By Lemma 1.4\n\n( _**L**_ _[\u2212]_ [1] ) _ij_ = P( _i, j, n_ + 1) _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_\n= P( _i, j, n_ + 1) _**L**_ _jj_ (( _**D**_ ( _**I**_ _\u2212_ _**A**_ )) _[\u2212]_ [1] ) _jj_\n= P( _i, j, n_ + 1) _**L**_ _jj_ _**D**_ _[\u2212]_ _jj_ [1][((] _**[I]**_ _[ \u2212]_ _**[A]**_ [)] _[\u2212]_ [1][)] _[jj]_\n\n= P( _i, j, n_ + 1) _**L**_ _jj_ _**D**_ _[\u2212]_ _jj_ [1][(] _**[I]**_ [ +] _**[ A]**_ [ +] _**[ A]**_ [2][ +] _[ \u00b7 \u00b7 \u00b7]_ [ )] _[jj]_\n\n9\n\n_\u2265_ _U_ _[\u2212]_ [2] _,_\n\nwhere the inequality holds because P( _i, j, n_ + 1) _,_ _**D**_ _[\u2212]_ _jj_ [1] _[\u2265]_ _[U]_ _[\u2212]_ [1][ and] _**[ L]**_ _[jj][,]_ [ (] _**[I]**_ [ +] _**[ A]**_ [ +] _**[ A]**_ [2][ +] _[ \u00b7 \u00b7 \u00b7]_ [ )] _[jj][ \u2265]_ [1.]\nTherefore\n_D_ _**L**_ ( _i, j_ ) = _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] ) _ij_ ) + 2 _\u2264\u2212_ log _nU_ ( _U_ _[\u2212]_ [2] ) + 2 _\u2264_ 4 _._\n\nNow we prove the third property, i.e., the triangle inequality. By Lemma 1.6,\n\n( _**L**_ _[\u2212]_ [1] ) _jj \u2264_ _n_ [2] _._\n\nTherefore since _**L**_ _jj \u2264_ _U_,\n\nlog _nU_ ( _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_ ) _\u2264_ 2 _._ (2)\n\nNow note that due to Markov property,\n\nP( _i, j, n_ + 1) _\u00b7_ P( _j, k, n_ + 1) _\u2264_ P( _i, k, n_ + 1) _._\n\nTherefore\n\n(P( _i, j, n_ +1) _\u00b7_ _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_ ) _\u00b7_ (P( _j, k, n_ +1) _\u00b7_ _**L**_ _kk_ ( _**L**_ _[\u2212]_ [1] ) _kk_ ) _\u2264_ (P( _i, k, n_ +1) _\u00b7_ _**L**_ _kk_ ( _**L**_ _[\u2212]_ [1] ) _kk_ )) _\u00b7_ ( _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_ ) _._\n\nThus by Lemma 1.4,\n( _**L**_ _[\u2212]_ [1] ) _i,j \u00b7_ ( _**L**_ _[\u2212]_ [1] ) _j,k \u2264_ ( _**L**_ _[\u2212]_ [1] ) _i,k \u00b7_ ( _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_ ) _._\n\nTaking the logarithm and using Eq (2), we have\n\nlog( _**L**_ _[\u2212]_ [1] ) _i,j_ + log( _**L**_ _[\u2212]_ [1] ) _j,k \u2264_ log( _**L**_ _[\u2212]_ [1] ) _i,k_ + log( _**L**_ _jj_ ( _**L**_ _[\u2212]_ [1] ) _jj_ ) _\u2264_ log( _**L**_ _[\u2212]_ [1] ) _i,k_ + 2 _._\n\nTherefore\n\n_D_ _**L**_ ( _i, j_ ) + _D_ _**L**_ ( _j, k_ ) = _\u2212_ log( _**L**_ _[\u2212]_ [1] ) _i,j \u2212_ log( _**L**_ _[\u2212]_ [1] ) _j,k_ + 4 _\u2265\u2212_ log( _**L**_ _[\u2212]_ [1] ) _i,k \u2212_ 2 + 4 = _D_ _**L**_ ( _i, k_ ) _._\n\nFinally, we conclude this part by showing that the principal submatrices of an invertible SDDM\nmatrix _**L**_ induce larger distances than _**L**_ itself. We will use this property in our almost-linear\u2013time\nalgorithm to establish that if two vertices are far from each other with respect to _**L**_, then they\nremain far with respect to any principal submatrix of _**L**_ .\n\n**Lemma 2.3** (Monotonicity of distance) **.** _Let_ _**L**_ _\u2208_ Z _[n][\u00d7][n]_ _be an invertible SDDM matrix, and let_\n_**L**_ _S,S denote the principal submatrix indexed by S \u2286_ [ _n_ ] _. Then, for all i, j \u2208_ _S, we have_\n\n_D_ _**L**_ ( _i, j_ ) _\u2264_ _D_ _**L**_ _S,S_ ( _i, j_ ) _._\n\n_Proof._ Let _**D**_ := diag( _**L**_ ) and\n\n_**A**_ := _**D**_ _[\u2212]_ [1] ( _**D**_ _\u2212_ _**L**_ ) = _**I**_ _\u2212_ _**D**_ _[\u2212]_ [1] _**L**_ _,_\n\nwhich represents the transition matrix of the associated graph to _**L**_ . Then _**L**_ = _**D**_ ( _**I**_ _\u2212_ _**A**_ ). Therefore,\n_**L**_ _[\u2212]_ [1] = ( _**I**_ _\u2212_ _**A**_ ) _[\u2212]_ [1] _**D**_ _[\u2212]_ [1] . We also have _**L**_ _S,S_ = _**D**_ _S,S_ ( _**I**_ _\u2212_ _**A**_ ) _S,S_ and ( _**L**_ _S,S_ ) _[\u2212]_ [1] = (( _**I**_ _\u2212_ _**A**_ ) _S,S_ ) _[\u2212]_ [1] ( _**D**_ _S,S_ ) _[\u2212]_ [1] .\nBy invertibility of _**L**_,\n\n( _**I**_ _\u2212_ _**A**_ ) _[\u2212]_ [1] = _**I**_ + _**A**_ + _**A**_ [2] + _\u00b7 \u00b7 \u00b7,_\n\n10\n\n( _**I**_ _S,S \u2212_ _**A**_ _S,S_ ) _[\u2212]_ [1] = _**I**_ + _**A**_ _S,S_ + ( _**A**_ _S,S_ ) [2] + _\u00b7 \u00b7 \u00b7 ._\n\nConsequently, for any _i, j \u2208_ _S_ we have\n\n_\u221e_\n\ufffd\n\n_k_ =0\n\n_\u221e_\n\ufffd\n\n_k_ =0\n\n\ufffd( _**L**_ _S,S_ ) _[\u2212]_ [1][\ufffd]\n_ij_ _[,]_\n\n_ij_ _[.]_\n\n\ufffd _**L**_ _[\u2212]_ [1][\ufffd]\n\n1\n_ij_ [=] _**L**_\n_jj_\n\n\ufffd _**A**_ _[k]_ [\ufffd]\n\n1\n_ij_ [=] _**L**_\n_jj_\n\n( _**A**_ _S,S_ ) _[k]_ [\ufffd]\n\ufffd\n\nIt follows from the nonnegativity of _**A**_ that \ufffd _**A**_ _[k]_ [\ufffd]\n\n_ij_ _[\u2265]_ \ufffd( _**A**_ _S,S_ ) _[k]_ [\ufffd]\n\nIt follows from the nonnegativity of _**A**_ that \ufffd _**A**_ _[k]_ [\ufffd] _ij_ _[\u2265]_ \ufffd( _**A**_ _S,S_ ) _[k]_ [\ufffd] _ij_ [for all] _[ k]_ [, and thus (] _**[L]**_ _[\u2212]_ [1][)] _[ij][ \u2265]_\n\n(( _**L**_ _S,S_ ) _[\u2212]_ [1] ) _ij_ . The result then follows from the definition of the distance.\n\n**2.2** **Constructing a Cover with Low Probability Distance Diameter**\n\nIn this section, we first present the definition of our low-diameter cover, which is characterized by\nthree parameters: _r_ in, _r_ out, and _\u03b1_ . The parameter _\u03b1_ serves as an upper bound on the number of\nouter balls that cover a single vertex. _r_ in is an upper bound on the diameter of the outer balls, and\nconsequently also on the diameter of the inner balls. Finally, _r_ out provides a lower bound on the\ndistance between vertices inside an inner ball and those outside its corresponding outer ball.\n\n**Definition 2.4** (( _r_ in _, r_ out _, \u03b1_ )-cover) **.** _Given an n-by-n invertible SDDM matrix_ _**L**_ _with integer en-_\n_tries in_ [ _\u2212U, U_ ] _, we say a set of pairs C_ = _{_ ( _V_ 1 _, W_ 1) _,_ ( _V_ 2 _, W_ 2) _, . . .,_ ( _Vk, Wk_ ) _}, with Vi, Wi \u2286_ [ _n_ ] _,_\n_for all i \u2208_ [ _k_ ] _, is a_ ( _rin, rout, \u03b1_ ) _-cover for_ _**L**_ _if it satisfies the following where D_ _**L**_ _is a probability_\n_distance with respect to_ _**L**_ _._\n\n_1. Vi \u2286_ _Wi \u2286_ [ _n_ ] _for all i \u2208_ [ _k_ ] _._\n\n_2. For every u \u2208_ [ _n_ ] _, there exists i \u2208_ [ _k_ ] _such that u \u2208_ _Vi._\n\n_3. For every u \u2208_ [ _n_ ] _, |{i \u2208_ [ _k_ ] : _u \u2208_ _Wi}| \u2264_ _\u03b1._\n\n_4. For any i \u2208_ [ _k_ ] _, and any u, v \u2208_ _Wi, D_ _**L**_ ( _u, v_ ) _\u2264_ _rin._\n\n_5. For any i \u2208_ [ _k_ ] _, and any u \u2208_ _Vi, v \u2208_ [ _n_ ] _\\ Wi, D_ _**L**_ ( _u, v_ ) _> rout._\n\n_We colloquially refer to Vi\u2019s as inner balls and Wi\u2019s as outer balls._\n\nThe following result states that a low-diameter cover with suitable values of the parameters _r_ in,\n_r_ out, and _\u03b1_ exists and can be computed in almost-linear time with high probability. The remainder\nof this section is devoted to proving this theorem.\n\n**Theorem 2.1.** _Let U >_ 32 _and n >_ 10 _. There exists an algorithm that given \u03b4 \u2208_ (0 _,_ 1) _and an_\n_n-by-n invertible SDDM matrix_ _**L**_ _with integer entries in_ [ _\u2212U, U_ ] _, with probability at least_ 1 _\u2212_ _\u03b4,_\n_computes an_ ( _rin, rout, \u03b1_ ) _-cover C for_ _**L**_ _with_\n\n_rin_ = 2 [2] _[\u2113]_ [+1] _,_ _rout_ = 2 _[\u2113][\u2212]_ [2] _,_ _\u03b1_ = 6 _\u2113_ [2] _\u00b7_ 16 _[\u2113]_ _\u00b7 \u2308_ log( _n/\u03b4_ ) _\u2309,_ _\u2113_ = _\u2308_ ~~\ufffd~~ log _n\u2309_ + 3\n\n_in m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _U_ ) log( _\u03b4_ _[\u2212]_ [1] ) log( _U\u03b4_ _[\u2212]_ [1] ) _bit operations._\n\n_Proof._ We first prove that the output of LowDiamConstruct satisfies all the properties in Definition 2.4 with probability at least 1 _\u2212_ _\u03b4_ . With probability at least 1 _\u2212_ _\u03b4/_ 2, all the linear systems\nin Step 4(a)ii of LowDiamConstruct are solved correctly. Therefore for the rest of the proof, we\nassume that we have the error guarantee of Step 4(a)ii.\n\n11\n\n**LowDiamConstruct** : Constructing a low-diameter cover.\nInput: _**L**_, an _n \u00d7 n_ invertible SDDM matrix with integer entries in [ _\u2212U, U_ ], and _\u03b4 \u2208_ (0 _,_ 1)\nOutput: _{_ ( _Vi, Wi_ ) _}i_ with properties stated in Definition 2.4\n\n1. Let _\u2113_ = _\u2308_ _[\u221a]_ log _n\u2309_ + 3, for _i \u2208_ [ _\u2113_ ], _di_ = 2 _[i]_ 4 _[\u2212][\u2113]_ [1] [,] _[ p][i]_ [ = min] _[{]_ _n_ [1] _[\u00b7]_ [ 2] _[\u2113]_ [(] _[i][\u2212]_ [1)] _[,]_ [ 1] _[}]_ [.]\n\n2. Let _M_ be the smallest power of two larger than _nU_ .\n\n3. Set _C_ = _\u2205_ .\n\n4. For _i \u2208_ [ _\u2113_ ], _j \u2208_ [ _\u2113_ ]:\n\n(a) Repeat for _B_ := 6 _\u00b7_ 16 _[\u2113]_ _\u00b7 \u2308_ log( _n/\u03b4_ ) _\u2309_ times:\n\ni. Sample a set _S_ by including each element of [ _n_ ] independently with probability\n\n_pj_ .\nii. Compute a vector _**y**_ such that with probability 1 _\u2212_ _\u03b4/_ (2 _\u2113_ [2] _B_ ) satisfies that\n_\u2212_ 1\n\ufffd\ufffd _**y**_ _\u2212_ _**L**_ **1** _S_ \ufffd\ufffd2 _[\u2264]_ _[M]_ _[\u2212]_ [2] _[d][i]_ [. E.g., using][ Corollary 1.7][.]\n\niii. Let _T_ = _{k \u2208_ [ _n_ ] : _**y**_ _k \u2265_ _M_ _[\u2212][d][i][/]_ [2] _}_ and _GT_ be the induced subgraph on _T_ of the\ngraph corresponding to _**L**_ .\n\niv. For each _v \u2208_ _S_, let _Cv_ be the connected component of _GT_ that contains _v_ . If for\nall _w \u2208_ _S \\ {v}_, _Cv \u2229_ _Cw_ = _\u2205_, then we set\n\n_V_ = _{k \u2208_ _Cv_ : _**y**_ _k \u2265_ _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _}_\n\nand\n_W_ = _{k \u2208_ _Cv_ : _**y**_ _k \u2265_ _M_ _[\u2212]_ [(] _[d][i][/]_ [2)+2] _},_\n\nand add ( _V, W_ ) to _C_ .\n\n5. Return _C_\n\nFigure 1: low-diameter construction\n\n1. Since _U >_ 32 and _n >_ 10, we have _di \u2265_ 32 and _M >_ 320. Therefore, _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _<_\n_M_ _[\u2212]_ [(] _[d][i][/]_ [2)+2], and\n\n_{k \u2208_ _Cu_ : _**y**_ _k \u2265_ _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _} \u2286{k \u2208_ _Cu_ : _**y**_ _k \u2265_ _M_ _[\u2212]_ [(] _[d][i][/]_ [2)+2] _},_\n\nfor all ( _V, W_ ) _\u2208C_ we have _V \u2286_ _W_ .\n\n2. Let _u \u2208_ [ _n_ ]. First we show that there exists _i \u2208_ [ _\u2113_ ] such that\n\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ _\u2264_ 8 _\u2113_ _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di/_ 4 _}_ _._ (3)\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nSuppose this does not hold for any _i \u2208_ [ _\u2113_ ]. Then since 8 _di_ +3 = 2 _di_ +1 = _di_, for _i \u2208_ [ _\u2113_ _\u2212_ 3], we\nhave\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di}_ _>_ 8 _\u2113_ _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di_ +3 _}_ _._\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\n12\n\nTherefore\n\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d_ 1 _}_ _>_ 8 _\u2113\u00b7_ ( _\u2308\u2113/_ 3 _\u2309\u2212_ 1) _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d\u2113}_ _._\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nNow note that\n8 _[\u2113][\u00b7]_ [(] _[\u2308][\u2113/]_ [3] _[\u2309\u2212]_ [1)] = 2 [3] _[\u2113][\u00b7]_ [(] _[\u2308][\u2113/]_ [3] _[\u2309\u2212]_ [1)] _\u2265_ 2 _[\u2113]_ [2] _[\u2212]_ [3] _[\u2113]_ _\u2265_ 2 [log] _[ n]_ = _n,_\n\nwhere the last inequality follows from\n\n_\u2113_ [2] _\u2212_ 3 _\u2113_ = _\u2113_ _\u00b7 \u2308_ ~~\ufffd~~ log _n\u2309_ _>_ log _n._\n\nThus\n\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d_ 1 _}_ _> n \u00b7_ _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d\u2113}_ _._ (4)\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nMoreover since ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _u \u2265_ 1 _/U_, \ufffd\ufffd _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d\u2113}_ \ufffd\ufffd _\u2265_ 1. Additionally\n\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212d_ 1 _}_ _\u2264_ _n._\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nHowever this contradicts (4). Therefore there exists _i \u2208_ [ _\u2113_ ] such that\n\n_{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ _\u2264_ 8 _\u2113_ _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di/_ 4 _}_ _._\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nNow since _p_ 1 = _n_ [1] [and] _[ p][n]_ [ = 1, there exists] _[ j][ \u2208]_ [[] _[\u2113]_ _[\u2212]_ [1], such that] _[ p][j][ <]_ [ 1]\n\n1 1\n_\u2264|{k \u2208_ [ _n_ ] : ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _k \u2265_ _M_ _[\u2212]_ [2] _[d][i]_ _}| \u2264_ [1] _._ (5)\n_pj \u00b7_ 2 _[\u2113]_ _[\u2264]_ _pj_ +1 _pj_\n\nTherefore for the _i_ and _j_ that satisfy (3) and (5), respectively, for any iteration of the inner\nloop (Step 4a of LowDiamConstruct), we have\n\n1 _S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ _\u2264_ 1 _._\n2 _[\u2113]_ _[\u2264]_ [E] \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\nLet _\u03b2_ = \ufffd\ufffd _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ \ufffd\ufffd. We have\n\nP _S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ = 1 = _\u03b2pj_ (1 _\u2212_ _pj_ ) _[\u03b2][\u2212]_ [1]\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\n\n_\u2265_ _\u03b2pje_ _[\u2212][p][j]_ [(] _[\u03b2][\u2212]_ [1)] _[/]_ [(1] _[\u2212][p][j]_ [)]\n\n_\u2265_ _\u03b2pje_ _[\u2212][p][j]_ _[\u03b2/]_ [(1] _[\u2212][p][j]_ [)]\n\n_\u2265_ 2 _[\u2212][\u2113]_ _e_ _[\u2212]_ [1] _._\n\nTherefore if _S_ 1 _, . . ., S_ 2 _\u2113_ is the sampled set in 2 _[\u2113]_ different iterations of the inner loop (Step 4a\nof LowDiamConstruct), with probability at least 1 _\u2212_ _e_ _[\u2212][e][\u2212]_ [1] _\u2265_ 0 _._ 3, there is a _q \u2208_ [2 _[\u2113]_ ] such\nthat\n\n_Sq \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ = 1 _._\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nNow condition on \ufffd\ufffd _Sq \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ \ufffd\ufffd = 1, the probability that\n\n_Sq \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di/_ 4 _}_ = 1\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\n13\n\nis\n\ufffd\ufffd _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di/_ 4 _}_ \ufffd\ufffd\n~~\ufffd~~ \ufffd _{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ ~~\ufffd~~ \ufffd _\u2265_ 8 [1] _[\u2113]_ _[,]_\n\nwhere the inequality follows from (3). Therefore with probability at least (1 _\u2212_ _e_ _[\u2212]_ [1] ) _\u00b7_ 0 _._ 3 _\u2265_ [1] 6\n\nover 16 _[\u2113]_ iterations of the inner loop, we pick at least one _S_ such that\n\n_S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212di/_ 4 _}_ = _S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _\u2212_ 1 _**e**_ ( _u_ )) _k \u2265_ _M_ _\u2212_ 2 _di}_ = 1 _._ (6)\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n\nTherefore over _B_ = 6 _\u00b7_ 16 _[\u2113]_ _\u00b7 \u2308_ log(2 _n/\u03b4_ ) _\u2309_ iterations, with probability at least 1 _\u2212_ 2 _\u03b4n_ [, we pick]\nat least one such _S_ .\n\nLet _v_ be the only element of _S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _k \u2265_ _M_ _[\u2212][d][i][/]_ [4] _}_ . Therefore\n\n_M_ _[\u2212][d][i][/]_ [4] _\u2264_ ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _v \u2264_ \ufffd( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _k_ = ( _**L**_ _[\u2212]_ [1] **1** _S_ ) _u \u2264_ _**y**_ _u_ + _M_ _[\u2212]_ [2] _[d][i]_ _,_ (7)\n\n_k\u2208S_\n\n_\u2212_ 1\nwhere the last inequality follow from \ufffd\ufffd _**y**_ _\u2212_ _**L**_ **1** _S_ \ufffd\ufffd2 _[\u2264]_ _[M]_ _[\u2212]_ [2] _[d][i]_ [. Thus] _**[ y]**_ _[u][ \u2265]_ _[M]_ _[\u2212][d][i][/]_ [4] _[ \u2212]_ _[M]_ _[\u2212]_ [2] _[d][i]_\nand _u \u2208_ _V_ . We now show that for all _w \u2208_ _S \\ {v}_, _Cv \u2229_ _Cw_ = _\u2205_ . Since _U >_ 64,\n\n1 _\u2264_ log _nU_ ( _M_ ) _\u2264_ 1 _._ 2 _,_ and 0 _._ 8 _\u2264_ log _M_ ( _nU_ ) _\u2264_ 1 _._ (8)\n\nNote that by (6), since _{v}_ = _S \u2229{k \u2208_ [ _n_ ] : ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _k \u2265_ _M_ _[\u2212][d][i][/]_ [4] _}_, for any _w_ _[\u2032]_ _\u2208_ _S \\ {v}_, we\nhave ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[u]_ [)] ) _w\u2032 < M_ _[\u2212]_ [2] _[d][i]_, and therefore\n\n_\u2212_ log _M_ (( _**L**_ _[\u2212]_ [1] ) _uw\u2032_ ) _>_ 2 _di,_\n\nand\n\n_D_ _**L**_ ( _u, w_ _[\u2032]_ ) = _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] ) _uw\u2032_ ) + 2 = _[\u2212]_ [lo] log [g] _[M]_ _M_ [((] ( _**[L]**_ _nU_ _[\u2212]_ [1][)] ) _[uw][\u2032]_ [)] + 2 _\u2265_ 2 _di_ + 2 _,_\n\nwhere the inequality follows from (8). By (7), _M_ _[\u2212][d][i][/]_ [4] _\u2264_ ( _**L**_ _[\u2212]_ [1] ) _uv_, and thus\n\n_di_\n\n4 _[\u2265\u2212]_ [log] _[M]_ [((] _**[L]**_ _[\u2212]_ [1][)] _[uv]_ [)] _[.]_\n\nTherefore by (8),\n\n0 _._ 3 _di_ + 2 = 1 _._ 2 _\u00b7_ _[d][i]_\n\n4 [+ 2] _[ \u2265\u2212]_ [log] _[nU]_ [(] _[M]_ [) log] _[M]_ [((] _**[L]**_ _[\u2212]_ [1][)] _[uv]_ [) + 2]\n\n= _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] ) _uv_ ) + 2 = _D_ _**L**_ ( _u, v_ ) _._ (9)\n\nFor the sake of contradiction, suppose there exists _w \u2208_ _S \\ {v}_ with _w \u2208_ _Cv_ . Moreover let\n_v_ = _k_ 0 _, k_ 1 _, . . ., kp\u2212_ 1 _, kp_ = _w_ be an arbitrary path between _v_ and _w_ that goes through _Cv_, i.e.,\n_k_ 0 _, . . ., kp \u2208_ _Cv_ . By triangle inequality (Claim 2.2), for all _g \u2208_ [ _p_ ], we have\n\n_D_ _**L**_ ( _u, kg_ ) _\u2264_ _D_ _**L**_ ( _u, kg\u2212_ 1) + _D_ _**L**_ ( _kg\u2212_ 1 _, kg_ ) _._\n\nMoreover by Claim 2.2, since for all _g \u2208_ [ _p_ ], _kg\u2212_ 1 and _kg_ are adjacent, _D_ _**L**_ ( _kg\u2212_ 1 _, kg_ ) _\u2264_ 4.\nTherefore since _D_ _**L**_ ( _u, v_ ) _\u2264_ 0 _._ 3 _di_ + 2, _D_ _**L**_ ( _u, w_ ) _\u2265_ 2 _di_ + 2, and _di \u2265_ 8, there exists _q \u2208_ [ _p_ ] such\nthat\n1 _._ 2 _\u00b7 di_ + 2 _\u2264_ _D_ _**L**_ ( _u, kq_ ) _\u2264_ 1 _._ 2 _\u00b7 di_ + 6\n\n14\n\nTherefore for all _w_ _[\u2032]_ _\u2208_ _S \\ {v}_\n\n2 _di_ + 2 _\u2264_ _D_ _**L**_ ( _u, w_ _[\u2032]_ ) _\u2264_ _D_ _**L**_ ( _u, kq_ ) + _D_ _**L**_ ( _kq, w_ _[\u2032]_ ) _\u2264_ 1 _._ 2 _\u00b7 di_ + 6 + _D_ _**L**_ ( _kq, w_ _[\u2032]_ ) _,_\n\nwhich gives\n_D_ _**L**_ ( _kq, w_ _[\u2032]_ ) _\u2265_ 0 _._ 8 _di \u2212_ 4 _._\n\nMoreover by triangle inequality\n\n1 _._ 2 _\u00b7 di_ + 2 _\u2264_ _D_ _**L**_ ( _u, kq_ ) _\u2264_ _D_ _**L**_ ( _u, v_ ) + _D_ _**L**_ ( _v, kq_ ) _\u2264_ 0 _._ 3 _di_ + 2 + _D_ _**L**_ ( _v, kq_ ) _,_\n\nwhich gives\n_D_ _**L**_ ( _v, kq_ ) _\u2265_ 0 _._ 9 _di._\n\nTherefore\n\n_[nU]_ [(] _**[L]**_ _[\u2212]_ [1] **[1]** _[S]_ [)] _[k][q]_ _\u2265_ _[\u2212]_ [log] _[nU]_ [(] _[|][S][| \u00b7]_ [ max] _[w][\u2032][\u2208][S]_ [(] _**[L]**_ _[\u2212]_ [1][)] _[k][q][w][\u2032]_ [)]\n\nlog _nU_ ( _M_ ) log _nU_ ( _M_ )\n\n_\u2212_ log _M_ ( _**L**_ _[\u2212]_ [1] **1** _S_ ) _kq_ = _[\u2212]_ [log] _[nU]_ [(] _**[L]**_ _[\u2212]_ [1] **[1]** _[S]_ [)] _[k][q]_\n\nlog _nU_ ( _M_ )\n\n_\u2265_ _[\u2212]_ [1 + min] _[w][\u2032][\u2208][S][ D]_ _**[L]**_ [(] _[k][q][,][ w][\u2032]_ [)] _[ \u2212]_ [2]\n\n_\u2265_ 0 _._ 66 _di \u2212_ 6 _._\n1 _._ 2\n\n[)] _[ \u2212]_ [2]\n\n_[w][\u2032][\u2208][S][ D]_ _**[L]**_ [(] _[k][q][,][ w]_\n\n_\u2265_ [0] _[.]_ [8] _[d][i][ \u2212]_ [7]\nlog _nU_ ( _M_ ) 1 _._ 2\n\nThus\n( _**L**_ _[\u2212]_ [1] **1** _S_ ) _kq \u2264_ _M_ _[\u2212]_ [0] _[.]_ [66] _[d][i]_ [+6] _._\n\nNow since _U >_ 32 and _n >_ 10, we have _di \u2265_ 32, _M >_ 320, and\n\n_**y**_ _kq \u2264_ _M_ _[\u2212]_ [0] _[.]_ [66] _[d][i]_ [+6] + _M_ _[\u2212]_ [2] _[d][i]_ _< M_ _[\u2212][d][i][/]_ [2] _._\n\nTherefore _kq_ is not in _T_ and is not in the connected component of _v_ . Therefore by this\ncontradiction for all _w \u2208_ _S \\ {v}_, _Cv \u2229_ _Cw_ = _\u2205_ .\n\n3. This holds because in each iteration of the loop (i), we pick at most one outer ball _W_ that\ncontains a vertex _u_ . Therefore each vertex is included in at most 6 _\u2113_ [2] _\u00b7_ 16 _[\u2113]_ _\u00b7 \u2308_ log( _n/\u03b4_ ) _\u2309_ outer\nballs.\n\n4. For the last two parts, let ( _V, W_ ) _\u2208C_ be an inner ball, outer ball pair and _i, j_ be their\ncorresponding iterand in the outer loop. Moreover let _v_ be the unique element in _S_ that is\ninside the connected component _Cv_ of _GT_ . Therefore\n\n_V_ = _{k \u2208_ _Cv_ : _**y**_ _k \u2265_ _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _}_\n\nand\n_W_ = _{k \u2208_ _Cv_ : _**y**_ _k \u2265_ _M_ [(] _[\u2212][d][i][/]_ [2)+2] _}._\n\nLet _y \u2208_ _W_ . Then we have\n\n( _**L**_ _[\u2212]_ [1] **1** _S_ ) _y_ + _M_ _[\u2212]_ [2] _[d][i]_ _\u2265_ _**y**_ _y \u2265_ _M_ [(] _[\u2212][d][i][/]_ [2)+2] _._\n\nMoreover\n( _**L**_ _[\u2212]_ [1] **1** _S_ ) _y_ = ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ + \ufffd ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _y._\n\n_w\u2208S\\{v}_\n\nNext, we show, for _w \u2208_ _S \\ {v}_,\n\n( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _y < M_ _[\u2212][d][i][/]_ [2] _._ (10)\n\n15\n\nThis is because for any _o \u2208_ [ _n_ ] _\\ {w}_,\n\n\ufffd _**L**_ _oq_ ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _q_ = 0\n\n_q\u2208_ [ _n_ ]\n\nTherefore\n\ufffd\n\n_q\u2208_ [ _n_ ] _\\{o}_\n\n_\u2212_ _**LL**_ _oooq_ ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _q_ = ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _o_\n\nSince [\ufffd] _\u2212_ _**L**_ _oq_\n_q\u2208_ [ _n_ ] _\\{o}_ _**L**_ _oo_ _[\u2264]_ [1, either (] _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[w]_ [)][)] _[o]_ [ is equal to (] _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[w]_ [)][)] _[q]_ [ for all] _[ q]_ [ that are adjacent]\n\nto _o_ or for one neighbor _q_, ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _q >_ ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _o_ . Continuing this argument inductively,\none can see that if ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _y \u2265_ _M_ _[\u2212][d][i][/]_ [2], then there is a path from _y_ to _w_ where for all\nvertices _q_ on this path ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _q \u2265_ _M_ _[\u2212][d][i][/]_ [2] . In this case _y \u2208_ _Cw_ and therefore since _y_ is also\nin _Cv_, we have _Cv \u2229_ _Cw \u0338_ = _\u2205_ which is a contradiction.\n\nTherefore\n( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y \u2265_ _M_ _[\u2212]_ [(] _[d][i][/]_ [2)+2] _\u2212_ _nM_ _[\u2212][d][i][/]_ [2] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _\u2265_ _M_ _[\u2212]_ [(] _[d][i][/]_ [2)+1] _._\n\nThus\n\n_D_ _**L**_ ( _v, y_ ) = _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ ) + 2 = _\u2212_ log _M_ (( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ ) log _nU M_ + 2\n\n_\u2264_ ( _[d][i]_\n\n2 _[\u2212]_ [1) log] _[nU][ M]_ [ + 2]\n\n_\u2264_ 0 _._ 6 _di \u2212_ 1 _._ 2 + 2 _\u2264_ 0 _._ 65 _di,_ (11)\n\nwhere the penultimate inequality follows from (8). Now by triangle inequality (Claim 2.2) for\n_y, y_ _[\u2032]_ _\u2208_ _W_,\n_D_ _**L**_ ( _y, y_ _[\u2032]_ ) _\u2264_ _D_ _**L**_ ( _v, y_ ) + _D_ _**L**_ ( _v, y_ _[\u2032]_ ) _\u2264_ 1 _._ 3 _di._\n\nTherefore since the largest _di_ is 4 _[\u2113]_, the result follows.\n\n5. Let _y \u2208_ _V_ and _z \u2208_ [ _n_ ] _\\ W_ . Similar to the proof of the previous property, we can show that\nfor all _w \u2208_ _S \\ {v}_, ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[w]_ [)] ) _y < M_ _[\u2212][d][i][/]_ [2] (see (10)). Moreover since _y \u2208_ _V_, we have\n\n( _**L**_ _[\u2212]_ [1] **1** _S_ ) _y_ + _M_ _[\u2212]_ [2] _[d][i]_ _\u2265_ _**y**_ _y \u2265_ _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _M_ _[\u2212]_ [2] _[d][i]_ _._\n\nTherefore since ( _**L**_ _[\u2212]_ [1] **1** _S_ ) _y_ = ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ + [\ufffd] _w\u2208S\\{v}_ [(] _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[w]_ [)][)] _[y]_ [,]\n\n( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y \u2265_ _M_ _[\u2212][d][i][/]_ [4] _\u2212_ _nM_ _[\u2212][d][i][/]_ [2] _\u2212_ 2 _M_ _[\u2212]_ [2] _[d][i]_ _\u2265_ _M_ _[\u2212][d][i][/]_ [4+0] _[.]_ [1] _._\n\nThus\n\n_D_ _**L**_ ( _v, y_ ) = _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ ) + 2 = _\u2212_ log _M_ (( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _y_ ) log _nU M_ + 2\n\n_\u2264_ ( _[d][i]_\n\n4 _[\u2212]_ [0] _[.]_ [1) log] _[nU][ M]_ [ + 2]\n\n_\u2264_ 0 _._ 3 _di \u2212_ 0 _._ 08 + 2 _\u2264_ 0 _._ 36 _di,_ (12)\n\nwhere the penultimate inequality follows from (8). Now by triangle inequality (Claim 2.2)\nand (12),\n_D_ _**L**_ ( _v, z_ ) _\u2264_ _D_ _**L**_ ( _v, y_ ) + _D_ _**L**_ ( _y, z_ ) _\u2264_ 0 _._ 36 _di_ + _D_ _**L**_ ( _y, z_ ) _._\n\n16\n\nAgain, by an argument similar to the previous part for (10), we have ( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _z < M_ _[\u2212][d][i][/]_ [2] ;\notherwise, _z_ would belong to _Cv_ and thus to _W_, which is a contradiction. Therefore by (8),\n\n_D_ _**L**_ ( _v, z_ ) = _\u2212_ log _nU_ (( _**L**_ _[\u2212]_ [1] _**e**_ [(] _[v]_ [)] ) _z_ ) + 2 = _[\u2212]_ [lo][g] _[M]_ [((] _**[L]**_ _[\u2212]_ [1] _**[e]**_ [(] _[v]_ [)][)] _[z]_ [)]\n\n2 [+ 2] _[,]_\n\n_**[e]**_ _[v]_ [)] _[z]_ [)]\n\n_[M]_ [((] _**[L]**_ _[\u2212]_ + 2 _>_ _[d][i]_\n\nlog _M_ ( _nU_ ) 2\n\nwhich gives\n_D_ _**L**_ ( _y, z_ ) _\u2265_ 0 _._ 14 _di_ + 2 _._\n\nThus since the smallest _di_ is 2 _[\u2113]_ [+1], the result follows.\n\nWe now bound the bit complexity and failure probability of the algorithm. The algorithm\nperforms a total of 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _n_ ) log( _n/\u03b4_ ) iterations. In each iteration, we solve a linear system\nthat takes\n\n\ufffd\n_O_ ( _m_ log( _M_ [4] _[\u2113]_ ) log( _UM_ [4] _[\u2113]_ _\u03b4_ _[\u2212]_ [1] _\u2113_ [2] _B_ )) = _m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _U_ ) log( _U\u03b4_ _[\u2212]_ [1] )\n\ntime. Moreover, in each iteration we compute connected components, which takes _O_ ( _m_ ) time.\nTherefore, the total bit complexity of the algorithm is bounded by\n\n_m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _U_ ) log( _\u03b4_ _[\u2212]_ [1] ) log( _U\u03b4_ _[\u2212]_ [1] ) _._\n\nFor the failure probability, note that since the total number of iterations is _\u2113_ [2] _B_, and each linearsystem solve succeeds with probability at least 1 _\u2212\u03b4/_ (2 _\u2113_ [2] _B_ ), by a union bound all linear systems are\nsolved correctly with probability at least 1 _\u2212_ _\u03b4/_ 2. Furthermore, as argued for the second property,\nwe obtain a desirable set _S_ for each vertex with probability at least 1 _\u2212_ _\u03b4/_ (2 _n_ ) over the _B_ iterations\nof the inner loop for the corresponding _i_ and _j_ . Hence, with probability at least 1 _\u2212_ _\u03b4/_ 2, we select\na desirable _S_ for all vertices throughout the algorithm, ensuring that all vertices are covered by\nthe resulting low-diameter cover. By another union bound, the algorithm therefore succeeds with\nprobability at least 1 _\u2212_ _\u03b4_ .\n\n### **3 The Almost-Linear-Time Algorithm**\n\nIn this section, we present our algorithm for solving SDDM linear systems with entrywise approximation guarantees in almost-linear time and prove the main theorem of the paper (Theorem 1.1).\nTo this end, we first recall the threshold decay (TD) framework from [GNY26], its requirements,\nand the guarantees it provides in Section 3.1. We then derive bounds on the error of solutions to\npartial linear systems solved within the TD framework in Section 3.2. Next, in Section 3.3, we show\nthat our low-diameter cover can be used to construct the partial solvers required in the iterations of\nthe TD framework. Finally, we provide implementation details for achieving almost-linear running\ntime and complete the proof in Section 3.4.\n\n**3.1** **The Threshold Decay Framework**\n\nOur almost-linear\u2013time algorithm builds upon the TD framework proposed in [GNY26]. In this\nframework, the linear system is solved by iteratively solving a sequence of partial linear systems,\nwhere each matrix is a principal submatrix of the original SDDM matrix, and the right-hand side\nvector is adaptively updated based on previously computed entrywise approximations to certain\n\nentries\u2014see ThresholdDecay.\n\n17\n\n**ThresholdDecay** : The algorithm framework for our solvers. Implementations are specified\nlater. Only correctness is proved for the framework.\nInput: _**L**_ : an _n \u00d7 n_ invertible RDDL matrix with integer entries in [ _\u2212U, U_ ],\n_**b**_ : a nonnegative vector with integer entries in [0 _, U_ ],\n_\u03f5_ : the target accuracy,\n_T_ : number of iterations (in this paper we always set it to _n_ )\nAssume that _U \u2265_ 2 _, T \u2265_ 10 _, \u03f5 \u2208_ (0 _,_ 1)\nOutput: vector \ufffd _**x**_ supported on some set _A \u2286_ [ _n_ ] such that \ufffd _**x**_ _A_ ~~_\u2248_~~ _\u03f5_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _A_ .\n\n(0) _\u03f5_\n1. Initialize _S_ [(0)] = [ _n_ ], _**b**_ [\ufffd] = _**b**_, and \ufffd _**x**_ (0) to a zero dimensional vector. Let _\u03f5L_ := 64 _T_ ( _nU_ ) [2] [.]\n\n2. For _t_ = 0 _. . . T_ :\n\n(a) Compute \ufffd _**x**_ [(] _[t]_ [)] defined on _S_ [(] _[t]_ [)] such that \ufffd\ufffd\ufffd\ufffd _**x**_ ( _t_ ) _\u2212_ _**L**_ _\u2212S_ [(] 1 _[t]_ [)] _,S_ [(] _[t]_ [)] _**[b]**_ [\ufffd] ( _t_ ) [\ufffd] \ufffd\ufffd2 _[\u2264]_ _[\u03f5][L]_ \ufffd\ufffd\ufffd\ufffd _**b**_ ( _t_ ) [\ufffd] \ufffd\ufffd2 [.]\n\n(b) Let _\u03b8t_ be the smallest power of two larger than 4( _nU_ 1 ) [2] \ufffd\ufffd\ufffd\ufffd _**b**_ ( _t_ ) [\ufffd] \ufffd\ufffd1 [.]\n\n(c) Let _F_ [(] _[t]_ [)] _\u2286_ _S_ [(] _[t]_ [)] be the indices of all the entries in \ufffd _**x**_ [(] _[t]_ [)] larger than or equal to _\u03b8t_, and\nlet _S_ [(] _[t]_ [+1)] _\u2190_ _S_ [(] _[t]_ [)] _\\ F_ [(] _[t]_ [)] .\n\n(d) Let \ufffd _**x**_ [(] _[t]_ [+1)] be defined on [ _n_ ] _\\ S_ [(] _[t]_ [+1)] with [ _**x**_ \ufffd [(] [ _n_ _[t]_ [+1)] ] _\\S_ [(] _[t]_ [)][;][ \ufffd] _**[x]**_ [ (] _F_ _[t]_ [+1)][(] _[t]_ [)][ ]] _[ \u2190]_ [[] _**[x]**_ [\ufffd][ (] _[t]_ [)][;][ \ufffd] _**[x]**_ [ (] _F_ _[t]_ [)][(] _[t]_ [)][].]\n\n(e) Create vector _**b**_ [\ufffd] ( _t_ +1) for the next iteration such that\n\n_**b**_ \ufffd( _t_ +1) ~~_\u2248_~~ _\u03f5/_ (8 _T_ ) _**b**_ _S_ ( _t_ +1) _\u2212_ _**L**_ _S_ ( _t_ +1) _,_ [ _n_ ] _\\S_ ( _t_ +1) \ufffd _**x**_ ( _t_ +1) (13)\n\n3. Output set _A_ := [ _n_ ] _\\ S_ [(] _[T]_ [)] and \ufffd _**x**_ := [ _**x**_ \ufffd _A_ ; \ufffd _**x**_ _S_ ( _T_ )] = [ _**x**_ \ufffd [(] _[T]_ [)] ; **0** ]\n\nFigure 2: The Threshold Decay framework.\n\n**Recall Threshold Decay.** Let ~~_**x**_~~ := _**L**_ _[\u2212]_ [1] _**b**_ denote the solution vector. In Threshold Decay,\n\n[ _n_ ] = _S_ [(0)] _\u2283_ _S_ [(1)] _\u2283_ _S_ [(2)] _\u2283_ _. . ._ are a chain of indices where _S_ [(] _[t]_ [)] is the set of indices for which an\nentrywise approximate has yet not been computed at iteration _t_ . We invoke Laplacian solver on\nthe set _S_ [(] _[t]_ [)] to solve \ufffd _**x**_ [(] _[t]_ [)] :\n\n\ufffd ( _t_ ) \ufffd( _t_ )\n_\u2225_ _**x**_ [(] _[t]_ [)] _\u2212_ ( _**L**_ _S_ ( _t_ ) _,S_ ( _t_ )) _[\u2212]_ [1] _**b**_ [\ufffd] _\u2225_ 2 _\u2264_ _\u03f5L\u2225_ _**b**_ _\u2225_ 2 (14)\n\nThe framework has the following correctness guarantees.\n\n**Lemma 3.1** (Lemma 3.7 of [GNY26]) **.** _Given \u03f5 \u2208_ (0 _,_ 1) _, integer T \u2265_ 10 _, U \u2265_ 2 _, an n_ _\u00d7_ _n invertible_\n_RDDL matrix_ _**L**_ _with integer entries in_ [ _\u2212U, U_ ] _, and a nonnegative vector_ _**b**_ _with integer weights_\n_in_ [0 _, U_ ] _, let_ ~~_**x**_~~ := _**L**_ _[\u2212]_ [1] _**b**_ _denote the exact solution vector,_ ThresholdDecay _has the following_\n_guarantees for all t \u2208_ [0 _, T_ ] _:_\n\n( _t\u2212_ 1) [\ufffd]\n_**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[.]_\n\n_1._\n\n_**b**_ ( _t_ ) [\ufffd] _**b**_ ( _t_ ) [\ufffd] 1\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[\u2264]_ [(] _[nU]_ [)] _[\u2212][t][ \u2225]_ _**[b]**_ _[\u2225]_ [1] _[. Moreover, if][ t >]_ [ 0] _[,]_ \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[\u2264]_ ( _nU_ )\n\n_2._ \ufffd _**x**_ [(] _[t]_ [)] ~~_\u2248_~~ _\u03f5t/_ (4 _T_ ) ~~_**x**_~~ [ _n_ ] _\\S_ ( _t_ ) _. Note that we define_ \ufffd _**x**_ [(0)] _to be a zero dimensional vector._\n\n18\n\n( _t_ ) [\ufffd]\n_3. For all i \u2208_ _S_ [(] _[t]_ [+1)] _,_ ~~_**x**_~~ _i <_ ( _nU_ ) _[\u2212]_ [2][ \ufffd\ufffd] _**b**_\n\ufffd [\ufffd] \ufffd\ufffd1 _[\u2264]_ [(] _[nU]_ [)] _[\u2212]_ [(] _[t]_ [+2)] _[ \u2225]_ _**[b]**_ _[\u2225]_ [1] _[.]_\n\n( _t_ )\nThe first property implies that the threshold _\u2225_ _**b**_ [\ufffd] _\u2225_ 1 decreases over iterations. The second\nproperty ensures that the computed values are accurate entrywise approximations. The third\nproperty guarantees that large entries are solved and removed from the set _S_ [(] _[t]_ [)] in iteration _t_ .\n\nWe invoke the following theorem from [GNY26] to establish the correctness of the framework.\nNote that in this paper we apply the framework only to SDDM matrices, although it generalizes\n\nto RDDL matrices.\n\n**Theorem 3.1** (Correctness of the Threshold Decay framework, Theorem 3.1 of [GNY26]) **.** _Given_\n_\u03f5 \u2208_ (0 _,_ 1) _, integer T \u2265_ 10 _, U \u2265_ 2 _, an n \u00d7 n invertible RDDL matrix_ _**L**_ _with integer entries in_\n\n[ _\u2212U, U_ ] _, and a nonnegative vector_ _**b**_ _with integer weights in_ [0 _, U_ ] _,_ ThresholdDecay _produces a_\n_vector_ \ufffd _**x**_ _and a set A \u2286_ [ _n_ ] _such that_ \ufffd _**x**_ _has support A, with the following properties hold:_\n\n  - _For any i \u2208_ [ _n_ ] _with_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i \u2265_ ( _nU_ ) _[\u2212]_ [(] _[T]_ [+1)] _\u2225_ _**b**_ _\u2225_ 1 _, we have i \u2208_ _A._\n\n  - _Our output is an entrywise_ exp( _\u03f5_ ) _-approximation on A, i.e.,_ \ufffd _**x**_ _A_ ~~_\u2248_~~ _\u03f5_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _A._\n\n  - _Specifically, when T_ = _n, we have_ \ufffd _**x**_ ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_ _._\n\n**3.2** **Errors Corresponding to Partial Linear Systems**\n\nIn this subsection, we present results that bound the error for solutions to partial linear systems,\ni.e., when a subset of entries is set to zero. We will use these bounds to establish the correctness\nof our algorithm.\n\n**Lemma 3.2.** _Let_ _**b**_ _be a nonnegative n-dimensional vector, and let P denote the set of its positive_\n_entries. If T \u2286_ [ _n_ ] _\\ P and D_ _**L**_ ( _u, v_ ) _\u2265_ _d >_ 0 _for all u \u2208_ _P and v \u2208_ _T_ _, then_\n\n_\u2212_ 1 _\u2212_ 1\n\ufffd\ufffd( _**L**_ ) _\u2212T,\u2212T_ _**b**_ _\u2212T \u2212_ ( _**L**_ _\u2212T,\u2212T_ ) _**b**_ _\u2212T_ \ufffd\ufffd2 _[< n]_ [2] _[.]_ [5] _[U]_ [(] _[nU]_ [)][2] _[\u2212][d][ \u2225]_ _**[b]**_ _[\u2225]_ [1] _[ .]_\n\n_Proof._ Let\n\n_**L**_ _\u2212T,\u2212T_ _**L**_ _\u2212T,T_\n_**L**_ =\n\ufffd _**L**_ _T,\u2212T_ _**L**_ _T,T_\n\n_,_\n\ufffd\n\nand let _**S**_ := _**L**_ _T,T \u2212_ _**L**_ _T,\u2212T_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _**L**_ _\u2212T,T_ be the Schur complement. Then, by Eq (1),\n\n( _**L**_ _[\u2212]_ [1] ) _T,\u2212T_ = _\u2212_ _**S**_ _[\u2212]_ [1] _**L**_ _T,\u2212T_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _,_\n\n( _**L**_ _[\u2212]_ [1] ) _\u2212T,\u2212T_ = ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] + ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _**L**_ _\u2212T,T_ _**S**_ _[\u2212]_ [1] _**L**_ _T,\u2212T_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _._\n\nWe can bound\n\n_\u2212_ 1 _\u2212_ 1\n\ufffd\ufffd( _**L**_ ) _\u2212T,\u2212T_ _**b**_ _\u2212T \u2212_ ( _**L**_ _\u2212T,\u2212T_ ) _**b**_ _\u2212T_ \ufffd\ufffd2 [=] _[ \u2225]_ [(] _**[L]**_ _[\u2212][T,][\u2212][T]_ [ )] _[\u2212]_ [1] _**[L]**_ _[\u2212][T,T]_ _**[ S]**_ _[ \u2212]_ [1] _**[L]**_ _[T,][\u2212][T]_ [ (] _**[L]**_ _[\u2212][T,][\u2212][T]_ [ )] _[\u2212]_ [1] _**[b]**_ _[\u2212][T][ \u2225]_ [2]\n= _\u2225_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _**L**_ _\u2212T,T_ ( _**L**_ _[\u2212]_ [1] ) _T,\u2212T_ _**b**_ _\u2212T \u2225_ 2\n_\u2264\u2225_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _\u2225_ 2 _\u2225_ _**L**_ _\u2212T,T \u2225\u221e\u2192_ 2 _\u2225_ ( _**L**_ _[\u2212]_ [1] ) _T,\u2212T_ _**b**_ _\u2212T \u2225\u221e_\n\n_\u2264_ _n_ [2] _\u00b7_ _[\u221a]_ _nU \u00b7_ ( _nU_ ) [2] _[\u2212][d]_ _\u2225_ _**b**_ _\u2212T \u2225_ 1\n\nwhere we used Lemma 1.6 to bound _\u2225_ ( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _\u2225_ 2, the fact that the maximum entry of _**L**_ is _U_ to\nbound _\u2225_ _**L**_ _\u2212T,T \u2225\u221e\u2192_ 2, and the property of the probability distance to bound _\u2225_ ( _**L**_ _[\u2212]_ [1] ) _T,\u2212T \u2225_ max in the\nlast inequality.\n\n19\n\nThe previous lemma provides an upper bound on the error incurred when removing a set of\nvertices that are sufficiently far\u2014in terms of probability distance\u2014from the support of the righthand side vector. We now extend this result to quantify the total error in approximating the\nfull solution of the linear system by zeroing out the corresponding entries for these far vertices.\nIntuitively, the corollary shows that vertices far from the nonzero entries of _**b**_ contribute negligibly\nto the solution of _**Lx**_ = _**b**_, and their removal introduces only a small error.\n\n**Corollary 3.3.** _Let_ _**L**_ _\u2208_ Z _[n][\u00d7][n]_ _be an invertible SDDM matrix, and let_ _**b**_ _be any nonnegative n-_\n_dimensional vector. Let P denote the set of indices of its positive entries, and let T \u2286_ [ _n_ ] _\\ P_ _. If_\n_D_ _**L**_ ( _u, v_ ) _\u2265_ _d >_ 0 _for all u \u2208_ _P, v \u2208_ _T_ _, then_\n\n\ufffd( _**L**_ _[\u2212]_ [1] _**b**_ ) _\u2212T_ ; ( _**L**_ _[\u2212]_ [1] _**b**_ ) _T_ \ufffd _\u2212_ \ufffd( _**L**_ _\u2212T,\u2212T_ ) _[\u2212]_ [1] _**b**_ _\u2212T_ ; **0** \ufffd [\ufffd]\n\ufffd\ufffd\ufffd \ufffd\ufffd2 _[\u2264]_ [(] _[nU]_ [)] _[\u2212][d]_ [+5] _[ \u2225]_ _**[b]**_ _[\u2225]_ [2] _[ .]_\n\n_Proof._ Since _**b**_ _T_ = **0**, we have ( _**L**_ _[\u2212]_ [1] ) _\u2212T,\u2212T_ _**b**_ _\u2212T_ = ( _**L**_ _[\u2212]_ [1] _**b**_ ) _\u2212T_ . Applying Lemma 3.2 to _**b**_ _\u2212T_, we\nobtain\n\n_\u2212_ 1 _\u2212_ 1\n\ufffd\ufffd( _**L**_ _\u2212T,\u2212T_ ) _**b**_ _\u2212T \u2212_ ( _**L**_ _**b**_ ) _\u2212T_ \ufffd\ufffd2 _[<]_ [ (] _[nU]_ [)][4] _[.]_ [5] _[\u2212][d][ \u2225]_ _**[b]**_ _[\u2212][T][ \u2225]_ [1] _[ \u2264]_ [(] _[nU]_ [)][4] _[.]_ [5] _[\u2212][d][\u221a][n][ \u2225]_ _**[b]**_ _[\u2212][T][ \u2225]_ [2] _[ .]_ (15)\n\nNext, observe that\n\n( _**L**_ _[\u2212]_ [1] _**b**_ ) _T_ = ( _**L**_ _[\u2212]_ [1] ) _T,P_ _**b**_ _P_ + ( _**L**_ _[\u2212]_ [1] ) _T,\u2212P_ _**b**_ _\u2212P_ = ( _**L**_ _[\u2212]_ [1] ) _T,P_ _**b**_ _P ._\n\nThus we have\n\ufffd\ufffd( _**L**_ _\u2212_ 1) _T,P_ _**b**_ _P_ \ufffd\ufffd2 _[\u2264]_ _[nU][ \u00b7]_ [ (] _[nU]_ [)][2] _[\u2212][d][ \u2225]_ _**[b]**_ _[P][ \u2225]_ [1][ = (] _[nU]_ [)][3] _[\u2212][d][ \u2225]_ _**[b]**_ _[P][ \u2225]_ [1] _[ .]_\n\n**3.3** **The Efficient Partial Solver**\n\nIn our ThresholdDecay framework, we introduce the boundary-expanded set for the use of our\nefficient partial solver in the next section.\n\n**The boundary-expanded set.** Recall that each step of ThresholdDecay, we extract the\nlarge entries in the solution vector of the subsystem\n\n( _t_ )\n_**L**_ _S_ ( _t_ ) _,S_ ( _t_ ) _**x**_ = _**b**_ [\ufffd] _._\n\nSuppose that the right-hand-side vector _**b**_ [\ufffd] ( _t_ ) has support _I \u2286_ [ _n_ ]. The combinatorial interpretation\nof the solution is the sum of random walks on the subgraph _S_ [(] _[t]_ [)] starting from the vertices in _I_ .\nBy leveraging the low-diameter cover, we enlarge the set _I_ to its _boundary-expanded set_, ensuring\nthat all but a small weighted fraction of the random walks remain inside this set. This allows us\nto solve the subsystem restricted to the boundary-expanded set instead of _S_ [(] _[t]_ [)], incurring only a\nsmall additive error, which is sufficient to accurately recover the large entries.\n\n**Definition 3.4** (Boundary-expanded set) **.** _Given a low-diameter cover C_ = _{_ ( _Vi, Wi_ ) _}i and a subset_\n_I \u2286_ [ _n_ ] _, we define the boundary-expanded set of I with respect to C as_\n\nExp _C_ ( _I_ ) := _{u \u2208_ [ _n_ ] : ( _\u2203_ ( _Vi, Wi_ ) _\u2208C_ )( _u \u2208_ _Vi \u2227|Wi \u2229_ _I| >_ 0) _}._\n\n20\n\n**PartialSolve** : The subroutine that solves the system _**L**_ _S,S_ _**x**_ = _**b**_ [\ufffd] using our low-diameter cover.\nInput: Access to _**L**_ in ThresholdDecay, a low-diameter cover _C_ of _**L**_,\na subset _S \u2286_ [ _n_ ], the right-hand-side vector _**b**_ [\ufffd], the accuracy parameter _\u03f5L_, and _\u03b4L \u2208_ (0 _,_ 1).\nThis procedure has access to the sets _I, H \u2286_ [ _n_ ].\nInput requirements: We assume _I_ = _{u \u2208_ _S_ : _**b**_ [\ufffd] _u >_ 0 _}_ and _H_ = Exp _C_ ( _I_ ) _\u2229_ _S_ .\n\nOutput: vector \ufffd _**x**_ such that _**x**_ _\u2212_ ( _**L**_ _S,S_ ) _\u2212_ 1 \ufffd _**b**_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5][L]_ \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd2 [.]\n\n1. We call the Laplacian solver in Corollary 1.7 under fixed-point arithmetic,\n\n_**x**_ \ufffd _H \u2190_ _Z \u00b7_ LaplacianSolver( _**L**_ _H,H_ _,_ _**b**_ [\ufffd] _H_ _/Z, \u03f5L/_ 2 _, \u03b4L_ ) _._ (17)\n\nwhere _Z \u2190_ _**b**_ _H_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd1 [is the normalization factor.]\n\n2. Output vector \ufffd _**x**_ := [ _**x**_ \ufffd _H_ ; \ufffd _**x**_ _S\\H_ ] = [ _**x**_ \ufffd; **0** ]\n\nFigure 3: Solve the linear system restricted on a subset of vertices using the low-diameter cover\n\nNote that Exp _C_ ( _I_ ) is a superset of _I_ that contains all the inner balls whose outer ball touches\n_I_ . An equivalent definition of Exp _C_ ( _I_ ) is\n\nExp _C_ ( _I_ ) := \ufffd _Vi._ (16)\n\n( _Vi,Wi_ ) _\u2208C_ : _|Wi\u2229I|>_ 0\n\nWe call standard Laplacian solvers on the boundary-expanded set Exp _C_ ( _I_ ) so that the entries on _I_\nhave good approximations.\n\n**The efficient partial solver.** We present the main subroutine, PartialSolve, of our almost\n( _t_ )\nlinear-time algorithm that solves a partial system _**L**_ _S_ ( _t_ ) _,S_ ( _t_ ) _**x**_ = _**b**_ [\ufffd] in the _t_ -th iteration of ThresholdDecay.\n\nWe state our main lemma for the correctness of PartialSolve.\n\n**Lemma 3.5** (Correctness of PartialSolve) **.** _For any_ _**L**_ _,_ _**b**_ [\ufffd] _, any I, H that satisfy the input re-_\n_quirements, any_ ( _r_ 1 _, r_ 2 _, s_ ) _-cover C such that r_ 2 _\u2265_ 5 + log _nU_ (2 _/\u03f5L_ ) _, the returned vector_ \ufffd _**x**_ _of_ PartialSolve _satisfies_\n\n_\u2212_ 1\ufffd\n_**x**_ _\u2212_ ( _**L**_ _S,S_ ) _**b**_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5][L]_ \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd2\n\n_with probability \u2265_ 1 _\u2212_ _\u03b4L._\n\n_Proof._ Recall that \ufffd _**x**_ is obtained from (17), which satisfies\n\n_**x**_ _H \u2212_ ( _**L**_ _H,H_ ) _\u2212_ 1 _**b**_ \ufffd _H_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5]_ 2 _[L]_\n\nwith probability at least 1 _\u2212_ _\u03b4L_ and _H_ = Exp _C_ ( _I_ ) _\u2229_ _S_ .\n\n21\n\n_**b**_ _H_ (18)\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd2 _[.]_\n\nFix any _u \u2208_ _S \\ H_, we have _u /\u2208_ Exp _C_ ( _I_ ). By the definition of Exp _C_ ( _I_ ), it holds that\n\n( _\u2200i_ )( _u /\u2208_ _Vi \u2228|Wi \u2229_ _I|_ = 0) _._\n\nBy the definition of the clusters, there must exist an _iu_ such that _u \u2208_ _Viu_ . Thus, _|Wiu \u2229_ _I|_ = 0,\nimplying that _D_ _**L**_ ( _u, v_ ) _> r_ 2 for all _v \u2208_ _I_, due to the last property Definition 2.4. Note that the\ndistance here is with respect to the Laplacian matrix of the entire graph. By Lemma 2.3, we have\n_D_ _**L**_ _S,S_ ( _u, v_ ) _\u2265_ _D_ _**L**_ ( _u, v_ ). Therefore, we have shown that\n\n_D_ _**L**_ _S,S_ ( _u, v_ ) _> r_ 2 _,_ _\u2200u \u2208_ _S \\ H, v \u2208_ _I._ (19)\n\n\ufffd We then apply Corollary 3.3 to the base Laplacian matrix _**L**_ _S,S_ and the right-hand-side vector\n_**b**_ defined on the set _S_, with _S \\ H_ being the target set, obtaining\n\n( _**L**_ _S,S_ ) _[\u2212]_ [1][ \ufffd] _**b**_ (20)\n\ufffd\ufffd\ufffd\ufffd \ufffd _H_ _[\u2212]_ [(] _**[L]**_ _[H,H]_ [)] _[\u2212]_ [1][ \ufffd] _**[b]**_ _[H]_ \ufffd\ufffd\ufffd2 _[\u2264]_ [(] _[nU]_ [)] _[\u2212][r]_ [2][+5][ \ufffd\ufffd\ufffd\ufffd] _**[b]**_ \ufffd\ufffd\ufffd2\n\n(20)\n_H_ _[\u2212]_ [(] _**[L]**_ _[H,H]_ [)] _[\u2212]_ [1][ \ufffd] _**[b]**_ _[H]_ \ufffd\ufffd\ufffd2 _[\u2264]_ [(] _[nU]_ [)] _[\u2212][r]_ [2][+5][ \ufffd\ufffd\ufffd\ufffd] _**[b]**_ \ufffd\ufffd\ufffd2\n( _**L**_ _S,S_ ) _[\u2212]_ [1] _**b**_ [\ufffd] _\u2264_ ( _nU_ ) _[\u2212][r]_ [2][+5][ \ufffd\ufffd] _**b**_ (21)\n\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd _S\\H_ \ufffd\ufffd\ufffd\ufffd2 \ufffd [\ufffd] \ufffd\ufffd\ufffd2\n\n_S\\H_\n\n_\u2264_ ( _nU_ ) _[\u2212][r]_ [2][+5][ \ufffd\ufffd] _**b**_ (21)\n\ufffd [\ufffd] \ufffd\ufffd\ufffd2\n\ufffd\ufffd\ufffd\ufffd2\n\nSetting _r_ 2 _\u2265_ 5 + log _nU_ (2 _/\u03f5L_ ), triangle inequality with Eq (18) and Eq (20) achieves\n\n_\u03f5L_\n\n_**x**_ _H \u2212_ ( _**L**_ _S,S_ ) _[\u2212]_ [1] _**b**_ [\ufffd] _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd _H_ \ufffd\ufffd\ufffd2 _[\u2264]_ \ufffd 2 [+ (] _[nU]_ [)] _[\u2212][r]_ [2][+5][\ufffd\ufffd\ufffd\ufffd\ufffd] _**[b]**_ \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5][L]_ \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd2 _[.]_\n\n_H_\n\n\ufffd\ufffd\ufffd2 _[\u2264]_ \ufffd _\u03f5_ 2 _L_\n\n_L_\n\n_**b**_ (22)\n2 [+ (] _[nU]_ [)] _[\u2212][r]_ [2][+5][\ufffd\ufffd\ufffd\ufffd\ufffd] _**[b]**_ \ufffd\ufffd\ufffd2 _[\u2264]_ _[\u03f5][L]_ \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd2 _[.]_\n\nRecall that \ufffd _**x**_ _S\\H_ = **0** . Thus, Eq (21) achieves\n\ufffd\ufffd\ufffd\ufffd\ufffd _**x**_ _S\\H \u2212_ \ufffd( _**L**_ _S,S_ ) _[\u2212]_ [1] _**b**_ [\ufffd] \ufffd _S\\H_ \ufffd\ufffd\ufffd\ufffd2\n\n_S\\H_\n\n_\u2264_ ( _nU_ ) _[\u2212][r]_ [2][+5][ \ufffd\ufffd] _**b**_ _**b**_ (23)\n\ufffd [\ufffd] \ufffd\ufffd\ufffd2 _[< \u03f5][L]_ \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd2 _[.]_\n\ufffd\ufffd\ufffd\ufffd2\n\nThe correctness lemma then follows from combining Eq (22) and Eq (23).\n\n**3.4** **The Almost-Linear-Time SDDM Solver**\n\nIn this section, we present our almost-linear-time SDDM solver, SDDMSolve, by plugging in PartialSolve into ThresholdDecay with our pre-computed low-diameter cover from LowDiamConstruct. The correctness of our solver follows directly from the correctness of the subroutines\n(Lemma 3.1, Lemma 3.5, and Theorem 2.1). We focus on fast implementations and the resulting\nalmost-linear running time bounds.\n\nIn iteration _t_, we call PartialSolve on the subsystem _**L**_ _S_ ( _t_ ) _,S_ ( _t_ ) defined on the subset _S_ [(] _[t]_ [)] . We\n\nuse _I_ [(] _[t]_ [)] _, H_ [(] _[t]_ [)] _, \u03b7_ [(] _[t]_ [)] _,_ \ufffd _**x**_ [(] _[t]_ [)] to denote _I, H, \u03b7,_ \ufffd _**x**_ of PartialSolve invoked in the _t_ -th iteration. In the\nworst case, the sum of the sizes of _S_ [(] _[t]_ [)] over all iterations is \u0398( _n_ [2] ). Our partial solver works on the\nsmaller subset _H_ [(] _[t]_ [)] instead of _S_ [(] _[t]_ [)] . The following lemma shows that each vertex occurs in only a\nsmall number of sets _H_ [(] _[t]_ [)] \u2019s.\n\n**Lemma 3.6.** _In_ SDDMSolve _, for any u \u2208_ [ _n_ ] _, it holds that_ [\ufffd] _[T]_ _t_ =0 **[1]** [[] _[u][ \u2208]_ _[H]_ [(] _[t]_ [)][]] _[ \u2264]_ _[r][in][.]_\n\nNote that by Theorem 2.1, we have that _r_ in = 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] is small. We first prove the lemma in\nthe next section. To get the almost-linear running time, we also discuss the efficient maintenance\nof the boundary-expanded set Exp _C_ ( _S_ [(] _[t]_ [)] ) in PartialSolve, as well as fast implementations of the\nupdates to the vectors and sets in ThresholdDecay.\n\n22\n\n**SDDMSolve** : The entrywise approximate linear system solver for SDDM matrices based on\nThresholdDecay and PartialSolve, with fast implementations.\nInput: _**L**_ _,_ _**b**_ _, \u03f5, \u03ba_ of ThresholdDecay, where _**L**_ is an invertible SDDM matrix. _\u03b4 \u2208_ (0 _,_ 1).\nWLOG, assume _**L**_ is irreducible.\nOutput: vector \ufffd _**x**_ such that \ufffd _**x**_ ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_ .\n\n1. Produce a low-diameter cover _C \u2190_ LowDiamConstruct( _**L**_ _, \u03b4/_ 2).\n\n2. Run ThresholdDecay, with vectors _**b**_ [\ufffd] ( _t_ ) _,_ \ufffd _**x**_ ( _t_ ) _,_ \ufffd _**x**_ ( _t_ ) represented by _O_ (log( _nU/\u03f5_ ))-bit\nfloating-point numbers.\n\n( _t_ )\n**Step 2a:** We maintain _I_ [(] _[t]_ [)] := _{u \u2208_ _S_ [(] _[t]_ [)] : _**b**_ [\ufffd] _u_ _[>]_ [ 0] _[}]_ [ and] _[ H]_ [(] _[t]_ [)][ :=][ Exp] _C_ [(] _[I]_ [(] _[t]_ [)][)] _[\u2229][S]_ [(] _[t]_ [)][ efficiently]\nover the iterations. In iteration _t_ :\n\n(a) \ufffd _**x**_ [(] _[t]_ [)] _\u2190_ PartialSolve( _**L**_ _, C, S_ [(] _[t]_ [)] _,_ _**b**_ [\ufffd] ( _t_ ) _, \u03f5L, \u03b4/_ (2 _n_ ) _, H_ ( _t_ ) _, I_ ( _t_ )).\n\n**Step 2b, 2c, 2d:** Work only on the subset of indices _H_ [(] _[t]_ [)] ; ignore the entries on _S_ [(] _[t]_ [)] .\n\n**Step 2e:** Initialize _n_ -dimensional vector \ufffd _**v**_ [(0)] = 0. In iteration _t_ :\n\n(a) Compute \ufffd _**v**_ [(] _[t]_ [+1)] defined on _S_ [(] _[t]_ [+1)], using in-place updates to \ufffd _**v**_ [(] _[t]_ [)],\n\n_**v**_ \ufffd [(] _[t]_ [+1)] _\u2190_ _**v**_ \ufffd [(] _S_ _[t]_ [(][)] _[t]_ [+1)] _[ \u2212]_ _**[L]**_ _[S]_ [(] _[t]_ [+1)] _[,F]_ [ (] _[t]_ [)][ \ufffd] _**[x]**_ [ (] _F_ _[t]_ [)][(] _[t]_ [)] _[.]_ (24)\n\n(b) Then, we have an implicit representation for _**b**_ [\ufffd] ( _t_ +1), that is,\n\n_**b**_ \ufffd( _t_ +1) := _**b**_ _S_ ( _t_ +1) + \ufffd _**v**_ ( _t_ +1) _._ (25)\n\nReturn the vector \ufffd _**x**_ produced by ThresholdDecay.\n\nFigure 4: The entrywise approximate linear system solver for SDDM matrices in almost-linear-time\n\n**3.4.1** **Bounding the sum of sizes**\n\nIn this section, we bound the sum of sizes of _H_ [(] _[t]_ [)] over all iterations _t_ . We need the following lemma\nfrom [GNY26].\n\n**Lemma 3.7** (Lemma 3.14 of [GNY26]) **.** _Let_ _**L**_ _be an n \u00d7 n invertible SDDM matrix with integer_\n_weights in_ [ _\u2212U, U_ ] _, and_ _**b**_ _be a nonnegative vector of dimension n. For any i, j \u2208_ [ _n_ ] _with_ _**L**_ _ij \u0338_ = 0 _,_\n_we have_\n\n( _nU_ ) _[\u2212]_ [1] _\u00b7_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j \u2264_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i \u2264_ _nU \u00b7_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j._\n\nWe also need the following generalized version of the lemma, using our probability distance\n(defined in Definition 2.1).\n\n**Lemma 3.8.** _Let_ _**L**_ _be an n \u00d7 n invertible SDDM matrix with integer weights in_ [ _\u2212U, U_ ] _, and_ _**b**_ _be_\n_a nonnegative vector of dimension n. For any i, j \u2208_ [ _n_ ] _with D_ _**L**_ ( _i, j_ ) _\u2264_ _d, we have_\n\n( _nU_ ) _[\u2212][d]_ _\u00b7_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j \u2264_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i \u2264_ ( _nU_ ) _[d]_ _\u00b7_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j_\n\n23\n\n_Proof._ Fix any _k \u2208_ [ _n_ ]. By the triangle inequality from Claim 2.2, we have _D_ _**L**_ ( _i, k_ ) _\u2264_ _D_ _**L**_ ( _i, j_ ) +\n_D_ _**L**_ ( _j, k_ ), and thus\n\n( _**L**_ _[\u2212]_ [1] ) _ik \u2265_ ( _**L**_ _[\u2212]_ [1] ) _ij_ ( _**L**_ _[\u2212]_ [1] ) _jk_ ( _nU_ ) _[\u2212]_ [2] _\u2265_ ( _nU_ ) _[\u2212][d]_ [+2] _\u00b7_ ( _**L**_ _[\u2212]_ [1] ) _jk_ ( _nU_ ) _[\u2212]_ [2] = ( _nU_ ) _[\u2212][d]_ _\u00b7_ ( _**L**_ _[\u2212]_ [1] ) _jk._ (26)\n\nNote that ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i_ and ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j_ can be written as linear combinations:\n\n_n_\n\ufffd( _**L**_ _[\u2212]_ [1] ) _jk_ _**b**_ _k._\n\n_k_ =1\n\n( _**L**_ _[\u2212]_ [1] _**b**_ ) _i_ =\n\n_n_\n\ufffd( _**L**_ _[\u2212]_ [1] ) _ik_ _**b**_ _k,_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j_ =\n\n_k_ =1\n\nSince _**b**_ _k \u2265_ 0 for all _k_, the inequality ( _**L**_ _[\u2212]_ [1] _**b**_ ) _i \u2265_ ( _nU_ ) _[\u2212][d]_ _\u00b7_ ( _**L**_ _[\u2212]_ [1] _**b**_ ) _j_ follows by taking the same linear\ncombination of both sides of (26). The other direction of the lemma follows by symmetry.\n\n_Proof of Lemma 3.6._ We fix any _u \u2208_ [ _n_ ]. Suppose that in iteration _t_, _u_ is contained in the set\n\n_H_ [(] _[t]_ [)] = Exp _C_ ( _I_ [(] _[t]_ [)] ) _\u2229_ _S_ [(] _[t]_ [)] _._\n\nWe thus have _u \u2208_ _S_ [(] _[t]_ [)] and _u \u2208_ Exp _C_ ( _I_ [(] _[t]_ [)] ). By the definition of boundary-expanded set, there exists\n( _V, W_ ) _\u2208C_ such that _u \u2208_ _V_ and _|W \u2229_ _I_ [(] _[t]_ [)] _| >_ 0. Let _v_ be any vertex in _W \u2229_ _I_ [(] _[t]_ [)] . By the definition\n\n( _t_ )\nof _I_ [(] _[t]_ [)], we have _**b**_ [\ufffd] _v_ _>_ 0 _._ Let ~~_**x**_~~ := _**L**_ _[\u2212]_ [1] _**b**_ . We now lower bound ~~_**x**_~~ _v_ .\n\nBy step 2e of ThresholdDecay, we have\n\n_**b**_ \ufffd( _t_ ) ~~_\u2248_~~ _\u03f5/_ (8 _T_ ) _**b**_ _S_ ( _t_ ) _\u2212_ _**L**_ _S_ ( _t_ ) _,_ [ _n_ ] _\\S_ ( _t_ ) \ufffd _**x**_ ( _t_ ) _._\n\nTherefore, either _**b**_ _v >_ 0, or there exists _w \u2208_ [ _n_ ] _\\ S_ [(] _[t]_ [)] such that _|_ _**L**_ _v,w| >_ 0 and \ufffd _**x**_ [(] _w_ _[t]_ [)] _[>]_ [ 0. In the]\nfirst case, ~~_**x**_~~ _v \u2265_ _**b**_ _v \u2265_ 1. In the second case, by Lemma 3.7,\n\n1\n~~_**x**_~~ _v \u2265_ ( _nU_ ) _[\u2212]_ [1] ~~_**x**_~~ _w_ ~~_\u2248_~~ _\u03f5t/_ (4 _T_ ) \ufffd _**x**_ _w \u2265_ _\u03b8t\u2212_ 1 =\n4( _nU_ ) [2]\n\n( _t\u2212_ 1) [\ufffd]\n_**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[.]_\n\nwhere the entrywise approximation follows from the second property of Lemma 3.1, and the last\ninequality follows from step 2c of ThresholdDecay. We thus obtain the following lower bound\n\n_\u2212_\n(where we define _**b**_ [\ufffd] ( 1) as the all-ones vector to handle the first case)\n\n1\n~~_**x**_~~ _v \u2265_ 8( _nU_ ) [2]\n\n( _t\u2212_ 1) [\ufffd]\n_**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[.]_\n\nSince _u, v_ are in the same outer ball _W_ in the low-diameter cover _C_, by the fourth property of\nDefinition 2.4, we have _D_ _**L**_ ( _u, v_ ) _\u2264_ _r_ in. Therefore, by Lemma 3.8,\n\n( _t\u2212_ 1) [\ufffd]\n~~_**x**_~~ _u \u2265_ ~~_**x**_~~ _v \u00b7_ ( _nU_ ) _[\u2212][r]_ [in] _\u2265_ ( _nU_ ) _[\u2212][r]_ [in] _[\u2212]_ [3][ \ufffd\ufffd] _**b**_ (27)\n\ufffd [\ufffd] \ufffd\ufffd1 _[.]_\n\nIf _u_ survives after _r_ in + 1 iterations, then _u \u2208_ _S_ [(] _[t]_ [+] _[r]_ [in][+1)] and by Lemma 3.1,\n\n( _t_ + _r_ in) [\ufffd] ( _t\u2212_ 1) [\ufffd]\n~~_**x**_~~ _u <_ ( _nU_ ) _[\u2212]_ [2][ \ufffd\ufffd] _**b**_ _**b**_\n\ufffd [\ufffd] \ufffd\ufffd1 _[<]_ [ (] _[nU]_ [)] _[\u2212]_ [3] _[\u2212][r]_ [in] \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1\n\nwhere we repeatedly applied property 1 of Lemma 3.1 for the second inequality. This contradicts\nwith (27). Therefore, for any _u \u2208_ [ _n_ ], it must survive at most _r_ in iterations, and thus\n\n_T_\n\ufffd **1** [ _u \u2208_ _H_ [(] _[t]_ [)] ] _\u2264_ _r_ in _._\n\n_t_ =0\n\n24\n\n**3.4.2** **Maintaining the vector** _**b**_ [\ufffd] ( _t_ )\n\nThe implementation of step 2e (stated in SDDMSolve) is the same implementation as in Pre\ndictiveSDDMSolver of [GNY26]. This maintains the vector _**b**_ [\ufffd] ( _t_ ) efficiently over the iterations\nby storing an extra vector \ufffd _**v**_ [(] _[t]_ [)] .\n\n( _t_ )\nNote that _F_ [(] _[t]_ [)] = _S_ [(] _[t]_ [)] _\\_ _S_ [(] _[t]_ [+1)] is the set of removed vertices in iteration _t_ . We update _**b**_ [\ufffd] on the\nedges from _F_ [(] _[t]_ [)] to _S_ [(] _[t]_ [+1)], i.e., the nonzero entries of _**L**_ _S_ ( _t_ +1) _,F_ ( _t_ ). Each edge only contributes once\nover all iterations, so the total number of arithmetic operation is _O_ ( _n_ + _m_ ). The detailed proof\nappears in the proof of Lemma 3.13 of [GNY26].\n\n**Claim 3.9** (Lemma 3.13 of [GNY26]) **.** _The implementation of Step 2e in_ SDDMSolve _runs in a_\n_total of O_ (( _n_ + _m_ ) log( _nU/\u03f5_ )) _bit operations. There are only O_ ( _n_ + _m_ ) _total entry updates to the_\n\n( _t_ )\n_vector_ \ufffd _**v**_ [(] _[t]_ [)] _and_ _**b**_ [\ufffd] _._\n\nFurthermore, we need to track the norms of the vector _**b**_ [\ufffd] ( _t_ ), including _**b**_ ( _t_ ) [\ufffd] _**b**_ ( _t_ ) [\ufffd]\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 [and] \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd2 [, for]\nuse in other steps of the algorithm. This can be implemented efficiently as well.\n\n( _t_ ) [\ufffd] ( _t_ ) [\ufffd]\n**Claim 3.10.** _In_ SDDMSolve _, for any constant c >_ 0 _, we can maintain_ _**b**_ _**b**_\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd1 _[and]_ \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd2 _[up]_\n\n_to multiplicative error of_ ( _\u03f5/_ ( _nU_ )) _[c]_ _with total O_ (( _n_ + _m_ ) log( _nU/\u03f5_ ) log _n_ ) _bit operations._\n\n_Proof._ By Claim 3.9, there are only _O_ ( _n_ + _m_ ) total updates to the vector \ufffd _**v**_ [(] _[t]_ [)] . Observe that it\nsuffices to compute the sum of _p_ -th powers over the index set _S_ [(] _[t]_ [)], since\n\n\ufffd\ufffd\ufffd\ufffd _**b**_ ( _t_ ) [\ufffd] \ufffd\ufffd _p_ [=] \ufffd ( _**b**_ _i_ + _**v**_ [(] _i_ _[t]_ [)][)] _[p][.]_\n\n\ufffd ( _**b**_ _i_ + _**v**_ [(] _i_ _[t]_ [)][)] _[p][.]_\n\n_i\u2208S_ [(] _[t]_ [)]\n\n_p_ [=] \ufffd\n\nWe can maintain this sum while updating _S_ [(] _[t]_ [)] and _**v**_ [(] _[t]_ [)] . There are _n_ vertex removals from _S_ [(] _[t]_ [)] and\n_O_ ( _n_ + _m_ ) entry updates to _**v**_ [(] _[t]_ [)] . However, directly subtracting the sum when removing vertices from\n_S_ [(] _[t]_ [)] can cause numerical issues due to cancelation. To avoid this, we use dynamic data structures\nthat maintain partial sums. A segment tree supports _O_ (log _n_ ) update and query time per operation.\nWe conclude the claim by using an _O_ (log( _nU/\u03f5_ ))-bit floating-point number for each node of the\nsegment tree.\n\n**3.4.3** **Maintaining** _I_ [(] _[t]_ [)] **and** _H_ [(] _[t]_ [)]\n\nIn this section, we discuss how the set _I_ [(] _[t]_ [)] and _H_ [(] _[t]_ [)] are maintained efficiently. Recall the input\n\n( _t_ )\nrequirements for PartialSolve, _I_ [(] _[t]_ [)] = _{u \u2208_ _S_ [(] _[t]_ [)] : _**b**_ [\ufffd] _u_ _[>]_ [ 0] _[}]_ [, and] _[ H]_ [(] _[t]_ [)][ =][ Exp] _C_ [(] _[I]_ [(] _[t]_ [)][)] _[ \u2229]_ _[S]_ [(] _[t]_ [)][.]\n\n( _t_ )\n**Maintaining** _I_ [(] _[t]_ [)] **.** Note that there is no numerical issue here. Since _**b**_ [\ufffd] is constructed with multiplicative approximation guarantees (and represented using floating points), it is easy to distinguish\na nonzero value from a zero, as no cancelation occurs throughout our algorithm.\n\nBy Claim 3.9, there are only _O_ ( _n_ + _m_ ) total entry updates to _**b**_ [\ufffd] ( _t_ ). Consequently, maintaining\n\n( _t_ )\n_I_ [(] _[t]_ [)] alongside _**b**_ [\ufffd] is straightforward in total time _O_ ( _n_ + _m_ ).\n\n_I_ [(] _[t]_ [)] has a more desirable property, as shown in the next claim.\n\n**Claim 3.11.** _For any iteration t < T and any vertex u \u2208_ _S_ [(] _[t]_ [+1)] _, if_ _**b**_ [\ufffd] ( _ut_ ) _>_ 0 _, then it follows that_\n\ufffd( _t_ +1)\n_**b**_ _u_ _>_ 0 _._\n\n25\n\n_Proof._ It follows directly from the construction of _**b**_ [\ufffd] ( _t_ ), (24) and (25), and the fact that _**L**_ _S_ ( _t_ +1) _,F_ ( _t_ )\n\nonly has non-positive entries while \ufffd _**x**_ [(] _F_ _[t]_ [)][(] _[t]_ [)][ has positive entries.]\n\nThe claim shows that each vertex _u_ is inserted to _I_ [(] _[t]_ [)] only once. It is removed from _I_ [(] _[t]_ [)] only\nwhen _u_ is no longer in the set _S_ [(] _[t]_ [)] .\n\n**Maintaining** _H_ [(] _[t]_ [)] **.** By the equivalent definition of boundary-expanded set (16),\n\n_Vi_ =\n\n\ufffd \ufffd\n\n( _Vi,Wi_ ) _\u2208C_ : _|Wi\u2229I|>_ 0 _u\u2208I_\n\nExp _C_ ( _I_ ) = \ufffd\n\n_u\u2208I_\n\n_Vi_\n\n\ufffd\n\ufffd\n\n( _Vi,Wi_ ) _\u2208C_ : _u\u2208Wi_\n\n= \ufffd Cores _C_ ( _u_ ) _._\n\ufffd _u\u2208I_\n\n=\n\ufffd\n\ufffd\n\nwhere Cores _C_ ( _u_ ) := [\ufffd] ( _Vi,Wi_ ) _\u2208C_ : _u\u2208Wi_ _[V][i]_ [ is the union of cores of the balls containing] _[ u]_ [. We maintain]\nthe set _H_ [(] _[t]_ [)] = Exp _C_ ( _I_ [(] _[t]_ [)] ) _\u2229_ _S_ [(] _[t]_ [)] as follows:\n\n  - Create a counter cnt _i_ for each cluster _i \u2208|C|_, with initial value 0. Maintain the indices of\npositive counters _C>_ 0 := _{i_ : cnt _i >_ 0 _}_ .\n\n  - Insert/Delete _u_ in _I_ [(] _[t]_ [)] : For each _i_ such that ( _Vi, Wi_ ) _\u2208C_ and _u \u2208_ _Wi_, increment/decrement\ncnt _i_ by 1 and update _C>_ 0.\n\n  - Build _H_ [(] _[t]_ [)] in iteration _t_ : Build the union set by removing duplicates\n\n_H_ [(] _[t]_ [)] _\u2190_ _Vi._\n\ufffd\n\n_i\u2208C>_ 0\n\nBy the third property of Definition 2.4 and that _C_ is an ( _r_ in _, r_ out _, \u03b1_ )-cover, each vertex _u_ is contained\nin at most _\u03b1_ outer balls in _C_ .\n\nFor the second step, since each vertex is inserted to _I_ [(] _[t]_ [)] only once, the total number of updates\nto the counters is bounded by 2 _n\u03b1_ = _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] .\n\nFor the third step, _H_ [(] _[t]_ [)] is constructed in time complexity _O_ ( _|H_ [(] _[t]_ [)] _| \u00b7 \u03b1_ ), since each vertex _u_ in\n_H_ [(] _[t]_ [)] has at most _\u03b1 \u2212_ 1 duplicates by the third property of _C_ .\n\nThe total time complexity for maintaining _H_ [(] _[t]_ [)] throughout the iterations is\n\n\ufffd\n\n_T_\n\ufffd\n\ufffd _t_ =0\n\n\ufffd _|H_ [(] _[t]_ [)] _|_\n\n_t_ =0\n\n_O_ ( _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] ) +\n\n_T_\n\ufffd _O_ ( _|H_ [(] _[t]_ [)] _| \u00b7 \u03b1_ ) = _O_ ( _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] ) + _\u03b1 \u00b7 O_\n\n_t_ =0\n\n= _O_ ( _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] ) + _\u03b1 \u00b7 n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] = _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _._\n\nwhere the second equality follows from Lemma 3.6. We summarize our discussions into the following\nclaim.\n\n**Claim 3.12.** _In_ SDDMSolve _, H_ [(] _[t]_ [)] _can be maintained in time complexity n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _throughout_\n_the iterations._\n\n**3.4.4** **Wrap-up**\n\nIn this section, we put everything together to prove the main theorem of the paper.\n\n26\n\n**Theorem 1.1.** _There exists a randomized algorithm_ SDDMSolve _such that, for any \u03b4 \u2208_ (0 _,_ 1)\n_and any \u03f5 >_ ( _nU_ ) _[\u2212]_ [2] _\u221a_ log _n (i.e., not exponentially small), any invertible SDDM matrix_ _**L**_ _\u2208_ Z _n\u00d7n_\n\n_with m nonzero integer entries in_ [ _\u2212U, U_ ] _and a nonnegative vector_ _**b**_ _\u2208_ Z _[n]_ _with integer entries in_\n\n[0 _, U_ ] _, with probability at least_ 1 _\u2212_ _\u03b4, computes the entrywise approximate solution_\n\n_**x**_ \ufffd ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_\n\n_whose entries are represented by O_ (log( _nU/\u03f5_ )) _-bit floating points, using_ [2]\n\n\ufffd\n_O_ ( _m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log( _U_ ) log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] ))\n\n_bit operations._\n\n_Proof._ We start by recalling the parameters.\n\n**Parameters.** In Step 1 of SDDMSolve, it follows from Theorem 2.1 that _C_ is an ( _r_ in _, r_ out _, \u03b1_ )cover with parameters as below, for _\u2113_ := _\u2308_ _[\u221a]_ log _n\u2309_ + 3:\n\n  - Diameter: _r_ in = 2 [2] _[\u2113]_ [+1] = 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] .\n\n  - Outer gap: _r_ out = 2 _[\u2113][\u2212]_ [2] = 2 [\u2126(] _[\u221a]_ [log] _[ n]_ [)] .\n\n  - Size parameter: _\u03b1_ = 6 _\u2113_ [2] _\u00b7_ 16 _[\u2113]_ _\u00b7 \u2308_ log( _n/\u03b4_ ) _\u2309_ = 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] .\n\nThis cover is produced in _O_ [\ufffd] ( _mn_ _[o]_ [(1)] log( _U\u03b4_ _[\u2212]_ [1] )) bit operations.\n\nIn Step 2 of SDDMSolve, we run ThresholdDecay for _T_ = _n_ iterations.\n\n**Correctness.** We apply Lemma 3.5 to show that PartialSolve satisfies the guarantees of\nStep 2a in ThresholdDecay. It suffices to verify\n\n5 + log _nU_ (2 _/\u03f5L_ ) = 5 + log _nU_ (128 _T_ ( _nU_ ) [2] _/\u03f5_ ) _\u2264_ 9 + log _nU_ (1 _/\u03f5_ ) _\u2264_ 9 + 2 _\u221a_ log _n < r_ in\n\nSince _r_ in = 2 [2] _[\u2113]_ [+1], the inequality holds provided that _\u03f5 \u2265_ 1 _/_ poly( _n_ ). It then follows from the\ncorrectness of ThresholdDecay (Theorem 3.1) that \ufffd _**x**_ ~~_\u2248_~~ _\u03f5_ _**L**_ _[\u2212]_ [1] _**b**_, concluding the correctness of\nour almost-linear-time solver.\n\nAbout the probability correctness:\n\n  - Failure probability by using LowDiamConstruct is _\u2264_ _\u03b4/_ 2. We call this procedure once.\n\n  - Failure probability by using PartialSolve is _\u2264_ _\u03b4/_ (2 _n_ ). We call this procedure once each\niteration, so overall _n_ times.\n\nUnion bound gives the failure probability of SDDMSolve to be _\u2264_ _\u03b4_, thus the algorithm\nsucceeds with probability at least 1 _\u2212_ _\u03b4_ .\n\n2 \ufffd _O_ suppresses the log log( _U\u03f5\u2212_ 1 _\u03b4\u2212_ 1) factors.\n\n27\n\n**Bit complexity.** By Lemma 3.6, for any _u \u2208_ [ _n_ ], we have\n\n_T_\n\ufffd **1** [ _u \u2208_ _H_ [(] _[t]_ [)] ] _\u2264_ _r_ in = 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _,_\n\n_t_ =0\n\nand consequently, the total size of _H_ [(] _[t]_ [)] over all iterations is almost-linear in _n_, i.e.,\n\n_T_\n\ufffd _|H_ [(] _[t]_ [)] _| \u2264_ _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _._ (28)\n\n_t_ =0\n\nBy Claim 3.12, the set _H_ [(] _[t]_ [)] is maintained in _n_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] operations throughout the iterations.\n\n**Step 2a** is the dominating step. We bound the total time of the Laplacian solvers we invoked.\nBy\ufffd Corollary 1.7, the Laplacian solver in iteration _t_ solves the subsystem _**L**_ _H_ ( _t_ ) _,H_ ( _t_ ), and requires\n_O_ (nnz( _**L**_ _H_ ( _t_ ) _,H_ ( _t_ )) log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] )) bit operations. The sum of sparsity can be bounded by\n\n_T_\n\ufffd nnz( _**L**_ _H_ ( _t_ ) _,H_ ( _t_ )) _\u2264_\n\n_t_ =0\n\n_T_\n\ufffd\n\n_t_ =0\n\n\ufffd **1** [ _u \u2208_ _H_ [(] _[t]_ [)] ] _\u00b7_ deg( _u_ )\n\n_u\u2208_ [ _n_ ]\n\n\ufffd\n\n_\u00b7_ deg( _u_ ) _\u2264_ _m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _._\n\n_\u2264_\n\ufffd\n\n_u\u2208_ [ _n_ ]\n\n_T_\n\ufffd\n\ufffd _t_ =0\n\n\ufffd **1** [ _u \u2208_ _H_ [(] _[t]_ [)] ]\n\n_t_ =0\n\nFor **Steps 2b, 2c, 2d**, every vector is supported only on the set _H_ [(] _[t]_ [)] . A straightforward implementation that iterates over _H_ [(] _[t]_ [)] gives a total of _O_ [\ufffd] (2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] _\u00b7 n_ ) bit operations. For example, in\n**Step 2c**, we need to compute the set _F_ [(] _[t]_ [)] _\u2286_ _S_ [(] _[t]_ [)] such that\n\n_F_ [(] _[t]_ [)] = _{i \u2208_ _S_ [(] _[t]_ [)] : \ufffd _**x**_ [(] _i_ _[t]_ [)] _\u2265_ _\u03b8t}._\n\nWe cannot afford enumerating over _S_ [(] _[t]_ [)] ; instead, we enumerate over _H_ [(] _[t]_ [)] and skip the indices in\n_S_ [(] _[t]_ [)] _\\_ _H_ [(] _[t]_ [)] since we know they are all zeros. By Eq (28), this step take a total of almost-linear time.\n\nLastly, by Claim 3.9 and Claim 3.10, **Step 2e** is implemented in _O_ (( _n_ + _m_ ) log( _nU/\u03f5_ )) time.\nPutting everything together, we conclude that SDDMSolve runs in _O_ [\ufffd] ( _m_ 2 _[O]_ [(] _[\u221a]_ [log] _[ n]_ [)] log [2] ( _U\u03f5_ _[\u2212]_ [1] _\u03b4_ _[\u2212]_ [1] ))\nbit operations. The final running time follows by considering the running time of computing the\nlow-diameter cover as well.\n\n### **4 Conclusion**\n\nWe presented an almost-linear\u2013time algorithm for solving SDDM linear systems with entrywise\napproximation guarantees. A natural open question is whether one can achieve truly near-linear\nrunning time, that is, _O_ ( _m_ poly log _n_ ). In this work, we focused on inputs given in fixed-point\nrepresentation. However, as noted in [GNY26], the case of floating-point inputs presents additional\nchallenges due to possible reductions from shortest-path problems. Investigating algorithms for\nSDDM systems with floating-point inputs therefore remains an interesting direction for future\nresearch.\n\n### **References**\n\n[BGK [+] 11] Guy E Blelloch, Anupam Gupta, Ioannis Koutis, Gary L Miller, Richard Peng, and\nKanat Tangwongsan. Near linear-work parallel SDD solvers, low-diameter decomposition, and low-stretch subgraphs. In _Proceedings of the twenty-third annual ACM_\n_symposium on Parallelism in algorithms and architectures_, pages 13\u201322, 2011. 1, 8\n\n28\n\n[CKM [+] 14] Michael B Cohen, Rasmus Kyng, Gary L Miller, Jakub W Pachocki, Richard Peng,\nAnup B Rao, and Shen Chen Xu. Solving SDD linear systems in nearly _m_ log [1] _[/]_ [2] _n_\ntime. In _Proceedings of the forty-sixth annual ACM symposium on Theory of computing_,\npages 343\u2013352, 2014. 1\n\n[Coh98] Edith Cohen. Fast algorithms for constructing _t_ -spanners and paths with stretch _t_ .\n_SIAM Journal on Computing_, 28(1):210\u2013236, 1998. 8\n\n[GKS23] Yuan Gao, Rasmus Kyng, and Daniel A. Spielman. Robust and practical solution of\nLaplacian equations by approximate elimination. _CoRR_, abs/2303.00709, 2023. 8\n\n[GNY26] Mehrdad Ghadiri, Hoai-An Nguyen, and Junzhao Yang. Entrywise approximation for\nmatrix inversion and linear systems. In _SODA_, 2026. 1, 3, 4, 5, 6, 8, 17, 18, 19, 23, 25,\n\n28\n\n[GTH85] Winfried K Grassmann, Michael I Taksar, and Daniel P Heyman. Regenerative analysis\nand steady state distributions for Markov chains. _Operations Research_, 33(5):1107\u20131116,\n1985. 8\n\n[Hey87] Daniel P Heyman. Further comparisons of direct methods for computing stationary\ndistributions of Markov chains. _SIAM Journal on Algebraic Discrete Methods_, 8(2):226\u2013\n232, 1987. 8\n\n[Hig90] Nicholas J Higham. Exploiting fast matrix multiplication within the level 3 BLAS.\n_ACM Transactions on Mathematical Software (TOMS)_, 16(4):352\u2013368, 1990. 8\n\n[HP84] WJ Harrod and RJ Plemmons. Comparison of some direct methods for computing\nstationary distributions of Markov chains. _SIAM journal on scientific and statistical_\n_computing_, 5(2):453\u2013469, 1984. 8\n\n[JS21] Arun Jambulapati and Aaron Sidford. Ultrasparse ultrasparsifiers and faster Laplacian\nsystem solvers. _ACM Transactions on Algorithms_, 2021. 1\n\n[KLP [+] 16] Rasmus Kyng, Yin Tat Lee, Richard Peng, Sushant Sachdeva, and Daniel A Spielman.\nSparsified Cholesky and multigrid solvers for connection Laplacians. In _Proceedings_\n_of the forty-eighth annual ACM symposium on Theory of Computing_, pages 842\u2013850,\n\n2016. 1\n\n[KMP11] Ioannis Koutis, Gary L Miller, and Richard Peng. A nearly- _m_ log _n_ time solver for SDD\nlinear systems. In _2011 IEEE 52nd Annual Symposium on Foundations of Computer_\n_Science_, pages 590\u2013598. IEEE, 2011. 1\n\n[KMP14] Ioannis Koutis, Gary L Miller, and Richard Peng. Approaching optimality for solving\nSDD linear systems. _SIAM Journal on Computing_, 43(1):337\u2013354, 2014. 1\n\n[KMST10] Alexandra Kolla, Yury Makarychev, Amin Saberi, and Shang-Hua Teng. Subgraph\nsparsification and nearly optimal ultrasparsifiers. In _Proceedings of the forty-second_\n_ACM symposium on Theory of computing_, pages 57\u201366, 2010. 1\n\n[KOSZ13] Jonathan A Kelner, Lorenzo Orecchia, Aaron Sidford, and Zeyuan Allen Zhu. A simple,\ncombinatorial algorithm for solving SDD systems in nearly-linear time. In _Proceedings_\n_of the forty-fifth annual ACM symposium on Theory of computing_, pages 911\u2013920, 2013.\n\n1\n\n29\n\n[KS16] Rasmus Kyng and Sushant Sachdeva. Approximate Gaussian elimination for Laplacians\n\n      - fast, sparse, and simple. In _FOCS_, pages 573\u2013582. IEEE Computer Society, 2016. 1\n\n[LS13] Yin Tat Lee and Aaron Sidford. Efficient accelerated coordinate descent methods and\nfaster algorithms for solving linear systems. In _2013 ieee 54th annual symposium on_\n_foundations of computer science_, pages 147\u2013156. IEEE, 2013. 1\n\n[O\u2019C93] Colm Art O\u2019Cinneide. Entrywise perturbation theory and error analysis for Markov\nchains. _Numerische Mathematik_, 65(1):109\u2013120, 1993. 8\n\n[O\u2019C96] Colm Art O\u2019Cinneide. Relative-error bounds for the LU decomposition via the GTH\nalgorithm. _Numerische Mathematik_, 73:507\u2013519, 1996. 8\n\n[PS14] Richard Peng and Daniel A Spielman. An efficient parallel solver for SDD linear systems.\nIn _Proceedings of the forty-sixth annual ACM symposium on Theory of computing_, pages\n333\u2013342, 2014. 1\n\n[ST14] D. Spielman and S. Teng. Nearly linear time algorithms for preconditioning and solving\nsymmetric, diagonally dominant linear systems. _SIAM Journal on Matrix Analysis and_\n_Applications_, 35(3):835\u2013885, 2014. Available at: `[http://arxiv.org/abs/cs/0607105](http://arxiv.org/abs/cs/0607105)` .\n1, 4, 6\n\n[Str69] Volker Strassen. Gaussian elimination is not optimal. _Numerische mathematik_,\n13(4):354\u2013356, 1969. 8\n\n30"}, {"role": "assistant", "content": "**Mechanism:** The algorithm employs an iterative 'Threshold Decay' framework, intelligently guided by a novel 'Low-Diameter Cover' and a unique 'probability distance' metric, to adaptively focus computational effort on the most significant solution components.\n\n**Explanation:** Consider solving a vast electrical circuit problem, where `L` is the circuit's conductance matrix and `b` is the applied current, yielding voltages `x`. Traditional solvers (like a general-purpose voltmeter) might give you an accurate overall voltage reading, but struggle to precisely measure tiny individual wire voltages if they vary wildly from the large ones. To get those tiny voltages accurately, you'd need an impossibly precise voltmeter, making the whole process too slow. This paper aims for *entrywise* accuracy, meaning each individual wire's voltage `x_i` is measured with high precision. The 'Threshold Decay' framework operates like a smart electrician. It identifies wires with currently large voltages, measures them, and 'fixes' them in the circuit. The problem then simplifies for the remaining wires. The critical challenge is knowing which *other* wires, not yet measured, might develop large voltages as the circuit changes, without exhaustively testing every single wire. This is where the 'Low-Diameter Cover' comes in. It's a specialized map of the circuit, where the 'distance' between two points `i` and `j` is not physical distance, but a 'probability distance' based on `-(log((L^-1)_ij))`. This distance intuitively quantifies how much a voltage change at `j` influences `i` via the inverse matrix. This special map groups wires into 'inner' and 'outer' zones (like nested sets in a hash map). Wires inside an inner zone are 'close' in this probability sense, but 'far' from those outside its corresponding outer zone. When the algorithm needs to process a subsystem (a loop iteration), it uses this map to 'predict' which wires (`H`, the active set) are truly important based on the known active voltages (`I`). If a wire is 'far' in probability distance from all known active voltages, it's mathematically safe to ignore its voltage (set it to zero) without corrupting the accuracy of the large voltages. This allows the algorithm to call a standard, faster `L x = b` solver (like a specific component tester) on a much smaller, relevant sub-circuit (`L_H,H`), iteratively refining the solution. Dynamic data structures, similar to hash maps and segment trees, efficiently track and update the active sets and `b` vector values throughout the process."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**4.1** **Setup**\n\nWe implement DynaExq using PyTorch [22] and HuggingFace\nTransformers [31], with AutoRound [16] providing low-bit expert quantization. All experiments are conducted on **RTX-5090**\nand **A6000** GPUs (32-48 GB HBM), representing realistic memoryconstrained single-device settings targeted by this work.\n**Models and Datasets.** We evaluate DynaExq on **Qwen3-30B-**\n**A3B** [1] and **Qwen3-80B-A3B** [2]. The 30B model contains 48\nlayers and 128 experts per layer (8 active), while the 80B variant\nincreases to 512 experts (10 active) with a comparable active parameter count of \u223c3B. Both models exhibit substantial expert-level\nredundancy, making them strong candidates for runtime precision\nadaptation.\nWe benchmark across diverse tasks: WikiText-2 [21], MMLUPro [30], GPQA [24], AIME25 [3], GSM8K [5], HumanEval [4], and\nMMLU-ProX [32]. These datasets jointly stress different aspects of\nmodel behavior, including linguistic and mathematical reasoning,\nmultilingual understanding, and code generation.\nTo isolate the effect of expert-level quantization, all non-expert\nand routing components remain in full precision. We evaluate DynaExq against uniform FP16, INT4, and INT2 baselines, ensuring\nconsistent routing dynamics and enabling a controlled study of\nexpert precision strategies.\n\nDynamic Expert Quantization for Scalable Mixture-of-Experts Inference\n\n**4.2** **Perplexity under Expert Quantization**\n\n**4.4** **Performance Metrics**\n\nWe further assess latency and throughput: time-to-first-token (TTFT),\ntime-per-output-token (TPOP), prefill throughput, and decode throughput (Figures 5). DynaExq achieves performance between highprecision (FP16/INT4) and low-precision (INT2/INT4) baselines,\ntypically retaining more than 85% of INT2 throughput.\nDespite selectively assigning high precision only to hot-path\nexperts, DynaExq maintains stable performance across both GPUs\nand both model sizes. This indicates that its asynchronous precision\nswitching pipeline effectively decouples background transitions\nfrom the forward path, avoiding runtime stalls.\nTaken together, these results show that DynaExq achieves a\nfavorable balance: it recovers much of the accuracy benefit of\nhigh-precision experts while incurring only moderate overhead\nrelative to uniformly low-precision inference. The resulting hybridprecision execution enables large MoE models to run on single-GPU\nhardware otherwise unable to host full-precision variants. As model\nscales continue to grow, this precision-aware approach provides a\npractical path toward sustaining deployability under increasingly\nstringent memory limits."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is dynamic, on-the-fly precision assignment for 'expert' sub-networks within a Mixture-of-Experts (MoE) model. Instead of quantizing all experts uniformly, DynaExq identifies 'hot-path' experts \u2013 those frequently invoked or critical to the current computation. These critical experts retain higher precision (e.g., INT4 or FP16), while less active experts are aggressively quantized to lower precision (e.g., INT2). This is akin to a tiered memory system: frequently accessed data (hot experts) resides in a faster, higher-resolution cache (high precision), while less used data is swapped to slower, lower-resolution storage (low precision). The 'asynchronous precision switching pipeline' is crucial; it acts like a background thread or a memory management unit that can prepare and switch an expert's precision in parallel, preventing it from blocking the main forward computation path. This allows for precision changes without introducing runtime stalls.\n\n**Explanation:** Think of an MoE model as a program with hundreds of specialized functions (experts), but for any given input, only a small subset of these functions are called. Traditionally, you might compile all these functions with the same floating-point precision, demanding a lot of memory. This system is like having a dynamic compiler that observes which functions are 'hot' (frequently executed or critical for the current task). For these hot functions, it uses a high-fidelity numerical representation (e.g., standard `float` or a 4-bit integer, which is more precise). For the vast majority of 'cold' functions, it uses a much more memory-efficient, lower-fidelity representation (e.g., a 2-bit integer). The 'asynchronous' part means this switch isn't a blocking operation; it's like having a separate, low-priority process that updates the precision of functions in memory *while* the main program continues its calculations, similar to how an operating system might manage virtual memory pages or a garbage collector operates in the background. This clever resource allocation allows the overall large model to fit and execute effectively on single-device GPUs with limited High Bandwidth Memory (HBM), because not every part of the program needs its most memory-intensive, precise representation at the same exact moment, thus enabling models that would otherwise be too large."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**17**\n\n3.1 The Threshold Decay Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n3.2 Errors Corresponding to Partial Linear Systems . . . . . . . . . . . . . . . . . . . . . 19\n\n3.3 The Efficient Partial Solver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\n3.4 The Almost-Linear-Time SDDM Solver . . . . . . . . . . . . . . . . . . . . . . . . . 22\n\n3.4.1 Bounding the sum of sizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3.4.2 Maintaining the vector _**b**_ [\ufffd] ( _t_ ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n3.4.3 Maintaining _I_ [(] _[t]_ [)] and _H_ [(] _[t]_ [)] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n3.4.4 Wrap-up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26"}, {"role": "assistant", "content": "**Mechanism:** The 'Threshold Decay Framework' likely operates by dynamically pruning or approximating less significant components of a problem, focusing computational resources on the most 'active' or influential elements. This allows for iterative refinement without recomputing the entire system each time. The 'Efficient Partial Solver' probably utilizes this framework to solve only the necessary subset of equations at each step. The 'Almost-Linear-Time SDDM Solver' then provides a specific algorithm, for Symmetric Diagonally Dominant Matrices (common in graph problems), that achieves near-optimal O(N) or O(N log N) complexity. This performance is enabled by careful data structure management (like 'maintaining vectors' and 'bounding sums of sizes') to ensure that updates are cheap and irrelevant parts of the system don't incur computational overhead, similar to how a well-indexed database table avoids full scans.\n\n**Explanation:** This section lays out a new approach to drastically speed up the solution of large linear systems, especially those arising from network or graph-related problems. The 'Threshold Decay Framework' is an intelligent way to manage complexity: it essentially 'filters' the problem, concentrating processing power on the parts that are currently most critical, letting less important parts 'fade' until they become significant again. Think of it like a smart algorithm that only processes the most relevant transactions in a ledger at any given moment. The 'Efficient Partial Solver' is a component that can solve just a piece of the larger problem without having to tackle the whole thing. The 'Almost-Linear-Time SDDM Solver' is the star, a specialized algorithm designed for a particular type of matrix (SDDM) that frequently appears in engineering and scientific computing. Its 'almost-linear-time' performance means its speed scales incredibly well with problem size, which is achieved by using clever internal bookkeeping and data management (like efficiently updating vector 'b' or maintaining sets 'I' and 'H') to avoid redundant calculations, much like how an efficient hash map provides near-constant time lookups even in a huge dataset."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_rpsi,j_ ( _si_ ( _j_ ) _, sj_ ( _i_ )) = _i for all j \u2208_ _`UndecidedNeighbors`_ **then**\n\n**8** Output 1 (join MIS and terminate);\n\n```\n   /* Round 3: Observe Undecided Neighbors\u2019 Outputs */\n```"}, {"role": "assistant", "content": "**Mechanism:** This describes a local consensus mechanism for a node (let's call it 'node i') in a distributed graph algorithm. Node i evaluates a condition based on specific signals received from its 'undecided' neighbors (let's call them 'node j'). The condition implies that each undecided neighbor j must explicitly 'approve' or acknowledge node i's decision.\n\n**Explanation:** Essentially, node i performs a logical AND operation on the feedback from its active, undecided neighbors. If all these neighbors unanimously signal that they will not conflict with node i's decision (e.g., they won't try to join the same set or indicate a conflict), then node i can confidently commit to joining the set (like a Maximum Independent Set). This allows node i to transition from an active, undecided state to a decided, inactive state, effectively pruning the graph for subsequent computation rounds."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_message sj_ ( _i_ ) _is \u03d5_ **then**\n\n**16** `BeenCheated` _\u2190_ true;\n\n**17** Compute _rpsi,j_ ( _si_ ( _j_ ) _, sj_ ( _i_ )) as defined in Definition 3.1;"}, {"role": "assistant", "content": "**Mechanism:** This code snippet represents a conditional fault detection and quantification block, similar to an 'if-then' statement in programming, triggered by a specific message property.\n\n**Explanation:** The core mechanism is a conditional check on an incoming message `sj(i)` against a predicate `\u03d5`. If this predicate evaluates to true, it implies a detected anomaly or violation. First, a boolean flag, `BeenCheated`, is set to `true`. This acts as a simple, fast indicator (like a status bit) that an integrity breach or malicious action has occurred. Subsequently, a function `rpsi,j` is called, taking two arguments: `si(j)` (likely the expected state or message from `j` by `i`) and `sj(i)` (the actual, potentially problematic, message received). This `rpsi,j` computation, detailed in 'Definition 3.1', serves to mathematically quantify the divergence or 'severity' of the anomaly. It's a precise, numerical measure of the deviation detected by the `BeenCheated` flag, probably used for later decision-making or penalty application."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**27**\n\n2\n\n## **1. Introduction**\n\nNowadays, nuclear fusion is one of the most important scientific and engineering problems of our time due to the\nquest for clean, sustainable energy. Fusion reactors promise an almost infinite energy source with major safety\nand environmental advantages over traditional fission and fossil fuel technologies by exploiting a similar process\nthat powers stars [2]. The confinement of a high-temperature plasma in a magnetic field is the most promising\nmethod for accomplishing controlled fusion on Earth. However, high-fidelity computational simulations are\nrequired due to the enormous expense and complexity of building and running experimental reactors [40].\nThese simulations are essential resources for developing new approaches, deciphering experimental data, and\ninvestigating plasma phenomena that are challenging or impossible to measure directly.\nFluid and kinetic models are the two main categories into which plasma simulation paradigms fall. Largescale instabilities and general plasma behavior are effectively captured by fluid models, which are governed by\nMagneto-HydroDynamics (MHD) equations and treat the plasma as a continuum [24]. Kinetic models, on the\nother hand, follow the paths of individual particles and offer a more accurate, albeit more computationally\nexpensive, representation of the plasma [25]. The development of hybrid fluid-kinetic approaches has been\nprompted by the prohibitive computational cost of fully kinetic simulations for reactor-scale plasmas over MHDrelevant timescales. These models create a self-consistent framework by combining the accuracy of a kinetic\ntreatment for certain, important particle populations with the computational efficiency of a fluid description\nfor the bulk plasma [35].\nNumerous specialized numerical codes have been created to handle the various physical regimes found in magnetically confined plasmas. Usually, each of these tools is tailored for a particular set of scales, equations, or\nconfigurations. In particular, for hybrid MHD-kinetic simulations many codes have been developed, for instance:\nJOREK [19], NIMROD [39], M3D-C1-K [13, 28], MEGA [41] and XHMGC [43] are some of the leading codes in\nthe field, designed to couple a fluid description of the bulk plasma with a kinetic treatment for specific particle\nspecies. Among them, specific interest has sparked in the simulation of stellarator reactors, leading to the development of specific extensions to account for the three-dimensionality of the plasma [7, 33, 47], underscoring\nthe interest and need of the scientific community for this kind of reactor.\nThe tokamak and the stellarator are the two main device concepts that have emerged in the field of magnetic\nconfinement fusion. Both configurations are actively researched as promising concepts for a fusion reactor with\ndifferent strengths and weaknesses. The tokamak\u2019s intrinsic toroidal symmetry makes its physical model and\nnumerical implementation easier, but the stellarator\u2019s non-axisymmetric, three-dimensional magnetic field poses\na much greater computational challenge. The need for sophisticated simulation tools that can faithfully capture\nthe unique physics of stellarator designs is growing in importance, triggered in particular by the successful\noperation of the W7-X. As a result, although there are established hybrid simulation frameworks for tokamaks\nin codes like JOREK [19], there is still a vital and ongoing research need to extend them to stellarator geometries.\nThe breakdown of toroidal axisymmetry is the main obstacle to applying the available hybrid models to stellarators. This symmetry permits a spectral decomposition of the mesh geometry in the toroidal direction, in\nwhich Fourier harmonics are decoupled, in tokamak simulations. The numerical problem is greatly simplified by\nthis decoupling since each harmonic\u2019s kinetic particle data can be independently projected onto the fluid grid.\nThese harmonics are intrinsically coupled in a stellarator due to the three-dimensional nature of the geometry.\nThe basis functions utilized for the finite element discretization are functions of all three spatial dimensions\nsince the physical form of the poloidal cross-section varies with the toroidal angle. The uncoupled projection\nscheme would produce nonphysical results if applied to stellarators and would fail to accurately represent the\nphysical plasma.\nBy creating, putting into practice, and validating the algorithms necessary for a global non-linear hybrid fluidkinetic simulation capability within the JOREK stellarator model, this thesis directly tackles this challenge.\nThe design of a novel particle-in-cell projection scheme that completely takes into account the coupling between\ntoroidal harmonics that results from the non-axisymmetric mesh geometry is the main contribution. This\napproach allows for a precise and self-consistent transfer of information from the kinetic particles to the fluid\ngrid by accurately formulating and solving the global linear system for all harmonics at the same time. These\nprojections are needed for diagnosing the particle dynamics and for a self-consistent coupling between fluid\nand kinetics. To overcome the significant computational cost of this approach, two key optimizations were\nimplemented. Firstly, the assembly of the global system matrix is accelerated using the Fast Fourier Transform\n(FFT). Secondly, a three-dimensional R-Tree spatial index is introduced to handle the expensive task of localizing\na high number of particles within the complex 3D grid.\nThe work is structured as follows: the required theoretical background is given in section 2, which also describes\nthe _G_ [1] B\u00e9zier finite element framework used in JOREK for the fluid model and the reduced-MHD equations.\nThe kinetic particle-in-cell methodology is then presented, along with an original derivation of the mathematical formulation for the projection scheme and the Boris pusher for particle tracing. The main contributions of\nthis study are described in detail in section 3. The new coupled-harmonic projection algorithm is implemented\n\n3\n\nafter first validating the basic particle tracing in stellarator configurations. Quantitative convergence tests and\nqualitative projections on realistic stellarator geometries are used to illustrate the precision and effectiveness\nof this new scheme. Following this validation, the chapter analyzes the computational performance of the key\noptimizations, presenting a speedup analysis of the FFT-accelerated matrix construction against the direct integration method. We conclude by exploring how the 3D R-Tree for effective particle localization is implemented\nand examining its performance. This methodical approach paves the way for next-generation, high-fidelity\nstellarator simulations by validating the new framework as a reliable and accurate tool.\n\n## **2. Background**\n\nThe theoretical foundation for comprehending the hybrid simulation approach used in this thesis is laid out\nin this section. We first describe the motivation behind this study, emphasizing the significance of using the\nstellarator and tokamak models for high-fidelity plasma simulations. Next, we describe the hybrid model\u2019s two\nmain pillars. The reduced MHD equations and the numerical framework for solving them in the JOREK code,\nwhich combines _G_ [1] continuous B\u00e9zier finite elements for the poloidal plane with a toroidal Fourier expansion,\nare introduced first in the fluid component. Second, we present the kinetic model, which explains how the\nNewton-Lorentz equations govern the motion of individual particles and how the Boris pusher algorithm is used\nto integrate them.\n\n**2.1.** **Motivation**\n\nFusion reactors have been a primary focus of clean energy research for the past half-century, offering the\npromise of clean, virtually limitless energy without the drawbacks associated with fission energy. The significant\nengineering challenges and extensive resources required for experimentation have slowed progress, necessitating\ncomputer-aided simulations to test and validate hypotheses.\n\n**2.1.1** **Simulation types**\n\nA basic taxonomy of plasma physics simulations was proposed in early literature [4], establishing a clear distinction between kinetic and fluid simulations. Kinetic simulations describe plasma at the particle level, while\nfluid simulations treat plasma as a single or multiple fluids governed by MHD equations. The fundamental\ntrade-off between these approaches balances computational requirements against accuracy. While fully kinetic\nsimulations can precisely capture particle interactions within plasma, the computational complexity grows exponentially with particle count. On the other hand, fluid-based simulations solve Maxwell\u2019s equations on finite\nelement grids, with complexity directly related to grid resolution and the sophistication of the MHD equations\nemployed. In recent years, despite the increase in HPC computational power[45], the inherent approximations\nin fluid simulations have limited achievable accuracy, driving the development of hybrid simulation approaches.\nIn these hybrid simulations, the fluid solver is combined with a kinetic simulation of particular particle species\nthat cannot be described well in the fluid picture, like supra-thermal ions [5], neutral particles or impurities [27],\nor runaway electrons [3]. The time evolution of the kinetic simulation provides accurate information about the\ntime evolution of plasma constituents under kinetic assumptions, which is then incorporated into the next fluid\ntime step by coupling terms. A schematic example of the underlying physics is shown in Fig. 1. This creates a\ncontinuous feedback loop between the two simulation approaches, allowing them to self-consistently evolve the\ncomplete system.\n\n**2.1.2** **Reactors types**\n\nFusion reactions exploiting magnetic confinement of the plasma are carried out at the moment, mainly, using\ntwo different types of reactors, stellarator and tokamak. The latter has seen widespread use in the scientific\ncommunity for its symmetric shape and ease of design; on the other hand, designs and simulations of stellarator\nreactors have been limited by the computational power available [17]. Nevertheless, the stellarator reactor\noffers a number of advantages such as intrinsically steady-state operation, fewer MHD instabilities, and nearly\ndisruption-free operation, i.e., no severe loss of the overall plasma confinement quality [46].\nDue to the popularity of tokamak designs, significant progress has been made in developing physically accurate\nsimulations that combine finite element method (FEM) resolution of (reduced) MHD models with kinetic solvers,\ncreating hybrid solutions, e.g., in the JOREK [19] codebase that is of interest to this thesis. While substantial\nwork has been done to develop MHD models for stellarator reactors [31, 32], current simulations lack the crucial\nkinetic solver component. Integrating such a solver with fluid models would enable more accurate stellarator\nsimulations, potentially accelerating research for the next generation of these less widely studied reactor designs.\n\n4\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-4-0.png)\n\nFigure 1: Feedback loop between electromagnetic fields and plasma in kinetic-fluid simulations. The\nLorentz force acts on charged particles, influencing their motion and altering currents and charge\ndensities, which in turn affect the electromagnetic fields [23].\n\nFigure 2: A computer graphic representation of the two different types of reactors [46]. On the left,\nthe tokamak; on the right, the stellarator.\n\n**2.2.** **Governing equations and Numerical Approximations for the fluid**\n\nThe code is logically separated into two different parts: the fluid part and the kinetic part.\nThe fluid part provides a starting point for the kinetic module by solving a reduced MHD model of the plasma\nusing the Finite Element Method (FEM).\n\n**2.2.1** **The MHD stellarator model**\n\nFirstly conceptualized in [31] and further implemented in [32], the implemented model aims at handling the\nMHD equations by not considering the fast magnetosonic waves, since they account for the fastest time scales\nof the system and are often not relevant to the problems considered.\nThe set of equations derived from the viscoresistive MHD equations is provided with time evolution equations\nfor the density, velocity, magnetic field, and internal energy, as well as additional definitions and constraints, as\nfollows:\n\n5\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-4-1.png)\n_\u2202\u03c1_\n\n_\u2202t_ [+] _[ \u2207\u00b7]_ [ (] _[\u03c1]_ **[v]** [) =] _[ P,]_\n\n_\u03c1_ _[\u2202]_ **[v]**\n\n_\u2202t_ [+] _[ \u03c1]_ [(] **[v]** _[ \u00b7 \u2207]_ [)] **[v]** [ +] **[ v]** _[P]_ [ =] **[ j]** _[ \u00d7]_ **[ B]** _[ \u2212\u2207][p]_ [ +] _[ \u00b5]_ [\u2206] **[v]** _[,]_\n\n_\u2202_ **B**\n\n_\u2202t_ [=] _[ \u2212\u2207\u00d7]_ **[ E]** _[,]_\n\n2\n\n_\u2202E_ _\u03c1v_\n\n_\u2202t_ [+] _[ \u2207\u00b7]_ \ufffd\ufffd 2\n\n_[ \u00d7]_ **[ B]** _\u2212_ _\u03ba\u22a5\u2207\u22a5T \u2212_ _\u03ba\u2225\u2207\u2225T_ = _Se \u2212_ _[v]_ [2] _[P]_\n\n_\u00b5_ 0 \ufffd 2\n\n_\u2202E_\n\n_v_ _\u03b3p_\n\n+\n2 _\u03b3 \u2212_ 1\n\n_p_ _D\u22a5_\n**v** +\n\ufffd _\u03b3 \u2212_ 1 _\u03c1_\n\n_\u22a5_\n\n_\u03c1_ _[\u2207][\u22a5][\u03c1]_ [ +] **[ E]** _[ \u00d7]_ _\u00b5_ 0 **[ B]**\n\n2 _[,]_\n\n(1)\n\n_E_ = _[\u03c1][v]_ [2]\n\n_[v]_ [2] + _p_ _[B]_ [2]\n\n2 _\u03b3 \u2212_ 1 [+] 2 _\u00b5_\n\n2 _\u00b5_ 0 _,_\n\n_\u2207\u00d7_ **B** = _\u00b5_ 0 **j** _,_\n\n_\u2207\u00b7_ **B** = 0 _,_\n\n**E** = _\u2212_ **v** _\u00d7_ **B** + _\u03b7_ **j** _,_\n\n_P_ = _\u2207\u00b7_ ( _D\u22a5\u2207\u22a5\u03c1_ ) + _S\u03c1._\n\nThese equations, modified with suitable ansatzes, will be solved on a 2D _G_ [1] continuous finite element grid\ncombined with a toroidal Fourier decomposition to provide the electromagnetic field in which the kinetic particles\nwill move through. For a definition of all symbols, refer to [31].\n\n**2.2.2** **Spatial Discretization**\n\nThe JOREK code uses _G_ [1] continuous isoparametric B\u00e9zier finite elements [19] to discretize the poloidal crosssection of the plasma and a Fourier expansion on the toroidal direction. This allows for achieving the same\nphysical accuracy with a low number of DoFs compared to other types of elements [10].\n\n**2.2.3** **B\u00e9zier Finite Elements**\n\nFor the finite element method taken into account, Bernstein polynomials are used along each of the two elementlocal coordinates _s_ and _t_ :\n\n3!\n_Bi_ [3][(] _[s]_ [) =] (2)\n_i_ ! (3 _\u2212_ _i_ )! _[s][i]_ [ (1] _[ \u2212]_ _[s]_ [)][3] _[\u2212][i]_\n\nThese exhibit some interesting properties such as:\n\n_\u2022_ ( _Bi_ _[n]_ [) is a basis of][ P] _[n]_ [,]\n\n_\u2022_ 0 _\u2264_ _Bi_ _[n]_ [(] _[s]_ [)] _[ \u2264]_ [1] _[,][ \u2200][s][ \u2208]_ [[0] _[,]_ [ 1]]\n\n_\u2022_ ( _Bi_ _[n]_ [) is a partition of unity =] _[\u21d2]_ [\ufffd] _[n]_ _i_ =0 _[B]_ _i_ _[n]_ [(] _[s]_ [) = 1] _[,][ \u2200][s][ \u2208]_ [[0] _[,]_ [ 1]]\n\nEach element uses two different third-degree Bernstein polynomials defined by:\n\n_Bi,j_ [3] [(] _[s, t]_ [) =] _[ B]_ _i_ [3][(] _[s]_ [)] _[ B]_ _j_ [3][(] _[t]_ [)] _i, j_ = 0 _. . ._ 3 _,_ (3)\n\nWhere 0 _\u2264_ _s, t \u2264_ 1 denote the local coordinates, which take values 0 and 1 at the four element vertices\nThese 16 basis functions _B_ [3]\n_i,j_ [(] _[s, t]_ [) are then used to build a 2D B\u00e9zier patch through parametrization of 16]\ncontrol points _Pi,j_, each of them belonging to an appropriate vector space, in our case _Pi,j \u2208_ R.\nThe position of each point _P_ ( _s, t_ ) on the patch is defined as:\n\n3\n\ufffd _Pi,jBi,j_ [3] [(] _[s, t]_ [)] (4)\n\n_j_ =0\n\n_P_ ( _s, t_ ) =\n\n3\n\ufffd\n\n_i_ =0\n\nIn this equation, the Bernstein polynomial serves as the weights for the control points. Since the used polynomials form a partition of unity, some properties arise, in particular:\n\n6\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-6-0.png)\n\nFigure 3: A single 2D isoparametric B\u00e9zier element in an axisymmetric R-Z space. The geometry\nis parameterized by a mapping from the local s-t parent domain using Bernstein polynomial basis\nfunctions, which are also used to interpolate field variables like temperature.\n\nA point _P_ ( _s, t_ ) on a parametric surface is a convex combination of the set of control points _{Pi,j}_ if it can be\nwritten as:\n\n3\n\ufffd _\u03b1i,j_ ( _s, t_ ) _Pi,j_ (5)\n\n_j_ =0\n\n_P_ ( _s, t_ ) =\n\n3\n\ufffd\n\n_i_ =0\n\nWhere the blending functions _\u03b1i,j_ ( _s, t_ ) must satisfy the following properties for all ( _s, t_ ) in their domain (e.g.,\n_s, t \u2208_ [0 _,_ 1]):\n\n_\u2022_ **Non-negativity:** _\u03b1i,j_ ( _s, t_ ) _\u2265_ 0 _\u2200i, j_\n\n3\n\n_\u2022_ **Partition of Unity:** [\ufffd][3] _i_ =0 \ufffd _j_ =0 _[\u03b1][i,j]_ [(] _[s, t]_ [) = 1]\n\nSince the polynomials satisfy both conditions, it is guaranteed that all the points are contained in the convex\nhull of their control points.\nFrom (4) we can also derive the local derivatives, for instance on _P_ 0 _,_ 0:\n\n_\u2202P_\n\n_\u2202s_\n\n_\u2202P_\n\n_\u2202t_\n\n_\u2202_ [2] _P_\n\n_\u2202s\u2202t_\n\n= 3( _P_ 1 _,_ 0 _\u2212_ _P_ 0 _,_ 0);\n\ufffd\ufffd\ufffd\ufffd( _s,t_ )=(0 _,_ 0)\n\n= 3( _P_ 0 _,_ 1 _\u2212_ _P_ 0 _,_ 0);\n\ufffd\ufffd\ufffd\ufffd( _s,t_ )=(0 _,_ 0)\n\n= 9( _P_ 1 _,_ 1 + _P_ 0 _,_ 0 _\u2212_ _P_ 0 _,_ 1 _\u2212_ _P_ 1 _,_ 0) _._\n\ufffd\ufffd\ufffd\ufffd( _s,t_ )=(0 _,_ 0)\n\n(6)\n\n(7)\n\n(8)\n\nBoth variables and space are discretized using these 16 basis functions, giving the iso-parametric characterization\nto this method.\n\n**2.2.4** **Tesselation of the domain**\n\nIn the finite element method, we split the entire domain into different smaller elements, in our case B\u00e9zier\npatches (e.g., Fig. 3). In doing so, we need to take care to satisfy specific conditions imposed by the application\u2019s\ndomain-specific requirements.\nThe first important constraint to satisfy is Geometric continuity between elements ( _G_ [0] ), which simply ensures\nthat there are no gaps between two adjacent elements. Without loss of generality, we consider two adjacent\nsurfaces _S_ and _S_ _[\u2032]_ which share a common boundary, assuming such boundary lies at the edge _s_ = 1 for patch\n_S_, and _s_ = 0 for patch _S_ _[\u2032]_ .\nThe boundary of the first patch is defined by _{P_ 3 _,_ 0 _, P_ 3 _,_ 1 _, P_ 3 _,_ 2 _, P_ 3 _,_ 3 _}_, while for the second one _{P_ 0 _[\u2032]_ _,_ 0 _[, P]_ 0 _[ \u2032]_ _,_ 1 _[, P]_ 0 _[ \u2032]_ _,_ 2 _[, P]_ 0 _[ \u2032]_ _,_ 3 _[}]_ [.]\n_G_ [0] is therefore easily achieved by simply enforcing:\n\n_P_ 3 _,j_ = _P_ 0 _[\u2032]_ _,j_ _\u2200j \u2208_ 0 _,_ 1 _,_ 2 _,_ 3 (9)\n\nHaving a continuous surface across the domain is almost trivial, and given for most elements, it becomes more\ninteresting to consider the _G_ [1] continuity between the elements. This must be enforced to avoid sharp, nonphysical creases between elements. To ensure such smooth surfaces between elements, the derivatives need to\nbe constrained in some way. _G_ [1] continuity requires satisfaction of the so-called \"tangent plane condition\" [42]\n\n7\n\nThe tangent plane at any point of the boundary is spanned by the four partial derivatives. For instance,\nconsidering the previous shared edge, assuming _G_ [0] continuity, we know that:\n\n\ufffd\ufffd\ufffd\ufffd _s_ _[\u2032]_ =0\n\n(10)\n\n= 0 _._ (11)\n\ufffd\n\n_\u2202P_\n\n_\u2202t_\n\n= _[\u2202P][ \u2032]_\n\ufffd\ufffd\ufffd\ufffd _s_ =0 _\u2202t_ _[\u2032]_\n\nLeaving us with the need to constrain only the other derivatives:\n\n_\u2202P \u2032_\n+ _k_ 3( _t_ )\n\ufffd \ufffd _\u2202s_ _[\u2032]_\n\n_\u2202P_\n_k_ 1( _t_ )\n\ufffd _\u2202s_\n\n_\u2202P_\n+ _k_ 2( _t_ )\n\ufffd \ufffd _\u2202t_\n\nIn practice, this requirement is equivalent to imposing the collinear alignment of the control points across the\nboundary [29]:\n\n_P_ 3 _,j \u2212_ _P_ 1 _[\u2032]_ _,j_ [=] _[ k]_ [(] _[P]_ [2] _[,j]_ _[\u2212]_ _[P]_ [3] _[,j]_ [)] _\u2200j \u2208_ 0 _,_ 1 _,_ 2 _,_ 3 (12)\n\nIn (12) _k_ is a (positive) scaling factor between the magnitudes of the tangent vectors across the boundary. A\nspecial case is found for _k_ = 1, where the formulation leads to _C_ [1] continuity and the Hermite polynomial. This\nparameter allows for flexibility in the mesh refinement.\n\n**2.2.5** **Imposing** _G_ [1] **on the field**\n\nNow, we focus on how the geometrical tools derived so far can be used to interpolate a field. To better\nunderstand which information is needed on each node, it is better to shift the perspective from the element to\na single vertex.\nFollowing the derivation in (8), we know that the values and derivative in one of the corners only depends on\nthe three closest control points. Given this, we define a local 3 _\u00d7_ 3 grid of control points, denoted _Pi,j_ where\n( _i, j_ ) _\u2208{\u2212_ 1 _,_ 0 _,_ 1 _}_ [2], centered on the shared vertex _P_ 0 _,_ 0. This 9-point grid is a subset of the control points from\nthe four adjoining 16-point patches. For example, for one patch, _P_ 0 _,_ 0 corresponds to its corner control point,\n_P_ 1 _,_ 0 to its first tangential control point, and _P_ 1 _,_ 1 to its first twist control point.\nThe isoparametric property means that each control point is a vector _Pi,j_ = ( _Ri,j, Zi,j, wi,j_ ), where ( _R, Z_ ) are\nthe spatial coordinates and _w_ is the field. We assume the mesh geometry ( _Ri,j, Zi,j_ ) is given. The unknowns\nare the nine scalar values _wi,j_, which constitute the initial DOFs at the node _P_ 0 _,_ 0.\nWith this vertex-centered notation, the _G_ [1] continuity condition (12) can be expressed more generally for the\ntwo principal directions s and t:\n\n_P_ 1 _,j \u2212_ _P_ 0 _,j_ = _ks_ ( _P_ 0 _,j \u2212_ _P\u2212_ 1 _,j_ ) _\u2200j \u2208\u2212_ 1 _,_ 0 _,_ 1\n\n_Pi,_ 1 _\u2212_ _Pi,_ 0 = _kt_ ( _Pi,_ 0 _\u2212_ _Pi,\u2212_ 1) _\u2200i \u2208\u2212_ 1 _,_ 0 _,_ 1\n\n(13)\n\n(14)\n\nwhere _ks_ and _kt_ are scalar constants determined by the mesh geometry.\nSince our geometry is fixed, the equations can be used directly on _wi,j_ to derive the necessary DoFs. Consider\nthe equations for the _s_ -direction:\n\n_w_ 1 _,j \u2212_ _w_ 0 _,j_ = _ks_ ( _w_ 0 _,j \u2212_ _w\u2212_ 1 _,j_ ) _\u2200j \u2208\u2212_ 1 _,_ 0 _,_ 1 (15)\n\nAs (15) shows, the DoFs are not independent; they must lie on a line in the field space.\nWe can now define the directed distances along the control polygon legs, from the central node as:\n\n_du,j_ = sign( _j_ ) _\u00b7 ||Mj,_ 0 _\u2212_ _M_ 0 _,_ 0 _||_ for _j_ = _\u00b1_ 1\n\n_dv,i_ = sign( _i_ ) _\u00b7 ||M_ 0 _,i \u2212_ _M_ 0 _,_ 0 _||_ for _i_ = _\u00b1_ 1\n\nwhere _Mi,j_ are the projection on ( _O, x, y_ ):\n\n(16)\n\n(17)\n\n_Mi,j_ = ( _Ri,j, Zi,j_ ) (18)\n\nThe values _du,i_ and _dv,j_ are scalar properties derived from the mesh geometry.\nThe first two DoFs, after the field value _w_ 0 _,_ 0 itself, are _a_ 0 _,_ 0 and _b_ 0 _,_ 0, defined as:\n\n_a_ 0 _,_ 0 _\u2261_ _[w]_ [1] _[,]_ [0] _[ \u2212]_ _[w]_ [0] _[,]_ [0]\n\n_du,\u2212_ 1\n\n[0] _[ \u2212]_ _[w]_ [0] _[,]_ [0] = _[w][\u2212]_ [1] _[,]_ [0] _[ \u2212]_ _[w]_ [0] _[,]_ [0]\n\n_du,_ 1 _du,\u2212_ 1\n\n_b_ 0 _,_ 0 _\u2261_ _[w]_ [0] _[,]_ [1] _[ \u2212]_ _[w]_ [0] _[,]_ [0]\n\n_[ \u2212]_ _[w]_ [0] _[,]_ [0]\n\n= _[w]_ [0] _[,][\u2212]_ [1] _[ \u2212]_ _[w]_ [0] _[,]_ [0]\n_dv,_ 1 _dv,\u2212_ 1\n\n_._\n_dv,\u2212_ 1\n\n(19)\n\n(20)\n\nImposing the equivalence on the DoFs guarantees the required smoothness of the solution.\n\n8\n\nThis handles the derivatives in _s_ and _t_, reducing the four DoFs related to the direct neighbors of the vertex to\nonly two, but leaves us with the open issue of handling the mixed derivatives at the twist/corner points.\nFor each of the four corners is possible to define:\n\n**m** _i,j \u2261_ _Pi,j_ + _P_ 0 _,_ 0 _\u2212_ _Pi,_ 0 _\u2212_ _P_ 0 _,j._ (21)\n\n_\u2202_ [2] _P_\nThis serves the purpose of approximating a discrete mixed derivative _\u2202s\u2202t_ [; geometrically, this follows the]\nparallelogram rule.\nIt is possible to prove that:\n\n_[d][u][,][i]_ **m** _k,j,_ **m** _k,j_ = _[d][v][,j]_\n\n_du,k_ _dv,l_\n\n**m** _i,j_ = _[d][u][,][i]_\n\n**m** _k,l,_ _\u2200i, j, k, l_ = _\u00b1_ 1 _,_ (22)\n_dv,l_\n\nYielding the existence at the corner of a vector independent from the local twist points:\n\n1 1\n**m** _i,j_ = **m** _k,l_ = _[\u20d7]_ \u0393 _,_ _\u2200i, j, k, l_ = _\u00b1_ 1 _._ (23)\n_du,idv,j_ _du,kdv,l_\n\nTherefore, calling _\u03b3_ 0 _,_ 0 the third coordinate of _[\u20d7]_ \u0393, we obtain:\n\n_\u03c8i,j_ + _\u03c8_ 0 _,_ 0 _\u2212_ _\u03c8i,_ 0 _\u2212_ _\u03c8_ 0 _,j_ = _\u03b3_ 0 _,_ 0 _du,idv,j_ _\u2200i, j_ = _\u00b1_ 1 _._ (24)\n\nConsequently, only four degrees of freedom ( _\u03c8_ 0 _,_ 0 _, \u03b1_ 0 _,_ 0 _, \u03b2_ 0 _,_ 0 _, \u03b3_ 0 _,_ 0), instead of nine, are necessary for each fluid\nquantity to determine all the control points associated with vertex _P_ 0 _,_ 0:\n\n\uf8f1\uf8f4 _\u03c8i,_ 0 = _\u03c8_ 0 _,_ 0 + _\u03b1_ 0 _,_ 0 _du,i_\n\n_\u03c8_ 0 _,j_ = _\u03c8_ 0 _,_ 0 + _\u03b2_ 0 _,_ 0 _dv,j_\n\n\uf8f2\uf8f4\uf8f3 _\u03c8i,j_ = _\u03c8i,_ 0 + _\u03c8_ 0 _,j \u2212_ _\u03c8_ 0 _,_ 0 + _\u03b3_ 0 _,_ 0 _du,idv,j_\n\n_\u2200i, j_ = _\u00b1_ 1 _._ (25)\n\n**2.2.6** **Field Interpolation**\n\nA basis of normalized vectors is defined at a vertex _P_ 0 _,_ 0. This basis consists of three vectors, **U** 0 _,_ 0, **V** 0 _,_ 0, and\n**W** 0 _,_ 0:\n\n_v_ 0 _,_ 0 _,x_\n\n\uf8eb _v_ 0 _,_ 0 _,y_\n\n\uf8ed _\u03b2_ 0 _,_ 0\n\n_w_ 0 _,_ 0 _,x_\n\n\uf8eb _w_ 0 _,_ 0 _,y_\n\n\uf8ed _\u03b3_ 0 _,_ 0\n\n\uf8f6 _,_ **V** 0 _,_ 0 =\n\n\uf8f8\n\n\uf8f6 _,_ **W** 0 _,_ 0 =\n\n\uf8f8\n\n\uf8f6\n\n(26)\n\uf8f8\n\n(27)\n\n**U** 0 _,_ 0 =\n\n_u_ 0 _,_ 0 _,x_\n\n\uf8eb _u_ 0 _,_ 0 _,y_\n\n\uf8ed _\u03b1_ 0 _,_ 0\n\n\uf8eb\n\nwhere the spatial subvectors \u02dc _u_ 0 _,_ 0, \u02dc _v_ 0 _,_ 0, and \u02dc _w_ 0 _,_ 0 (from Fig. 3.1(b)) are given by:\n\n\u02dc\n_u_ 0 _,_ 0 = _[M]_ [1] _[,]_ _d_ [0] _u,_ _[\u2212][M]_ 1 [0] _[,]_ [0]\n\n\u02dc\n_v_ 0 _,_ 0 = _[M]_ [0] _[,]_ _d_ [1] _[\u2212][M]_ [0] _[,]_ [0]\n\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3\n\n_du,_ 1 _dv,_ 1\n\n_,_ _dv,_ 1\n\n\u02dc\n_w_ 0 _,_ 0 = _[M]_ [1] _[,]_ [1][+] _[M]_ _d_ [0] _[,]_ [0] _[\u2212]_ _d_ _[M]_ [0] _[,]_ [1] _[\u2212][M]_ [1] _[,]_ [0]\n\nThe basis is written at each vertex, the B\u00e9zier parameterization of **P** = ( _x, y, \u03c8_ ) on element _EK_ can be rewritten\n\nas:\n\n\uf8f6\n\n_,_ (28)\n\uf8f8\n\n4\n\ufffd\n\n_i_ =1\n\n\uf8eb\n\n_x_ \u02dc _ik_ ( _s, t_ )\n\n\u02dc\n\n\uf8eb\n\n_y_ \u02dc _ik_ ( _s, t_ )\n\uf8ed _\u03c8ik_ ( _s, t_ )\n\n**P** ( _s, t_ ) =\n\n4\n\ufffd **P** \u02dc _ik_ ( _s, t_ ) =\n\n_k_ =1\n\nwhere index _i_ denotes vertex _i_ . The four components **P** [\u02dc] _i_ are given by:\n\n**P** \u02dc _i_ 1( _s, t_ ) = (1 _\u2212_ _s_ ) [2] (1 _\u2212_ _t_ ) [2] [(1 + 2 _s_ )(1 + 2 _t_ ) **P** _i_ 1 + 3 _s_ (1 + 2 _t_ ) _du,i_ 1 **U** _i_ 1\n+ 3 _t_ (1 + 2 _s_ ) _dv,i_ 1 **V** _i_ 1 + 9 _stdu,i_ 1 _dv,i_ 1 **W** _i_ 1] _,_\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n**P** \u02dc _i_ 2( _s, t_ ) = _s_ [2] (1 _\u2212_ _t_ ) [2] [(3 _\u2212_ 2 _s_ )(1 + 2 _t_ ) **P** _i_ 2 + 3(1 _\u2212_ _s_ )(1 + 2 _t_ ) _du,i_ 2 **U** _i_ 2\n+ 3 _t_ (3 _\u2212_ 2 _s_ ) _dv,i_ 2 **V** _i_ 2 + 9(1 _\u2212_ _s_ ) _tdu,i_ 2 _dv,i_ 2 **W** _i_ 2] _,_\n\n(29)\n\n**P** \u02dc _i_ 3( _s, t_ ) = _s_ [2] _t_ [2] [(3 _\u2212_ 2 _s_ )(3 _\u2212_ 2 _t_ ) **P** _i_ 3 + 3(1 _\u2212_ _s_ )(3 _\u2212_ 2 _t_ ) _du,i_ 3 **U** _i_ 3\n+ 3(3 _\u2212_ 2 _s_ )(1 _\u2212_ _t_ ) _dv,i_ 3 **V** _i_ 3 + 9(1 _\u2212_ _s_ )(1 _\u2212_ _t_ ) _du,i_ 3 _dv,i_ 3 **W** _i_ 3] _,_\n\n**P** \u02dc _i_ 4( _s, t_ ) = (1 _\u2212_ _s_ ) [2] _t_ [2] [(1 + 2 _s_ )(3 _\u2212_ 2 _t_ ) **P** _i_ 4 + 3 _s_ (3 _\u2212_ 2 _t_ ) _du,i_ 4 **U** _i_ 4\n+ 3(1 + 2 _s_ )(1 _\u2212_ _t_ ) _dv,i_ 4 **V** _i_ 4 + 9 _s_ (1 _\u2212_ _t_ ) _du,i_ 4 _dv,i_ 4 **W** _i_ 4] _,_\n\n9\n\nEach of the ( **P** [\u02dc] _i_ ) can be set into the general form:\n\n**P** \u02dc _i_ ( _s, t_ ) = _bi,_ 1 _|K_ ( _s, t_ ) **P** _i_ + _bi,_ 2 _|K_ ( _s, t_ ) **U** _i_ + _bi,_ 3 _|K_ ( _s, t_ ) **V** _i_ + _bi,_ 4 _|K_ ( _s, t_ ) **W** _i,_ (30)\n\n_b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [) are the B\u00e9zier basis functions.]\nElements with a higher order of continuity are also available in the JOREK code, although not considered in\nthis work. A more detailed discussion on geometrical continuity of B\u00e9zier patches can be found in [34].\n\n**2.2.7** **Bounding Box of a Bicubic B\u00e9zier Element**\n\nAs we will see in section 3.6, for some algorithms it is important to know the bounding box of each element.\nThe bounding box of an element is defined as the smallest, axis-aligned rectangle that contains all the points\nbelonging to an element.\nLet\u2019s start by considering the physical coordinates ( _R, Z_ ), at a specific toroidal angle _\u03d5_ they are a function of\nthe local coordinates ( _s, t_ ) _\u2208_ [0 _,_ 1] [2] :\n\n3\n\ufffd **P** _i,j_ ( _\u03d5_ ) _Bi_ [3][(] _[s]_ [)] _[B]_ _j_ [3][(] _[t]_ [)] (31)\n\n_j_ =0\n\n_R_ ( _s, t_ )\n**x** ( _s, t_ ) =\n\ufffd _Z_ ( _s, t_ )\n\n=\n\ufffd\n\n3\n\ufffd\n\n_i_ =0\n\nFinding the extreme points of _R_ ( _s, t_ ) and _Z_ ( _s, t_ ) would require solving _\u2207R_ ( _s, t_ ) = 0 and _\u2207Z_ ( _s, t_ ) = 0 over the\ndomain ( _s, t_ ) _\u2208_ [0 _,_ 1] [2], an expensive problem to solve for each element. A robust and efficient approximation\nconsists of finding the extrema on the boundaries of the element. This assumption holds for the meshes taken\ninto consideration, and is enforced at the start of the simulation by assuring that the Jacobian determinant\ndoes not change sign inside the element.\nThe search for extrema is restricted to the four edges of the element: _s_ = 0 _, s_ = 1 _, t_ = 0 _,_ and _t_ = 1. Consider\nthe coordinate _R_ along the edge _t_ = 0, for _s \u2208_ [0 _,_ 1]. The function _R_ ( _s, t_ = 0) simplifies to a 1D cubic B\u00e9zier\n\ncurve:\n\n3\n\n_R_ ( _s, t_ = 0) = \ufffd _Ri,_ 0( _\u03d5_ ) _Bi_ [3][(] _[s]_ [)] (32)\n\n_i_ =0\n\nThis is a cubic polynomial in _s_ . To find its local extrema for _s \u2208_ (0 _,_ 1), we must find the roots of its derivative\nwith respect to _s_ :\n\n\ufffd\n\n_d_ _[d]_\n_ds_ _[R]_ [(] _[s, t]_ [ = 0) =] _ds_\n\n3\n\ufffd\n\ufffd _i_ =0\n\n\ufffd _Ri,_ 0( _\u03d5_ ) _Bi_ [3][(] _[s]_ [)]\n\n_i_ =0\n\n= 0 (33)\n\nSince the Bernstein polynomials _Bi_ [3][(] _[s]_ [) are cubic in] _[ s]_ [, their derivative is quadratic. This results in a simple]\nquadratic equation of the form _as_ [2] + _bs_ + _c_ = 0, which can be efficiently solved for each boundary, for each\ndimension.\n\nBy taking the minimum and maximum along each boundary, we get the corners of the bounding box for each\nelement.\n\n**2.2.8** **Toroidal Fourier expansion**\n\nTo account for the 3D nature of the problem, we need to discretize along the toroidal direction, especially\nin non-axisymmetric devices such as stellarators. Every physical or geometric quantity can be expressed in\na Fourier series of the toroidal angle \u03a6. Since everything we are interested in is real-valued, we use a basis\nconsisting of real trigonometric functions. Any quantity _X_ is expressed as:\n\n_n_ tor\n\n_X_ ( _s, t,_ \u03a6) = \ufffd _Xl_ ( _s, t_ ) _Zl_ (\u03a6) (34)\n\n_l_ =1\n\nwhere _Xl_ are the real-valued Fourier coefficients (which depend on the poloidal coordinates), and the basis\nfunctions _Zl_ (\u03a6) are defined in [37] as:\n\n_Zl_ (\u03a6) =\n\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3\n\n1 if _l_ = 1 (for the _n_ = 0 mode)\ncos \ufffd _n_ period 2 _[l]_ [\u03a6] \ufffd if _l >_ 1 is even\n\ncos \ufffd _n_ period 2 _[l]_ [\u03a6] \ufffd if _l >_ 1 is even\n\nsin \ufffd _n_ period _[l][\u2212]_ 2 [1] [\u03a6] \ufffd if _l >_ 1 is odd\n\n(35)\n\n[1] if _l >_ 1 is odd\n\n2 [\u03a6] \ufffd\n\nHere, _n_ period denotes the field-periodicity of the configuration, allowing for representations of geometries that\ncomplete their pattern multiple times in one full 2 _\u03c0_ turn.\n\n10\n\n**2.2.9** **The Finite Element Method**\n\nNow, we have all the tools necessary to build the numerical framework to solve the governing equations that\ndescribe the plasma.\nTo accomplish this task, we use the Finite Element Method [48]. By subdividing the domain into smaller\nsubdomains, looking for a suitable coefficient, we will be able to numerically approximate the function.\nIn our case, the poloidal domain _D_ is partitioned into a mesh of non-overlapping B\u00e9zier patch finite elements\n_DK_, such that:\n\n_D_ = \ufffd _DK_ (36)\n\n_K_\n\nFor each element _K_, we associate a set of nodes where the degrees of freedom are defined. In addition to the\nvertices, each element carries four additional control points that influence the shape of the basis functions within\nthe patch. The local basis functions are _b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [), where (] _[s, t]_ [) are local coordinates within the element] _[ D][K]_ [,]\nand the indices _i, j_ represent the nodes and control points associated with it.\nThe solution within each element is expressed as a linear combination of these local basis functions:\n\n_\u03c8_ [(] _[K]_ [)] ( _s, t_ ) = \ufffd _\u03c8i,j_ [(] _[K]_ [)] _[b]_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] (37)\n\n_i,j_\n\nAs previously noted, the solution needs to be three-dimensional, so we take that into account by introducing\nthe Fourier expansion along the toroidal angle \u03a6:\n\n\ufffd _\u03c8i,j,l_ [(] _[K]_ [)] _[b]_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][l]_ [(\u03a6)] (38)\n\n_i,j_\n\n_\u03c8_ [(] _[K]_ [)] ( _s, t,_ \u03a6) =\n\n_n_ tor\n\ufffd\n\n_l_ =1\n\nWhere:\n\n_\u2022 Zl_ (\u03a6) are the toroidal basis functions\n\n_\u2022 \u03c8i,j,l_ [(] _[K]_ [)] [are the local degrees of freedom associated with the] _[ l]_ [-th toroidal mode and the (] _[i, j]_ [)-th local basis]\nfunction within element _K_,\n\n_\u2022 b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [) are the B\u00e9zier basis functions defined locally over element] _[ D][K]_ [.]\n\n**2.3.** **Governing equations and Numerical Approximations for the kinetics**\n\nIn this section, we are going to provide a general overview of the kinetics equations and the numerical approximations considered, as well as their stability. For a detailed description, see [12].\n\n**2.3.1** **Newton-Lorentz equation**\n\nWe study the motion of charged particles in a given electromagnetic field, according to Newton\u2019s equations:\n\n_d_ **x**\n\n(39)\n_dt_ [=] **[ v]** _[,]_\n\n_m_ _[d]_ **[v]** (40)\n\n_dt_ [=] _[ q]_ [[] **[E]** [(] **[x]** [) +] **[ v]** _[ \u00d7]_ **[ B]** [(] **[x]** [)]] _[,]_\n\nWhere **x** ( **v** ) is the position (velocity) of the particle with mass _m_ and charge _q_, while **E** ( **B** ) is the given electric\n(magnetic) field.\nThe electromagnetic field is always considered given, as it is calculated by solving the MHD equations before\nstarting the kinetic solver, and is considered a static field during the particle pushing.\n\n**2.3.2** **The Boris Pusher**\n\nFor the case under study, we chose to employ an explicit time stepping scheme called the Boris pusher, an\nintegration scheme with second order accuracy and comparably light computational requirements.\nThis algorithm is considered a leap-frog type of algorithm, since it employs staggered updates of position and\nvelocity in time. In particular, velocities are updated at time _t_ = _t_ _[n]_ [+1] _[/]_ [2] = ( _n_ + [1] 2 [)\u2206] _[t]_ [ and position are updated]\n\nlike _t_ = _t_ _[n]_ = _n_ \u2206 _t_ .\nThe following discussion stems from [12], which presents a detailed analysis of the numerical properties of such\nalgorithms, out of scope for the discussion carried out in this work.\n\n11\n\nThe algorithm separates the two different equations, the electric and the magnetic parts of the Lorentz force,\nby performing the following three steps:\nA half-step update (time step \u2206 _t/_ 2) with the contribution of only the electric field:\n\n_[q]_\n\n_m_ **[E]** [(] **[x]** _[n]_ [)\u2206] 2 _[t]_\n\n**v** _[\u2212]_ = **v** _[n][\u2212]_ [1] _[/]_ [2] + _[q]_\n\n(41)\n2 _[.]_\n\nPerform a full step (time step \u2206 _t_ ) following the magnetic field:\n\n**v** _[\u2032]_ = **v** _[\u2212]_ + _f_ _[n,]_ [\u2206] _[t]_ **v** _[\u2212]_ _\u00d7_ **B** ( **x** _[n]_ ) _,_ (42)\n\n2 _f_ _[n,]_ [\u2206] _[t]_\n**v** [+] = **v** _[\u2212]_ + 1 + ( _f_ _[n,]_ [\u2206] _[t]_ ) [2] **B** ( **x** _[n]_ ) [2] **[v]** _[\u2032][ \u00d7]_ **[ B]** [(] **[x]** _[n]_ [)] _[,]_ (43)\n\nwith\n\n_[q]_ \u2206 _t_\n\n_m_ 2\n\n_[q]_\n_f_ _[n,]_ [\u2206] _[t]_ = [tan][(] _m_\n\n_[q]_ _t_\n\n_m_ 2 _[|]_ **[B]** [(] **[x]** _[n]_ [)] _[|]_ [)]\n\n_._ (44)\n_|_ **B** ( **x** _[n]_ ) _|_\n\nPerform another half-step update (time step \u2206 _t/_ 2) with acceleration only due to the electric field:\n\n_[q]_\n\n_m_ **[E]** [(] **[x]** _[n]_ [)\u2206] 2 _[t]_\n\n**v** _[n]_ [+1] _[/]_ [2] = **v** [+] + _[q]_\n\n(45)\n2 _[.]_\n\nOnce the velocity update is completed, the position can be updated by\n\n**x** _[n]_ [+1] = **x** _[n]_ + **v** _[n]_ [+1] _[/]_ [2] \u2206 _t._ (46)\n\nThis algorithm is second-order accurate and time reversible [12]. Of course, as for any leap-frog algorithm, the\naccuracy also depends on the choice of the initial step that needs to be provided to relate the (known) particle\nposition and velocity at time _t_ = 0 to the velocity **v** _[\u2212]_ [1] _[/]_ [2] (or **v** [1] _[/]_ [2] ) that the algorithm needs to get started.\n\n**2.3.3** **Projecting particles on the Finite Element grid**\n\nTo couple the kinetic particles with the fluid part, it is necessary to translate the discrete information from the\nparticles into a continuous field compatible with our Finite Element formulation of the MHD equations. We\nemploy a projection using the previously established methodologies. The goal is to find a continuous field, _p_,\nthat is equivalent in a weighted-average sense to the source data from the particles, _X_ .\nThis equivalence is formally expressed in the weak form, which states that the two quantities are identical when\nintegrated against any valid test function _v_ :\n\n\ufffd\n\n_pv dV_ =\n_V_ \ufffd\n\n_Xv dV_ (47)\n_V_\n\nHere, _p_ is the projected field to be solved for (e.g., mass density, parallel velocity), and _X_ represents the\ncorresponding moment of the particle distribution function, 1 for number density, _Lz_ for radiative energy loss,\n_m_ for mass density, _v\u2225_ for parallel velocity, _E_ for energy et cetera [11].\nUsually, in these particle methods, we introduce a shape function _S_ ( _x_ ) describing the shape of the particle in\nspace. Various shape functions can be chosen and consequently give rise to different types of smoothing effects\non the particle; by including these shape functions into the formulation, we get:\n\n\ufffd\n\n\ufffd\n\n_pv dV_ =\n_V_ \ufffd\n\n_V_\n\n_v dV_ (48)\n\n_N_\n\ufffd _S_ ( **x** _\u2212_ **x** _i_ ) _wiX_\n\ufffd _i_ =1\n\nThe term _wi_ indicates the weight we give to each particle in the simulation. This is done to create macroparticles,\nwhose evolution is tied together but which carry different amounts of physical properties.\n\n**Matrix construction**\n\nLet\u2019s now look at the single element to construct the matrix representing the linear system of equations that\nneeds to be solved for the projections. Within each element _DK_, the field _p_, following the formulation introduced\nin (38), is approximated as:\n\n\ufffd _p_ [(] _i,j,l_ _[K]_ [)] _[b]_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][l]_ [(\u03a6)] (49)\n\n_i,j_\n\n12\n\n_p_ [(] _[K]_ [)] ( _s, t,_ \u03a6) =\n\n_n_ tor\n\ufffd\n\n_l_ =1\n\nSimilarly, the test function _v_ is expressed as:\n\n_v_ [(] _[K]_ [)] ( _s, t,_ \u03a6) =\n\n_n_ tor\n\ufffd\n\n_m_ =1\n\n\ufffd _vk,\u2113,m_ [(] _[K]_ [)] _[b]_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][m]_ [(\u03a6)] (50)\n\n_k,\u2113_\n\nThe mapping from local coordinates ( _s, t,_ \u03a6) to physical cylindrical coordinates ( _R, Z, \u03d5_ ) is given by:\n\n( _s, t,_ \u03a6) _\ufffd\u2192_ **x** ( _s, t,_ \u03a6) = ( _R_ ( _s, t,_ \u03a6) _, Z_ ( _s, t,_ \u03a6) _, \u03d5_ = \u03a6) (51)\n\nThe Jacobian of the 2D poloidal mapping ( _s, t_ ) _\ufffd\u2192_ ( _R, Z_ ) is:\n\n_\u2202R_ _\u2202R_\n\n_\u2202s_ _\u2202t_\n\n_\u2202Z_ _\u2202Z_\n\n_\u2202s_ _\u2202t_\n\n_\u2202R_\n_J_ pol [(] _[K]_ [)][(] _[s, t,]_ [ \u03a6) = det] _\u2202Z\u2202s_\n\ufffd _\u2202s_\n\n_\u2202t_\n\n(52)\n\n\ufffd\n\nNote that _J_ pol [(] _[K]_ [)] [depends in general on all three coordinates] _[ s]_ [,] _[ t]_ [, and \u03a6 due to the dependence of] _[ R]_ [ and] _[ Z]_ [. The]\nphysical volume element _dV_ = _R dR dZ d\u03d5_ transforms to the local coordinates as:\n\n_dV_ = _R_ ( _s, t,_ \u03a6) _J_ pol [(] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ ds dt d]_ [\u03a6 =:] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ ds dt d]_ [\u03a6] (53)\n\nwhere _J_ [(] _[K]_ [)] = _R \u00b7 J_ pol [(] _[K]_ [)] [is the determinant of the full 3D coordinate transformation Jacobian.]\nThe element-wise contribution to the left-hand side of equation (48) is:\n\n\ufffd _DK_\n\n2 _\u03c0_\n\n_p_ [(] _[K]_ [)] ( _s, t,_ \u03a6) _v_ [(] _[K]_ [)] ( _s, t,_ \u03a6) _J_ [(] _[K]_ [)] ( _s, t,_ \u03a6) _d_ \u03a6 _ds dt_ (54)\n\n\ufffd0\n\nSubstituting the basis function expansions for _p_ [(] _[K]_ [)] and _v_ [(] _[K]_ [)] gives the element mass matrix contribution. The\nequation for an arbitrary test function _v_ is satisfied if it holds for each basis function. This leads to a linear\nsystem where the element mass matrix _M_ [(] _[K]_ [)] couples the degrees of freedom _p_ [(] _i,j,l_ _[K]_ [)][. A single entry of this matrix,]\nwhich couples the poloidal basis functions indexed by ( _i, j_ ) and ( _k, \u2113_ ) and the toroidal modes _l_ and _m_, is given\nby:\n\n2 _\u03c0_\n_M_ [(] _[K]_ [)]\n_ij,k\u2113,lm_ [=]\n\ufffd0\n\n_b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] _[ b]_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ ds dt]_ _Zl_ (\u03a6) _Zm_ (\u03a6) _d_ \u03a6 (55)\n\n\ufffd\ufffd _DK_ \ufffd\n\nTo evaluate this integral numerically, we can conceptually separate the integration over the poloidal plane from\nthe integration over the toroidal angle. Let\u2019s define an intermediate function, _Fij,k\u2113_ (\u03a6), which represents the\nresult of the poloidal integral for a given toroidal angle \u03a6:\n\n_Fij,k\u2113_ (\u03a6) := _b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] _[ b]_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ ds dt]_ (56)\n\ufffd _DK_\n\nThe integral over the 2D reference element _DK_ is approximated using a fourth-order Gaussian quadrature rule.\nThis is constructed as the product of two 1D rules, leading to a double summation over the quadrature points\n( _sms, tmt_ ) with their corresponding 1D weights _\u03c9ms_ and _\u03c9mt_ :\n\n_n_ gp\n\ufffd _\u03c9ms\u03c9mt b_ [(] _i,j_ _[K]_ [)][(] _[s][ms][, t][mt]_ [)] _[ b]_ [(] _k,\u2113_ _[K]_ [)][(] _[s][ms][, t][mt]_ [)] _[ J]_ [ (] _[K]_ [)][(] _[s][ms][, t][mt][,]_ [ \u03a6)] (57)\n\n_mt_ =1\n\n_Fij,k\u2113_ (\u03a6) _\u2248_\n\n_n_ gp\n\ufffd\n\n_ms_ =1\n\nWith this intermediate function, the expression for the mass matrix entry simplifies to a single integral over the\ntoroidal angle:\n\n2 _\u03c0_\n_Mij,k\u2113,lm_ [(] _[K]_ [)] [=] _Fij,k\u2113_ (\u03a6) _Zl_ (\u03a6) _Zm_ (\u03a6) _d_ \u03a6 (58)\n\ufffd0\n\nSince the integral in (58) is integrating a periodic function, it can be evaluated using a periodic Gaussian\nquadrature, which is exact with _N_ points for trigonometric polynomials of degree 2 _N \u2212_ 2 [6]. We therefore\nsample the function in _nplane_ equidistant points along the toroidal direction.\n\n2 _\u03c0_\n_M_ [(] _[K]_ [)]\n_ij,k\u2113,lm_ [=] _nplane_\n\n_n_ plane\n\ufffd _Fij,k\u2113_ (\u03a6 _p_ ) _Zl_ (\u03a6 _p_ ) _Zm_ (\u03a6 _p_ ) (59)\n\n_p_ =1\n\n13\n\n**Uncoupled Harmonics in an Axisymmetric Geometry**\nThe coupling between different toroidal harmonics on the left-hand side comes directly from the geometry of\nthe mesh, see eq. (55). The term responsible for coupling the toroidal modes _l_ and _m_ is the full 3D Jacobian\ndeterminant, _J_ [(] _[K]_ [)] ( _s, t,_ \u03a6) = _R_ ( _s, t,_ \u03a6) _J_ pol [(] _[K]_ [)][(] _[s, t,]_ [ \u03a6). If this Jacobian is a function of the toroidal angle \u03a6, the]\nintegral over \u03a6 will generally be different from zero for _l \u0338_ = _m_ .\nAn important simplification happens if the mesh grid is axisymmetric. In an axisymmetric grid, the poloidal\nsection is the same, independently of toroidal angle \u03a6. This means the mapping from the local coordinates ( _s, t_ )\nto the physical poloidal coordinates ( _R, Z_ ) is independent of \u03a6:\n\n( _s, t_ ) _\ufffd\u2192_ **x** pol( _s, t_ ) = ( _R_ ( _s, t_ ) _, Z_ ( _s, t_ )) (independent of \u03a6) (60)\n\nTherefore, the derivatives are also independent of \u03a6. This directly changes the Jacobian in the poloidal section\nby providing independence from the toroidal direction.\nWith this simplification, the mass matrix integral can be rearranged, as the term in the square brackets is no\nlonger a function of \u03a6:\n\n2 _\u03c0_\n_b_ [(] _i,j_ _[K]_ [)][(] _[s, t]_ [)] _[ b]_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ J]_ [ (] _[K]_ [)][(] _[s, t]_ [)] _[ ds dt]_\n_DK_ \ufffd\ufffd\ufffd0\n\n_M_ [(] _[K]_ [)]\n_ij,k\u2113,lm_ [=]\n\ufffd\ufffd\n\n_\u03c0_\n\n_Zl_ (\u03a6) _Zm_ (\u03a6) _d_ \u03a6\n0 \ufffd\n\n(61)\n\nThe basis set _{Zl_ (\u03a6) _}_ is constructed from sines, cosines, and a constant term, which are orthogonal over a\nperiod. This means the integral is zero unless the two basis functions are the same:\n\n2 _\u03c0_\n\n_Zl_ (\u03a6) _Zm_ (\u03a6) _d_ \u03a6 = _Cl \u03b4lm_ (62)\n\n\ufffd0\n\nwhere _Cl_ is the normalization constant given by\n\n_Cl_ =\n\n2 _\u03c0_ if _l_ = 1\n(63)\n_\u03c0_ if _l >_ 1\n\ufffd\n\nand _\u03b4lm_ is the Kronecker delta.\nThe appearance of the delta means that the matrix entry _Mij,k\u2113,lm_ [(] _[K]_ [)] [is different from zero only if the toroidal]\nmode indices are identical ( _l_ = _m_ ). Therefore, for an axisymmetric grid like the already existing projections for\ntokamak cases in the code, the global mass matrix is perfectly block-diagonal when rearranged to cluster the\nharmonics contribution together.\nEach harmonic is decoupled, allowing the full linear system to be solved as a set of smaller, independent systems.\nA similar scheme is employed in the iterative solver of the fluid as an effective and efficient preconditioner for\nthe fluid matrix [20, 21].\nThis is not the case for stellarator scenarios considered in this work.\n\n**Fast Fourier Transform for the evaluation of the toroidal integral**\nFor stellarator simulations, a high number of harmonics is usually needed to accurately represent solutions\non the plasma, given the intrinsic coupling of harmonics due to the non-axisymmetric geometry; the matrix\nassembly becomes a bottleneck for simulations. However, there is a computationally more efficient algorithm,\nused in the fluid part, to evaluate the toroidal integral by using the Fast Fourier Transform [9].\nLet\u2019s define the integer wavenumber _\u03bd_ :\n\n_\u03bd_ ( _l_ ) = \ufffd _l/_ 2\ufffd = _\u21d2_ _\u03bd_ (1) = 0 _, \u03bd_ (2) = _\u03bd_ (3) = 1 _, \u03bd_ (4) = _\u03bd_ (5) = 2 _, . . ._ (64)\n\nSuch that the couple of _sin_ and _cos_ with the same periodicity can be addressed by the same wavenumber.\nWith these identities, every real basis function can be rewritten as\n\n[1] 2 \ufffd _e_ [i] _[q]_ [\u03a6] + _e_ _[\u2212]_ [i] _[q]_ [\u03a6][\ufffd] _,_ _Z_ 2 _q_ +1(\u03a6) = sin( _q_ \u03a6) = 2i [1]\n\n_Z_ 2 _q_ (\u03a6) = cos( _q_ \u03a6) = [1] 2\n\n2i [1] \ufffd _e_ [i] _[q]_ [\u03a6] _\u2212_ _e_ _[\u2212]_ [i] _[q]_ [\u03a6][\ufffd] _._ (65)\n\nTherefore, any product _Zl Zm_ can be written as a linear combination of two complex exponentials:\n\n_Zl_ (\u03a6) _Zm_ (\u03a6) = 21 _e_ [i[] _[\u03bd]_ [(] _[l]_ [)] _[\u2212][\u03bd]_ [(] _[m]_ [)]\u03a6] + _\u03c3lm e_ [i[] _[\u03bd]_ [(] _[l]_ [)+] _[\u03bd]_ [(] _[m]_ [)]\u03a6][\ufffd]\n\ufffd\n\nwhere the coefficient _\u03c3lm_ depends only on the parity of the two indices:\n\n(66)\n\n(67)\n\n_\u03c3lm_ =\n\n\uf8f1+1 _l_ and _m have the same parity_ \ufffdcos _\u00d7_ cos or sin _\u00d7_ sin\ufffd _,_\n\uf8f2\uf8f3 _\u2212_ 1 _l_ and _m have opposite parity_ \ufffdcos _\u00d7_ sin or sin _\u00d7_ cos\ufffd _._\n\n14\n\nThe two exponential factors carry wavenumbers\n\n_r_ 1 := _\u03bd_ ( _l_ ) _\u2212_ _\u03bd_ ( _m_ ) _,_ _r_ 2 := _\u03bd_ ( _l_ ) + _\u03bd_ ( _m_ ) _,_ (68)\n\nboth of which obey _|r_ 1 _,_ 2 _| < n_ plane _/_ 2 in practice, because we strictly choose _n_ plane _\u2265_ 2 _n_ tor in the simulations.\nInserting (66) into (59) and distributing the summation gives:\n\n_\u03c0_\n_M_ [(] _[K]_ [)]\n_ij,k\u2113,lm_ [=] _n_ plane\n\n_\u03c0_\n\n=\n\n_n_ plane\n\n_n_ plane\n\ufffd\n\n_n_ plane\n\ufffd _Fij,k\u2113_ (\u03a6 _p_ ) _e_ [(i] _[r]_ [1][\u03a6] _[p]_ [)] + _\u03c3lm_\n\ufffd _p_ =1\n\n\ufffd _Fij,k\u2113_ (\u03a6 _p_ ) \ufffd _e_ [(i] _[r]_ [1][\u03a6] _[p]_ [)] + _\u03c3lme_ [(i] _[r]_ [2][\u03a6] _[p]_ [)][\ufffd]\n\n_p_ =1\n\n(69)\n\nplane\n\ufffd _Fij,k\u2113_ (\u03a6 _p_ ) _e_ [(i] _[r]_ [2][\u03a6] _[p]_ [)]\n\n_p_ =1 \ufffd\n\n_n_ plane\n\ufffd\n\nWe can now define the complex discrete Fourier coefficients:\n\n\ufffd\n_F_ _[r]_\n_ij,k\u2113_ [:=]\n\n_n_ plane\n\ufffd _Fij,k\u2113_ (\u03a6 _p_ ) _e_ _[\u2212]_ [i] _[ r]_ [ \u03a6] _[p]_ _,_ _r_ = 1 _, . . ., n_ plane _._ (70)\n\n_p_ =1\n\nand by substituting them into (70) we obtain:\n\n_\u03c0_\n_M_ [(] _[K]_ [)]\n_ij,k\u2113,lm_ [=] _n_ plane\n\n\ufffd\n_F_ _[\u2212][r]_ [1]\n\ufffd _ij,k\u2113_ [+] _[ \u03c3][lm]_ [ \ufffd] _[F][ \u2212]_ _ij,k\u2113_ _[r]_ [2] \ufffd\n\n(71)\n\nSince all the coefficients can be obtained from a single FFT computation, the asymptotic complexity is greatly\nreduced.\n\nWhen using the direct summation, for each degree of freedom on the poloidal section, we have to evaluate the\nfunction in _nplane_ different points for each couple _l, m_ of toroidal harmonics:\n\ncostdirect = _n_ [2] tor _[\u00d7][ O]_ [(] _[n]_ [plane][) =] _[ O]_ [(] _[n]_ [2] tor _[n]_ [plane][)] _[.]_ (72)\n\nOn the other hand, using the FFT acceleration, we compute all the coefficients in a single FFT pass of complexity\n_O_ ( _nplanelog_ ( _nplane_ )). Once all the coefficients are obtained, we construct the matrix by carefully adding the\nrelevant coefficients for each couple following (66), resulting in a final complexity of:\n\ncostFFT = _O_ ( _n_ plane log _n_ plane + _n_ [2] tor [)] _[.]_ (73)\n\nIn the direct method, the expensive _O_ ( _n_ plane) summation is repeated _N_ tor [2] [times. In the FFT method, the]\nexpensive part, with a slightly higher cost of _O_ ( _n_ plane log _n_ plane), is performed only once. The subsequent\nassembly is extremely fast.\n\n**Right hand side**\nWe consider now the right-hand side of the weak formulation from (48):\n\n\ufffd\n\n\ufffd _V_\n\n_N_\n\ufffd\n\ufffd _i_ =1\n\n\ufffd _S_ ( **x** _\u2212_ **x** _i_ ) _wi X_ ( **x** )\n\n_i_ =1\n\n_v_ ( **x** ) _dV_ (74)\n\nThe element-wise contribution is obtained by substituting the expansion for _v_ and the transformation for _dV_ :\n\n\ufffd\n\n_N_\n\ufffd\n\ufffd _i_ =1\n\n\ufffd _S_ ( **x** ( _s, t,_ \u03a6) _\u2212_ **x** _i_ ) _wi X_ ( **x** ( _s, t,_ \u03a6))\n\n_i_ =1\n\n_n_ tor\n\ufffd\n\n_m_ =1\n\n_v_ [(] _[K]_ [)]\n\n\ufffd _k,\u2113,m_\n\n_k,\u2113_\n\n\ufffd02 _\u03c0_\n\n\ufffd _DK_\n\n_b_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][m]_ [(\u03a6)] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ d]_ [\u03a6] _[ ds dt]_ (75)\n\nWe define the right-hand-side vector coefficients _L_ [(] _k,\u2113,m_ _[K]_ [)] [from the integral term as:]\n\n\ufffd\n\n_N_\n\ufffd\n\ufffd _i_ =1\n\n\ufffd _S_ ( **x** ( _s, t,_ \u03a6) _\u2212_ **x** _i_ ) _wi X_ ( **x** _i_ )\n\n_i_ =1\n\n_L_ [(] _[K]_ [)]\n_k,\u2113,m_ [=]\n\ufffd _DK_\n\n\ufffd02 _\u03c0_\n\n_b_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][m]_ [(\u03a6)] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ d]_ [\u03a6] _[ ds dt]_ (76)\n\nwhere for brevity we use _X_ ( **x** _i_ ) as the value of the moment for particle _i_ .\nThe evaluation of this integral depends on the choice of the shape function _S_ . The simplest and most computationally efficient choice is the Dirac delta function, _S_ ( **x** _\u2212_ **x** _i_ ) = _\u03b4_ ( **x** _\u2212_ **x** _i_ ). Using this choice, the integral in\nequation (76) can be greatly simplified.\n\n15\n\nThe Dirac delta function transforms between coordinate systems according to the rule:\n\n_\u03b4_ ( **x** _\u2212_ **x** _i_ ) = _[\u03b4]_ [(] _[s][ \u2212]_ _[s][i]_ [)] _[\u03b4]_ [(] _[t][ \u2212]_ _[t][i]_ [)] _[\u03b4]_ [(][\u03a6] _[ \u2212]_ [\u03a6] _[i]_ [)] (77)\n\n_|J_ [(] _[K]_ [)] ( _si, ti,_ \u03a6 _i_ ) _|_\n\nwhere ( _si, ti,_ \u03a6 _i_ ) are the local coordinates of the particle at position **x** _i_ . This transformation is valid only\nfor particles located within the element _K_ ; otherwise, the delta function is zero over the integration domain\n_DK \u00d7_ [0 _,_ 2 _\u03c0_ ).\nSubstituting this into the expression for _L_ [(] _k,\u2113,m_ _[K]_ [)] [and swapping the sum and integral, we get:]\n\n_\u03b4_ ( _s \u2212_ _si_ ) _\u03b4_ ( _t \u2212_ _ti_ ) _\u03b4_ (\u03a6 _\u2212_ \u03a6 _i_ )\n\n_|J_ [(] _[K]_ [)] ( _si, ti,_ \u03a6 _i_ ) _|_ _wiX_ ( **x** _i_ ) _b_ [(] _k,\u2113_ _[K]_ [)][(] _[s, t]_ [)] _[ Z][m]_ [(\u03a6)] _[ J]_ [ (] _[K]_ [)][(] _[s, t,]_ [ \u03a6)] _[ d]_ [\u03a6] _[ ds dt]_ (78)\n\n\ufffd02 _\u03c0_\n\n_L_ [(] _[K]_ [)]\n_k,\u2113,m_ [=] \ufffd\n\n_i\u2208K_\n\n\ufffd _DK_\n\nThe summation is now restricted to particles _i \u2208_ _K_ that reside within the element _K_ . By the sifting property\nof the delta function, the integral collapses to an evaluation of the integrand at the particle\u2019s local coordinates\n( _si, ti,_ \u03a6 _i_ ):\n\n_i_ \ufffd _\u2208K_ _wiX_ ( **x** _i_ ) _b_ [(] _k,\u2113_ _[K]_ [)][(] _[s][i][, t][i]_ [)] _[ Z][m]_ [(\u03a6] _[i]_ [)] _|J_ _[J]_ [ (][(] _[K][K]_ [)][)][(] ( _[s]_ _s_ _[i]_ _i_ _[,]_ _, t_ _[ t][i]_ _i_ _[,]_ _,_ [ \u03a6] \u03a6 _[i]_ _i_ ) [)]\n\n_L_ [(] _[K]_ [)]\n_k,\u2113,m_ [=] \ufffd\n\n_[,]_ _[,]_ (79)\n\n_|J_ [(] _[K]_ [)] ( _si, ti,_ \u03a6 _i_ ) _|_\n\nAssuming the element mapping is not inverted, the Jacobian determinant _J_ [(] _[K]_ [)] is positive, and the fraction\nequals one. This reduces the computationally expensive triple integral to a simple sum over the particles within\nthe element:\n\n_L_ [(] _k,\u2113,m_ _[K]_ [)] [=] \ufffd _wi X_ ( **x** _i_ ) _b_ [(] _k,\u2113_ _[K]_ [)][(] _[s][i][, t][i]_ [)] _[ Z][m]_ [(\u03a6] _[i]_ [)] (80)\n\n_i\u2208K_\n\nThis formulation provides a significant computational advantage, as it avoids numerical quadrature and only\nrequires finding which particles reside in which element and evaluating the basis functions at the particle\nlocations.\n\nSo, the element-wise right-hand side of the weak form becomes:\n\n\ufffd\n\n_n_ tor\n\ufffd\n\n_m_ =1\n\n_v_ [(] _[K]_ [)]\n\n\ufffd _k,\u2113,m_\n\n_k,\u2113_\n\n\ufffd\ufffd _i\u2208K_\n\n_wi X_ ( **x** _i_ ) _b_ [(] _k,\u2113_ _[K]_ [)][(] _[s][i][, t][i]_ [)] _[ Z][m]_ [(\u03a6] _[i]_ [)]\n\n_i\u2208K_\n\n(81)\n\n## **3. Algorithms and verification for PiC methods in the JOREK stel-** **larator model**\n\nThe new particle-in-cell (PiC) capabilities within the JOREK stellarator model are implemented and verified in\nthis section after the theoretical underpinnings were established in the previous section. Here, the development\nand verification of the algorithms needed for a fully functional hybrid simulation are the main priorities. In order\nto verify that the basic particle tracing operates as anticipated in both tokamak and stellarator configurations,\nwe start by presenting initial tests. Expanding upon this, we describe the main contribution of this work: the\napplication of a fully coupled harmonic projection scheme, which is necessary to accurately depict fields in\nstellarator geometries that are not axisymmetric. First, qualitative projections onto realistic stellarator meshes\nare used to illustrate the efficacy of this approach, which is then quantitatively validated through a series of\nconvergence tests. Lastly, we implement and evaluate a spatial R-Tree data structure to tackle the problem of\neffectively locating particles within the 3D mesh.\n\n**3.1.** **Preliminary tests**\n\n**3.1.1** **Particle Tracing**\n\nIn order to produce a working hybrid solver for the stellarator model, it is crucial to have consistent kinetic\nsimulation results with the existing code base. For this purpose, three simulations have been set up and\ntested in which particles are pushed in static fields: a tokamak configuration in a stellarator model, a tokamak\nconfiguration in a tokamak model, and a stellarator configuration in a stellarator model. The first and the\nsecond should have an agreeing result, while the third should showcase the non-axisymmetric behavior intrinsic\nto the stellarator geometry.\nThe stellarator model used is the model 180, while the tokamak model used is 600\nAs expected, the first two configurations yield the same result within numerical tolerance as seen in Fig. 4. In\ncontrast, the tracing on the stellarator case follows the characteristic geometry of the stellarator (Fig. 5).\n\n16\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-16-0.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-16-1.png)\n\nFigure 4: Comparison of particle trajectories between stellarator and tokamak models in tokamak\nconfiguration.\n\nFigure 5: Particle Tracing in a stellarator case using the stellarator model\n\n**3.1.2** **Different Trajectories**\n\nIn toroidal fusion plasmas like tokamaks, neoclassical transport arises from collisions in the toroidally inhomogeneous magnetic field, which is fundamentally different from classical transport in a uniform field. In a simple\ncylindrical model (\u201cclassical\u201d limit), cross-field diffusion is set by the random walk of gyrocenters (step size,\nthe Larmor radius) [18, 44]. However, the tokamak\u2019s toroidal geometry makes the field stronger on the inboard\nside, so particles with small parallel velocity become magnetically trapped and bounce between mirror points\non the outboard side. These trapped particles execute banana-shaped orbits in the poloidal plane. [18].\nBy choosing an appropriate initial position and velocity for some particles, we should be able to reproduce\nbanana and trapped orbits in the tokamak. These serve as a first step experiment to check if the stellarator\ncode in JOREK is suitable to reproduce the effects of neoclassical transport and consequently see if the results\nfrom the pure tokamak model are in agreement.\n\n17\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-16-2.png)\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-17-0.png)\n\nFigure 6: The three types of particle trajectories in the tested cases\n\nAs expected, the results show perfectly matching results between the models, assuring compatibility for particle\npushing, see Fig. 6.\n\n**3.1.3** **Particle Projection**\n\nWhile the pusher allows for particles to follow the field calculated on the fluid timestepping, at some point, it is\nnecessary to project the particles on the fluid mesh to retrieve useful properties on the particle moving through\nthe plasma. To achieve this, in the axis-symmetric tokamak, each harmonic is retrieved by solving a separate\nlinear system.\nAs this is the complementary step for kinetic simulations, more tests have been performed to ensure agreement\nin the different models. To achieve this, a special three-dimensional Gaussian particle distribution has been\nemployed spanning across the two poloidal dimensions and on the toroidal dimension.\n\n18\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-18-0.png)\n\nFigure 7: Projection of three-dimensional Gaussian distribution\n\nThe result of the aforementioned distribution when projected is a two-dimensional Gaussian, decomposed in its\nharmonics (Fig. 7).\nAs expected, the results in the two tokamak-like cases are sound across models. Here tough we can have a\nfirst appreciation of the problem revolving around projection in the stellarator case when using the uncoupled\nharmonics system, since the geometry is non-axisymmetrical we cannot treat each harmonic separately and\nsolving their respective linear system, we have to couple all the harmonics together and account for the three\ndimensional variation of the grid along the toroidal direction in the Jacobian.\n\n**3.2.** **Implementation of the coupled harmonics**\n\nThe mathematical derivation done in (58) highlights the system for which we are trying to solve; this required\nsome significant modifications to the code, as the infrastructure heavily relied on splitting the system among\n\n19\n\nthe harmonics.\n\n**3.2.1** **Changes in the matrix system**\n\nBefore jumping directly to the results, it is important to verify that our mathematical assumptions and conclusions are well reflected in the practical solution implemented.\nThe first concrete difference we should be able to see is a Jacobian changing along the toroidal angle:\n\nFigure 8: Dependence of the Jacobian on the toroidal angle for several mesh elements. The plot shows\na stronger variation for the innermost elements due to their higher geometric distortion near the mesh\n\naxis.\n\nAs evident from Fig. 8, the Jacobian now presents a dependence on the toroidal angle. Interestingly, we can also\nobserve a stronger influence on the Jacobian in the innermost elements. This is due to the higher distortions\ntowards the mesh axis of the elements.\n\nThis dependence on the three-dimensional Jacobian also allows us to create a meaningful system to solve,\nconsidering all the harmonics, which is immediately evident from Fig. 9:\n\n20\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-19-0.png)\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-20-0.png)\n\n(a) Sparsity pattern of a system matrix where the\ntoroidal modes are uncoupled. Each colored block\non the diagonal represents the physics within a single toroidal mode number, _n_ . The zero-valued offdiagonal blocks indicate no coupling between different\nmodes.\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-20-1.png)\n\n(b) Sparsity pattern of a system matrix with coupling between toroidal modes. The non-zero offdiagonal blocks represent the interaction between different modes (e.g., coupling between modes _n_ and\n_n \u00b1_ 1)\n\nFigure 9: Comparison of system matrix structures for a physical model with (a) uncoupled and (b)\ncoupled toroidal modes. The uncoupled case results in a simple block-diagonal matrix, while coupling\nintroduces off-diagonal terms.\n\n**3.3.** **Coupled projection**\n\nWith all the modifications in place, we can now have a qualitative appreciation of the coupled harmonics by\nrevising the projection proposed in Fig. 7 in the coupled scenario.\nBefore being able to appropriately represent our complex geometry, it was necessary to take into account\nthe non-axysimmetric geometry of the stellarator. As previously discussed, the assumption on the geometry\ninfluenced not only the underlying math of the system but also several support diagnostics along with the code,\nin particular, the vtk export resulting from projecting particles used the 2D basis to represent the poloidal\nsection without taking into account the toroidal angle; for this reason, an extension to 3D geometries has been\ndeveloped.\nAlthough the geometry is represented continuously over the toroidal angle _\u03d5 \u2208_ [0 _,_ 2 _\u03c0_ ], for clarity, this work will\nprimarily show results at a few discrete toroidal planes\n\n**3.3.1** **Gaussian distribution on the W7-A**\n\nThe first test case considered is the Wendelstein 7-A (W7-A)[30], a classical stellarator. While its geometry is\nnon-axisymmetric, it is not subject to drastic deformation. The three-dimensional variation provides a suitable\nbenchmark to initially validate the coupled harmonic projection scheme.\nFor these tests, we employ a three-dimensional Gaussian of the form:\n\n( _R \u2212_ _R_ 0) [2]\n\ufffd 2 _\u03c3R_ [2]\n\n2 _\u03c3_ [2]\n_\u03d5_\n\n\ufffd\ufffd\n\n_f_ ( _R, Z, \u03d5_ ) = exp\n\n_\u2212_\n\n\ufffd\n\n_\u2212_ _R_ 0) [2]\n\n+ [(] _[Z][ \u2212]_ _[Z]_ [0][)][2]\n2 _\u03c3R_ [2] 2 _\u03c3Z_ [2]\n\n_[Z]_ [0][)][2]\n\n+ [(] _[\u03d5][ \u2212]_ _[\u03d5]_ [0][)][2]\n2 _\u03c3Z_ [2] 2 _\u03c3_ [2]\n\n(82)\n\nFor the Gaussian projected onto W7-A, the parameters chosen are:\n\n_R_ 0 = 2 _._ 02 _,_ _Z_ 0 = 0 _,_ _\u03d5_ 0 = _[\u03c0]_\n\n2\n\n_\u03c3R_ = _\u03c3Z_ = 0 _._ 01 _,_ _\u03c3\u03d5_ = _[\u03c0]_\n\n2\n\n21\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-0.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-1.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-2.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-3.png)\n\n(a) Cross-section at _\u03d5_ = 0. (b) Cross-section at _\u03d5_ = _[\u03c0]_ 2 [.] (c) Cross-section at _\u03d5_ = _\u03c0_ .\n\nFigure 10: Visualization of the W7-A stellarator\u2019s non-axisymmetric geometry. The poloidal crosssection is shown at three different toroidal angles.\n\nAs shown in Fig. 10, even for relatively simple non-axisymmetric geometries, the toroidal dependency of the\nmesh already has a noticeable influence on the solution; taking into account the full Jacobian, such deformation\nis correctly accounted for and the shape of the Gaussian is recovered correctly.\n\n**3.3.2** **Gaussian distribution on the W7-X**\n\nWhile W7-A provides a suitable starting point, it is crucial to move toward more realistic and contemporary\ngeometries, where a strong dependence on the toroidal direction greatly deforms the mesh shape. For these\nreasons, further tests have been conducted on the geometry of the W7-X [26], the latest stellarator reactor\nlocated at the Max Planck Institute for Plasma Physics in Greifswald.\nW7-X is a quasi-isodynamic stellarator, and the geometry of the reactor closely resembles the geometries of\nSQuIDs [15], a promising future reactor design for which, in recent years, great interest has developed.\nDue to the highly shaped mesh, the Gaussian distribution cannot be initialized in the same _RZ_ position like in\nthe W7-A case; for this reason, suitable positions are chosen to showcase the most deformed geometries.\nThe Results shown in Fig. 11 use a 3D Gaussian with parameters: _Z_ 0 = 0 _, \u03c3R_ = _\u03c3Z_ = 0 _._ 45 _,_ _\u03c3\u03d5_ = 16 _[\u03c0]_\n\n(a) Cross-section at _\u03d5_ = 0 with _R_ 0 = 6. (b) Cross-section at _\u03d5_ = _\u03c0_ with _R_ 0 = 5.\n\nFigure 11: Projection of a Gaussian distribution onto the W7-X geometry. The significant deformation\nof the poloidal cross-section between the toroidal angles _\u03d5_ = 0 and _\u03d5_ = _\u03c0_ showcases the capability of\nthe coupled projection scheme on a highly shaped, realistic geometry.\n\n22\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-4.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-5.png)\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-21-6.png)\n**3.4.** **Convergence Tests**\n\nWhile the qualitative analysis shows promising results, it is vital to present quantitative studies as evidence of\nthe scheme\u2019s accuracy. For this, a range of convergence tests has been performed by projecting some known\nanalytical functions onto the W7-X grid. The idea is to measure the change of error as we increase the number\nof toroidal harmonics used to compute the solution. With the uncoupled projection, no convergence is expected\nsince the geometrical coupling of harmonics is neglected. In contrast, for the coupled scheme, we expect an\nexponential, spectral [8], convergence.\nWe choose the _L_ [2] norm between the original analytical function and the numerical solution from the projection\non the FEM grid. By increasing the resolution of the solution, through the increase in the number of toroidal\nharmonics, we expect this error to decrease faster than the uncoupled counterpart. These tests have been\nperformed on three different functions and are reported below:\n\nFigure 12: Performance of the coupled vs. uncoupled schemes for the function cos [2] (2 _\u03d5_ ). The uncoupled\nsystem fails to converge, while the coupled system shows a sharp convergence. The error decays\nprecisely at _n_ tor = 9, which corresponds to a maximum mode number of _M_ = 4 in our basis set\n( _n_ tor = 2 _M_ + 1), capturing the dominant harmonic in the function\u2019s analytical form. The remaining\nerror at higher resolution is close to the machine epsilon for double-precision floating points.\n\nThe first function under consideration is a _cos_ [2] (2 _\u03d5_ ), whose Fourier expansion has a periodicity of 4 ( [1] 2 [+]\n\n1\n2 _[cos]_ [(4] _[x\u03d5]_ [)). The behavior is perfectly in line with the theoretical assumptions: the sharp increase in accuracy]\nis explained by the introduction of the harmonic with the proper periodicity into the spectral decomposition\n(Fig. 12). This pathological case highlights how the uncoupled system is fundamentally unable to approximate\nthe function to a meaningful level of accuracy.\nIn order to validate the method against more realistic distribution scenarios, tests were performed using Gaussian\nfunctions (Fig. 13). The first scenario presents the perfect candidate for the convergence study. By using a\nperiodic and smooth ( _C_ _[\u221e]_ ) function such as _e_ _[cos]_ [(] _[\u03d5]_ [)], we can appreciate the spectral convergence of the method.\n\n_\u2212_ [(] _[\u03d5][\u2212][\u03c0]_ [)][2]\nThe second case, a standard Gaussian on the toroidal direction of equation: exp \ufffd 2(0 _._ 3) [2] \ufffd, demonstrates how\n\nthe uncoupled system can almost approximate the results from the coupled scenario for a small number of\nharmonics, usually this is not the case for production cases as the complex physics needs a high number of\nharmonics to be properly represented.\n\n**3.5.** **FFT acceleration of the matrix construction**\n\nAs described in sec. 2.3.3, the integral on the toroidal direction can be efficiently evaluated by means of the FFT\nalgorithm. This strategy was already employed in the construction of the matrix in the fluid time stepping, but\nsince the toroidal dependency is missing in the tokamak case, the strategy had to be implemented from scratch\nfor the projection system.\n\n23\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-22-0.png)\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-23-0.png)\n\n(a) Convergence for a periodized Gaussian function.\nThe function is smooth and periodic.\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-23-1.png)\n\n(b) Convergence for a non-periodic Gaussian function.\nThe convergence rate is slower, and the uncoupled approximation is good enough for a small _ntor_ number.\n\nFigure 13: Convergence tests for two Gaussian functions projected on the W7-X grid.\n\nThe general strategy implemented was to collect all the toroidally independent parts of the integral together,\nand then, depending on whether the user wants to run the code with or without the FFT, either add the\ndirect integration contribution or compute the coefficients via FFT. For the FFT computation, we leveraged\nthe FFTW library [14].\nThe actual system to be solved for is slightly different from the one presented earlier. In order to get a smoother\nprojection of the kinetic quantities, it is sometimes useful to use some filters applied to the derivatives of the\nsolution. For these terms, a separate FFT needs to be performed; thus, two different sets of FFTs are performed\nseparately and later reassembled together in one single matrix per element.\nAn excellent way to demonstrate the effectiveness of this implementation is to compare the performance with\nand without the FFT acceleration. Fig. 14 shows the average wall time required to build the projection matrix\nfor both the direct integration (non-FFT) and the FFT-based methods alongside the speedup, plotted against\nthe number of toroidal harmonics used ( _ntor_ ).\n\nFigure 14: Comparison of wall time for the matrix assembly with (FFT) and without (non-FFT)\nconsidering _nplane_ = 2 _ntor_ the Fast Fourier Transform acceleration, as a function of the number\nof toroidal harmonics ( _ntor_ ). The speedup, calculated as the ratio of non-FFT time to FFT time,\ndemonstrates a significant performance gain, aligned with the theoretical linear speedup with respect\n\nto _ntor_ .\n\nAs can be noted in Fig. 14, while the number of toroidal harmonics increases, the computational cost of the\n\n24\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-23-2.png)\ndirect integration method (represented by red triangles) increases quickly. The wall time for the FFT-based\nmethod (green squares), on the other hand, shows a considerably softer increase. Performance is significantly\nimproved as a result of this scaling difference. The blue line on the plot represents the speedup, which is the\nratio of the non-FFT time to the FFT time. With _ntor_, it grows almost linearly, and for _ntor_ = 25, it achieves\na notable speedup.\n\n**3.6.** **The RTree**\n\nA crucial missing step for a complete working simulation lies in the association of each particle with the\ncorresponding element. This step is needed since each particle lives in the real space _RZ\u03d5_, but the finite\nelement formulation requires an element-wise location of the particles to project the relevant quantities.\nThis problem can be reduced to a classical spatial indexing problem, for which many solutions have been\ndeveloped over the years, depending on the specific application requirements.\nFor the problem at stake, since the mesh naturally partitions the space into regions, a region proposal algorithm\nis required. For these reasons, the RTree [16] algorithm and data structure were the most natural choice and\nare already used in the 2D tokamak applications of the code.\nThe underlying idea being that the bounding boxes in three dimensions of each element must cover the entire\nelement, this is achieved by finding the minimum and maximum points of the element along two different\npoloidal section located at _\u03d5_ 1 _, \u03d5_ 2 and defining the bounding box as ([ _Rmin, Rmax_ ] _,_ [ _Zmin, Zmax_ ] _,_ [ _\u03d5_ 1 _, \u03d5_ 2]).\nTo find the 2D minimum bounding box at a given poloidal section, we can look for the points at which the\nderivative is zero along each of the four element sides, as briefly explained in sec. 2.2.7.\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-24-0.png)\n\n(a) R-Tree structure for\nthe poloidal plane _\u03d5_ = 0\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-24-1.png)\n\n(b) R-Tree structure for the poloidal plane _\u03d5_ = _\u03c0_\n\nFigure 15: Visualization of the 2D R-Tree spatial indexes for the W7-X grid at two different toroidal\nangles. Each rectangle represents the 2D bounding box of a single mesh element at that specific poloidal\ncross-section. The significant change in the bounding box layout between (a) and (b) illustrates the\nstrong geometric variation along the toroidal direction.\n\nWith the minimum of the element in the poloidal section (Fig. 15), we chose to consider the width of the\nbounding box in the toroidal direction as the distance between two different poloidal sections, thus creating our\nthree-dimensional bounding box (Fig. 16).\n\n25\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-25-0.png)\n\nFigure 16: The 3D R-Tree data structure used for efficient particle lookup in the W7-X stellarator\ngeometry. The image shows the 3D bounding boxes that form the tree\u2019s nodes, creating a hierarchical\nmap of the simulation domain. This spatial partitioning is a critical component for associating particles\nwith their host finite elements in the non-axisymmetric grid.\n\nThe introduction of the third dimension on both the RTree algorithm and the local coordinate search introduces\na significant overhead. This overhead should still be bounded by a factor proportional to the number of particles,\nfor the association step between the particles and elements, and a constant, for the element creation.\nAs we can see in Fig. 17, we have a worst-case scenario of 80x speed-down for the tree creation. This is a\nfavorable result, as a naive slicing of the toroidal direction into _nplanes_ = 128 might suggest a 128x slowdown.\nThe improved performance is due to the R-Tree\u2019s hierarchical structure, which efficiently groups elements and\nprunes the search space, avoiding a linear scaling with the number of poloidal planes.\nAs per the particles association itself, adding a third dimension was bound to be computationally expensive; on\naverage, we measure a 3x speed down, for which a small amount is attributable to the imperfect discretizations\nof the toroidal direction requiring, on average, 1.65x more elements to lookup.\n\n26\n\n![](papers/images/Algorithms-and-optimizations-for-global-nonlinear-hybrid-fluidkinetic-finite-element-stellarator-simulations.pdf-26-0.png)\n\nFigure 17: Performance comparison of the R-Tree implementation for element creation and particle\nassociation. The plot highlights the computational overhead introduced by the third dimension.\n\n## **4. Conclusion**\n\nThe development of strong, predictive simulation capabilities is essential to the search for commercially viable\nfusion energy, particularly for the geometrically challenging stellarator concept. A fundamental challenge in\nthis field is the precise application of a hybrid fluid-kinetic model in a non-axisymmetric framework. Decoupled\nprojection schemes used in simpler tokamak simulations are physically incorrect for stellarators because the\ntoroidal Fourier harmonics are coupled by the intrinsic three-dimensional nature of the magnetic field.\nThe main contribution of this work is the design, implementation, and validation of a novel, globally coupled\nparticle-in-cell projection scheme within the JOREK finite element code. This technique addresses the core\nchallenge by building and solving a single, cohesive linear system over the entire 3D, non-axisymmetric mesh. By\nself-consistently accounting for the geometric coupling between all toroidal harmonics, the system ensures a highfidelity transfer of information from the kinetic particle population to the fluid grid. An effective Fast Fourier\nTransform (FFT) based approach was used to make this computationally demanding global matrix construction\npossible. Qualitative projections onto realistic Wendelstein 7-X geometries demonstrated the scheme\u2019s ability\nto capture complex shaping. More significantly, quantitative convergence tests conclusively demonstrated the\nmethod\u2019s superiority: the coupled scheme achieved the theoretically expected spectral convergence for smooth\nanalytical functions, whereas the uncoupled approach failed to converge, highlighting the necessity of this global\n\ntreatment.\nAs a second significant contribution, an effective particle localization algorithm was implemented to address\nthe prohibitive computational cost of a global scheme. We developed a scalable solution for associating millions\nof particles with their host finite elements by creating a three-dimensional R-Tree spatial index specific to the\nJOREK mesh structure. Performance analysis verified that this algorithm tackles the 3D search\u2019s complexity\nwith a reasonable overhead, keeping the hybrid model tractable for large-scale, high-performance computing.\n\n27\n\nIn addition to providing a solid and verified framework, this work opens up a number of fascinating directions\nfor further investigation. In order to study how kinetic effects drive or dampen MHD instabilities, the most\nimmediate next step is to enable the feedback of the kinetic particles on the fluid. A distributed memory model\nwith MPI could be used to parallelize the assembly of the global matrix and right-hand-side vector, further\nimproving scalability.\nAlthough they come with some trade-offs, other possible improvements have been taken into consideration.\nOne of them might be to find the true extrema of each element\u2019s geometry; for example, a Newton iteration\ncould be used to determine the bounding boxes of the R-Tree with greater precision; however, this is probably\ntoo computationally costly for a marginal gain. Likewise, iterative solvers [38] are suboptimal to solve the\nprojection system, even though they are frequently used for large linear systems. The use of direct solver\nlibraries [1, 22, 36] based on a one-time matrix factorization is much more efficient because the projection\nsystem is solved repeatedly with the same matrix but a changing right-hand side.\nTogether, these contributions eliminate a significant obstacle to running high-fidelity, non-linear hybrid simulations of stellarator plasmas. This validated framework makes a previously unattainable range of predictive\nstudies possible, enabling the community to better understand, optimize, and design the next generation of\nfusion energy devices and advancing our progress toward clean, sustainable energy.\n\n## **References**\n\n[1] P. R. Amestoy, I. S. Duff, J. Koster, and J.-Y. L\u2019Excellent. A fully asynchronous multifrontal solver using\ndistributed dynamic scheduling. _SIAM Journal on Matrix Analysis and Applications_, 23(1):15\u201341, 2001.\n\n[2] R. Aymar. Iter overview. _Fusion Engineering and Design_, 36(1):9\u201321, 1997.\n\n[3] H. Bergstr\u00f6m, S.-J. Liu, V. Bandaru, M. Hoelzl, JOREK Team, and JET Contributors. Introduction\nof a 3d global non-linear full-f particle-in-cell model for runaway electrons in jorek. _Plasma Physics and_\n_Controlled Fusion_, 67(3):035004, feb 2025.\n\n[4] C. K. Birdsall and A. B. Langdon. _Plasma physics via computer simulation_ . Taylor and Francis, New\nYork, spl. indian ed. edition, 2005.\n\n[5] T. Bogaarts, M. Hoelzl, G. T. A. Huijsmans, and X. Wang. Development and application of a hybrid\nmhd-kinetic model in jorek. _Physics of Plasmas_, 29:122501, 12 2022.\n\n[6] J. P. Boyd. _Chebyshev and Fourier Spectral Methods_ . Dover Publications, Mineola, NY, second edition,\n2001.\n\n[7] C. Sovinec and B. Cornille. Initial Results of NIMSTELL, the Stellarator Variant of NIMROD. In _APS_\n_Division of Plasma Physics Meeting Abstracts_, volume 2021 of _APS Meeting Abstracts_, page PP11.092,\nOctober 2021.\n\n[8] C. Canuto, M. Y. Hussaini, A. Quarteroni, and T. A. Zang. _Spectral Methods: Fundamentals in Single_\n_Domains_ . Scientific Computation. Springer, Berlin, Heidelberg, 2006.\n\n[9] J. Cooley and J. Tukey. An algorithm for the machine calculation of complex fourier series. _Mathematics_\n_of Computation_, 19(90):297\u2013301, 1965.\n\n[10] O. Czarny and G. T. A. Huijsmans. B\u00e9zier surfaces and finite elements for mhd simulations. _Journal of_\n_Computational Physics_, 227(16):7423\u20137445, 2008.\n\n[11] D. C. van Vugt. _Nonlinear coupled MHD-kinetic particle simulations of heavy impurities in tokamak_\n_plasmas_ . Phd thesis 1 (research tu/e / graduation tu/e), Applied Physics and Science Education, July\n2019. Proefschrift.\n\n[12] G. L. Delzanno and E. Camporeale. On particle movers in cylindrical geometry for particle-in-cell simulations. _Journal of Computational Physics_, 253:259\u2013277, 2013.\n\n[13] N. M. Ferraro and S. C. Jardin. Calculations of two-fluid magnetohydrodynamic axisymmetric steadystates. _Journal of Computational Physics_, 228(20):7742\u20137770, 2009.\n\n[14] M. Frigo and S. G. Johnson. The design and implementation of fftw3. _Proceedings of the IEEE_, 93(2):216\u2013\n231, 2005.\n\n28\n\n[15] A. G. Goodman, P. Xanthopoulos, G. G. Plunk, H. Smith, C. N\u00fchrenberg, C. D. Beidler, S. A. Henneberg,\nG. Roberg-Clark, M. Drevlak, and P. Helander. Quasi-isodynamic stellarators with low turbulence as\nfusion reactor candidates. _PRX Energy_, 3:023010, Jun 2024.\n\n[16] A. Guttman. R-trees: a dynamic index structure for spatial searching. In _Proceedings of the 1984 ACM_\n_SIGMOD International Conference on Management of Data_, SIGMOD \u201984, page 47\u201357, New York, NY,\nUSA, 1984. Association for Computing Machinery.\n\n[17] P. Helander, C. D. Beidler, T. M. Bird, M. Drevlak, Y. Feng, R. Hatzky, F. Jenko, R. Kleiber, J. H. E.\nProll, Yu. Turkin, and P. Xanthopoulos. Stellarator and tokamak plasmas: a comparison. _Plasma Physics_\n_and Controlled Fusion_, 54(12):124009, nov 2012.\n\n[18] P. Helander and D. J. Sigmar. _Collisional Transport in Magnetized Plasmas_ . Cambridge University Press,\n2002.\n\n[19] M. Hoelzl, G. T. A. Huijsmans, S. J. P. Pamela, M. B\u00e9coulet, E. Nardon, F. J. Artola, B. Nkonga, C. V.\nAtanasiu, V. Bandaru, A. Bhole, D. Bonfiglio, A. Cathey, O. Czarny, A. Dvornova, T. Feh\u00e9r, A. Fil,\nE. Franck, S. Futatani, M. Gruca, H. Guillard, J. W. Haverkort, I. Holod, D. Hu, S. K. Kim, S. Q.\nKorving, L. Kos, I. Krebs, L. Kripner, G. Latu, F. Liu, P. Merkel, D. Meshcheriakov, V. Mitterauer,\nS. Mochalskyy, J. A. Morales, R. Nies, N. Nikulsin, F. Orain, J. Pratt, R. Ramasamy, P. Ramet, C. Reux,\nK. S\u00e4rkim\u00e4ki, N. Schwarz, P. S. Verma, S. F. Smith, C. Sommariva, E. Strumberger, D. C. van Vugt,\nM. Verbeek, E. Westerhof, F. Wieschollek, and J. Zielinski. The jorek non-linear extended mhd code and\napplications to large-scale instabilities and their control in magnetically confined fusion plasmas. _Nuclear_\n_Fusion_, 61(6):065001, May 2021.\n\n[20] I. Holod, M. Hoelzl, P. S. Verma, G. T. A. Huijsmans, R. Nies, and JOREK Team. Enhanced preconditioner\nfor jorek mhd solver. _Plasma Physics and Controlled Fusion_, 63(11):114002, sep 2021.\n\n[21] G. T. A. Huijsmans. Implementation of an iterative solver in the non-linear mhd code jorek. Technical Report ANR-CIS-2006-001-02, Association Euratom-CEA, CEA/DSM/DRFC, Centre de Cadarache, 13108\nSt. Paul lez Durance, France, 2008.\n\n[22] P. H\u00e9non, P. Ramet, and J. Roman. Pastix: A parallel direct solver for sparse spd matrices based on\nefficient static scheduling and memory managment. 01 2001.\n\n[23] L.-M. Imbert-Gerard, E. J. Paul, and A. M. Wright. An introduction to stellarators: From magnetic fields\nto symmetries and optimization, 2020.\n\n[24] S. C. Jardin. Review of implicit methods for the magnetohydrodynamic description of magnetically confined\nplasmas. _Journal of Computational Physics_, 231(3):822\u2013838, 2012. Special Issue: Computational Plasma\nPhysics.\n\n[25] J. Killeen, G. D. Kerbel, M. G. McCoy, and A. A. Mirin. _Introduction_, pages 1\u20137. Springer Berlin\nHeidelberg, Berlin, Heidelberg, 1986.\n\n[26] T. Klinger, A. Alonso, S. Bozhenkov, R. Burhenn, A. Dinklage, G. Fuchert, J. Geiger, O. Grulke, A. Langenberg, M. Hirsch, G. Kocsis, J. Knauer, A. Kr\u00e4mer-Flecken, H. Laqua, S. Lazerson, M. Landreman,\nH. Maa\u00dfberg, S. Marsen, M. Otte, N. Pablant, E. Pasch, K. Rahbarnia, T. Stange, T. Szepesi, H. Thomsen, P. Traverso, J. L. Velasco, T. Wauters, G. Weir, T. Windisch, and The Wendelstein 7-X Team.\nPerformance and properties of the first plasmas of wendelstein 7-x. _Plasma Physics and Controlled Fusion_,\n59(1):014018, oct 2016.\n\n[27] S. Q. Korving. _MHD Simulations of Neutral and Impurity Transport in ELM-controlled Plasmas: with ap-_\n_plication to ITER_ . Phd thesis 1 (research tu/e / graduation tu/e), Applied Physics and Science Education,\nJune 2024. Proefschrift.\n\n[28] C. Liu, S. C. Jardin, H. Qin, J. Xiao, N. M. Ferraro, and J. Breslau. Hybrid simulation of energetic particles\ninteracting with magnetohydrodynamics using a slow manifold algorithm and gpu acceleration. _Computer_\n_Physics Communications_, 275:108313, June 2022.\n\n[29] D. Liu. GC1 continuity conditions between two adjacent rational B\u00e9zier surface patches. _Computer Aided_\n_Geometric Design_, 7(1-4):151\u2013163, 1990.\n\n[30] Max Planck Institute for Plasma Physics. Wendelstein 7-a. `[https://www.ipp.mpg.de/3951949/](https://www.ipp.mpg.de/3951949/wendelstein7a)`\n`[wendelstein7a](https://www.ipp.mpg.de/3951949/wendelstein7a)`, 2025. Accessed: 2025-07-14.\n\n29\n\n[31] N. Nikulsin, M. Hoelzl, A. Zocco, K. Lackner, and S. G\u00fcnter. A three-dimensional reduced mhd model\nconsistent with full mhd. _Physics of Plasmas_, 26(10), October 2019.\n\n[32] N. Nikulsin, M. Hoelzl, A. Zocco, K. Lackner, and S. G\u00fcnter. Testing of the new jorek stellarator-capable\nmodel in the tokamak limit. _Journal of Plasma Physics_, 87(3), May 2021.\n\n[33] N. Nikulsin, R. Ramasamy, M. Hoelzl, F. Hindenlang, E. Strumberger, K. Lackner, S. G\u00fcnter, and JOREK\nTeam. Jorek3d: An extension of the jorek nonlinear mhd code to stellarators. _Physics of Plasmas_,\n29(6):063901, 06 2022.\n\n[34] S. J. P. Pamela, G. T. A. Huijsmans, and M. Hoelzl. A generalised formulation of g-continuous bezier\nelements applied to non-linear mhd simulations. _Journal of Computational Physics_, 464:111101, 2022.\n\n[35] W. Park, S. Parker, H. Biglari, M. Chance, L. Chen, C. Z. Cheng, T. S. Hahm, W. W. Lee, R. Kulsrud,\nD. Monticello, L. Sugiyama, and R. White. Three-dimensional hybrid gyrokinetic-magnetohydrodynamics\nsimulation. _Physics of Fluids B: Plasma Physics_, 4(7):2033\u20132037, 07 1992.\n\n[36] F.-H. Rouet, X. S. Li, P. Ghysels, and A. Napov. A distributed-memory package for dense hierarchically\nsemi-separable matrix computations using randomization, 2015.\n\n[37] P. R\u00e1c. Gpu-accelerated stiffness matrix construction for finite element mhd code jorek. Master\u2019s thesis,\nFaculty of Informatics, Universit\u00e0 della Svizzera italiana, Lugano, Switzerland, 2024. Supervisors: M.\nMulterer; Supporting Supervisors: M. Hoelzl, I. Holod.\n\n[38] Y. Saad. _Iterative Methods for Sparse Linear Systems_ . Society for Industrial and Applied Mathematics,\nsecond edition, 2003.\n\n[39] C. R. Sovinec, A. H. Glasser, T. A. Gianakon, D. C. Barnes, R. A. Nebel, S. E. Kruger, D. D. Schnack,\nS. J. Plimpton, A. Tarditi, and M. S. Chu. Nonlinear magnetohydrodynamics simulation using high-order\nfinite elements. _Journal of Computational Physics_, 195(1):355\u2013386, 2004.\n\n[40] W. M. Tang. Scientific and computational challenges of the fusion simulation project (fsp). _Journal of_\n_Physics: Conference Series_, 125(1):012047, jul 2008.\n\n[41] Y. Todo and T. Sato. Linear and nonlinear particle-magnetohydrodynamic simulations of the toroidal\nalfv\u00e9n eigenmode. _Physics of Plasmas_, 5(5):1321\u20131327, 05 1998.\n\n[42] T. Ueshiba and G. Roth. Generating smooth surfaces with bicubic splines over triangular meshes: toward\nautomatic model building from unorganized 3d points. In _Second International Conference on 3-D Digital_\n_Imaging and Modeling (Cat. No.PR00062)_, pages 302\u2013311, 1999.\n\n[43] X. Wang, S. Briguglio, L. Chen, C. Di Troia, G. Fogaccia, G. Vlad, and F. Zonca. An extended hybrid magnetohydrodynamics gyrokinetic model for numerical simulation of shear alfv\u00e9n waves in burning plasmas.\n_Physics of Plasmas_, 18(5), May 2011.\n\n[44] J. Wesson. _Tokamaks_ . Oxford University Press, 4 edition, 2011.\n\n[45] R&D World. An overview of the late 2024 supercomputing landscape in 6 charts. `[https://www.](https://www.rdworldonline.com/an-overview-of-the-late-2024-supercomputing-landscape-in-6-charts/)`\n`[rdworldonline.com/an-overview-of-the-late-2024-supercomputing-landscape-in-6-charts/](https://www.rdworldonline.com/an-overview-of-the-late-2024-supercomputing-landscape-in-6-charts/)`,\n2025. Accessed: 2025-08-28.\n\n[46] Y. Xu. A general comparison between tokamak and stellarator plasmas. _Matter and Radiation at Extremes_,\n1(4):192\u2013200, 2016.\n\n[47] Y. Zhou, N. M. Ferraro, S. C. Jardin, and H. R. Strauss. Approach to nonlinear magnetohydrodynamic\nsimulations in stellarator geometry. _Nuclear Fusion_, 61(8):086015, July 2021.\n\n[48] O.C. Zienkiewicz, R.L. Taylor, and J.Z. Zhu. _The Finite Element Method: Its Basis and Fundamentals_,\npage iii. Butterworth-Heinemann, Oxford, January 2013.\n\n30\n\n## **Algoritmi e ottimizzazioni per la simulazione globale e non-lineare di** **stellarator tramite modelli ibridi fluido-cinetici con il metodo degli** **elementi finiti**\n\nIl progresso della ricerca sull\u2019energia da fusione nucleare richiede lo sviluppo di modelli predittivi per i plasmi\nnei reattori stellarator. Tuttavia, la modellizzazione di questi sistemi presenta alcune sfide computazionali. Tra\nqueste, una delle difficolt\u00e0 principali consiste nel simulare con precisione la dinamica delle particelle all\u2019interno\ndel plasma, un compito che richiede modelli ibridi, a met\u00e0 tra fluidodinamica e cinetica. A differenza dei\ntokamak, la geometria non assisimmetrica degli stellarator induce un accoppiamento intrinseco tra i modi\ntoroidali, che complicano ulteriormente la simulazione.\nPartendo da tali premesse, il presente lavoro propone, dunque, un nuovo schema di proiezione, integrato nel\ncodice a elementi finiti JOREK. Tale approccio consente di trasferire l\u2019informazione cinetica sulla mesh in modo\nconsistente e fisicamente fondato, gestendo la complessit\u00e0 della mesh 3D. Ci\u00f2 avviene costruendo e risolvendo\nun unico sistema lineare che include simultaneamente tutte le armoniche toroidali.\nAl fine di gestire in modo efficiente e gestibile la localizzazione di milioni di particelle, \u00e8 stato sviluppato\nun algoritmo di indirizzamento spaziale attraverso un R-Tree tridimensionale, il quale garantisce la fattibilit\u00e0\ncomputazionale del metodo su larga scala. L\u2019affidabilit\u00e0 del codice sviluppato \u00e8 stata rigorosamente verificata\nsu geometrie realistiche del reattore stellarator Wendelstein 7-X.\nI test di convergenza hanno confermato il raggiungimento della convergenza spettrale prevista dalla teoria,\nevidenziando, inoltre, il contrasto con le scarse prestazioni degli approcci non accoppiati. Di conseguenza, si\n\u00e8 evidenziato come lo sviluppo di questo strumento computazionale fornisca una risorsa essenziale per l\u2019analisi\npredittiva e l\u2019ottimizzazione di futuri progetti cinetici su stellarator.\n\n**Parole chiave:** Simulazioni di stellarator, Modelli ibridi fluido-cinetici, Metodo degli Elementi Finiti\n(FEM), Metodo Particle-in-Cell (PiC), JOREK, Calcolo ad Alte Prestazioni (HPC)\n\n31"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is overcoming the breakdown of toroidal axisymmetry in stellarator geometries by establishing a 'coupled-harmonic projection scheme'. This involves formulating and solving a single, global linear system (M * p = L) that simultaneously accounts for the intrinsic coupling of all toroidal Fourier harmonics, unlike the decoupled, block-diagonal systems used for axisymmetric tokamaks. Efficiency is achieved through Fast Fourier Transform (FFT) for matrix (M) assembly and a 3D R-Tree for efficient particle localization (for L vector assembly).\n\n**Explanation:** In fusion plasma simulations, we use a hybrid approach: a fluid model for the bulk plasma (using FEM on a grid) and a kinetic model for specific particles. The challenge lies in accurately transferring particle information (from the kinetic model) to the fluid grid ('projection'). In tokamaks, which are toroidally symmetric, the problem simplifies because different Fourier harmonics (representing toroidal variations) are 'decoupled'. This means you can solve many smaller, independent linear systems (like separate small programs for each frequency) to project particle data.However, stellarators have complex, non-axisymmetric 3D geometries. This 'breaks' the symmetry, meaning all the toroidal Fourier harmonics are intrinsically 'coupled'. You cannot solve for one harmonic's contribution without considering all the others, making the overall linear system for projection (M * p = L) much larger and denser; it's like a single giant program that must process all frequencies together.This work's solution is to *explicitly solve this global coupled system*. The 'M' (mass) matrix, which describes how the grid's basis functions interact, now has non-zero entries connecting different harmonics. To make this computationally feasible:1.  **FFT for 'M' assembly:** Calculating the integral components of 'M' (which involve products of basis functions and the Jacobian) for all coupled harmonics is a huge task. Instead of direct summation over many toroidal planes for each (l, m) pair (which is O(N_tor^2 * N_plane)), they leverage the Fourier structure of the integral. By using FFT, they can compute all required Fourier coefficients much more efficiently (O(N_plane log N_plane + N_tor^2)), effectively parallelizing and accelerating many repetitive computations in one pass.2.  **3D R-Tree for 'L' assembly:** The 'L' (right-hand side) vector collects the weighted contributions from individual particles. To do this efficiently, you must quickly find which 'finite element' (grid cell) each of millions of particles belongs to. A 3D R-Tree is a spatial indexing data structure, similar to a hash map for 3D coordinates. It organizes the bounding boxes of grid elements hierarchically. When searching for a particle, the R-Tree quickly prunes vast areas of the grid, directing the search to only a few relevant bounding boxes, drastically reducing the search time per particle from iterating through all elements to a logarithmic time complexity.This combined approach ensures physical accuracy by fully accounting for 3D coupling and maintains computational tractability through clever algorithmic optimizations."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_Ri < Rj for all j \u2208_ `UndecidedNeighbors` **then**\n\n**15** Output 1 (join MIS);\n\n```\n   /* Round 5: Reacting to Neighbor Decisions */\n```"}, {"role": "assistant", "content": "**Mechanism:** This mechanism is a distributed contention resolution or local leader election strategy. Each node (i) possesses a unique or prioritized value (Ri). It then compares its value against all its 'undecided' direct neighbors (j). If node (i)'s value (Ri) is strictly less than every neighbor's value (Rj) in the 'UndecidedNeighbors' set, it unilaterally decides to 'join MIS'. This ensures that in any local neighborhood, only one node (the one with the minimum Ri) will satisfy this condition and take the action in that specific round, preventing multiple nodes from simultaneously joining the MIS from within the same immediate vicinity.\n\n**Explanation:** Think of it like a simple 'for loop' where a node iterates through its list of neighbors who haven't made up their minds yet. For each undecided neighbor, it compares its own unique 'rank' or priority number (Ri) to that neighbor's rank (Rj). If, after checking *all* undecided neighbors, it finds that its own rank (Ri) is the absolute smallest, it means it's the 'most important' or 'highest priority' in that immediate group. This gives it the green light to proceed with an action, which here is 'join MIS'. It's a way for a distributed system to pick a 'winner' locally based on a simple numerical comparison."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**3.1** **Evolutionary Algorithms**\n\nEvolutionary algorithms have long been a compelling alternative to backpropagation-based training methods.\nDespite encompassing a broad range of algorithms (e.g., genetic algorithms (Such et al., 2018) or symbolic\nevolution (Koza, 1994)), most contemporary research on evolution has shifted towards algorithms that scale\nbetter to large numbers of neural network parameters (Jaderberg et al., 2017; Hansen & Ostermeier, 2001;\nSalimans et al., 2017).\n\nOur work focuses on evolving the weights of predetermined architectures, building up from the NES (Wierstra\net al., 2011) family of methods. Such an approach has recently grown in prominence, following the application\nof NES to policy learning in conventional RL environments (Salimans et al., 2017) to alleviate some of the\nchallenges that policy-gradient methods struggle with, like long-horizon environments. Since then, evolution\nhas been widely applied in other domains, such as meta-learning (e.g., (Lu et al., 2022; Metz et al., 2022; Lange\net al., 2023; Goldie et al., 2024; 2025)), hyperparameter tuning (e.g., (Parker-Holder et al., 2021; Tani et al.,\n2021; Vincent & Jidesh, 2023)) and drug discovery (Towers et al., 2025). Here, we consider the limitations\nand solutions to applying ES at significant scale, beyond the small networks and population sizes of these prior\nworks, with a broad focus on policy-learning. In particular, Salimans et al. (2017) uses a maximum population\nsize of 1440, whereas our maximum population size is on the order of hundreds of thousands.\n\nES is limited by its requirement for full, potentially expensive evaluations of the fitness function due to\nsimulating policies in long-horizon environments and potentially high memory usage. Persistent Evolution\nStrategies (Vicol et al., 2021) demonstrate a significant speedup by updating networks _online_ (i.e., during the\nunroll), with followups offering further variance reduction (Li et al., 2023b; Vicol et al., 2023). We note that\nthese works are orthogonal to our focus on scaling up the population size of ES; we leave the application of\nthese techniques on top of EGGROLL to future work.\n\n**3.2** **Evolution Strategies for LLMs**\n\nAlthough gradient backpropagation is typically used for LLM training and fine-tuning, prior work has explored\nES variants for fine-tuning. In particular, zeroth order optimization (Zhang et al., 2024), which is analogous to\nES with a population size of 1, is used by Malladi et al. (2023) for memory-efficient LLM fine-tuning. Yu et al.\n(2025) extend this approach by projecting perturbations to a low-rank subspace, improving the convergence\nof zeroth order optimization. Jin et al. (2024) performs ES directly on LoRA matrices. These works focus\non the supervised fine-tuning setting, finding comparable performance to full fine-tuning, but they do not\ndetermine whether pretraining is possible with zeroth order methods; we find that large population sizes are\nnecessary for pretraining performance, indicating that zeroth order optimization methods would be unsuitable\nfor pretraining.\n\nRecent work has also explored ES in the context of LLM reasoning. Korotyshova et al. (2025) first train\nLoRA adapters using supervised fine-tuning (SFT) before decomposing them into fixed SVD bases alongside\nsingular values that are trained using CMA-ES. They achieve comparable performance to GRPO (Shao et al.,\n2024) in significantly less wall-clock time on math reasoning benchmarks. Qiu et al. (2025) directly use ES\nto optimize all LLM parameters for reasoning, with stronger performance than GRPO on the countdown\nreasoning task. However, both of these approaches use relatively small population sizes, on the order of a\nhundred unique perturbations per update, and instead collect hundreds of rollouts per perturbation to efficiently\nuse GPUs. By contrast, our approach allows all generations to use different perturbations, such that our\nmaximum population size per update is orders of magnitude larger (equal to the maximum inference batch\nsize), without compromising token generation throughput."}, {"role": "assistant", "content": "**Mechanism:** Evolutionary Algorithms (EAs), specifically Evolution Strategies (ES), operate by iteratively sampling a population of candidate solutions (e.g., program settings) from a statistical distribution. Their 'fitness' (performance) is evaluated, and then the distribution's parameters (like its center and spread) are updated based on which samples performed best. This is akin to a 'guess and check' loop with intelligent feedback.\n\n**Explanation:** Think of it like a sophisticated search algorithm, similar to a loop in programming, where each iteration aims to find the 'best' configuration for a complex system. Instead of calculating precise adjustments based on an error signal (like gradient descent, which is like knowing exactly which way to turn a knob), ES takes many 'guesses'. It starts with a broad idea (a statistical distribution of possible configurations). In each step, it generates a 'population' of slightly varied copies of these configurations (like creating many different objects from a class). Each copy is then executed to determine its performance or 'fitness' score. After evaluating all copies, the algorithm analyzes their scores and adjusts its broad idea (the distribution) to center more around the successful guesses. This is like updating a 'mean' and 'variance' in statistics, shifting the focus towards more promising regions of the solution space. This paper's innovation lies in massively scaling the 'population size' variable in this loop\u2014to hundreds of thousands\u2014for complex tasks such as pretraining large language models (LLMs). Prior ES work for LLMs either used a population size of 1 or a few hundred, often compensating with repeated evaluations of the same individual. The challenge is that evaluating fitness (running an LLM) is very expensive, so increasing the number of distinct guesses (population size) without slowing down is a significant engineering challenge. This allows the algorithm to explore a much wider range of possibilities in each iteration, which is crucial when the solution space is vast and intricate, as it is with training LLMs from scratch."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe now introduce and motivate our method EGGROLL, which is presented in Algorithm 1. In Section 4.1\nwe derive a low-rank ES update that approximates a full-rank ES gradient. One practical issue with using\na low-rank matrix approximation is that its distribution and score function have no analytic solution except\nfor degenerate cases, so in Section 4.2 we derive an alternative score function from the limiting high-rank\nGaussian which we propose as an approximation.\n\n5\n\n**4.1** **Low Rank Evolution Strategies** **Algorithm 1** EGGROLL( _r, \u03b1, \u03c3, T_ max _, N_ workers)\n\nRecall the Gaussian matrix ES update from Eq. (4).\nOur goal is to introduce a tractable approximation to\ngenerating full-rank matrices, using low-rank matrices\n_AB_ _[\u22a4]_ as our search matrices instead. We denote the\ndistribution of _A_ as _p_ ( _A_ ) and _B_ as _p_ ( _B_ ) assume that the\nelements of _A_ and _B_ are drawn independently:\n**Assumption 1.** _Assume all elements ai,j \u2208_ _A and_\n_bi,j \u2208_ _B are continuous identically and independently_\n_distributed random variables according to some zero-_\n_mean, symmetric, absolutely continuous (i.e., it has a_\n_density) distribution p_ 0( _\u00b7_ ) _with finite 4th order moments_\n_and variance_ 0 _< \u03c3_ 0 [2] _[.]_\n\n**initialise** _\u00b5_ and workers with known random seeds _\u03c2_\n**for** _T_ max timesteps **do**\n\n**for** Each worker _i \u2208{_ 1 _, . . . N_ workers _}_ in parallel **do**\n\n_Ai \u223c_ _p_ ( _Ai_ ) _, Bi \u223c_ _p_ ( _Bi_ )\n_Ei \u2190_ ~~_\u221a_~~ 1 _r_ _AiBi_ _[\u22a4]_\n_fi \u2190_ _f_ ( _\u00b5_ + _\u03c3Ei_ )\n**end for**\n\nWorkers share scalar fitness _fi_ with other workers\n**for** Each worker _i \u2208{_ 1 _, . . . N_ workers _}_ in parallel **do**\n\nReconstruct _Ej_ for _j \u2208{_ 1 _, . . . N_ workers _}_ from _\u03c2_\n\n_\u00b5 \u2190_ _\u00b5_ + _\u03b1_ _N_ Workers1 \ufffd _Nj_ =1Workers _Ej_ _fj_\n**end for**\n\n**end for**\n\nThe low-rank approximation _AB_ _[\u22a4]_ must be carefully integrated into the Gaussian matrix ES objective in\nEq. (3) to ensure that the variance of the updates remains bounded with increasing number of columns _r_ as the\nelements of _AB_ _[\u22a4]_ are a sum of _r_ random variables. To counter this, we scale the outer product by ~~_\u221a_~~ 1 _r_ which\nkeeps the variance of _E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ as _O_ (1).\n\nObserve that _E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ maps to the manifold M _[r]_ _\u2282_ R _[m][\u00d7][n]_ of rank _r_ matrices, which is a subset of R _[m][\u00d7][n]_ .\nThis means that the density _p_ ( _E_ ) is defined with respect to a unit volume over the manifold and cannot be\ndefined with respect to the standard unit volume in Euclidean space as the volume of the manifold is zero\nusing this measure. For the corresponding score function, gradients with respect to log _p_ ( _E_ ) are defined\nover the tangent space to M _[r]_ instead of in the usual Euclidean space. An intuitive reason for this is that\nthere is dependence between elements of _E_ and so it is not possible to take partial derivatives with respect\nto each element whilst keeping all other elements free. In principle it is possible to define all distributions\nand gradients with respect to the manifold M _[r]_, however this makes an analysis of low-rank updates difficult.\nInstead, we study the variable _Z_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ + _\u03f5_ where _\u03f5_ is an _m \u00d7 n_ matrix with independent decaying\n1\nGaussian elements _\u03f5i,j \u223cN_ (0 _,_ _[\u03c3]_ _\u03f5_ [2] _/r_ ). The variable _Z_ = ~~_\u221a_~~ _r_ _AB_ _[\u22a4]_ + _\u03f5_ has a well-defined density _p_ ( _Z_ ) for all\n_\u03c3\u03f5 >_ 0. This conceptual tool greatly simplifies analysis and as _\u03c3\u03f5_ can be made arbitrarily small and hence _p_ ( _E_ )\ncan be arbitrarily close to _p_ ( _Z_ ), the difference between the update used in practice and the update analysed is\nnegligible. Substituting for _p_ ( _E_ ) = _p_ ( _Z_ ) in Eq. (3), we derive the low-rank ES objective:\n\n_J_ LR( _\u00b5_ ) = E _Z\u223cp_ ( _Z_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3Z_ )] _._\n\nWe now verify that _p_ ( _z_ ) is well-defined and show how _J_ LR( _\u00b5_ ) can be optimised using the score function of\n_p_ ( _Z_ ):\n**Theorem 1.** _**Low-rank ES Gradient.**_ _Let Assumption 1 hold. Then for finite r:_\n\n_gLR_ := _\u2207\u00b5JLR_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3Z]_ [)]] _[ .]_\n\n_where Z is generated by sampling A \u223c_ _p_ ( _A_ ) _, B \u223c_ _p_ ( _B_ ) _, \u03f5 \u223c_ _p_ ( _\u03f5_ ) _and making the transformation Z_ =\n1 _AB_ _[\u22a4]_ + _\u03f5._\n~~_\u221a_~~ _r_\n\n**4.2** **Score Function Approximation**\n\nAs the mapping ( _A, B, \u03f5_ ) : _\u2192_ _Z_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ + _\u03f5_ is non-invertible, there does not exist a simple closed form\nsolution for the density _p_ ( _Z_ ) and score function except in degenerate cases such as _m_ = _n_ = 1. Instead, we\nuse an approximation for the score function _S_ [\u02c6] ( _Z_ ) _\u2248\u2207Z_ log _p_ ( _Z_ ):\n\n\u02c6 \u02c6\n_g_ LR = _\u2212_ [1] _S_ ( _Z_ ) _f_ ( _M_ = _\u00b5_ + _\u03c3Z_ ) _._ (5)\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)] \ufffd \ufffd\n\nTo optimise the ES objective using the EGGROLL update, we adapt the parallelised evolutionary strategies\nalgorithm from Salimans et al. (2017). In our experiments and Algorithm 1, we use a Gaussian approximate\n\n6\n\nscore function, which is obtained from taking the limit _r \u2192\u221e_ . As _\u03f5_ is a random matrix formed of independent\nGaussian elements, it can be decomposed into an equivalent sum of _r_ independent Gaussian matrices:\n\n1\n\n_\u03f5_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd _\u03f5i,_\n\n_i_ =1\n\nwhere each random matrix _\u03f5i \u223c_ _p_ ( _\u03f5i_ ) has the same distribution as _\u03f5_ . Likewise, the matrix _AB_ _[\u22a4]_ can be\ndecomposed as a sum of independent, zero-mean vector outer products:\n\n_AB_ _[\u22a4]_ =\n\n_r_\n\ufffd _aib_ _[\u22a4]_ _i_ _[,]_\n\n_i_ =1\n\nwhere _ai_ and _bi_ are the _i_ th column vectors of _A_ and _B_ . This allows us to write _Z_ as a standardised sum of _r_\nindependent random matrices:\n\n1\n_Z_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd \ufffd _aib_ _[\u22a4]_ _i_ [+] _[ \u03f5][i]_ \ufffd _._ (6)\n\n_i_ =1\n\nUnder Assumption 1, the central limit theorem proves that _p_ ( _Z_ ) converges in distribution to a Gaussian\n_N_ (0 _, Im\u03c3_ 0 [4] _[, I][n][\u03c3]_ 0 [4][)][. Using this limiting distribution in place of the true distribution] _[ p]_ [(] _[Z]_ [)][, we obtain the]\nGaussian approximate score function:\n\n_S_ \u02c6( _Z_ ) = _\u2212_ [1] _Z._ (7)\n\n_\u03c3_ 0 [4]\n\nWe remark that EGGROLL is not wedded to any particular score function approximator and we derive and\nexplore a set of mean-field approximators in Appendix B as alternatives, however our experiments show that\nthe Gaussian approximator has the best overall performance on the set of tasks we evaluated on. We make\na Monte Carlo estimate of expectation in Eq. (5) with _N_ workers samples to optimise the parameters _\u00b5_ using\n(approximate) stochastic gradient ascent. This yields the Gaussian EGGROLL update:\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-6-0.png)\n\nHere we have absorbed the constants _\u03c3_ [1] [and] _\u03c3_ 10 [4] [into the tunable learning rate] _[ \u03b1][t]_ [. As each random matrix]\n\n_Ei,t_ in Eq. (8) has rank _r_ almost surely and the matrix is updated using a sum of _N_ worker such matrices,\nthe overall EGGROLL matrix parameter update has rank min( _Nr, m, n_ ) almost surely, meaning that the\noverall parameter update is not restricted to be low-rank. For all experiments in Section 6, _Nr >_ min( _, m, n_ ),\nmeaning EGGROLL parameter updates are full-rank.\n\n**4.3** **Hardware-Efficient EGGROLL Implementation**\n\nA key reason to use EGGROLL over standard ES is that large populations can be simulated in parallel on a\nGPU thanks to the low-rank perturbations. For the sake of exposition, we write equations from the perspective\nof a single worker, _i_, and explain in text how this corresponds to batched GPU operations.\n\nConsider the task of computing a batched forward pass over inputs _xi \u2208_ R _[d][in]_ for a linear layer with mean\nparameter _\u00b5 \u2208_ R _[d][out][\u00d7][d][in]_ . The standard forward pass is just a regular matrix multiplication, _x\u00b5_ _[T]_, since _\u00b5_ is\nconstant across all threads. However, naively applying ES by trying to compute _xi_ ( _\u00b5_ + _\u03c3Ei_ ) _[T]_ becomes a\nbatched matrix multiplication, which is inefficient on GPUs since every element of _\u00b5_ + _\u03c3Ei_ is only used in a\nsingle multiplication, yielding poor arithmetic intensity.\n\n7\n\nHowever, with EGGROLL we know that _xi_ ( _\u00b5_ + _\u03c3Ei_ ) = _xi\u00b5_ + ~~_\u221a_~~ _\u03c3r_ ( _xiBi_ ) _A_ _[T]_ _i_ [. In this context, the bulk of]\ncompute is spent on the efficient calculation of _xi\u00b5_ using regular matrix multiplication. Meanwhile, when\n_r_ = 1, _xiBi_ simply becomes an inexpensive batched vector-vector dot product to get a batch of scalars, which\nis then processed by a batched scalar-vector multiplication when multiplying by _A_ _[T]_ _i_ [. This decomposition]\nis key to efficient batched LoRA inference, such as those used by vLLM (Kwon et al., 2023), which why\nEGGROLL achieves the same speeds as batched LoRA inference systems.\n\nWe additionally optimize the update process by not explicitly materializing the individual _Ei_ in the computation\nof [\ufffd] _[N]_ _i_ =1 _[E][i][f][i]_ [, the key term in the Gaussian approximate score function. In particular, when the rank is 1, we]\nreconstruct _A \u2208_ R _[N]_ _[\u00d7][d][out]_ and _B \u2208_ R _[N]_ _[\u00d7][d][in]_ and calculate the expression as ( _A \u2299_ _f_ ) _B_ _[T]_, which is a simple\nmatrix multiplication."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a low-rank approximation for high-dimensional matrix perturbations in an Evolution Strategy (ES). Instead of sampling a full 'm x n' matrix 'E' for perturbations, EGGROLL constructs 'E' as '(1/sqrt(r)) * A * B^T', where 'A' is 'm x r' and 'B' is 'n x r'. This significantly reduces the number of independent parameters to '(m+n)*r'. The '1/sqrt(r)' scaling maintains a consistent variance for 'E'. To address the mathematical difficulty of directly working with low-rank matrices (which live on a zero-measure manifold), a 'conceptual tool' is introduced: a vanishingly small Gaussian noise 'epsilon' is added to 'E', forming 'Z = (1/sqrt(r))AB^T + epsilon'. This 'Z' now occupies the full 'm x n' Euclidean space, acquiring a well-defined, continuous density 'p(Z)' and a valid score function. Since 'p(Z)' is still complex, its score function is approximated. Leveraging the Central Limit Theorem (viewing 'Z' as a sum of 'r' independent random matrices), as 'r' approaches infinity, 'p(Z)' converges to a Gaussian distribution. The score function of a Gaussian is simple ('-Sigma^-1 * Z'), yielding the practical Gaussian approximate score function 'S_hat(Z) = (-1/sigma_0^4)Z', which is a linear scaling of 'Z'. The ES update rule, typically 'mu = mu + alpha * E_i * f_i', is adapted by using 'Z_i' and its Gaussian score function approximation. The parallelized worker structure (like a map-reduce pattern) computes 'Z_i' and 'f_i' independently, then aggregates 'Z_i * f_i' to update 'mu'.\n\n**Explanation:** Imagine you want to change a very complex image, which is like a giant grid of 'm' rows and 'n' columns, where each pixel has a color. In traditional Evolution Strategies (ES), to make a slight tweak to the image (let's call it 'E'), you'd randomly change *every single pixel* independently. This is like creating a 'full-rank' change, which is simple conceptually but involves 'm*n' numbers. If your image is huge (e.g., '1000x1000'), that's a million numbers to deal with for *each* tweak. This method, EGGROLL, says: 'What if we don't need to change every pixel independently to make a meaningful change?' Instead, they suggest changing the image by combining two much smaller strips of color, 'A' (an 'm' by 'r' strip) and 'B' (an 'n' by 'r' strip), and then multiplying them together ('A' times 'B's transpose) to make the 'm' by 'n' image change. This 'A*B^T' operation creates a 'low-rank' change. The key is that 'r' (the 'rank' or thickness of the strips) is much smaller than 'm' or 'n'. So, instead of 'm*n' numbers, you only deal with '(m+n)*r' numbers. This is a massive reduction! Think of it like a hash map where a complex state is represented by a much smaller key. Now, there's a subtle mathematical problem: when you only use 'A*B^T' to make changes, the resulting image changes are not 'free' to be anything. They are restricted to a specific subspace (a 'manifold'). This restriction makes it mathematically tricky to calculate the 'direction' to change 'A' and 'B' to make the image better (the 'score function'). To solve this, they introduce a clever conceptual trick: they add a *tiny* amount of random 'fuzz' ('epsilon') to the 'A*B^T' image. This fuzz is so small you can barely see it, but it mathematically 'lifts' the image out of that restricted subspace. Now, because of this tiny fuzz, the image 'Z = (1/sqrt(r))AB^T + epsilon' is no longer restricted, and you *can* use standard calculus to figure out the best direction to change it. It's like adding a tiny bit of noise to a signal to make it easier to process without corrupting the original message too much. Even with this fuzz, finding the *exact* 'direction' to change 'Z' is still complex. So, they use an approximation. They realize that if you combine many such 'A*B^T + epsilon' pieces (like a loop running 'r' times), the overall effect tends to look like a simple, well-behaved random 'blur' (a Gaussian distribution), thanks to the Central Limit Theorem. The 'direction' to change a simple blur is just proportional to the blur itself! So, they use this simple proportional rule for their 'score function approximation'. Finally, the whole process is like a distributed computing job. Many 'workers' (like separate threads or processes) independently generate their 'A' and 'B' strips, calculate their 'Z', and see how good the resulting image 'f(mu + sigma*Z)' is. They then send their 'Z' and 'f' values back to a central controller. The controller, using the approximated score function, aggregates all these 'Z*f' products to update the main 'mu' (the target image parameter) in the right direction. This parallelization, combined with the low-rank 'A' and 'B' (which are much smaller to send around than full 'E' matrices), makes the entire process very fast and hardware-efficient, especially on GPUs. The '1/sqrt(r)' scaling is like a normalization step to prevent the combined 'A*B^T' from becoming too large as 'r' increases, ensuring stable updates. The hardware efficiency section is a practical demonstration of how these low-rank operations map directly to highly optimized batched matrix operations on GPUs, similar to how techniques like LoRA work for large models."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ + 1\n\n48 D. Dimopoulos, et al.\n\nPacket loss:\n\n**begin**\n\n**9** _\ud835\udc52\ud835\udc5d\ud835\udc5c\ud835\udc50\u210e_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ \u2190\u2212 0"}, {"role": "assistant", "content": "**Mechanism:** The first line implements an atomic increment operation on a variable `cwnd_cnt`, acting as a simple counter. The subsequent lines introduce a conditional block triggered by 'Packet loss', within which an `epoch_start` variable is initialized to zero. This mechanism establishes a baseline or timestamp for a new operational phase.\n\n**Explanation:** The expression `cwnd_cnt \u2190\u2212 cwnd_cnt + 1` is a direct equivalent to `cwnd_cnt++` in C-like languages. It's a fundamental arithmetic operation to increment a counter, likely tracking a state or event related to the congestion window. The 'Packet loss:' label signifies an event handler or a specific code path taken when a network packet fails to reach its destination. Within this block, `epoch_start \u2190\u2212 0` is a variable initialization. It's akin to setting a `startTime` variable to zero at the beginning of a new 'try' or 'phase' after a failure event. This allows the system to measure durations or relative times from this new 'epoch' of recovery or re-evaluation, rather than from a global or continuously running clock. It's a critical state management primitive for reactive control systems."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc4f\ud835\udc64_\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc56_ \u2265 _\ud835\udc4f\ud835\udc64_\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc5f_ __\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61_ **and** _\ud835\udc4f\ud835\udc64_\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc56_ \u2264 _\ud835\udc4f\ud835\udc64_\ud835\udc62\ud835\udc5d\ud835\udc5d\ud835\udc52\ud835\udc5f_ __\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61_ **then**\n\n**28** _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ + + ;"}, {"role": "assistant", "content": "**Mechanism:** This snippet uses a conditional check (an 'if' statement) combined with a simple counter increment. It acts as a basic filter and tallying mechanism.\n\n**Explanation:** At its core, this is a standard `if` statement you'd find in any programming language. It takes an input, `bw_of_SFi` (bandwidth of a 'Service Function instance' or similar entity). It then applies two boundary checks: `bw_of_SFi` must be greater than or equal to a `lower_limit` AND less than or equal to an `upper_limit`. If both conditions are met (meaning the bandwidth falls within the specified range), a global counter, `number_of_SFs_in_btlneck`, is incremented. This effectively counts how many instances meet the criteria for being considered part of a 'bottleneck' based on their bandwidth characteristics. It's akin to iterating through a list (implicitly, given the context of a loop or streaming data) and applying a filter function, then summing the results that pass the filter."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**5**\n\n2.1 Two communities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\n2.2 More than two communities . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n2.3 Relation to previous works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17"}, {"role": "assistant", "content": "**Mechanism:** This section likely details a set of rules or an algorithm to group individual entities (like people, data points, or nodes in a network) into distinct 'communities' or clusters. The core mechanism would involve defining how 'similar' entities are, or how 'connected' they are, and then applying a process to draw boundaries that separate highly connected or similar groups from each other. 'Two communities' would be a simpler, perhaps binary, partitioning rule, while 'more than two communities' suggests an extension to identify multiple, finer-grained divisions based on the same or more complex similarity metrics.\n\n**Explanation:** Think of having a giant list of many items, like a HashMap where each item has certain properties or connections to other items. This paper explains a special kind of loop or recursion that goes through all these items. For 'two communities,' it might apply a simple if-else condition to decide if an item belongs to 'Group A' or 'Group B' based on a threshold. For 'more than two communities,' it would be like assigning an index to each item to put it into one of many array buckets, where the index is determined by more complex comparisons or aggregated connection scores. The 'mechanism' is the specific logic within that loop that determines which bucket an item falls into, often by calculating a 'score' for each possible group and picking the best fit."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Experimental Setup**\n\n**Implementation** . We implement TLT on top of VeRL [53]\nand utilizes Ray [37] for distributed execution. The Worker\nCoordinator is realized with a centralized controller that\n\nemploys ZeroMQ [17] messaging. The Adaptive Drafter\u2019s\nimplementation is based on training pipelines from EAGLE\nand trained with FSDP2 [44]. For asynchronous checkpointing, we leverage PyTorch DCP [45]. To further improve generation efficiency, we employ SGLang [70] as the rollout\nbackend, with implementing adaptive enabling of SD, drafter\nweight update and the BEG-MAB tuner following [55]. We\nadditionally use [68] as our model-free drafter.\n**Testbed** . We conduct experiments on a cluster of 8 NVIDIA\nDGX H100 [39] servers, totaling 64 GPUs. Each server is\nequipped with 8 NVIDIA H100 GPUs, 2 Intel Xeon Platinum\n8480C (112 cores) CPUs and 2TB memory. GPUs are interconnected to each other by 900GB/s NVLink, and inter-node\ncommunication is achieved via NVIDIA Mellanox 400Gb/s\nInfiniBand. To evaluate system\u2019s performance across heterogeneous hardware, we also conduct experiments on a\ndifferent cluster equipped with NVIDIA DGX A100 servers.\nUnless otherwise specified, experiments are conducted on\nH100 GPUs by default.\n**Models** . Following the training procedure introduced in\nDeepSeek-R1 [9], the reasoning RL process can begin either from a fine-tuned model or directly from a base model\nwithout additional fine-tuning. To demonstrate that TLT robustly accommodates different model architectures, scales,\nand training paradigms, we evaluate the following models:\n\n(1) _Qwen2.5-7B_ (Qwen2.5-7B): a popular base model;\n(2) _DeepSeek-R1-Distill-Qwen-7B_ (DeepSeek-7B): a distilled\nmodel exhibiting good initial reasoning capabilities;\n(3) _Qwen2.5-32B_ (Qwen-32B): a larger base model without\nany additional fine-tuning, as in [66];\n(4) _Llama-3.3-70B-Instruct_ (Llama-70B): a larger instructiontuned model to assess scalability.\n**Datasets** . For the primary RL training dataset, we use a\nsubset from Eurus-2-RL [8], a comprehensive dataset curated\nfor reasoning RL. This dataset contains mathematics and\ncoding problems equipped with verifiers (LaTeX answers and\n\ntest cases, respectively). The coding problems originate from\ncompetitive programming sources (e.g., CodeContests [23],\nCodeforces [7]), while the math problems range from high\nschool to olympiad-level difficulty [24]. For drafter training,\nwe use a subset from OpenThoughts2-1M [41] as the warmup dataset.\n**RL Settings** . We primarily follow the reasoning RL algorithm GRPO proposed by DeepSeek [9, 51]. Specifically, for\neach prompt, we set the temperature=0.9, with a maximum\ngeneration length of 32K tokens, consistent with common RL\ntraining settings. We apply TP= 2, 4, or 8 depending on model\nscale for the rollout engine. Additionally, all experiments utilize mixed-precision training with the Adam optimizer [19],\nwhere BF16 precision is employed during both model rollout\nand inference stages.\n**Baselines** . We consider the following baselines.\n\n(1) _Open-R1_ [10]: a popular RL training framework built\nupon TRL[59], integrating vLLM [21] for rollouts and\nDeepSpeed [47] for training. Currently, it only supports\nseparate model placement, requiring serving and training to be performed on distinct nodes.\n(2) _VeRL_ [53]: the state-of-the-art open-source RL training\nframework by ByteDance. It enables colocation of models on shared devices by utilizing GPU time-sharing.\n(3) _TLT-Base_ : Our base implementation with vanilla speculative decoding support. Specifically, we disable adaptive drafter and use the model-free drafter instead.\n\n**Metrics** . Following [53], we use token throughput (tokens/sec)\nfor end-to-end evaluation. This metric is calculated by dividing the total number of tokens in both prompts and responses\nwithin a global batch by the duration of a single RL step. We\naverage results over three training steps following an initial\nwarm-up step and use a trained draft model for evaluation.\n\n**6.2** **End-to-End Evaluation**\n\nWe evaluate TLT against popular RL training frameworks,\nincluding Open-R1 [10] and VeRL [53], across multiple GPU\nplatforms (NVIDIA H100 and A100) and various LLM scales.\nFigure 11 demonstrates that TLT consistently outperforms\nVeRL. Open-R1 consistently underperforms, primarily because it struggles to fully utilize all available GPUs concurrently and suffers from a tight coupling between its rollout\nand training batch size. Similar substantial gains are observed\non the A100 platform, highlighting its effectiveness across\ndifferent hardware generations. We also present results for\nTLT-Base, which utilizes a model-free drafter and yields good\nbenefits, demonstrating that the TLT framework provides\ncontinuous efficiency gains throughout the entire training\nprocess. These end-to-end performance gains stem directly\nfrom TLT\u2019s ability to mitigate the long-tail rollout bottleneck\nof reasoning RL training.\nMoreover, Figure 12 illustrates the average reward curves\nduring RL training for both VeRL and TLT using Qwen2.57B and Qwen2.5-32B models. It is evident that two curves\n\n9\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-0.png)\n\n**Figure 11. End-to-end Training Speed Evaluation.** The y-axis indicates the relative training throughput of each system\nrunning GRPO [51] RL algorithm. TLT achieves 1.7-2.1\u00d7 speedup over the state-of-the-art RL training system VeRL [53].\n\n0.6\n\n0.5\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-1.png)\n\n0.4\n\n0.3\n\n0.2\n\n20 40 60 80 100\nRL Step\n\n20 40 60 80 100\nRL Step\n\n**Figure 12. End-to-end Training Curves.** Average reward curves for VeRL and TLT using the Qwen2.5 7B and 32B models.\n\n**Table 1. Effect of topK for speculative decoding.** Results\nare benchmarked using Qwen-32B on H100 GPUs (TP=4),\nwith Draft_Depth=12 and Tokens_to_Verify=64.\n\nTopK 4 6 8 10 12 16\n\nAccept Length 8.29 8.66 8.67 8.67 8.60 8.42\n\nSpeedup 3.51\u00d7 **3.65** \u00d7 3.64\u00d7 3.64\u00d7 3.56\u00d7 3.47\u00d7\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-2.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-4.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-3.png)\n\n**Figure 13. Effect of hyperparameters for speculative**\n**decoding.** Measurements performed with Qwen-32B (TP=4).\n\noverlap closely, indicating that TLT preserves model quality.\nThis confirms that TLT\u2019s adaptive drafter and rollout engine\neffectively accelerate training without compromising the\nlearning dynamics of the underlying RL algorithm.\n\n**6.3** **Evaluation of Adaptive SD**\n\nIn this section, we provide in-depth analysis on the effectiveness of our design for adaptive speculative decoding.\n**Effect of Adaptive SD Strategy** . Tuning the SD configuration is crucial for achieving optimal speedups. Figure 13\nillustrates how Draft_Depth and Tokens_to_Verify influence speculative decoding performance with batch size = 1,\ntopK=8 and CUDA Graph enabled. For more stable accept\nlength in the grid search, we set temperature=0. Increasing\nthe draft depth generally raises the average accept length\n(a), though this benefit tapers off once the draft depth becomes sufficiently large. (b) reports the resulting speedups\nover the non-speculative baseline. This demonstrates that\n\nmaximizing accept length alone is insufficient; drafting parameters must be tuned to optimize real performance rather\nthan intermediate metrics.\n\nRegarding topK, we find that efficiency is relatively insensitive to the value used during drafting (Table 1). To balance\noverall efficiency with framework simplicity, we fix this hyperparameter for our MAB auto-tuner.\nMoreover, the optimal configurations for speculative decoding also vary with input batch size (Table 2). Although\nthe speedup decreases as batch size grows, the model still\nbenefits substantially from SD even at batch size 32. Another\nkey observation is that Tokens_to_Verify should be adjusted based on the batch size: larger batches achieve optimal\nperformance when fewer tokens are verified. These findings\nfurther demonstrate the effectiveness of our BEG MAB Selec\ntor in identifying appropriate configurations across dynamic\nrunning request numbers.\n**Case Study for Adaptive SD** . Figure 14 presents a case\nstudy of the rollout profile during an RL step with 128 requests using Qwen-32B on H100 GPUs. Instead of consistently applying SD throughout the entire rollout process,\nleading to potential slowdown during the early phase when\n\n10\n\n**Table 2. Effect of batch sizes on speculative decoding.**\nSpeedup numbers are benchmarked using Qwen-32B on\nH100 GPUs (TP=4), with Draft_Depth=10 and topK=8.\n\n**# Tokens to Verify**\n**Speedup**\n\n16 32 48 64\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-10-1.png)\n\nBatch Size = 1 3.22\u00d7 3.46\u00d7 3.56\u00d7 **3.62** \u00d7\n\n|Col1|Col2|Col3|\n|---|---|---|\n||Baseline<br>||\n||Rollout Ends<br>~~Adaptive SD (Ours)~~||\n||||\n|138<br>337<br>~~**SD starts**~~|138<br>337<br>~~**SD starts**~~|138<br>337<br>~~**SD starts**~~|\n||||\n\n**Figure 14. Rollout running-request profiling.** Example\nof processing 128 requests with and without adaptive decoding using Qwen-32B (TP=4).\n\nthe number of running requests is high, TLT switches to SD\nonly when the number of remaining requests drops below a\nthreshold (default 32), where SD becomes beneficial. Within\nthese SD-enabled regions, TLT further dynamically adapts\nSD configurations based on the current request count to\nmaximize throughput. Overall, TLT delivers a 2.44\u00d7 speedup\nover the baseline system without speculative decoding.\n**Bucketed CUDAGraph Capturing** . Preparing CUDAGraph\nfor multiple SD strategies can be memory-intensive. As\nshown in Table 3, naively capturing a separate graph for\neach of the four candidate strategies inflates memory usage from 7.81 GB to 30.39 GB. Our Bucketed CUDAGraph\ndesign addresses this problem by reducing graph memory\nconsumption to just 10.69 GB, a 2.8\u00d7 reduction compared\nto the naive method and only a marginal increase over the\nsingle static strategy, allowing the adaptive tuner to flexibly\nswitch between SD configurations for maximized efficiency.\n\n**6.4** **Evaluation of Spot Trainer**\n\n**Training Adaptive Drafter** . Figure 15 presents an example\ntraining curve illustrating the adaptive drafter\u2019s training\nprocess. After initial warm-up, the drafter\u2019s top-3 next-token\nprediction accuracy increases significantly. When the target\nmodel is updated after an RL step, the drafter\u2019s accuracy\ntemporarily dips due to the distribution shift caused by the\nupdate. However, this accuracy is rapidly recovered within\na few subsequent drafter training iterations, demonstrating\nthe effectiveness and robustness of our adaptive method.\n\n**Table 3. Bucketed CUDAGraph reduces memory foot-**\n**print.** Numbers measured using Llama-3-8B on H100 GPUs\n(TP=4). Search space includes 4 different strategies.\n\n**Method** **Memory Footprint**\n\nSingle Strategy 7.81 GB\n\n100\n\n# Drafter Training Steps\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy||\n|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy|\n||Target Model Training Step<br>Target Model Update|||\n|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|\n\n**Figure 15. Accuracy of the draft model during adaptive**\n**training.** The adaptive drafter\u2019s top-3 accuracy shows a\nconsistent upward trend. While target model updates cause\nminor dips, the drafter quickly adapts and recovers.\n\n**Effectiveness of Adaptive Drafter** . Table 4 highlights the\neffectiveness of adaptively training the draft model. With\nthis adaptive training mechanism, TLT consistently achieves\nhigher average accept lengths for the Target-R model across\nboth RL- ~~trainin~~ g tasks and downstream evaluations, demonstrating improved alignment and performance.\nFigure 16 further corroborates this finding, which shows\nthe acceptance probability at different token positions within\nthe drafted sequence. Due to the output distribution shift of\nthe target model and error accumulation, the vanilla draft\nmodel struggles to accurately predict tokens several steps\nahead, severely limiting the effective accept length. The adaptive drafter, however, sustains higher acceptance probabilities across these positions, showcasing its ability to mitigate\nevolving target model and maintain longer accept lengths.\n**Efficient Spot Trainer** . Spot Trainer achieves preemptible,\nhigh-throughput training with negligible runtime overheads.\nAmong its optimizations, Selective Asynchronous Checkpointing (Figure 17 (a)) facilitates the trainer\u2019s preemptible\ndesign without significant work loss. Compared to the vanilla\nsynchronous design, our approach reduces the checkpointing latency by 9.2 \u00d7 through both offloading the save process\nto a background thread and selectively dumping only the\ntrainable parameters of the draft model. Figure 17 (b) demonstrates the effectiveness of sequence packing. This technique\neliminates wasteful computation on padding tokens by concatenating variable-length sequences, improving training\nthroughput by 2.2\u00d7 over vanilla batching.\n**System Overhead Analysis** . We identify three primary\nsources of overhead in TLT: (1) Stage-transition overhead,\nintroduced by additional the drafter-weight update and optimizer offloading compared to VeRL [53]. This accounts for\nless than 1% of the RL-step duration due to the much smaller\n\n11\n\n**Table 4. Effectiveness of Adaptive Drafter.** Adaptive\ndrafter maintains alignment with the target model. TargetBase denotes Qwen2.5-7B; and Target-R denotes the model\nafter RL. Downstream indicates the collection of math, coding and reasoning domains in MTBench [69].\n\n**RL Training** **Downstream**\n\nTarget-Base Target-R Target-Base Target-R\n\nAccept Length 4.59 6.53 3.76 5.15\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-0.png)\n\n|280|ms|893|ms<br>32|Col5|Col6|\n|---|---|---|---|---|---|\n|**280**|**ms**||**92**<br>**.x**|||\n||||**.x**|||\n\n|893|ms|22x|Col4|\n|---|---|---|---|\n|** sam**|** ples/sec**|**.**||\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-2.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-1.png)\n\n**Figure 16. Token accept rate of different draft models** .\nOur adaptive draft model achieves prominently higher accept\nrate when predicting distant tokens in rollout scenario.\n\nmodel size. (2) SD switch overhead, incurred when switching from normal decoding to SD. Because the draft model is\ninitially inactive for large batch sizes, we perform a reprefill step to activate SD, which completes within 3 seconds.\n(3) Drafter-training coordination overhead, caused by occasional contention during spot-trainer execution. However,\nwe find that it is unnecessary to train the drafter every RL\nstep, performing once every 10 steps is sufficient to maintain accuracy. Overall, the performance gains of TLT far\noutweigh this overhead, yielding end-to-end speedups."}, {"role": "assistant", "content": "**Mechanism:** TLT accelerates Reinforcement Learning (RL) training for Large Language Models by mitigating the 'long-tail rollout bottleneck' through an adaptive speculative decoding (SD) mechanism and an efficient 'spot trainer'. The core idea of SD is to use a smaller, faster 'drafter' model to generate a sequence of predicted tokens. These predicted tokens are then 'verified' in parallel by the larger, more accurate 'target' model. If the target model confirms the predictions, multiple tokens are accepted in one step, effectively reducing the number of computationally expensive forward passes required by the large model. If a prediction is incorrect, the process reverts to the last correct token, and the target model generates the next token from scratch. The 'adaptive' aspect comes from the drafter model continuously being updated and aligned with the evolving target model through a separate, lightweight training loop (Spot Trainer). This ensures the drafter's predictions remain accurate even as the target model learns and shifts its output distribution. Furthermore, a multi-armed bandit (MAB) approach, like an intelligent lookup table, is used to dynamically select the optimal SD configuration (e.g., how many tokens to draft) based on real-time conditions (like the number of active requests), thereby maximizing throughput. System-level optimizations like Bucketed CUDAGraphs reduce GPU memory footprint for various SD strategies, and Selective Asynchronous Checkpointing allows the drafter's progress to be saved in the background, minimizing interruptions.\n\n**Explanation:** At its heart, TLT works by making intelligent guesses and then quickly checking those guesses, much like a CPU's branch prediction. When the big, slow-to-calculate language model (the 'target' model) needs to generate a lot of text, a smaller, faster 'drafter' model tries to predict a short sequence of tokens ahead of time. Think of it like a hash map where the drafter gives you a potential 'value' (a token sequence) based on a 'key' (the current text), and the target model then efficiently checks if that 'value' is actually correct. If many guesses are right, we 'fast-forward' past generating those tokens one by one. The drafter isn't static; it's constantly trained in a separate, lightweight background loop (the 'Spot Trainer') to keep its predictions aligned with the main target model as it learns, like a feedback control system continuously adjusting to keep an output stable. This training uses techniques like sequence packing, which is like grouping many small lists of varying lengths into one big list for efficient processing, avoiding wasted computation on padding. The system also dynamically picks the best guessing strategy using a 'BEG-MAB tuner', which is an algorithm that learns over time which settings (like 'Draft_Depth' or 'Tokens_to_Verify') yield the best 'speedup' outcome, similar to a greedy algorithm exploring options. Finally, to prevent system pauses, important tasks like saving the drafter's progress are done asynchronously in a separate thread, like a background process, ensuring the main learning task keeps running smoothly. This combination of intelligent guessing, continuous adaptation, and efficient system management is what drives the substantial performance gains."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nOver the past year, we have witnessed the emergence of\nreasoning LLMs, such as OpenAI-o1 [40], DeepSeek-R1 [9]\nand Gemini-2.5Pro [15], exhibiting remarkable capability improvements in mathematical reasoning, programming, and\nmultidisciplinary knowledge tasks [6]. A key driver behind\nthese improvements is the use of reinforcement learning\n(RL), which has become the standard approach for endowing LLMs with strong reasoning capabilities [9, 51, 56, 66].\nHowever, this RL approach faces efficiency challenges due to\nthe unique workload characteristics involved. Our analysis\nof self-collected traces (Figure 1) and production traces from\nByteDance (Figure 2) identifies the following key characteristics of reasoning RL process:\n\n\u2217 Equal Contribution. Part of the work was done while Shang Yang was\ninterning at NVIDIA.\n\n|Rollout|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|||Other|Other|Other|\n||||||\n||||||\n||||||\n\n|Rollou|t Inference&Train|Col3|Col4|Col5|Col6|TrainDrafter|Col8|Col9|Col10|Col11|Col12|Col13|Col14|AdaptiveSD|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||**Next Step**|**Next Step**|\n||||||||||||||||\n||**Idle**||||||||||||||\n||||||||||||||||\n||||||||||||||||\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-0-0.png)\n\n**(b)** Illustration of the time line of RL reasoning step w./wo. TLT.\n**Figure 1.** Observed issues of long-tail generation (rollout)\nand workload imbalance in reasoning RL. TLT system effectively addresses these challenges with adaptive drafter.\n\n**(1) Unbalanced Rollout and Training Time** . During RL,\nthe first and most time-consuming stage is _rollout_, where\nthe model generates numerous candidate responses. These\nresponses are then used in subsequent _inference_ and _training_\nstages to update the model. As shown in Figure 1 (a), the\nrollout phase consumes a disproportionately large fraction\n\n\u223c\n( 85%) of the total step time, becoming a primary bottleneck.\n**(2) Persistent Long-Tail Distribution** . A major source of\nRL training inefficiency arises from the _long-tail distribu-_\n_tion_ of rollout response lengths. As shown in Figure 1(a),\nalthough most generated sequences are relatively short, a\nsmall fraction extends to extreme lengths. Crucially, this inefficiency is not an occasional occurrence but a persistent pattern observed throughout long-term training, as evidenced\nby ByteDance\u2019s production traces (Figure 2). In most RL steps,\na few responses reach the maximum configured length, while\nthe majority remain substantially shorter. The pronounced\ngap between this maximum length and the 75th percentile\n(p75) underscores significant resource under-utilization.\n**(3) Substantial Time and Resource Demands** . Figure 2\nshows that reasoning RL training for a 32B model took 11\ndays to complete only 385 steps, even using 128 GPUs. Individual training steps averaged approximately 40 minutes,\nwhile periodic evaluations (conducted every 5 steps) required\nroughly 20 minutes each, demonstrating the process is extremely time and resource-intensive.\n\n1\n\nVeRL Ours\n\nTime Breakdown\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n3\n\n2\n\n1\n\n0\n\n0 10K 20K 30K\nRollout Response Length (tokens)\n\n**(a)** Distribution of response length and RL step time breakdown.\n\n_W1_\n\n_W2_\n\n_W3_\n\n_W4_\n\n_W5_\n\n_Time_ **Vanilla** **Ours**\n\nExisting systems [35, 52, 53, 60, 64, 65, 72] for RLHF (RL\nfrom Human Feedback) primarily focus their optimization\nefforts on managing multiple models, optimizing data transfer, and orchestrating device allocation across the different\nphases. However, they neglect tackling the rollout bottleneck,\nthereby remaining inefficient for reasoning RL tasks. Critically, reasoning rollouts are often over an order of magnitude\nlonger than typical RLHF outputs [42, 53, 72], giving reasoning RL fundamentally different workload characteristics and\ndemanding distinct system-level optimizations.\nWhile various acceleration techniques exist for LLM serving, many are ill-suited for the RL training context. Methods\nlike quantization [11, 30] and model sparsity [33, 63], despite\noffering speedups, are typically _lossy_, risking model accuracy\ndegradation and altering output probabilities. We identify\nSpeculative Decoding (SD) [5, 22] as a highly suitable approach. SD utilizes a lightweight draft model to generate\ntoken sequences speculatively, which are then verified in\nparallel by the main target model. SD is particularly wellsuited for RL training due to two primary merits: (1) _Mathe-_\n_matically Lossless_ . The output distribution remains identical\nto the target model\u2019s original distribution; (2) _Efficient for_\n_Long-Tail_ . SD enhances throughput by shifting the process\nfrom being memory-bound towards compute-bound, which\nis particularly effective for the long-tail phase of RL rollouts,\nwhere effective batch sizes are typically small.\nHowever, existing speculative decoding techniques [4, 14,\n16, 26, 36, 67] are designed for static inference scenarios,\nwhere the target model is fixed. Applying them within the\ndynamic reasoning RL training is fundamentally non-trivial,\npresenting significant challenges: (1) _Evolving Target Model_ :\nthe target model\u2019s weights are constantly updated during\nRL training, making the draft model progressively stale, severely undermining the effectiveness of SD. (2) _Draft Model_\n_Training Costs_ : Effective SD often relies on specialized draft\nmodels [2, 14, 25\u201327, 67], which require extra training to\nalign with the target model, introducing additional overhead\nand complexity for users. (3) _Scheduling Complexity_ : SD performance is sensitive to batch size and hyperparameters\n(e.g., draft depth). Reasoning RL rollouts, however, are characterized by dynamically fluctuating effective batch sizes\nas sequences complete at different times, necessitating an\neffective strategy selector for efficient SD deployment.\nTo address these challenges, we introduce TLT, an efficient\nsystem for reasoning RL training featuring adaptive speculative decoding. TLT aims to mitigate the long-tail rollout\nbottleneck while guaranteeing mathematical losslessness.\nThe core design of TLT derives from the following insights:\nFirst, _Exploiting Rollout Bubbles_ . The characteristically long\nduration of RL rollouts provides ample time to utilize GPU\nresources that progressively become available due to the\nlong-tail nature. Resources freed as sequences complete can\nthus be repurposed for other tasks, such as draft model training, without additional costs. Second, _Non-Blocking Drafter_\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-1-0.png)\n\n5K\n\n0\n\n0 50 100 150 200 250 300 350\nRL Training Steps (11 days over 128 GPUs)\n\n**Figure 2. RL Training trace from ByteDance** [3], based\non the Qwen2.5-32B model [46] and executed on H20 96GB\nGPUs. \"p75\" denotes the 75th percentile and more granular\npercentile data were not provided in the original source.\n\n_Training_ . Draft model training can be decoupled from full\nrollout completion; training asynchronously on partial or\nreadily available data allows its computation to be effectively\noverlapped with ongoing rollouts.\nIncorporating aforementioned insights, we build TLT with\nmultiple system optimizations: (1) Adaptive Drafter (\u00a74): We\nadopt a lightweight draft model continuously adapted via\nour spot trainer, innovatively addressing the evolving target model challenge arising from RL training. This trainer\nleverages idle GPU resources during long-tail rollouts for opportunistic, preemptible drafter updates, ensuring alignment\nwith the evolving target model without adding overhead.\n(2) Adaptive Rollout Engine (\u00a75): TLT maintains a memoryefficient pool of pre-captured CUDAGraphs and leverages the\nBEG-MAB tuner to adaptively select suitable SD strategies\nfor each input batch. It also supports model-free speculative\ndecoding for early rollout steps. Figure 1(b) presents an intuitive illustration of the TLT workflow, where the system\nautomatically leverages idle resources (e.g., workers W3-W5)\nfor opportunistic draft model training (blue blocks), counteracting performance dips caused by target model updating\nwithout additional costs. Meanwhile, TLT adaptively enables\nspeculative decoding (blue hatched blocks) during these periods of resource under-utilization for better efficiency.\nBy synergistically combining an adaptive draft model with\ncoordinated scheduling, TLT effectively mitigates the longtail issue inherent to RL training. We evaluated TLT on various model architectures and real-world datasets. Experiments demonstrate that TLT significantly accelerates endto-end training throughput, while preserving model output\nquality and minimizing resource waste. Furthermore, the\nprocess yields an effective draft model suitable for future\ndeployment as a free byproduct."}, {"role": "assistant", "content": "**Mechanism:** TLT addresses the core inefficiency of RL training, which is the disproportionate time spent in the 'rollout' phase and the resource under-utilization caused by the 'long-tail distribution' of response lengths. It does this by leveraging idle GPU cycles that appear when shorter sequences complete, leaving resources free while longer sequences are still generating. These 'rollout bubbles' are opportunistically filled by a 'spot trainer' that continuously trains and updates a lightweight draft model. This draft model is then used for Speculative Decoding (SD) in the subsequent rollouts. SD works by having the small, fast draft model propose several tokens at once, which the larger, slower target model then verifies in parallel. This is mathematically lossless, meaning the final output is identical to what the target model would have produced on its own, but much faster if the draft model's predictions are often correct. The 'adaptive' nature means the draft model stays relevant even as the target model's weights change during RL training, and the rollout engine dynamically selects the best SD strategy based on current batch characteristics.\n\n**Explanation:** Think of RL training as a multi-stage pipeline. The biggest bottleneck is the 'rollout' where the model generates many sequences. Due to varying lengths (a 'long-tail' where most are short, but a few are extremely long), GPUs often sit idle after processing short sequences, waiting for the longest ones to finish. TLT turns this idle time into productive work. It's like having a dedicated background thread that monitors CPU utilization. When cores are idle, this thread starts a low-priority task (training the draft model). This draft model is a smaller, faster approximation of the main model, similar to a cache that needs constant refreshing. As the main model learns (its weights change), the draft model is continually updated using these otherwise wasted GPU cycles, ensuring it remains 'fresh.' Then, for subsequent rollouts, instead of the main model generating one token at a time, it uses this fresh draft model like a 'lookahead buffer.' The draft model quickly proposes a short sequence of tokens. The main model, acting like a parallel checker, can verify these proposed tokens all at once. If they're good, it's a massive speedup; if not, it falls back to single-token generation but without any correctness penalty. This mechanism effectively reduces the effective inference time, especially for those long-tail sequences that previously caused substantial idle time. The adaptive part means it dynamically decides when and how to apply this speculative decoding, like a smart scheduler optimizing resource allocation based on real-time workload."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe AMD Versal family represents a new generation of adaptive computing platforms, integrating\n\na heterogeneous System-on-Chip (SoC) architecture. Each device combines a real-time processing\n\nunit (RT), an application processing unit (APU), programmable logic (PL), and a novel acceleration\n\nfabric known as the _AI Engine_ (AIE). The AI Engine is composed of a two-dimensional array of\n\n400 RISC-V vector processors, interconnected through a high-bandwidth network-on-chip. Data\n\nexchange between the AIE and the PL occurs via 39 specialized interface tiles that employ the\n\nAXI4-Stream protocol. These interfaces convert 128-bit data streams from the PL domain to 32-bit\n\nstreams suitable for the AI Engine domain. Given that the AI Engine operates at a maximum\n\nclock frequency of 1.25 GHz, achieving peak throughput requires the PL domain to be clocked at\n\none-quarter of this frequency (312.5 MHz) to maintain synchronization.\n\nEach AI Engine tile features a vector processor coupled with 32 KB of local memory. The vector\n\nunit supports both integer and floating-point arithmetic, using two distinct execution pipelines. It\n\ncan perform up to two 128-bit load operations and one store operation per clock cycle. To exploit\n\nthis vectorized architecture, developers can use C++ intrinsics or, more conveniently, the high-level\n\nAPIs provided in recent AMD toolchains [10].\n\nLocal memory within a tile typically serves as stack and heap storage, as well as a ping\npong buffer for efficient double-buffered data transfers. A particularly useful feature of the AIE\n\narchitecture is the support for _runtime parameters_, which allow values to be dynamically loaded\n\ninto the memory banks of specific AI Engine tiles by the processing system (PS).\n\n\u2013 3 \u2013\n\nAI Engine tiles can communicate with one another through four principal mechanisms, two\n\nlocal - Cascade Streams and Input/Output Buffers, and two non-local - AXI4-Streams and Packet\n\nStreams. We will use the two latter.\n\nOne of the main advantages of the AI Engine over traditional programmable logic is its native\n\nsupport for floating-point arithmetic, which eliminates the need for quantization when deploying\n\nAI models. In addition, AIE computation is deterministic and does not require timing closure, a\n\ncommon challenge in FPGA design."}, {"role": "assistant", "content": "**Mechanism:** The AI Engine achieves high-throughput, low-latency acceleration for data-parallel tasks, common in AI inference and signal processing, by deploying a two-dimensional mesh of dedicated vector processors. These processors operate in a SIMD (Single Instruction, Multiple Data)-like fashion, supported by fast local memory (double-buffered for continuous data flow) and a high-bandwidth on-chip network, effectively creating a specialized compute fabric that avoids the general-purpose overhead of CPUs and the timing complexities of traditional FPGAs.\n\n**Explanation:** Think of the AI Engine as a grid of 400 small, specialized calculators, each with its own tiny scratchpad (32KB local memory). When you want to multiply a long list of numbers, instead of one calculator doing it item by item (like a single loop in a program), you give a chunk of the list to each of the 400 calculators, and they all work simultaneously. The 'vector unit' means each calculator can do multiple math operations on a small group of numbers at once. The 'ping-pong buffer' is a programming pattern where you use two memory regions like two buckets: while you're emptying data from one bucket (processing it), you're filling the other with new data. This hides the time it takes to get new data, making processing continuous. The data exchange between the Programmable Logic (PL) and the AI Engine is like having different conveyor belt widths: the PL uses a wide belt (128-bit), but the AI Engine uses a narrower one (32-bit). Interface tiles act as a conversion station, efficiently repacking items and ensuring they arrive at the correct pace, similar to a clock domain crossing FIFO. 'Runtime parameters' are akin to global variables that can be updated on the fly by the main processing system without requiring the entire system to be reconfigured or rebooted, allowing for dynamic changes to algorithms or coefficients. The native floating-point support means these specialized calculators directly understand 'decimal' numbers, avoiding the need for complex conversion tricks (quantization) and ensuring predictable timing, which is a major design headache ('timing closure') with generic reconfigurable logic."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this paper, we introduce EGGROLL, a powerful method for blackbox optimisation that scales evolutionary\nstrategies to billion-parameter models and beyond using low-rank search matrices. Our experiments demonstrate that EGGROLL is effective with rank as small as _r_ = 1, which represents substantial computational and\nmemory savings for negligible decrease in performance when compared to the full-rank ES update. Empirically,\nEGGROLL delivers large speedups over na\u00efve ES in tabula rasa and multi-agent RL, and can power end-to-end\ntraining pipelines for large language models. Our theoretical analysis reveals that the low-rank EGGROLL\nupdate quickly converges with rank _r_, however further theoretical analysis is needed to explain the success of\nour method when _r_ = 1.\n\nLooking forward, we are working on applying EGGROLL for other problems beyond the reach of modern\ngradient-based techniques. In particular, EGGROLL can enable the training of large scale end-to-end neurosymbolic systems (Sarker et al., 2021) which have nondifferentiable components. For instance, we can\ntrain neural networks that directly interface with symbolic modules for specialized functions, like memory\nor calculations. We can also optimize end-to-end systems of language models, training them to be aware of\ninference-time harnesses and interactions with other agents in complex systems.\n\n**Acknowledgements**\n\nCompute for this project is graciously provided by the Isambard-AI National AI Research Resource, under\nthe projects \u201cFLAIR 2025 Moonshot Projects\u201d and \u201cRobustness via Self-Play RL.\u201d Some experiments also\n[used compute generously given by JASMIN, the UK\u2019s collaborative data analysis environment (https:](https://www.jasmin.ac.uk)\n[//www.jasmin.ac.uk).](https://www.jasmin.ac.uk)\n\n11\n\nBidipta Sarkar is supported by the Clarendon Fund Scholarship in partnership with a Department of Engineering\nScience Studentship for his Oxford DPhil. Mattie Fellows is funded by a generous grant from the UKRI\nEngineering and Physical Sciences Research Council EP/Y028481/1. Jakob Nicolaus Foerster is partially\nfunded by the UKRI grant EP/Y028481/1 (originally selected for funding by the ERC). Jakob Nicolaus Foerster\nis also supported by the JPMC Research Award and the Amazon Research Award. Juan Agustin Duque is\nsupported by the St-Pierre-Larochelle Scholarship at the University of Montreal and by Aaron Courville\u2019s\nCIFAR AI Chair in Representations that Generalize Systematically. Lukas Seier is supported by the Intelligent\nEarth CDT with funding from the UKRI grant number EP/Y030907/1.\n\n**References**\n\nShun-ichi Amari. Natural gradient works efficiently in learning. _Neural Computation_, 10(2):251\u2013276, 1998.\ndoi: 10.1162/089976698300017746.\n\nA. B. Basset. _A Treatise on Hydrodynamics: with numerous examples_, volume 2. Deighton, Bell, and Co.,\nCambridge, UK, 1892.\n\nYoshua Bengio, R\u00e9jean Ducharme, and Pascal Vincent. A neural probabilistic language model. In T. Leen,\nT. Dietterich, and V. Tresp (eds.), _Advances in Neural Information Processing Systems_, volume 13.\n[MIT Press, 2000. URL https://proceedings.neurips.cc/paper_files/paper/2000/](https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf)\n[file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf)\n\nHans-Georg Beyer. Toward a theory of evolution strategies: Self-adaptation. _Evolutionary Computation_, 3:\n[311\u2013347, 1995. URL https://api.semanticscholar.org/CorpusID:17416734.](https://api.semanticscholar.org/CorpusID:17416734)\n\nHans-Georg Beyer and Hans-Paul Schwefel. Evolution strategies \u2013a comprehensive introduction. _Natural_\n_Computing_, 1(1):3\u201352, 2002.\n\nR. N. Bhattacharya and R. Ranga Rao. _Normal approximation and asymptotic expansions_ . Wiley series in\nprobability and mathematical statistics. Wiley, New York, 1976. ISBN 047107201X.\n\nCl\u00e9ment Bonnet, Daniel Luo, Donal Byrne, Shikha Surana, Sasha Abramowitz, Paul Duckworth, Vincent\nCoyette, Laurence I. Midgley, Elshadai Tegegn, Tristan Kalloniatis, Omayma Mahjoub, Matthew Macfarlane,\nAndries P. Smit, Nathan Grinsztajn, Raphael Boige, Cemlyn N. Waters, Mohamed A. Mimouni, Ulrich\nA. Mbou Sob, Ruan de Kock, Siddarth Singh, Daniel Furelos-Blanco, Victor Le, Arnu Pretorius, and\nAlexandre Laterre. Jumanji: a diverse suite of scalable reinforcement learning environments in jax, 2024.\n[URL https://arxiv.org/abs/2306.09884.](https://arxiv.org/abs/2306.09884)\n\nJames Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George\nNecula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable\n[transformations of Python+NumPy programs, 2018. URL http://github.com/jax-ml/jax.](http://github.com/jax-ml/jax)\n\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,\nChristopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models\n[are few-shot learners, 2020. URL https://arxiv.org/abs/2005.14165.](https://arxiv.org/abs/2005.14165)\n\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, ..., Barret Zoph, Liam Fedus, and ...\n(full list). Palm: Scaling language modeling with pathways. _J. Mach. Learn. Res._, 24(1144), 2023. URL\n[https://jmlr.org/papers/volume24/22-1144/22-1144.pdf.](https://jmlr.org/papers/volume24/22-1144/22-1144.pdf)\n\nA. P. Dawid. Some matrix-variate distribution theory: Notational considerations and a bayesian application.\n_Biometrika_, 68(1):265\u2013274, 1981. ISSN 0006-3444.\n\n12\n\nNan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun,\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P. Bosma, Zongwei Zhou,\nTao Wang, Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathleen Meier-Hellstern, Toju\nDuke, Lucas Dixon, Kun Zhang, Quoc Le, Yonghui Wu, Zhifeng Chen, and Claire Cui. Glam: Efficient\nscaling of language models with mixture-of-experts. In _Proceedings of the 39th International Conference_\n_on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pp. 5547\u20135569, Jul 2022.\n[URL https://proceedings.mlr.press/v162/du22c.html.](https://proceedings.mlr.press/v162/du22c.html)\n\nRichard Durrett. _Probability: Theory and Examples_ . Cambridge University Press, Cambridge, UK, 4th edition,\n2010.\n\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: scaling to trillion parameter models\nwith simple and efficient sparsity. _J. Mach. Learn. Res._, 23(1):1\u201339, January 2022. ISSN 1532-4435. URL\n[https://jmlr.org/papers/volume23/21-0998/21-0998.pdf.](https://jmlr.org/papers/volume23/21-0998/21-0998.pdf)\n\n[Jakob Nicolaus Foerster. Nonlinear computation in deep linear networks, sep 2017. URL https://blog.](https://blog.openai.com/nonlinear-computation-in-linear-networks/)\n[openai.com/nonlinear-computation-in-linear-networks/. Accessed: 2025-11-20.](https://blog.openai.com/nonlinear-computation-in-linear-networks/)\n\nGerald B. Folland. _Real Analysis: Modern Techniques and Their Applications_ . John Wiley & Sons, New York,\n2nd edition, 1999. See Theorem 8.22 (Riemann\u2013Lebesgue Lemma).\n\nC. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem. Brax \u2013 a\n[differentiable physics engine for large scale rigid body simulation, 2021. URL https://arxiv.org/](https://arxiv.org/abs/2106.13281)\n[abs/2106.13281.](https://arxiv.org/abs/2106.13281)\n\nAlexander D. Goldie, Chris Lu, Matthew T. Jackson, Shimon Whiteson, and Jakob N. Foerster. Can Learned\nOptimization Make Reinforcement Learning Less Difficult? In _Advances in Neural Information Processing_\n_Systems_, volume 37, pp. 5454\u20135497, 2024.\n\nAlexander David Goldie, Zilin Wang, Jaron Cohen, Jakob Nicolaus Foerster, and Shimon Whiteson. How\n[Should We Meta-Learn Reinforcement Learning Algorithms? May 2025. URL https://openreview.](https://openreview.net/forum?id=jKzQ6af2DU)\n[net/forum?id=jKzQ6af2DU.](https://openreview.net/forum?id=jKzQ6af2DU)\n\nIan Goodfellow, Yoshua Bengio, and Aaron Courville. _Deep Learning_ [. MIT Press, 2016. http://www.](http://www.deeplearningbook.org)\n[deeplearningbook.org.](http://www.deeplearningbook.org)\n\nIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes,\nN. Lawrence, and K.Q. Weinberger (eds.), _Advances in Neural Information Processing Systems_, volume 27. Curran Associates, Inc., 2014. [URL https://proceedings.neurips.cc/paper_](https://proceedings.neurips.cc/paper_files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf)\n[files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf)\n\nI. S. (Izrail Solomonovich) Gradshte\u02d8\u0131n, I. M. (Iosif Moiseevich) Ryzhik, Daniel Zwillinger, Victor Moll, and\nInc Scripta Technica. _Table of integrals, series, and products_ . Academic Press, San Diego ; Tokyo, 8 edition,\n2015. ISBN 0123849330.\n\nG R Grimmett and D R Stirzaker. Probability and random processes. _Journal of the Royal Statistical Society._\n_Series A, Statistics in society_, 156(3):503\u2013503, 1993. ISSN 0964-1998.\n\nPeter Hall. _The bootstrap and Edgeworth expansion_ . Springer series in statistics. Springer-Verlag, New York,\n1992. ISBN 9780387945088.\n\n[Nikolaus Hansen. The cma evolution strategy: A tutorial, 2023. URL https://arxiv.org/abs/1604.](https://arxiv.org/abs/1604.00772)\n\n[00772.](https://arxiv.org/abs/1604.00772)\n\nNikolaus Hansen and Andreas Ostermeier. Completely Derandomized Self-Adaptation in Evolution Strategies.\n_Evolutionary Computation_, 9(2):159\u2013195, June 2001. ISSN 1063-6560. doi: 10.1162/106365601750190398.\n[URL https://ieeexplore.ieee.org/document/6790628.](https://ieeexplore.ieee.org/document/6790628)\n\n13\n\nJoel Heck and Fathi M. Salem. Simplified minimal gated unit variations for recurrent neural networks, 2017.\n[URL https://arxiv.org/abs/1701.03452.](https://arxiv.org/abs/1701.03452)\n\nSepp Hochreiter and J\u00fcrgen Schmidhuber. Lstm can solve hard long time lag problems. In M.C. Mozer,\nM. Jordan, and T. Petsche (eds.), _Advances in Neural Information Processing Systems_, volume 9.\n[MIT Press, 1996. URL https://proceedings.neurips.cc/paper_files/paper/1996/](https://proceedings.neurips.cc/paper_files/paper/1996/file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf)\n[file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/1996/file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf)\n\nMark Horowitz. 1.1 computing\u2019s energy problem (and what we can do about it). In _2014 IEEE International_\n_Solid-State Circuits Conference Digest of Technical Papers (ISSCC)_, pp. 10\u201314, 2014. doi: 10.1109/ISSCC.\n2014.6757323.\n\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. Lora: Low-rank adaptation of large language models. In _ICLR_ . OpenReview.net, 2022.\n\nMax Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi,\nOriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, Chrisantha Fernando, and Koray Kavukcuoglu.\n[Population Based Training of Neural Networks, November 2017. URL http://arxiv.org/abs/](http://arxiv.org/abs/1711.09846)\n[1711.09846. arXiv:1711.09846 [cs].](http://arxiv.org/abs/1711.09846)\n\nFeihu Jin, Yifan Liu, and Ying Tan. Derivative-free optimization for low-rank adaptation in large language\nmodels. _IEEE/ACM Trans. Audio, Speech and Lang. Proc._, 32:4607\u20134616, October 2024. ISSN 2329-9290.\n[doi: 10.1109/TASLP.2024.3477330. URL https://doi.org/10.1109/TASLP.2024.3477330.](https://doi.org/10.1109/TASLP.2024.3477330)\n\nJean Kaddour. The minipile challenge for data-efficient language models. _arXiv preprint arXiv:2304.08442_,\n2023.\n\nSham M Kakade. A natural policy gradient. In T. Dietterich, S. Becker, and Z. Ghahramani (eds.), _Advances in Neural Information Processing Systems_, volume 14. MIT Press,\n2001. [URL https://proceedings.neurips.cc/paper_files/paper/2001/file/](https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)\n[4b86abe48d358ecf194c56c69108433e-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)\n\nDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and Yann LeCun\n(eds.), _2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April_\n_14-16, 2014, Conference Track Proceedings_ [, 2014. URL http://arxiv.org/abs/1312.6114.](http://arxiv.org/abs/1312.6114)\n\nDaria Korotyshova, Boris Shaposhnikov, Alexey Malakhov, Alexey Khokhulin, Nikita Surnachev, Kirill\nOvcharenko, George Bredis, Alexey Gorbatovski, Viacheslav Sinii, and Daniil Gavrilov. Essa: Evolutionary\n[strategies for scalable alignment, 2025. URL https://arxiv.org/abs/2507.04453.](https://arxiv.org/abs/2507.04453)\n\nJohn R. Koza. Genetic programming as a means for programming computers by natural selection. _Statistics_\n_and Computing_ [, 4(2):87\u2013112, June 1994. ISSN 1573-1375. doi: 10.1007/BF00175355. URL https:](https://doi.org/10.1007/BF00175355)\n[//doi.org/10.1007/BF00175355.](https://doi.org/10.1007/BF00175355)\n\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep\nconvolutional neural networks. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger\n(eds.), _Advances in Neural Information Processing Systems_, volume 25. Curran Associates,\n[Inc., 2012. URL https://proceedings.neurips.cc/paper_files/paper/2012/file/](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n[c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with\npagedattention. In _Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles_,\n2023.\n\nRobert Tjarko Lange, Tom Schaul, Yutian Chen, Tom Zahavy, Valentin Dallibard, Chris Lu, Satinder Singh,\nand Sebastian Flennerhag. Discovering Evolution Strategies via Meta-Black-Box Optimization, March\n[2023. URL http://arxiv.org/abs/2211.11260. arXiv:2211.11260 [cs].](http://arxiv.org/abs/2211.11260)\n\n14\n\nPierre-Simon Laplace. M\u00e9moire sur les int\u00e9grales d\u00e9finies et leur application aux probabilit\u00e9s, et sp\u00e9cialement\n\u00e0 la recherche du milieu qu\u2019il faut choisir entre les r\u00e9sultats des observations. _M\u00e9moires de la Classe des_\n_Sciences Math\u00e9matiques et Physiques de l\u2019Institut Imp\u00e9rial de France,_ 1 [re] s\u00e9rie, 11(1 [re] partie):297\u2013347,\n1811.\n\nV. P. Leonov and A. N. Shiryaev. On a method of calculation of semi-invariants. _Theory of Probability and Its_\n_Applications_ [, 4(3):342\u2013355, 1959. URL https://www.mathnet.ru/eng/tvp4894.](https://www.mathnet.ru/eng/tvp4894)\n\nOscar Li, James Harrison, Jascha Sohl-Dickstein, Virginia Smith, and Luke Metz. Variance-reduced gradient\nestimation via noise-reuse in online evolution strategies. In _Thirty-seventh Conference on Neural Information_\n_Processing Systems_, 2023a.\n\nOscar Li, James Harrison, Jascha Sohl-Dickstein, Virginia Smith, and Luke Metz. Noise-Reuse in Online\n[Evolution Strategies, April 2023b. URL http://arxiv.org/abs/2304.12180. arXiv:2304.12180](http://arxiv.org/abs/2304.12180)\n\n[cs].\n\n[Jarek Liesen, Chris Lu, and Robert Lange. rejax, 2024. URL https://github.com/keraJLi/rejax.](https://github.com/keraJLi/rejax)\n\nRyan Lowe, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor Mordatch. Multi-agent actor-critic for\nmixed cooperative-competitive environments. _Advances in neural information processing systems_, 30, 2017.\n\nChris Lu, Jakub Kuba, Alistair Letcher, Luke Metz, Christian Schroeder de Witt, and Jakob Foerster. Discovered policy optimisation. _Advances in Neural Information Processing Systems_, 35:16455\u201316468, 2022.\n\nH. M. Macdonald. Zeroes of the bessel functions. _Proceedings of the London Mathematical Society_, 30:\n165\u2013179, 1899. doi: 10.1112/plms/s1-30.1.165.\n\nSadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen, and Sanjeev Arora.\nFine-tuning language models with just forward passes. In _Proceedings of the 37th International Conference_\n_on Neural Information Processing Systems_, NIPS \u201923, Red Hook, NY, USA, 2023. Curran Associates Inc.\n\nMichael Matthews, Michael Beukman, Benjamin Ellis, Mikayel Samvelyan, Matthew Jackson, Samuel\nCoward, and Jakob Foerster. Craftax: A lightning-fast benchmark for open-ended reinforcement learning.\n_arXiv preprint arXiv:2402.16801_, 2024.\n\nMichael T. Matthews, Michael Beukman, Chris Lu, and Jakob Nicolaus Foerster. Kinetix: Investigating\nthe training of general agents through open-ended physics-based control tasks. In _ICLR_, 2025. URL\n[https://openreview.net/forum?id=zCxGCdzreM.](https://openreview.net/forum?id=zCxGCdzreM)\n\n[P. McCullagh. Cumulants (lecture notes). Lecture notes, University of Chicago (pdf), 2013. URL https:](https://www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf)\n[//www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf.](https://www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf)\n\nPeter McCullagh. _Tensor Methods in Statistics_ . Monographs on Statistics and Applied Probability. Chapman\n[& Hall / CRC, London, 1987. URL https://www.stat.uchicago.edu/~pmcc/tensorbook/](https://www.stat.uchicago.edu/~pmcc/tensorbook/DoverEdition.pdf)\n[DoverEdition.pdf. Discusses multivariate moments and cumulants (cumulant tensors).](https://www.stat.uchicago.edu/~pmcc/tensorbook/DoverEdition.pdf)\n\nWilliam Merrill, Jackson Petty, and Ashish Sabharwal. The illusion of state in state-space models. In\nRuslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and\nFelix Berkenkamp (eds.), _Proceedings of the 41st International Conference on Machine Learning_, volume\n235 of _Proceedings of Machine Learning Research_, pp. 35492\u201335506. PMLR, 21\u201327 Jul 2024. URL\n[https://proceedings.mlr.press/v235/merrill24a.html.](https://proceedings.mlr.press/v235/merrill24a.html)\n\nLuke Metz, James Harrison, C. Daniel Freeman, Amil Merchant, Lucas Beyer, James Bradbury, Naman\nAgrawal, Ben Poole, Igor Mordatch, Adam Roberts, and Jascha Sohl-Dickstein. VeLO: Training Versatile\n[Learned Optimizers by Scaling Up, November 2022. URL http://arxiv.org/abs/2211.09760.](http://arxiv.org/abs/2211.09760)\narXiv:2211.09760 [cs, math, stat].\n\nJack Parker-Holder, Vu Nguyen, and Stephen Roberts. Provably Efficient Online Hyperparameter Opti[mization with Population-Based Bandits, June 2021. URL http://arxiv.org/abs/2002.02518.](http://arxiv.org/abs/2002.02518)\narXiv:2002.02518 [cs].\n\n15\n\nBo Peng, Ruichong Zhang, Daniel Goldstein, Eric Alcaide, Xingjian Du, Haowen Hou, Jiaju Lin, Jiaxing\nLiu, Janna Lu, William Merrill, Guangyu Song, Kaifeng Tan, Saiteja Utpala, Nathan Wilce, Johan S. Wind,\nTianyi Wu, Daniel Wuttke, and Christian Zhou-Zheng. Rwkv-7 \"goose\" with expressive dynamic state\n[evolution, 2025. URL https://arxiv.org/abs/2503.14456.](https://arxiv.org/abs/2503.14456)\n\n[K. B. Petersen and M. S. Pedersen. The matrix cookbook, October 2008. URL http://www2.imm.dtu.](http://www2.imm.dtu.dk/pubdb/p.php?3274)\n[dk/pubdb/p.php?3274. Version 20081110.](http://www2.imm.dtu.dk/pubdb/p.php?3274)\n\nEduardo Pignatelli, Jarek Liesen, Robert Tjarko Lange, Chris Lu, Pablo Samuel Castro, and Laura Toni. Navix:\n[Scaling minigrid environments with jax, 2024. URL https://arxiv.org/abs/2407.19396.](https://arxiv.org/abs/2407.19396)\n\nXin Qiu, Yulu Gan, Conor F. Hayes, Qiyao Liang, Elliot Meyerson, Babak Hodjat, and Risto Miikkulainen.\n[Evolution strategies at scale: Llm fine-tuning beyond reinforcement learning, 2025. URL https://](https://arxiv.org/abs/2509.24372)\n[arxiv.org/abs/2509.24372.](https://arxiv.org/abs/2509.24372)\n\nI. Rechenberg. Evolutionsstrategien. In Berthold Schneider and Ulrich Ranft (eds.), _Simulationsmethoden_\n_in der Medizin und Biologie_, pp. 83\u2013114, Berlin, Heidelberg, 1978. Springer Berlin Heidelberg. ISBN\n978-3-642-81283-5.\n\nV. K. Rohatgi. _An introduction to probability theory and mathematical statistics_ . Wiley series in probability\nand mathematical statistics. Wiley, New York, 1976. ISBN 0471731358.\n\nFrank. Rosenblatt. _Principles of neurodynamics : perceptrons and the theory of brain mechanisms._ Spartan\nBooks, Washington, 1962.\n\nAlexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson,\nTimon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, et al. Jaxmarl: Multi-agent rl\nenvironments in jax. _arXiv preprint arXiv:2311.10090_, 2023.\n\nTim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable\n[alternative to reinforcement learning, 2017. URL https://arxiv.org/abs/1703.03864.](https://arxiv.org/abs/1703.03864)\n\nJohn K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw. Parallel random numbers: As easy as 1, 2,\n3. In _SC \u201911: Proceedings of 2011 International Conference for High Performance Computing, Networking,_\n_Storage and Analysis_, pp. 1\u201312, 2011. doi: 10.1145/2063384.2063405.\n\nMd Kamruzzaman Sarker, Lu Zhou, Aaron Eberhart, and Pascal Hitzler. Neuro-symbolic artificial intelligence:\n[Current trends, 2021. URL https://arxiv.org/abs/2105.05330.](https://arxiv.org/abs/2105.05330)\n\nZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang,\nY. K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open\n[language models, 2024. URL https://arxiv.org/abs/2402.03300.](https://arxiv.org/abs/2402.03300)\n\nJasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine learning\n[algorithms, 2012. URL https://arxiv.org/abs/1206.2944.](https://arxiv.org/abs/1206.2944)\n\nFelipe Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman, Kenneth O. Stanley, and Jeff\nClune. Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural\n[Networks for Reinforcement Learning, April 2018. URL http://arxiv.org/abs/1712.06567.](http://arxiv.org/abs/1712.06567)\narXiv:1712.06567 [cs].\n\nLaurits Tani, Diana Rand, Christian Veelken, and Mario Kadastik. Evolutionary algorithms for hyperparameter\noptimization in machine learning for application in high energy physics. _The European Physical Journal C_,\n81(2):170, February 2021. ISSN 1434-6044, 1434-6052. doi: 10.1140/epjc/s10052-021-08950-y. URL\n[http://arxiv.org/abs/2011.04434. arXiv:2011.04434 [hep-ex].](http://arxiv.org/abs/2011.04434)\n\nNico M Temme. _Bessel Functions_, chapter 9, pp. 219\u2013255. John Wiley and Sons, Ltd, 1996. ISBN\n[9781118032572. doi: https://doi.org/10.1002/9781118032572.ch9. URL https://onlinelibrary.](https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118032572.ch9)\n[wiley.com/doi/abs/10.1002/9781118032572.ch9.](https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118032572.ch9)\n\n16\n\nSebastian Towers, Aleksandra Kalisz, Philippe A. Robert, Alicia Higueruelo, Francesca Vianello, MingHan Chloe Tsai, Harrison Steel, and Jakob N. Foerster. ADIOS: Antibody Development via Opponent\n[Shaping, June 2025. URL http://arxiv.org/abs/2409.10588. arXiv:2409.10588 [q-bio].](http://arxiv.org/abs/2409.10588)\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett (eds.), _Advances in Neural Information Processing Systems_,\n[volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n[files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n\nPaul Vicol, Luke Metz, and Jascha Sohl-Dickstein. Unbiased gradient estimation in unrolled computation\ngraphs with persistent evolution strategies. In Marina Meila and Tong Zhang (eds.), _Proceedings of the_\n_38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning_\n_Research_ [, pp. 10553\u201310563. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/](https://proceedings.mlr.press/v139/vicol21a.html)\n[v139/vicol21a.html.](https://proceedings.mlr.press/v139/vicol21a.html)\n\nPaul Vicol, Zico Kolter, and Kevin Swersky. Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single, April 2023. [URL http://arxiv.org/abs/2304.11153.](http://arxiv.org/abs/2304.11153)\narXiv:2304.11153 [cs, stat].\n\nAmala Mary Vincent and P. Jidesh. An improved hyperparameter optimization framework for AutoML\nsystems using evolutionary algorithms. _Scientific Reports_, 13(1):4737, March 2023. ISSN 2045-2322. doi:\n[10.1038/s41598-023-32027-3. URL https://doi.org/10.1038/s41598-023-32027-3.](https://doi.org/10.1038/s41598-023-32027-3)\n\nG. N. Watson. _A Treatise on the Theory of Bessel Functions_ . Cambridge University Press, Cambridge, 2\nedition, 1944. Reprinted with corrections, various later printings.\n\nG. B. Whitham. _Linear and nonlinear waves_ . Pure and applied mathematics. Wiley-Interscience, New York,\n1999. ISBN 9786613306241.\n\nDaan Wierstra, Tom Schaul, Jan Peters, and J\u00fcrgen Schmidhuber. Natural evolution strategies. pp. 3381\u20133387,\n06 2008. doi: 10.1109/CEC.2008.4631255.\n\nDaan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, and J\u00fcrgen Schmidhuber. Natural evolution\n[strategies, 2011. URL https://arxiv.org/abs/1106.4487.](https://arxiv.org/abs/1106.4487)\n\nC.S. Withers. A simple expression for the multivariate hermite polynomials. _Statistics and Probability Letters_,\n47(2):165\u2013169, 2000. ISSN 0167-7152. doi: https://doi.org/10.1016/S0167-7152(99)00153-4. URL\n[https://www.sciencedirect.com/science/article/pii/S0167715299001534.](https://www.sciencedirect.com/science/article/pii/S0167715299001534)\n\nKe Xue, Chao Qian, Ling Xu, and Xudong Fei. Evolutionary gradient descent for non-convex optimization.\nIn Zhi-Hua Zhou (ed.), _Proceedings of the Thirtieth International Joint Conference on Artificial Intelli-_\n_gence, IJCAI-21_, pp. 3221\u20133227. International Joint Conferences on Artificial Intelligence Organization,\n[8 2021. doi: 10.24963/ijcai.2021/443. URL https://doi.org/10.24963/ijcai.2021/443.](https://doi.org/10.24963/ijcai.2021/443)\nMain Track.\n\nZiming Yu, Pan Zhou, Sike Wang, Jia Li, Mi Tian, and Hua Huang. Zeroth-order fine-tuning of llms in random\nsubspaces. In _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)_, pp.\n4475\u20134485, October 2025.\n\nYihua Zhang, Pingzhi Li, Junyuan Hong, Jiaxiang Li, Yimeng Zhang, Wenqing Zheng, Pin-Yu Chen, Jason D.\nLee, Wotao Yin, Mingyi Hong, Zhangyang Wang, Sijia Liu, and Tianlong Chen. Revisiting zeroth-order\noptimization for memory-efficient llm fine-tuning: A benchmark, 2024.\n\n17\n\n**Appendix**\n\n**A Proofs** **19**\n\nA.1 ES Matrix Gradient Deviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n\nA.2 Error Rate Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n\n**B** **Mean Field Score Function Approximator** **27**\n\nB.1 Bessel Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n\nB.2 Derivation of Mean-field Approximators . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n**C EGG Architecture** **33**\n\nC.1 Notation and Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n\nC.2 Parameter Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n\nC.3 Matrix Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.4 Embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.5 Layer Normalization (LN) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.6 MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\nC.7 GRU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\nC.8 Fitness Calculation in Integer Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n**D EGG Pretraining with Integer EGGROLL** **35**\n\nD.1 Adding EGGROLL Perturbations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nD.2 Fitness Shaping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nD.3 Parameter Update . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n**E** **EGG Ablations** **36**\n\nE.1 Data Efficient Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nE.2 Controlling For Data Across Population Sizes . . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n**F** **EGGROLL Speed**"}, {"role": "assistant", "content": "**Mechanism:** EGGROLL addresses the computational bottleneck of Evolutionary Strategies (ES) for high-dimensional parameter spaces (like billion-parameter models) by constraining the search direction. Instead of constructing and inverting a full covariance matrix for parameter perturbations (which scales quadratically with parameter count, D^2), it projects the search updates onto a low-rank subspace.\n\n**Explanation:** In essence, when a system has a massive number of parameters, not all dimensions are equally important for improvement. Many parameters might be highly correlated, or only a few 'master' directions might account for most of the meaningful variation in performance. EGGROLL's low-rank search matrix approximates these critical directions. If you think of your model's parameters as coordinates in a vast space, instead of exploring randomly in all directions (a full-rank search), EGGROLL focuses the search along a small number of 'principal axes' or 'eigenvectors' that are most impactful. When 'r=1', it means the search is effectively restricted to a single, most influential direction. This dramatically reduces the number of computations from roughly D-squared (for matrix operations) to D times 'r' (for vector operations), akin to only needing to update a few 'pointers' to important directions rather than every single parameter independently. This mechanism makes ES practical for blackbox optimization of systems where gradients are unavailable or intractable, such as those with non-differentiable components."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_any j \u2208_ _`UndecidedNeighbors`_ _has output_ 1 **then**\n\n**10** Output 0 and terminate;\n\n**11** Remove all _j \u2208_ `UndecidedNeighbors` who output 0;"}, {"role": "assistant", "content": "**Mechanism:** This snippet implements a decentralized arbitration and state-pruning mechanism. It's akin to a distributed \"veto\" system combined with an iterative refinement of participant sets.\n\n**Explanation:** The core idea is to efficiently resolve a distributed decision. Consider 'UndecidedNeighbors' as a dynamic list of peer processes or agents. The first rule establishes a short-circuiting rejection condition: if any of these neighbors signals a strong positive (an \"output 1\" which could represent a claim, a strong preference, or a conflict), the current process immediately issues a \"0\" (a rejection or non-selection) and halts its current decision cycle. This behaves like a 'return false' or 'exit' statement in a loop, ensuring immediate reaction to critical signals. The second rule, executed only if no strong positive ('1') signal was received from any neighbor, serves as a list-pruning optimization: any neighbor that explicitly indicated a \"0\" (a \"no,\" \"neutral,\" or \"I'm out\" vote for this specific contention) is removed from the 'UndecidedNeighbors' set. This effectively reduces the pool of participants for the next iteration, speeding up subsequent computations by discarding those who have already made up their mind in the negative."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**17**\n\n3.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n3.2 Sum-of-Squares hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.3 Stochastic block model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20"}, {"role": "assistant", "content": "**Mechanism:** This section lays the groundwork by defining symbols (notation), then introduces a method to convert complex non-convex polynomial optimization problems into a sequence of increasingly tighter convex semidefinite programs (Sum-of-Squares hierarchy), and finally describes a probabilistic graph generation model (Stochastic block model) where node communities dictate connection probabilities.\n\n**Explanation:** First, 'Notation' is simply about defining the common language, much like declaring variables and types in a programming language so everyone understands what 'x' or 'G' refers to. The 'Sum-of-Squares hierarchy' is a technique used to find solutions or prove bounds for problems that are initially very hard to solve directly. It works by taking a complex, non-linear problem and iteratively relaxing it into a series of 'easier' convex problems (semidefinite programs). Each step in the 'hierarchy' provides a tighter approximation of the original problem, allowing us to get closer to the true answer by solving a sequence of well-behaved problems, conceptually similar to a loop that refines an estimate in each iteration. The 'Stochastic block model' is a way to construct networks with community structures. You assign each node (like a person) to a 'block' (like a team), and then for any two nodes, the probability they form a connection (an edge) depends on which blocks they belong to. It's like a function that takes node assignments and inter-block connection probabilities as input, and outputs a graph where connections are drawn stochastically."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_j \u2208_ `UndecidedNeighbors` **do**\n\n**8** Choose strategy _si_ ( _j_ ) _\u2208{_ r _,_ p _,_ s _}_ uniformly at random and send to _j_ ;\n\n```\n   /* Round 2: Join MIS if possible */\n```"}, {"role": "assistant", "content": "**Mechanism:** A processing node iterates through its locally known set of uncommitted, adjacent nodes (its 'UndecidedNeighbors'). For each such neighbor, it performs a uniform random selection from a fixed set of three discrete strategies ('r', 'p', 's'). This chosen strategy is then encapsulated and transmitted as a message to that specific neighbor.\n\n**Explanation:** This mechanism introduces a foundational element of randomness at a local level. By having each node independently propose one of three equally probable strategies to its undecided neighbors, it effectively 'seeds' initial communication with fair, unbiased inputs. This prevents any inherent bias or pre-coordination, ensuring that no single strategy or node disproportionately influences the initial state of uncommitted neighbors. In the context of distributed algorithms like Maximal Independent Set (MIS) construction (implied by 'Round 2: Join MIS if possible'), these random signals often serve as 'bids' or 'proposals' that help break symmetry and resolve potential conflicts or deadlocks when multiple nodes might simultaneously attempt to join the set. It's akin to each undecided entity receiving a random, low-stakes 'first offer' to react to, kicking off a decentralized decision-making process."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n`UndecidedNeighbors` _is empty_ **then**\n\n**21** Output 1\n\n21\n\nthese guarantees. Thus, Algorithm 9 terminates in 5 _\u00d7 O_ (log _n_ ) iterations (i.e., _O_ (log _n_ ) rounds\nasymptotically). However, an additional argument is needed: in the original algorithm by\nM\u00b4etivier et al. [15], the probability that two nodes pick the same rank is negligible due to the\nuse of real-valued randomness. In contrast, in our algorithm, each node generates a rank using\n_c_ log _n_ random bits, so the probability that any two nodes pick the same rank is non-negligible.\nIn each round, every node generates a rank consisting of _c_ log _n_ random bits. The total\nnumber of possible ranks is 2 _[c]_ [ log] _[ n]_ = _n_ _[c]_ . By the union bound, the probability that any two\nnodes pick the same rank in a given round is at most \ufffd _n_ 2\ufffd _\u00b7_ _n_ [1] ~~_[c]_~~ [=] _[ O]_ \ufffd _n_ _[c]_ 1 _[\u2212]_ [2] \ufffd _._ When this process\n\nis repeated independently for _O_ (log _n_ ) rounds, the probability that any two nodes collide in at\nleast one of the rounds is bounded by _O_ \ufffd _n_ lo _[c]_ g _[\u2212]_ _n_ [2] \ufffd _,_ which is negligible for any sufficiently large\nconstant _c >_ 2. Thus, with high probability, no two nodes ever pick the same rank across all\nrounds.\nSince the original algorithm with real-valued ranks succeeds with probability 1 _\u2212_ 1 _/_ poly( _n_ ),\nthe bit-based version succeeds with probability at least 1 _\u2212_ 1 _/_ poly( _n_ ).\n\n**Theorem 4.6** (Positive Probability of MIS Inclusion) **.** _Under Algorithm 9, every node has a_\n_strictly positive probability of eventually outputting_ 1 _(i.e., joining the MIS) in each round in_\n_which none of its neighbors has output_ 1 _._\n\n_Proof._ Consider an undecided node _i_ . Its priority is computed as _Ri_ = _ri\u2192i \u2295_ _r_ opp( _i_ ) _\u2192i,_ where\nboth random values are drawn independently and uniformly from _{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ . The priorities of\nall neighbors are defined analogously, so that they are independent and identically distributed\nover _{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ .\nHence, the probability that _Ri_ is strictly smaller than the priorities of all its active neighbors\nis 1 _/di_ where _di_ is the number of undecided neighbors of _i_ . Therefore, as long as none of its\nneighbors has the output 1, node _i_ always has a strictly positive probability of joining the MIS.\n\n### **5 Conclusion and Future Work**\n\nWe proposed a model that incorporates rational behavior in distributed message passing algorithms. We considered a utility function, where nodes are incentivized to compute a correct\nsolution and prefer to be included in the MIS. We designed two algorithms that are resilient\nto rational behavior: no node has an incentive to deviate from the prescribed algorithm. Additionally, assuming that no node deviates from the algorithm, we can guarantee correctness,\ntermination, and positive probability of inclusion.\nHowever, each algorithm comes with certain drawbacks. The rank-based strategy algorithm\nrelies on cryptographic assumptions, which implicitly restrict agents to bounded computational\npower \u2013 a non-standard assumption in the context of distributed algorithms. Moreover, this\nalgorithm may use large messages; a node that becomes the opponent of _k_ neighbors will send\n_O_ ( _k_ log _n_ )-bit messages over each incident edge. On the other hand, the RPS-based strategy\nalgorithm avoids cryptographic assumptions and sends at most _O_ (log _n_ )-bit messages over each\nedge per round. But its round complexity has exponential dependence on the maximum degree\nof the network.\n\nWhile our algorithms are resilient to unilateral deviations, they do not prevent coordination\nor implicit collusion among multiple nodes. For example, once a node realizes that it cannot\njoin the MIS (because one of its neighbors has already output 1), it may still have an incentive\nto continue participating in the algorithm in a way that strategically reduces the chances of its\nneighbors, thereby improving the inclusion probability of the nodes with which it is colluding.\nAdditionally, the two algorithms presented are somewhat sensitive to the assumptions about\n\n22\n\nthe underlying model and utility structure. If the utilities are perturbed even slightly, our\nequilibrium guarantees may not hold. For instance, if the utility of a node in a locally valid\nsolution where it belong to the MIS is negative, our algorithms no longer ensure equilibrium.\nAn important direction for future work, therefore, is to design algorithms that remain robust\nunder a broader class of utility functions, collusion, or to establish _impossibility results_ that\ncharacterize the precise limitations of such robustness.\n\n### **References**\n\n[1] Ittai Abraham, Danny Dolev, Rica Gonen, and Joseph Y. Halpern. Distributed computing\nmeets game theory: robust mechanisms for rational secret sharing and multiparty computation. In Eric Ruppert and Dahlia Malkhi, editors, _Proceedings of the Twenty-Fifth Annual_\n_ACM Symposium on Principles of Distributed Computing, PODC 2006, Denver, CO, USA,_\n_July 23-26, 2006_, pages 53\u201362. ACM, 2006. `[doi:10.1145/1146381.1146393](https://doi.org/10.1145/1146381.1146393)` .\n\n[2] Ittai Abraham, Danny Dolev, and Joseph Y. Halpern. Distributed protocols for leader\nelection: A game-theoretic perspective. _ACM Trans. Economics and Comput._, 7(1):4:1\u2013\n4:26, 2019. `[doi:10.1145/3303712](https://doi.org/10.1145/3303712)` .\n\n[3] Yackolley Amoussou-Guenou, Bruno Biais, Maria Potop-Butucaru, and Sara Tucci Piergiovanni. Rational vs byzantine players in consensus-based blockchains. In Amal El Fallah\nSeghrouchni, Gita Sukthankar, Bo An, and Neil Yorke-Smith, editors, _Proceedings of the_\n_19th International Conference on Autonomous Agents and Multiagent Systems, AAMAS_\n_\u201920, Auckland, New Zealand, May 9-13, 2020_, pages 43\u201351. International Foundation for\nAutonomous Agents and Multiagent Systems, 2020. URL: `[https://dl.acm.org/doi/10.](https://dl.acm.org/doi/10.5555/3398761.3398772)`\n`[5555/3398761.3398772](https://dl.acm.org/doi/10.5555/3398761.3398772)` .\n\n[4] Simon Collet, Pierre Fraigniaud, and Paolo Penna. Equilibria of Games in Networks\nfor Local Tasks. In _22nd International Conference on Principles of Distributed Systems_\n_(OPODIS 2018)_, volume 125, pages 6:1\u20136:16, Dagstuhl, Germany, 2019. URL: `[https:](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.OPODIS.2018.6)`\n`[//drops.dagstuhl.de/entities/document/10.4230/LIPIcs.OPODIS.2018.6](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.OPODIS.2018.6)`, `[doi:10.](https://doi.org/10.4230/LIPIcs.OPODIS.2018.6)`\n`[4230/LIPIcs.OPODIS.2018.6](https://doi.org/10.4230/LIPIcs.OPODIS.2018.6)` .\n\n[5] Joan Feigenbaum and Scott Shenker. Distributed algorithmic mechanism design: recent results and future directions. In _Proceedings of the 6th International Workshop on_\n_Discrete Algorithms and Methods for Mobile Computing and Communications (DIAL-M_\n_2002), Atlanta, Georgia, USA, September 28-28, 2002_, pages 1\u201313. ACM, 2002. `[doi:](https://doi.org/10.1145/570810.570812)`\n`[10.1145/570810.570812](https://doi.org/10.1145/570810.570812)` .\n\n[6] Jeremy T. Fineman, Calvin C. Newport, Micah Sherr, and Tonghe Wang. Fair maximal\nindependent sets. In _2014 IEEE 28th International Parallel and Distributed Processing_\n_Symposium, Phoenix, AZ, USA, May 19-23, 2014_, pages 712\u2013721. IEEE Computer Society,\n2014. `[doi:10.1109/IPDPS.2014.79](https://doi.org/10.1109/IPDPS.2014.79)` .\n\n[7] Drew Fudenberg and Jean Tirole. _Game theory (3. pr.)_ . MIT Press, 1991.\n\n[8] Mohsen Ghaffari and Christoph Grunau. Near-Optimal Deterministic Network Decomposition and Ruling Set, and Improved MIS . In _2024 IEEE 65th Annual Symposium on_\n_Foundations of Computer Science (FOCS)_, pages 2148\u20132179, Los Alamitos, CA, USA, October 2024. IEEE Computer Society. URL: `[https://doi.ieeecomputersociety.org/10.](https://doi.ieeecomputersociety.org/10.1109/FOCS61266.2024.00007)`\n`[1109/FOCS61266.2024.00007](https://doi.ieeecomputersociety.org/10.1109/FOCS61266.2024.00007)`, `[doi:10.1109/FOCS61266.2024.00007](https://doi.org/10.1109/FOCS61266.2024.00007)` .\n\n[9] Tiantian Gong and Zeyu Liu. Rational secret sharing with competition. _IACR Cryptol._\n_ePrint Arch._, page 242, 2025. URL: `[https://eprint.iacr.org/2025/242](https://eprint.iacr.org/2025/242)` .\n\n23\n\n[10] Joseph Y. Halpern and Vanessa Teague. Rational secret sharing and multiparty computation: Extended abstract. _CoRR_, abs/cs/0609035, 2006. URL: `[http://arxiv.org/abs/](http://arxiv.org/abs/cs/0609035)`\n`[cs/0609035](http://arxiv.org/abs/cs/0609035)`, `[arXiv:cs/0609035](https://arxiv.org/abs/cs/0609035)` .\n\n[11] Juho Hirvonen and Sara Ranjbaran. Designing local distributed mechanisms. _CoRR_,\nabs/2411.06788, 2024. URL: `[https://doi.org/10.48550/arXiv.2411.06788](https://doi.org/10.48550/arXiv.2411.06788)`, `[arXiv:](https://arxiv.org/abs/2411.06788)`\n`[2411.06788](https://arxiv.org/abs/2411.06788)`, `[doi:10.48550/ARXIV.2411.06788](https://doi.org/10.48550/ARXIV.2411.06788)` .\n\n[12] Nathan Linial. Distributive graph algorithms-global solutions from local data. In _28th_\n_Annual Symposium on Foundations of Computer Science, Los Angeles, California, USA,_\n_27-29 October 1987_, pages 331\u2013335. IEEE Computer Society, 1987. `[doi:10.1109/SFCS.](https://doi.org/10.1109/SFCS.1987.20)`\n\n`[1987.20](https://doi.org/10.1109/SFCS.1987.20)` .\n\n[13] Michael Luby. A simple parallel algorithm for the maximal independent set problem. In\nRobert Sedgewick, editor, _Proceedings of the 17th Annual ACM Symposium on Theory_\n_of Computing, May 6-8, 1985, Providence, Rhode Island, USA_, pages 1\u201310. ACM, 1985.\n`[doi:10.1145/22145.22146](https://doi.org/10.1145/22145.22146)` .\n\n[14] Shaik Maleka, Amjed Shareef, and C. Pandu Rangan. The deterministic protocol for rational secret sharing. In _22nd IEEE International Symposium on Parallel and Distributed_\n_Processing, IPDPS 2008, Miami, Florida USA, April 14-18, 2008_, pages 1\u20137. IEEE, 2008.\n`[doi:10.1109/IPDPS.2008.4536558](https://doi.org/10.1109/IPDPS.2008.4536558)` .\n\n[15] Yves M\u00b4etivier, John Michael Robson, Nasser Saheb-Djahromi, and Akka Zemmari. An\noptimal bit complexity randomized distributed MIS algorithm. _Distributed Comput._, 23(56):331\u2013340, 2011. URL: `[https://doi.org/10.1007/s00446-010-0121-5](https://doi.org/10.1007/s00446-010-0121-5)`, `[doi:10.1007/](https://doi.org/10.1007/S00446-010-0121-5)`\n\n`[S00446-010-0121-5](https://doi.org/10.1007/S00446-010-0121-5)` .\n\n[16] Noam Nisan. Algorithms for selfish agents. In Christoph Meinel and Sophie Tison, editors, _STACS 99, 16th Annual Symposium on Theoretical Aspects of Computer Science,_\n_Trier, Germany, March 4-6, 1999, Proceedings_, volume 1563 of _Lecture Notes in Computer_\n_Science_, pages 1\u201315. Springer, 1999. `[doi:10.1007/3-540-49116-3\\_1](https://doi.org/10.1007/3-540-49116-3_1)` .\n\n[17] Martin J. Osborne and Ariel Rubinstein. _A Course in Game Theory_ . The MIT\nPress, Cambridge, MA, 1994. URL: `[https://sites.math.rutgers.edu/~zeilberg/](https://sites.math.rutgers.edu/~zeilberg/EM20/OsborneRubinsteinMasterpiece.pdf)`\n`[EM20/OsborneRubinsteinMasterpiece.pdf](https://sites.math.rutgers.edu/~zeilberg/EM20/OsborneRubinsteinMasterpiece.pdf)` .\n\n[18] Li-Hsing Yen, Jean-Yao Huang, and Volker Turau. Designing self-stabilizing systems using\ngame theory. _ACM Trans. Auton. Adapt. Syst._, 11(3):18:1\u201318:27, 2016. `[doi:10.1145/](https://doi.org/10.1145/2957760)`\n\n`[2957760](https://doi.org/10.1145/2957760)` .\n\n[19] Li-Hsing Yen and Guang-Hong Sun. Game-theoretic approach to self-stabilizing minimal\nindependent dominating sets. In Yang Xiang, Jingtao Sun, Giancarlo Fortino, Antonio\nGuerrieri, and Jason J. Jung, editors, _Internet and Distributed Computing Systems - 11th_\n_International Conference, IDCS 2018, Tokyo, Japan, October 11-13, 2018, Proceedings_,\nvolume 11226 of _Lecture Notes in Computer Science_, pages 173\u2013184. Springer, 2018. `[doi:](https://doi.org/10.1007/978-3-030-02738-4_15)`\n`[10.1007/978-3-030-02738-4\\_15](https://doi.org/10.1007/978-3-030-02738-4_15)` .\n\n### **A Useful Tail Inequalities**\n\nFollowing are two tail inequalities we use in our analysis of the running time of the RPS based\nMIS algorithm.\n\n24\n\n**Lemma A.1** (Reverse Markov Inequality) **.** _Let Y be a real-valued random variable such that_\n_Y \u2264_ _a almost surely, for some constant a \u2208_ R _, and let d <_ E[ _Y_ ] _. Then,_\n\n[]] _[ \u2212]_ _[d]_\nPr ( _Y \u2265_ _d_ ) _\u2265_ [E][[] _[Y]_ _._\n\n_a \u2212_ _d_\n\n**Lemma A.2** (Chernoff Bound: Lower Tail) **.** _Let X_ 1 _, X_ 2 _, . . ., Xn be independent Bernoulli ran-_\n_dom variables taking values in {_ 0 _,_ 1 _}, and let X_ = [\ufffd] _[n]_ _i_ =1 _[X][i][, and][ \u00b5]_ [ =][ E][[] _[X]_ []] _[. Then, for any]_\n0 _< \u03b4 <_ 1 _, the following inequality holds:_\n\nPr( _X \u2264_ (1 _\u2212_ _\u03b4_ ) _\u00b5_ ) _\u2264_ exp _\u2212_ _[\u03b4]_ [2] _[\u00b5]_\n\ufffd 2\n\n25\n\n\ufffd"}, {"role": "assistant", "content": "**Mechanism:** The mechanism for ensuring positive inclusion probability for a node relies on a localized, independent random rank generation and comparison. Each 'undecided' node `i` generates a `c log n`-bit random rank `Ri`. This rank is effectively a unique identifier for that round. The probabilities are designed such that if node `i`'s rank is strictly smaller than all its currently 'active' (undecided) neighbors' ranks, it joins the MIS. Since all ranks are drawn independently and uniformly from the same large set (2^(c log n) possibilities), the probability that `Ri` is the minimum among `i` and its `di` undecided neighbors is simply `1 / (di + 1)` (if considering `i` itself) or `1/di` as stated (if considering minimum among neighbors, which implies `i` beats them). This `1/di` probability ensures that as long as a node is undecided and has undecided neighbors, it has a non-zero chance of becoming the 'winner' in its local neighborhood and joining the MIS. The use of `c log n` bits ensures that the probability of two nodes generating the exact same rank is vanishingly small across multiple rounds, which is crucial for the algorithm's correctness, contrasting with the ideal but impossible 'real-valued randomness' assumption in older algorithms.\n\n**Explanation:** The core idea for probabilistic termination and inclusion is about managing collisions. When nodes pick random ranks, there's always a chance two nodes pick the same rank. By using `c log n` random bits, the total number of possible ranks is `n^c`. The union bound tells us that the probability of *any* two nodes colliding in a *single* round is `O(n^(1-c))`. If `c > 2`, this quickly becomes negligible. Repeating this process for `O(log n)` rounds further reduces the chance of *any* collision across *all* rounds to `O(n^(1-c) log n)`, which is also negligible for sufficiently large `c`. This means with high probability, each node effectively has a unique random 'priority ticket' in each round. Theorem 4.6 then leverages this uniqueness: for any undecided node `i`, its rank `Ri` and its neighbors' ranks are independent and identically distributed. Thus, the chance that `Ri` is the smallest (making `i` 'win' and join the MIS) among its `di` undecided neighbors is `1 / (di + 1)` (or `1/di` if the wording implicitly means winning against *other* neighbors), which is a guaranteed positive probability. This is like a lottery where you have `di` tickets and each has an equal chance of winning, ensuring you always have a shot as long as you're in the game and haven't lost by a neighbor already joining."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**19 end if**\n\n**20 return** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_\n\nThe theoretical aspects of _ECF_ packet scheduling algorithm are provided in 2.2.3.\n\n**Algorithm 4:** RR (num_segments \u2265 1, cwnd_limited=true)\n\n**Input:** Set of available subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R\n\n**1** Get _num_segments_ from MPTCP send buffer ;\n\n**2 for** _each \ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S **do**"}, {"role": "assistant", "content": "**Mechanism:** The snippet describes two distinct scheduling behaviors. Initially, it concludes a process where a single 'best' subflow (`sfbest`) was identified and selected, likely based on some performance metric from the `ECF` algorithm. Subsequently, it introduces a Round Robin (RR) scheduling mechanism. RR fundamentally operates by iterating through a collection of available subflows (`S`) in a cyclic fashion. For each subflow in the iteration, it retrieves a predefined quantity of data segments (`num_segments`) from a send buffer. A critical control mechanism is `cwnd_limited=true`, which means that even when a subflow's turn comes, data dispatch is constrained by that subflow's current congestion window (a network feedback mechanism), acting as a backpressure system.\n\n**Explanation:** The initial lines indicate the completion of a decision-making process where a particular network path, or 'subflow', identified as `sfbest`, was chosen for data transmission, probably because it was performing optimally according to a specific algorithm (`ECF`). Immediately following this, the text initiates a description of a new algorithm called Round Robin (RR). This is a foundational programming pattern, essentially a `for` loop that cycles through a set of available network paths (`S`). Inside this loop, for each path, the system fetches a predetermined number of data blocks, or 'segments', from the outgoing data queue. The `cwnd_limited=true` parameter is a key condition: it ensures that data is only sent if the network path isn't already overloaded. This is like a traffic light for each path, preventing it from sending more cars than the road can handle at that moment, even if it's its turn."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Background** **4**\n2.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n2.1.1 Simulation types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.1.2 Reactors types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Governing equations and Numerical Approximations for the fluid . . . . . . . . . . . . . . . . . . 5\n2.2.1 The MHD stellarator model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\n2.2.2 Spatial Discretization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.2.3 B\u00e9zier Finite Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n\n2.2.4 Tesselation of the domain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.5 Imposing _G_ [1] on the field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.6 Field Interpolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.7 Bounding Box of a Bicubic B\u00e9zier Element . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.8 Toroidal Fourier expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.9 The Finite Element Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n2.3 Governing equations and Numerical Approximations for the kinetics . . . . . . . . . . . . . . . . 11\n2.3.1 Newton-Lorentz equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 The Boris Pusher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n2.3.3 Projecting particles on the Finite Element grid . . . . . . . . . . . . . . . . . . . . . . . . 12"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is the decomposition of a complex, continuous physical problem into a set of discrete, solvable approximations. It uses a spatial tessellation (like a complex 3D grid or mesh) to represent the reactor's geometry and the fluid behavior, and then a particle-in-cell approach for the kinetic behavior. The fluid dynamics are solved using Finite Element Method (FEM) on this mesh, which approximates differential equations by transforming them into algebraic systems over small, interconnected regions. Particle trajectories are updated iteratively using a specific numerical integrator (Boris Pusher) which efficiently handles the Lorentz force, then these particles 'project' their properties back onto the grid to influence the fluid.\n\n**Explanation:** This section lays out the groundwork for simulating a stellarator, a complex fusion device, by breaking down the physics into manageable computational chunks. For the plasma, it uses Magnetohydrodynamics (MHD) to treat it as a continuous, electrically conducting fluid. To solve this, the entire physical space is 'discretized' \u2013 chopped into many small, interconnected elements (like cells in a spreadsheet, but 3D). B\u00e9zier Finite Elements are used to define these elements, allowing for very smooth and accurate representation of the reactor's complex, curved shapes, essentially creating a high-fidelity 'wireframe model'. The Finite Element Method then solves the MHD equations over these elements. For individual particles, it tracks their movement using the Newton-Lorentz equation, and a 'Boris Pusher' algorithm serves as a numerical loop that calculates each particle's new position and velocity step-by-step, accounting for magnetic forces. Finally, to link the particle behavior with the fluid model, particles 'project' their influence (like charge or current) onto the discrete grid points, allowing the two simulation types to interact."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_\ud835\udc5d\ud835\udc56\ud835\udc5d\ud835\udc52_ **then**\n\n**150** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51, \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61_ _ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ ) ;"}, {"role": "assistant", "content": "**Mechanism:** This code snippet updates the congestion window (`cwnd`) using a controlled additive increase, but only when the network bottleneck is considered fully utilized by the BBR algorithm. The `min` function caps this growth by `BBR.target_cwnd` to prevent overshooting optimal capacity.\n\n**Explanation:** This is a conditional update to the network's sending window. `cwnd` represents the number of data segments that can be unacknowledged in transit. The `if BBR.filled_pipe then` clause means this update only happens when BBR believes the network path's bottleneck is saturated, indicating we're not under-utilizing the available bandwidth. The `cwnd + packets_delivered` part performs an additive increase, effectively probing for more bandwidth by sending a few more packets than just successfully delivered. However, this growth is carefully constrained by the `min` operation. `BBR.target_cwnd` is BBR's dynamically calculated estimate of the optimal window size to maintain high throughput without causing excessive queueing. This ensures the window grows efficiently to fill the pipe but doesn't exceed BBR's current best estimate for stable operation, similar to how a `max` or `min` function in programming (like `Math.min()` in JavaScript) is used to clamp a value within specific bounds."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_\ud835\udc5d\ud835\udc56\ud835\udc5d\ud835\udc52_ **or** _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ _> \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ **then**\n\n**137** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ ;\n\n**138** BBR_Set_Send_Quantum():"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an adaptive feedback loop that adjusts the target sending speed (pacing_rate) based on real-time observations of data delivery (rate), acting like an optimistic update to leverage available capacity.\n\n**Explanation:** This code functions as a crucial update within the BBR algorithm. It first performs a conditional check, much like an 'if' statement. If 'BBR.filled_pipe' is true, it means the algorithm has a good understanding of the network's capacity. Alternatively, if the 'rate' (the actual observed speed of data delivery) is *greater* than our current 'BBR.pacing_rate' (our target sending speed), it's a clear signal the network can handle more. In either case, the 'pacing_rate' is immediately updated to match the higher observed 'rate'. This is an aggressive, proactive adjustment, preventing the sender from artificially limiting itself. Following this, 'BBR_Set_Send_Quantum()' is called, which, akin to calculating a 'batch size' for data packets, uses the new 'pacing_rate' to determine the optimal amount of data to send in each burst, ensuring smooth, efficient transmission without overwhelming network buffers."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_\ud835\udc4f\ud835\udc64_\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ \u2265 3 **then**\n\n**85** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_ _ _\ud835\udc5d\ud835\udc56\ud835\udc5d\ud835\udc52_ = _\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc52_ ;\n\n**86** BBR_Check_Drain():"}, {"role": "assistant", "content": "**Mechanism:** This code snippet employs a simple conditional logic (an 'if' statement) to trigger a state transition, utilizing a counter as a debouncing or confirmation mechanism before initiating a subsequent action.\n\n**Explanation:** At its core, this is a standard control flow mechanism: an `if` statement. The `_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_\ud835\udc4f\ud835\udc64_\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_` variable acts as a counter, tracking how many consecutive or recent measurements have indicated that the network link's capacity (the 'pipe's' bandwidth) is fully utilized. The condition `_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_\ud835\udc4f\ud835\udc64_\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ \u2265 3` means the system requires at least three consistent observations of a 'full pipe' before it commits to that state. This threshold prevents the system from prematurely reacting to a single, potentially noisy or transient measurement. Once this condition is met, a boolean flag `_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_ _ _\ud835\udc5d\ud835\udc56\ud835\udc5d\ud835\udc52_` is set to `true`, explicitly signaling that the algorithm has confirmed the pipe is full. This flag effectively transitions the congestion control algorithm (like BBR) into a new operational phase. Immediately following this state update, the `BBR_Check_Drain()` function is called. This function's purpose, in the context of a 'filled pipe,' is typically to reduce the amount of data in flight, moving from a bandwidth probing phase (where extra data might be sent to 'fill' the pipe and measure its capacity) to a stable, efficient 'drain' phase, where the sending rate matches the discovered bandwidth without causing excessive queuing. It's a precise state-machine step to stabilize network flow."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-5-4.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-5-0.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-5-3.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-5-1.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-5-2.png)\n\nFigure 4: **Repeating VSC videos exposes a counting shortcut.** We propose a simple sanity check for VSC,\ncalled _VSC-Repeat_ . We concatenate each VSC video (from the 10-min split) with itself 1 _\u2212_ 5 times. Since no new\nscene is introduced, the ground-truth number of unique objects remains unchanged. This sanity check can help test\nif models indeed hold long-term global state or rather exploit simple segmentation-based shortcuts.\n\nPreviously, we showed that a simple frame-level baseline nearly saturates VSR without any spatial supersensing.\nThis led to a hypothesis that Cambrian-S\u2019 benchmark-tailored inference methods might be improving performance\nby exploiting benchmark shortcuts. In this section, we showcase this aspect on the VSI-Super-Counting (VSC)\nbenchmark. We (i) describe the VSC task, (ii) summarize the predictive sensing inference mechanism proposed\nin Cambrian-S, and (iii) show that a sanity check called _VSC-Repeat_ \u2014repeating the same environments multiple\ntimes\u2014drastically impacts performance. This reveals that the inference pipeline relies on a benchmark-specific\nshortcut of counting objects across new rooms rather than genuine spatial supersensing.\n\n**VSC Task.** VSC requires counting the number of _unique_ objects of a target category (e.g., chairs) across an entire\nlong video stream. A correct solution must not only detect objects in individual frames, but also reason across\ntime to identify duplicates and avoid counting the same object multiple times. The ground-truth label is a single\nunique-object count for the whole video. Performance is measured using mean relative accuracy (Yang et al., 2025a).\n\n**Inference mechanism of Cambrian-S for VSC.** Cambrian-S introduces a surprise-based event segmentation\napproach to improve performance on VSC. It uses a latent frame-prediction model to compute a \u201csurprise\u201d signal\n(prediction error) and segments the continuous visual input whenever surprise is high, treating these points as\nscene-change boundaries. This yields a sequence of spatially coherent segments. Within each segment, the model\naccumulates frame features in an event buffer. When a high-surprise frame is detected, the model summarizes the\nbuffered features to produce a segment-level count estimate, then clears the buffer and starts a new segment. This\ncycle repeats until the end of the video, after which the segment-level count estimates are aggregated into a final\nobject-count prediction. This design implicitly assumes that each segment corresponds to a distinct environment\nthat is visited at most once. Under this assumption, resetting the buffer at each surprise boundary should not hurt\nunique-object counting (For details, see Section 4.3 in (Yang et al., 2025b)).\n\n**A Sanity Check.** We show that this bespoke segmentation mechanism described above inadvertently overfits to\nquirks of the VSC benchmark without truly improving spatial supersensing. For each 10-minute VSC video, we\nrevisit the environments without introducing new objects by stitching the same clip to itself 1-5 times, forming\nour sanity check called _VSC-Repeat_ . This produces a sequence in which the same rooms and objects are revisited\nrepeatedly, removing the shortcut in the VSC-benchmark of video never re-entering a previously visited environment.\nA model performing genuine spatial supersensing should recognize that these are repeated observations of the\n\n                                                 same environments and keep its predicted object count unchanged. VSC Repeat does not change the underlying\n\n6\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-6-2.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-6-0.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-6-1.png)\n\nFigure 5: **(Left) Cambrian collapses on** _**VSC-Repeat**_ with mean relative accuracy going from 42% to 0%\nafter 5 repeats, indicating that its inference method relies on VSC-specific shortcuts rather than genuine spatial\ncognition. **(Right) Cambrian-S near-perfectly overcounts the objects proportional to repeats** indicating\nthe predicted number of objects is strongly correlated to number of repeats, i.e. simply counting objects across new\nrooms as unique rather than maintaining a persistent set of unique objects across rooms. A supersensing model\nshould output the same object counts across VSC-Repeat, since the unique object count stays the same.\n\nspatial layout or object counts; it only violates the implicit assumption, built into both the benchmark and the\npredictive-sensing inference pipeline, that each spatial environment will be seen once in a monotone sequence.\n\n**Cambrian-S (almost) entirely fails on our VSC-Repeat Benchmark.** As illustrated in Figure 5, repeating\neach 10-minute video 2 times (yielding a 30 min video) drastically reduces the mean relative accuracy (MRA) of the\nCambrian-S inference pipeline from 42 _._ 0% to 3 _._ 6%; the MRA further goes down to 0% upon 5 repeats (yielding a 1\nhour video). By comparing performance of Cambrian-S on the original VSC benchmark (brown line), we show that\nthe accuracy drop is not due to increasing the length of the video, but indeed due to our repeat procedure. We\nalso note that the predicted counts grow with the number of times the environments are revisited (Figure 5 right).\nThis behavior is consistent with a shortcut heuristic that effectively counts _segments_ or _rooms visited_ rather than\nperform spatial supersensing and aggregate information throughout the video to recognize unique objects. This\nfailure mode indicates that VSC performance is strongly tied to structural assumptions of the dataset (e.g., that\nscenes never repeat) rather than to revisit-invariant spatial reasoning.\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-6-3.png)\n\n**Conclusion.** A supersensing system that maintains an internal map over time should detect that revisited rooms\n\n                                  -                                  do not introduce new objects; the current Cambrian S inference pipeline instead re counts at each surprise boundary.\nAs a consequence, high VSC performance should be interpreted with caution when evaluating newer methods as\nevidence of continual counting, as they may exploit quirks of the VSC benchmark construction while neglecting the\nmore advanced spatial and temporal understanding required for video world modeling."}, {"role": "assistant", "content": "**Mechanism:** The Cambrian-S model attempts to count unique objects by segmenting the video stream into 'events' based on 'surprise' (prediction error). When surprise is high, it assumes a scene change. At each scene change, it processes features from the current segment, generates a segment-level count, and crucially, clears its internal 'event buffer'. This means it forgets all object features observed in previous segments.\n\n**Explanation:** The core problem stems from how Cambrian-S manages its state across time. It treats each 'segment' of the video (demarcated by high prediction error, indicating a scene change) as an independent unit. Think of it like a function that gets called for each scene segment. This function detects objects, adds them to a temporary list (its 'event buffer'), and then at the end of the segment, it summarizes that list to get a segment-specific object count. The critical flaw is that this temporary list, or 'event buffer', is completely reset at the boundary of each segment. The VSC-Repeat test exposes this by simply replaying previously seen environments. When a room reappears, the system 'clears its memory' (resets the buffer) from its previous visit to that room. Therefore, when it re-observes the same objects in the revisited room, it has no memory of having seen them before *in a prior segment*. It processes them as if they are brand new, unique objects for this 'new' segment, leading to an inflated overall count proportional to the number of repeats, rather than maintaining a persistent set of unique objects across the entire video stream."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nSince its birth with Bitcoin [1], blockchain technology has emerged as a disruptive innovation in numerous domains,\n\nincluding Decentralized Finance and data certification, handling high-stakes assets like cryptocurrencies and sensitive\n\ndata [2]. Smart Contracts (SCs) are central to this ecosystem. SCs are Turing-complete programs executed on blockchains,\n\nin which consensus protocols guarantee valid execution through validated transactions [3]. SCs are replicated identically\n\nacross decentralized network nodes and are designed to automatically trigger predefined actions in response to specific\n\nevents [4]. Interactions with SCs occur via transactions, validated by blockchain nodes, with outcomes recorded on\n\neach node\u2019s copy of the distributed ledger. Solidity is the most widely used language for SC development [5]. Differently\n\nfrom traditional programs, SCs might be directly executed by the end users. Therefore, Solidity provides a special tag,\n\n@notice tag \u2013 part of its NatSpec format [1] \u2013 through which developers can provide non-technical documentation of the\n\nfunction behavior, guiding end-users before contract execution [6].\n\nRecent years have also seen rapid advancements in Large Language Models (LLMs), which have shown remarkable\n\ncapabilities in code-related tasks. Tools like GitHub Copilot and ChatGPT have demonstrated the ability to generate code\n\nvalid snippets [7, 8], assist in software comprehension [9], and even detect vulnerabilities across various programming\n\nlanguages [10, 11].\n\nThe potential of LLMs in generating general-purpose programs (e.g., in Java) has already been widely evaluated [7].\n\nOn the other hand, the literature provides only limited evidence of the capability of such approaches to automatically\n\ngenerate SCs. SC development introduces unique challenges: Syntactic and semantic plausibility are not enough, and\n\nsecurity, gas-efficiency, and robustness against adversarial inputs are of primary importance to grant the success of a\n\nSC. Recent work has begun exploring these issues, evaluating LLMs for tasks ranging from vulnerability detection [10]\n\nto automatic comment generation [12] and contract generation [13]. Given the syntactic similarity between Solidity\n\nand other general-purpose programming languages such as JavaScript, it is theoretically expected that LLMs have the\n\npotential to succeed in this task. However, it is completely unclear how the generated programs perform in terms of\n\ngas-consumption \u2013 as mentioned, a critical property for SCs \u2013 and maintainability.\n\nIn this study, we aim to fill this gap by systematically evaluating the capabilities of a set of LLMs in generating Solidity\n\nSCs from natural language descriptions. Our objective is not only to understand to what extent correct SCs can be\n\ngenerated, but also to assess how gas-efficient and maintainable such generated programs are. To this aim, we test four\n\nstate-of-the-art LLMs, covering both closed- and open-source ones, namely ChatGPT-4o, Gemini 1.5 Flash, CodeLlama,\n\nand DeepSeek-Coder-v2. We experiment LLMs in two modalities: (i) we use a simple zero-shot prompt in which we\n\nplainly ask those models to generate a Solidity with a given _notice_ ; (ii) we adopt retrieval-augmented generation (RAG)\n\nand provide the model with functionally similar SCs besides the previously-mentioned documentation.\n\nFirst, we measure how closely the generated functions resemble existing implementations across multiple dimensions.\n\n**Code similarity** is assessed via BLEU, structural similarity using Tree Edit Distance (TED) on abstract syntax trees\n\n(ASTs), and semantic similarity through SmartEmbed embeddings [14]. We also assess the **code plausibility** by running\n\nautomatically generated tests, to understand whether, in spite of differences, the generated SCs are _plausible_ solutions.\n\nWe refer to plausiblity since generated contracts require further analysis to ensure that they are fully correct, i.e., if\n\nthese are acceptable to developers [15]. Then, we focus on non-functional properties. We measure the **gas-efficiency**\n\nto understand whether the generated SCs are practically viable solutions and **code complexity** \u2013 evaluated with\n\ncyclomatic and cognitive complexity metrics \u2013 to estimate their maintainability.\n\n1https://docs.soliditylang.org/en/latest/natspec-format.html\n\nManuscript submitted to ACM\n\nBeyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts3\n\nOur results show that, although all evaluated LLMs can produce Solidity functions highly similar to real contracts,\n\ntheir functional plausibility remains limited in the absence of additional context. In a zero-shot setting, LLMs generate\n\n_plausible_ SCs (i.e., for which no test fails) up to 9.09% of the cases with up to 25.53% of correct function\u2019 call output.\n\nWhen using RAG, these percentages reach up to 45.19% and 23.08% with DeepSeek-coder-v2. The gas consumption is\n\nsubstantially lower than the one of manually-written SCs. We observed that RAG substantially improves plausibility\n\nrates and reduces gas consumption, narrowing the gap between generated and reference implementations.\n\nOverall, our study contributes a systematic benchmark of LLM performance on SC generation, considering similarity,\n\ncomplexity, and plausibility, and provides evidence that retrieval-based prompting is a promising direction for improving\n\npractical viability. All data, code, and artifacts involved in our work are available in our **replication package** [16]."}, {"role": "assistant", "content": "**Mechanism:** Large Language Models (LLMs) operate by predicting the next token (code segment) based on learned patterns from vast datasets. Smart Contracts (SCs) are autonomous, self-executing programs on a distributed ledger, where execution incurs a computational cost ('gas'). The central mechanism tested is the LLM's ability to generate Solidity SCs, and then to evaluate these generated contracts against multiple criteria to ensure they are not just syntactically correct but also functionally sound and efficient.\n\n**Explanation:** The study evaluates LLMs for Smart Contract generation. It uses a multi-pronged evaluation: 1. Code Similarity: Measures how much the generated code resembles existing SCs using metrics like BLEU (token overlap, similar to how many words two sentences share), Tree Edit Distance (TED, structural differences in Abstract Syntax Trees, like comparing code's 'skeletons'), and SmartEmbed (vector representations for semantic closeness, like finding code that does the 'same thing' even if written differently). 2. Functional Plausibility: This is assessed by running automated tests against the generated SC, similar to unit tests in traditional programming. If tests pass, the SC is 'plausible.' 3. Non-functional Properties: This involves measuring 'gas-efficiency' (the computational cost of executing the SC on the blockchain, directly impacting transaction fees, analogous to CPU cycles) and 'maintainability' (using metrics like Cyclomatic Complexity for code paths and Cognitive Complexity for human understanding). A key enhancement is Retrieval-Augmented Generation (RAG). This mechanism provides the LLM with relevant, pre-existing SC examples alongside the prompt. This acts like giving a programmer a library of well-tested code snippets, guiding the LLM to generate more accurate and efficient code by leveraging known good patterns and effectively narrowing its generation space."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**3.1** **Methodology**\n\n**3.1.1** **Data Collection**\n\nTable 2: Overview of Data Sources and Models by Modality\n\n**Modality Dataset** **#** **Model** **#** **# Traces**\n\nQwen3 (8B, 14B, 32B) (Yang et al., 2025) 3 31,836\n\nDeepSeek-R1-Distill-Qwen2.5 (1.5B, 7B, 4 42,448\n14B, 32B) (DeepSeek-AI et al., 2025)\n\n**Text** GeneralThought (Taylor, 2024) 10,322\n\nClaimSpect (Kargupta et al., 2025) 290\n\nDeepSeek-R1-Distill-Llama3 (8B, 70B) 2 21,224\n(DeepSeek-AI et al., 2025)\n\nDeepScaleR-1.5B-Preview (Luo et al., 2025) 1 10,612\ns1.1-32B (Muennighoff et al., 2025) 1 10,612\nOpenThinker-32B (Guha et al., 2025) 1 10,612\nDeepHermes-3-Llama-3-8B-Preview 1 10,612\n(Teknium et al., 2025)\n\n**Audio**\n\nDeepSeek-R1 (DeepSeek-AI et al., 2025) 1 10,612\n**Total (Text Data)** **10,612** **Total (Text Models)**"}, {"role": "assistant", "content": "**Mechanism:** The fundamental mechanism is data aggregation via observation and logging. This section describes the process of constructing a training dataset by collecting 'traces' from a diverse set of pre-existing large language models and an audio model. Essentially, it's a form of behavioral cloning or knowledge distillation where the internal processing steps or intermediate reasoning states of powerful 'teacher' models are captured and recorded.\n\n**Explanation:** The core idea is to create a rich, pre-processed knowledge base for a subsequent training task. Instead of generating raw data or training from scratch, they are querying multiple existing, often very large, models (e.g., 8B to 70B parameters) and extracting their 'traces'. Think of each 'trace' as a detailed log entry or a sequence of internal states, much like debugging information or a stack trace in a program, but at a conceptual level of the model's thought process. This data collection phase is like running a massive suite of tests or prompts against each source model and recording not just the final output, but the computational path taken to get there. The diversity in models (different architectures, sizes, and presumed training objectives) ensures a varied dataset, akin to having many different algorithms contribute to a shared problem-solving log. This aggregated 'trace' data then forms a structured input for training a new model, allowing it to learn from the 'reasoning' patterns of multiple sophisticated systems rather than just their final responses."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe Findings section presents a taxonomy of data annotation errors,\nhighlighting their causes and impacts (Figure 2). It also reports\nexpert validation results confirming the taxonomy\u2019s usefulness,\nindustrial relevance, and practical applicability (Section 4.2).\n\n**4.1** **RQ1: Data Annotation Errors, their Types,**\n**Causes and Impacts in AIePS Development**\n\n**(1) Completeness Errors.** This section addresses completeness errors related to both data coverage and the data annotation processes\nthat sustain and verify that coverage over time.\n**(1.1) Attribute Omission:** Missing or incomplete attributes\n( _e.g.,_ colour, state, occlusion, or diversity attributes) leave datasets\ninsufficiently descriptive. As one participant noted, _\u201cAnother issue_\n_is adding proper metadata [attribute]... otherwise, older datasets_\n_become outdated or inconsistent.\u201d_ (ID10) Causes include unclear requirements, annotator fatigue, and lack of validation or schema\nlinkages (ID5\u2013ID10). Such omissions degrade reliability and performance in edge case scenarios.\n**(1.2) Missing Feedback Loop:** This error refers to the absence of a systematic review and refinement process that allows\nrecurring annotation errors to persist across iterations. As highlighted, _\u201cThe most striking aspect missing from this process flow is_\n_the feedback loop... teams cannot adjust their approach during an-_\n_notation, and mistakes get repeated.\u201d_ (ID3) Weak communication,\nrare quality reviews, and tools lacking traceability hinder continuous improvement (ID9\u2013ID18), slowing iterations and degrading\nperception quality. The \u201cMissing feedback loop\u201d is categorised under completeness because it represents a process through which\ncompleteness fails to be achieved or maintained, rather than an\nisolated data issue.\n\n**(1.3) Privacy and Compliance Omission:** This error refers\nto the insufficient enforcement or documentation of privacy and\ncompliance measures during data annotation. Inadequate anonymisation or weak enforcement of GDPR-like policies introduces ethical\nand legal risks. Participants noted, _\u201cEnsuring data privacy... is criti-_\n_cal when dealing with sensitive data,\u201d_ (ID15) and _\u201cGDPR requirements_\n_remain somewhat unclear and there is an inherent risk in misinter-_\n\n_preting these guidelines\u201d_ (ID9). Missing anonymisation tools or audit\n\n1 **[The replication data associated with this study is publicly accessible and](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)**\n**[available online here.](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)**\n\nlogs (ID13\u2013ID18) reduce visual uniformity and trustworthiness. Although \u201cPrivacy and Compliance Omission\u201d primarily relates to\nethical and legal governance, it is included under the completeness\ntheme as it directly influences dataset coverage. Weak enforcement\nor unclear interpretation of privacy requirements often leads to the\nomission of sensitive samples or attributes, thereby reducing the\nrepresentativeness and completeness of annotated data.\n**(1.4) Edge cases /Unforeseen Scenarios Omission:** This error refers to the omission of rare, unexpected, or safety-critical\ncases that fall outside predefined annotation guidelines. Rare or\nunforeseen scenarios are often ignored. One participant explained,\n_\u201cAt the same time, we should acknowledge the existence of unknown_\n_scenarios, particularly edge cases. The challenge with unknown sce-_\n_narios is that we cannot write explicit guidelines for them because they_\n_are unknown.\u201d_ (ID12) Another added, _\u201cAmbiguities arose\u2014whether_\n_a pedestrian on a scooter should be annotated as relevant or not.\u201d_\n(ID6) Missing mechanisms to flag unusual cases (ID8, ID13) limit\nrobustness in safety-critical settings.\n**(1.5) Selection Bias:** Overrepresentation of common conditions ( _e.g.,_ daylight, clear weather) creates unbalanced datasets.\n_\u201cSome projects focus on specific events... this inherently introduces_\n_bias.\u201d_ (ID5) and _\u201cMost datasets capture sunny conditions... models_\n_struggle in rain or at night.\u201d_ (ID18) Lack of planning and diversity\nrequirements (ID14\u2013ID17) reduces model adaptability and fairness.\n**(1.6) Synchronisation \\ Calibration Issues:** This error refers\nto the misalignment or incomplete calibration of multi-sensor systems such as cameras, radar, and LiDAR used during data collection\nand annotation. Misaligned or unsynchronised sensors produce\nannotation drift. As noted, _\u201cYou need to synchronise sensors so that_\n_data points align in time and space... otherwise, they show up in_\n_different places.\u201d_ (ID10) Missing timestamp checks and calibration\nmetadata (ID16\u2013ID18) reduce precision in multi-sensor fusion.\n**(2) Accuracy Errors.** Under this theme, we address both procedural and data related factors contributing to accuracy errors. We\nare adopting a holistic life cycle perspective rather than a purely\ndata-centric view.\n\n**(2.1) Wrong Class Label:** This error refers to the incorrect\nassignment of semantic categories to objects or scenes, where visually or contextually similar instances are labelled under the wrong\nclass. Misclassifications occur when annotators confuse similar\ncategories. _\u201cIn autonomous driving, you have different classes of vehi-_\n_cles....OK, this is a car, this is a truck, this is a van ... different people_\n_might annotate the same object differently.\u201d_ (ID18) Ambiguous class\nboundaries, annotator fatigue, and poor validation (ID2\u2013ID7) lead\nto noisy supervision and degraded model reliability.\n**(2.2) Bounding Box Errors:** This error refers to inaccurate,\ninconsistent, or corrupted bounding boxes used to localise objects\nin images or sequences. Bounding-box errors arose from weak\nquality assurance tolerances, ambiguous guidelines for occlusions,\nsubjective boundary interpretations, annotator fatigue, and tool\ninstability, causing inconsistent rendering or corrupted coordinate\ndata. One participant shared, _\u201cSome clients insist on pixel-perfect_\n_accuracy like a 10-pixel margin.\u201d_ (ID2) Another added, _\u201cWhen anno-_\n_tating objects... avoid optimistic annotations; underestimating size_\n_causes issues in collision avoidance.\u201d_ (ID12) Missing QA tolerances\nand unstable rendering tools (ID8\u2013ID14) amplify spatial drift and\ntracking instability.\n\n4\n\nData Annotation Quality Problems in AI-Enabled Perception System Development,,\n\n_Causes:_ unclear schema; fatigue; weak validation/schema links.\n\n**Attribute omission**\n\n_Effects:_ missing attributes; poorer descriptiveness; brittle edge-case performance.\n\n_Causes:_ no review/traceability; weak comms; rare QA.\n\n**Missing feedback loop**\n\n_Effects:_ recurring errors; slow improvement; degraded accuracy.\n\n_Causes:_ absent anonymisation; unclear GDPR; no audit logs.\n\n**Privacy/compliance omissions**\n\n_Effects:_ legal/ethical risk; unusable data; trust erosion.\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-4-0.png)\n\n_Causes:_ no rare-case flagging/triage; incomplete guideline coverage.\n\n_Effects:_ poor robustness in safety-critical events; long-tail failures.\n\n_Causes:_ over-sampling typical scenes; no diversity plan.\n\n_Effects:_ unfairness; domain-shift fragility; low adaptability.\n\n_Causes:_ unsynchronised sensors; missing timestamps/calib metadata.\n\n_Effects:_ spatial/temporal drift; weak multimodal fusion precision.\n\n_Causes:_ ambiguous class boundaries; fatigue; limited QA.\n\n_Effects:_ noisy supervision; misclassifications; lower reliability.\n\n_Causes:_ weak QA tolerances; subjective edges; tool instability.\n\n_Effects:_ localisation drift; tracking instability; collision-risk errors.\n\n_Causes:_ outdated/misaligned taxonomy; inconsistent detail levels.\n\n_Effects:_ poor interoperability/transfer; biased feature learning.\n\n_Causes:_ vague/incomplete docs; no versioning; limited feedback.\n\n_Effects:_ high IAA variance; rework; reduced model reliability.\n\n_Causes:_ unbalanced data; automation over-trust; cognitive bias.\n\n_Effects:_ systemic skew; fairness/trust issues; bias propagation.\n\n_Causes:_ subjective judgements; ambiguous rules; limited QA cycles.\n\n_Effects:_ label noise; low dataset reliability; reconciliation cost.\n\n_Causes:_ unclear/contradictory/overlong guidelines; missing context.\n\n_Effects:_ divergent interpretations; delays; more rework.\n\n_Causes:_ poor comms of downstream goals; limited onboarding.\n\n_Effects:_ misaligned relevance; inconsistent boundaries/coverage.\n\n_Causes:_ under-documented transitions; multi-vendor rule drift.\n\n_Effects:_ fragmented datasets; post-hoc harmonisation needs.\n\n_Causes:_ scarce QA automation; no traceability/versioned checks.\n\n_Effects:_ undetected errors; weak reproducibility; instability.\n\n_Causes:_ no shared ontology/benchmarks; uneven standard adoption.\n\n_Effects:_ inconsistency; poor comparability; limited reuse.\n\n_Causes:_ calibration/sync gaps; weak 3D\u21922D projection validation.\n\n_Effects:_ distorted alignment; degraded fusion; tracking errors.\n\n**Edge/unforeseen scenarios**\n\n**Selection bias**\n\n**Synchronization issues**\n\n**Wrong class label**\n\n**Bounding-box errors**\n\n**Granularity mismatch**\n\n**Insufficient guidance**\n\n**Bias-driven errors**\n\n**Inter-annotator disagreement**\n\n**Ambiguous instructions**\n\n**Lack of purpose knowledge**\n\n**Misaligned hand-offs**\n\n**Limited review & logging**\n\n**Lack of frameworks/standards**\n\n**Cross-modality misalignment**\n\n**Figure 2: Taxonomy of data annotation errors in AI-enabled perception systems, organised into three main categories: Com-**\n**pleteness, Accuracy, and Consistency.**\n\n**(2.3) Granularity Mismatch:** This error refers to inaccuracies in the level of annotation detail, either overly fine-grained or\noverly coarse, relative to the intended schema or perception task.\nMisalignment between annotation detail and schema depth leads\nto inconsistency. _\u201cIf the requirement specifies capturing the entire_\n_head but annotators only mark facial features, this introduces bias.\u201d_\n\n(ID8) and _\u201cWe used a taxonomy... it didn\u2019t include trams... the tax-_\n_onomy was from the US.\u201d_ (ID17). Outdated taxonomies (ID9, ID18)\nreduce dataset interoperability and model transferability. Inconsistent levels of detail, such as incomplete object coverage or missing\n3D dimensions (ID8, ID18), impair model calibration and feature\n\n5\n\n,, Saeeda et al.\n\nlearning, ultimately degrading recognition accuracy and the ability\nof AIePS to adapt across diverse operational domains.\n**(2.4) Insufficient Guidance:** This error refers to vague, incomplete, or ambiguous annotation guidelines that fail to provide\nclear operational instructions for annotators. Unclear and incomplete annotation guidelines lead to subjective interpretation. _\u201cIf_\n_annotators are given vague guidelines... they may not annotate con-_\n_sistently.\u201d_ (ID2) and _\u201cInitially, it wasn\u2019t clear how to annotate in_\n_cases where visibility was poor.\u201d_ (ID5) Insufficient guidance resulted\nfrom incomplete documentation of quality criteria, ambiguous or\nevolving rules, limited annotator expertise and feedback, and tool\nlimitations such as missing guideline prompts, version control, and\ntraceability to design goals. Ambiguous or incomplete annotation\nguidelines increase inter-annotator variability, introduce systematic\nnoise, and weaken label consistency, ultimately reducing model accuracy, reliability, and trust in AIePS (ID5, ID6, ID7, ID16). Although\n\u201cInsufficient Guidance\u201d stems from process or documentation shortcomings, it is classified as an accuracy error because it directly\nleads to incorrect or suboptimal labelling. Ambiguous or evolving\nguidelines cause misinterpretations, class confusion, and boundary\nerrors, systemic sources of inaccuracy rather than mere procedural\nflaws. While \u201cInsufficient guidance\u201d can also lead to inter-annotator\nvariability ( _e.g.,_ consistency errors), it is primarily categorised under\naccuracy because the root cause lies in inadequate or ambiguous\nannotation instructions that lead annotators to produce incorrect\nor imprecise labels relative to the intended ground truth.\n**(2.5) Bias-Driven Errors:** This error refers to systematic deviations in annotation outcomes caused by human, contextual, or\nautomation-induced biases that distort the accurate representation of real-world phenomena. Systematic deviations arise from\ncognitive or automation-induced bias. _\u201cSubsets systematically mis-_\n_labeled (e.g.,., red cars)... supervisors might have interpreted dif-_\n_ferently.\u201d_ (ID2) and _\u201cAutomation tools rubber-stamped labels... an-_\n_notators over-trusted tool outputs.\u201d_ (ID6) Bias-driven errors arose\nfrom unbalanced datasets, misaligned taxonomies, and overreliance\non automated labelling, compounded by human cognitive biases,\nautomation overtrust, and inconsistent quality assurance, which\nreinforced systemic data skew and unfairness (ID9, ID11, ID15).\nOverreliance on automated pre-labelling and unbalanced samples\n(ID8\u2013ID15) propagates bias into perception models, harming fairness and trustworthiness.\n\n**(3) Consistency Errors.** Under this theme, we cover both\nprocedural and data oriented consistency errors. While accuracy\nconcerns whether a label is correct with respect to a known ground\ntruth, consistency concerns whether multiple annotators or tools\nwould label the same instance in the same way.\n**(3.1) Inter-Annotator Disagreement:** This error refers to the\nvariation in labels assigned by different annotators to the same data\ninstance, caused by subjective judgments, ambiguous guidelines,\nor inconsistent interpretation, resulting in annotation noise and\nreduced dataset reliability. As one participant emphasised, _\u201cYes,_\n_consensus is essential. If multiple annotators work on the same data,_\n_their outputs should align to ensure accuracy.\u201d_ (ID1) Another added,\n_\u201cDifferent annotators ... they will subjectively annotate the object_\n_depending on distance or shape ... then we need a second person_\n_to correct this.\u201d_ (ID18) Human judgment variability, vague definitions of relevance or environmental context (ID3, ID6\u2013ID7), and\n\ncost-driven limits on extensive review cycles (ID9, ID15) increase\nannotation noise and reduce dataset reliability, requiring additional\nreconciliation efforts before model training.\n**(3.2) Ambiguous Instructions:** This error refers to unclear,\ncomplex, or contradictory annotation guidelines that cause annotators to interpret labelling rules differently, leading to inconsistent\nannotations and reduced data quality. One expert explained, _\u201cClients_\n_often provide guidelines, but we frequently revise them to improve_\n_efficiency. I advocate for simplification annotators should not have_\n_to read 140 pages to understand the guidelines.\u201d_ (ID2) Similarly, another observed, _\u201cDetermining which pedestrians are \u2018relevant\u2019 was_\n_unclear; guidelines did not define it strictly, leading to divergent [in-_\n_consistent] interpretations.\u201d_ (ID6) Ambiguous instructions, such as\novercomplicated or overly descriptive guidelines (ID1\u2013ID3, ID5),\nmissing contextual criteria ( _e.g._, occlusions, lighting, traffic density) (ID7\u2013ID9), lack of communication channels for clarifications\n(ID13), and unrealistic attempts to eliminate all ambiguity without\niterative updates (ID16) amplify disagreement and rework, as annotators interpret rules differently under time pressure or limited\nsupervision.\n**(3.3) Lack of Purpose Knowledge:** This error refers to annotators\u2019 limited understanding of the dataset\u2019s intended use or\ndownstream model goals, leading to misaligned labelling decisions\nand inconsistent relevance judgments. Annotators often lack awareness of the dataset\u2019s end-use, leading to divergent judgments and\ninconsistent relevance assessments. As one participant stated, _\u201cThe_\n_annotators sometimes don\u2019t understand why they are annotating cer-_\n_tain things or how it ties into the overall purpose. They often say, \u2018If we_\n_knew what this was supposed to train for, we could do it better.\u2019\u201d_ (ID4)\nAnother noted, _\u201cRequirements pass through multiple stakeholders,_\n_and annotators often don\u2019t know the true purpose of labelling. This_\n_loss of context leads to inconsistent quality.\u201d_ (ID6) Poor communication of downstream objectives (ID8, ID11), insufficient domain\nexpertise (ID12), and limited onboarding for new annotators result\nin inconsistent boundary choices, missing edge-case handling, and\nreduced overall alignment with model requirements.\n**(3.4) Misaligned Hand-offs:** This error refers to inconsistencies and information loss that occur when annotation tasks, requirements, or guidelines are transferred between teams or stakeholders\nwithout proper documentation or communication, resulting in fragmented, inconsistent datasets. Inconsistencies often emerge during\ntransitions between client, QA, and annotation teams. _\u201cOEMs define_\n_requirements, but these may not be directly shared with suppliers._\n_By the time they reach annotators, the instructions are incomplete or_\n_altered, creating inconsistencies.\u201d_ (ID6) Another participant added,\n_\u201cIf a team does annotation internally instead of outsourcing, they_\n_might not document it properly. Instead, they\u2019ll convey details in_\n_meetings, and that information can be very temporary, easily for-_\n_gotten.\u201d_ (ID11) Under-documented communication, missing shared\ntracking tools, and inconsistent rule interpretation across multiple\nvendors (ID4\u2013ID6, ID8, ID11, ID14) lead to fragmented datasets and\nrequire post-hoc harmonisation to ensure uniformity before model\ndeployment.\n**(3.5) Limited Review & Logging:** This error refers to the\nabsence of consistent quality checks and detailed record keeping\nduring the annotation process, which prevents error detection,\ntraceability, and reproducibility of annotation decisions. Scarce QA\n\n6\n\nData Annotation Quality Problems in AI-Enabled Perception System Development,,\n\nresources and weak process traceability leave inconsistencies undetected. One participant explained, _\u201cGiven the vast data, manual_\n_review is not economically viable. With too few QA resources, errors_\n_remain undetected.\u201d_ (ID6) Another added, _\u201cAnnotation companies_\n_rely on manual reviewing ... they said they want 95% accuracy, but_\n_it was all done manually ... automated QA was lacking.\u201d_ (ID18) Insufficient automated validation (ID10, ID13), limited sampling or\ninter-annotator agreement checks (ID14\u2013ID17), and high costs of\nindependent verification (ID15\u2013ID16) result, corrupted or inconsistent labels ( _e.g.,_ ., bounding-box drift or missing objects) . These\nerrors propagate into training data, lowering model stability and\ngeneralisation.\n**(3.6) Lack of Frameworks and Standards:** This error refers\nto the absence of unified annotation protocols, ontologies, or benchmarking criteria across projects or organisations, leading to inconsistent practices, poor comparability, and reduced reproducibility\nof annotated datasets. The absence of shared annotation standards\n\nor tool benchmarks leads to inconsistent practices across organisations. One participant summarised, _\u201cOne of the biggest challenges is_\n_the lack of standardisation in the annotation market... It is difficult to_\n_compare different annotation providers because there is no universal_\n_benchmark.\u201d_ (ID3) Similarly, another noted, _\u201cThere is no common_\n_standard ... every company follows their own guideline ... sometimes_\n_datasets lack information about how annotations were done.\u201d_ (ID18)\nMissing international standards (ID6, ID9, ID13), inconsistent adherence to ISO/UNECE guidelines (ID10, ID15), and incomplete\ndocumentation in datasets limit comparability, benchmarking, and\nreproducibility across AIePS.\n**(3.7) Cross-Modality Misalignment:** This error refers to\nspatial or temporal inconsistencies between annotations across\ndifferent sensor modalities ( _e.g.,_ camera, LiDAR, radar), caused by\ncalibration errors or synchronisation gaps, leading to inaccurate\ndata fusion and degraded perception performance. Misalignment\nbetween sensor modalities ( _e.g.,_ ., camera\u2013LiDAR\u2013radar) results in\ninconsistent spatial annotations. As one participant highlighted,\n_\u201cWhen multiple sensors record the same scene, they need to be regis-_\n_tered together... You need calibration to make sure they align.\u201d_ (ID10)\nAnother added, _\u201cWe projected annotations from point cloud onto_\n_the image plane and checked alignment... sometimes the projection_\n_didn\u2019t capture the object correctly.\u201d_ (ID18) Temporal sampling differences (ID13, ID17), inadequate calibration protocols (ID9\u2013ID10),\nand missing 3D-to-2D projection validation distort object positioning and tracking accuracy across modalities, impairing fusion-based\nperception and sensor reliability.\n\n**4.2** **RQ2: Experts\u2019 Validation of the Data**\n**Annotation Errors Taxonomy**\n\n**Validation Purpose and Scope.** The validation focused on confirming the accuracy, relevance, and industrial applicability of the\nidentified error categories rather than generating new data. Thats\nthe reason the validation involved four experts (1 OEM, 1 Tier1, 2 Tier-2); these participants were senior practitioners directly\ninvolved in data annotation governance and quality assurance,\nselected for their domain expertise and cross-organisational perspective. While all experts were based in European automotive\ncontexts, their organisations operate globally, ensuring exposure\n\nto international standards and practices. This confirmatory and\ntriangulated approach, grounded in design science and empirical\nsoftware engineering principles [14, 30], ensured the taxonomy\u2019s\npractical relevance and completeness within real-world annotation workflows. The aim of this validation was depth and expert\ntriangulation rather than statistical generalisation.\n**Validation Approach.** Experts reviewed the data annotation\nerror taxonomy using a structured questionnaire covering four\ndimensions: (1) their background and experience in annotation\nworkflows, (2) the taxonomy\u2019s usefulness and relevance, (3) its\nclarity, categorisation, and improvement areas, and (4) its practical\napplicability within supply chain processes. This systematic design\nensured a balanced evaluation of both conceptual soundness and\nindustrial usability (see \u2192 [Structured Validation Questions). The](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n(Table 2) shows details of the complete validation responses.\n**(1) Expert Profiles: Starting Questions (Q1\u2013Q4).** The validation involved experts, including a System Safety Expert (OEM),\nMachine Learning Engineer (Tier-1), Director of Customer Services\n(Tier-2), and Perception Expert (Tier-2). Each possessed 4\u02d85 years of\nexperience in annotation workflows and AIePS development, with\ndirect roles in data collection, annotation, and AI system integra\ntion.\n\n**(2) Usefulness, Relevance, and Applicability (Q5\u2013Q16).**\nAcross all experts, the taxonomy was perceived as highly relevant,\npractical, and directly applicable within industrial settings for structuring, diagnosing, and improving data annotation workflows.\n\n  - The **OEM system safety expert** viewed the taxonomy as a\n_\u201cfailure-mode catalogue\u201d_ analogous to FMEA (Failure Mode and Effects Analysis), helping identify and trace data-related weaknesses\nin perception-system development. It was considered particularly\nvaluable for root-cause analysis, supplier quality reviews, and training of perception validation teams. The expert also noted that it\nsupports the diagnosis of perception failures ( _e.g.,_ inconsistent object recognition or missed detections) and facilitates cross-team\ncommunication among the safety, perception, and data quality\n\nunits.\n\n  - The **Tier-** 1 **ML engineer** described the taxonomy as a practical _\u201cchecklist\u201d_ for setting up new annotation pipelines, reviewing\nguidelines, and validating existing annotation processes. It was\nalso seen as a \u201ccheat sheet\u201d for systematically verifying completeness, identifying recurring issues, and ensuring that all major error\nsources are considered during the design or revision of data annotation workflows.\n\n  - The **Tier-** 2 **director of customer services and perception**\n**expert** emphasised that the taxonomy supports _\u201csystematic analyt-_\n_ics of annotation errors\u201d_ and improves _\u201conboarding for new projects.\u201d_\nThey found it particularly useful for structuring internal quality\nassurance (QA), facilitating client discussions, and aligning understanding between annotation providers and customers. Perception\nexpert further highlighted its potential as onboarding material for\nnew employees and clients, and as a reference during guideline\noptimization and annotation tool configuration.\n**(3) Reflection on Clarity, and Improvements (Q9\u2013Q12).**\nAll experts agreed that the three overarching quality dimensions,\ncompleteness, accuracy, and consistency, effectively capture the\nmain data quality challenges observed in industrial contexts. The\nOEM noted that these dimensions align with established quality\n\n7\n\n,, Saeeda et al.\n\n**Table 2: Expert validation outcomes, industrial utility, and implications for the taxonomy of data annotation errors**\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-7-0.png)\n\n**Usefulness** High relevance for structuring and\ndiagnosing annotation failures;\nrecognised as a cross-industry\nquality reference.\n\n**Practical Experience** The taxonomy is clear and comprehensive, suggesting the merging of\noverlapping categories.\n\n**Relevance** Consensus on three dimensions:\ncompleteness, accuracy, and\nconsistency, aligned with ISObased quality standards.\n\n**Suggestions** Encouraged merging sub-items,\nsimplifying structure, and adding\nquantitative risk indicators.\n\n_\u201cTier-2: Add a risk-assessment_\n_matrix linking severity and proba-_\n_bility.\u201d_\n\n_\u201cOEM: Use for checking perception-_\n_system root causes.\u201d_\n_\u201cTier-1: Cheat sheet for reviewing_\n_annotation processes.\u201d_\n\n_\u201cOEM: Can be used as a failure-_\n_mode catalogue.\u201d_\n_\u201cTier-1: Helpful when setting up_\n_new annotation pipelines.\u201d_\n_\u201cTier-2: Useful as a checklist and for_\n_systematic analytics.\u201d_\n\n_\u201cTier-2: Human vs automation not_\n_enough\u2014add tool and guideline_\n_causes.\u201d_\n\n_\u201cOEM: These are the same dimen-_\n_sions we face daily.\u201d_\n\nValidated taxonomy\u2019s generalisability; retained as a framework\nfor audits and supplier quality\nreviews.\n\nExpanded causes to include \u201ctoolrelated\u201d and \u201cguideline-related\u201d\nerror types.\n\nMaintained three main categories;\nclarified overlaps through refined\ndefinitions.\n\n**Strengthens QA traceability.**\nEnables structured failure\ndiagnosis and cross-team\nquality review.\n\n**Improves clarity of defect**\n**reporting.** Supports consistent\nerror documentation across\n\nannotation teams.\n\n**Ensures interpretability in**\n**audits.** Aligns with existing\nindustry QA frameworks.\n\n**Enables risk-based prioriti-**\n**sation.** Supports safety-critical\nassessment of annotation errors.\n\n**Suggestions** Encouraged merging sub-items, _\u201cTier-2: Add a risk-assessment_ **Enables risk-based prioriti-** Planned extension of taxonomy\nsimplifying structure, and adding _matrix linking severity and proba-_ **sation.** Supports safety-critical with severity\u2013frequency mapping\nquantitative risk indicators. _bility.\u201d_ assessment of annotation errors. (akin to FMEA scoring).\n\n**Use Case Scenarios** Realistic applications include _\u201cOEM: Use for checking perception-_ **Enhances training and** Evidence of immediate applicabiltraining, QA reviews, and root- _system root causes.\u201d_ **collaboration.** Standardises ity; supports integration into QA\ncause analysis. _\u201cTier-1: Cheat sheet for reviewing_ terminology across suppliers tools and training programs.\n\n**Enhances training and**\n**collaboration.** Standardises\nterminology across suppliers\nand OEMs.\n\nEvidence of immediate applicability; supports integration into QA\ntools and training programs.\n\n**Supports model reliability**\n**and safety.** Enables early identification of critical annotation\nfaults.\n\n**Errors and Integration** Systematic mislabelling, vague instructions, and missing edge cases\nare considered most damaging.\n\n_\u201cTier-2: Systematic errors lead_\n_to ML models learning incorrect_\n_patterns.\u201d_\n\nPrioritised these error types in\nthe final taxonomy; marked as\nhigh-severity recurrent issues.\n\nand safety standards such as ISO 21448, while the Tier-1 expert\nemphasised simplifying and consolidating categories to facilitate\nadoption, a recommendation incorporated into the final taxonomy\nrefinement. Tier-2 experts proposed distinguishing more clearly\nbetween human-, automation, and tool-induced errors, which informed the cause impact grouping in our analysis. Collectively,\nexperts encouraged extending the taxonomy through studies of\nreal-world failure cases and linking each error type with measurable\nseverity indicators such as frequency or safety impact.\n**(4) Preliminary Risk Categorization of Errors** . The experts\nconsistently emphasised high-risk errors such as systematic mislabeling, incomplete or edge-case omissions, inconsistent annotations,\nand schema mismatches, all of which align with the taxonomy\u2019s 18\ncore errors. In contrast, several low-frequency but practically significant errors also emerged, including cross-modality misalignment,\nlow-quality pre-annotations, limited feedback loops, and human\nfatigue. While less frequently mentioned, these emergent cases\nreveal evolving challenges arising from automation, organisational\nconstraints, and human variability, indicating where future quality\n[assurance efforts and process improvements should focus. (see: \u2192](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n[Table 3- Expert Classification of Annotation Errors by Risk Level.)](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)"}, {"role": "assistant", "content": "**Mechanism:** The paper provides a hierarchical diagnostic framework, dissecting data annotation quality into three core failure domains: completeness, accuracy, and consistency. Each domain is further broken down into specific error types, identifying their causes and consequences. This is fundamentally a structured method for defect classification and root-cause analysis within the 'data layer' of an AI system, validated through expert empirical review to confirm its practical utility in real-world scenarios.\n\n**Explanation:** Think of data annotation as creating the ground-truth test suite for an AI model. 'Completeness Errors' are analogous to missing test cases in your suite; for example, 'Attribute Omission' is like a database schema lacking a critical field, or 'Selection Bias' is having unit tests only for sunny weather conditions, leaving your system vulnerable in rain. 'Accuracy Errors' mean your test cases themselves are flawed. 'Wrong Class Label' is a unit test asserting 'expected = car' when it should be 'expected = truck', while 'Insufficient Guidance' is like a vague API specification causing developers to implement functions inconsistently. 'Consistency Errors' refer to variability in how tests are written or interpreted. 'Inter-Annotator Disagreement' is when two developers write tests for the same functionality but use different criteria, leading to conflicting results. 'Lack of Purpose Knowledge' is developers implementing features without understanding the user story, leading to a technically correct but functionally misaligned solution. The validation confirms this taxonomy effectively identifies the 'bugs' in the data generation process, similar to how a robust debugging framework helps engineers pinpoint code defects. It's a systematic approach to ensuring the 'training data' component of an AI system adheres to quality standards."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**1**\n\n1.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n\n1.2 Technical Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n1.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8"}, {"role": "assistant", "content": "**Mechanism:** These are structural components of a research paper designed to progressively introduce the reader to the context, core ideas, and comparative landscape.\n\n**Explanation:** The 'Preliminaries' section is crucial for establishing a common ground of definitions, notation, and foundational concepts, much like declaring variables and helper functions at the beginning of a program to ensure consistency and reduce ambiguity throughout the code. The 'Technical Overview' serves as a high-level architectural diagram, explaining the major components and their interactions without diving into granular implementation details. It's akin to a system design document or an API contract, showing the 'what' and 'how' at a conceptual level. 'Related Work' provides a critical survey of existing solutions, highlighting their limitations and positioning the current paper's contribution within the broader field. This is like performing a market analysis of existing software libraries or algorithms to understand their strengths and weaknesses before developing a new one, ensuring novel contributions and avoiding re-inventing the wheel unnecessarily."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**38**\n\n6.1 The lower bound instance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n6.2 Introducing potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Two-phase analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n6.4 Further improvement: Limiting the number of combinations . . . . . . . . . . . . . . . . . 41\n6.5 The final piece: Potential decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves using a potential function to distribute the cost of expensive operations over a sequence of cheaper ones, essentially 'pre-paying' for future work or tracking a measure of 'disorder' within a system.\n\n**Explanation:** This section outlines a strategy for analyzing and improving an algorithm's efficiency, likely in an amortized sense. It starts by setting a fundamental benchmark, a 'lower bound' (6.1), representing the theoretical minimum effort required. The crucial step is 'introducing potential' (6.2): this is like having a dynamic 'energy reserve' associated with the system's state. Cheap operations might increase this reserve, while expensive operations might deplete it. By adding the change in this reserve to the actual cost, we get an 'amortized' cost that's often much lower and more consistent than peak actual costs. This is similar to how a `credit_balance` variable might track resource availability across different functions. The 'two-phase analysis' (6.3) suggests dividing the algorithm's execution into distinct stages, perhaps like different phases of a program's execution, allowing for specialized analysis or different potential functions for each phase. 'Limiting the number of combinations' (6.4) is a direct optimization technique, akin to using a hash set to store seen states or a filter to prune invalid branches in a search algorithm, preventing redundant or impossible computations. Finally, 'potential decomposition' (6.5) implies breaking down a complex global potential function into several simpler, local functions, each tracking a specific aspect. This is like decomposing a large problem into smaller sub-problems, each with its own simple counter or metric, making the overall analysis more manageable and robust."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis study presents a structured taxonomy of 18 data annotation\nerrors in AI-enabled automotive perception, integrating theoretical\n\n8\n\nData Annotation Quality Problems in AI-Enabled Perception System Development,,\n\ndata-quality concepts with industrial insights. Grounded in the\ndimensions of completeness, accuracy, and consistency.\n**Data Annotation Errors and the State of the Art.** Com\npleteness errors capture the underrepresentation of critical driving scenarios and incomplete information capture in perception\ndatasets [1, 38]. Traditional issues such as _edge-case omissions_, _se-_\n_lection bias_, and _attribute omission_ align with known \u201clong-tail\u201d\nchallenges [3, 15, 17]. Yet, our taxonomy extends this view by introducing novel dimensions such as _privacy/compliance omissions_, _miss-_\n_ing feedback loops_, and _sensor synchronisation issues_ [7, 29, 36, 41].\nThese additions highlight that completeness is not merely a matter\nof dataset size but of regulatory, temporal, and multimodal adequacy across sensors and stakeholders. The Figure 3 highlights\nthe most frequently mentioned completeness-related errors in the\nstudy. Missing feedback loop and selection bias were the most common issues, followed by edge/unforeseen scenarios. Less frequent\nbut notable errors included attribute omission, privacy/compliance\nomissions, and calibration/synchronization issues. Overall, the findings suggest that systemic gaps, particularly in feedback and data\nselection, are the main contributors to completeness errors.\n\n**Figure 3: High mentioned completeness errors.**\n\nAccuracy errors represent distortions between the intended\nground truth and the final annotation. Common cases such as _wrong_\n_class labels_, _bounding-box errors_, and _granularity mismatches_ remain\nfrequent causes of label noise [18, 25, 32]. At the same time, industrial evidence revealed human automation interaction issues\n\n_automation over trust_, _insufficient guidance_, and _lack of calibration_\n_feedback_ that amplify inaccuracies through over-reliance on automated pre-labelling tools [3, 29, 39]. These findings bridge technical\nand socio-organisational sources of label errors, showing that accuracy degradation often stems from both data limitations and human\ndecision making biases. Figure 4 presents the most frequently mentioned accuracy related errors in the study. Insufficient guidance\nwas the most commonly reported issue, followed by bounding box\nerrors and wrong class labels, each occurring frequently. Bias driven\nerrors were also notable, while granularity mismatch appeared less\noften. Overall, the findings suggest that accuracy problems stem\nlargely from unclear annotation instructions and technical labelling\ninconsistencies, underscoring the need for clearer guidelines and\nimproved annotation precision.\nConsistency errors denote deviations in labelling uniformity\nacross annotators, projects, and modalities [3, 17, 35]. While inconsistent instructions and inadequate calibration remain established\nconcerns, our taxonomy identifies process-level consistency failures\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-8-0.png)\n\n**Figure 4: High mentioned accuracy errors.**\n\nunique to distributed industrial pipelines such as _misaligned hand-_\n_offs_, _cross-modality misalignment_, and lack of _standardisation frame-_\n_works_ [4, 36, 41]. Many of these issues stem from socio-technical\nmisalignments, including ambiguous guidelines, workload variability, and lack of motivational factors and annotator fatigue [3, 24].\nAddressing such issues thus requires not only better annotation\ntools but also systematic processes such as feedback loops, clearer\norganisational responsibilities, and continuous cross-team calibration. As shown in the Figure 5, ambiguous instructions were the\nmost frequently reported consistency-related error in our study,\nfollowed by inter-annotator disagreement and lack of frameworks\nor standards. Other notable issues, such as misaligned hand-offs\nand limited review and logging, point to process level errors, while\nlack of purpose knowledge and cross-modality alignment appeared\nless often but remain relevant. We observed that annotation incon\nsistency arises from both human variability and systemic gaps in\nprocess standardisation and guidance.\n\n**Figure 5: High mentioned consistency errors.**\n\n**Data Annotation Errors and Quality Degradation.** The\nstudy demonstrates that annotation errors are not random or isolated incidents but systemic drivers of downstream quality degradation in perception models. Completeness errors, such as missing feedback loops or edge case omissions, reduce dataset representativeness and weaken model generalisation [1, 38]. Accuracyrelated errors, including mislabeling, bounding-box misplacement,\nand granularity mismatches, distort learning signals and reduce\npredictive reliability [3, 17, 25]. Likewise, consistency issues from\ninter-annotator disagreement to cross-modality misalignment introduce latent noise that propagates through training and deployment [15, 24]. Together, these defects can cascade throughout the AI\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-8-1.png)\n\n9\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-8-2.png)\n,, Saeeda et al.\n\nlifecycle, undermining performance in safety-critical metrics such\nas false positives, missed detections, and perception uncertainty.\nGrounded in the established principles of _completeness_, _accuracy_,\nand _consistency_ [2, 27, 37], the taxonomy operationalises abstract\ndata-quality constructs into concrete, auditable categories. This provides a data-centric assurance foundation aligned with the broader\ntrustworthy-AI agenda, emphasising traceability, explainability, and\ngovernance in line with EU and ISO standards.\n**Emergent Low-Frequency Annotation Errors.** Beyond the\n18 high-frequency error types, our analysis also revealed several\nlow-frequency but practically significant error types across the\ncompleteness, accuracy, and consistency dimensions. From a completeness perspective, these low-mention cases point to partial\nor uneven data coverage, including missing modalities, skipped\nframes, and restrictive dataset curation driven by technical, legal,\nor organisational constraints [29, 36, 38, 41]. We also found automation related omissions, for instance, when foundation models\noverlook rare or privacy sensitive instances and quality lapses\nsuch as incomplete pre-annotations or malfunction induced data\nloss [3, 39]. For accuracy, the low-frequency issues reflect small\nspatial or temporal misalignments, hybrid or automated labelling\nerrors, and human factors such as fatigue, bias, and overreliance\non automation [18, 24, 25, 32, 34, 38]. Even minor inaccuracies in\nannotation precision can propagate through training pipelines, degrading perception reliability. Under consistency, low-frequency\ncases reveal gradual or structural drifts in annotation uniformity\nacross projects or over time [3, 17]. These arise from evolving\nguidelines, automation carryover errors, and mismatches between\nannotators\u2019 understanding and supervisors\u2019 expectations [34, 39].\nVariations in workload, motivation, and team calibration, along\nwith limited onboarding or expert oversight, further amplify such\ninconsistencies [8, 24]. Collectively, these low-frequency but conceptually important errors reveal emerging challenges in modern\nannotation pipelines, where automation, organisational constraints,\nand human variability intersect to shape data quality beyond the\ndominant error categories captured in the taxonomy.\n**Industrial Validation and Implications.** Industry experts\nacross OEMs, Tier-1, and Tier-2 suppliers validated the taxonomy\u2019s\nclarity, relevance, and operational value. They characterised it as\na \u201cfailure-mode catalogue\u201d analogous to FMEA, an interpretation\nabsent in prior literature. The taxonomy enables direct traceability\nfrom perception anomalies ( _e.g.,_ ., false positives, missed detections)\nto upstream data defects ( _e.g.,_ ., incomplete coverage, misaligned\nhand-offs). It provides a shared vocabulary for diagnosing whether\nan issue originates from human annotation, automation, or tooling,\nthereby improving cross-tier communication and quality control.\nExperts also recognised its educational value for onboarding, internal QA reviews, and continuous improvement, and suggested\nintegrating it into annotation dashboards to institutionalise a dataquality culture.\n**Trustworthy AI Developemnt and Data Governance Im-**\n**plications.** The data annotation errors taxonomy contributes to\nthe broader trustworthy AI agenda by linking data quality, process transparency, and accountability across the AI systems developemnt lifecycle. It supports traceability of errors from perception\nanomalies to underlying annotation causes, an essential capability for compliance with emerging standards such as ISO/IEC 5259,\n\nIEEE _\ud835\udc43_ 2801, ISO 26262, _\ud835\udc46\ud835\udc34\ud835\udc38\ud835\udc3d_ 3016 lifecycle assurance with these\nframeworks. The taxonomy provides a practical foundation for\ngovernance-by-design, where annotation quality becomes an auditable and traceable element of AI system certification. In doing so,\nit operationalises fairness, transparency, and accountability as measurable engineering properties rather than abstract ethical goals.\n**Implications for the AI-Enabled System Development**\n**Lifecycle.** The taxonomy influences all phases of AI-enabled system development by embedding data quality considerations into\nengineering workflows. During _data collection and curation_, it improves dataset representativeness by identifying completenessrelated gaps. In _annotation and tooling_, it guides workflow design\nto mitigate human\u2013automation drift and reinforce auditability. For\n_model training and evaluation_, it provides traceability between annotation noise and model reliability, informing retraining priorities.\nWithin _verification and validation (V&V)_, it supports safety traceability by linking perception errors to underlying data issues. In\n_requirements engineering_, it formalises data-specific criteria such as\ninter-annotator agreement thresholds, while in _quality assurance_\n_and maintenance_, it establishes a foundation for audits, supplier\nevaluations, and continuous improvement. These cross-cutting implications position the taxonomy as a unifying framework aligning\ndata governance, model assurance, and system level quality management across the AI lifecycle.\n**Implications for Research and Practice.** Beyond AIePS developemnt life cycle integration, the taxonomy also offers broader\nimplications for both research and industrial practice. For research\npurposes, this study establishes an empirically grounded taxonomy\nthat systematises how data annotation errors manifest in the development of AIePS. It highlights the need for future research to\nmove beyond isolated notions of \u201cdata quality\u201d toward integrated\nframeworks linking annotation processes, organisational factors,\nand model performance. The taxonomy can serve as a foundation\nfor quantitative studies measuring the impact of specific error types\non model outcomes, as well as for developing automated tools that\ndetect or predict annotation errors. For practice, the taxonomy\nprovides practitioners with a structured lens for diagnosing and\npreventing quality issues throughout the annotation lifecycle. It\ncan inform the design of quality assurance checklists, onboarding materials, and supplier evaluation criteria, fostering shared\nterminology across OEMs, Tier-1s, and annotation vendors. By\nidentifying high-impact error types such as missing feedback loops,\ninsufficient guidance, and weak quality control organisations can\nprioritise interventions that strengthen both annotation quality and\ngovernance. Moreover, the taxonomy encourages proactive error\nmonitoring and the integration of feedback into existing annotation workflows, enabling continuous improvement. It also supports\ntraceability by linking annotation errors to downstream perception\nfailures, enhancing transparency in safety-critical development.\nFinally, it establishes a conceptual foundation for data governance\nstandards and policy frameworks, ensuring that annotation quality\nis treated as a first-class element of system assurance rather than a\nperipheral task.\n**Future Work.** Future research should expand validation across\ndiverse geographical and industrial contexts to strengthen generalisability. Another critical direction is the development of semiautomated quality assurance systems that apply the taxonomy for\n\n10\n\nData Annotation Quality Problems in AI-Enabled Perception System Development,,\n\nreal-time monitoring, drift detection, and prioritised correction,\nthus enabling continuous data assurance throughout the AI lifecycle. Furthermore, quantitative studies correlating the frequency and\nseverity of specific error types with model performance metrics\nwould deepen understanding of their practical impact. Integrating\nseverity probability matrices, similar to FMEA (Failure Mode and\nEffects Analysis) scoring, can support risk-based prioritisation in\nindustrial annotation workflows. By embedding such automated\nmechanisms into annotation tools and MLOps pipelines, future\nwork can transform the taxonomy from a diagnostic artefact into a\nproactive engineering instrument for lifecycle assurance in SE4AI.\n\n**ACKNOWLEDGMENTS** This research is supported by Vinnova, Program Fordons strategisk Forskning och Innovation (FFI),\nProject FAMER (2023-00771).\n\n**References**\n\n[1] Mrinal R Bachute and Javed M Subhedar. 2021. Autonomous driving architectures:\ninsights of machine learning and deep learning algorithms. _Machine Learning_\n_with Applications_ 6 (2021), 100164.\n\n[2] Carlo Batini, Cinzia Cappiello, Chiara Francalanci, and Andrea Maurino. 2009.\nMethodologies for data quality assessment and improvement. _ACM Computing_\n_Surveys (CSUR)_ [41, 3 (2009), 1\u201352. doi:10.1145/1541880.1541883](https://doi.org/10.1145/1541880.1541883)\n\n[3] Jacob Beck. 2023. Quality aspects of annotated data: A research synthesis. _AStA_\n_Wirtschafts-und Sozialstatistisches Archiv_ 17, 3 (2023), 331\u2013353.\n\n[4] Markus Borg, Jens Henriksson, Kasper Socha, Olof Lennartsson, Elias\nSonnsj\u00f6 L\u00f6negren, Thanh Bui, Piotr Tomaszewski, Sankar Raman Sathyamoorthy, Sebastian Brink, and Mahshid Helali Moghadam. 2023. Ergo, SMIRK is\nsafe: a safety case for a machine learning component in a pedestrian automatic\nemergency brake system. _Software quality journal_ 31, 2 (2023), 335\u2013403.\n\n[5] Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in qualitative\nresearch. _Qualitative Research in Psychology_ 3, 2 (2006), 77\u2013101.\n\n[6] Mario I Chacon-Murguia and Claudia Prieto-Resendiz. 2015. Detecting driver\ndrowsiness: A survey of system designs and technology. _IEEE Consumer Elec-_\n_tronics Magazine_ 4, 4 (2015), 107\u2013119.\n\n[7] Rung-Ching Chen, Vani Suthamathi Saravanarajan, Long-Sheng Chen, and Hui\nYu. 2022. Road segmentation and environment labeling for autonomous vehicles.\n_Applied Sciences_ 12, 14 (2022), 7191.\n\n[8] Harshil Darji, Jelena Mitrovi\u0107, and Michael Granitzer. 2024. Challenges and\nConsiderations in Annotating Legal Data: A Comprehensive Overview. _arXiv_\n_preprint arXiv:2407.17503_ (2024).\n\n[9] Florenc Demrozi, Marin Jereghi, and Graziano Pravadelli. 2021. Towards the\nautomatic data annotation for human activity recognition based on wearables\nand BLE beacons. In _2021 IEEE International Symposium on Inertial Sensors and_\n_Systems (INERTIAL)_ . IEEE, 1\u20134.\n\n[10] Sangeeta Dey and Seok-Won Lee. 2023. A Multi-layered collaborative framework\nfor evidence-driven data requirements engineering for machine learning-based\nsafety-critical systems. In _Proceedings of the 38th ACM/SIGAPP Symposium on_\n_Applied Computing_ . 1404\u20131413.\n\n[11] Teodor Fredriksson, David Issa Mattos, Jan Bosch, and Helena Holmstr\u00f6m Olsson.\n2020. Data labeling: An empirical investigation into industrial challenges and\nmitigation strategies. In _International Conference on Product-Focused Software_\n_Process Improvement_ . Springer, 202\u2013216.\n\n[12] Luiz G Galv\u00e3o and M Nazmul Huda. 2023. Pedestrian and vehicle behaviour prediction in autonomous vehicle system\u2014A review. _Expert Systems with Applications_\n(2023), 121983.\n\n[13] Khan Mohammad Habibullah, Hans-Martin Heyn, Gregory Gay, Jennifer Horkoff,\nEric Knauss, Markus Borg, Alessia Knauss, H\u00e5kan Sivencrona, and Jing Li. 2023.\nRequirements engineering for automotive perception systems: An interview\nstudy. In _International Working Conference on Requirements Engineering: Founda-_\n_tion for Software Quality_ . Springer, 189\u2013205.\n\n[14] Alan R. Hevner, Salvatore T. March, Jinsoo Park, and Sudha Ram. 2004. Design\nScience in Information Systems Research. _MIS Quarterly_ 28, 1 (2004), 75\u2013105.\n[doi:10.2307/25148625](https://doi.org/10.2307/25148625)\n\n[15] Hans-Martin Heyn, Khan Mohammad Habibullah, Eric Knauss, Jennifer Horkoff,\nMarkus Borg, Alessia Knauss, and Polly Jing Li. 2023. Automotive perception\nsoftware development: An empirical investigation into data, annotation, and\necosystem challenges. In _2023 IEEE/ACM 2nd International Conference on AI_\n_Engineering\u2013Software Engineering for AI (CAIN)_ . IEEE, 13\u201324.\n\n[16] Asad J Khattak, Numan Ahmad, Behram Wali, and Eric Dumbaugh. 2021. A\ntaxonomy of driving errors and violations: Evidence from the naturalistic driving\nstudy. _Accident Analysis & Prevention_ 151 (2021), 105873.\n\n[17] Jan-Christoph Klie, Richard Eckart de Castilho, and Iryna Gurevych. 2024. Analyzing dataset annotation quality management in the wild. _Computational_\n_Linguistics_ (2024), 1\u201348.\n\n[18] Christopher Klugmann, Rafid Mahmood, Guruprasad Hegde, Amit Kale, and\nDaniel Kondermann. 2024. No Need to Sacrifice Data Quality for Quantity:\nCrowd-Informed Machine Annotation for Cost-Effective Understanding of Visual\nData. _arXiv preprint arXiv:2409.00048_ (2024).\n\n[19] Frank Kr\u00fcger. 2022. Keynote: Adventures in Annotation: Providing High Quality\nLabels for Supervised Machine Learning. In _2022 IEEE International Conference on_\n_Pervasive Computing and Communications Workshops and other Affiliated Events_\n_(PerCom Workshops)_ . IEEE, 254\u2013254.\n\n[20] Vipin Kumar Kukkala, Jordan Tunnell, Sudeep Pasricha, and Thomas Bradley.\n2018. Advanced driver-assistance systems: A path toward autonomous vehicles.\n_IEEE Consumer Electronics Magazine_ 7, 5 (2018), 18\u201325.\n\n[21] Joseph Maxwell. 1992. Understanding and validity in qualitative research. _Har-_\n_vard Educational Review_ 62, 3 (1992), 279\u2013301.\n\n[22] Maab Mohammedali and Muntasir Adam. 2023. The influence of data annotation process requirements on performance criteria of ML models. _Gothenburg_\n_University Library_ (2023).\n\n[23] Alireza Najafi and Azzedine Boukerche. 2024. On The Performance of Perception\nSystems of Autonomous Vehicles. In _ICC 2024-IEEE International Conference on_\n_Communications_ . IEEE, 5365\u20135370.\n\n[24] Emily \u00d6hman. 2020. Challenges in Annotation: Annotator Experiences from a\nCrowdsourced Emotion Annotation Task.. In _DHN_ . 293\u2013301.\n\n[25] Sarina Penquitt, Jonathan Klees, Rinor Cakaj, Daniel Kondermann, Matthias\nRottmann, and Lars Schmarje. 2025. From Label Error Detection to Correction:\nA Modular Framework and Benchmark for Object Detection Datasets. _arXiv_\n_preprint arXiv:2508.06556_ (2025).\n\n[26] Heinrich Peters, Alireza Hashemi, and James Rae. 2024. Generalizable Error\nModeling for Human Data Annotation: Evidence From an Industry-Scale Search\nData Annotation Program. _ACM Journal of Data and Information Quality_ 16, 3\n(2024), 1\u201315.\n\n[27] Leo L. Pipino, Yang W. Lee, and Richard Y. Wang. 2002. Data quality assessment.\n_Commun. ACM_ [45, 4 (2002), 211\u2013218. doi:10.1145/505248.506010](https://doi.org/10.1145/505248.506010)\n\n[28] Paul Ralph, Nauman bin Ali, Sebastian Baltes, Domenico Bianculli, Jessica Diaz,\nYvonne Dittrich, Neil Ernst, Michael Felderer, Robert Feldt, Antonio Filieri,\nBreno Bernard Nicolau de Fran\u00e7a, Carlo Alberto Furia, Greg Gay, Nicolas Gold,\nDaniel Graziotin, Pinjia He, Rashina Hoda, Natalia Juristo, Barbara Kitchenham, Valentina Lenarduzzi, Jorge Mart\u00ednez, Jorge Melegati, Daniel Mendez,\nTim Menzies, Jefferson Molleri, Dietmar Pfahl, Romain Robbes, Daniel Russo,\nNyyti Saarim\u00e4ki, Federica Sarro, Davide Taibi, Janet Siegmund, Diomidis Spinellis, Miroslaw Staron, Klaas Stol, Margaret-Anne Storey, Davide Taibi, Damian\nTamburri, Marco Torchiano, Christoph Treude, Burak Turhan, Xiaofeng Wang,\nand Sira Vegas. 2020. Empirical Standards for Software Engineering Research.\n[arXiv:2010.03525 [cs.SE] https://arxiv.org/abs/2010.03525](https://arxiv.org/abs/2010.03525)\n\n[29] Federico Ruggeri, Eleonora Misino, Arianna Muti, Katerina Korre, Paolo Torroni, and Alberto Barr\u00f3n-Cede\u00f1o. 2024. Let Guidelines Guide You: A Prescriptive Guideline-Centered Data Annotation Methodology. _arXiv preprint_\n_arXiv:2406.14099_ (2024).\n\n[30] Per Runeson and Martin H\u00f6st. 2009. Guidelines for conducting and reporting\ncase study research in software engineering. _Empirical software engineering_ 14\n(2009), 131\u2013164.\n\n[31] V Samuktha, S Abhilash, Nitish Kumar, and P Rajalakshmi. 2024. A Framework\nfor Object Classification via Camera-Radar Fusion with Automated Labeling. In\n_2024 IEEE Sensors Applications Symposium (SAS)_ . IEEE, 1\u20136.\n\n[32] Marius Schubert, Tobias Riedlinger, Karsten Kahl, Daniel Kr\u00f6ll, Sebastian Schoenen, Sini\u0161a \u0160egvi\u0107, and Matthias Rottmann. 2024. Identifying label errors in\nobject detection datasets by loss inspection. In _Proceedings of the IEEE/CVF Win-_\n_ter Conference on Applications of Computer Vision_ . 4582\u20134591.\n\n[33] Devendra Sharma. 2020. Evaluation and Analysis of Perception Systems for\nAutonomous Driving.\n\n[34] Anting Shen and Forrest Nelson Iandola. 2020. Automated annotation techniques.\nUS Patent 10,872,251.\n\n[35] Gijs van Dijck, Carlos Aguilera, and Shashank M Chakravarthy. 2024. Deciphering\ndisagreement in the annotation of EU legislation. _Artificial Intelligence and Law_\n(2024), 1\u201336.\n\n[36] Marceli Wac, Raul Santos-Rodriguez, Chris McWilliams, and Christopher Bourdeaux. 2023. Capturing requirements for a data annotation tool for intensive\ncare: Experimental user-centered design study. _arXiv preprint arXiv:2309.16500_\n(2023).\n\n[37] Yair Wand and Richard Y. Wang. 1996. Anchoring data quality dimensions in\nontological foundations. _Commun. ACM_ [39, 11 (1996), 86\u201395. doi:10.1145/240455.](https://doi.org/10.1145/240455.240479)\n[240479](https://doi.org/10.1145/240455.240479)\n\n[38] Yuning Wang, Zeyu Han, Yining Xing, Shaobing Xu, and Jianqiang Wang. 2024.\nA survey on datasets for the decision making of autonomous vehicles. _IEEE_\n_Intelligent Transportation Systems Magazine_ (2024).\n\n11\n\n,, Saeeda et al.\n\n[39] Eleanor Watson, Thiago Viana, and Shujun Zhang. 2023. Augmented Behavioral Annotation Tools, with Application to Multimodal Datasets and Models: A\nSystematic Review. _AI_ 4, 1 (2023), 128\u2013171.\n\n[40] Kai Yang, Xiaolin Tang, Jun Li, Hong Wang, Guichuan Zhong, Jiaxin Chen,\nand Dongpu Cao. 2023. Uncertainties in onboard algorithms for autonomous\nvehicles: Challenges, mitigation, and perspectives. _IEEE Transactions on Intelligent_\n\n_Transportation Systems_ (2023).\n\n[41] Ziyuan Zhong, Zhisheng Hu, Shengjian Guo, Xinyang Zhang, Zhenyu Zhong,\nand Baishakhi Ray. 2022. Detecting multi-sensor fusion errors in advanced\ndriver-assistance systems. In _Proceedings of the 31st ACM SIGSOFT International_\n_Symposium on Software Testing and Analysis_ . 493\u2013505.\n\n12"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism by which annotation errors degrade AI perception models is through the corruption of the training signal. Each error type distorts the ground truth in a specific way, causing the model to learn suboptimal mappings from input features to desired outputs.\n\n**Explanation:** For 'completeness' errors, the mechanism is a missing or biased input space. If critical scenarios or object attributes are absent from the dataset (like keys missing from a hash map), the model never forms a robust internal representation for these conditions. When encountered in the real world, the model behaves unpredictably, as it's essentially trying to perform a lookup for an untrained input. 'Accuracy' errors directly inject noise into the objective function during training. If the target labels are incorrect (e.g., a wrong class label or misaligned bounding box), the gradient descent algorithm guides the model weights towards a flawed optimum, much like a navigation system with incorrect map data, causing the model to learn a distorted mapping. 'Consistency' errors introduce ambiguity and variance in the ground truth. When the same real-world phenomenon is labeled differently across annotators or modalities, the model receives conflicting signals. This prevents the model from converging on a stable feature representation, making its output less precise and reliable, as if multiple lookup tables for the same data had slightly different entries, forcing the model to average out these inconsistencies rather than learning a clear pattern."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Pure Integer Pretraining of an RNN Language Model**\n\nTo demonstrate the potential of EGGROLL as a general optimization method, we study whether EGGROLL\ncould be used for language model pretraining. Since EGGROLL does not rely on gradients, we can explicitly\ndesign a language model architecture to be efficient and hardware-friendly at inference time. In particular, we\nbuild a model under the following constraints to emphasize the flexibility of EGGROLL:\n\n1. **Pure Integer Training:** On H100 systems, int8 is the fastest datatype, with int8 matrix multiplication\nwith int32 accumulation being the fastest tensor core operation. Furthermore, integer datatypes are\nmuch simpler to implement in hardware, providing massive energy savings for high-throughput\nsystems (Horowitz, 2014). Therefore, we keep all weights in int8 and all activations in integer\nformats, _never_ casting to floating point at any point during training.\n\n2. **Nonlinear RNN:** Modern language models use sequence-parallel architectures like Transformers and\nSSMs, since they enable stable gradients without backpropagation through time. However, most of\nthese sequence-parallel architectures are unable to handle simple state tracking (Merrill et al., 2024),\nwhereas classic recurrent networks like LSTMs and GRUs can handle these problems with a single\nlayer. Since EGGROLL does not require backpropagation through time, we can train on unbounded\nsequence lengths (Li et al., 2023a) with nonlinear RNNs of broader complexity classes. Specifically,\nwe develop a variant of the minGRU model (Heck & Salem, 2017) that performs all operations in\ninteger formats.\n\n3. **Removal of all Activation Functions:** Inspired by Foerster (2017), we remove all activation\nfunctions, like the rectified linear unit and hyperbolic tangent, due to the nonlinearity present in the\nint8 datatype. Specifically, the saturated addition of int8 values provides sufficient nonlinearity due to\nthe implicit clipping of values to the int8 dynamic range, which evolution strategies can exploit.\n\nWe call the resulting language model EGG, the **E** volved **G** enerative **G** RU, an EGGROLL-friendly architecture.\nIts architecture is similar to standard pre-layernorm transformer decoder models, but we (1) use a variant of L1\nnormalization instead of L2 normalization for our layernorm to avoid square roots, (2) replace self-attention\nwith our custom GRU, and (3) perform all operations in integer datatypes. See Appendix C for more details on\nthe architecture.\n\nWe train an EGG model with 6 layers and hidden dimension 256 to do character-level prediction on the\nminipile dataset (Kaddour, 2023). We update parameters after 100 tokens for each population member,\napplying truncated ES by keeping the hidden state and only resetting at document boundaries. We plot the\ntest loss in Fig. 2b over training steps across a range of population sizes, where the best test loss is 3.41\nbits/byte. We find that training is stable and loss curves are relatively smooth, especially with large population\nsizes, avoiding loss spikes, nan values, and other instabilities associated with backprop-based training at low\nprecision datatypes.\n\nNote that our largest population size is 2 [18] = 262144, which is two orders of magnitude larger than the largest\nexperiment done by Salimans et al. (2017) while only requiring a single GPU to train. We see that multiplying\nthe population size by 8 results in the loss dropping by approximately 0.4 over the range of population values\nwe have tested, though this pattern will eventually break since the loss must be strictly positive. We conduct\nmore ablations in Appendix E, determining how data efficient training can be achieved with EGGROLL and\nvalidating the importance of large batch sizes.\n\n**6.2** **Reinforcement Learning Tasks**\n\nIn these experiments, we compare the performance of EGGROLL against standard OpenES as implemented in\nSalimans et al. (2017) on reinforcement learning tasks. Given the small network sizes, we can use Open ES at\nthis scale, but we note that as network sizes increase, the use of vanilla OpenES becomes impossible. We use\nthe standard formulation of simply optimizing for the final return in the environment. For both EGGROLL\nand OpenES, we perform hyperparameter optimization (HPO) separately for each environment. For each\nalgorithm\u2013environment pair, we define plausible ranges for all key hyperparameters based on prior work and\npreliminary experiments. We then perform 20 random search trials, where each trial corresponds to a single\n\n9\n\nPendulum-v1\n\n1.0\n\n0.5\n\n0.0\n\n1.0\n\n0.5\n\n0.0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-0.png)\n\n0 2 4\nSteps 1e8\n\nJumanji 2048\n\n0 2 4\nSteps 1e8\n\nCraftax Symbolic\n\n0 2 4\nSteps 1e8\n\nNavix DoorKey (8x8)\n\n0 2 4\nSteps 1e8\n\nBrax Inverted Double Pendulum\n\n1.0\n\n0.5\n\n0.0\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Control Left (m)\n\n1.5\n\n1.0\n\n0.5\n\n0.0\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.5\n\n0.0\n\n1.0\n\n0.5\n\n0.0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-5.png)\n\nFigure 4: Comparison of reinforcement learning Mean returns normalized by PPO performance for 10 seeds. The returns\nare evaluated using the mean of the parameters. HPO was conducted for each algorithm/environment pair. The shaded\nregion is the standard error of the mean .\n\ntraining run with a randomly sampled hyperparameter configuration. Each configuration is evaluated based on\nthe final return achieved by the mean policy parameters at the end of training. After all trials, we select the\nconfiguration that yields the highest final return. Using this best configuration, we then run 10 independent\nseeds to evaluate performance and report the mean and standard error of the mean across these seeds.\n\nWe use policy networks with 3 layers of 256 neurons and a range of environments that demonstrate different\ncapabilities. We evaluate across the Navix (Pignatelli et al., 2024), Craftax (Matthews et al., 2024), Brax\n(Freeman et al., 2021), Kinetix (Matthews et al., 2025), and Jumanji (Bonnet et al., 2024) suites of environments.\nWe evaluate 16 environments in total. To pick environments, we choose environments that are not trivial or\nimpossible for PPO to solve, according to the original papers. We also choose environments that are part of\ndifferent categories when these are available (e.g. environment size in Kinetix or categories in Jumanji).\n\nWe show a subsample of the environments that were evaluated in Fig. 4. The remaining environment results\nare in Appendix G.1. Our findings show that EGGROLL is competitive with Open ES on 7/16 environments,\nunderperforms on 2/16, and outperforms on 7/16. This does not take into account the speed-ups when\ncompared to using OpenES (full-rank updates). We postulate that the reason for this performance increase is\nthat the large networks are difficult to optimize for Open ES and lend themselves well to low rank updates. All\nhyperparameter configuration details are available in Appendix G.1.\n\n**6.3** **LLM Fine-tuning for Reasoning Tasks**\n\nWe apply EGGROLL for LLM finetuning of RWKV-7 (Peng et al., 2025) models in two reasoning tasks:\ncountdown and GSM8K. The RWKV architecture is a recurrent model that, compared to transformers, is\nespecially suited to parallelization due to the fact that any memory otherwise spent on the KV cache can be\nused to evaluate population members. The training curves of EGGROLL and GRPO in countdown are shown\nin figure 5a. EGGROLL fine-tuning on an RWKV-7 1.5B model converges to a higher validation accuracy\nof 35% (v.s. 23%) under the same hardware and wall-clock time in the countdown task. Similarly, figure 5b\n\n10\n\nGSM8K \u2014 RWKV 7g7B\n\n0 2 4 6 8 10\n\nRelative wall-clock time (hours)\n\nGRPO (n=3) EGGROLL (n=3)\n\n(b)\n\n0.3\n\n0.2\n\n0.1\n\n0.0\n\nCountdown \u2014 RWKV 7g1.5B\n\n0 1 2 3 4 5 6 7 8\n\nRelative wall-clock time (hours)\n\nGRPO (n=3) EGGROLL (n=3)\n\n(a)\n\n0.80\n\n0.75\n\n0.70\n\n0.65\n\n0.60\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-10-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-10-1.png)\n\nFigure 5: Comparison of the validation score of 3 seeds of EGGROLL v.s. 3 seeds of GRPO in: (a) Countdown task with\nan RWKV 7g1.5B model on a single GPU. EGGROLL allows 1024 parallel generations per GPU whereas GRPO only 32.\n(b) GSM8K task with an RWKV 7g7B model on 8 GPUs. EGGROLL allows 8096 parallel genrations (1024 per GPU)\nwhereas GRPO only 256 (32 per GPU).\n\nshows that EGGROLL outperforms GRPO on GSM8K fine-tuning. Our scoring function draws parallels to the\ngroup relative advantage of GRPO. In particular, to score a set of noise directions, _E \u2261{E_ 1 _, . . ., En}_, we first\ncompute their accuracies, _{s_ 1 _,qi, . . ., sn,qi}_, on _|q|_ = _m_ questions, creating a matrix of scores _S \u2208_ R _[m][\u00d7][n]_ .\nWe then compute the _z_ score per question, with the main difference that we use the global variance \u00af _\u03c3_, and\naverage over all the questions to compute the final score for the noise direction _Ei_ :\n\n_m_\n\n\u00af\n_si_ = [1]\n\n_m_\n\n_m_\n\ufffd\n\n\ufffd _zi,qj_ = _m_ [1]\n\n_j_ =1\n\n_m_\n\ufffd\n\n_j_ =1\n\n_si,j \u2212_ _\u00b5qj_\n\n_\u03c3_ \u00af _._\n\nThis scoring function has the purpose of weighting all questions within the same batch the same across\npopulation members."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism here is an evolutionary strategy (EGGROLL) applied to a novel, integer-only recurrent network architecture (EGG). Instead of traditional gradient descent, which calculates precise \"slopes\" to adjust parameters, EGGROLL works by randomly perturbing a base set of parameters, evaluating the performance of these \"mutated\" versions, and then adjusting the base parameters towards the more successful mutations. This is analogous to a parallel search algorithm where many slightly different versions of the code (the model) are run, their outputs compared, and the best-performing code informs the next iteration.\n\n**Explanation:** The key insight is that by foregoing gradient-based learning, we're free from its constraints. Specifically, backpropagation through time for RNNs often struggles with vanishing/exploding gradients, limiting effective sequence length. EGGROLL, being gradient-free, can train RNNs on \"unbounded sequence lengths\" because it doesn't rely on backpropagation's chained derivatives. Pure integer training isn't just a simplification; it's a strategic choice. CPUs and specialized hardware (like H100 tensor cores) perform integer operations much faster than floating-point. By *never* casting to float, they avoid expensive conversion overheads and leverage native hardware capabilities directly, like using fast integer arithmetic logic units. Explicit activation functions like ReLU are removed because the \"saturated addition of int8 values\" provides sufficient nonlinearity. When you add two int8 numbers, if the result exceeds 127, it's clipped to 127. This clipping *is* a nonlinearity, acting like a 'squashing' function. Evolutionary strategies, unlike gradient descent, can directly exploit this inherent, non-differentiable nonlinearity. L1 normalization avoids computationally expensive square root operations, simplifying integer arithmetic. For LLM fine-tuning, EGGROLL's strength is its massive parallelism. Instead of one model being updated, thousands of \"noisy\" copies are evaluated concurrently. The memory that would be used for a single model's cache in a standard setup can instead be reallocated to support running many population members simultaneously on a single GPU. This turns a sequential evaluation process into a highly parallel one, like running many small independent programs on different threads, each testing a slight variation of a larger program. The \"scoring function\" then acts like a 'fitness' evaluator, determining which variations are most successful by standardizing their performance relative to the group, ensuring fair comparison."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe final performance of the array is jointly bounded by _data_\n_movement_ and _compute capability_ :\n\nPerfarray = min\ufffdAIarray \u00b7 _\ud835\udc35\ud835\udc4a_ offchip _,_ Effcore \u00b7 Perf [peak] core [\u00b7] _[ \ud835\udc41]_ core\ufffd _,_ (12)\n\nwhere _\ud835\udc35\ud835\udc4a_ offchip is the available off-chip bandwidth, which is around\n65 GB/s for the Strix Point laptop. _\ud835\udc41_ core = 32 is the number of\ncompute cores, Perf [peak] core [=][ 1] _[.]_ [84 TFLOPS is the per-core peak perfor-]\nmance, and Effcore is the compute core efficiency.\n_Impact of \ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] _[.]_ [ A larger] _[ \ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1] [increases the accumulation chain]\nlength _\ud835\udc41_ accum in the microkernel, allowing a longer steady state in\nEq. 11 or Eq. 10. We use Eq. 10 for conservativeness. Combining it\nwith Eq. 8, we model the microkernel efficiency Effmicro as\n\n_\ud835\udc41_ clusters \u00b7 _\ud835\udc41_ accum\nEffmicro = _._\n~~\ufffd~~ _\ud835\udc47_ prolog + _\ud835\udc3c\ud835\udc3c_            - ( _\ud835\udc41_ accum \u2212 _\ud835\udc36_ ) + _\ud835\udc47_ epilog ~~\ufffd~~            - _\ud835\udc41_ clusters\n\nSince _\ud835\udc41_ accum scales with _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] [, we can approximate]\n\nEffmicro ( _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] [)][ =] _\ud835\udf16_ + _\ud835\udf02\ud835\udc47\ud835\udf02\ud835\udc3c\ud835\udc3c\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] _\ud835\udc3e_ _[\ud835\udc3f]_ [1] _._ (13)\n\n**Table 1: Microkernel-level and core-level performance under**\n**different** _\ud835\udc47\ud835\udc3e_ **and** _\ud835\udf0c_ **.**\n\n_\ud835\udc47\ud835\udc3e_ _\ud835\udf0c_ Perfmicro (Tflops) Effmicro Perfcore (Tflops) Effcore\n\n8 1 0.36 0.2 0.290 0.156\n\n8 2 0.36 0.2 0.277 0.149\n\n8 4 0.36 0.2 0.250 0.134\n\n8 8 0.36 0.2 0.216 0.116\n\n16 1 0.66 0.36 0.529 0.284\n\n16 2 0.66 0.36 0.501 0.272\n\n16 4 0.66 0.36 0.474 0.257\n\n16 8 0.66 0.36 0.359 0.195\n\n32 2 0.76 0.41 0.615 0.331\n\n32 4 0.75 0.41 0.574 0.312\n\n32 8 0.77 0.42 0.562 0.306\n\n64 4 1.16 0.63 0.920 0.511\n\n64 8 1.16 0.63 0.867 0.482\n\nThis expression captures diminishing returns: Effmicro grows linearly for _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] [\u226a] _\ud835\udf02\ud835\udc3c\ud835\udc3c\ud835\udf16_ [, but saturates to] _\ud835\udc3c\ud835\udc3c_ [1] [as] _[ \ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1] [increases.]\n\n_Impact of asymmetry._ Between consecutive microkernels, we\nobserve a fixed overhead for switching microkernels, measured as\n_\ud835\udeff_ \u2248 50 cycles in tracing. For a core to finish an output tile ( _\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ [1] _\ud835\udc36_ _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] [)][,]\n\nin the symmetric case it requires _\ud835\udc3e_ switches, and _\ud835\udf0c_ - _\ud835\udc3e_ switches\n_\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1]\n\nwhen using asymmetric tile buffering. Its latency is\n\n2 _\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ [1] _\ud835\udc36_ _[\ud835\udc3e\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] _\ud835\udc3e_\n_\ud835\udc47_ asym = Perf [peak] core [\u00b7][Eff] micro [+] _[ \ud835\udeff]_ [\u00b7] _[ \ud835\udf0c]_ [\u00b7] _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] _._ (14)\n\n_Combined efficiency._ The resulting effective core efficiency is\n\nEffcore = 2 _\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ [1] _\ud835\udc36_ _[\ud835\udc3e\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] = 1\n_\ud835\udc47_ asym Effmicro1 [+] 2 _\ud835\udc47\ud835\udeff\ud835\udc40\ud835\udc36_ _[\ud835\udc3f]_ _\ud835\udf0c_ [1] Perf _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [peak] core [1] _[\ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1]\n\n_._ (15)\n\nThe optimal strategy to maximize Effcore is to choose _\ud835\udc47\ud835\udc3e_ **as large**\n**as possible** and _\ud835\udf0c_ **as small as possible**, which is the opposite of\nthe strategy that maximizes AI _\ud835\udf0c_ . The final performance (Eq. 12)\ntherefore emerges from a _tradeoff between maximizing arithmetic_\n_intensity and sustaining high compute efficiency_ ."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a 'min' function determining the system bottleneck: performance is capped by the lesser of the available data bandwidth and the effective compute throughput. Core and microkernel efficiencies are derived from amortizing fixed overheads over useful work, creating a diminishing returns curve.\n\n**Explanation:** System performance (Perfarray) is like a garden hose with two kinks: one from the water supply (data movement) and one from how well you aim the nozzle (compute capability). The hose can only spray as much water as the tightest kink allows. We have `Effmicro`, which improves as the 'accumulation chain length' (`TKL1`) increases, akin to a `for` loop processing a larger batch to amortize setup costs. However, this efficiency eventually plateaus because other architectural limits (e.g., register pressure, instruction dependencies) become the new bottleneck, similar to how increasing a buffer beyond a certain size doesn't make a network connection faster if the physical link is saturated. Core efficiency (`Effcore`) further drops due to 'context switching' overhead (`delta`) between microkernels. This overhead is scaled by a factor `rho`, effectively penalizing frequent task switches or complex data handling. A larger `TKL1` can 'absorb' this overhead better. The final dilemma is a classic engineering tradeoff: maximizing 'arithmetic intensity' (doing a lot of computation per unit of data fetched, which might imply larger `rho` or fewer fetches) can increase context switching or data management overheads, thereby hurting core efficiency. Conversely, striving for high core efficiency might mean processing data in smaller, more agile chunks, which could reduce arithmetic intensity. The design challenge is to find the optimal `TKL1` and `rho` to balance these competing factors for peak practical performance."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**45**\n\n### **1 Introduction**\n\nGraph coloring is arguably the most popular topic in graph theory. It is also one of the most well-studied\ntopics in algorithms, because it is known to be one of the hardest problems to approximate. For general\ngraphs, it is inapproximable within a factor _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ for any _\ud835\udf16>_ 0, unless ZPP = NP [10]. The best known\napproximation algorithm computes a coloring within a factor of _\ud835\udc42_ ( _\ud835\udc5b_ (log log _\ud835\udc5b_ ) [2] /(log _\ud835\udc5b_ ) [3] ) [13]. Even for\n3-colorable graphs, the best approximation algorithm achieves a factor of _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [0] _[.]_ [1975] ) [17].\nFormally, the _graph coloring problem_ asks to color each vertex of a graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ) so that no two\nadjacent vertices have the same color. The number of colors should be as small as possible. Let _\ud835\udf12_ ( _\ud835\udc3a_ ) be the\nchromatic number of _\ud835\udc3a_, i.e., the number of colors needed for an optimal coloring.\nIn this paper, our primary focus is on the online version of graph coloring.\n\n**Online graph coloring.** The _online coloring problem_ is defined differently. In the online version of the\ngraph coloring problem, the vertices of an unknown graph arrive one by one, together with edges adjacent\nto the already present vertices. Upon the arrival of each vertex _\ud835\udc63_, a color must be immediately assigned to _\ud835\udc63_\nbefore the next vertex arrives. The goal is to obtain a proper coloring of the resulting graph. The challenge is\nto design a coloring strategy that minimizes the total number of assigned colors. The online graph coloring\nproblem appears to be even harder than the graph coloring problem.\nThe online graph coloring problem is indeed challenging because, sometimes, intuitive algorithms fail;\nfor example, the FirstFit algorithm, which repeatedly assigns the least-indexed available color to each\narriving vertex, cannot even bound the number of colors (see Figure 1). This algorithm works well only for\n_\ud835\udc51_ -degenerate graphs (i.e., every induced subgraph has a vertex of degree at most _\ud835\udc51_ \u2212 1), see [16]. [1]\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-2-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-2-1.png)\n\n1 1 1\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-2-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-2-3.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-2-4.png)\n\nFigure 1: A worst-case input for FirstFit, which uses 2 [1] _[\ud835\udc5b]_ [colors even for bipartite graphs [][16][].]\n\n**Previous studies on online coloring.** Lov\u00b4asz, Saks, and Trotter [21] in 1989 give a deterministic online\ncoloring algorithm with a competitive ratio [2] of _\ud835\udc42_ ( _\ud835\udc5b_ /log [\u2217] _\ud835\udc5b_ ). Kierstead [18] in 1998 improves the competitive\nratio (though not explicitly stated) to _\ud835\udc42_ ( _\ud835\udc5b_ log log log _\ud835\udc5b_ /log log _\ud835\udc5b_ ). Vishwanathan in 1992 [23] gives a\nrandomized algorithm that attains a competitive ratio of _\ud835\udc42_ ( _\ud835\udc5b_ / ~~\u221a~~ log _\ud835\udc5b_ ). His randomized algorithm is modified\n\nin [14] to improve the competitive ratio to _\ud835\udc42_ ( _\ud835\udc5b_ /log _\ud835\udc5b_ ). However, there is a 2 _\ud835\udc5b_ /log [2] _\ud835\udc5b_ lower bound (of the\ncompetitive ratio) for deterministic online graph coloring, and this bound also holds up to a constant factor\nfor randomized algorithms [15]. Even for a tree, the lower bound is log _\ud835\udc5b_, see [4, 12].\nGiven very strong negative results for approximating the chromatic number in the online graph coloring\nproblem (even worse than the graph coloring case), it really makes sense to consider the online graph\ncoloring for _\ud835\udc58_ -colorable graphs. For _\ud835\udc58_ \u2265 3, a randomized algorithm that uses _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][1][/(] _[\ud835\udc58]_ [\u2212][1][)] ) colors is found\n\n1\nFirstFit only uses _\ud835\udc42_ ( _\ud835\udc51_ log _\ud835\udc5b_ ) colors for such a graph.\n2The competitive ratio is the maximum value of (the algorithm\u2019s solution [i.e., the number of colors used]) divided by (the\noptimal solution [i.e., chromatic number]) for all possible inputs.\n\n1\n\nby Vishwanathan [23], and a deterministic algorithm that uses _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] ) colors is given by Kierstead in 1998\n\n[18]. For special cases when _\ud835\udc58_ = 3 and _\ud835\udc58_ = 4, deterministic algorithms that use _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][/][3] ) colors and _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] )\ncolors are given in 1998 by Kierstead [18]. However, no improvement has been made for deterministic\nalgorithms since 1998, and a significant gap remains between the upper and lower bounds. Surprisingly, the\nonly known lower bound is \u03a9(log _[\ud835\udc58]_ [\u2212][1] _\ud835\udc5b_ ) colors [23].\nFor _\ud835\udc58_ = 2, a deterministic algorithm that uses 2 log2( _\ud835\udc5b_ + 1) colors is found by Lov\u00b4asz, Saks, and Trotter\nin 1989 [21]. For the lower bound of deterministic algorithms, after a series of research [4, 5, 11], Gutowski\net al. in 2014 [11] finally showed that achieving 2 log2 _\ud835\udc5b_ \u2212 10 colors is impossible. However, the performance\nof randomized algorithms remains open, where Vishwanathan [23] gives a lower bound of 72 [1] [log][2] _[\ud835\udc5b]_ [colors.]\n\nDeterministic and randomized online algorithms to color the following graph classes achieve \u0398(log _\ud835\udc5b_ )\ncolors: trees, planar, bounded-treewidth, and disk graphs [1]. For more references for online graph colorings,\nwe refer the reader to the survey by Kierstead [19].\n\n**Deterministic vs Randomized.** Generally speaking, deterministic online algorithms have large gaps compared to randomized online algorithms for many problems. For example, deterministic online caching\nalgorithms cannot provide better worst-case guarantees than known trivial algorithms; however, randomization may yield significantly better results (see [22], Chapter 24). This is also the case for the online\nedge-coloring problem, see recent progress in [6, 7, 8]. We also predict that this is also the case for online\ncoloring problems. Note that our deterministic online algorithms below do not match the randomized cases.\nThe difficulty for deterministic online algorithms in coloring problems lies in the so-called \u201dadversarial\nattack\u201d from the context of \u201dmachine learning\u201d [3]. This means that whenever we assign a color to an\narrived vertex, the next vertex to arrive puts us in the worst possible situation. This is very typical in\nthe adversarial bandit problem [2], which assumes no stochastic assumptions about the process generating\nrewards for actions. This means that, in the deterministic case, we must always consider the worst-case\nscenario. In contrast, in the randomized case, it occurs only with very small probability, allowing us to\npresent a randomized online algorithm with fewer colors.\n\n**1.1** **Our contributions**\n\nIn this paper, we study online coloring algorithms for _\ud835\udc58_ -colorable graphs. Our goal is to close the gap\nbetween the upper and lower bounds. So far, the best-known deterministic algorithm, proposed by Kierstead\nin 1998 [18], uses _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] ) colors. Nearly thirty years later, this paper finally makes progress. Our main\ncontributions improve the results for all _\ud835\udc58_ \u2265 2, except _\ud835\udc58_ = 3.\n\n**Theorem 1.1.** _There exists a deterministic online algorithm to color \ud835\udc58-colorable graphs with_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] )\n_colors, for \ud835\udc58_ \u2265 2 _. This algorithm also achieves a competitive ratio of \ud835\udc42_ ( _\ud835\udc5b_ /log log _\ud835\udc5b_ ) _._\n\nThis significantly improves the current upper bound of _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] ) colors [18] when _\ud835\udc58_ \u2265 5. This\nalso improves the competitive ratio for deterministic online algorithms, where the current best result is\n_\ud835\udc42_ ( _\ud835\udc5b_ log log log _\ud835\udc5b_ /log log _\ud835\udc5b_ ) due to Kierstead [18].\n\n**Theorem 1.2.** _There exists a deterministic online algorithm to color 4-colorable graphs with_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] )\n\n_colors._\n\nThis improves the current upper bound of _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] ) colors [18]. Since the _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] )-color algorithm\nin Theorem 1.1 works with _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] ) colors when _\ud835\udc58_ = 4, Theorem 1.2 is better. By combining Theorem 1.1\nand Theorem 1.2, we also improve the results for _\ud835\udc58_ \u2265 5 (to _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][6][/(][3] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][)\u2212][2][)] ) colors; see Theorem 4.17).\nOur results, compared with the previous best, are shown in Table 1.\nFor _\ud835\udc58_ = 2, the lower bound and the upper bound exactly match at 2 log2 _\ud835\udc5b_ \u00b1 _\ud835\udc42_ (1) colors for deterministic\nalgorithms [21, 11]. However, for randomized algorithms, we can do a little better, as follows:\n\n2\n\n_\ud835\udc58_ 3 4 5 6 7\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\nPrevious Results _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [6667] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [8334] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9917] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9987] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9999] )\nOur Results \u2014 _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [8236] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [8966] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [9319] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [9517] )\n\nTable 1: Comparison between the previous best results [18] and our results, for _\ud835\udc58_ \u2264 7.\n\n**Theorem 1.3.** _There exists a randomized online algorithm to color 2-colorable graphs with_ 1 _._ 034 log2 _\ud835\udc5b_ +\n_\ud835\udc42_ (1) _colors._\n\n**Theorem 1.4.** _Any randomized online algorithm to color 2-colorable graphs requires_ 96 [91] [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)] _[ colors.]_\n\nOur results imply that randomized algorithms can perform slightly better, but still have a limit. Theorem 1.3 and Theorem 1.4 imply that the gap is 1 _._ 09x.\n\n**1.2** **Overview of our techniques**\n\nWe now provide an overview of our techniques for the results stated above.\n\n**1.2.1** _\ud835\udc58_ \u2265 5 **case, Theorem 1.1**\n\nThe key is to consider a \u201c _locally \u2113-colorable graph_ \u201d, which is a graph without small (constant-order) non- _\u2113_ colorable subgraphs. Since every _\u2113_ -colorable graph is locally _\u2113_ -colorable but not vice versa, coloring locally\n_\u2113_ -colorable graphs is more difficult than coloring _\u2113_ -colorable graphs. For _\u2113_ = 1 and _\u2113_ = 2, there exist\ndeterministic algorithms that use _\ud835\udc42_ (1) colors and _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] ) colors, respectively; for _\u2113_ = 2, an _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] )-color\nalgorithm for graphs without odd cycles _\ud835\udc36_ 3 or _\ud835\udc36_ 5 is given by Kierstead [18]. However, no algorithm is known\nfor _\u2113_ \u2265 3.\nOur main result is to achieve _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] ) colors for such graphs. As a consequence, we present\na deterministic online coloring algorithm for _\ud835\udc58_ -colorable graphs with _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] ) colors. Below, we\nexplain how to derive an algorithm for locally _\u2113_ -colorable graphs with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ) colors, where _\ud835\udf16_ = _\u2113_ ( _\u2113_ \u221221)+2 [.]\nFirst, we try the FirstFit algorithm using colors 1 _,_ 2 _, . . ., \ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_, but for some vertices, there are no\navailable colors. In such a case, we must pay for new colors. However, such a vertex _\ud835\udc63_ is adjacent to at least\n_\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ previous vertices. Specifically, let _\ud835\udc46_ be the set of vertices colored by FirstFit, and let _\ud835\udc47_ be the rest of\nthe vertices. Then, | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ holds for each _\ud835\udc63_ \u2208 _\ud835\udc47_ (otherwise, we can color _\ud835\udc63_ by FirstFit). Using this\nlarge degree condition, we aim to obtain a \u201cgood subset _\ud835\udc46_ [\u2032] \u201d in _\ud835\udc46_ that tells us about the upper bound of the\nchromatic number in _\ud835\udc3a_ [ _\ud835\udc41_ ( _\ud835\udc46_ [\u2032] )] (and hence the future vertices in _\ud835\udc41_ ( _\ud835\udc46_ [\u2032] )). The best scenario is to consider the\ncase when _\ud835\udc3a_ is _\u2113_ -colorable (not just locally _\u2113_ -colorable), and to obtain a subset _\ud835\udc46_ [\u2032] \u2286 _\ud835\udc46_, in which only one\ncolor is used in _\ud835\udc46_ [\u2032] in some _\u2113_ -coloring of _\ud835\udc3a_ . We call such a set _\ud835\udc46_ [\u2032] a _1-color set_ . Then the graph _\ud835\udc3a_ [ _\ud835\udc41_ ( _\ud835\udc46_ [\u2032] )] is\nguaranteed to be ( _\u2113_ \u2212 1)-colorable. In particular, all the \u201cfuture\u201d vertices that are adjacent to a vertex in _\ud835\udc46_ [\u2032] can\nbe ( _\u2113_ \u2212 1)-colored. This allows us to apply our algorithm inductively (on _\u2113_ ), and hence we can (inductively)\ncolor the vertices in _\ud835\udc41_ ( _\ud835\udc46_ [\u2032] ).\nTo implement the above idea for locally _\u2113_ -colorable graphs, we define a _level-\ud835\udc51_ _set_, which measures how\nclose the set is to a 1-color set above. Formally, we say that a subset _\ud835\udc46_ [\u2032] \u2286 _\ud835\udc46_ is level- _\ud835\udc51_ if, for every small\n(constant-order) subset _\ud835\udc4b_ \u2286 _\ud835\udc49_, only _\u2113_ \u2212 _\ud835\udc51_ or fewer colors are used in _\ud835\udc4b_ \u2229 _\ud835\udc46_ [\u2032] in some _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ]. [3]\n\nThe entire set _\ud835\udc46_ is just a level-0 set; but we aim to obtain a level-1 set, a level-2 set, and so on, and finally a\nlevel-( _\u2113_ \u2212 1) set. This is because, once we obtain a level-( _\u2113_ \u2212 1) set _\ud835\udc46_ [\u2032], as argued in the previous paragraph,\n_\ud835\udc3a_ [ _\ud835\udc41_ ( _\ud835\udc46_ [\u2032] )] is indeed a locally ( _\u2113_ \u2212 1)-colorable graph (see subsection 3.3). [4]\n\n3Note that since _\ud835\udc3a_ is locally _\u2113_ -colorable, there exists some _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ].\n4It means that we increase the level by \u0398( _\u2113_ 2) in total (until reaching \u201clocally 1-colorable\u201d); it is why we achieve _\ud835\udc42_ ( _\ud835\udc5b_ 1\u22121/\u0398( _\u2113_ [2] ) ).\n\n3\n\nTo obtain a level-1 set, we pick a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_, and then _\ud835\udc46_ 1 = _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ ) is indeed a level-1 set. [5] To obtain a\nlevel-2 set, we pick two _adjacent_ vertices _\ud835\udc64_ 1 _, \ud835\udc64_ 2 \u2208 _\ud835\udc47_, and then _\ud835\udc46_ 2 = _\ud835\udc41\ud835\udc46_ 1 ( _\ud835\udc64_ 1) or _\ud835\udc46_ 3 = _\ud835\udc41\ud835\udc46_ 1 ( _\ud835\udc64_ 2) is indeed a\nlevel-2 set (see Figure 2). [6] The important thing is that we cannot guarantee which of the two sets is a level-2\nset, but we can guarantee that at least one of them is a level-2 set. Similarly, we can also obtain level-3 or\nhigher sets in a similar way (see subsection 3.4). Note that the constructions of these level sets are for the\nsake of coloring \u201cfuture\u201d vertices. Note also that some readers may wonder that the obtained subsets (e.g., _\ud835\udc46_ 2\nand _\ud835\udc46_ 3) can be empty (or very small) in the worst case, but due to the large degree condition, we are always\nguaranteed to obtain such subsets (see subsection 3.4 for details). In addition, some readers may also worry\nthat many mistakes might occur (e.g., either _\ud835\udc46_ 2 or _\ud835\udc46_ 3 may not be a level-2 set), but we can bound the number\nof mistakes (Lemma 3.8), and therefore we do not pay many colors for mistakes.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-5-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-5-1.png)\n\n\ud835\udc46 \ud835\udc46 \ud835\udc46 \ud835\udc46 \ud835\udc46\n\nFigure 2: A sketch of our algorithm for _\ud835\udc58_ \u2265 5 case. The left and right figures show the creation\nof level-1 and level-2 sets. Note that the entire set _\ud835\udc46_ is level-0, not even a level-1 set.\n\n**1.2.2** _\ud835\udc58_ = 4 **case, Theorem 1.2**\n\nThe key to our algorithm is the use of the second-neighborhood structure. In the algorithm used in Theorem 1.1\nthat achieves _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] ) colors for _\ud835\udc58_ = 4, we obtain 1-color sets (see subsubsection 1.2.1) of \u03a9( _\ud835\udc5b_ [1][/][2] ) vertices,\n2-color sets of \u03a9( _\ud835\udc5b_ [2][/][3] ) vertices, and 3-color sets of \u03a9( _\ud835\udc5b_ [5][/][6] ) vertices. If any of the larger sets (e.g., 3-color sets\nof \u03a9( _\ud835\udc5b_ [0] _[.]_ [9] ) vertices) were obtained, there would be a good chance of improvement, but it is still challenging.\nWe resolve this problem with our novel _double greedy method_, which applies FirstFit twice to exploit the\nsecond-neighborhood structure. Let _\ud835\udc46_ be the vertices colored by the first FirstFit, let _\ud835\udc47_ be the vertices\ncolored by the second FirstFit, and let _\ud835\udc48_ be the rest of the vertices. [7] Both runs of FirstFit use _\ud835\udc42_ ( _\ud835\udc5b_ [5][/][6] )\ncolors. [8] The first step is to obtain a 1-color set of \u03a9( _\ud835\udc5b_ [1][/][2] ) vertices in _\ud835\udc47_ (using _\ud835\udc48_ ). The second step is that,\nwhen _\ud835\udc47_ [\u2032] \u2286 _\ud835\udc47_ is the obtained 1-color set, _\ud835\udc41\ud835\udc46_ ( _\ud835\udc47_ [\u2032] ) is a 3-color set of \u03a9( _\ud835\udc5b_ ) vertices, in most cases (Figure 3\nleft). Thus, we make progress (for the future vertices to arrive), unless an exceptional case arises.\nHowever, if there exists a dense subgraph between _\ud835\udc46_ and _\ud835\udc47_ (which is an exceptional case), we cannot\nobtain a 3-color set of \u03a9( _\ud835\udc5b_ ) vertices. Indeed, in the worst case, the obtained 3-color set consists of \u0398( _\ud835\udc5b_ [5][/][6] )\nvertices. In such cases, we pick a pair of vertices _\ud835\udc62_ 1 _, \ud835\udc62_ 2 \u2208 _\ud835\udc47_ where _\ud835\udc4d_ = _\ud835\udc41\ud835\udc46_ ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ ( _\ud835\udc62_ 2) is large, that\nis, \u03a9( _\ud835\udc5b_ [2][/][3][+] _[\ud835\udf16]_ ) vertices for some _\ud835\udf16>_ 0 (Figure 3 right). If there exists a 4-coloring of the given graph in\nwhich distinct colors are used for _\ud835\udc62_ 1 and _\ud835\udc62_ 2, then _\ud835\udc4d_ is indeed a 2-color set, leading to make progress (for the\nfuture vertices to arrive). We call this method _Common & Simplify technique_ . With these two techniques, we\neventually achieve _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors, improving on Kierstead\u2019s result [18] by a factor of _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][/][102] ). We also\nbelieve that these techniques are useful for many other online coloring algorithms.\n\n5If _\ud835\udc46_ 1 is not level-1, there exists a small subset _\ud835\udc4b_ \u2286 _\ud835\udc46_ 1 where _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ ]) = _\u2113_, and therefore _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ \u222a{ _\ud835\udc63_ }]) _> \u2113_ (and _\ud835\udc3a_ is not\nlocally _\u2113_ -colorable).\n6If both _\ud835\udc46_ 2 and _\ud835\udc46_ 3 are not level-2, there exist small subsets _\ud835\udc4b_ 2 \u2286 _\ud835\udc46_ 2 and _\ud835\udc4b_ 3 \u2286 _\ud835\udc46_ 3 where _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ 2]) \u2265 _\u2113_ \u2212 1 and _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ 3]) \u2265 _\u2113_ \u2212 1,\nand therefore _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ 2 \u222a _\ud835\udc4b_ 3 \u222a{ _\ud835\udc63, \ud835\udc64_ 1 _, \ud835\udc64_ 2}]) _> \u2113_ (and _\ud835\udc3a_ is not locally _\u2113_ -colorable).\n7It is equivalent to \u201capplying FirstFit using 2 _\ud835\udc5b_ 1\u2212 _\ud835\udf16_ colors, let _\ud835\udc46_ be the vertices colored by colors 1 _,_ 2 _, . . ., \ud835\udc5b_ 1\u2212 _\ud835\udf16_, let _\ud835\udc47_ be the\nvertices colored by colors _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ + 1 _, \ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ + 2 _, . . .,_ 2 _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_, and let _\ud835\udc48_ be the rest of the vertices\u201d.\n8Indeed, we only use _\ud835\udc5b_ 14/17 _, \ud835\udc5b_ 13/17 colors in _\ud835\udc46,\ud835\udc47_ in our algorithm, respectively, but for simplicity, we assume _\ud835\udc42_ ( _\ud835\udc5b_ 5/6) colors.\n\n4\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-6-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-6-1.png)\n\nor\n\nFigure 3: A sketch of our techniques in _\ud835\udc58_ = 4 case.\n\n**1.2.3** _\ud835\udc58_ = 2 **case upper bound, Theorem 1.3**\n\nWe apply randomization to Lov\u00b4asz, Saks, and Trotter\u2019s algorithm [21] and show that this leads to better\nperformance. By carefully analyzing how quickly the \u201cthird color\u201d is forced to be used, we obtain an upper\nbound of 1 _._ 096 log2 _\ud835\udc5b_ + _\ud835\udc42_ (1) colors. For a better result, we analyze how quickly the (2 _\ud835\udc3f_ + 1)-th color is\nforced to be used for _\ud835\udc3f_ \u2265 2. We use a computer-aided approach based on dynamic programming. Eventually,\nwith careful analysis up to _\ud835\udc3f_ = 10, we improve the upper bound to 1 _._ 034 log2 _\ud835\udc5b_ .\n\n**1.2.4** _\ud835\udc58_ = 2 **case lower bound, Theorem 1.4**\n\nWe consider a binary-tree-like graph (Figure 4) and use the classic \u201cpotential function\u201d argument. We\nintroduce a potential function to represent the required number of colors, and show that any online algorithm\nwould increase the potential by \u201c [3] [colors\u201d per depth, leading to a lower bound of] [3] [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors. For]\n\n[3] 4 [colors\u201d per depth, leading to a lower bound of] [3] 4\n\nwould increase the potential by \u201c 4 [colors\u201d per depth, leading to a lower bound of] 4 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors. For]\n\na better result, we note that when the potential increase is smaller at one depth, a larger increase typically\noccurs at the next depth. We analyze how potential increases occur across two consecutive depths. However,\nthe setting is more complex and requires a computer to brute-force all the essential cases. In the end, we\nobtain a lower bound of [91] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [1] [ colors.]\n\n96 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors.]\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-6-3.png)\n\nSecond Depth\n\nFirst Depth\n\nFigure 4: The input for the depth-2 case, which we consider for the lower bound. The vertices\nare arranged from bottom to top (the colors are used for readability purposes only).\n\n**1.3** **Organization of this paper**\n\nThis paper is organized as follows. In section 2, we present the preliminaries needed for the proof. In section 3,\nwe present a deterministic online algorithm that obtains a general upper bound for _\ud835\udc58_ \u2265 5 (Theorem 1.1),\nincluding a comparison with Kierstead\u2019s previous algorithm (subsection 3.7). In section 4, we present a\ndeterministic online algorithm for the special case _\ud835\udc58_ = 4 (Theorem 1.2). In section 5, we prove the upper\nbound 1 _._ 034 log2 _\ud835\udc5b_ + _\ud835\udc42_ (1) for _\ud835\udc58_ = 2 (Theorem 1.3). In section 6, we prove the lower bound [91] 96 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)]\n\nfor _\ud835\udc58_ = 2 (Theorem 1.4). Finally, in section 7, we conclude this paper with several remarks (including\nthe reason why our proof techniques do not improve the _\ud835\udc58_ = 3 case) and several conjectures. Note that to\nunderstand section 4, the content of section 3 is required, but section 5 and section 6 are independent.\n\n5\n\n### **2 Preliminaries**\n\n**Online coloring.** We define the _online coloring problem_ as follows. We are given an undirected graph\n_\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ) where _\ud835\udc49_ = { _\ud835\udc63_ 1 _, \ud835\udc63_ 2 _, . . ., \ud835\udc63\ud835\udc5b_ }. We denote by _\ud835\udc5b_ the number of vertices. We perform the following\nprocedure for _\ud835\udc56_ = 1 _,_ 2 _, . . ., \ud835\udc5b_ : receive a vertex _\ud835\udc63\ud835\udc56_ together with its incident edges to some of _\ud835\udc63_ 1 _, \ud835\udc63_ 2 _, . . ., \ud835\udc63\ud835\udc56_ \u22121,\nand color _\ud835\udc63\ud835\udc56_ with a color _\ud835\udc50_ ( _\ud835\udc63\ud835\udc56_ ) \u2208 N. The next vertex _\ud835\udc63\ud835\udc56_ +1 arrives only after coloring _\ud835\udc63\ud835\udc56_ . No two adjacent\nvertices are allowed to share the same color. The objective is to minimize the total number of colors used,\nthat is, to minimize max{ _\ud835\udc50_ ( _\ud835\udc63_ 1) _, \ud835\udc50_ ( _\ud835\udc63_ 2) _, . . ., \ud835\udc50_ ( _\ud835\udc63\ud835\udc5b_ )}.\n\n**FirstFit algorithm.** The most straightforward strategy is to assign each new vertex the smallest available\ncolor. This strategy is often referred to as FirstFit. We utilize it as a subroutine in our main algorithm.\n\n_\u2113_ **-color set.** In a graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ), a vertex set _\ud835\udc46_ \u2286 _\ud835\udc49_ is \u201can _\u2113_ -color set in some _\ud835\udc58_ -coloring of _\ud835\udc3a_ \u201d if there\nexists a _\ud835\udc58_ -coloring of _\ud835\udc3a_ such that _\u2113_ or fewer colors appear in _\ud835\udc46_ . Otherwise, _\ud835\udc46_ is \u201cnot an _\u2113_ -color set in any\n_\ud835\udc58_ -coloring of _\ud835\udc3a_ \u201d. For example, the blue shaded area in Figure 5 left is a 1-color set in some 3-coloring of _\ud835\udc3a_,\nbut the red shaded area in Figure 5 right is not a 1-color set in any 3-coloring of _\ud835\udc3a_ . Note that if _\ud835\udf12_ ( _\ud835\udc3a_ ) _> \ud835\udc58_, _\ud835\udc46_\nis _not_ an _\u2113_ -color set in any _\ud835\udc58_ -coloring of _\ud835\udc3a_ .\n\nFigure 5: The structure between _\ud835\udc46_ (shaded area) and the other vertices.\n\n**Notations.** For a vertex _\ud835\udc63_ \u2208 _\ud835\udc49_, we denote its neighborhood by _\ud835\udc41_ ( _\ud835\udc63_ ). For a vertex set _\ud835\udc46_ \u2286 _\ud835\udc49_, we denote\nits neighborhood by _\ud835\udc41_ ( _\ud835\udc46_ ) = [\ufffd] _\ud835\udc63_ \u2208 _\ud835\udc46_ _[\ud835\udc41]_ [(] _[\ud835\udc63]_ [)][. For] _[ \ud835\udc4b]_ [\u2286] _[\ud835\udc49]_ [, we denote] _[ \ud835\udc41]_ _\ud835\udc4b_ [(] _[\ud835\udc63]_ [)][ =] _[ \ud835\udc41]_ [(] _[\ud835\udc63]_ [) \u2229] _[\ud835\udc4b]_ [. In addition, we write]\n_\ud835\udc3a_ [ _\ud835\udc46_ ] for the subgraph of _\ud835\udc3a_ induced by _\ud835\udc46_ \u2286 _\ud835\udc49_ .\nIn general, we use _\ud835\udc42,_ \u03a9 _,_ \u0398 notations with respect to _\ud835\udc5b_, and ignore other constants. For example, in\nan online coloring algorithm for _\ud835\udc58_ -colorable graphs for a constant _\ud835\udc58_, even if the number of colors used is\n2 [2] _[\ud835\udc58]_ - _\ud835\udc5b_ [1][/][2], we write \u201c _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] ) colors\u201d. Also, we write _\ud835\udc42_ [\ufffd] ( _\ud835\udc53_ ( _\ud835\udc5b_ )) _,_ \u03a9 [\ufffd] ( _\ud835\udc53_ ( _\ud835\udc5b_ )) and \u0398 [\ufffd] ( _\ud835\udc53_ ( _\ud835\udc5b_ )) to hide log _\ud835\udc5b_ factors.\nWe assume all logarithms are base 2 unless stated otherwise (i.e., log _\ud835\udc5b_ = log2 _\ud835\udc5b_ ).\n\n### **3 General bound**\n\nIn this section, we present a deterministic online algorithm that colors any\ufffd _\ud835\udc5b_ -vertex _\ud835\udc58_ -colorable graph with\n_\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] ) colors, for any constant _\ud835\udc58_ . This significantly improves the previous results for _\ud835\udc58_ \u2265 5. To\nthis end, we first explain an online coloring algorithm that uses _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][)+][2][)] ) colors, which is slightly\nworse than our best result. Generally speaking, we consider the situation when the number of vertices _\ud835\udc5b_ is\nknown in advance. This makes sense because of the following lemma (which is already proved in Lemma\n1.10 of Kierstead [18]; for completeness, we give a proof here.)\n\n**Lemma 3.1** ([18]) **.** _Suppose there exists a deterministic online coloring algorithm for a specific graph class_\n_(e.g., \ud835\udc58-colorable graphs) with \ud835\udc5b_ _vertices that uses \ud835\udc53_ ( _\ud835\udc5b_ ) _colors. Then, there exists a deterministic online_\n_coloring algorithm for this graph class that uses at most_ 4 _\ud835\udc53_ ( _the current number of vertices_ ) _colors, at any_\n_moment. Here, we assume that \ud835\udc53_ ( _\ud835\udc5b_ ) _is an integer and_ 0 \u2264 _\ud835\udc53_ ( _\ud835\udc5b_ + 1) \u2212 _\ud835\udc53_ ( _\ud835\udc5b_ ) \u2264 1 _for all \ud835\udc5b._\n\n6\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-7-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-7-1.png)\n_Proof._ We run the following algorithm, for _\ud835\udc56_ = 0 _,_ 1 _,_ 2 _, . . ._ :\n\nLet _\ud835\udc61\ud835\udc56_ be the largest _\ud835\udc61_ such that _\ud835\udc53_ ( _\ud835\udc61_ ) \u2264 2 _[\ud835\udc56]_ (it satisfies _\ud835\udc53_ ( _\ud835\udc61\ud835\udc56_ ) = 2 _[\ud835\udc56]_ by the assumption). For the next\n_\ud835\udc61\ud835\udc56_ vertices (or until all the vertices arrive), we use an algorithm for _\ud835\udc61\ud835\udc56_ -vertex graphs. [9]\n\nConsider the moment when _\ud835\udc56_ = _\ud835\udc56_ 0. The _\ud835\udc56_ 0 = 0 case is obvious, so we suppose _\ud835\udc56_ 0 \u2265 1. The current number of\nvertices _\ud835\udc5a_ satisfies _\ud835\udc5a_ \u2265 _\ud835\udc61\ud835\udc56_ 0 \u22121, because the loop with _\ud835\udc56_ = _\ud835\udc56_ 0 \u2212 1 is already finished. Thus, _\ud835\udc53_ ( _\ud835\udc5a_ ) \u2265 2 _[\ud835\udc56]_ [0] [\u2212][1] . Also,\nthe algorithm used at most 1 + 2 + \u00b7 \u00b7 \u00b7 + 2 _[\ud835\udc56]_ [0] = 2 _[\ud835\udc56]_ [0][+][1] \u2212 1 colors, which is less than 4 _\ud835\udc53_ ( _\ud835\udc5a_ ).\n\nThroughout this section, we denote _\ud835\udc5b_ by the number of vertices in _\ud835\udc3a_ .\n\n**3.1** **Algorithm for locally** _\u2113_ **-colorable graph**\n\nFirst, we consider an online algorithm for \u201clocally\u201d _\u2113_ -colorable graphs, that is, graphs in which every small\nsubgraph is _\u2113_ -colorable. Formally, we give the following definition.\n\n**Locally** _\u2113_ **-colorable.** A graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ) is locally _\u2113_ -colorable if for every subset _\ud835\udc46_ \u2286 _\ud835\udc49_ with | _\ud835\udc46_ | _<_ 2 [2] _[\u2113]_,\nwe have _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc46_ ]) \u2264 _\u2113_ .\n\nNote that locally _\u2113_ -colorable graphs are not necessarily _\u2113_ -colorable. Indeed, _\ud835\udf12_ ( _\ud835\udc3a_ ) could be arbitrarily\nlarge compared to _\u2113_, even for _\u2113_ = 2; cf., consider a graph _\ud835\udc3a_ of large girth with _\ud835\udf12_ ( _\ud835\udc3a_ ) unbounded (it is\nwell-known that such a graph does exist, by the classical result of Erd\u02ddos, see [9]).\nFor _\u2113_ = 1, the graph has no edges, so we can color it online with 1 color. For _\u2113_ = 2, only _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] ) colors\nare needed, by the following stronger theorem of Kierstead [18].\n\n**Theorem 3.2** ([18]) **.** _There is a deterministic online algorithm that colors any graph that contains no odd_\n_cycles \ud835\udc36_ 3 _or \ud835\udc36_ 5 _using only \ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] ) _colors._\n\nOur main contribution is to give a deterministic online algorithm for _\u2113_ \u2265 3, with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] )\ncolors. Since every _\u2113_ -colorable graph is locally _\u2113_ -colorable, this is indeed our main technical contribution\n(over Kierstead\u2019s result [18]) for the general _\u2113_ -colorable graphs. Below, we present our algorithm for _\u2113_ \u2265 3.\n\n**3.2** **Reduction to the subproblem**\n\nThe first step is to apply the FirstFit algorithm with colors 1 _,_ 2 _, . . ., \ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_, where _\ud835\udf16_ = _\u2113_ ( _\u2113_ \u221221)+2 [.]\nHowever, sometimes there are no available colors for a vertex _\ud835\udc63_ . In this case, | _\ud835\udc41\ud835\udc46_ now ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ holds,\nwhere _\ud835\udc46_ now is the current set of vertices colored by FirstFit. We now attempt to utilize the dense subgraph\nbetween _\ud835\udc46_ 0 and _\ud835\udc47_ 0 = _\ud835\udc49_ \\ _\ud835\udc46_ 0 to color the remaining vertices online, where _\ud835\udc46_ 0 is the final set of vertices colored\nby FirstFit. The overall framework for online coloring is shown in Algorithm 1.\n\n**Algorithm 1** OnlineColoring( _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ))\n\n1: **for** each arrival of _\ud835\udc63_ \u2208 _\ud835\udc49_ **do**\n\n2: **if** _\ud835\udc63_ can be colored by color 1 _,_ 2 _, . . ., \ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ **then**\n\n3: color _\ud835\udc63_ with FirstFit\n\n4: **else**\n\n5: color _\ud835\udc63_ with a special algorithm _\u22b2_ Uses color _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ + 1 or bigger\n\n9\nFor example, for the _\ud835\udc53_ ( _\ud835\udc5b_ ) = \u2308 ~~[\u221a]~~ ~~_\ud835\udc5b_~~ ~~\u2309~~ case, we use an algorithm for 1-vertex graphs for the first 1 vertex, and we use an algorithm\nfor 4-vertex graphs for the next 4 vertices, then we use an algorithm for 16-vertex graphs for the next 16 vertices, and so on.\n\n7\n\nThe goal of this section is to present a deterministic online algorithm that colors _\ud835\udc47_ 0 with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ )\ncolors, that is, an algorithm referred to as the \u201cspecial algorithm\u201d in line 5. We denote such a problem as\n**else-problem** . Formally, the else-problem is the following:\n\n  - Color all vertices in _\ud835\udc47_ 0 (i.e., color all vertices not colored by FirstFit). Indeed, each time a vertex in\n_\ud835\udc47_ 0 arrives, we apply this problem, but we never reset the algorithm (i.e., this algorithm leverages past\niterations, see more details below).\n\n  - Let _\ud835\udc46_ now and _\ud835\udc47_ now be the \u201ccurrent\u201d vertices which are subsets of _\ud835\udc46_ 0 and _\ud835\udc47_ 0, respectively. When some\nvertex _\ud835\udc60_ that is colored by FirstFit arrives, we add _\ud835\udc60_ to _\ud835\udc46_ now.\n\n  - When some vertex _\ud835\udc61_ that is not colored by FirstFit arrives, we add _\ud835\udc61_ to _\ud835\udc47_ now and give a color to _\ud835\udc61_ .\nWhen coloring vertex _\ud835\udc61_ \u2208 _\ud835\udc47_ 0, we are allowed to use structural information from _\ud835\udc3a_ [ _\ud835\udc46_ now \u222a _\ud835\udc47_ now], which\nis obtained from this algorithm previously applied to color vertices in _\ud835\udc47_ now. Note that the information\nwhen coloring _\ud835\udc61_ can also be used for the \u201cfuture\u201d vertices that will not be colored by FirstFit.\n\nIf an algorithm to solve the else-problem exists, our online coloring algorithm for locally _\u2113_ -colorable\ngraphs directly follows because the number of colors used is _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ + _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ) = _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ). Note that we use\ndifferent colors for FirstFit and for the else-problem (see comment on line 5).\nHowever, solving the else-problem remains challenging. Indeed, if we do not take _\ud835\udc46_ 0 into account (i.e.,\nwe try to color _\ud835\udc47_ 0 online without using _\ud835\udc46_ 0), the problem remains the same. Therefore, we must use the fact\nthat _\ud835\udc3a_ is locally _\u2113_ -colorable, and hence _\ud835\udc46_ 0 plays an important role when coloring vertices in _\ud835\udc47_ 0. To this end,\nwe first define the following _level-\ud835\udc51_ _set_ :\n\n**Level-** _\ud835\udc51_ **set.** We say that a subset _\ud835\udc46_ \u2286 _\ud835\udc46_ 0 is a _level-\ud835\udc51_ _set_ if for every _\ud835\udc4b_ \u2286 _\ud835\udc49_ where | _\ud835\udc4b_ | _<_ 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1], _\ud835\udc4b_ \u2229 _\ud835\udc46_ is\nan ( _\u2113_ \u2212 _\ud835\udc51_ )-color set in some _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ].\n\nThe reason we define this level- _\ud835\udc51_ set is that the level corresponds to the simplicity of the problem; the higher\nthe level is, the easier it is to handle (see the overview in subsubsection 1.2.1). For example, the level-( _\u2113_ \u2212 1)\nset is the easiest to handle (see subsection 3.3).\nThus, we further break down the problem into the following simpler subproblems. In this subproblem,\nthere is a parameter _\ud835\udc51_ called _level_ (which corresponds to the above level- _\ud835\udc51_ set), and the _\ud835\udc51_ = 0 case corresponds\nto the else-problem. We try to solve this subproblem in the order of _\ud835\udc51_ = _\u2113_ \u2212 1 _, \u2113_ \u2212 2 _, . . .,_ 0 (i.e., induction on\nthe reverse order of _\ud835\udc51_ ). See Figure 6 for our objective.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-9-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-9-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-9-2.png)\n\n\u2026\n\n**level-** (\u2113\u2212\ud835\udfcf) **subproblem** **level-** (\u2113\u2212\ud835\udfd0) **subproblem** **level-0 subproblem**\n\nFigure 6: The sketch of the roadmap. We solve it in the order of _\ud835\udc51_ = _\u2113_ \u2212 1 _, \u2113_ \u2212 2 _, . . .,_ 0. The\nbright vertices are _\ud835\udc46_ and _\ud835\udc47_ . Note that _\ud835\udc46_ and _\ud835\udc47_ are given in the order of arrival.\n\n8\n\n**Level-** _\ud835\udc51_ **subproblem.** We consider the subgraph _\ud835\udc3a_ [ _\ud835\udc46_ \u222a _\ud835\udc47_ ] ( _\ud835\udc46_ \u2286 _\ud835\udc46_ 0 _,\ud835\udc47_ \u2286 _\ud835\udc47_ 0), where we need to color\nthe vertices in _\ud835\udc47_ online. Initially, _\ud835\udc46_ and _\ud835\udc47_ are empty, and vertices are added to _\ud835\udc46_ and _\ud835\udc47_ in the order of\narrival (i.e., sometimes vertices in _\ud835\udc46_ arrive after vertices in _\ud835\udc47_ ). Every time a vertex _\ud835\udc63_ is added to _\ud835\udc47_, we need\nto color the vertex _\ud835\udc63_ . It is guaranteed that | _\ud835\udc46_ | \u2264 _\ud835\udefe\ud835\udc51_ and | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 _\ud835\udefe\ud835\udc51_ +1 ( _\ud835\udc63_ \u2208 _\ud835\udc47_ ) at any moment, where\n_\ud835\udefe\ud835\udc56_ = _\ud835\udc5b_ [1][\u2212] _[\ud835\udc56\ud835\udf16]_ /2 _[\ud835\udc56]_ [(] _[\ud835\udc56]_ [\u2212][1][)/][2] for each _\ud835\udc56_ = 0 _,_ 1 _, . . ., \u2113_ . We can also assume that _\ud835\udc46_ is a level- _\ud835\udc51_ set.\nHowever, at some point, we can _abort_ the coloring when we can output a set _\ud835\udc4b_ \u2286 _\ud835\udc46_ \u222a _\ud835\udc47_ that violates the\ncondition for the level- _\ud835\udc51_ set, that is, | _\ud835\udc4b_ | _<_ 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1] and _\ud835\udc4b_ \u2229 _\ud835\udc46_ is not an ( _\u2113_ \u2212 _\ud835\udc51_ )-color set in any _\u2113_ -coloring of\n_\ud835\udc3a_ [ _\ud835\udc4b_ ]. Note that we must give a color to the last received vertex before aborting.\nFor the instance _\ud835\udc43_ of the subproblem, we denote _\ud835\udc46_ and _\ud835\udc47_ for this subproblem as _\ud835\udc46_ ( _\ud835\udc43_ ) and _\ud835\udc47_ ( _\ud835\udc43_ ).\n\n**Goal of subproblem.** From the next section, we present an online algorithm for the subproblem that, at\nany point (until aborting), uses:\n\nmax(| _\ud835\udc47_ | _, \ud835\udc5b_ 1\u2212 _\ud835\udc51\ud835\udf16_ )\n_\ud835\udc42_\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\ufffd\n\ncolors.\n\ufffd\n\nNote that if the level-0 subproblem aborts, the given graph _\ud835\udc3a_ is invalid (not locally _\u2113_ -colorable). This is\nbecause there exists a set _\ud835\udc4b_ \u2286 _\ud835\udc49_ where | _\ud835\udc4b_ | _<_ 2 [2] _[\u2113]_ and _\ud835\udc4b_ \u2229 _\ud835\udc46_ is not even an _\u2113_ -color set in any _\u2113_ -coloring of\n_\ud835\udc3a_ [ _\ud835\udc4b_ ], which means that _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b_ ]) _> \u2113_ . Therefore, given that the final graph _\ud835\udc3a_ is _\u2113_ -colorable, we will show\nthat our proposed algorithm for the else-problem uses _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ) colors.\n\n**Important Remarks.** In this section, we present our algorithm inductively (i.e., recursively) on both _\u2113_ and\n_\ud835\udc51_ . For this purpose, throughout this section, we assume that for all _\u2113_ [\u2032] _< \u2113_, there exists an online algorithm\nthat colors any locally _\u2113_ [\u2032] -colorable graph _\ud835\udc3a_ [\u2032] = ( _\ud835\udc49_ [\u2032] _, \ud835\udc38_ [\u2032] ) with _\ud835\udc42_ (| _\ud835\udc49_ [\u2032] | [1][\u2212][2][/(] _[\u2113]_ [\u2032] [(] _[\u2113]_ [\u2032] [\u2212][1][)+][2][)] ) colors, even when | _\ud835\udc49_ [\u2032] |\nis not known in advance (this is justified by Lemma 3.1). We denote such an algorithm by Locally( _\u2113_ [\u2032] ).\nNote that the base case for _\u2113_ is _\u2113_ = 1 (this case obviously holds).\nMoreover, we assume that for all _\ud835\udc51_ [\u2032] _> \ud835\udc51_, there exists an online algorithm that solves the level- _\ud835\udc51_ [\u2032]\n\nsubproblem with _\ud835\udc42_ (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [1][\u2212] _[\ud835\udc51]_ [\u2032] _[\ud835\udf16]_ )/ _\ud835\udc5b_ _[\ud835\udf16]_ ) colors. We denote such an algorithm by Subproblem( _\ud835\udc51_ [\u2032] ).\n\n**3.3** **Base case for the subproblem** ( _\ud835\udc51_ = _\u2113_ \u2212 1)\n\n**Lemma 3.3.** _The base case of the subproblem (level \ud835\udc51_ = _\u2113_ \u2212 1 _) can be solved with_\n\nmax(| _\ud835\udc47_ | _, \ud835\udc5b_ 1\u2212( _\u2113_ \u22121) _\ud835\udf16_ )\n_\ud835\udc42_\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\ufffd\n\n_colors._\n\ufffd\n\n_Proof._ Consider coloring vertices in _\ud835\udc47_ by running Locally( _\u2113_ \u2212 1). When _\ud835\udc3a_ [ _\ud835\udc47_ ] becomes not locally ( _\u2113_ \u2212 1)colorable, we can abort the procedure. To create an output for aborting, we first pick any _\ud835\udc4b\ud835\udc47_ \u2286 _\ud835\udc47_ such that\n_\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b\ud835\udc47_ ]) \u2265 _\u2113_ and | _\ud835\udc4b\ud835\udc47_ | _<_ 2 [2] _[\u2113]_ [\u2212][1] . Then, for each _\ud835\udc61_ \u2208 _\ud835\udc4b\ud835\udc47_, let up( _\ud835\udc61_ ) be one vertex selected from _\ud835\udc41\ud835\udc46_ ( _\ud835\udc61_ ) (if there\nare multiple vertices, we can select any). Let\n\n_\ud835\udc4b\ud835\udc46_ = {up( _\ud835\udc61_ ) : _\ud835\udc61_ \u2208 _\ud835\udc4b\ud835\udc47_ }\n\nand output _\ud835\udc4b_ = _\ud835\udc4b\ud835\udc46_ \u222a _\ud835\udc4b\ud835\udc47_ . The output _\ud835\udc4b_ satisfies the abort conditions, because (i) | _\ud835\udc4b_ | _<_ 2 [2] _[\u2113]_ [\u2212][1][+][1] and (ii)\n_\ud835\udc4b_ \u2229 _\ud835\udc46_ = _\ud835\udc4b\ud835\udc46_ is not a 1-color set in any _\u2113_ -coloring of _\ud835\udc4b_ ; if all the vertices in _\ud835\udc4b\ud835\udc46_ have the same color in some\n_\u2113_ -coloring of _\ud835\udc4b_, then _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b\ud835\udc47_ ]) \u2264 _\u2113_ \u2212 1 would hold, contradicting _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc4b\ud835\udc47_ ]) \u2265 _\u2113_ . It remains to bound the\nnumber of colors used. By induction on _\u2113_, the algorithm uses _\ud835\udc42_ (| _\ud835\udc47_ | [1][\u2212][2][/((] _[\u2113]_ [\u2212][1][) (] _[\u2113]_ [\u2212][2][)+][2][)] ) colors. Since\n\n2\n| _\ud835\udc47_ | [1][\u2212] ( _\u2113_ \u22121) ( _\u2113_ \u22122)+2 \u2264 [max][(|] _[\ud835\udc47]_ [|] _[, \ud835\udc5b]_ [1][\u2212(] _[\u2113]_ [\u2212][1][)] _[ \ud835\udf16]_ [)]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nfor _\ud835\udf16_ = _\u2113_ ( _\u2113_ \u221221)+2 [, the number of colors used is within the required bound. Note that we need one additional]\ncolor when aborting occurs, but it is negligible.\n\n9\n\n**3.4** **Inductive step on level** _\ud835\udc51_ **: Algorithm**\n\nSince we have solved the base case _\ud835\udc51_ = _\u2113_ \u2212 1 of the subproblem, our next goal is to solve the _\ud835\udc51_ \u2264 _\u2113_ \u2212 2 case,\nin the order of _\ud835\udc51_ = _\u2113_ \u2212 2 _, \u2113_ \u2212 3 _, . . .,_ 0. Our algorithm for coloring a vertex when a vertex in _\ud835\udc47_ arrives, for the\nlevel- _\ud835\udc51_ subproblem, is described in Algorithm 2.\n\n**Algorithm 2** Subproblem( _\ud835\udc51_ ) for _\ud835\udc51_ \u2264 _\u2113_ \u2212 2\n\n1: P _,_ Q \u2190[]\n\n2: _\ud835\udc37_ \u2190\u2205\n\n3: **for** each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ **do** _\u22b2\ud835\udc46_ is also updated accordingly\n\n4: _\ud835\udc41_ [\u2032]\n_\ud835\udc46_ [(] _[\ud835\udc63]_ [) \u2190] [(the first] _[ \ud835\udefe][\ud835\udc51]_ [+][1][ elements in] _[ \ud835\udc41][\ud835\udc46]_ [(] _[\ud835\udc63]_ [)][)]\n\n5: **if** for some _\ud835\udc56, \ud835\udc57_, | _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc63]_ [) \u2229] _[\ud835\udc46]_ [(] _[\ud835\udc43][\ud835\udc56, \ud835\udc57]_ [)| \u2265] _[\ud835\udefe][\ud835\udc51]_ [+][2][ and] _[ \ud835\udc43][\ud835\udc56, \ud835\udc57]_ [is not aborted yet] **[ then]**\n\n6: color _\ud835\udc63_ using subroutine _\ud835\udc43\ud835\udc56, \ud835\udc57_ (by adding _\ud835\udc63_ to _\ud835\udc47_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ )) _\u22b2_ Use Subproblem( _\ud835\udc51_ + 1)\n\n7: **else**\n\n8: _\ud835\udc37_ \u2190 _\ud835\udc37_ \u222a{ _\ud835\udc63_ }\n\n9: color _\ud835\udc63_ with Locally( _\ud835\udc51_ ) (on _\ud835\udc37_ )\n\n10: **if** _\ud835\udc3a_ [ _\ud835\udc37_ ] is not locally _\ud835\udc51_ -colorable anymore **then**\n\n11: find _\ud835\udc37_ [\u2032] \u2286 _\ud835\udc37_ such that _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc37_ [\u2032] ]) _> \ud835\udc51_ and | _\ud835\udc37_ [\u2032] | _<_ 2 [2] _[\ud835\udc51]_\n\n12: add _\ud835\udc37_ [\u2032] to Q\n\n13: **for** each _\ud835\udc5e\ud835\udc56, \ud835\udc57_ \u2208 _\ud835\udc37_ [\u2032] **do**\n\n14: initiate a new instance _\ud835\udc43\ud835\udc56, \ud835\udc57_ of the level-( _\ud835\udc51_ + 1) subproblem, and set _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) \u2190 _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc5e][\ud835\udc56, \ud835\udc57]_ [)]\n\n15: add the list of initiated subproblems [ _\ud835\udc43\ud835\udc56,_ 1 _, . . ., \ud835\udc43\ud835\udc56,_ | _\ud835\udc37_ \u2032 |] to P\n\n16: _\ud835\udc37_ \u2190\u2205\n\n17: **if** for some _\ud835\udc56_, subroutines _\ud835\udc43\ud835\udc56,_ 1 _, . . ., \ud835\udc43\ud835\udc56,_ | P _\ud835\udc56_ | are all aborted **then**\n\n18: **for** _\ud835\udc57_ = 1 _,_ 2 _, . . .,_ |P _\ud835\udc56_ | **do**\n\n19: _\ud835\udc4b_ _\ud835\udc57_ \u2190 (the returned set for _\ud835\udc43\ud835\udc56, \ud835\udc57_ )\n\n20: **return** _\ud835\udc4b_ \u2190( _\ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc4b_ | P _\ud835\udc56_ |) \u222a _\ud835\udc44\ud835\udc56_ and abort the procedure\n\n**Overview of Subproblem** ( _\ud835\udc51_ ) **.** Below, we describe how Subproblem( _\ud835\udc51_ ) works. First, the key intuition is\nthe following:\n\nAssume that a small subset _\ud835\udc37_ [\u2032] \u2286 _\ud835\udc47_ with _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc37_ [\u2032] ]) _> \ud835\udc51_ exists. Then, for at least one _\ud835\udc65_ \u2208 _\ud835\udc37_ [\u2032],\nthe subset _\ud835\udc41\ud835\udc46_ ( _\ud835\udc65_ ) forms a level-( _\ud835\udc51_ + 1) set, which is easier to handle (i.e., by induction, we can\napply the level _\ud835\udc51_ [\u2032] _> \ud835\udc51_ subproblem), and therefore leads to some profit for future vertices (as we\nprove in Lemma 3.4). See subsubsection 1.2.1 for examples ( _\ud835\udc37_ [\u2032] can be a vertex when _\ud835\udc51_ = 0,\nand _\ud835\udc37_ [\u2032] can be two adjacent vertices when _\ud835\udc51_ = 1).\n\nIn our algorithm, to color the vertices in _\ud835\udc47_, we normally use Locally( _\ud835\udc51_ ) (Figure 7 left). When _\ud835\udc3a_ [ _\ud835\udc47_ ] becomes\nnot locally _\ud835\udc51_ -colorable, we can find a subset _\ud835\udc37_ [\u2032] \u2286 _\ud835\udc47_ such that | _\ud835\udc37_ [\u2032] | _<_ 2 [2] _[\ud835\udc51]_ and _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc37_ [\u2032] ]) _> \ud835\udc51_ . For each\n_\ud835\udc65_ \u2208 _\ud835\udc37_ [\u2032], we simultaneously initiate a new instance _\ud835\udc43_ of the level-( _\ud835\udc51_ + 1) subproblem where _\ud835\udc46_ ( _\ud835\udc43_ ) = _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc65]_ [)]\n(Figure 7 middle) and _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc65]_ [)][ is the first] _[ \ud835\udefe][\ud835\udc51]_ [+][1][ vertices of] _[ \ud835\udc41][\ud835\udc46]_ [(] _[\ud835\udc65]_ [)][. From now on, we refer to these initiated]\nlevel-( _\ud835\udc51_ + 1) subproblem instances as _subroutines_, for the sake of coloring the \u201cfuture\u201d vertices efficiently.\nThe important fact is that, as long as _\ud835\udc46_ is a level- _\ud835\udc51_ set, at least one subroutine must survive (Lemma 3.4).\nAfter the initiation, we now color a newly arrived vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ in either of the following ways (Figure 7\nright): (1) color _\ud835\udc63_ with an already initiated subroutine _\ud835\udc43_ when the number of neighbors of _\ud835\udc63_ to _\ud835\udc46_ ( _\ud835\udc43_ ) is _\ud835\udefe\ud835\udc51_ +2\nor more (otherwise, this would violate the input condition of the level-( _\ud835\udc51_ + 1) subproblem), or (2) color\n\n10\n\n_\ud835\udc63_ with Locally( _\ud835\udc51_ ) again, with completely new colors. [10] Since the number of times that the initiation of\nnew subroutines occurs is _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udf16]_ ) due to the values _\ud835\udefe\ud835\udc51, \ud835\udefe\ud835\udc51_ +1, and _\ud835\udefe\ud835\udc51_ +2 (Lemma 3.7), this algorithm uses the\nrequired number of colors.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-12-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-12-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-12-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-12-3.png)\n\nFigure 7: The sketch of the procedure when _\ud835\udc51_ = 2. In the middle and the right figure, each\nbig rounded blue square in _\ud835\udc46_ is the set of adjacent vertices for each _\ud835\udc63_ \u2208 _\ud835\udc37_ [\u2032] .\n\n**Implementation.** To implement this idea, let us first note that when a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ arrives, we have already\nrecorded the current locally _\ud835\udc51_ -colorable subset _\ud835\udc37_ \u2286 _\ud835\udc47_ (initially, _\ud835\udc37_ is empty).\nWe also recorded the list of currently initiated subroutines by a two-dimensional array P = [P1 _,_ P2 _, . . ._ ] =\n\n[[ _\ud835\udc43_ 1 _,_ 1 _, . . ., \ud835\udc43_ 1 _,_ | P1 |] _,_ [ _\ud835\udc43_ 2 _,_ 1 _, . . ., \ud835\udc43_ 2 _,_ | P2 |] _, . . ._ ] (again initially empty), where for each _\ud835\udc56, \ud835\udc57_, a subroutine _\ud835\udc43\ud835\udc56, \ud835\udc57_ was\ninitiated, and the subroutines in the same P _\ud835\udc56_ were initiated at the same time.\nWe also recorded the list of small non- _\ud835\udc51_ -colorable subgraphs that caused the initiation of subroutines by\nan array of vertex sets Q = [ _\ud835\udc44_ 1 _, \ud835\udc44_ 2 _, . . ._ ], where each _\ud835\udc44\ud835\udc56_ = { _\ud835\udc5e\ud835\udc56,_ 1 _, . . ., \ud835\udc5e\ud835\udc56,_ | P _\ud835\udc56_ | } comes from _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) = _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc5e][\ud835\udc56, \ud835\udc57]_ [)]\nfor each _\ud835\udc57_ (Figure 8 left). Then, for each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_, we run the following procedure:\n\n1. If there exists some _\ud835\udc56, \ud835\udc57_ such that | _\ud835\udc41\ud835\udc46_ [\u2032] [(] _[\ud835\udc63]_ [) \u2229] _[\ud835\udc46]_ [(] _[\ud835\udc43][\ud835\udc56, \ud835\udc57]_ [)| \u2265] _[\ud835\udefe][\ud835\udc51]_ [+][2][ and] _[ \ud835\udc43][\ud835\udc56, \ud835\udc57]_ [is not aborted, we color] _[ \ud835\udc63]_ [with]\nsubroutine _\ud835\udc43\ud835\udc56, \ud835\udc57_ (lines 5\u20136).\n\n2. Otherwise, color _\ud835\udc63_ with Locally( _\ud835\udc51_ ), and add _\ud835\udc63_ to _\ud835\udc37_ (lines 8\u20139). If _\ud835\udc3a_ [ _\ud835\udc37_ ] becomes not locally\n_\ud835\udc51_ -colorable, we initiate new subroutines. We add the list of initiated subroutines to P and the small\nnon- _\ud835\udc51_ -colorable subgraph to Q. We also reset _\ud835\udc37_ (lines 10\u201316).\n\nNote that at the timing when _\ud835\udc3a_ [ _\ud835\udc37_ ] becomes not locally _\ud835\udc51_ -colorable, we must pay one additional color\nto color _\ud835\udc63_ . From now on, we must use different colors at line 9.\n\nNote that for 1, we use completely different colors among different subroutines, e.g., between _\ud835\udc43_ 1 _,_ 1 and _\ud835\udc43_ 1 _,_ 2.\nIf all the subroutines initiated at the same time are aborted, it turns out that the assumption of the original\nsubproblem is violated, so the original subproblem itself can be aborted (lines 18\u201320). Now for 2, after\ncoloring _\ud835\udc63_, we update P and Q for the sake of coloring \u201cfuture\u201d vertices, but to be clear, the returned set\n( _\ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc4b_ | P _\ud835\udc56_ |) \u222a _\ud835\udc44\ud835\udc56_ is shown in Figure 8 right, where set _\ud835\udc4b_ _\ud835\udc57_ is the output of the aborted subroutine\n_\ud835\udc43\ud835\udc56, \ud835\udc57_ (see line 19).\n\n10This means that we do not use the colors used in Locally( _\ud835\udc51_ ) before the initiation of new subroutines. If the subgraph consisting\nof the vertices colored by Locally( _\ud835\udc51_ ) (after the last initiation of subroutines) becomes not locally _\ud835\udc51_ -colorable, we initiate a new\nsubroutine and restart Locally( _\ud835\udc51_ ) again.\n\n11\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-13-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-13-0.png)\n\n|\ud835\udc5e1,1|\ud835\udc5e12<br>,|\ud835\udc5e1,3|Col4|\ud835\udf12 \ud835\udc3a \ud835\udc44 \ud835\udc56 > \ud835\udc51 is met|\n|---|---|---|---|---|\n|\ud835\udc5e1,1|\ud835\udc5e1,2|\ud835\udc5e1,3|||\n\nFigure 8: Left: the relationship between arrays P and Q. The red triangle shows the adjacency\nbetween vertex _\ud835\udc5e\ud835\udc56, \ud835\udc57_ and the vertex set _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ). Note that subroutines _\ud835\udc43_ 1 _,_ 1 _, \ud835\udc43_ 1 _,_ 2 _, \ud835\udc43_ 1 _,_ 3 are\ninitiated earlier than subroutines _\ud835\udc43_ 2 _,_ 1 _, \ud835\udc43_ 2 _,_ 2 _, \ud835\udc43_ 2 _,_ 3. Right: an example of graph _\ud835\udc3a_ [ _\ud835\udc4b_ ] for the\naborting output _\ud835\udc4b_, when _\ud835\udc51_ = 2. The output set _\ud835\udc4b_ is the set of dark (red, dark blue, and orange)\nvertices.\n\n**3.5** **Inductive step on level** _\ud835\udc51_ **: Analysis**\n\nIn this subsection, we discuss the correctness of our proposed algorithm and analyze the number of colors\nused. The goal is to show that we achieve _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] ) colors (Theorem 3.9).\n\n**Lemma 3.4.** _If the procedure Subproblem_ ( _\ud835\udc51_ ) _aborts, for the returned set \ud835\udc4b_ _at line 20, \ud835\udc4b_ \u2229 _\ud835\udc46_ _is not a_\n( _\u2113_ \u2212 _\ud835\udc51_ ) _-color set in any \u2113-coloring of \ud835\udc3a_ [ _\ud835\udc4b_ ] _(see Figure 8 right for the structure of \ud835\udc3a_ [ _\ud835\udc4b_ ] _)._\n\n_Proof._ Suppose for a contradiction that _\ud835\udc4b_ \u2229 _\ud835\udc46_ is an ( _\u2113_ \u2212 _\ud835\udc51_ )-color set in some _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ], that is,\nthere exists an _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ] that colors _\ud835\udc4b_ \u2229 _\ud835\udc46_ by colors {1 _,_ 2 _, . . ., \u2113_ \u2212 _\ud835\udc51_ }. Then, a contradiction occurs\nbetween the following two:\n\n1. By _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc44\ud835\udc56_ ]) _> \ud835\udc51_, at least one vertex in _\ud835\udc44\ud835\udc56_, say _\ud835\udc5e\ud835\udc56, \ud835\udc57_, is colored by some color _\ud835\udc5f_ \u2208{1 _,_ 2 _, . . ., \u2113_ \u2212 _\ud835\udc51_ },\nin that _\u2113_ -coloring. Since _\ud835\udc5e\ud835\udc56, \ud835\udc57_ is adjacent to all vertices in _\ud835\udc4b_ _\ud835\udc57_ \u2229 _\ud835\udc46_, the vertices in _\ud835\udc4b_ _\ud835\udc57_ \u2229 _\ud835\udc46_ are colored by\ncolors {1 _,_ 2 _, . . ., \u2113_ \u2212 _\ud835\udc51_ } \\ { _\ud835\udc5f_ }, so _\ud835\udc4b_ _\ud835\udc57_ \u2229 _\ud835\udc46_ is an ( _\u2113_ \u2212 _\ud835\udc51_ \u2212 1)-color set in some _\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ _\ud835\udc57_ ].\n\n2. By the assumption on the returned set for aborting, _\ud835\udc4b_ _\ud835\udc57_ \u2229 _\ud835\udc46_ is not an ( _\u2113_ \u2212 _\ud835\udc51_ \u2212 1)-color set in any\n_\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ _\ud835\udc57_ ].\n\nTherefore, Lemma 3.4 holds.\n\n**Lemma 3.5.** _For the returned set \ud835\udc4b,_ | _\ud835\udc4b_ | _<_ 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1] _holds._\n\n_Proof._ First, by line 20, | _\ud835\udc4b_ | \u2264| _\ud835\udc4b_ 1| + | _\ud835\udc4b_ 2| + \u00b7 \u00b7 \u00b7 + | _\ud835\udc4b_ | P _\ud835\udc56_ | | + | _\ud835\udc44\ud835\udc56_ | holds. By | _\ud835\udc4b\ud835\udc56_ | _<_ 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1][+][1] (by induction on\n_\ud835\udc51_ ) and |P _\ud835\udc56_ | _,_ | _\ud835\udc44\ud835\udc56_ | _<_ 2 [2] _[\ud835\udc51]_ (by induction on _\u2113_ ), we have:\n\n| _\ud835\udc4b_ | \u2264 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1][+][1] \u2212 1                          - 2 [2] _[\ud835\udc51]_ \u2212 1 + 2 [2] _[\ud835\udc51]_ \u2212 1 _<_ 2 [2] _[\u2113]_ [\u2212][2] _[\ud835\udc51]_ [+][1]\n\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\n\nTherefore, Lemma 3.5 holds.\n\nNext, we analyze the number of colors used in this procedure. To this end, we first show the following\nlemma (which follows from Problem 13.13 in [20]; for completeness, we give a proof here.)\n\n**Lemma 3.6** ([20]) **.** _Let \ud835\udc60, \ud835\udc4e_ \u2265 1 _be real numbers such that_ | _\ud835\udc46_ | \u2264 _\ud835\udc60. Let \ud835\udc34_ 1 _, . . ., \ud835\udc34\ud835\udc5a_ \u2286 _\ud835\udc46_ _be sets that_ | _\ud835\udc34\ud835\udc56_ | \u2265 _\ud835\udc4e_ _[\ud835\udc60]_\n\n_for each \ud835\udc56_ _and_ | _\ud835\udc34\ud835\udc56_ \u2229 _\ud835\udc34_ _\ud835\udc57_ | \u2264 2 _\ud835\udc4e\ud835\udc60_ [2] _[for each][ \ud835\udc56, \ud835\udc57]_ [(] _[\ud835\udc56]_ [\u2260] _[\ud835\udc57]_ [)] _[. Then,][ \ud835\udc5a<]_ [ 2] _[\ud835\udc4e]_ _[must hold.]_\n\n12\n\n_Proof._ First, _\ud835\udc34_ 1 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc34\ud835\udc5a_ is the disjoint union of _\ud835\udc34\ud835\udc56_ \\ ( _\ud835\udc34_ 1 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc34\ud835\udc56_ \u22121) for _\ud835\udc56_ = 1 _, . . ., \ud835\udc5a_ . Since\n\n_\ud835\udc60_\n\n| _\ud835\udc34\ud835\udc56_ \\ ( _\ud835\udc34_ 1 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc34\ud835\udc56_ \u22121)| \u2265 max(| _\ud835\udc34\ud835\udc56_ | \u2212(| _\ud835\udc34_ 1 \u2229 _\ud835\udc34\ud835\udc56_ | + \u00b7 \u00b7 \u00b7 + | _\ud835\udc34\ud835\udc56_ \u22121 \u2229 _\ud835\udc34\ud835\udc56_ |) _,_ 0) \u2265 max( _\ud835\udc4e_ _[\ud835\udc60]_ [\u2212(] _[\ud835\udc56]_ [\u2212] [1][) \u00b7] 2 _\ud835\udc4e_ [2] _[,]_ [ 0][)][:]\n\n_\ud835\udc60_ _\ud835\udc60_\n\n_\ud835\udc4e_ [\u2212(] _[\ud835\udc56]_ [\u2212] [1][) \u00b7] 2 _\ud835\udc4e_ [2] _[,]_ [ 0] \ufffd\n\n| _\ud835\udc46_ | \u2265| _\ud835\udc34_ 1 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc34\ud835\udc5a_ | \u2265\n\n_\ud835\udc5a_\n\u2211\ufe01\n\n_\ud835\udc60_\nmax\n\n\u2211\ufe01 \ufffd _\ud835\udc4e_\n\n_\ud835\udc56_ =1\n\nThe right-hand side is an increasing function of _\ud835\udc5a_, and its value is _[\ud835\udc5a]_ [(][4] _[\ud835\udc4e]_ 4 [\u2212] _\ud835\udc4e_ [(][2] _[\ud835\udc5a]_ [+][1][))] _\ud835\udc60_ for _\ud835\udc5a_ \u2264 2 _\ud835\udc4e_ + 1. This value\n\nexceeds _\ud835\udc60_ at _\ud835\udc5a_ = 2 _\ud835\udc4e_, so due to | _\ud835\udc46_ | \u2264 _\ud835\udc60_, the inequality above does not hold for _\ud835\udc5a_ \u2265 2 _\ud835\udc4e_ . Hence, _\ud835\udc5a<_ 2 _\ud835\udc4e_ .\n\n**Lemma 3.7.** |P| = _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udf16]_ ) _holds._\n\n_Proof._ While the procedure is not aborted, for each _\ud835\udc56_, there exists _\ud835\udc61\ud835\udc56_ such that _\ud835\udc43\ud835\udc56,\ud835\udc61\ud835\udc56_ is not aborted. We let\n_\ud835\udc34\ud835\udc56_ = _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56,\ud835\udc61\ud835\udc56_ ) for such _\ud835\udc61\ud835\udc56_ . Obviously, | _\ud835\udc46_ | \u2264 _\ud835\udefe\ud835\udc51_, | _\ud835\udc34\ud835\udc56_ | \u2265 _\ud835\udefe\ud835\udc51_ +1, and _\ud835\udc34\ud835\udc56_ \u2286 _\ud835\udc46_ .\nAlso, | _\ud835\udc34\ud835\udc56_ \u2229 _\ud835\udc34_ _\ud835\udc57_ | \u2264 _\ud835\udefe\ud835\udc51_ +2 holds for each _\ud835\udc56, \ud835\udc57_ ( _\ud835\udc56< \ud835\udc57_ ). This is because vertex _\ud835\udc5e_ _\ud835\udc57,\ud835\udc61_ _\ud835\udc57_ arrives after P _\ud835\udc56_ has been\nadded to P (by _\ud835\udc56< \ud835\udc57_ and the reset of _\ud835\udc37_ on line 16). This means that if | _\ud835\udc34\ud835\udc56_ \u2229 _\ud835\udc34_ _\ud835\udc57_ | _> \ud835\udefe\ud835\udc51_ +2, vertex _\ud835\udc5e_ _\ud835\udc57,\ud835\udc61_ _\ud835\udc57_ should\nhave been colored by subroutine _\ud835\udc43\ud835\udc56,\ud835\udc61\ud835\udc56_ due to line 5, which is a contradiction.\nThus, by applying Lemma 3.6 with _\ud835\udc60_ = _\ud835\udefe\ud835\udc51_ and _\ud835\udc4e_ = 2 _[\ud835\udc51]_ _\ud835\udc5b_ _[\ud835\udf16]_ (note that | _\ud835\udc34\ud835\udc56_ | \u2265 _\ud835\udefe\ud835\udc51_ +1 = _[\ud835\udefe][\ud835\udc51]_ [and][ |] _[\ud835\udc34][\ud835\udc56]_ [\u2229] _[\ud835\udc34]_ _[\ud835\udc57]_ [| \u2264]\n\nThus, by applying Lemma 3.6 with _\ud835\udc60_ = _\ud835\udefe\ud835\udc51_ and _\ud835\udc4e_ = 2 _\ud835\udc5b_ _[\ud835\udf16]_ (note that | _\ud835\udc34\ud835\udc56_ | \u2265 _\ud835\udefe\ud835\udc51_ +1 = _\ud835\udc4e_ _[\ud835\udc51]_ [and][ |] _[\ud835\udc34][\ud835\udc56]_ [\u2229] _[\ud835\udc34]_ _[\ud835\udc57]_ [| \u2264]\n\n_\ud835\udefe\ud835\udc51_ +2 = _[\ud835\udefe][\ud835\udc51]_ [2] [), we obtain][ |P|] _[ <]_ [ 2] _[\ud835\udc4e]_ [=] _[ \ud835\udc42]_ [(] _[\ud835\udc5b][\ud835\udf16]_ [)][.]\n\n2 _\ud835\udc4e_ _[\ud835\udc51]_ [2] [), we obtain][ |P|] _[ <]_ [ 2] _[\ud835\udc4e]_ [=] _[ \ud835\udc42]_ [(] _[\ud835\udc5b][\ud835\udf16]_ [)][.]\n\n**Lemma 3.8.** _Suppose \ud835\udc51_ \u2264 _\u2113_ \u2212 2 _. Before the procedure for the level-\ud835\udc51_ _subproblem aborts, it uses_\n\nmax(| _\ud835\udc47_ | _, \ud835\udc5b_ 1\u2212 _\ud835\udc51\ud835\udf16_ )\n_\ud835\udc42_\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\ufffd\n\n_colors._\n\ufffd\n\n_Proof._ First, it suffices to consider the case when | _\ud835\udc47_ | \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ . This is because if we only use _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ )\ncolors when | _\ud835\udc47_ | = _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_, it is trivial that we only use _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ ) colors when | _\ud835\udc47_ | _< \ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_, which matches\nthe requirement. Let _\ud835\udc50_ 1 and _\ud835\udc50_ 2 be the number of colors used for coloring vertices in _\ud835\udc37_ (line 9) and level-( _\ud835\udc51_ +1)\nsubroutines (line 6), respectively. Then, when | _\ud835\udc47_ | \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_, the number of colors used for the subproblem is\n_\ud835\udc50_ 1 + _\ud835\udc50_ 2 colors, and each case is as follows:\n\n- _\ud835\udc50_ 1: By Lemma 3.7, we run Locally( _\ud835\udc51_ ) for at most |P| = _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udf16]_ ) times. By induction on _\u2113_, each run\nrequires _\ud835\udc42_ (| _\ud835\udc37_ | [1][\u2212][2][/(] _[\ud835\udc51]_ [(] _[\ud835\udc51]_ [\u2212][1][)+][2][)] ) colors. Since | _\ud835\udc37_ | [1][\u2212][2][/(] _[\ud835\udc51]_ [(] _[\ud835\udc51]_ [\u2212][1][)+][2][)] is a concave function of | _\ud835\udc37_ |, the worst\ncase is when |P| = \u0398( _\ud835\udc5b_ _[\ud835\udf16]_ ) and | _\ud835\udc37_ | = \u0398( [|] _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [)][ for all runs. In such a case, each run requires only] _[ \ud835\udc42]_ [(] [|] _[\ud835\udc37]_ ~~_[\ud835\udf16]_~~ [|] [)]\n\n[|] _[\ud835\udc47]_ [|] [|] _[\ud835\udc37]_ [|]\n\n_\ud835\udc5b_ ~~_[\ud835\udf16]_~~ [)][ for all runs. In such a case, each run requires only] _[ \ud835\udc42]_ [(] _\ud835\udc5b_ ~~_[\ud835\udf16]_~~\n\ncase is when |P| = \u0398( _\ud835\udc5b_ _[\ud835\udf16]_ ) and | _\ud835\udc37_ | = \u0398( _\ud835\udc5b_ ~~_[\ud835\udf16]_~~ [)][ for all runs. In such a case, each run requires only] _[ \ud835\udc42]_ [(] _\ud835\udc5b_ ~~_[\ud835\udf16]_~~ [)]\n\ncolors because\n\n2\n| _\ud835\udc37_ | [1][\u2212] _\ud835\udc51_ ( _\ud835\udc51_ \u22121)+2 \u2264 [|] _[\ud835\udc37]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nholds when | _\ud835\udc47_ | \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ (i.e., | _\ud835\udc37_ | = \u03a9( _\ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ )) and _\ud835\udf16_ = _\u2113_ ( _\u2113_ \u221221)+2 [. Therefore,] _[ \ud835\udc50]_ [1][ =] _[ \ud835\udc42]_ [(] [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [)][.]\n\n- _\ud835\udc50_ 2: By induction on _\ud835\udc51_ :\n\n\ufffd\n\n_\ud835\udc50_ 2 = _\ud835\udc42_\n\n\ufffd\u2211\ufe01 _\ud835\udc56, \ud835\udc57_\n\nmax(| _\ud835\udc47_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ )| _, \ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ )\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nand by _\ud835\udc56_ = _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udf16]_ ) (Lemma 3.7), _\ud835\udc57_ = _\ud835\udc42_ (1) (by line 11), and [\ufffd] _\ud835\udc56, \ud835\udc57_ [|] _[\ud835\udc47]_ [(] _[\ud835\udc43]_ _\ud835\udc56, \ud835\udc57_ [)| \u2264|] _[\ud835\udc47]_ [|][, we have] _[ \ud835\udc50]_ 2 [=] _[ \ud835\udc42]_ [(] [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [)][.]\n\nTherefore, _\ud835\udc50_ 1 + _\ud835\udc50_ 2 = _\ud835\udc42_ ( [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [)][ when][ |] _[\ud835\udc47]_ [| \u2265] _[\ud835\udc5b]_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ [, and][ Lemma 3.8][ follows.]\n\n**Theorem 3.9.** _There exists a deterministic online algorithm that colors any locally \u2113-colorable graphs with_\n_\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] ) _colors, for \u2113_ \u2265 2 _._\n\n13\n\n_Proof._ First, we show that Subproblem( _\ud835\udc51_ ) successfully solves the level- _\ud835\udc51_ subproblem. To prove the\ncorrectness, we must prove the following three: (1) upon aborting, _\ud835\udc4b_ \u2229 _\ud835\udc46_ is not a ( _\u2113_ \u2212 _\ud835\udc51_ )-color set in any\n_\u2113_ -coloring of _\ud835\udc3a_ [ _\ud835\udc4b_ ], (2) | _\ud835\udc4b_ | is within the limit, and (3) the number of colors used is as we claimed. (1)\nfollows from Lemma 3.3 and Lemma 3.4, (2) follows from Lemma 3.3 and Lemma 3.5, and (3) follows from\nLemma 3.3 and Lemma 3.8. Therefore, Subproblem( _\ud835\udc51_ ) works successfully.\nBy applying Subproblem( _\ud835\udc51_ ) for _\ud835\udc51_ = _\u2113_ \u2212 1 _, \u2113_ \u2212 2 _, . . .,_ 0, Subproblem(0) solves the else-problem using\n_\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ) colors. Combining this with Algorithm 1, by induction on _\u2113_, we obtain a deterministic online\nalgorithm that colors any locally _\u2113_ -colorable graph using _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ ) colors. This result also holds when the\nnumber of vertices _\ud835\udc5b_ is not known in advance, due to Lemma 3.1. Therefore, Theorem 3.9 holds.\n\n**3.6** **The improvement**\n\nIn the previous subsections, we showed a deterministic algorithm that colors any locally _\u2113_ -colorable graph\nwith _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] ) colors. This algorithm also colors _\ud835\udc58_ -colorable graphs with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][)+][2][)] )\ncolors, because _\ud835\udc58_ -colorable graphs are always locally _\ud835\udc58_ -colorable. Compared to the current best result of\n_\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] ) colors, the exponential becomes quadratic, which is already a big improvement.\nIn this subsection, we further improve the result to _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] ) colors. The key to the improvement\nis that, while only an _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][2] )-color algorithm is known for locally 2-colorable graphs, there is an _\ud835\udc42_ (log _\ud835\udc5b_ )color algorithm for 2-colorable (bipartite) graphs, by Lov\u00b4asz, Saks, and Trotter [21]. We define the following\nsubproblem, where the _\ud835\udc51_ = 0 case is the same as the else-problem when the given graph _\ud835\udc3a_ is _\ud835\udc58_ -colorable\n(not just locally _\ud835\udc58_ -colorable). Then, we can use the _\ud835\udc42_ (log _\ud835\udc5b_ )-color algorithm as the base case ( _\ud835\udc58_ = 2).\n\n**Subproblem+.** We consider a modification of the subproblem, [11] which is specifically created for the case\nwhen _\ud835\udc3a_ is _\ud835\udc58_ -colorable. We set _\ud835\udf16_ = _\ud835\udc58_ ( _\ud835\udc58_ 2\u22121) [, and guarantee the constraints on][ |] _[\ud835\udc46]_ [|][ and][ |] _[\ud835\udc41][\ud835\udc46]_ [(] _[\ud835\udc63]_ [)|][ with the new]\n_\ud835\udf16_ . We can also assume that _\ud835\udc46_ is a ( _\ud835\udc58_ \u2212 _\ud835\udc51_ )-color set in some _\ud835\udc58_ -coloring of _\ud835\udc3a_ . The aborting condition also\nchanges; we can abort if it turns out that _\ud835\udc46_ is not a ( _\ud835\udc58_ \u2212 _\ud835\udc51_ )-color set. Note that, since the procedure only\nknows the information of _\ud835\udc3a_ [ _\ud835\udc46_ \u222a _\ud835\udc47_ ], aborting is a valid move only when _\ud835\udc46_ is not a ( _\ud835\udc58_ \u2212 _\ud835\udc51_ )-color set in some\n_\ud835\udc58_ -coloring of _\ud835\udc3a_ [ _\ud835\udc46_ \u222a _\ud835\udc47_ ]. We are not required to return anything when aborting.\n\nOur objective is to give an algorithm with the following number of colors (until aborting):\n\n\ufffd max(| _\ud835\udc47_ | _, \ud835\udc5b_ 1\u2212 _\ud835\udc51\ud835\udf16_ )\n_\ud835\udc42_\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\ufffd\n\n_._\n\ufffd\n\n**Solution to subproblem+.** First, we consider the base case _\ud835\udc51_ = _\ud835\udc58_ \u2212 1. Let Coloring( _\ud835\udc58_ \u2212 1) be an\nonline algorithm that colors any ( _\ud835\udc58_ \u2212 1)-colorable graph _\ud835\udc3a_ [\u2032] = ( _\ud835\udc49_ [\u2032] _, \ud835\udc38_ [\u2032] ) using _\ud835\udc42_ [\ufffd] (| _\ud835\udc49_ [\u2032] | [1][\u2212][2][/((] _[\ud835\udc58]_ [\u2212][1][) (] _[\ud835\udc58]_ [\u2212][2][))] ) colors.\nNote that such an algorithm exists by induction on _\ud835\udc58_, where the base case is _\ud835\udc58_ = 2, in which case, as\nmentioned above, an _\ud835\udc42_ (log | _\ud835\udc49_ [\u2032] |)-color algorithm exists [21]. Then, the base case can be solved by running\nColoring( _\ud835\udc58_ \u2212 1), because, if _\ud835\udc46_ is a 1-color set, _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc47_ ]) \u2264 _\ud835\udc58_ \u2212 1 holds. Since\n\n2\n| _\ud835\udc47_ | [1][\u2212] ( _\ud835\udc58_ \u22121) ( _\ud835\udc58_ \u22122) \u2264 [max][(|] _[\ud835\udc47]_ [|] _[, \ud835\udc5b]_ [1][\u2212(] _[\ud835\udc58]_ [\u2212][1][)] _[ \ud835\udf16]_ [)]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nholds when _\ud835\udf16_ = _\ud835\udc58_ ( _\ud835\udc58_ 2\u22121) [, the required number of colors is satisfied.]\nNext, for the case of _\ud835\udc51_ \u2208{0 _,_ 1 _, . . ., \ud835\udc58_ \u2212 2} inductively, the same algorithm as Algorithm 2 works, because\nof the following Lemma 3.10 and Lemma 3.11.\n\n11In subproblem+, we consider the setting of subgraph _\ud835\udc3a_ [ _\ud835\udc46_ \u222a _\ud835\udc47_ ] ( _\ud835\udc46_ \u2286 _\ud835\udc46_ 0 _,\ud835\udc47_ \u2286 _\ud835\udc47_ 0), similarly to the original subproblem.\n\n14\n\n**Lemma 3.10.** _If there is an \ud835\udc56_ _such that subroutines \ud835\udc43\ud835\udc56,_ 1 _, . . ., \ud835\udc43\ud835\udc56,_ | P _\ud835\udc56_ | _are all aborted at line 17, \ud835\udc46_ _is not a_\n( _\ud835\udc58_ \u2212 _\ud835\udc51_ ) _-color set in any \ud835\udc58-coloring of \ud835\udc3a._\n\n_Proof._ We prove this lemma in the same manner as Lemma 3.4. Suppose for a contradiction that _\ud835\udc46_ is a\n( _\ud835\udc58_ \u2212 _\ud835\udc51_ )-color set in some _\ud835\udc58_ -coloring of _\ud835\udc3a_, that is, there exists a _\ud835\udc58_ -coloring of _\ud835\udc3a_ that colors _\ud835\udc46_ by colors\n{1 _,_ 2 _, . . ., \ud835\udc58_ \u2212 _\ud835\udc51_ }. Then, a contradiction occurs between the following two:\n\n1. By _\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc44\ud835\udc56_ ]) _> \ud835\udc51_, at least one vertex in _\ud835\udc44\ud835\udc56_, say _\ud835\udc5e\ud835\udc56, \ud835\udc57_, is colored by some color _\ud835\udc5f_ \u2208{1 _,_ 2 _, . . ., \ud835\udc58_ \u2212 _\ud835\udc51_ },\nin that _\ud835\udc58_ -coloring. Since _\ud835\udc5e\ud835\udc56, \ud835\udc57_ is adjacent to all vertices in _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ), vertices in _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) are colored by\ncolors {1 _,_ 2 _, . . ., \ud835\udc58_ \u2212 _\ud835\udc51_ } \\ { _\ud835\udc5f_ }, so _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) is a ( _\ud835\udc58_ \u2212 _\ud835\udc51_ \u2212 1)-color set.\n\n2. By the assumption for aborting, _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) is not a ( _\ud835\udc58_ \u2212 _\ud835\udc51_ \u2212 1)-color set.\n\nTherefore, Lemma 3.10 holds.\n\n**Lemma 3.11.** _If the number of colors used in the base case \ud835\udc51_ = _\ud835\udc58_ \u2212 1 _satisfies the required number of colors,_\n_the number of colors used for \ud835\udc51_ \u2264 _\ud835\udc58_ \u2212 2 _also satisfies the required number of colors._\n\n_Proof._ Consider using the same manner as Lemma 3.8. Obviously, _\ud835\udc50_ 2 in Lemma 3.8 satisfies the required\nnumber of colors. _\ud835\udc50_ 1 also satisfies the required number of colors, because when _\ud835\udf16_ = _\ud835\udc58_ ( _\ud835\udc58_ 2\u22121) [,]\n\n2\n| _\ud835\udc37_ | [1][\u2212] _\ud835\udc51_ ( _\ud835\udc51_ \u22121)+2 \u2264 [|] _[\ud835\udc37]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nholds for all _\ud835\udc51_ \u2264 _\ud835\udc58_ \u2212 2 when | _\ud835\udc37_ | = \u0398( [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [)][. Therefore,][ Lemma 3.11][ holds.]\n\nBy Lemma 3.10 and Lemma 3.11, we now complete the proof of an _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] )-color algorithm\nfor _\ud835\udc58_ -colorable graphs, which is our best result obtained so far. Formally, we have the following theorem.\n\n**Theorem 3.12.** \ufffd _There exists a deterministic online algorithm that colors any \ud835\udc58-colorable graph with_\n_\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] ) _colors._\n\n**3.7** **Comparison with Kierstead\u2019s algorithm**\n\nAs mentioned in section 1, Kierstead discovered an algorithm that uses _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][/][3] ) colors for _\ud835\udc58_ = 3 and _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] )\ncolors for _\ud835\udc58_ = 4. These algorithms use a framework similar to the algorithm described in subsection 3.6.\nIndeed, although Kierstead employs his original _witness-tree_ idea, what he does is essentially the same as in\nsubsection 3.6. However, his ideas are not enough to give an algorithm for locally _\u2113_ -colorable graphs when\n_\u2113_ \u2265 3, and as a result, it is only possible to obtain an algorithm with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] ) colors. From subsection 3.2\nto subsection 3.5, we ultimately find an algorithm that also works for _\u2113_ \u2265 3, with _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] ) colors,\nleading to an improvement from exponential to quadratic.\n\n**3.8** **The competitive ratio**\n\nWe have shown a deterministic online algorithm to color locally _\u2113_ -colorable graphs with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] )\ncolors (Theorem 3.9). To analyze the competitive ratio of this algorithm, we need to examine the constant\nfactor in the number of colors.\n\n**Lemma 3.13.** _For the algorithms in section 3, the following statements hold for all \u2113_ \u2265 1 _and_ 0 \u2264 _\ud835\udc51_ \u2264 _\u2113_ \u2212 1 _,_\n_where \ud835\udf16_ = _\u2113_ ( _\u2113_ \u221221)+2 _[:]_\n\n_(a) The algorithm for locally \u2113-colorable graphs uses at most_ 2 [2] _[\u2113]_ [+][2]  - _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ _colors (when \ud835\udc5b_ _is not known in_\n_advance), and_\n\n15\n\n_(b) Subproblem_ ( _\ud835\udc51_ ) _uses at most_ 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][2]  - max(| _\ud835\udc47_ | _, \ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ )/ _\ud835\udc5b_ _[\ud835\udf16]_ _colors._\n\n_Proof._ We prove by induction on _\u2113_ . In order to prove the lemma for a pair ( _\u2113, \ud835\udc51_ ), we assume that (a) holds\nfor all smaller values of _\u2113_, and (b) holds for all larger values of _\ud835\udc51_ .\nFirst, we prove (a). It is obvious for _\u2113_ = 1. For _\u2113_ \u2265 2, in the case where _\ud835\udc5b_ is known in advance, we use\n2 [2] _[\u2113]_ [+][2] [\u2212][4] - _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_ colors for the else-problem (which is the same as Subproblem(0)) by assumption (b), and _\ud835\udc5b_ [1][\u2212] _[\ud835\udf16]_\n\ncolors for FirstFit. Since _\ud835\udc5b_ is not known in advance, the number of colors is multiplied by 4 (Lemma 3.1).\nSince 4 \u00b7 (2 [2] _[\u2113]_ [+][2] [\u2212][4] + 1) \u2264 2 [2] _[\u2113]_ [+][2], (a) holds.\nNext, we prove (b). For the base case _\ud835\udc51_ = _\u2113_ \u2212 1, by the proof of Lemma 3.3, we only use\n\n2 [2] _[\u2113]_ [+][1]                 - [max][(|] _[\ud835\udc47]_ [|] _[, \ud835\udc5b]_ [1][\u2212(] _[\u2113]_ [\u2212][1][)] _[ \ud835\udf16]_ [)]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\ncolors, which means that (b) holds. It remains to prove (b) for the cases where _\ud835\udc51_ \u2264 _\u2113_ \u2212 2. We follow the proof\nof Lemma 3.8; we define _\ud835\udc50_ 1 and _\ud835\udc50_ 2 in the same way, and assume | _\ud835\udc47_ | \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ . By the proof of Lemma 3.8,\n_\ud835\udc50_ 1 \u2264 2 [2] _[\ud835\udc51]_ [+][2] - [|] _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [\u00b7][ max][(] [|][ P] ~~_[\ud835\udf16]_~~ [|] _[,]_ [ 1][) \u2264] [2][2] _[\ud835\udc51]_ [+][2][+] _[\ud835\udc51]_ [+][1][ holds (by][ |P| \u2264] [2][ \u00b7] _\ud835\udefe\ud835\udc51_ [=][ 2] _[\ud835\udc51]_ [+][1] _[\ud835\udc5b][\ud835\udf16]_ [;][ Lemma 3.7][), and for] _[ \ud835\udc50]_ [2][,]\n\n[ P] [|] _\ud835\udefe\ud835\udc51_\n\n_\ud835\udc5b_ ~~_[\ud835\udf16]_~~ _[,]_ [ 1][) \u2264] [2][2] _[\ud835\udc51]_ [+][2][+] _[\ud835\udc51]_ [+][1][ holds (by][ |P| \u2264] [2][ \u00b7] _\ud835\udefe\ud835\udc51_ +1 [=][ 2] _[\ud835\udc51]_ [+][1] _[\ud835\udc5b][\ud835\udf16]_ [;][ Lemma 3.7][), and for] _[ \ud835\udc50]_ [2][,]\n\n[|] _[\ud835\udc47]_ [|] [|][ P] [|]\n\n_\ud835\udc5b_ ~~_[\ud835\udf16]_~~ [\u00b7][ max][(] _\ud835\udc5b_ ~~_[\ud835\udf16]_~~\n\n_\ud835\udc50_ 2 = 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][3][ \u2211\ufe01]\n\n_\ud835\udc56, \ud835\udc57_\n\nmax(| _\ud835\udc47_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ )| _, \ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ )\n\n\u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][3][ \u2211\ufe01]\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n_\ud835\udc56, \ud835\udc57_\n\n| _\ud835\udc47_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ )|\n\n+ _\ud835\udc5b_ [1][\u2212(] _[\ud835\udc51]_ [+][2][)] _[ \ud835\udf16]_\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\ufffd \ufffd\n\nholds. Here, _\ud835\udc56_ \u2264 2 - _\ud835\udefe\ud835\udefe\ud835\udc51\ud835\udc51_ +1 [=][ 2] _[\ud835\udc51]_ [+][1] _[\ud835\udc5b][\ud835\udf16]_ [(by][ Lemma 3.7][),] _[ \ud835\udc57]_ [\u2264] [2][2] _[\ud835\udc51]_ [(by line 11), and][ \ufffd] _\ud835\udc56, \ud835\udc57_ [|] _[\ud835\udc47]_ [(] _[\ud835\udc43]_ _\ud835\udc56, \ud835\udc57_ [)| \u2264|] _[\ud835\udc47]_ [|][. Therefore:]\n\n_\ud835\udc50_ 2 \u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][3][ \ufffd] [|] _[\ud835\udc47]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_ [+ (][2] _[\ud835\udc51]_ [+][1] _[\ud835\udc5b][\ud835\udf16]_ [) \u00b7][ 2][2] _[\ud835\udc51]_ [\u00b7] _[ \ud835\udc5b]_ [1][\u2212(] _[\ud835\udc51]_ [+][2][)] _[ \ud835\udf16]_ \ufffd\n\n= 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][3][ \ufffd] [|] _[\ud835\udc47]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_ [+][ 2][2] _[\ud835\udc51]_ [+] _[\ud835\udc51]_ [+][1] _[\ud835\udc5b]_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_\n\ufffd\n\n\u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][3] (2 [2] _[\ud835\udc51]_ [+] _[\ud835\udc51]_ [+][1] + 1) [|] _[\ud835\udc47]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n\u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][2] [\u2212][1]           - [|] _[\ud835\udc47]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\nIn the first inequality, we use the fact that [|] _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|]\n\nIn the first inequality, we use the fact that [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [\u2265] _[\ud835\udc5b]_ [1][\u2212(] _[\ud835\udc51]_ [+][1][)] _[ \ud835\udf16]_ [. In the second inequality, we use the fact that]\n\n2 [2] _[\ud835\udc51]_ [+] _[\ud835\udc51]_ [+][1] + 1 \u2264 2 [2] _[\ud835\udc51]_ [+][2] [\u2212][1] for all _\ud835\udc51_ \u2265 0. Finally, since 2 [2] _[\ud835\udc51]_ [+][2][+] _[\ud835\udc51]_ [+][1] + 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][2] [\u2212][1] \u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][2] for _\ud835\udc51_ \u2264 _\u2113_ \u2212 2, the\ntotal number of colors satisfies _\ud835\udc50_ 1 + _\ud835\udc50_ 2 \u2264 2 [2] _[\u2113]_ [+][2] [\u2212][2] _[\ud835\udc51]_ [+][2] - [|] _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [. Therefore, (b) holds.]\n\n_\ud835\udc5b_ ~~_[\ud835\udf16]_~~ [. Therefore, (b) holds.]\n\nFinally, we prove the main result of this subsection. The previous best-known competitive ratio is\n_\ud835\udc42_ ( _\ud835\udc5b_ log log log _\ud835\udc5b_ /log log _\ud835\udc5b_ ) by Kierstead [18], which yields a deterministic online algorithm that colors\n_\ud835\udc58_ -colorable graphs with _\ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc58]_ [!] colors. Theorem 3.14 improves this ratio by a factor of log log log _\ud835\udc5b_ .\n\n**Theorem 3.14.** _There exists a deterministic online coloring algorithm with competitive ratio \ud835\udc42_ ( log log _\ud835\udc5b_ _\ud835\udc5b_ [)] _[.]_\n\n_Proof._ First, we prove that, for all _\u2113_ \u2264 2 [1] [log log] _[ \ud835\udc5b]_ [, the following holds for sufficiently large] _[ \ud835\udc5b]_ [:]\n\n_\ud835\udc5b_\n2 [2] _[\u2113]_ [+][2]                - _\ud835\udc5b_ [1][\u2212][1][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] _<_\nlog log _\ud835\udc5b_\n\nTaking the logarithm of each side, we get the following:\n\n1\n2 _[\u2113]_ [+][2] + 1 \u2212\n\ufffd _\u2113_ ( _\u2113_ \u2212 1) + 2\n\nlog _\ud835\udc5b<_ log _\ud835\udc5b_ \u2212 log log log _\ud835\udc5b_\n\ufffd\n\nlog _\ud835\udc5b_\n(\u21d4) 2 _[\u2113]_ [+][2] + log log log _\ud835\udc5b<_ _\u2113_ ( _\u2113_ \u2212 1) + 2\n\n16\n\n[1] 2 [log log] _[ \ud835\udc5b]_ [, the left-hand side is] _[ \ud835\udc5c]_ [(][log] _[ \ud835\udc5b]_ [/(][log log] _[ \ud835\udc5b]_ [)][2][)][ due to 2] _[\u2113]_ [+][2][ =] _[ \ud835\udc42]_ [(] \u221a\ufe01\n\nHere, for _\u2113_ \u2264 [1]\n\n[)][ due to 2] [+] [ =] _[ \ud835\udc42]_ [(]\n\nHere, for _\u2113_ \u2264 2 [log log] _[ \ud835\udc5b]_ [, the left-hand side is] _[ \ud835\udc5c]_ [(][log] _[ \ud835\udc5b]_ [/(][log log] _[ \ud835\udc5b]_ [)] \u221a\ufe01log _\ud835\udc5b_ ). However, the\n\nright-hand side is \u03a9(log _\ud835\udc5b_ /(log log _\ud835\udc5b_ ) [2] ). Therefore, the inequality holds for sufficiently large _\ud835\udc5b_ . Combining\nthis with Lemma 3.13, the algorithm for _\u2113_ -colorable graphs where _\u2113_ \u2264 [1] [log log] _[ \ud835\udc5b]_ [only uses] _\ud835\udc5b_ [colors,]\n\nthis with Lemma 3.13, the algorithm for _\u2113_ -colorable graphs where _\u2113_ \u2264 2 [log log] _[ \ud835\udc5b]_ [only uses] log log _\ud835\udc5b_ _\ud835\udc5b_ [colors,]\n\nwhen _\ud835\udc5b_ is sufficiently large.\nNow, we describe an algorithm that works even when we do not know _\u2113_ . Consider the following algorithm:\n(1) run an algorithm for locally ( [1] [log log] _[ \ud835\udc5b]_ [)][-colorable graphs, and (2) if the algorithm aborts, give up and]\n\n(1) run an algorithm for locally ( 2 [log log] _[ \ud835\udc5b]_ [)][-colorable graphs, and (2) if the algorithm aborts, give up and]\n\nuse a different color for each vertex. The number of colors used is at most\n\nlog log _\ud835\udc5b_ _\ud835\udc5b_ ( _\ud835\udf12_ ( _\ud835\udc3a_ ) \u2264 [1] 2 [log log] _[ \ud835\udc5b]_ [)]\n\ufffd _\ud835\udc5b_ ( _\ud835\udf12_ ( _\ud835\udc3a_ ) _>_ [1] 2 [log log] _[ \ud835\udc5b]_ [)]\n\n2 [log log] _[ \ud835\udc5b]_ [)]\n\n[1]\n\n2 [log log] _[ \ud835\udc5b]_ [)]\n\n_\ud835\udc5b_ ( _\ud835\udf12_ ( _\ud835\udc3a_ ) _>_ [1]\n\n_\ud835\udc5b_\nwhen _\ud835\udc5b_ is sufficiently large. Therefore, this algorithm achieves a competitive ratio of _\ud835\udc42_ ( log log _\ud835\udc5b_ [)][. Note]\nthat this algorithm works in polynomial time. The non-trivial point is whether we can find _\ud835\udc37_ [\u2032] \u2286 _\ud835\udc37_ where\n_\ud835\udf12_ ( _\ud835\udc3a_ [ _\ud835\udc37_ [\u2032] ]) _> \ud835\udc51_ and | _\ud835\udc37_ [\u2032] | _<_ 2 [2] _[\ud835\udc51]_ in polynomial time, but it can be done by looking at the output of the level-0\nsubproblem (of the problem for locally _\ud835\udc51_ -colorable graphs that colors vertices in _\ud835\udc37_ ).\n\n### **4 Improvement for 4-colorable graphs**\n\n_\ud835\udc42_ In this section, we present a deterministic online algorithm to color a 4-colorable graph\ufffd( _\ud835\udc5b_ [14][/][17] ) colors, improving the previous bound of _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] ). First, we describe the idea of our algorithm. _\ud835\udc3a_ of _\ud835\udc5b_ vertices with\n\n**4.1** **The idea of the algorithm**\n\nThe first step follows the same approach as in subsection 3.2 and uses the FirstFit algorithm with _\ud835\udc5b_ [14][/][17]\n\ncolors. Then, we solve the else-problem under the following assumptions, which (2) is a new one.\n\n**Assumptions for the else-problem.** (1) When _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 arrives, | _\ud835\udc41\ud835\udc46_ now ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [14][/][17] is guaranteed. [12] (2)\nThere is no edge ( _\ud835\udc60, \ud835\udc61_ ) ( _\ud835\udc60_ \u2208 _\ud835\udc46_ 0 _, \ud835\udc61_ \u2208 _\ud835\udc47_ 0) in _\ud835\udc3a_ that _\ud835\udc60_ arrives _later_ than _\ud835\udc61_ .\n\nFor the assumption (2), this is not necessarily true for the \u201cactual\u201d graph, but we can ignore all such edges\n( _\ud835\udc60, \ud835\udc61_ ). It does not cause a problem because | _\ud835\udc41\ud835\udc46_ now ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [14][/][17] still holds and the deletion of edges between\n_\ud835\udc46_ 0 and _\ud835\udc47_ 0 does not change the validity of the coloring (we color the vertices in _\ud835\udc47_ 0 in the else-problem, with\ncompletely different colors from those in _\ud835\udc46_ 0). Then, _\ud835\udc41\ud835\udc46_ now ( _\ud835\udc63_ ) = _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ ) holds at any moment for any already\narrived vertex _\ud835\udc63_ . In this section, we often access _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ ) in the algorithms. This may seem to use \u201cfuture\u201d\ninformation, but it is not the case because of this assumption; we can just access _\ud835\udc41\ud835\udc46_ now ( _\ud835\udc63_ ).\nOur task is to color the vertices in _\ud835\udc47_ 0 online using _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors. However, it remains challenging.\nNow, we first consider the special case when there is no dense subgraph in _\ud835\udc3a_ .\n\n**No-dense property.** There are no subsets _\ud835\udc46\ud835\udc37_ \u2286 _\ud835\udc46_ 0 and _\ud835\udc47\ud835\udc37_ \u2286 _\ud835\udc47_ 0 that satisfy the following conditions: (i)\n| _\ud835\udc47\ud835\udc37_ | \u2264 _\ud835\udc5b_ [8][/][17], (ii) | _\ud835\udc46\ud835\udc37_ | \u2264 _\ud835\udc5b_ [8][/][17] | _\ud835\udc47\ud835\udc37_ |, and (iii) | _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc63_ )| \u2265 [1] 3 _[\ud835\udc5b]_ [14][/][17][ for all] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc47][\ud835\udc37]_ [.]\n\nThe steps to solve the special case are shown in Figure 9. The first step is to obtain a 1-color set _\ud835\udc47\ud835\udc37_ \u2286 _\ud835\udc47_ 0\nin some 4-coloring of _\ud835\udc3a_, where | _\ud835\udc47\ud835\udc37_ | = \u03a9( _\ud835\udc5b_ [7][/][17] ) (Figure 9A). To obtain a large 1-color set, we use FirstFit\nin _\ud835\udc47_ 0 (see the details in subsection 4.2). Since we run FirstFit in both _\ud835\udc46_ 0 and _\ud835\udc47_ 0, we call this technique the\n_double greedy method_ . Then, assuming the no-dense property, we obtain a large 3-color set in _\ud835\udc46_ 0 (Figure 9B),\nbecause indeed, _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc47\ud835\udc37_ ) is a 3-color set of \u03a9( _\ud835\udc5b_ [15][/][17] ) vertices. Moreover, repeating this process allows us\n\n12As in subsection 3.2, _\ud835\udc46_ 0 and _\ud835\udc47_ 0 is the \u201cfinal\u201d set of vertices that are colored and uncolored by FirstFit, respectively, and _\ud835\udc46_ now\nis a \u201ccurrent\u201d set of vertices that are colored by FirstFit.\n\n17\n\nto cover _\ud835\udc46_ 0 with _\ud835\udc42_ ( _\ud835\udc5b_ [2][/][17] ) 3-color sets (Figure 9C). Afterward, we color the remaining vertices using the\nsubproblem where the subset _\ud835\udc46_ \u2286 _\ud835\udc46_ 0 is a 3-color set, as we did in subsection 3.6 (Figure 9D).\nCompared to Kierstead\u2019s algorithm for _\ud835\udc58_ = 4, which generates _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][/][6] ) 3-color sets, our algorithm\ngenerates fewer 3-color sets. This leads to the improvement from _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][6] ) colors to _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-19-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-19-3.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-19-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-19-1.png)\n\nFigure 9: The sketch of our algorithm for the no-dense case.\n\nHowever, in some cases, the no-dense property does not hold. Indeed, the worst case is | _\ud835\udc46\ud835\udc37_ | = _\ud835\udc5b_ [14][/][17] even\nthough | _\ud835\udc47\ud835\udc37_ | = _\ud835\udc5b_ [8][/][17] . To this end, we use our novel _Common & Simplify technique_ to reduce the else-problem\nto one with the no-dense property. The core idea of the technique is to pick two highly common vertices\n_\ud835\udc62_ 1 _, \ud835\udc62_ 2 \u2208 _\ud835\udc47_ 0 that satisfy | _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2)| = \u03a9 [\ufffd] ( _\ud835\udc5b_ [12][/][17] ) (we can show that such a pair exists if the no-dense\nproperty does not hold; see Lemma 4.9). If there exists a 4-coloring of _\ud835\udc3a_ in which different colors are used\nfor _\ud835\udc62_ 1 and _\ud835\udc62_ 2, _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2) is a 2-color set of \u03a9 [\ufffd] ( _\ud835\udc5b_ [12][/][17] ) vertices (Figure 10), which is large enough\nto reduce to the 2-color version of subproblem+. Note that sometimes _\ud835\udc62_ 1 and _\ud835\udc62_ 2 may be assigned the same\ncolor, but we can force ( _\ud835\udc62_ 1 _, \ud835\udc62_ 2) to be different colors with at least 4 [1] [ratio (see][ subsection 4.6][).]\n\nIn subsection 4.2, we first show the preliminaries that are required for the proof. In subsection 4.3 and\nsubsection 4.4, we present an algorithm for the no-dense property case. In subsection 4.5 and subsection 4.6,\nwe introduce the Common & Simplify technique and finally present a deterministic online algorithm that\ncolors any 4-colorable graph with _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-19-4.png)\n\nFigure 10: The core idea in Common & Simplify technique. If _\ud835\udc62_ 1 and _\ud835\udc62_ 2 are colored by color\n1 and 2 in some 4-coloring of _\ud835\udc3a_, then _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2) is forced to be a 2-color set.\n\n**4.2** **Preliminaries**\n\nFirst, we define three subproblems that our algorithm requires.\n\n**3-color set problem.** We consider a modification of the level-1 subproblem+, where _\ud835\udc46_ is initially set and is\nfixed throughout the procedure. It is guaranteed that | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| = \u03a9 [\ufffd] (| _\ud835\udc46_ |/ _\ud835\udc5b_ [3][/][17] ) for each _\ud835\udc63_ \u2208 _\ud835\udc47_ . We can assume\nthat _\ud835\udc46_ is a 3-color set in some 4-coloring of _\ud835\udc3a_ . If this assumption is violated, we can abort the procedure. Our\ntask is to color the vertices in _\ud835\udc47_ online, using _\ud835\udc42_ [\ufffd] (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [15][/][17] )/ _\ud835\udc5b_ [3][/][17] ) colors. The algorithm for solving\nthe 3-color set problem is denoted as 3-Color( _\ud835\udc46_ ).\n\n18\n\n**2-color set problem.** We consider a modification of the level-2 subproblem+, where _\ud835\udc46_ is initially set and is\nfixed throughout the procedure. It is guaranteed that | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| = \u03a9 [\ufffd] (| _\ud835\udc46_ |/ _\ud835\udc5b_ [3][/][17] ) for each _\ud835\udc63_ \u2208 _\ud835\udc47_ . We can assume\nthat _\ud835\udc46_ is a 2-color set in some 4-coloring of _\ud835\udc3a_ . If this assumption is violated, we can abort the procedure. Our\ntask is to color the vertices in _\ud835\udc47_ online, using _\ud835\udc42_ [\ufffd] (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [12][/][17] )/ _\ud835\udc5b_ [3][/][17] ) colors. The algorithm for solving\nthe 2-color set problem is denoted as 2-Color( _\ud835\udc46_ ).\n\n**1-color candidates problem.** We consider a modification of the level-0 subproblem+. Similar to the\noriginal subproblem+ (and unlike 3-color/2-color set problems), vertices are added to _\ud835\udc46_ and _\ud835\udc47_ in the order of\narrival. It is guaranteed that | _\ud835\udc46_ | \u2264 _\ud835\udc5b_ [16][/][17] and | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 2 [1] _[\ud835\udc5b]_ [13][/][17][ (] _[\ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [)][ at any moment. Our task is to color]\n\nthe vertices in _\ud835\udc47_ online, using _\ud835\udc42_ (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [16][/][17] )/ _\ud835\udc5b_ [5][/][17] ) colors, until we abort the procedure by outputting\nthe following set:\n\nA set A = { _\ud835\udc34_ 1 _, \ud835\udc34_ 2 _, . . ., \ud835\udc34\ud835\udc5a_ } ( _\ud835\udc34\ud835\udc56_ \u2286 _\ud835\udc46_ ) that satisfies the following conditions: | _\ud835\udc34\ud835\udc56_ | \u2265 64 [1] _[\ud835\udc5b]_ [7][/][17][ for]\n\nall _\ud835\udc56_, _\ud835\udc5a_ \u2264 10, and there exists some _\ud835\udc56_ such that _\ud835\udc34\ud835\udc56_ is a 1-color set in some 4-coloring of _\ud835\udc3a_ . (It\nmeans that no matter how \u201cfuture\u201d vertices arrive, at least one _\ud835\udc34\ud835\udc56_ must be a 1-color set as long\nas the graph is 4-colorable.)\n\nThe algorithm to solve the 1-color candidates problem is denoted as 1-Color-Cand( _\ud835\udc46_ ). Note that sketches\nof the three defined problems are shown in Figure 11.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-20-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-20-1.png)\n\n\ud835\udc460 3-color \ud835\udc46 (fixed) \ud835\udc460 2-col \ud835\udc46 (fixed)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-20-2.png)\n\n3-color set problem 2-color set problem 1-color candidates problem\n\nFigure 11: The sketches of the three problems.\n\n**Lemma 4.1.** _A deterministic online algorithm that solves both the 3-color set problem and the 2-color set_\n_problem exists._\n\n_Proof._ We first consider the \u201cgeneral | _\ud835\udc46_ |\u201d version of the level- _\ud835\udc51_ subproblem+ for _\ud835\udc58_ -colorable graphs, which\nmakes the following modifications (consider _\ud835\udf16_ = _\ud835\udc58_ ( _\ud835\udc58_ 2\u22121) [as in subproblem+):]\n\n_\ud835\udc46_ is initially a set and is fixed throughout the procedure, but there are no constraints on | _\ud835\udc46_ |\n(ultimately, only | _\ud835\udc46_ | \u2265 1 is required). It is guaranteed that | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265| _\ud835\udc46_ |/(2 _[\ud835\udc51]_ _\ud835\udc5b_ _[\ud835\udf16]_ ) for each _\ud835\udc63_ \u2208 _\ud835\udc47_ .\n\nIn this modified problem, the same algorithm as subproblem+, except that we set _\ud835\udefe\ud835\udc56_ = | _\ud835\udc46_ |/(2 _[\ud835\udc56]_ [(] _[\ud835\udc56]_ [\u2212][1][)/][2] _\ud835\udc5b_ _[\ud835\udc56\ud835\udf16]_ ),\nworks (note that _\ud835\udefe\ud835\udc51_\n_\ud835\udefe\ud835\udc51_ +1 [=][ 2] _[\ud835\udc51][\ud835\udc5b][\ud835\udf16]_ [, which is not modified). This is because, in the proof for subproblem+ (cf.,]\nLemma 3.7), we only used the fact that | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265| _\ud835\udc46_ |/(2 _[\ud835\udc51]_ _\ud835\udc5b_ _[\ud835\udf16]_ ), not the size of | _\ud835\udc46_ | itself. Therefore, we can\nstill solve this problem with _\ud835\udc42_ [\ufffd] (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ )/ _\ud835\udc5b_ _[\ud835\udf16]_ ) colors. The same result also holds when the constraints\nare changed to | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 \u03a9 [\ufffd] (| _\ud835\udc46_ |/ _\ud835\udc5b_ _[\ud835\udf16]_ ), by the proof of subproblem+.\n\n\u201d\nThe 3-color/2-color set problems are the ( _\ud835\udc58, \ud835\udc51_ ) = (4 _,_ 1) _,_ (4 _,_ 2) cases of the modified problem, where \u201c _\ud835\udc5b_\nis replaced by _\ud835\udc5b_ [18][/][17] (this corresponds to the case if _\ud835\udc3a_ were a _\ud835\udc5b_ [18][/][17] -vertex graph). Therefore, there exists a\ndeterministic online algorithm that solves the 3-color/2-color set problems.\n\n**Lemma 4.2.** _There exists a deterministic online algorithm that solves the 1-color candidates problem._\n\n19\n\n_Proof._ We consider the following level- _\ud835\udc51_ subproblem for the 1-color candidate problem. The _\ud835\udc51_ = 0 case\ncorresponds to the 1-color candidate problem.\n\nIt is guaranteed that | _\ud835\udc46_ | \u2264 _\ud835\udefe\ud835\udc51_ and | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 _\ud835\udefe\ud835\udc51_ +1 ( _\ud835\udc63_ \u2208 _\ud835\udc47_ ), where _\ud835\udefe\ud835\udc56_ = _\ud835\udc5b_ [(][16][\u2212][3] _[\ud835\udc56]_ [)/][17] /2 _[\ud835\udc56]_ [(] _[\ud835\udc56]_ [+][1][)/][2] . The\noutput A when aborting must satisfy the following condition: assuming that _\ud835\udc46_ is a (4 \u2212 _\ud835\udc51_ )-color\nset in some 4-coloring of _\ud835\udc3a_, there exists some _\ud835\udc56_ that _\ud835\udc34\ud835\udc56_ is a 1-color set in some 4-coloring of _\ud835\udc3a_ .\nNote that any A meets the condition if we know that _\ud835\udc46_ is not a (4 \u2212 _\ud835\udc51_ )-color set. We only use\n_\ud835\udc42_ (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [(][16][\u2212][3] _[\ud835\udc51]_ [)/][17] )/ _\ud835\udc5b_ [5][/][17] ) colors (at any moment until aborting).\n\n**The** _\ud835\udc51_ = 2 **case.** For the base case _\ud835\udc51_ = 2, we color vertices in _\ud835\udc47_ using an algorithm for graphs that contain\nno odd cycles _\ud835\udc36_ 3 or _\ud835\udc36_ 5 (Theorem 3.2), with _\ud835\udc42_ (| _\ud835\udc47_ | [1][/][2] ) colors. When a small odd cycle ( _\ud835\udc50_ 1 _, \ud835\udc50_ 2 _, . . ., \ud835\udc50\ud835\udc5a_ ) ( _\ud835\udc5a_ \u2208\n{3 _,_ 5}) appears in _\ud835\udc3a_ [ _\ud835\udc47_ ], we abort the procedure by outputting the following (also see Figure 12 left):\n\nA = { _\ud835\udc41\ud835\udc46_ ( _\ud835\udc50_ 1) _, \ud835\udc41\ud835\udc46_ ( _\ud835\udc50_ 2) _, . . ., \ud835\udc41\ud835\udc46_ ( _\ud835\udc50\ud835\udc5a_ )}\n\nNote that | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc50\ud835\udc56_ )| \u2265 _\ud835\udefe_ 3 = 64 [1] _[\ud835\udc5b]_ [7][/][17][ for each] _[\ud835\udc56]_ [. From the proof of][ Lemma 3.10][ and by] _[ \ud835\udf12]_ [(] _[\ud835\udc3a]_ [[{] _[\ud835\udc50]_ [1] _[, \ud835\udc50]_ [2] _[, . . ., \ud835\udc50][\ud835\udc5a]_ [}]) \u2265]\n\n3, assuming that _\ud835\udc46_ is a 2-color set, at least one of _\ud835\udc41\ud835\udc46_ ( _\ud835\udc50\ud835\udc56_ ) is a 1-color set, and hence A is valid. The number\nof colors used meets the requirement by the following inequality:\n\n| _\ud835\udc47_ | [1][/][2] \u2264 [max][(|] _[\ud835\udc47]_ [|] _[, \ud835\udc5b]_ [10][/][17][)]\n\n_\ud835\udc5b_ [5][/][17]\n\n**The** _\ud835\udc51_ \u2264 1 **case.** Next, the _\ud835\udc51_ \u2208{0 _,_ 1} case can be solved using the same way as in subproblem+, except\nthat we need to output A when aborting. When all the subroutines initiated at the same time abort (line 17\nof Algorithm 2), and the output of the subroutine _\ud835\udc43\ud835\udc56, \ud835\udc57_ is A _\ud835\udc57_ (corresponds to line 19 of Algorithm 2), we can\nabort the procedure by outputting the following (also see Figure 12 middle/right):\n\nA = A1 \u222aA2 \u222a\u00b7 \u00b7 \u00b7 \u222aA | P _\ud835\udc56_ |\n\nThe correctness of this algorithm follows from the proof of Lemma 3.10: assuming that _\ud835\udc46_ is a (4 \u2212 _\ud835\udc51_ )-color\nset, _\ud835\udc46_ ( _\ud835\udc43\ud835\udc56, \ud835\udc57_ ) is a (3 \u2212 _\ud835\udc51_ )-color set for at least one _\ud835\udc57_, and for such _\ud835\udc57_, there is at least one 1-color set in A _\ud835\udc57_ . We\ncan also prove that the number of colors used meets the requirement in the same manner as in the proof of\nLemma 3.8. Finally, we estimate the order of the returned set A. For _\ud835\udc51_ = 2, |A| \u2264 5 holds. For _\ud835\udc51_ = 1 and\n_\ud835\udc51_ = 0, the found \u201csmall subgraph\u201d when running Locally( _\ud835\udc51_ ) always is of order 2 (an edge) and order 1 (a\nvertex), respectively. Hence, |A| \u2264 5 \u00b7 2 \u00b7 1 = 10. Therefore, we have solved the 1-color candidates problem\ndeterministically.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-21-2.png)\n\n\ud835\udc46 (2-color set) \ud835\udc46 (3-color set) \ud835\udc46 (4-color set)\n\nReturned sets:\n\nat least one\n\nis 1-color set\n\n|\ud835\udc46 (3 -color set)|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||\n\n|\ud835\udc46 (4 -color set)|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||\n\nFigure 12: An example of returned sets when _\ud835\udc51_ = 2 _,_ 1 _,_ 0 in the order. The gray vertices are\nthe vertices colored by level-( _\ud835\udc51_ + 1) or higher subproblems.\n\n20\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-21-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-21-1.png)\n**Important Remarks.** In the algorithm described in subsection 4.3, we use 1-Color-Cand( _\ud835\udc46_ ) as a subroutine. Here, deletion of vertices in _\ud835\udc46_ may occur. Since the deletion is an invalid operation for the 1-color\ncandidates problem, we need to \u201creset\u201d the subroutine and start using new colors. Formally, if _\ud835\udc46_ changes from\n_\ud835\udc46_ 1 to _\ud835\udc46_ 2 (\u2286 _\ud835\udc46_ 1) by deletion, we finish the current subroutine of 1-Color-Cand, and start a new subroutine of\n1-Color-Cand by setting _\ud835\udc46_ = _\ud835\udc46_ 2 _,\ud835\udc47_ = \u2205. In the new subroutine, we use completely new colors for coloring\nvertices coming to _\ud835\udc47_ (such a case may occur in 4. of **Implementation** in the next subsection).\n\n**4.3** **The first step: No-dense case**\n\nIn this section, we introduce an algorithm to solve the else-problem when the no-dense property holds. Our\nalgorithm is described in Algorithm 3 (No-Dense-Case).\n\n**Algorithm 3** No-Dense-Case\n\n1: _\ud835\udc47_ FF \u2190\u2205\n\n2: R \u2190[]\n\n3: _\ud835\udc50_ \u2190 0\n\n4: **for** each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 **do**\n\n5: **if** for some _\ud835\udc56, \ud835\udc57_, | _\ud835\udc41\ud835\udc45\ud835\udc56, \ud835\udc57_ ( _\ud835\udc63_ )| \u2265 64001 _[\ud835\udc5b]_ [12][/][17][ and 3-Color][(] _[\ud835\udc45][\ud835\udc56, \ud835\udc57]_ [)][ is not aborted yet] **[ then]**\n\n6: color _\ud835\udc63_ with 3-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ )\n\n7: **else if** | _\ud835\udc41\ud835\udc47_ FF ( _\ud835\udc63_ )| _< \ud835\udc5b_ [13][/][17] **then**\n\n8: color _\ud835\udc63_ with FirstFit (among _\ud835\udc47_ FF)\n\n9: _\ud835\udc47_ FF \u2190 _\ud835\udc47_ FF \u222a{ _\ud835\udc63_ }\n\n10: **else**\n\n11: _\ud835\udc47_ NG \u2190{ _\ud835\udc63_ \u2208 _\ud835\udc47_ FF : | _\ud835\udc41_ [\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [(] _[\ud835\udc63]_ [)| \u2265] 2 [1] _[\ud835\udc5b]_ [14][/][17][}]\n\n12: color _\ud835\udc63_ with 1-Color-Cand( _\ud835\udc47_ FF \\ _\ud835\udc47_ NG)\n\n13: **if** 1-Color-Cand( _\ud835\udc47_ FF \\ _\ud835\udc47_ NG) returns a set A **then**\n\n14: add { _\ud835\udc41\ud835\udc46_ [\u2032] 0\\(\u222a _\ud835\udc56, \ud835\udc57_ _\ud835\udc45\ud835\udc56, \ud835\udc57_ ) [(] _[\ud835\udc34]_ [)][ :] _[ \ud835\udc34]_ [\u2208A}][ to][ R] _\u22b2\ud835\udc41\ud835\udc4b_ [\u2032] [(] _[\ud835\udc34]_ [)][: the first] 64 [1] _[\ud835\udc5b]_ [15][/][17][ elements of] _[ \ud835\udc41][\ud835\udc4b]_ [(] _[\ud835\udc34]_ [)]\n\n15: _\ud835\udc50_ \u2190 _\ud835\udc50_ + 1\n\n16: **if** _\ud835\udc50> \ud835\udc5b_ [1][/][17] or | _\ud835\udc47_ FF| _> \ud835\udc5b_ [16][/][17] **then**\n\n17: _\ud835\udc47_ FF \u2190\u2205 and reset FirstFit\n\n18: _\ud835\udc50_ \u2190 0\n\n**Overview of No-Dense-Case.** Below, we explain how No-Dense-Case works. Normally, to color vertices\nin _\ud835\udc47_ 0 online, we use FirstFit (among _\ud835\udc47_ 0) with _\ud835\udc5b_ [13][/][17] colors. However, some vertices in _\ud835\udc47_ 0 cannot be colored\nby FirstFit. We instead color such a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 with 1-Color-Cand( _\ud835\udc47_ FF), where _\ud835\udc47_ FF \u2286 _\ud835\udc47_ 0 is the\ncurrent set of vertices colored by FirstFit (Figure 13 left). When 1-Color-Cand eventually returns a set\nof \u201ccandidate 1-color sets\u201d A, we initiate a new subroutine 3-Color( _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc34_ )) for each _\ud835\udc34_ \u2208A. This is\nbecause, if _\ud835\udc34_ is a 1-color set, _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc34_ ) is always a 3-color set in some 4-coloring of _\ud835\udc3a_, and we can also assume\n| _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc34_ )| \u2265 64 [1] _[\ud835\udc5b]_ [15][/][17][ due to the no-dense property (][Figure 13][ middle).]\n\nAfterwards, we may color a newly arrived vertex by 3-Color( _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc34_ )) if there is a sufficient number of\nedges to _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc34_ ), i.e., 64001 _[\ud835\udc5b]_ [12][/][17][ edges or more (][Figure 13][ right). Thus, the initiation of the new subroutines]\nis for the sake of coloring the \u201cfuture\u201d vertices efficiently. Note that if a new vertex cannot be colored by\neither FirstFit or 3-Color, we color it with 1-Color-Cand( _\ud835\udc47_ FF) again.\n\n**Implementation.** To implement this idea, when a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 arrives, we have again recorded the list of\ncurrently initiated 3-Color subroutines by a two-dimensional array R = [R1 _,_ R2 _, . . ._ ] = [[ _\ud835\udc45_ 1 _,_ 1 _, . . ., \ud835\udc45_ 1 _,_ |R1 |],\n\n[ _\ud835\udc45_ 2 _,_ 1 _, . . ., \ud835\udc45_ 2 _,_ |R2 |] _, . . ._ ], where each _\ud835\udc45\ud835\udc56, \ud835\udc57_ denotes that a subroutine 3-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ ) was initiated. R _\ud835\udc56_ denotes\n\n21\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-23-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-23-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-23-1.png)\n\nFigure 13: The sketch of the algorithm in No-Dense-Case.\n\nthe set of subroutines initiated at the same time. We also defined a counter _\ud835\udc50_ which is initially zero. Then,\nfor each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0, we run the following procedure:\n\n1. If there exists some _\ud835\udc56, \ud835\udc57_ where | _\ud835\udc41\ud835\udc45\ud835\udc56, \ud835\udc57_ ( _\ud835\udc63_ )| \u2265 64001 _[\ud835\udc5b]_ [12][/][17][ and 3-Color][(] _[\ud835\udc45][\ud835\udc56, \ud835\udc57]_ [)][ is not aborted, we color] _[ \ud835\udc63]_\nwith 3-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ ), as this meets the degree condition for the 3-color set problem (lines 5\u20136).\n\n2. Otherwise, if _\ud835\udc63_ can be colored by FirstFit, we use FirstFit and add _\ud835\udc63_ to _\ud835\udc47_ FF (lines 7\u20139).\n\n3. Otherwise, color _\ud835\udc63_ with 1-Color-Cand( _\ud835\udc47_ FF \\ _\ud835\udc47_ NG) where\n\n1\n_\ud835\udc47_ NG = \ufffd _\ud835\udc63_ \u2208 _\ud835\udc47_ FF : \ufffd\ufffd\ufffd _\ud835\udc41_ \ufffd _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [(] _[\ud835\udc63]_ [)] \ufffd\ufffd\ufffd \u2265 2 _[\ud835\udc5b]_ [14][/][17] \ufffd\n\nThe reason we do not simply apply 1-Color-Cand( _\ud835\udc47_ FF) is to avoid the situation of \u201cfinding a 3-color\nset that is already known\u201d, e.g., _\ud835\udc45_ 1 _,_ 1 = _\ud835\udc45_ 2 _,_ 1 occurs (lines 11\u201312).\n\n4. When 1-Color-Cand( _\ud835\udc47_ FF \\ _\ud835\udc47_ NG) aborts, we receive a set of \u201ccandidate 1-color sets\u201d A. We use\nthis obtained information to benefit the \u201cfuture\u201d vertices. Specifically, for each _\ud835\udc34_ \u2208A, we initiate a\nsubroutine 3-Color( _\ud835\udc41\ud835\udc46_ [\u2032] 0\\( [\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [)][ (] _[\ud835\udc34]_ [))][ where] _[ \ud835\udc41]_ _\ud835\udc4b_ [\u2032] [(] _[\ud835\udc34]_ [)][ is the first] 64 [1] _[\ud835\udc5b]_ [15][/][17][ elements of] _[ \ud835\udc41][\ud835\udc4b]_ [(] _[\ud835\udc34]_ [)][.]\n\nThen, we increase _\ud835\udc50_ by one, and add some elements to R, for the sake of coloring \u201cfuture\u201d vertices\nefficiently (lines 13\u201315). Note that\n\n1\n\ufffd\ufffd\ufffd _\ud835\udc41\ud835\udc46_ 0\\(\ufffd _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [)][ (] _[\ud835\udc34]_ [)] \ufffd\ufffd\ufffd \u2265 64 _[\ud835\udc5b]_ [15][/][17]\n\nalways holds at line 14 due to the no-dense property and by | _\ud835\udc34_ | \u2265 [1]\n\nalways holds at line 14 due to the no-dense property and by | _\ud835\udc34_ | \u2265 64 [1] _[\ud835\udc5b]_ [7][/][17][. We can apply the no-dense]\n\nproperty because | _\ud835\udc41\ud835\udc46_ 0\\(\u222a _\ud835\udc56, \ud835\udc57_ _\ud835\udc45\ud835\udc56, \ud835\udc57_ ) ( _\ud835\udc63_ )| \u2265 2 [1] _[\ud835\udc5b]_ [14][/][17][ holds for each] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [FF][ \\] _[ \ud835\udc47]_ [NG][ (due to line 11).]\n\n2 [1] _[\ud835\udc5b]_ [14][/][17][ holds for each] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [FF][ \\] _[ \ud835\udc47]_ [NG][ (due to line 11).]\n\n5. When we reach _\ud835\udc50> \ud835\udc5b_ [1][/][17] or | _\ud835\udc47_ FF| _> \ud835\udc5b_ [16][/][17], we finally reset FirstFit and counter _\ud835\udc50_ (lines 16\u201318). This\nis because if we continue, it violates the input condition | _\ud835\udc46_ | \u2264 _\ud835\udc5b_ [16][/][17] in 1-Color-Cand, or | _\ud835\udc47_ NG| may\nbecome too large (Lemma 4.4). After the reset, we must use different colors in FirstFit at line 8.\n\n**4.4** **Correctness & Analysis**\n\nNext, we discuss the correctness and the number of colors used in No-Dense-Case. The goal is to show\nLemma 4.7 (correctness of our algorithm). We first show some requied lemmas.\n\n**Lemma 4.3.** |R| \u2264 64 _\ud835\udc5b_ [2][/][17] _holds._\n\n22\n\n_Proof._ For each _\ud835\udc56_, there is at least one _\ud835\udc61_ that 3-Color( _\ud835\udc45\ud835\udc56,\ud835\udc61_ ) is not aborted. This is because at least one of _\ud835\udc45\ud835\udc56,\ud835\udc61_\nis a 3-color set in some 4-coloring of _\ud835\udc3a_ . For such _\ud835\udc61_, let _\ud835\udc45\ud835\udc56_ [\u2032] [=] _[ \ud835\udc45][\ud835\udc56,\ud835\udc61]_ [. Then, by line 14,][ |] _[\ud835\udc45]_ _\ud835\udc56_ [\u2032] [\u2229] _[\ud835\udc45]_ [\u2032] _\ud835\udc57_ [|][ =][ 0][ (] _[\ud835\udc56]_ [\u2260] _[\ud835\udc57]_ [)][.]\nSince | _\ud835\udc45\ud835\udc56_ [\u2032][|][ =] 64 [1] _[\ud835\udc5b]_ [15][/][17][ for each] _[ \ud835\udc56]_ [,][ Lemma 4.3][ holds.]\n\n**Lemma 4.4.** _If \ud835\udc50_ \u2264 _\ud835\udc5b_ [1][/][17] _, then_ | _\ud835\udc47_ NG| _< \ud835\udc5b_ [8][/][17] _under the no-dense property._\n\n_Proof._ Let R [\u2032] be the elements that were added to R before the last reset of FirstFit. Since (i) |R [\u2032] | = 64 _\ud835\udc5b_ [2][/][17]\n\n(Lemma 4.3), (ii) |R _\ud835\udc56_ [\u2032][| \u2264] [10 (][Lemma 4.1][), and (iii)][ |] _[\ud835\udc41][\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [\u2032] [(] _[\ud835\udc63]_ [)|] _[ <]_ 64001 _[\ud835\udc5b]_ [12][/][17][ for each] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [FF][ (by line 5),]\n\n\ufffd\ufffd\ufffd _\ud835\udc41_ \ufffd _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [\u2032] [(] _[\ud835\udc63]_ [)] \ufffd\ufffd\ufffd \u2264 64001 _[\ud835\udc5b]_ [12][/][17][ \u00b7][ 64] _[\ud835\udc5b]_ [2][/][17][ \u00b7][ 10][ =] 10 [1] _[\ud835\udc5b]_ [14][/][17]\n\nholds for each _\ud835\udc63_ \u2208 _\ud835\udc47_ FF. Therefore, by line 11,\n\n1\n\n2 _[\ud835\udc5b]_ [14][/][17][ \u2212] [1]\n\n5 _[\ud835\udc5b]_ [14][/][17]\n\n1\n\ufffd\ufffd\ufffd _\ud835\udc41_ (\ufffd _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [)\\(][\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [\u2032] [)][ (] _[\ud835\udc63]_ [)] \ufffd\ufffd\ufffd \u2265 2\n\n[1]\n\n10 _[\ud835\udc5b]_ [14][/][17][ =][ 2] 5\n\nholds for each _\ud835\udc63_ \u2208 _\ud835\udc47_ NG. Now, consider applying the no-dense property where _\ud835\udc47\ud835\udc37_ = _\ud835\udc47_ NG and _\ud835\udc46\ud835\udc37_ =\n( [\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [) \\ (][\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [\u2032] [)][.][13][ By] _[ \ud835\udc50]_ [\u2264] _[\ud835\udc5b]_ [1][/][17][,][ |R] _[\ud835\udc56]_ [| \u2264] [10, and][ |] _[\ud835\udc45][\ud835\udc56, \ud835\udc57]_ [|][ =] 64 [1] _[\ud835\udc5b]_ [15][/][17][,]\n\n_\ud835\udc45_\n_\ud835\udc56, \ud835\udc57_\n\n\ufffd\ufffd _\ud835\udc56, \ud835\udc57_\n\n\u2264 _\ud835\udc5b_ 1/17 \u00b7 10 \u00b7 1\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n\ufffd\n\n| _\ud835\udc46\ud835\udc37_ | =\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n\\\n\n_\ud835\udc45_ [\u2032]\n_\ud835\udc56, \ud835\udc57_\n\n\ufffd\ufffd _\ud835\udc56, \ud835\udc57_\n\n1 [5]\n\n64 _[\ud835\udc5b]_ [15][/][17][ =] 32\n\n32 _[\ud835\udc5b]_ [16][/][17]\n\nholds, and if | _\ud835\udc47_ NG| \u2265 _\ud835\udc5b_ [8][/][17], it contradicts the no-dense property. Therefore, | _\ud835\udc47_ NG| _< \ud835\udc5b_ [8][/][17] .\n\n**Lemma 4.5.** _For each call of 1-Color-Cand_ ( _\ud835\udc47_ FF \\ _\ud835\udc47_ NG) _,_ | _\ud835\udc41\ud835\udc47_ FF\\ _\ud835\udc47_ NG ( _\ud835\udc63_ )| \u2265 2 [1] _[\ud835\udc5b]_ [13][/][17] _[ holds, which satisfies the]_\n\n_degree constraints of the 1-color candidate problem._\n\n_Proof._ By | _\ud835\udc41\ud835\udc47_ FF ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [13][/][17] (line 7) and | _\ud835\udc47_ NG| _< \ud835\udc5b_ [8][/][17] (Lemma 4.4), Lemma 4.5 follows.\n\n**Lemma 4.6.** _No-Dense-Case uses_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) _colors under no-dense property._\n\n_Proof._ Let _\ud835\udc50_ 1 _, \ud835\udc50_ 2 _, \ud835\udc50_ 3 be the number of colors used in 3-Color (line 6), FirstFit (line 8), and 1-Color-Cand\n(line 12), respectively. Then, the total number of colors used is _\ud835\udc50_ 1 + _\ud835\udc50_ 2 + _\ud835\udc50_ 3, and each value is as follows:\n\n   - _\ud835\udc50_ 1: By Lemma 4.1, Lemma 4.3 (|R| = _\ud835\udc42_ ( _\ud835\udc5b_ [2][/][17] ) and therefore 3-Color is initiated for _\ud835\udc42_ ( _\ud835\udc5b_ [2][/][17] ) times),\nand the fact that the sum of | _\ud835\udc47_ | for each 3-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ ) is at most _\ud835\udc5b_, _\ud835\udc50_ 1 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ).\n\n   - _\ud835\udc50_ 2: By Lemma 4.3 and line 16, the reset on FirstFit only occurs _\ud835\udc42_ ( _\ud835\udc5b_ [1][/][17] ) times. Since each run of\nFirstFit uses _\ud835\udc5b_ [13][/][17] colors, _\ud835\udc50_ 2 = _\ud835\udc42_ ( _\ud835\udc5b_ [14][/][17] ).\n\n  - By Lemma 4.2, we only use _\ud835\udc42_ ( _\ud835\udc5b_ [12][/][17] ) colors for each procedure of 1-Color-Cand. In addition,\nvertices are deleted from the set _\ud835\udc46_ of 1-Color-Cand (i.e., _\ud835\udc47_ FF \\ _\ud835\udc47_ NG) only when R changes, which\noccurs |R| = _\ud835\udc42_ ( _\ud835\udc5b_ [2][/][17] ) times. Therefore, _\ud835\udc50_ 3 = _\ud835\udc42_ ( _\ud835\udc5b_ [14][/][17] ).\n\nBy _\ud835\udc50_ 1 + _\ud835\udc50_ 2 + _\ud835\udc50_ 3 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ), the algorithm No-Dense-Case uses _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors.\n\n**Lemma 4.7.** _No-Dense-Case solves the else-problem with_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) _colors under no-dense property._\n\n_Proof._ To prove the correctness, we must show the following two: (1) the assumption of 1-Color-Cand\n(e.g. | _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ )| \u2265 [1] 2 _[\ud835\udc5b]_ [13][/][17][ for each] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [) is satisfied, and (2) the number of colors used is as required. (1)]\n\nfollows from Lemma 4.5, while (2) follows from Lemma 4.6. Therefore, Lemma 4.7 holds.\n\n13Note that since 2\n\n2\n\n5 _[\ud835\udc5b]_ [14][/][17][ \u2265] 3 [1]\n\n3 [1] _[\ud835\udc5b]_ [14][/][17][, we can apply the no-dense property.]\n\n23\n\n**4.5** **The second step: Avoiding dense case**\n\nThe last step is to reduce the else-problem to \u201cthe else-problem with the no-dense property\u201d. First, consider\nusing FirstFit with 2 _\ud835\udc5b_ [14][/][17] colors (instead of the previous _\ud835\udc5b_ [14][/][17] ). For each vertex that cannot be colored by\nFirstFit (i.e., vertices in _\ud835\udc47_ 0), we apply the following Algorithm 4 (Branch).\n\n**Algorithm 4** Branch\n\n1: **for** each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 **do**\n\n2: select either _\ud835\udc47\ud835\udc34_ or _\ud835\udc47\ud835\udc35_ \u201cwisely\u201d\n\n3: **if** _\ud835\udc47\ud835\udc34_ is selected **then**\n\n4: color _\ud835\udc63_ with No-Dense-Case\n\n5: **else**\n\n6: color _\ud835\udc63_ with a \u201cspecial procedure\u201d\n\nIn this Branch procedure, the no-dense property must hold between _\ud835\udc46_ 0 and _\ud835\udc47\ud835\udc34_, and there must exist a\ndeterministic online algorithm that colors the vertices in _\ud835\udc47\ud835\udc35_ (at line 6) using _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors. Formally, we\nmust solve the following problem:\n\n**Division problem.** Consider the else-problem in which | _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ )| \u2265 2 _\ud835\udc5b_ [14][/][17] for each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0. Our\ntask is to divide _\ud835\udc47_ 0 into _\ud835\udc47\ud835\udc34_ and _\ud835\udc47\ud835\udc35_ online, that is, once we receive a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ 0, we must immediately decide\nwhether _\ud835\udc63_ should belong to _\ud835\udc47\ud835\udc34_ or _\ud835\udc47\ud835\udc35_ (see Figure 14). If we select _\ud835\udc47\ud835\udc35_, we must color _\ud835\udc63_ . Our objective is that\nthe no-dense property holds between _\ud835\udc46_ 0 and _\ud835\udc47\ud835\udc34_, and that the vertices in _\ud835\udc47\ud835\udc35_ are colored with _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors.\nTo achieve the no-dense property, it is allowed to delete some edges between _\ud835\udc46_ 0 and _\ud835\udc47_ 0, but | _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [14][/][17]\n\nfor each _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 must still hold after deletion (otherwise, this would violate the assumption of the else-problem\nin subsection 4.1).\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-25-0.png)\n\nFigure 14: A sketch of the division problem.\n\nIf the division problem is solved, we obtain a deterministic online algorithm that uses _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors\nfor 4-colorable graphs (by the Branch procedure). Now, to solve the division problem, we first show an\nimportant definition and lemma.\n\n**Definition 4.8.** _We say that two vertices \ud835\udc62_ 1 _, \ud835\udc62_ 2 \u2208 _\ud835\udc47_ 0 _are \ud835\udefd-common if_ | _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2)| \u2265 _\ud835\udc5b_ _[\ud835\udefd]_ _. We say \ud835\udc47\ud835\udc34_\n_is_ ( _\ud835\udefc, \ud835\udefd_ ) _-free if there is no vertex set_ { _\ud835\udc61_ 1 _, \ud835\udc61_ 2 _, . . ., \ud835\udc61\ud835\udc5b_ _[\ud835\udefc]_ +1} \u2286 _\ud835\udc47\ud835\udc34_ _where \ud835\udc61_ 1 _, \ud835\udc61_ 2 _, . . ., \ud835\udc61\ud835\udc5b_ _[\ud835\udefc]_ +1 _arrive in this order, and_\n_for all \ud835\udc56, \ud835\udc61\ud835\udc56_ _and \ud835\udc61\ud835\udc5b_ _[\ud835\udefc]_ +1 _are \ud835\udefd-common._\n\n**Lemma 4.9.** _Suppose that the no-dense property does not hold between \ud835\udc46_ 0 _and \ud835\udc47\ud835\udc34. Then, \ud835\udc47\ud835\udc34_ _is not_ ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ ) _-_\n_free for at least one \ud835\udc56, where_ \u0394 = log _\ud835\udc5b, \ud835\udc3e_ = [2 lo] log [g][ lo] _\ud835\udc5b_ [g] _[ \ud835\udc5b]_ _, and:_\n\n8\n( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ ) =\n\ufffd\n\n8 2\n\n17 [\u2212]\n\ufffd\n\n2\n\n        - [\u0394][ \u2212] _[\ud835\udc56]_\n17 [+] _[ \ud835\udc3e]_ \u0394\n\ufffd\n\n2\n17 [\u2212]\n\ufffd\n\n[ \u2212] _[\ud835\udc56]_\n\n\u0394 _[,]_ [ 14] 17\n\n2\n\n        - _[\ud835\udc56]_\n17 [+] _[ \ud835\udc3e]_ \u0394\n\ufffd\n\n\u0394\n\n( _\ud835\udc56_ = 0 _,_ 1 _, . . .,_ \u0394)\n\ufffd\n\n24\n\n_Proof._ Since the no-dense property does not hold, there exist subsets _\ud835\udc46\ud835\udc37_ \u2286 _\ud835\udc46_ 0 _,\ud835\udc47\ud835\udc37_ \u2286 _\ud835\udc47\ud835\udc34_ such that | _\ud835\udc47\ud835\udc37_ | = _\ud835\udc5b_ _[\ud835\udc4e]_\n\n8\nand | _\ud835\udc46\ud835\udc37_ | \u2264 _\ud835\udc5b_ _[\ud835\udc4e]_ [+][8][/][17] hold for some _\ud835\udc4e_ \u2264 17 [, and][ |] _[\ud835\udc41][\ud835\udc46][\ud835\udc37]_ [(] _[\ud835\udc61]_ [)| \u2265] [1] 3\n\n8\nand | _\ud835\udc46\ud835\udc37_ | \u2264 _\ud835\udc5b_ _[\ud835\udc4e]_ [+][8][/][17] hold for some _\ud835\udc4e_ \u2264 17 [, and][ |] _[\ud835\udc41][\ud835\udc46][\ud835\udc37]_ [(] _[\ud835\udc61]_ [)| \u2265] [1] 3 _[\ud835\udc5b]_ [14][/][17][ for each] _[ \ud835\udc61]_ [\u2208] _[\ud835\udc47][\ud835\udc37]_ [. It suffices to prove the]\n\ncase that | _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ )| = [1] 3 _[\ud835\udc5b]_ [14][/][17][ for each] _[ \ud835\udc61]_ [\u2208] _[\ud835\udc47][\ud835\udc37]_ [, because this is the \u201chardest\u201d case.][14]\n\nSuppose for a contradiction that _\ud835\udc47\ud835\udc34_ is ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free for all _\ud835\udc56_ .\nWe consider the sum of _\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) = | _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ 1) \u2229 _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ 2)| over all { _\ud835\udc61_ 1 _, \ud835\udc61_ 2} \u2286 _\ud835\udc47\ud835\udc37_ (with _\ud835\udc61_ 1 arriving earlier\nthan _\ud835\udc61_ 2) in two ways. First, the sum is equal to the number of tuples ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2 _, \ud835\udc60_ ) ({ _\ud835\udc61_ 1 _, \ud835\udc61_ 2} \u2208 _\ud835\udc47\ud835\udc37, \ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_ that _\ud835\udc60_ is\nadjacent to both _\ud835\udc61_ 1 and _\ud835\udc61_ 2). For each _\ud835\udc60_, there are 2 [1] [|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)|(|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)| \u2212] [1][)][ ways to choose][ {] _[\ud835\udc61]_ [1] _[, \ud835\udc61]_ [2][}][ to meet the]\n\ncondition. Hence, the following equation holds:\n\n[1]\n\n3 _[\ud835\udc5b]_ [14][/][17][ for each] _[ \ud835\udc61]_ [\u2208] _[\ud835\udc47][\ud835\udc37]_ [, because this is the \u201chardest\u201d case.][14]\n\nSuppose for a contradiction that _\ud835\udc47\ud835\udc34_ is ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free for all _\ud835\udc56_ .\nWe consider the sum of _\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) = | _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ 1) \u2229 _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ 2)| over all { _\ud835\udc61_ 1 _, \ud835\udc61_ 2} \u2286 _\ud835\udc47\ud835\udc37_ (with _\ud835\udc61_ 1 arriving earlier\nthan _\ud835\udc61_ 2) in two ways. First, the sum is equal to the number of tuples ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2 _, \ud835\udc60_ ) ({ _\ud835\udc61_ 1 _, \ud835\udc61_ 2} \u2208 _\ud835\udc47\ud835\udc37, \ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_ that _\ud835\udc60_ is\nadjacent to both _\ud835\udc61_ 1 and _\ud835\udc61_ 2). For each _\ud835\udc60_, there are [1] [|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)|(|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)| \u2212] [1][)][ ways to choose][ {] _[\ud835\udc61]_ [1] _[, \ud835\udc61]_ [2][}][ to meet the]\n\n_\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) =\n\n\u2211\ufe01 \u2211\ufe01\n\n{ _\ud835\udc61_ 1 _,\ud835\udc61_ 2 }\u2286 _\ud835\udc47\ud835\udc37_ _\ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_\n\n\u2211\ufe01\n\n_\ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_\n\n1\n2 [|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)|(|] _[\ud835\udc41][\ud835\udc47][\ud835\udc37]_ [(] _[\ud835\udc60]_ [)| \u2212] [1][)] _[.]_\n\nThere are [1]\n\n3 [1] _[\ud835\udc5b][\ud835\udc4e]_ [+][14][/][17][ edges between] _[ \ud835\udc46][\ud835\udc37]_ [and] _[ \ud835\udc47][\ud835\udc37]_ [. Therefore,][ \ufffd] _\ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_ [|] _[\ud835\udc41]_ _\ud835\udc47\ud835\udc37_ [(] _[\ud835\udc60]_ [)|][ =] 3 [1]\n\nThere are 3 [1] _[\ud835\udc5b][\ud835\udc4e]_ [+][14][/][17][ edges between] _[ \ud835\udc46][\ud835\udc37]_ [and] _[ \ud835\udc47][\ud835\udc37]_ [. Therefore,][ \ufffd] _\ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_ [|] _[\ud835\udc41]_ _\ud835\udc47\ud835\udc37_ [(] _[\ud835\udc60]_ [)|][ =] 3 [1] _[\ud835\udc5b][\ud835\udc4e]_ [+][14][/][17][. Combining]\n\nwith | _\ud835\udc46\ud835\udc37_ | \u2264 _\ud835\udc5b_ _[\ud835\udc4e]_ [+][8][/][17], we obtain [\ufffd] _\ud835\udc60_ \u2208 _\ud835\udc46\ud835\udc37_ [|] _[\ud835\udc41]_ _\ud835\udc47\ud835\udc37_ [(] _[\ud835\udc60]_ [)|][2][ \u2265] [1] 9 _[\ud835\udc5b][\ud835\udc4e]_ [+][20][/][17][.][15][ Therefore,]\n\n_\ud835\udc47\ud835\udc37_ [(] _[\ud835\udc60]_ [)|][2][ \u2265] [1] 9 _[\ud835\udc5b][\ud835\udc4e]_ [+][20][/][17][.][15][ Therefore,]\n\n_\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) = \u03a9( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] ) _._\n\n\u2211\ufe01\n\n_\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) = \u03a9( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] ) _._\n\n\u2211\ufe01\n\n{ _\ud835\udc61_ 1 _,\ud835\udc61_ 2 }\u2286 _\ud835\udc47\ud835\udc37_\n\nSecond, given that _\ud835\udc47\ud835\udc34_ is ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free, for each _\ud835\udc61_ 2, the number of _\ud835\udc61_ 1\u2019s that _\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) \u2265 _\ud835\udc5b_ _[\ud835\udefd][\ud835\udc56]_ is at most _\ud835\udc5b_ _[\ud835\udefc][\ud835\udc56]_ .\nIt means that the number of { _\ud835\udc61_ 1 _, \ud835\udc61_ 2}\u2019s that _\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2) \u2265 _\ud835\udc5b_ _[\ud835\udefd][\ud835\udc56]_ is at most _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc][\ud835\udc56]_ . Let [ _\ud835\udc50_ 1 _, \ud835\udc50_ 2 _, . . ., \ud835\udc50\ud835\udc5a_ ] be a list of\n_\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2)\u2019s for all { _\ud835\udc61_ 1 _, \ud835\udc61_ 2}\u2019s, sorted in descending order. Then, _\ud835\udc50_ _\ud835\udc57_ \u2264 _\ud835\udc5b_ _[\ud835\udefd][\ud835\udc56]_ must hold for _\ud835\udc57_ = _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc][\ud835\udc56]_ +1 _, . . ., \ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc][\ud835\udc56]_ [+][1] .\nFor _\ud835\udc57_ = 1 _,_ 2 _, . . ., \ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc]_ [0], _\ud835\udc50_ _\ud835\udc57_ \u2264 _\ud835\udc5b_ _[\ud835\udefd]_ [0] must hold, by the assumption | _\ud835\udc41\ud835\udc46\ud835\udc37_ ( _\ud835\udc61_ )| = 3 [1] _[\ud835\udc5b]_ [14][/][17][ (\u2264] _[\ud835\udc5b][\ud835\udefd]_ [0][)][. Therefore, the]\n\nfollowing holds (note that _\ud835\udc5a_ \u2264 _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc]_ [\u0394], and _\ud835\udc5b_ _[\ud835\udefc][\ud835\udc56]_ [+] _[\ud835\udefd][\ud835\udc56]_ = _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17][\u2212] _[\ud835\udc3e]_ = _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] /(log _\ud835\udc5b_ ) [2] ) for each _\ud835\udc56_ ):\n\n_\ud835\udc5a_\n\n_\ud835\udc50\ud835\udc56_ \u2264 _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc]_ [0]   - _\ud835\udc5b_ _[\ud835\udefd]_ [0] +\n\n\u2211\ufe01\n\n_\ud835\udc56_ =1\n\n= _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17][\u2212] _[\ud835\udc3e]_ +\n\n\u0394\u22121\n\n( _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc][\ud835\udc56]_ [+][1] \u2212 _\ud835\udc5b_ _[\ud835\udc4e]_ [+] _[\ud835\udefc][\ud835\udc56]_ ) \u00b7 _\ud835\udc5b_ _[\ud835\udefd][\ud835\udc56]_\n\n\u2211\ufe01\n\n_\ud835\udc56_ =0\n\n\u0394\u22121\n\n( _\ud835\udc5b_ [(][2][/][17][+] _[\ud835\udc3e]_ [)/][\u0394] \u2212 1) \u00b7 _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17][\u2212] _[\ud835\udc3e]_\n\n\u2211\ufe01\n\n_\ud835\udc56_ =0\n\n= _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] /log _\ud835\udc5b_ ) _._\n\nWe obtain that the sum of _\ud835\udc50_ ( _\ud835\udc61_ 1 _, \ud835\udc61_ 2)\u2019s is both \u03a9( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] ) and _\ud835\udc42_ ( _\ud835\udc5b_ _[\ud835\udc4e]_ [+][20][/][17] /log _\ud835\udc5b_ ), which is a contradiction.\nTherefore, Lemma 4.9 follows.\n\nBy Lemma 4.9, the division problem is solved if _\ud835\udc47\ud835\udc34_ is ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free for all _\ud835\udc56_ = 0 _,_ 1 _, . . .,_ \u0394. Now, we aim\nto achieve ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free, instead of no-dense property.\n\n**4.6** **The Common & Simplify technique**\n\nSince handling multiple pairs at once is quite challenging, we first consider an algorithm that achieves\n( _\ud835\udefc, \ud835\udefd_ )-free for a single pair ( _\ud835\udefc, \ud835\udefd_ ). Our algorithm is described in Algorithm 5 (Division( _\ud835\udefc, \ud835\udefd_ )).\n\n**Overview of Division** ( _\ud835\udefc, \ud835\udefd_ ) **.** Below, we explain how the algorithm works. The important intuition is:\n\nUsing the vertices in _\ud835\udc47_ 0 that have a lot of common neighbors, we aim to obtain a large _\ud835\udc5b_ _[\ud835\udefd]_    vertex 2-color set. Indeed, if two _\ud835\udefd_ -common vertices _\ud835\udc62_ 1 _, \ud835\udc62_ 2 \u2208 _\ud835\udc47_ 0 have different colors in some\n4-coloring of _\ud835\udc3a_, _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2) is a _\ud835\udc5b_ _[\ud835\udefd]_ -vertex 2-color set in some 4-coloring of _\ud835\udc3a_ .\n\n14This is because _\ud835\udc47\ud835\udc34_ cannot _newly_ become non-( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free by deleting edges.\n15 2\nFor any real numbers _\ud835\udc65_ 1 _, . . ., \ud835\udc65\ud835\udc58_, the inequality _\ud835\udc65_ 1 [+ \u00b7 \u00b7 \u00b7 +] _[ \ud835\udc65]_ [2] _\ud835\udc58_ [\u2265] _\ud835\udc58_ [1] [(] _[\ud835\udc65]_ [1][ + \u00b7 \u00b7 \u00b7 +] _[ \ud835\udc65][\ud835\udc58]_ [)][2][ holds.]\n\n25\n\n**Algorithm 5** Division( _\ud835\udefc, \ud835\udefd_ )\n\n1: F _,_ I _, \ud835\udc36_ \u2190[]\n\n2: R \u2190[]\n\n3: **for** each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 **do**\n\n4: **if** for some _\ud835\udc56, \ud835\udc57_, | _\ud835\udc41\ud835\udc45\ud835\udc56, \ud835\udc57_ ( _\ud835\udc63_ )| \u2265 8 log1 _\ud835\udc5b_ _[\ud835\udc5b][\ud835\udefd]_ [\u2212][3][/][17][ and 2-color][(] _[\ud835\udc45][\ud835\udc56, \ud835\udc57]_ [)][ is not aborted yet] **[ then]**\n\n5: color _\ud835\udc63_ with 2-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ )\n\n6: **else**\n\n7: delete all edges from _\ud835\udc63_ to vertices in [\ufffd] _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_\n8: **if** _\ud835\udc63_ and _\ud835\udc39\ud835\udc56, \ud835\udc57_ are _\ud835\udefd_ -common for some _\ud835\udc56, \ud835\udc57_ **then**\n\n9: _\ud835\udc3c\ud835\udc56_ \u2190 _\ud835\udc3c\ud835\udc56_ \u222a{ _\ud835\udc63_ }\n\n10: color _\ud835\udc63_ with the special color for _\ud835\udc3c\ud835\udc56_\n11: **if** some _\ud835\udc62_ 1 _, \ud835\udc62_ 2 \u2208 _\ud835\udc3c\ud835\udc56_ are adjacent **then**\n\n12: _\ud835\udc64_ 1 \u2208{ _\ud835\udc64_ \u2208 _\ud835\udc39\ud835\udc56_ : _\ud835\udc62_ 1 and _\ud835\udc64_ are _\ud835\udefd_ \u2212common}\n\n13: _\ud835\udc64_ 2 \u2208{ _\ud835\udc64_ \u2208 _\ud835\udc39\ud835\udc56_ : _\ud835\udc62_ 2 and _\ud835\udc64_ are _\ud835\udefd_ \u2212common}\n\n14: add { _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2)} to\nR _\u22b2_ In this operation, we cap the size of each added set in R to _\ud835\udc5b_ _[\ud835\udefd]_\n\n15: F = I = _\ud835\udc36_ = []\n\n16: **else**\n\n17: _\ud835\udc39_ [\u2032] \u2190{ _\ud835\udc62_ \u2208 _\ud835\udc47\ud835\udc34_ : _\ud835\udc62_ and _\ud835\udc63_ are _\ud835\udefd_ \u2212common}\n\n18: **if** | _\ud835\udc39_ [\u2032] | \u2265 _\ud835\udc5b_ _[\ud835\udefc]_ **then**\n\n19: add _\ud835\udc39_ [\u2032] to array F\n\n20: add \u2205 to array I\n\n21: add _\ud835\udc63_ to array _\ud835\udc36_\n\n22: color _\ud835\udc63_ with a special color\n\n23: **else**\n\n24: put _\ud835\udc63_ in _\ud835\udc47\ud835\udc34_\n\nIn this algorithm, we normally put a new vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 to _\ud835\udc47\ud835\udc34_, but sometimes, _\ud835\udc47\ud835\udc34_ becomes not ( _\ud835\udefc, \ud835\udefd_ )-free\nwithout selecting _\ud835\udc47\ud835\udc35_ . In such a case, we select _\ud835\udc47\ud835\udc35_ instead and create a _dense group \ud835\udc39_ where\n\n_\ud835\udc39_ = { _\ud835\udc62_ \u2208 _\ud835\udc47\ud835\udc34_ : _\ud835\udc62_ and _\ud835\udc63_ are _\ud835\udefd_ -common}\n\nwhich is | _\ud835\udc39_ | \u2265 _\ud835\udc5b_ _[\ud835\udefc]_ . Note that we color _\ud835\udc63_ with a special unique color (Figure 15 left). Afterwards, if a newly\narrived vertex _\ud835\udc63_ [\u2032] \u2208 _\ud835\udc47_ 0 is _\ud835\udefd_ -common with at least one vertex _\ud835\udc62_ \u2208 _\ud835\udc47\ud835\udc34_ that is already in a (previously created)\ndense group _\ud835\udc39\ud835\udc56_, we color _\ud835\udc63_ [\u2032] with \u201cthe special color prepared for _\ud835\udc39\ud835\udc56_ \u201d (and put _\ud835\udc63_ [\u2032] to _\ud835\udc47\ud835\udc35_ ). At this point, the\nstructure between _\ud835\udc47\ud835\udc34_ and _\ud835\udc47\ud835\udc35_ and the color used in _\ud835\udc47\ud835\udc35_ are as shown in Figure 15 middle. Note that since the\ndense groups are disjoint, the number of dense groups that exist simultaneously is at most _\ud835\udc5b_ [1][\u2212] _[\ud835\udefc]_ .\nWhen coloring _\ud835\udc63_ [\u2032] with \u201cthe special color for _\ud835\udc39\ud835\udc56_ \u201d, a problem occurs when two vertices that share the same\nspecial color are adjacent (Figure 15 right). In this case, we need to color _\ud835\udc63_ [\u2032] with a new color just for this\nvertex. However, we can obtain a 2-color set in _\ud835\udc46_ 0 instead. Assume that ( _\ud835\udc62_ 1 _, \ud835\udc62_ 2) \u2208 _\ud835\udc47\ud835\udc35_ are adjacent, _\ud835\udc62_ 1 is\n_\ud835\udefd_ -common with _\ud835\udc64_ 1 \u2208 _\ud835\udc39\ud835\udc56_, _\ud835\udc62_ 2 is _\ud835\udefd_ -common with _\ud835\udc64_ 2 \u2208 _\ud835\udc39\ud835\udc56_, and each vertex in _\ud835\udc39\ud835\udc56_ is _\ud835\udefd_ -common with _\ud835\udc65_ . Then,\n\nat least one of\n\n\ufffd _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc65_ ) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc65_ ) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2)\ufffd\n\nmust be an _\ud835\udc5b_ _[\ud835\udefd]_ -vertex 2-color set. This is because _\ud835\udc62_ 1 and _\ud835\udc62_ 2 always have different colors in any 4-coloring of\n_\ud835\udc3a_, and therefore at least one of ( _\ud835\udc62_ 1 _, \ud835\udc64_ 1) _,_ ( _\ud835\udc64_ 1 _, \ud835\udc65_ ) _,_ ( _\ud835\udc65, \ud835\udc64_ 2) _,_ ( _\ud835\udc64_ 2 _, \ud835\udc62_ 2) has different colors in some 4-coloring of\n_\ud835\udc3a_ (see Lemma 4.10). Afterwards, like subsection 4.3, we can reduce to the 2-color set problem. Note that\nthis procedure is for the sake of coloring \u201cfuture\u201d vertices efficiently.\n\n26\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-28-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-28-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-28-1.png)\n\nFigure 15: The sketch of the algorithm between _\ud835\udc47\ud835\udc34_ and _\ud835\udc47\ud835\udc35_ . The dotted line indicates that two\nvertices are _\ud835\udefd_ -common (it does not always mean they are adjacent). Colors `A`, `a`, `B`, `b`, and `X`\nare different.\n\n**Implementation.** To implement this idea, when a vertex _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 arrives, we have recorded three arrays: the\nlist of dense groups as an array of sets F = [ _\ud835\udc39_ 1 _, \ud835\udc39_ 2 _, . . ._ ], another array I = [ _\ud835\udc3c_ 1 _, \ud835\udc3c_ 2 _, . . ._ ] where _\ud835\udc3c\ud835\udc56_ is the set\nof vertices colored by the special color for _\ud835\udc39\ud835\udc56_, and another array _\ud835\udc36_ = [ _\ud835\udc50_ 1 _, \ud835\udc50_ 2 _, . . ._ ] where _\ud835\udc50\ud835\udc56_ is _\ud835\udefd_ -common to\neach vertex in _\ud835\udc39\ud835\udc56_ (i.e., the cause of creating _\ud835\udc39\ud835\udc56_ ). We also recorded the list of initiated 2-Color subroutines in\narray R (the same details as Algorithm 3). Then, upon the arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_ 0, we run the following procedure:\n\n1. If there exist _\ud835\udc56, \ud835\udc57_ such that | _\ud835\udc41\ud835\udc45\ud835\udc56, \ud835\udc57_ ( _\ud835\udc63_ )| \u2265 8 log1 _\ud835\udc5b_ _[\ud835\udc5b][\ud835\udefd]_ [\u2212][3][/][17][ and 2-Color][(] _[\ud835\udc45][\ud835\udc56, \ud835\udc57]_ [)][ is not aborted, we color] _[ \ud835\udc63]_\nwith 2-Color( _\ud835\udc45\ud835\udc56, \ud835\udc57_ ), as it meets the condition for _\ud835\udc47_ in the 2-color set problem (lines 4\u20135).\n\n2. Otherwise, to ensure the no-dense property between _\ud835\udc46_ 0 and _\ud835\udc47\ud835\udc34_, we delete the edges between _\ud835\udc63_ and\n\ufffd _\ud835\udc56, \ud835\udc57_ _[\ud835\udc45]_ _\ud835\udc56, \ud835\udc57_ [(line 7). Then,]\n\n     - If _\ud835\udc63_ and _\ud835\udc65_ \u2208 _\ud835\udc39\ud835\udc56_ are _\ud835\udefd_ -common, we color _\ud835\udc63_ with the special color for _\ud835\udc39\ud835\udc56_ and update _\ud835\udc3c\ud835\udc56_ (lines 9\u201310).\nIf there is an edge inside _\ud835\udc3c\ud835\udc56_, we obtain four candidates for 2-color sets (lines 11\u201314), update R,\nand then reset all dense groups (line 15). Note that after coloring _\ud835\udc63_, we update R, but this is for\nthe sake of coloring \u201cfuture\u201d vertices efficiently.\n\n     - Otherwise, put _\ud835\udc63_ in _\ud835\udc47\ud835\udc34_ if it does not violate ( _\ud835\udefc, \ud835\udefd_ )-free (line 24). If not, select _\ud835\udc47\ud835\udc35_ and create a\ndense group (lines 19\u201322).\n\n**4.7** **Correctness & Analysis**\n\nNext, we discuss the correctness of and the number of colors used in Division( _\ud835\udefc, \ud835\udefd_ ). The goal is to show that\nthe algorithm correctly solves the division problem (Lemma 4.15). We first show some required lemmas.\n\n**Lemma 4.10.** _At line 14 of Division_ ( _\ud835\udefc, \ud835\udefd_ ) _, at least one of \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) \u2229\n_\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) _, \ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2) _is a 2-color set in some 4-coloring of \ud835\udc3a._\n\n_Proof._ Let _\ud835\udc5d_ 1 _, \ud835\udc5d_ 2 _, \ud835\udc5d_ 3 _, \ud835\udc5d_ 4 _, \ud835\udc5d_ 5 \u2208{1 _,_ 2 _,_ 3 _,_ 4} be the colors of _\ud835\udc62_ 1 _, \ud835\udc64_ 1 _, \ud835\udc50\ud835\udc56, \ud835\udc64_ 2 _, \ud835\udc62_ 2 in a 4-coloring of _\ud835\udc3a_ . Since\n_\ud835\udc62_ 1 _\ud835\udc62_ 2 \u2208 _\ud835\udc38_ ( _\ud835\udc3a_ ) and hence _\ud835\udc5d_ 1 \u2260 _\ud835\udc5d_ 5, there exists some _\ud835\udc56_ with _\ud835\udc5d\ud835\udc56_ \u2260 _\ud835\udc5d\ud835\udc56_ +1. If _\ud835\udc5d_ 1 \u2260 _\ud835\udc5d_ 2, then _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) is\na 2-color set. If _\ud835\udc5d_ 2 \u2260 _\ud835\udc5d_ 3, then _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 1) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) is a 2-color set. If _\ud835\udc5d_ 3 \u2260 _\ud835\udc5d_ 4, then _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc50\ud835\udc56_ ) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) is a\n2-color set. If _\ud835\udc5d_ 4 \u2260 _\ud835\udc5d_ 5, then _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc64_ 2) \u2229 _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc62_ 2) is a 2-color set.\n\n**Lemma 4.11.** |R| \u2264 _\ud835\udc5b_ [1][\u2212] _[\ud835\udefd]_ _._\n\n_Proof._ By Lemma 4.10, for each _\ud835\udc56_, there must be at least one _\ud835\udc61_ that 2-Color( _\ud835\udc45\ud835\udc56,\ud835\udc61_ ) is not aborted yet. For\nsuch _\ud835\udc61_, let _\ud835\udc45\ud835\udc56_ [\u2032] [=] _[ \ud835\udc45][\ud835\udc56,\ud835\udc61]_ [. Then,][ |] _[\ud835\udc45]_ _\ud835\udc56_ [\u2032] [\u2229] _[\ud835\udc45]_ [\u2032] _\ud835\udc57_ [|][ =][ 0][ (] _[\ud835\udc56]_ [\u2260] _[\ud835\udc57]_ [)][ by line 7 in Division][(] _[\ud835\udefc, \ud835\udefd]_ [)][. Since][ |] _[\ud835\udc45]_ _\ud835\udc56_ [\u2032][|][ =] _[ \ud835\udc5b][\ud835\udefd]_ [for each] _[ \ud835\udc56]_ [,]\nLemma 4.11 holds.\n\n27\n\n**Lemma 4.12.** _In line 7 of Division_ ( _\ud835\udefc, \ud835\udefd_ ) _, at most_ 2 log1 _\ud835\udc5b_ _[\ud835\udc5b]_ [14][/][17] _[ edges are deleted for each][ \ud835\udc63]_ [\u2208] _[\ud835\udc47]_ [0] _[.]_\n\n1\n_Proof._ By |R| \u2264 _\ud835\udc5b_ [1][\u2212] _[\ud835\udefd]_ (Lemma 4.11), |R _\ud835\udc56_ | = 4 for each _\ud835\udc56_, and the threshold in line 4 is 8 log _\ud835\udc5b_ _[\ud835\udc5b][\ud835\udefd]_ [\u2212][3][/][17][,]\n\n1 1\n8 log _\ud835\udc5b_ _[\ud835\udc5b][\ud835\udefd]_ [\u2212][3][/][17][ \u00b7 |R| \u00b7 |R] _[\ud835\udc56]_ [| \u2264] 2 log _\ud835\udc5b_ _[\ud835\udc5b]_ [14][/][17]\n\nedges are deleted from each _\ud835\udc41\ud835\udc46_ ( _\ud835\udc63_ ), and therefore Lemma 4.12 holds.\n\n**Lemma 4.13.** _Division_ ( _\ud835\udefc, \ud835\udefd_ ) _uses_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) _colors, if \ud835\udefc_ + _\ud835\udefd_ = [20]\n\n17 [\u2212] _[\ud835\udc3e][.]_\n\n[20]\n\n17 [\u2212] _[\ud835\udc3e]_ _[and][ \ud835\udefd]_ [\u2265] [12] 17\n\n_Proof._ Let _\ud835\udc50_ 1 _, \ud835\udc50_ 2 _, \ud835\udc50_ 3 be the number of colors used in lines 5, 10, and 22 in Division( _\ud835\udefc, \ud835\udefd_ ), respectively.\nThen, the number of colors used in Division( _\ud835\udefc, \ud835\udefd_ ) is _\ud835\udc50_ 1 + _\ud835\udc50_ 2 + _\ud835\udc50_ 3. Each value is as follows:\n\n   - _\ud835\udc50_ 1: By |R| = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [5][/][17] ) (Lemma 4.11 and the value of _\ud835\udefd_ ) and Lemma 4.1, _\ud835\udc50_ 1 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ).\n\n   - _\ud835\udc50_ 2: Since | _\ud835\udc39\ud835\udc56_ \u2229 _\ud835\udc39\ud835\udc57_ | = 0 ( _\ud835\udc56_ \u2260 _\ud835\udc57_ ) by lines 8 and 17, and | _\ud835\udc39\ud835\udc56_ | \u2265 _\ud835\udc5b_ _[\ud835\udefc]_ for each _\ud835\udc56_, we have |F | = |I| = _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udefc]_ ).\nSince only two colors are used in each _\ud835\udc3c\ud835\udc56_, and the resetting of I occurs _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212] _[\ud835\udefd]_ ) times (Lemma 4.11),\n_\ud835\udc50_ 2 = _\ud835\udc42_ ( _\ud835\udc5b_ [2][\u2212] _[\ud835\udefc]_ [\u2212] _[\ud835\udefd]_ ) = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ).\n\n   - _\ud835\udc50_ 3: From the same reason as for _\ud835\udc50_ 2, we have _\ud835\udc50_ 3 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ).\n\nAs _\ud835\udc50_ 1 + _\ud835\udc50_ 2 + _\ud835\udc50_ 3 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ), the algorithm Division( _\ud835\udefc, \ud835\udefd_ ) uses only _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors.\n\n**Lemma 4.14.** _The set \ud835\udc47\ud835\udc34_ _generated by Division_ ( _\ud835\udefc, \ud835\udefd_ ) _is_ ( _\ud835\udefc, \ud835\udefd_ ) _-free._\n\n_Proof._ It follows directly from lines 17\u201318 of Division( _\ud835\udefc, \ud835\udefd_ ).\n\nAt this point, we have successfully obtained an algorithm that achieves ( _\ud835\udefc, \ud835\udefd_ )-free in _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors\nfor a single pair ( _\ud835\udefc, \ud835\udefd_ ). Now, we finally show the solution to the division problem.\n\n**Lemma 4.15.** _There is an algorithm that solves the division problem._\n\n_Proof._ Consider an algorithm that applies lines 4\u201322 of Division( _\ud835\udefc, \ud835\udefd_ ) for each pair ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ ) for each\n_\ud835\udc56_ \u2208{0 _,_ 1 _, . . .,_ \u0394}. We use independent arrays F _,_ I _, \ud835\udc36_ for each pair ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ ), and for each arrival of _\ud835\udc63_ \u2208 _\ud835\udc47_, we\nrepeat lines 4\u201322 in Division( _\ud835\udefc, \ud835\udefd_ ) for _\ud835\udc56_ \u2208{0 _,_ 1 _, . . .,_ \u0394}. If all the results of the \u201cif-conditions\u201d are false, we\nput _\ud835\udc63_ in _\ud835\udc47\ud835\udc34_ .\nTo prove the correctness, we must prove the following three: (1) the no-dense property between _\ud835\udc46_ 0\nand _\ud835\udc47\ud835\udc34_, (2) the number of colors used for _\ud835\udc47\ud835\udc35_, and (3) | _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ )| \u2265 _\ud835\udc5b_ [14][/][17] holds for each _\ud835\udc63_ \u2208 _\ud835\udc47_ 0 even after\nthe edge deletion. For (1), by Lemma 4.14, _\ud835\udc47\ud835\udc34_ is obviously ( _\ud835\udefc\ud835\udc56, \ud835\udefd\ud835\udc56_ )-free for each _\ud835\udc56_, and by Lemma 4.9,\n_\ud835\udc42_ the no-dense property holds between\ufffd( _\ud835\udc5b_ [14][/][17] ) \u00b7 \u0394 = _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] ) colors. For (3), by _\ud835\udc46_ 0 and Lemma 4.12 _\ud835\udc47\ud835\udc34_ . For (2), by and \u0394 = Lemma 4.13 log _\ud835\udc5b_, at most and2 log\u0394 \u0394 =+1 _\ud835\udc5b_ [\u00b7] _[\ud835\udc5b]_ log [14][/][17] _\ud835\udc5b_ [ \u2264], we only use _[\ud835\udc5b]_ [14][/][17][ edges]\nin _\ud835\udc41\ud835\udc46_ 0 ( _\ud835\udc63_ ) are deleted in total for each _\ud835\udc63_ \u2208 _\ud835\udc47_ 0, which means that _\ud835\udc5b_ [14][/][17] or more edges remain. Therefore, the\nalgorithm above solves the division problem.\n\n**4.8** **Conclusion**\n\nFinally, by Lemma 4.15, Lemma 4.7, and subsection 4.1, we obtain the following theorem.\n\n**Theorem 4.16.** _There is a deterministic online algorithm that colors any 4-colorable graph with_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [14][/][17] )\n\n_colors._\n\nIn addition, combining with the results in section 3, we can also improve the results for _\ud835\udc58_ \u2265 5. We show\nthe following theorem:\n\n28\n\n_\ud835\udc42_ **Theorem 4.17.** \ufffd( _\ud835\udc5b_ [1][\u2212][6][/(][3] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][)\u2212] _There exists a deterministic online algorithm that colors any_ [2][)] ) _colors, for any \ud835\udc58_ \u2265 4 _._ _\ud835\udc58-colorable graph with_\n\n_Proof._ The case for _\ud835\udc58_ = 4 is proved in Theorem 4.16. For _\ud835\udc58_ \u2265 5, we prove that the algorithm to solve the\nlevel- _\ud835\udc51_ subproblem+ can achieve _\ud835\udc42_ [\ufffd] (max(| _\ud835\udc47_ | _, \ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ )/ _\ud835\udc5b_ _[\ud835\udf16]_ ) colors, where _\ud835\udf16_ = 3 _\ud835\udc58_ ( _\ud835\udc58_ \u221261)\u22122 [. We follow the proof]\nin subsection 3.6. For the _\ud835\udc51_ = _\ud835\udc58_ \u2212 1 case, it suffices to prove the following inequality:\n\n6\n| _\ud835\udc47_ | [1][\u2212] 3( _\ud835\udc58_ \u22121) ( _\ud835\udc58_ \u22122)\u22122 \u2264 [max][(|] _[\ud835\udc47]_ [|] _[, \ud835\udc5b]_ [1][\u2212(] _[\ud835\udc58]_ [\u2212][1][)] _[ \ud835\udf16]_ [)]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n6\nand it holds when _\ud835\udf16_ \u2264 3 _\ud835\udc58_ ( _\ud835\udc58_ \u22121)\u22122 [. For the] _[ \ud835\udc51]_ [\u2264] _[\ud835\udc58]_ [\u2212] [2 case, it suffices to prove the following inequality, for]\n\n| _\ud835\udc47_ | \u2265 _\ud835\udc5b_ [1][\u2212] _[\ud835\udc51\ud835\udf16]_ and | _\ud835\udc37_ | = [|] _\ud835\udc5b_ _[\ud835\udc47]_ ~~_[\ud835\udf16]_~~ [|] [:]\n\n2\n| _\ud835\udc37_ | [1][\u2212] _\ud835\udc51_ ( _\ud835\udc51_ \u22121)+2 \u2264 [|] _[\ud835\udc37]_ [|]\n\n_\ud835\udc5b_ _[\ud835\udf16]_\n\n2 6\nand it holds when _\ud835\udf16_ \u2264 _\ud835\udc51_ ( _\ud835\udc51_ +1)+4 [, which is above] 3 _\ud835\udc58_ ( _\ud835\udc58_ \u22121)\u22122 [even with] _[ \ud835\udc51]_ [=] _[ \ud835\udc58]_ [\u2212] [2, for all] _[ \ud835\udc58]_ [\u2265] [5. Therefore,]\nTheorem 4.17 holds.\n\nBy Theorem 4.17, the results for _\ud835\udc58_ \u2265 5 are slightly improved over Theorem 3.12. Our best results,\ncompared with Kierstead\u2019s algorithm [18], are shown in Table 2.\n\n_\ud835\udc58_ 3 4 5 6 7\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\nPrevious Results _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [6667] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [8334] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9917] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9987] ) _\ud835\udc42_ \ufffd( _\ud835\udc5b_ [0] _[.]_ [9999] )\nOur Results \u2014 _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [8236] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [8966] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [9319] ) _\ud835\udc42_ ( _\ud835\udc5b_ [0] _[.]_ [9517] )\n\nTable 2: Comparison between the previous best results [18] and our results, for _\ud835\udc58_ \u2264 7.\n\n### **5 Randomized algorithm for bipartite graphs**\n\nIn this section, we show an efficient randomized online coloring algorithm for bipartite graphs, against an\noblivious adversary (the case where the graph is determined before the coloring begins).\n\n**5.1** **The algorithm by Lov\u00b4asz, Saks, and Trotter**\n\nFirstly, we review a previously-known deterministic online coloring algorithm for bipartite graphs by Lov\u00b4asz,\nSaks, and Trotter (1989) [21]. This algorithm uses 2 log( _\ud835\udc5b_ + 1) colors in the worst case, and is an optimal\ndeterministic algorithm up to a constant number of colors [11]. The idea of this algorithm is to always try to\nachieve the \u201cbipartite coloring\u201d, and once it becomes impossible, we start using a new color. Note that the\nhard case is when there are many components of bipartite graphs, and some of them start merging when a\nnew vertex _\ud835\udc63_ arrives. In this case, we may need a new color for _\ud835\udc63_ .\nFormally, we assign a _level_ to each connected component, so that a level- _\u2113_ component uses colors\n1 _,_ 2 _, . . .,_ 2 _\u2113_ . The meaning of the level is how many times the algorithm fails to achieve the \u201cbipartite\ncoloring\u201d and is forced to use a new color. Therefore, we would like to estimate the maximum level.\nWe call a level- _\u2113_ component _matched_ if the colors 2 _\u2113_ \u2212 1 and 2 _\u2113_ are based on the \u201ccorrect\u201d 2-coloring;\nthat is, distances of any two vertices with color 2 _\u2113_ \u2212 1 are even, distances of any two vertices with color 2 _\u2113_\nare even, and distances of any vertex with color 2 _\u2113_ \u2212 1 and any vertex with color 2 _\u2113_ are odd. At any time,\nevery component is supposed to be matched. So, when a new vertex _\ud835\udc63_ arrives and some component becomes\nno longer matched, we increase the component\u2019s level by 1 and use a new color for vertex _\ud835\udc63_ . Otherwise, we\ncolor _\ud835\udc63_ with either color 2 _\u2113_ \u2212 1 or 2 _\u2113_, whichever is matched. Examples are shown in Figure 16.\n\n29\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-31-0.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-31-1.png)\n\nFigure 16: Two examples of the algorithm by Lov\u00b4asz, Saks, and Trotter [21]. Left figure\nshows an example when the component is still matched, and the right figure shows an example\nwhen we must increase the level from 2 to 3. The number inside each vertex is the color used.\n\nLov\u00b4asz, Saks, and Trotter\u2019s algorithm is described in Algorithm 6 (LST89). We suppose that _\ud835\udc49_ =\n{ _\ud835\udc63_ 1 _, . . ., \ud835\udc63\ud835\udc5b_ }, arriving in the order _\ud835\udc63_ 1 _, . . ., \ud835\udc63\ud835\udc5b_ . When vertex _\ud835\udc63\ud835\udc56_ arrives, the resulting component including _\ud835\udc63\ud835\udc56_\nis denoted as _\ud835\udc36\ud835\udc56_, and its level, after coloring _\ud835\udc63\ud835\udc56_, is denoted as _\u2113\ud835\udc56_ .\n\n**Algorithm 6** LST89( _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ))\n\n1: _\ud835\udc46_ \u2190\u2205 _\u22b2_ the set of indices of connected components of the current graph\n\n2: **for** _\ud835\udc56_ = 1 _, . . ., \ud835\udc5b_ **do**\n\n3: _\ud835\udc65\ud835\udc56,_ 1 _, . . ., \ud835\udc65\ud835\udc56,\ud835\udc58\ud835\udc56_ \u2190{ _\ud835\udc57_ \u2208 _\ud835\udc46_ : \u2203 _\ud835\udc62_ \u2208 _\ud835\udc36_ _\ud835\udc57, \ud835\udc62\ud835\udc63\ud835\udc56_ \u2208 _\ud835\udc38_ } _\u22b2_ the indices of components that are adjacent to _\ud835\udc63\ud835\udc56_\n4: _\ud835\udc36\ud835\udc56_ \u2190 _\ud835\udc36\ud835\udc65\ud835\udc56,_ 1 \u222a\u00b7 \u00b7 \u00b7 \u222a _\ud835\udc36\ud835\udc65\ud835\udc56,\ud835\udc58\ud835\udc56_ \u222a{ _\ud835\udc63\ud835\udc56_ }\n\n5: _\ud835\udc46_ \u2190( _\ud835\udc46_ \\ { _\ud835\udc65\ud835\udc56,_ 1 _, . . ., \ud835\udc65\ud835\udc56,\ud835\udc58\ud835\udc56_ }) \u222a{ _\ud835\udc56_ }\n\n6: **if** _\ud835\udc58\ud835\udc56_ = 0 **then**\n\n7: Color _\ud835\udc63\ud835\udc56_ by color 1\n\n8: _\u2113\ud835\udc56_ \u2190 1\n\n9: **else**\n\n10: _\u2113\ud835\udc56_ [\u2217] [\u2190] [max][(] _[\u2113][\ud835\udc65]_ _\ud835\udc56,_ 1 _[, . . ., \u2113][\ud835\udc65]_ _\ud835\udc56,\ud835\udc58\ud835\udc56_ [)]\n\n11: **if** _\ud835\udc36\ud835\udc56_ is matched (as a level- _\u2113\ud835\udc56_ [\u2217] [component)] **[ then]**\n\n12: Color _\ud835\udc63\ud835\udc56_ by either color 2 _\u2113\ud835\udc56_ [\u2217] [\u2212] [1 or 2] _[\u2113]_ _\ud835\udc56_ [\u2217] [so that] _[ \ud835\udc36][\ud835\udc56]_ [remains matched]\n\n13: _\u2113\ud835\udc56_ \u2190 _\u2113\ud835\udc56_ [\u2217]\n14: **else**\n\n15: Color _\ud835\udc63\ud835\udc56_ by color 2 _\u2113\ud835\udc56_ [\u2217] [+][ 1]\n\n16: _\u2113\ud835\udc56_ \u2190 _\u2113\ud835\udc56_ [\u2217] [+][ 1]\n\n**Theorem 5.1** ([21]) **.** _Algorithm 6 (LST89) uses at most_ 2 log( _\ud835\udc5b_ + 1) _colors for any graph._\n\n_Proof._ Let _\ud835\udc4e\u2113_ be the minimum _\ud835\udc5b_ that level- _\u2113_ components can appear. For _\u2113_ \u2265 2, a level- _\u2113_ component can\nbe formed only when two or more level-( _\u2113_ \u2212 1) components are merged into one component. Therefore,\n_\ud835\udc4e\u2113_ \u2265 2 _\ud835\udc4e\u2113_ \u22121 + 1. Then, _\ud835\udc4e\u2113_ \u2265 2 _[\u2113]_ \u2212 1 follows, so the algorithm uses at most 2 log( _\ud835\udc5b_ + 1) colors.\n\n**5.2** **The randomized algorithm and its probabilistic model**\n\nIn this subsection, we present a randomized algorithm for online coloring of bipartite graphs. This algorithm\nis essentially the randomized version of LST89, which makes the following modifications to Algorithm 6:\n\n  - Change line 7 to \u201cColor _\ud835\udc63\ud835\udc56_ by color 1 or 2 with probability [1] 2 [each\u201d]\n\n30\n\n  - Change line 15 to \u201cColor _\ud835\udc63\ud835\udc56_ by color 2 _\u2113\ud835\udc56_ [\u2217] [+][ 1 or 2] _[\u2113]_ _\ud835\udc56_ [\u2217] [+][ 2 with probability] [1] 2 [each\u201d]\n\nThe new algorithm is denoted by RandomizedLST. The number of colors will be improved from LST89,\nbecause the adversarial case, which requires a new color every time, can be avoided in expectation. The goal\nof this section is to prove that RandomizedLST uses at most 1 _._ 034 log _\ud835\udc5b_ + _\ud835\udc42_ (1) colors in expectation.\n\n**Probabilistic model of the performance.** We analyze the performance of RandomizedLST using a rooted\nforest _\ud835\udc47_ . When a vertex _\ud835\udc63\ud835\udc56_ arrives, the component _\ud835\udc36\ud835\udc56_ is formed by merging _\ud835\udc63\ud835\udc56_ and some existing connected\ncomponents, say _\ud835\udc36\ud835\udc65\ud835\udc56,_ 1 _, . . ., \ud835\udc36\ud835\udc65\ud835\udc56,\ud835\udc58\ud835\udc56_ . We represent in _\ud835\udc47_ this relation of how the components are merged. This\nis defined to be an _\ud835\udc5b_ -vertex forest where the vertices are labeled 1 _, . . ., \ud835\udc5b_, and the children of vertex _\ud835\udc56_ are\n_\ud835\udc65\ud835\udc56,_ 1 _, ..., \ud835\udc65\ud835\udc56,\ud835\udc58\ud835\udc56_ . [16] Then, the probability distribution of ( _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_ ) in RandomizedLST can be simulated by\nAlgorithm 7, which is shown in the following lemma.\n\n**Lemma 5.2.** _The probability distributions of_ ( _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_ ) _generated by RandomizedLST and by Algorithm 7_\n\n_are the same._\n\n**Algorithm 7** Alternative algorithm to generate levels _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_\n\n1: **for** _\ud835\udc56_ = 1 _, . . ., \ud835\udc5b_ **do**\n\n2: **if** vertex _\ud835\udc63\ud835\udc56_ is a leaf in _\ud835\udc47_ **then**\n\n3: _\u2113\ud835\udc56_ \u2190 1\n\n4: **else**\n\n5: _\u2113\ud835\udc56_ [\u2217] [\u2190] [max][(] _[\u2113][\ud835\udc65]_ _\ud835\udc56,_ 1 _[, . . ., \u2113][\ud835\udc65]_ _\ud835\udc56,\ud835\udc58\ud835\udc56_ [)]\n\n6: _\ud835\udc50\ud835\udc56_ \u2190 (number of _\ud835\udc57_ \u2019s that _\u2113\ud835\udc65\ud835\udc56, \ud835\udc57_ = _\u2113\ud835\udc56_ [\u2217][)]\n\n7: _\u2113\ud835\udc56_ \u2190 ( _\u2113\ud835\udc56_ [\u2217] [with probability 2][\u2212(] _[\ud835\udc50][\ud835\udc56]_ [\u2212][1][)] [, and] _[ \u2113]_ _\ud835\udc56_ [\u2217] [+][ 1 with probability 1][ \u2212] [2][\u2212(] _[\ud835\udc50][\ud835\udc56]_ [\u2212][1][)] [)]\n\n_Proof._ It suffices to show that in RandomizedLST, the conditional probability that _\u2113\ud835\udc56_ = _\u2113\ud835\udc56_ [\u2217] [given][ (] _[\u2113]_ [1] _[, . . ., \u2113][\ud835\udc56]_ [\u2212][1][)]\nis always 2 [\u2212(] _[\ud835\udc50][\ud835\udc56]_ [\u2212][1][)], where _\u2113\ud835\udc56_ [\u2217] [:][=][ max][(] _[\u2113][\ud835\udc65]_ _\ud835\udc56,_ 1 _[, . . ., \u2113][\ud835\udc65]_ _\ud835\udc56,\ud835\udc58\ud835\udc56_ [)][ and] _[ \ud835\udc50][\ud835\udc56]_ [:][=][ (][the number of] _[ \ud835\udc57]_ [\u2019s that] _[ \u2113][\ud835\udc65][\ud835\udc56, \ud835\udc57]_ [=] _[ \u2113]_ _\ud835\udc56_ [\u2217][)][. We relate]\na coloring of _\ud835\udc63_ 1 _, . . ., \ud835\udc63\ud835\udc56_ \u22121 to the colorings obtained by \u201cflipping\u201d the color of all the vertices in an arbitrary\nC [\u2032] \u2286{ _\ud835\udc36\ud835\udc65\ud835\udc56, \ud835\udc57_ : _\u2113\ud835\udc65\ud835\udc56, \ud835\udc57_ = _\u2113\ud835\udc56_ [\u2217][}][. Formally, flipping the color means that odd-numbered color 2] _[\u2113]_ [\u2212] [1 becomes color]\n2 _\u2113_, and even-numbered color 2 _\u2113_ becomes color 2 _\u2113_ \u2212 1. Then, we obtain 2 _[\ud835\udc50][\ud835\udc56]_ colorings. These colorings\nhave the same ( _\u2113_ 1 _, . . ., \u2113\ud835\udc56_ \u22121), and all of them appear with the same probability because the related coloring\nappears when all of the probabilistic decisions in C [\u2032] are inverted. However, _\ud835\udc36\ud835\udc56_ is matched for only two of\nthem. Therefore, the probability that _\u2113\ud835\udc56_ = _\u2113\ud835\udc56_ [\u2217] [is] 22 ~~_[\ud835\udc50]_~~ _[\ud835\udc56]_ [=][ 2][\u2212(] _[\ud835\udc50][\ud835\udc56]_ [\u2212][1][)] [, and otherwise] _[ \u2113][\ud835\udc56]_ [becomes] _[ \u2113]_ _\ud835\udc56_ [\u2217] [+][ 1.]\n\nThe expected number of colors in RandomizedLST is, obviously, between 2E[max( _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_ )] \u2212 1 and\n2E[max( _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_ )]. Especially when _\ud835\udc47_ is a tree, _\u2113\ud835\udc5b_ = max( _\u2113_ 1 _, . . ., \u2113\ud835\udc5b_ ) because vertex _\ud835\udc5b_ is the root of _\ud835\udc47_ ;\nin this case, it is crucial to estimate E[ _\u2113\ud835\udc5b_ ]. It turns out that, when we search for the graphs with the worst\nexpected number of colors, we only have to consider the case when _\ud835\udc3a_ is connected (i.e., _\ud835\udc47_ is a tree). This is\nbecause, when _\ud835\udc3a_ is not connected, we can modify the graph by adding edges between _\ud835\udc63\ud835\udc5b_ and all the other\nconnected components, and the levels will not decrease.\n\n**5.3** **Preliminaries for the analysis**\n\nIn this subsection, we prove the following lemma, which shows that it is sufficient to consider when _\ud835\udc47_ is a\nbinary tree. Hereafter, we call _\u2113\ud835\udc63_ the level of vertex _\ud835\udc63_ (of _\ud835\udc47_ ) and denote the root of _\ud835\udc47_ as root( _\ud835\udc47_ ).\n\n16The constructed _\ud835\udc47_ is indeed a rooted forest. It has no cycles due to _\ud835\udc65\ud835\udc56, \ud835\udc57_ _< \ud835\udc56_ . No vertex is a child of multiple vertices because\nonce a connected component is merged, it is no longer a connected component of the graph.\n\n31\n\n**Lemma 5.3.** _There is a binary tree \ud835\udc47_ _that maximizes_ E[ _\u2113_ root( _\ud835\udc47_ ) ] _among all trees with \ud835\udc5a_ _leaves._\n\nFirst, we define the following preorder \u2aaf on the set of rooted trees T :\n\n**Definition 5.4.** _For \ud835\udc47_ 1 _,\ud835\udc47_ 2 \u2208T _, \ud835\udc47_ 1 \u2aaf _\ud835\udc47_ 2 _if_ Pr _\ud835\udc47_ = _\ud835\udc47_ 1 [ _\u2113_ root( _\ud835\udc47_ 1 ) \u2265 _\ud835\udc61_ ] \u2265 Pr _\ud835\udc47_ = _\ud835\udc47_ 2 [ _\u2113_ root( _\ud835\udc47_ 2 ) \u2265 _\ud835\udc61_ ] _for all \ud835\udc61._\n\nIt is easy to see that the relation \u2aaf satisfies reflexivity and transitivity. Also, if _\ud835\udc47_ 1 \u2aaf _\ud835\udc47_ 2, then E[ _\u2113_ root( _\ud835\udc47_ 1 ) ] \u2265\nE[ _\u2113_ root( _\ud835\udc47_ 2 ) ] holds because E[ _\ud835\udc4b_ ] = [\ufffd][\u221e] _\ud835\udc61_ =1 [Pr][[] _[\ud835\udc4b]_ [\u2265] _[\ud835\udc61]_ []][ for any random variable] _[ \ud835\udc4b]_ [that takes a positive integer.]\n\n**Lemma 5.5.** _Let \ud835\udc47_ 1 _be a tree, and let \ud835\udc47_ 2 _be a tree created by replacing a subtree \ud835\udc47_ 1 [\u2032] _[(of][ \ud835\udc47]_ [1] _[) with a tree][ \ud835\udc47]_ 2 [\u2032] _[. If]_\n_\ud835\udc47_ [\u2032]\n1 [\u2aaf] _[\ud835\udc47]_ 2 [\u2032] _[, then][ \ud835\udc47]_ [1][ \u2aaf] _[\ud835\udc47]_ [2] _[ holds.]_\n\n_Proof._ Let _\ud835\udc5f_ = root( _\ud835\udc47_ 1) (= root( _\ud835\udc47_ 2)). We first consider the case that root( _\ud835\udc47_ 1 [\u2032][)][ (also root][(] _[\ud835\udc47]_ 2 [\u2032][)][) is a child of] _[ \ud835\udc5f]_ [.]\nLet _\ud835\udc65_ 1 _, . . ., \ud835\udc65\ud835\udc58_ ( _\ud835\udc65_ 1 = root( _\ud835\udc47_ 1 [\u2032][))][ be the children of] _[ \ud835\udc5f]_ [. If] _[ \ud835\udc58]_ [=][ 1, then] _[ \u2113][\ud835\udc5f]_ [=] _[ \u2113][\ud835\udc65]_ [1][, so it is obvious that] _[ \ud835\udc47]_ [1][ \u2aaf] _[\ud835\udc47]_ [2][ holds]\ngiven that _\ud835\udc47_ 1 [\u2032] [\u2aaf] _[\ud835\udc47]_ 2 [\u2032][. So suppose] _[ \ud835\udc58]_ [\u2265] [2. If the levels of] _[ \ud835\udc65]_ [2] _[, . . ., \ud835\udc65][\ud835\udc58]_ [are fixed, the level of] _[ \ud835\udc5f]_ [is decided in the]\nfollowing way, where _\u2113_ [\u2032] = max( _\u2113\ud835\udc65_ 2 _, . . ., \u2113\ud835\udc65\ud835\udc58_ ), and _\ud835\udc50_ [\u2032] = (number of _\ud835\udc57_ \u2019s ( _\ud835\udc57_ \u2265 2) that _\u2113\ud835\udc65_ _\ud835\udc57_ = _\u2113_ [\u2032] ):\n\n_\u2113\ud835\udc5f_ =\n\nTherefore:\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\n_\u2113_ [\u2032] with probability 2 [\u2212(] _[\ud835\udc50]_ [\u2032] [\u2212][1][)], and _\u2113_ [\u2032] + 1 with probability 1 \u2212 2 [\u2212(] _[\ud835\udc50]_ [\u2032] [\u2212][1][)] ( _\u2113\ud835\udc65_ 1 _< \u2113_ [\u2032] )\n_\u2113_ [\u2032] with probability 2 [\u2212] _[\ud835\udc50]_ [\u2032], and _\u2113_ [\u2032] + 1 with probability 1 \u2212 2 [\u2212] _[\ud835\udc50]_ [\u2032] ( _\u2113\ud835\udc65_ 1 = _\u2113_ [\u2032] )\n\n_\u2113\ud835\udc65_ 1 ( _\u2113\ud835\udc65_ 1 _> \u2113_ [\u2032] )\n\nPr[ _\u2113\ud835\udc5f_ \u2265 _\ud835\udc61_ ] =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\n1 ( _\ud835\udc61_ \u2264 _\u2113_ [\u2032] )\n(1 \u2212 2 [\u2212(] _[\ud835\udc50]_ [\u2032] [\u2212][1][)] ) + 2 [\u2212] _[\ud835\udc50]_ [\u2032] - Pr[ _\u2113\ud835\udc65_ 1 \u2265 _\u2113_ [\u2032] ] + 2 [\u2212] _[\ud835\udc50]_ [\u2032] - Pr[ _\u2113\ud835\udc65_ 1 \u2265 _\u2113_ [\u2032] + 1] ( _\ud835\udc61_ = _\u2113_ [\u2032] + 1)\n\nPr[ _\u2113\ud835\udc65_ 1 \u2265 _\ud835\udc61_ ] ( _\ud835\udc61_ \u2265 _\u2113_ [\u2032] + 2)\n\nWhen _\ud835\udc47_ 1 [\u2032] [is replaced by] _[ \ud835\udc47]_ 2 [\u2032][, Pr][[] _[\u2113][\ud835\udc65]_ [1] [\u2265] _[\ud835\udc61]_ []][ does not decrease for all] _[ \ud835\udc61]_ [, so Pr][[] _[\u2113][\ud835\udc5f]_ [\u2265] _[\ud835\udc61]_ []][ does not decrease for all] _[ \ud835\udc61]_ [,]\nwhich means that _\ud835\udc47_ 1 \u2aaf _\ud835\udc47_ 2.\nNext, we prove the general case. Let _\ud835\udc63_ 0 _, \ud835\udc63_ 1 _, . . ., \ud835\udc63_ _\ud835\udc58_ ( _\ud835\udc63_ _\ud835\udc58_ = _\ud835\udc5f_ ) be a path from root( _\ud835\udc47_ 1 [\u2032][)][ to] _[ \ud835\udc5f]_ [, and let] _[\ud835\udc47][\ud835\udc56, \ud835\udc57]_ [be the]\nsubtree of _\ud835\udc63_ _\ud835\udc57_ in _\ud835\udc47\ud835\udc56_ . The assumption _\ud835\udc47_ 1 [\u2032] [\u2aaf] _[\ud835\udc47]_ 2 [\u2032] [means] _[ \ud835\udc47]_ [1] _[,\ud835\udc63]_ [0] [\u2aaf] _[\ud835\udc47]_ [2] _[,\ud835\udc63]_ [0][. Also, if] _[ \ud835\udc47]_ [1] _[,\ud835\udc63]_ _[\ud835\udc57]_ [\u2aaf] _[\ud835\udc47]_ [2] _[,\ud835\udc63]_ _[\ud835\udc57]_ [, then] _[ \ud835\udc47]_ [1] _[,\ud835\udc63]_ _[\ud835\udc57]_ [+][1] [\u2aaf] _[\ud835\udc47]_ [2] _[,\ud835\udc63]_ _[\ud835\udc57]_ [+][1][,]\nas shown above. Therefore, ( _\ud835\udc47_ 1 =) _\ud835\udc47_ 1 _,\ud835\udc63\ud835\udc58_ \u2aaf _\ud835\udc47_ 2 _,\ud835\udc63\ud835\udc58_ (= _\ud835\udc47_ 2) is shown by induction.\n\n_Proof of Lemma 5.3._ Let _\ud835\udc47_ 0 be a tree that E[ _\u2113_ root( _\ud835\udc47_ 0 ) ] takes the maximum value among all trees with _\ud835\udc5a_ leaves.\nIf _\ud835\udc47_ 0 has some vertex _\ud835\udc63_ that has one child or three or more children, we perform the following operation to\nmake a new tree _\ud835\udc47_ 1. Let _\ud835\udc5d_ be the parent of _\ud835\udc63_ (if it exists), and let _\ud835\udc65_ 1 _, . . ., \ud835\udc65\ud835\udc58_ be the children of _\ud835\udc63_ .\n\n  - Case _\ud835\udc58_ = 1: Delete vertex _\ud835\udc63_, and set the parent of _\ud835\udc65_ 1 to _\ud835\udc5d_ (if it exists). We define this operation as\n_contraction_ . See the left of Figure 17.\n\n  - Case _\ud835\udc58_ \u2265 3: Delete vertex _\ud835\udc63_, and instead create vertices _\ud835\udc64_ 1 _, . . ., \ud835\udc64_ _\ud835\udc58_ \u22121. Set the parents of _\ud835\udc65_ 1 and _\ud835\udc65_ 2 to\n_\ud835\udc64_ 1, and for _\ud835\udc57_ = 1 _, . . ., \ud835\udc58_ \u2212 2, set the parents of _\ud835\udc64_ _\ud835\udc57_ and _\ud835\udc65_ _\ud835\udc57_ +2 to _\ud835\udc64_ _\ud835\udc57_ +1, and finally set the parent of _\ud835\udc64_ _\ud835\udc58_ \u22121\nto _\ud835\udc5d_ (if it exists). See the right of Figure 17.\n\nWe prove that _\ud835\udc47_ 0 \u2aaf _\ud835\udc47_ 1 holds.\n\n  - Case _\ud835\udc58_ = 1: The operation is to replace _\ud835\udc47_ 0 [\u2032] [with] _[ \ud835\udc47]_ 1 [\u2032][, where] _[ \ud835\udc47]_ 0 [\u2032] [is the subtree of] _[ \ud835\udc63]_ [in] _[ \ud835\udc47]_ [0][, and] _[ \ud835\udc47]_ 1 [\u2032] [is the]\nsubtree of _\ud835\udc65_ 1 in _\ud835\udc47_ 1. Since _\ud835\udc63_ has one child, _\u2113\ud835\udc63_ = _\u2113\ud835\udc65_ 1 holds; therefore, _\ud835\udc47_ 0 [\u2032] [\u2aaf] _[\ud835\udc47]_ 1 [\u2032][. By][ Lemma 5.5][,] _[ \ud835\udc47]_ [0][ \u2aaf] _[\ud835\udc47]_ [1][.]\n\n  - Case _\ud835\udc58_ \u2265 3: The operation is to replace _\ud835\udc47_ 0 [\u2032] [with] _[ \ud835\udc47]_ 1 [\u2032][, where] _[ \ud835\udc47]_ 0 [\u2032] [is the subtree of] _[ \ud835\udc63]_ [in] _[ \ud835\udc47]_ [0][, and] _[ \ud835\udc47]_ 1 [\u2032] [is the]\nsubtree of _\ud835\udc64_ _\ud835\udc58_ \u22121 in _\ud835\udc47_ 1. Let _\u2113_ [\u2217] = max( _\u2113\ud835\udc65_ 1 _, . . ., \u2113\ud835\udc65\ud835\udc58_ ), and _\ud835\udc50_ = (number of _\ud835\udc57_ \u2019s that _\u2113\ud835\udc65_ _\ud835\udc57_ = _\u2113_ [\u2217] ). Then, in\n_\ud835\udc47_ 0, the probability that _\u2113\ud835\udc63_ = _\u2113_ [\u2217] is 2 [\u2212(] _[\ud835\udc50]_ [\u2212][1][)], and otherwise _\u2113\ud835\udc63_ = _\u2113_ [\u2217] + 1. However, in _\ud835\udc47_ 1, to become\n_\u2113\ud835\udc64\ud835\udc58_ \u22121 = _\u2113_ [\u2217], at least _\ud835\udc50_ \u2212 1 events that \u201ca vertex is leveled _\u2113_ [\u2217] from two level- _\u2113_ [\u2217] children\u201d must happen\ninside _\ud835\udc64_ 1 _, . . ., \ud835\udc64_ _\ud835\udc58_ \u22121. The scenario happens with probability 2 [\u2212(] _[\ud835\udc50]_ [\u2212][1][)] or less. Otherwise, _\u2113\ud835\udc64\ud835\udc58_ \u22121 becomes\n_\u2113_ [\u2217] + 1 or more. Therefore, _\ud835\udc47_ 0 [\u2032] [\u2aaf] _[\ud835\udc47]_ 1 [\u2032][. By][ Lemma 5.5][,] _[ \ud835\udc47]_ [0][ \u2aaf] _[\ud835\udc47]_ [1][.]\n\n32\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-34-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-34-2.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-34-3.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-34-0.png)\n\nFigure 17: The operations to modify a tree, for _\ud835\udc58_ = 1 case (left) and _\ud835\udc58_ \u2265 3 case (right)\n\nWe repeatedly perform the operations, starting from _\ud835\udc47_ 0, until the tree becomes a binary tree. Note that\nthe number of leaves remains unchanged by the operations. Let _\ud835\udc47_ be the resulting tree. By the transitivity of\n(T _,_ \u2aaf), _\ud835\udc47_ 0 \u2aaf _\ud835\udc47_ holds, which means that E[ _\u2113_ root( _\ud835\udc47_ 0 ) ] \u2264 E[ _\u2113_ root( _\ud835\udc47_ ) ]. By the maximality of _\ud835\udc47_ 0, the binary tree\n_\ud835\udc47_ is another tree that E[ _\u2113_ root( _\ud835\udc47_ ) ] takes the maximum value among all trees with _\ud835\udc5a_ leaves.\n\nNow, it is crucial to estimate the maximum value of E[ _\u2113_ root( _\ud835\udc47_ ) ] among all binary trees _\ud835\udc47_ with at most\n_\ud835\udc5a_ leaves; let this value be _\ud835\udc53_ ( _\ud835\udc5a_ ). Then, we know that the expected performance of RandomizedLST is\nupper-bounded by 2 _\ud835\udc53_ ( _\ud835\udc5b_ ) colors because _\ud835\udc5b_ \u2265 _\ud835\udc5a_ .\n\n**5.4** **Analysis 1: Considering the level-2 terminals**\n\nWe start analyzing the worst-case performance of RandomizedLST. Instead of directly analyzing the maximum value of E[ _\u2113_ root( _\ud835\udc47_ ) ], we examine how quickly the level-2 vertices appear in the worst case.\n\n**Definition 5.6.** _For \ud835\udc56_ \u2265 1 _, a vertex is a_ level- _\ud835\udc56_ terminal _if it has level \ud835\udc56_ _and both of its two children have level_\n_\ud835\udc56_ \u2212 1 _(or is a leaf if \ud835\udc56_ = 1 _)._\n\n|1<br>100%|1 2<br>1 1 1 1<br>50% 50%|Col3|1 2 2<br>1 1 1 1 2 1<br>1 1 1 1 1 1<br>25% 25% 50%|\n|---|---|---|---|\n|1<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>2<br>1<br>1<br>1<br>12.5%<br>12.5%<br>25%<br>50%|1<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>2<br>1<br>1<br>1<br>12.5%<br>12.5%<br>25%<br>50%|1<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>2<br>1<br>1<br>1<br>1<br>2<br>2<br>2<br>1<br>1<br>1<br>1<br>3<br>2<br>2<br>1<br>1<br>1<br>1<br>12.5%<br>12.5%<br>25%<br>25%<br>12.5%<br>12.5%|1<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>1<br>1<br>1<br>1<br>1<br>2<br>2<br>1<br>1<br>1<br>1<br>1<br>2<br>1<br>2<br>1<br>1<br>1<br>1<br>2<br>2<br>2<br>1<br>1<br>1<br>1<br>3<br>2<br>2<br>1<br>1<br>1<br>1<br>12.5%<br>12.5%<br>25%<br>25%<br>12.5%<br>12.5%|\n\nFigure 18: The outcomes of levels for all possible trees with four or fewer leaves (percentage\n= probability of the corresponding outcome, red vertices = level-2 terminals, yellow vertices =\nother level 2+ vertices). There are two binary trees with _\ud835\udc5a_ = 4 leaves, and the expected number\nof level-2 terminals are [7] [and] [9]\n\n[7] 8 [and] [9] 8\n\n8 [for the bottom-left and the bottom-right cases, respectively.]\n\n33\n\nLet _\ud835\udc4e\ud835\udc5a_ be the maximum possible expected number of level-2 terminals for a tree with exactly _\ud835\udc5a_ leaves.\nFor example, _\ud835\udc4e_ 1 = 0 _, \ud835\udc4e_ 2 = [1] 2 _[, \ud835\udc4e]_ [3][ =] [3] 4 [, and] _[ \ud835\udc4e]_ [4][ =] [9] 8 [, as in][ Figure 18][. The following lemma shows that these]\n\nvalues also navigate the number of level- _\ud835\udc56_ terminals for _\ud835\udc56_ \u2265 3.\n\n**Lemma 5.7.** _Let \ud835\udefe_ _be a real number that satisfies \ud835\udc4e\ud835\udc5a_ [\u2032] \u2264 _\ud835\udefe_ - _\ud835\udc5a_ [\u2032] _for all \ud835\udc5a_ [\u2032] \u2265 1 _. Then, the expected number of_\n_level-\ud835\udc56_ _terminals for any tree \ud835\udc47_ _with \ud835\udc5a_ _leaves is at most \ud835\udefe_ _[\ud835\udc56]_ [\u2212][1] - _\ud835\udc5a._\n\n_Proof._ Let _\ud835\udc4b\ud835\udc56_ be the number of level- _\ud835\udc56_ terminals. By the assumption, E[ _\ud835\udc4b_ 1] = _\ud835\udc5a_ . Let _\ud835\udc47\ud835\udc56_ be a subgraph\ninduced by the set of vertices with level _\ud835\udc56_ or higher. [17]\n\nWe show a relation between the number of leaves in _\ud835\udc47\ud835\udc56_ (which is equal to _\ud835\udc4b\ud835\udc56_ ) and the number of level( _\ud835\udc56_ + 1) terminals (which is equal to _\ud835\udc4b\ud835\udc56_ +1). For a vertex _\ud835\udc63_ that has one child in _\ud835\udc47\ud835\udc56_, the level of _\ud835\udc63_ is the same\nas the level of the only child because the level of \u201canother child\u201d in _\ud835\udc47_ is _\ud835\udc56_ \u2212 1 or less; therefore, contracting\nsuch a vertex _\ud835\udc63_ does not affect the analysis. After repeating the contraction, _\ud835\udc47\ud835\udc56_ becomes a binary tree with\n_\ud835\udc4b\ud835\udc56_ leaves, and the way that levels are assigned in this binary tree is identical to that of the normal binary tree\ncase, except that levels start from _\ud835\udc56_ . Therefore, the expected number of level-( _\ud835\udc56_ + 1) terminals is at most _\ud835\udc4e\ud835\udc4b\ud835\udc56_ .\nIt follows that E[ _\ud835\udc4b\ud835\udc56_ +1] \u2264 E[ _\ud835\udc4e\ud835\udc4b\ud835\udc56_ ] \u2264 _\ud835\udefe_ - E[ _\ud835\udc4b\ud835\udc56_ ]. By induction, E[ _\ud835\udc4b\ud835\udc56_ ] \u2264 _\ud835\udefe_ _[\ud835\udc56]_ [\u2212][1] - _\ud835\udc5a_ is shown.\n\nBy this lemma, we can upper-bound the expected level of the root vertex using _\ud835\udefe_ .\n\n**Lemma 5.8.** E[ _\u2113_ root( _\ud835\udc47_ ) ] \u2264 log(11/ _\ud835\udefe_ ) [\u00b7][ log] _[ \ud835\udc5a]_ [+] _[ \ud835\udc42]_ [(][1][)] _[.]_\n\n_Proof._ If the level of the root is _\ud835\udc56_ or higher, there exists at least one level- _\ud835\udc56_ terminal, so Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc56_ ] \u2264\nmin(E[ _\ud835\udc4b\ud835\udc56_ ] _,_ 1) \u2264 min( _\ud835\udefe_ _[\ud835\udc56]_ [\u2212][1] - _\ud835\udc5a,_ 1) (the last inequality is from Lemma 5.7). Therefore:\n\n[1] [3]\n\n2 _[, \ud835\udc4e]_ [3][ =] 4\n\n[3] [9]\n\n4 [, and] _[ \ud835\udc4e]_ [4][ =] 8\n\nE[ _\u2113_ root( _\ud835\udc47_ ) ] =\n\n\u2264\n\n\u221e\n\u2211\ufe01 Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc56_ ]\n\n_\ud835\udc56_ =1\n\n\u221e\n\u2211\ufe01 min( _\ud835\udefe_ _[\ud835\udc56]_ [\u2212][1] - _\ud835\udc5a,_ 1)\n\n_\ud835\udc56_ =1\n\n1 1\n\u2264 1 +\nlog(1/ _\ud835\udefe_ ) [\u00b7][ log] _[ \ud835\udc5a]_ [+] \ufffd 1 \u2212 _\ud835\udefe_\n\nwhich shows that E[ _\u2113_ root( _\ud835\udc47_ ) ] \u2264 log(11/ _\ud835\udefe_ ) [\u00b7][ log] _[ \ud835\udc5a]_ [+] _[ \ud835\udc42]_ [(][1][)][.]\n\nThe remaining work for this subsection is to estimate the value of _\ud835\udefe_ .\n\n**Theorem 5.9.** _The minimum possible value of \ud835\udefe_ _is given by the following:_\n\n\ufffd\n\n[1] [1]\n\n[+]\n2 [2] 2\n\n[1] [1]\n\n[+]\n2 [5] 2\n\n[1] [1]\n\n[+]\n2 [10] 2\n\n[+ \u00b7 \u00b7 \u00b7] _[ <]_ [ 0] _[.]_ [282229]\n2 [19]\n\n_\ud835\udefe_ =\n\n\u221e\n\u2211\ufe01\n\n\u2211\ufe01 2 [\u2212(][2] _[\ud835\udc56]_ [\u2212][1][+] _[\ud835\udc56]_ [)] = 2 [1]\n\n_\ud835\udc56_ =1\n\n_Proof._ For a binary tree _\ud835\udc47_, let _\ud835\udc4e_ ( _\ud835\udc47_ ) be the expected number of level-2 terminals. This can be calculated by:\n\n_\ud835\udc4e_ ( _\ud835\udc47_ ) = 2 [\u2212(] _[\ud835\udc60][\ud835\udc63]_ [\u2212][1][)]\n\u2211\ufe01\n\n_\ud835\udc63_ \u2208 _\ud835\udc49_ ( _\ud835\udc47_ )\n\nwhere _\ud835\udc60\ud835\udc63_ is the number of leaves in the subtree rooted at vertex _\ud835\udc63_ . This is because the probability for _\ud835\udc63_ to\nbecome a level-2 terminal is 2 [\u2212(] _[\ud835\udc60][\ud835\udc63]_ [\u2212][1][)] ; all non-leaf vertices of the subtree except _\ud835\udc63_ (there are _\ud835\udc60\ud835\udc63_ \u2212 2 such\nvertices) should be leveled 1 from two level-1 children, and _\ud835\udc63_ should be leveled 2 from two level-1 children.\nLet _\ud835\udc47_ be a tree that maximizes _\ud835\udc4e_ ( _\ud835\udc47_ ) among all trees with _\ud835\udc5a_ = 2 _[\ud835\udc58]_ leaves ( _\ud835\udc58_ \u2265 1). We say that two leaves\nare _paired_ if they share the parents. Suppose that there exist at least two _unpaired_ leaves, and let _\ud835\udc62_ 1 and _\ud835\udc62_ 2 be\ntwo of them (since 2 _[\ud835\udc58]_ is an even number, the number of unpaired leaves is always even.) Then, we perform\nthe following operations on _\ud835\udc47_ :\n\n17In Figure 18, _\ud835\udc47_ 2 corresponds to the subgraph with red/yellow vertices and yellow edges.\n\n34\n\n1. Delete _\ud835\udc62_ 1 and contract the parent _\ud835\udc5d_ of _\ud835\udc62_ 1. This operation decreases _\ud835\udc4e_ ( _\ud835\udc47_ ) by at most 2 [\u2212(][3][\u2212][1][)] = [1] 4\n\nbecause this deletes _\ud835\udc5d_, and since _\ud835\udc62_ 1 is unpaired, _\ud835\udc60_ _\ud835\udc5d_ \u2265 3 holds. (Figure 19 left to middle)\n\n2. Create two new vertices and set their parents to _\ud835\udc62_ 2. This operation increases _\ud835\udc4e_ ( _\ud835\udc47_ ) by at least [1]\n\n[1] [1]\n\n2 [\u2212(] 8\n\n_\ud835\udc62_ 2. This operation increases _\ud835\udc4e_ by at least 2 8 [+]\n\n161 [+] 32 [1] [+ \u00b7 \u00b7 \u00b7 +] 21 ~~_[\ud835\udc5a]_~~ [)][ =] [1] 4 [+] 21 ~~_[\ud835\udc5a]_~~ [because by this operation,] _[ \ud835\udc60][\ud835\udc62]_ [2] [becomes 2, and] _[ \ud835\udc60][\ud835\udc63]_ [for all ancestors of] _[ \ud835\udc62]_ [2]\n\n161 [+] 32 [1] [+ \u00b7 \u00b7 \u00b7 +] 21 ~~_[\ud835\udc5a]_~~ [)][ =] [1] 4 [+] 21 ~~_[\ud835\udc5a]_~~ [because by this operation,] _[ \ud835\udc60][\ud835\udc62]_ [2] [becomes 2, and] _[ \ud835\udc60][\ud835\udc63]_ [for all ancestors of] _[ \ud835\udc62]_ [2]\n\nincreases by 1. Note that, since _\ud835\udc62_ 2 is unpaired, _\ud835\udc60\ud835\udc63_ \u2265 3 holds for the parent of _\ud835\udc62_ 2. (Figure 19 middle to\nright)\n\n[1] 1 [1]\n\n32 [+ \u00b7 \u00b7 \u00b7 +] 2 ~~_[\ud835\udc5a]_~~ [)][ =] 4\n\nOverall, _\ud835\udc4e_ ( _\ud835\udc47_ ) increases by at least 21 ~~_[\ud835\udc5a]_~~ [, contradicting the maximality of] _[ \ud835\udc4e]_ [(] _[\ud835\udc47]_ [)][. Therefore, every leaf is paired]\nto make a subtree with two leaves.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-36-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-36-0.png)\n\n**(p is deleted)**\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-36-2.png)\n\nFigure 19: The sketch of operations.\n\nUsing the same argument, we can show inductively that every subtree with 2 _[\ud835\udc56]_ leaves must be paired, for\n_\ud835\udc56_ = 1 _,_ 2 _, . . ., \ud835\udc58_ \u2212 1. Therefore, _\ud835\udc47_ is a complete binary tree; a binary tree that all 2 _[\ud835\udc58]_ leaves are at depth _\ud835\udc58_ .\nCalculating _\ud835\udc4e_ ( _\ud835\udc47_ ) for the complete binary tree gives:\n\n_\ud835\udc58_\n\u2211\ufe01 2 [\u2212(][2] _[\ud835\udc56]_ [\u2212][1][+] _[\ud835\udc56]_ [)]\n\n_\ud835\udc56_ =1\n\n_\ud835\udc4e_ 2 _\ud835\udc58_ =\n\n_\ud835\udc58_\n\u2211\ufe01 2 [\u2212(][2] _[\ud835\udc56]_ [\u2212][1][)] - 2 _[\ud835\udc58]_ [\u2212] _[\ud835\udc56]_ = 2 _[\ud835\udc58]_ \n_\ud835\udc56_ =1\n\nbecause there are 2 _[\ud835\udc58]_ [\u2212] _[\ud835\udc56]_ vertices such that _\ud835\udc60\ud835\udc63_ = 2 _[\ud835\udc56]_ . It follows that _\ud835\udc4e_ 2 _\ud835\udc58_ \u2264 _\ud835\udefe_ - 2 _[\ud835\udc58]_ for _\ud835\udefe_ given in the statement, and\nthe given _\ud835\udefe_ is the minimum possible value.\nSuppose _\ud835\udc4e\ud835\udc5a_ _> \ud835\udefe_  - _\ud835\udc5a_ for some _\ud835\udc5a_ . Then, for a large enough _\ud835\udc58_, _\ud835\udc4e\ud835\udc5a_  - \u230a [2] _[\ud835\udc58]_ [\u230b] _[> \ud835\udefe]_ [\u00b7][ 2] _[\ud835\udc58]_ [holds. For such] _[ \ud835\udc58]_ [, we]\n\nSuppose _\ud835\udc4e\ud835\udc5a_ _> \ud835\udefe_  - _\ud835\udc5a_ for some _\ud835\udc5a_ . Then, for a large enough _\ud835\udc58_, _\ud835\udc4e\ud835\udc5a_  - \u230a [2] _\ud835\udc5a_ [\u230b] _[> \ud835\udefe]_ [\u00b7][ 2] _[\ud835\udc58]_ [holds. For such] _[ \ud835\udc58]_ [, we]\n\ncan make a binary tree _\ud835\udc47_ with 2 _[\ud835\udc58]_ leaves, which contains \u230a [2] _[\ud835\udc58]_ [\u230b] [subtrees with] _[ \ud835\udc5a]_ [leaves. This tree can satisfy]\n\ncan make a binary tree _\ud835\udc47_ with 2 leaves, which contains \u230a _\ud835\udc5a_ [\u230b] [subtrees with] _[ \ud835\udc5a]_ [leaves. This tree can satisfy]\n\n_\ud835\udc4e_ ( _\ud835\udc47_ ) _> \ud835\udefe_ - 2 _[\ud835\udc58]_, which is a contradiction to _\ud835\udc4e_ 2 _\ud835\udc58_ \u2264 _\ud835\udefe_ - 2 _[\ud835\udc58]_ . Therefore, _\ud835\udc4e\ud835\udc5a_ \u2264 _\ud835\udefe_ - _\ud835\udc5a_ for all _\ud835\udc5a_ .\n\nBy assigning this _\ud835\udefe_ to Lemma 5.8, we make partial progress to the main problem of this section.\n\n**Corollary 5.10.** _For any graph \ud835\udc3a, RandomizedLST uses at most_ 1 _._ 096 log _\ud835\udc5b_ + _\ud835\udc42_ (1) _colors in expectation._\n\n**5.5** **Analysis 2: Increasing the layers**\n\nIn this subsection, we further improve the upper bound. To this end, we analyze how quickly the level-( _\ud835\udc3f_ + 1)\nvertices appear in the worst case for a constant _\ud835\udc3f_ \u2265 2. Similar to the _\ud835\udc3f_ = 1 case, we consider the maximum\nexpected number of level-( _\ud835\udc3f_ + 1) terminals for a tree with _\ud835\udc5a_ leaves, _\ud835\udc4e\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [. Let] _[ \ud835\udefe]_ [(] _[\ud835\udc3f]_ [)][ be the minimum] _[ \ud835\udefe]_ [that]\n_\ud835\udc4e\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] \u2264 _\ud835\udefe_ - _\ud835\udc5a_ for every _\ud835\udc5a_ \u2265 1; for example, we have shown _\ud835\udefe_ [(][1][)] \u2248 0 _._ 282228 (see Theorem 5.9). We can show\nthe following generalization of Lemma 5.8.\n\n**Lemma 5.11.** E[ _\u2113_ root( _\ud835\udc47_ )] \u2264 log2 (1 _\ud835\udc3f_ / _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] ) [\u00b7][ log] _[ \ud835\udc5a]_ [+] _[ \ud835\udc42]_ [(][1][)] _[.]_\n\n_Proof._ We can prove this fact similarly to the proofs of Lemma 5.7 and Lemma 5.8.\n\n35\n\nEstimating the value of _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] is difficult for _\ud835\udc3f_ \u2265 2, so we try to obtain a good upper bound for _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] by\ncomputer check. Obviously, simple brute force is impossible because trees can be infinitely large. Instead,\nour idea is to sum up the performances of small enough subtrees. The following lemma demonstrates that\nthe results of small trees can be used to upper-bound the value of _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] :\n\n**Lemma 5.12.** _Let \ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] _be the maximum value of (expected number of level-_ ( _\ud835\udc3f_ + 1) _terminals) +_ Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2264\n_\ud835\udc3f_ ] _among all binary trees \ud835\udc47_ _with \ud835\udc5a_ _leaves. Then,_\n\n_\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] \u2264 max\n\n_\ud835\udc4f_ _\ud835\udc35_ [(] _[\ud835\udc3f]_ [)] _\ud835\udc4f_ 2 [(] _[\ud835\udc3f]_ _\ud835\udc35_ [)] \u22121\n_\ud835\udc35_ _[, . . .,]_ 2 _\ud835\udc35_ \u2212 1\n\ufffd\n\n\ufffd\n\n_holds for any \ud835\udc35_ \u2265 1 _._\n\n_Proof._ Consider any binary tree _\ud835\udc47_ . For explanation, we color vertex _\ud835\udc63_ red if _\ud835\udc60\ud835\udc63_ \u2265 _\ud835\udc35_ and _\ud835\udc60\ud835\udc65_ _< \ud835\udc35_ for\nall the children _\ud835\udc65_ (of _\ud835\udc63_ ). Note that as in the proof of Theorem 5.9, _\ud835\udc60\ud835\udc63_ is the number of leaves in the\nsubtree rooted at vertex _\ud835\udc63_ . For each red-colored vertex _\ud835\udc63_, let _\ud835\udc48\ud835\udc63_ = (the set of vertices in the subtree of _\ud835\udc63_ ) \u222a\n(the set of ancestors of _\ud835\udc63_ ). We claim that the expected number of level-( _\ud835\udc3f_ + 1) terminals in _\ud835\udc48\ud835\udc63_ is bounded\nby _\ud835\udc4f\ud835\udc60_ [(] _\ud835\udc63_ _[\ud835\udc3f]_ [)] [. Since there can be at most one level-][(] _[\ud835\udc3f]_ [+][ 1][)][ terminals in the ancestors of] _[ \ud835\udc63]_ [(only when] _[ \u2113]_ _\ud835\udc63_ [\u2264] _[\ud835\udc3f]_ [), the]\nclaim follows. Since _\ud835\udc35_ \u2264 _\ud835\udc60\ud835\udc63_ \u2264 2 _\ud835\udc35_ \u2212 1 and the subtrees of red vertices are disjoint, the expected number of\nlevel-( _\ud835\udc3f_ + 1) terminals in [\ufffd] _\ud835\udc63_ :red _[\ud835\udc48]_ _\ud835\udc63_ [is at most:]\n\nmax\n\n_\ud835\udc4f_ _\ud835\udc35_ [(] _[\ud835\udc3f]_ [)] _\ud835\udc4f_ 2 [(] _[\ud835\udc3f]_ _\ud835\udc35_ [)] \u22121\n_\ud835\udc35_ _[, . . .,]_ 2 _\ud835\udc35_ \u2212 1\n\ufffd\n\n\ufffd\n\n- _\ud835\udc60\ud835\udc63._\n\u2211\ufe01\n\n_\ud835\udc63_ :red\n\nSome vertices are in _\ud835\udc49_ ( _\ud835\udc47_ ) \\ [\ufffd] _\ud835\udc63_ :red _[\ud835\udc48]_ _\ud835\udc63_ [, but they are composed of subtrees with] _[ \ud835\udc35]_ [\u2212] [1 or fewer leaves. Thus,]\nthe expected number of level-( _\ud835\udc3f_ + 1) terminals in these vertices is at most:\n\n\ufffd\n\n\ufffd\n\nmax\n\n_\ud835\udc4e_ 1 [(] _[\ud835\udc3f]_ [)] _\ud835\udc4e_ _\ud835\udc35_ [(] _[\ud835\udc3f]_ \u2212 [)] 1\n\n1 _[, . . .,]_ _\ud835\udc35_ \u2212 1\n\n\ufffd\n\n_._\n\n\ufffd\n\n_\ud835\udc5a_ \u2212 _\ud835\udc60\ud835\udc63_\n\u2211\ufe01\n\n_\ud835\udc63_ :red\n\nOverall, the expected number of level-( _\ud835\udc3f_ + 1) terminals in _\ud835\udc47_ can be upper-bounded by\n\nmax\n\n_\ud835\udc4e_ 1 [(] _[\ud835\udc3f]_ [)] _\ud835\udc4e_ _\ud835\udc35_ [(] _[\ud835\udc3f]_ \u2212 [)] 1 _\ud835\udc4f_ _\ud835\udc35_ [(] _[\ud835\udc3f]_ [)] _\ud835\udc4f_ 2 [(] _[\ud835\udc3f]_ _\ud835\udc35_ [)] \u22121\n\n1 _[, . . .,]_ _\ud835\udc35_ \u2212 1 _[,]_ _\ud835\udc35_ _[, . . .,]_ 2 _\ud835\udc35_ \u2212 1\n\n\ufffd\n\n\ufffd\n\n - _\ud835\udc5a,_\n\nand since _\ud835\udc4e\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [/] _[\ud835\udc5a]_ [\u2264] _[\ud835\udefe]_ [(] _[\ud835\udc3f]_ [)] [, the statement of the lemma holds.]\n\nSo, how do we calculate _\ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [? Brute-forcing all binary trees to calculate] _[ \ud835\udc4f]_ _\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] is realistic only for _\ud835\udc5a_ \u2264 40,\neven using a computer check. Instead, we attempt to obtain a good upper bound for _\ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [. First, we use the]\nfollowing lemma as a tool.\n\n**Lemma 5.13.** _Let \ud835\udc5d\ud835\udc5a,\ud835\udc61_ _be the maximum value of_ Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc61_ ] _among all binary trees \ud835\udc47_ _with \ud835\udc5a_ _leaves._\n_Define \ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [(] _[\ud835\udc5a]_ [\u2265] [1] _[, \ud835\udc61]_ [\u2265] [1][)] _[ by the recurrence relation that][ \ud835\udc5d]_ [\u2032] _\ud835\udc5a,_ 1 [=][ 1] _[ and]_\n\n_\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [=] _\ud835\udc5a\ud835\udc59_ max+ _\ud835\udc5a\ud835\udc5f_ = _\ud835\udc5a_\n\n\ufffd1 \u2212(1 \u2212 _\ud835\udc5d_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ [)(][1][ \u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ [) +] 2 [1] [(] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ \u22121 [\u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ [)(] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ \u22121 [\u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ [)] \ufffd\n\n_for \ud835\udc5a_ \u2265 2 _. Then, \ud835\udc5d\ud835\udc5a,\ud835\udc61_ \u2264 _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ _[holds for all][ \ud835\udc5a, \ud835\udc61][.]_\n\n36\n\n_Proof._ Let _\ud835\udc63\ud835\udc59, \ud835\udc63\ud835\udc5f_ be the children of root( _\ud835\udc47_ ), and let _\ud835\udc5a\ud835\udc59, \ud835\udc5a\ud835\udc5f_ the number of leaves in subtree of _\ud835\udc63\ud835\udc59_ and _\ud835\udc63\ud835\udc5f_,\nrespectively. Here, the following equation holds:\n\nPr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc61_ ] = (1 \u2212 Pr[ _\u2113\ud835\udc63\ud835\udc59_ _< \ud835\udc61_ ] \u00b7 Pr[ _\u2113\ud835\udc63\ud835\udc5f_ _< \ud835\udc61_ ]) + [1]\n\n2 [\u00b7][ Pr][[] _[\u2113][\ud835\udc63][\ud835\udc59]_ [=] _[ \ud835\udc61]_ [\u2212] [1][] \u00b7][ Pr][[] _[\u2113][\ud835\udc63][\ud835\udc5f]_ [=] _[ \ud835\udc61]_ [\u2212] [1][]]\n\nThis is because, _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc61_ if exactly one of the following happens:\n\n  - Either _\u2113\ud835\udc63\ud835\udc59_ \u2265 _\ud835\udc61_ or _\u2113\ud835\udc63\ud835\udc5f_ \u2265 _\ud835\udc61_ (probability 1 \u2212 Pr[ _\u2113\ud835\udc63\ud835\udc59_ _< \ud835\udc61_ ] \u00b7 Pr[ _\u2113\ud835\udc63\ud835\udc5f_ _< \ud835\udc61_ ])\n\n   - _\u2113\ud835\udc63\ud835\udc59_ = _\u2113\ud835\udc63\ud835\udc5f_ = _\ud835\udc61_ \u2212 1 and _\u2113_ root( _\ud835\udc47_ ) = _\ud835\udc61_ (probability [1] 2 [\u00b7][ Pr][[] _[\u2113][\ud835\udc63][\ud835\udc59]_ [=] _[ \ud835\udc61]_ [\u2212] [1][] \u00b7][ Pr][[] _[\u2113][\ud835\udc63][\ud835\udc5f]_ [=] _[ \ud835\udc61]_ [\u2212] [1][]][)]\n\nBy Lemma 5.5, Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc61_ ] is a (non-strictly) increasing function with respect to Pr[ _\u2113\ud835\udc63\ud835\udc59_ \u2265 _\ud835\udc56_ ] and\nPr[ _\u2113\ud835\udc63\ud835\udc5f_ \u2265 _\ud835\udc56_ ] for each _\ud835\udc56_ \u2208 N. Since Pr[ _\u2113\ud835\udc63_ _< \ud835\udc61_ ] = 1 \u2212 Pr[ _\u2113\ud835\udc63_ \u2265 _\ud835\udc61_ ] and Pr[ _\u2113\ud835\udc63_ = _\ud835\udc61_ ] = Pr[ _\u2113\ud835\udc63_ \u2265 _\ud835\udc61_ \u2212 1] \u2212 Pr[ _\u2113\ud835\udc63_ \u2265 _\ud835\udc61_ ]\nhold for any vertex _\ud835\udc63_, the following holds:\n\nPr[ _\u2113_ root( _\ud835\udc47_ ) \u2265 _\ud835\udc61_ ] \u2264 \ufffd1 \u2212(1 \u2212 _\ud835\udc5d_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ [)(][1][ \u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ [)] \ufffd + 2 [1] [(] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ \u22121 [\u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc61_ [)(] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ \u22121 [\u2212] _[\ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc61_ [)]\n\nwhich gives an upper bound of _\ud835\udc5d\ud835\udc5a,\ud835\udc61_ . We note that _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [can be calculated in] _[ \ud835\udc42]_ [(] _[\ud835\udc5a]_ [2] _[\ud835\udc61]_ [)][ time.]\n\nNext, we show an alternative way to count the expected number of level- _\ud835\udc58_ terminals. Let _\ud835\udc5e\ud835\udc63_ = Pr[ _\u2113\ud835\udc63_ \u2265\n_\ud835\udc3f_ + 1]. Then, the probability that _\ud835\udc63_ is a level-( _\ud835\udc3f_ + 1) terminal is the following, where left( _\ud835\udc63_ ) _,_ right( _\ud835\udc63_ ) are\nchildren of _\ud835\udc63_ :\n_\ud835\udc5e\ud835\udc63_ \u2212(1 \u2212(1 \u2212 _\ud835\udc5e_ left( _\ud835\udc63_ ) )(1 \u2212 _\ud835\udc5e_ right( _\ud835\udc63_ ) ))\n\nThis is because _\ud835\udc63_ is a level- _\ud835\udc58_ terminal when _\ud835\udc63_ has level _\ud835\udc3f_ + 1 or more (probability _\ud835\udc5e\ud835\udc63_ ) but not \u201ceither left( _\ud835\udc63_ )\nor _\ud835\udc63\ud835\udc5f_ have level _\ud835\udc3f_ + 1 or more (probability 1 \u2212(1 \u2212 _\ud835\udc5e_ left( _\ud835\udc63_ ) )(1 \u2212 _\ud835\udc5e_ right( _\ud835\udc63_ ) ))\u201d. The number of level-( _\ud835\udc3f_ + 1)\nterminals in _\ud835\udc47_ is the sum of this value for all _\ud835\udc63_ \u2208 _\ud835\udc49_ ( _\ud835\udc47_ ).\nFor _\ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [, we considered (expected number of level-][(] _[\ud835\udc3f]_ [+][ 1][)][ terminals) + Pr][[] _[\u2113]_ root( _\ud835\udc47_ ) [\u2264] _[\ud835\udc3f]_ []][. The value of]\nPr[ _\u2113_ root( _\ud835\udc47_ ) \u2264 _\ud835\udc3f_ ] (= 1 \u2212 _\ud835\udc5e_ root( _\ud835\udc47_ ) ) is equal to the sum of\n\n\u2212 _\ud835\udc5e\ud835\udc63_ + _\ud835\udc5e_ left( _\ud835\udc63_ ) + _\ud835\udc5e_ right( _\ud835\udc63_ )\n\nacross all non-leaf vertex _\ud835\udc63_, plus 1. This is because _\ud835\udc5e\ud835\udc63_ = 0 when _\ud835\udc63_ is a leaf, and _\ud835\udc5e\ud835\udc63_ for all non-root, non-leaf\nvertices are canceled out, only \u2212 _\ud835\udc5e_ root( _\ud835\udc47_ ) to remain. Therefore:\n\n(expected number of level-( _\ud835\udc3f_ + 1) terminals) + Pr[ _\u2113_ root( _\ud835\udc47_ ) \u2264 _\ud835\udc3f_ ] = 1 + \u2211\ufe01 _\ud835\udc5e_ left( _\ud835\udc63_ ) _\ud835\udc5e_ right( _\ud835\udc63_ )\n\n_\ud835\udc63_ :non-leaf\n\nbecause ( _\ud835\udc5e\ud835\udc63_ \u2212(1 \u2212(1 \u2212 _\ud835\udc5e_ left( _\ud835\udc63_ ) )(1 \u2212 _\ud835\udc5e_ right( _\ud835\udc63_ ) ))) + (\u2212 _\ud835\udc5e\ud835\udc63_ + _\ud835\udc5e_ left( _\ud835\udc63_ ) + _\ud835\udc5e_ right( _\ud835\udc63_ ) ) = _\ud835\udc5e_ left( _\ud835\udc63_ ) _\ud835\udc5e_ right( _\ud835\udc63_ ) . So, we must\nestimate the maximum value of 1 + [\ufffd] _\ud835\udc63_ :non-leaf _[\ud835\udc5e]_ left( _\ud835\udc63_ ) _[\ud835\udc5e]_ right( _\ud835\udc63_ ) [.]\nHere, _\ud835\udc5e\ud835\udc63_ can be between 0 and _\ud835\udc5d_ [\u2032] _\ud835\udc60\ud835\udc63_ _,\ud835\udc3f_ +1 [, where] _[ \ud835\udc60][\ud835\udc63]_ [is the number of leaves in the subtree of] _[ \ud835\udc63]_ [. We consider]\nthe relaxed problem to maximize 1 + [\ufffd] _\ud835\udc63_ :non-leaf _[\ud835\udc5e]_ left( _\ud835\udc63_ ) _[\ud835\udc5e]_ right( _\ud835\udc63_ ) [under 0][ \u2264] _[\ud835\udc5e]_ _\ud835\udc63_ [\u2264] _[\ud835\udc5d]_ [\u2032] _\ud835\udc60\ud835\udc63_ _,\ud835\udc3f_ +1 [for all] _[ \ud835\udc63]_ [\u2208] _[\ud835\udc49]_ [(] _[\ud835\udc47]_ [)][. Let]\n\n_\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] be the maximum value for the relaxed problem among all tree _\ud835\udc47_ .\nIf the tree _\ud835\udc47_ is fixed, it is obvious that _\ud835\udc5e\ud835\udc63_ = _\ud835\udc5d_ [\u2032] _\ud835\udc60\ud835\udc63_ _,\ud835\udc3f_ +1 [is the optimal solution. Using this fact, the dynamic]\n\nprogramming formula for the optimal value _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] can be easily found:\n\n**Lemma 5.14.** _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] _satisfies the following recurrence relation:_\n\n_\ud835\udc4f_ 1 [\u2032(] _[\ud835\udc3f]_ [)] = 1 _,_ _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] = 1 + _\ud835\udc5a\ud835\udc59_ max+ _\ud835\udc5a\ud835\udc5f_ = _\ud835\udc5a_ [((] _[\ud835\udc4f]_ [\u2032(] _\ud835\udc5a\ud835\udc59_ _[\ud835\udc3f]_ [)] \u2212 1) + ( _\ud835\udc4f_ [\u2032(] _\ud835\udc5a\ud835\udc5f_ _[\ud835\udc3f]_ [)] \u2212 1) + _\ud835\udc5d_ [\u2032] _\ud835\udc5a\ud835\udc59_ _,\ud835\udc3f_ +1 [\u00b7] _[ \ud835\udc5d]_ [\u2032] _\ud835\udc5a\ud835\udc5f_ _,\ud835\udc3f_ +1 [)]\n\nWe note that _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] can be calculated in _\ud835\udc42_ ( _\ud835\udc5a_ [2] ) time. The calculated _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] is an upper bound for _\ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] [.]\nHence, assigning _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] to _\ud835\udc4f\ud835\udc5a_ [(] _[\ud835\udc3f]_ [)] in Lemma 5.12, we give an upper bound (or \u201cupper bound of upper bound\u201d)\nof _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)], leading to the better analysis for the number of colors in RandomizedLST.\n\n37\n\n**Tackling numerical errors.** In order to upper bound _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)], we must calculate _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [and] _[ \ud835\udc4f]_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] . Conventionally, these values are represented by floating-point numbers, but it may cause numerical errors and create a\nhole in the proof. It is ideal to calculate everything with integers. So, we _round up_ each calculation of _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_\nand _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] to a rational number of the form _\ud835\udc37_ _[\ud835\udc5b]_ [(] _[\ud835\udc5b]_ [\u2208] [Z][)][, where] _[ \ud835\udc37]_ [is a fixed integer parameter. When we run]\n\nthe dynamic programming program, the calculated _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [and] _[ \ud835\udc4f]_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] will not be lower than the actual _\ud835\udc5d_ [\u2032] _\ud835\udc5a,\ud835\udc61_ [and]\n_\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] . Therefore, we can calculate an upper bound of _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)], and becomes more precise when _\ud835\udc37_ is larger.\n\n**Results.** We computed _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] for _\ud835\udc3f_ = 1 _, . . .,_ 10 and _\ud835\udc5a_ \u2264 2 \u00b7 2 [22] + 1 with _\ud835\udc37_ = 2 [30] . We note that it is\nreasonable to set _\ud835\udc35_ = 2 _[\ud835\udc58]_ + 1 for some integer _\ud835\udc58_, because _\ud835\udc4f_ [\u2032(] _\ud835\udc5a_ _[\ud835\udc3f]_ [)] / _\ud835\udc5a_ tends to be especially large when _\ud835\udc5a_ is a\npower of two. The resulting upper bounds on the expected number of colors in RandomizedLST, is shown\nin Table 3.\n\nTable 3: Computed _\ud835\udefe_ [\u2032] = max( _\ud835\udc4f_ [\u2032(] _\ud835\udc35_ _[\ud835\udc3f]_ [)] / _\ud835\udc35, . . ., \ud835\udc4f_ 2 [\u2032(] _\ud835\udc35_ _[\ud835\udc3f]_ \u2212 [)] 1 [/(][2] _[\ud835\udc35]_ [\u2212] [1][))][ and the corresponding upper]\nbounds on the number of colors in RandomizedLST (divided by log _\ud835\udc5b_ ), rounded up to 6\ndecimal places\n\n|\ud835\udc3f|\ud835\udc35|\ud835\udefe\u2032|colors|\n|---|---|---|---|\n|1|2~~4 ~~+ 1|`2.822285e-1`|`1.095852`|\n|2|2~~6 ~~+ 1|`7.373281e-2`|`1.063392`|\n|3|2~~8 ~~+ 1|`1.912694e-2`|`1.051111`|\n|4|2~~10 ~~+ 1|`4.957865e-3`|`1.044924`|\n|5|2~~12 ~~+ 1|`1.284998e-3`|`1.041231`|\n\n|\ud835\udc3f|\ud835\udc35|\ud835\udefe\u2032|colors|\n|---|---|---|---|\n|6|2~~14 ~~+ 1|`3.330478e-4`|`1.038783`|\n|7|2~~16 ~~+ 1|`8.632023e-5`|`1.037042`|\n|8|2~~18 ~~+ 1|`2.237284e-5`|`1.035741`|\n|9|2~~20 ~~+ 1|`5.798723e-6`|`1.034731`|\n|10|2~~22 ~~+ 1|`1.502954e-6`|`1.033925`|\n\nNow, we obtain _\ud835\udefe_ [(][10][)] \u2264 1 _._ 502954 \u00d7 10 [\u2212][6] . Therefore, by Lemma 5.11, the following theorem holds:\n\n**Theorem 5.15.** _For any graph \ud835\udc3a, RandomizedLST uses at most_ 1 _._ 034 log _\ud835\udc5b_ + _\ud835\udc42_ (1) _colors in expectation._\n\n**Performance of RandomizedLST.** We estimate _\ud835\udefe_ [(] _[\ud835\udc3f]_ [)] for _\ud835\udc3f_ \u2264 10, but if we can further increase _\ud835\udc3f_, it\nwould improve the upper bound on the performance of RandomizedLST. It seems to us that the worst-case\ninput graph for RandomizedLST is a complete binary tree. In this case, the experiment with dynamic\nprogramming shows that it uses around 1 _._ 027 log _\ud835\udc5b_ colors. Therefore, we conjecture the following:\n\n**Conjecture 5.16.** _RandomizedLST uses at most_ 1 _._ 027 log _\ud835\udc5b_ + _\ud835\udc42_ (1) _colors for any bipartite graph \ud835\udc3a._\n\n**Computer check and programs.** The programs used for the analysis and their results in this section can\nbe downloaded at `[https://github.com/square1001/online-bipartite-coloring](https://github.com/square1001/online-bipartite-coloring)` .\n\n### **6 Lower bound of the expected performance for bipartite graphs**\n\n**6.1** **The lower bound instance**\n\nIn this section, we show the limit of randomized algorithms (against an oblivious adversary). We prove the\nfollowing theorem.\n\n**Theorem 6.1.** _Any randomized online coloring algorithm for bipartite graphs requires at least_ [91] 96 [log] _[ \ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)]\n\n_colors in expectation in the worst case._\n\n38\n\nBy Yao\u2019s lemma [24], the goal is to give a distribution of bipartite graphs that any _deterministic_ algorithm\nuses at least [91] 96 [log] _[ \ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors in expectation. We construct such input graphs as in][ Figure 20][, having]\n\nstructures similar to a binary tree. The grade- _\u210e_ instance, which is constructed by merging two disjoint\ngrade-( _\u210e_ \u2212 1) instances with two extra vertices, contains 4 \u00b7 2 _[\u210e]_ \u2212 2 vertices.\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-40-1.png)\n\n![](papers/images/Online-Graph-Coloring-for-kColorable-Graphs.pdf-40-0.png)\n\n**v0,0** **v0,1** **v1,0** **v1,1** **v1,2** **v1,3**\n\nGrade 0\nGrade 1\n\nGrade 2\n\nFigure 20: The instances to give a lower bound for _\u210e_ = 0 _,_ 1 _,_ 2. The orange, green, and\npurple regions correspond to grade-0, grade-1, and grade-2 graphs, respectively. The two\nextra vertices are in stripe. The labels of vertices can be changed, depending on the random\nchoice.\n\nWe formally explain how to construct the grade- _\ud835\udc58_ instance. The vertices are _\ud835\udc63\ud835\udc56, \ud835\udc57_ (0 \u2264 _\ud835\udc56_ \u2264 _\u210e,_ 0 \u2264 _\ud835\udc57<_\n2 _[\u210e]_ [\u2212] _[\ud835\udc56]_ [+][1] ). We refer to the phase that _\ud835\udc63\ud835\udc56,_ 0 _, . . ., \ud835\udc63\ud835\udc56,_ 2 _\u210e_ \u2212 _\ud835\udc56_ +1 \u22121 arrive as \u201cphase _\ud835\udc56_ \u201d. At phase _\ud835\udc56_, there are 2 _[\u210e]_ [\u2212] _[\ud835\udc56]_ [+][1]\n\ncomponents of grade-( _\ud835\udc56_ \u2212 1) graphs. For _\ud835\udc57_ = 0 _,_ 2 _, . . .,_ 2 _[\u210e]_ [\u2212] _[\ud835\udc56]_ [+][1] \u2212 2, we randomly select two of the remaining\ngrade-( _\ud835\udc56_ \u2212 1) components, and \u201cmerge\u201d them with two new vertices _\ud835\udc63\ud835\udc56, \ud835\udc57_ and _\ud835\udc63\ud835\udc56, \ud835\udc57_ +1. Then, after phase _\ud835\udc56_, there\nare 2 _[\u210e]_ [\u2212] _[\ud835\udc56]_ components of grade- _\ud835\udc56_ graphs.\nFormally, when we merge two connected components (say _\ud835\udc36_ 1 and _\ud835\udc36_ 2) with two new vertices (say _\ud835\udc63\ud835\udc4e_\nand _\ud835\udc63\ud835\udc4f_ ), for each vertex in _\ud835\udc36_ 1 and _\ud835\udc36_ 2, we add an edge between it and _either \ud835\udc63\ud835\udc4e_ or _\ud835\udc63\ud835\udc4f_ in a way that the\nresulting graph remains bipartite, and we also add an edge between _\ud835\udc63\ud835\udc4e_ and _\ud835\udc63\ud835\udc4f_ . There are four possible\nresulting graphs because we can choose which side of bipartition of _\ud835\udc36\ud835\udc56_ will be linked to _\ud835\udc63\ud835\udc4e_ (and to _\ud835\udc63\ud835\udc4f_ ),\nindependently for _\ud835\udc56_ = 1 _,_ 2. The four choices will be selected with probability [1] 4 [each. We denote this]\n\nprocedure as Merge( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ ), which returns the resulting component.\nThe goal is to prove the following result, which implies Theorem 6.1.\n\n**Theorem 6.2.** _Any deterministic online coloring algorithm requires at least expected_ [91] 96 _[\u210e]_ [\u2212] _[\ud835\udc42]_ [(][1][)] _[ colors for]_\n\n_the grade-\u210e_ _instance._\n\n**6.2** **Introducing potential**\n\nA classic idea to lower-bound the performance of algorithms is to define a value called the _potential_ for the\ncurrent state and say that the potential always increases by a certain amount in each operation.\nWe define the potential for each connected component _\ud835\udc36_ . Define the state of _\ud835\udc36_ to be ( _\ud835\udc4b,\ud835\udc4c_ ), where _\ud835\udc4b_\nand _\ud835\udc4c_ are the sets of colors used in each bipartition of _\ud835\udc36_ . Later, we may also use ( _\ud835\udc4b,\ud835\udc4c_ ) to represent _\ud835\udc36_ itself.\nWe consider the following potential _\ud835\udf19_ 1:\n\n_\ud835\udf19_ 1( _\ud835\udc36_ ) := [1]\n\n2 [(|] _[\ud835\udc4b]_ [| + |] _[\ud835\udc4c]_ [|)]\n\nWe will show that, for each phase, the average potential of the components will increase by at least [3]\n\nWe will show that, for each phase, the average potential of the components will increase by at least 4 [in]\n\nexpectation. Since | _\ud835\udc4b_ \u222a _\ud835\udc4c_ | \u2265 _\ud835\udf19_ 1( _\ud835\udc36_ ) always holds, this proves that the expected number of colors used for the\ngrade- _\u210e_ instance is at least [3] _[\u210e]_ [+][ 1. To this end, we first prove that] _[ \ud835\udc4b]_ [and] _[ \ud835\udc4c]_ [are not in the inclusion relation.]\n\n4 _[\u210e]_ [+][ 1. To this end, we first prove that] _[ \ud835\udc4b]_ [and] _[ \ud835\udc4c]_ [are not in the inclusion relation.]\n\n39\n\n**Lemma 6.3.** _Let \ud835\udc36_ 1 _and \ud835\udc36_ 2 _be two connected components, and let \ud835\udc36_ := _Merge_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ ) _. Then, the_\n_state_ ( _\ud835\udc4b,\ud835\udc4c_ ) _of \ud835\udc36_ _neither satisfies \ud835\udc4b_ \u2286 _\ud835\udc4c_ _nor \ud835\udc4c_ \u2286 _\ud835\udc4b._\n\n_Proof._ To this end, we will show that _\ud835\udc4b_ \u2286 _\ud835\udc4c_ is impossible. Let ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) be the state of _\ud835\udc36_ _before_ coloring _\ud835\udc63\ud835\udc4e_\nand _\ud835\udc63\ud835\udc4f_ (they are \u201cuncolored\u201d at this moment). Let _\ud835\udc50\ud835\udc4e_ and _\ud835\udc50\ud835\udc4f_ be the colors used for _\ud835\udc63\ud835\udc4e_ and _\ud835\udc63\ud835\udc4f_, respectively.\nWithout loss of generality, _\ud835\udc63\ud835\udc4e_ is adjacent to vertices with a color in _\ud835\udc4c_ 0. Thus, _\ud835\udc50\ud835\udc4e_ \u2209 _\ud835\udc4c_ 0. Since _\ud835\udc50\ud835\udc4e_ \u2260 _\ud835\udc50\ud835\udc4f_,\n_\ud835\udc50\ud835\udc4e_ \u2209 _\ud835\udc4c_ 0 \u222a{ _\ud835\udc50\ud835\udc4f_ } = _\ud835\udc4c_ . Therefore, _\ud835\udc4b_ = _\ud835\udc4b_ 0 \u222a{ _\ud835\udc50\ud835\udc4e_ } \u2288 _\ud835\udc4c_ . By symmetry, _\ud835\udc4c_ \u2286 _\ud835\udc4b_ is also impossible.\n\nThis lemma implies that, for the grade- _\u210e_ instance, the state ( _\ud835\udc4b,\ud835\udc4c_ ) of any component at any time neither\nsatisfies _\ud835\udc4b_ \u2286 _\ud835\udc4c_ nor _\ud835\udc4c_ \u2286 _\ud835\udc4b_ . Now, we start proving the [3] 4 [lower bound. It suffices to prove the following]\n\nlemma.\n\n**Lemma 6.4.** _Let \ud835\udc36_ 1 _and \ud835\udc36_ 2 _be two connected components, and let \ud835\udc36_ := _Merge_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ ) _. Then,_\nE[ _\ud835\udf19_ 1( _\ud835\udc36_ )] \u2265 [1] [(] _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [1][(] _[\ud835\udc36]_ [2][)) +] [3] _[when the state]_ [ (] _[\ud835\udc4b,\ud835\udc4c]_ [)] _[ for each][ \ud835\udc36][\ud835\udc56]_ _[neither satisfies][ \ud835\udc4b]_ [\u2286] _[\ud835\udc4c]_ _[nor][ \ud835\udc4c]_ [\u2286] _[\ud835\udc4b][.]_\n\n2 [1] [(] _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [1][(] _[\ud835\udc36]_ [2][)) +] [3] 4\n\n4 _[when the state]_ [ (] _[\ud835\udc4b,\ud835\udc4c]_ [)] _[ for each][ \ud835\udc36][\ud835\udc56]_ _[neither satisfies][ \ud835\udc4b]_ [\u2286] _[\ud835\udc4c]_ _[nor][ \ud835\udc4c]_ [\u2286] _[\ud835\udc4b][.]_\n\n_Proof._ Let ( _\ud835\udc4b_ 1 _,\ud835\udc4c_ 1) and ( _\ud835\udc4b_ 2 _,\ud835\udc4c_ 2) be the states of _\ud835\udc36_ 1 and _\ud835\udc36_ 2, respectively. Let ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) and ( _\ud835\udc4b,\ud835\udc4c_ ) be the states\nof _\ud835\udc36_ before and after coloring { _\ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ }, respectively. Here, ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) can be any of ( _\ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4c_ 2) _,_ ( _\ud835\udc4b_ 1 \u222a\n_\ud835\udc4c_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4b_ 2) _,_ ( _\ud835\udc4c_ 1 \u222a _\ud835\udc4c_ 2 _, \ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2) _,_ ( _\ud835\udc4c_ 1 \u222a _\ud835\udc4b_ 2 _, \ud835\udc4b_ 1 \u222a _\ud835\udc4c_ 2), with probability 4 [1] [each. We consider the following value]\n\n\u03940. Since _\ud835\udc4b_ 0 \u2286 _\ud835\udc4b_ and _\ud835\udc4c_ 0 \u2286 _\ud835\udc4c_, \u03940 gives a lower bound of E[ _\ud835\udf19_ 1( _\ud835\udc36_ )] \u2212 2 [1] [(] _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [1][(] _[\ud835\udc36]_ [2][))][.]\n\n[1] _\ud835\udf19_ 1(( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0)) = [1]\n\n2 [(] _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [1][(] _[\ud835\udc36]_ [2][))] 2\n\ufffd\n\n\u03940 := E [ _\ud835\udf19_ 1(( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0))] \u2212 [1]\n\n[1] (1)\n\n2 [(|] _[\ud835\udc4b]_ [0][| + |] _[\ud835\udc4c]_ [0][|)]\n\ufffd\n\nWe see how much each color _\ud835\udc50_ contributes to \u03940, for the first and the second terms of Equation 1.\nExcluding the symmetric patterns, there are six cases to consider, shown in Table 4:\n\n|Case|1stterm|2ndterm|\u0394<br>0|\n|---|---|---|---|\n|_\ud835\udc50_\u2209_\ud835\udc4b_1_,\ud835\udc4c_1_, \ud835\udc4b_2_,\ud835\udc4c_2<br>_\ud835\udc50_\u2208_\ud835\udc4b_1_, \ud835\udc50_\u2209_\ud835\udc4c_1_, \ud835\udc4b_2_,\ud835\udc4c_2<br>_\ud835\udc50_\u2208_\ud835\udc4b_1_, \ud835\udc4b_2_, \ud835\udc50_\u2209_\ud835\udc4c_1_,\ud835\udc4c_2<br>_\ud835\udc50_\u2208_\ud835\udc4b_1_,\ud835\udc4c_1_, \ud835\udc50_\u2209_\ud835\udc4b_2_,\ud835\udc4c_2<br>_\ud835\udc50_\u2208_\ud835\udc4b_1_,\ud835\udc4c_1_, \ud835\udc4b_2_, \ud835\udc50_\u2209_\ud835\udc4c_2<br>_\ud835\udc50_\u2208_\ud835\udc4b_1_,\ud835\udc4c_1_, \ud835\udc4b_2_,\ud835\udc4c_2|0<br>1/2<br>3/4<br>1<br>1<br>1|0<br>1/4<br>1/2<br>1/2<br>3/4<br>1|0<br>1/4<br>1/4<br>1/2<br>1/4<br>0|\n\nTable 4: For each case, contribution to the 1st and 2nd term of (1), along with their difference\n\nBy Lemma 6.3, | _\ud835\udc4b_ 1 \u2295 _\ud835\udc4c_ 1| \u2265 2 and | _\ud835\udc4b_ 2 \u2295 _\ud835\udc4c_ 2| \u2265 2, where _\ud835\udc4b\ud835\udc56_ \u2295 _\ud835\udc4c\ud835\udc56_ = ( _\ud835\udc4b\ud835\udc56_ \\ _\ud835\udc4c\ud835\udc56_ ) \u222a( _\ud835\udc4c\ud835\udc56_ \\ _\ud835\udc4b\ud835\udc56_ ) is the symmetric\ndifference of _\ud835\udc4b\ud835\udc56_ and _\ud835\udc4c\ud835\udc56_ . The 2nd, 3rd, and 5th patterns in Table 4 correspond to the case that _\ud835\udc50_ \u2208 _\ud835\udc4b\ud835\udc56_ \u2295 _\ud835\udc4c\ud835\udc56_ for\nan _\ud835\udc56_ \u2208{1 _,_ 2} (the 3rd pattern is double-counted); for each case, each element in _\ud835\udc4b\ud835\udc56_ \u2295 _\ud835\udc4c\ud835\udc56_ ( _\ud835\udc56_ = 1 _,_ 2) contributes\nto \u03940 by [1] 4 _[,]_ [1] 8 _[,]_ [1] 4 [, respectively. Therefore,][ \u0394][0][ \u2265] [4][ \u00d7] [1] 8 [=] [1] 2 [, and except for the case that \u201ctwo] _[ \ud835\udc50]_ [\u2019s are in the]\n\n3rd pattern and no _\ud835\udc50_ \u2019s are in the 2nd, 4th, and 5th patterns,\u201d \u03940 \u2265 [3] 4 [, which means that the expected average]\n\npotential increases by [3] 4 [. Note that there is no case that][ \u0394][0][ =] [1] 4 [+] [1] 8 [+] [1] 8 [+] [1] 8 [=] [5] 8 [because the number of \u201c] [1] 8 [\u201d]\n\nmust be even.\n\nThe only exceptional case is, without loss of generality, _\ud835\udc4b_ 1 = {1 _, . . ., \ud835\udc50, \ud835\udc50_ +1} _,\ud835\udc4c_ 1 = {1 _, . . ., \ud835\udc50, \ud835\udc50_ +2} _, \ud835\udc4b_ 2 =\n{1 _, . . ., \ud835\udc50, \ud835\udc50_ + 1} _,\ud835\udc4c_ 2 = {1 _, . . ., \ud835\udc50, \ud835\udc50_ + 2} for some _\ud835\udc50_ . In this case:\n\n[1] [1]\n\n4 _[,]_ 8\n\n[1] [1]\n\n8 _[,]_ 4\n\n[1] [1]\n\n4 [, respectively. Therefore,][ \u0394][0][ \u2265] [4][ \u00d7] 8\n\n[1] [1]\n\n8 [=] 2\n\n[3] [1]\n\n4 [. Note that there is no case that][ \u0394][0][ =] 4\n\n[1] [1]\n\n4 [+] 8\n\n[1] [1]\n\n8 [+] 8\n\n[1] [1]\n\n8 [+] 8\n\n[1] [5]\n\n8 [=] 8\n\n[5] 8 [because the number of \u201c] [1] 8\n\n- If ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) = ( _\ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4c_ 2), we can color _\ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ by color _\ud835\udc50_ + 1 _, \ud835\udc50_ + 2, respectively, and ( _\ud835\udc4b,\ud835\udc4c_ ) =\n({1 _, . . ., \ud835\udc50, \ud835\udc50_ + 1} _,_ {1 _, . . ., \ud835\udc50, \ud835\udc50_ + 2}). The average potential stays at _\ud835\udc50_ + 1.\n\n- If ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) = ( _\ud835\udc4b_ 1 \u222a _\ud835\udc4c_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4b_ 2), _\ud835\udc4b_ 0 = _\ud835\udc4c_ 0 = {1 _, . . ., \ud835\udc50_ + 2}, so we need two extra colors to color _\ud835\udc63\ud835\udc4e_ and\n_\ud835\udc63\ud835\udc4f_ . The average potential increases from _\ud835\udc50_ + 1 to _\ud835\udc50_ + 3.\n\n40\n\n  - The cases of ( _\ud835\udc4b_ 0 _,\ud835\udc4c_ 0) = ( _\ud835\udc4c_ 1 \u222a _\ud835\udc4c_ 2 _, \ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2) _,_ ( _\ud835\udc4c_ 1 \u222a _\ud835\udc4b_ 2 _, \ud835\udc4b_ 1 \u222a _\ud835\udc4c_ 2) are symmetric to the first and the second\ncases, respectively.\n\nTherefore, the expected average potential increases by 1 in this case.\n\n**6.3** **Two-phase analysis**\n\nIn the previous subsection, we showed that any randomized algorithm requires at least [3]\n\n[3]\n\n4 [log] _[ \ud835\udc5b]_ [\u2212] [1] 2\n\nIn the previous subsection, we showed that any randomized algorithm requires at least 4 [log] _[ \ud835\udc5b]_ [\u2212] 2 [colors, using]\n\npotential _\ud835\udf19_ 1. Unfortunately, this is the best possible potential among functions of | _\ud835\udc4b_ \u2229 _\ud835\udc4c_ | _,_ | _\ud835\udc4b_ \\ _\ud835\udc4c_ | _,_ | _\ud835\udc4c_ \\ _\ud835\udc4b_ |. In\norder to improve the lower bound, we need to develop more sophisticated analysis methods.\nIn this subsection, we see how much the expected average potential of the components increases in two\nphases. We consider the model with four connected components, _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4. Two pairs of components\nare merged in the first phase, and the two \u201cmerged\u201d components are merged in the second phase. There are essentially 3 \u00d7 2 \u00d7 2 [3] = 48 outcomes, considering how components are paired (3 ways) and are merged in which\n\n=\norder (2 ways), along with how merges happen (2 [3] 8 ways, because 3 merges happen). [18] The \u201cplayer\u201d (algorithm) must decide the color of two added vertices right after every merge. Therefore, the minimum expected\nincrease in potential _\ud835\udf19_ when the player plays optimally, denoted by PotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ ),\ncan be computed in the expected minimax algorithm (Algorithm 8). The complex nature of this procedure\nmakes it more difficult to create cases with low increases in potential.\nWe introduce the following potential _\ud835\udf19_ 2, which slightly modifies _\ud835\udf19_ 1. [19] The goal is to prove Lemma 6.5,\nwhich directly leads to a lower bound of [89] _[\u210e]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors.]\n\n96 _[\u210e]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors.]\n\n_\ud835\udf19_ 2( _\ud835\udc36_ ) = | _\ud835\udc4b_ \u2229 _\ud835\udc4c_ | + [11]\n\n21 [|] _[\ud835\udc4b]_ [\u2295] _[\ud835\udc4c]_ [|]\n\n**Lemma 6.5.** _PotentialIncrease_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ 2) \u2265 48 [89] _[for any components][ \ud835\udc36]_ [1] _[, \ud835\udc36]_ [2] _[, \ud835\udc36]_ [3] _[, \ud835\udc36]_ [4] _[ where state]_\n\n( _\ud835\udc4b,\ud835\udc4c_ ) _neither satisfies \ud835\udc4b_ \u2286 _\ud835\udc4c_ _nor \ud835\udc4c_ \u2286 _\ud835\udc4b._\n\n_Proof._ This lemma can be shown by a computer search. First, we need to make the number of candidates for the combination of states of _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 computable (or at least finite). With all the ideas\nexplained in the next subsection, we reduce the number of combinations to consider to 16829. We compute\nPotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ 2) for all of them, and each call returned a result of 48 [89] [or more.]\n\n**Remarks on Algorithm 8.** When brute-forcing colors ( _\ud835\udc50\ud835\udc4e_ [(] _[\ud835\udc56]_ [)] _[, \ud835\udc50]_ _\ud835\udc4f_ [(] _[\ud835\udc56]_ [)] [) (] _[\ud835\udc56]_ [=][ 1] _[,]_ [ 2] _[,]_ [ 3][)][ in][ Algorithm 8][, we may]\nassume that we do not \u201cjump\u201d the colors; when there are only colors 1 _, . . ., \ud835\udc50_ in the current graph, we only\ncolor the next vertex using any of color 1 _, . . ., \ud835\udc50_ + 1. This makes the number of search states finite. Also,\nwhen _\ud835\udc4b\ud835\udc56_ +4 \\ _\ud835\udc4c\ud835\udc56_ +4 is not empty, it is obvious that choosing _\ud835\udc50\ud835\udc4e_ [(] _[\ud835\udc56]_ [)] [from] _[ \ud835\udc4b]_ _\ud835\udc56_ +4 [\\] _[\ud835\udc4c]_ _\ud835\udc56_ +4 [is an optimal strategy (then, it]\nbecomes _\ud835\udc4b_ [\u2032]\n_\ud835\udc56_ +4 [=] _[ \ud835\udc4b][\ud835\udc56]_ [+][4][). Similarly, when] _[ \ud835\udc4c][\ud835\udc56]_ [+][4][ \\] _[ \ud835\udc4b][\ud835\udc56]_ [+][4][ is not empty, it is optimal to choose] _[ \ud835\udc50]_ _\ud835\udc4f_ [(] _[\ud835\udc56]_ [)] [from] _[ \ud835\udc4c][\ud835\udc56]_ [+][4][ \\] _[ \ud835\udc4b][\ud835\udc56]_ [+][4][.]\nThen, we can further reduce the number of possibilities to consider.\n\n**6.4** **Further improvement: Limiting the number of combinations**\n\nIn this subsection, we complete the proof of Lemma 6.5; indeed, we explain how to enumerate all candidates\nof combinations of states of _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 such that PotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ 2) is less than 48 [89] [,]\n\nusing a computer search.\n\n18When merging components with states ( _\ud835\udc4b_ 1 _,\ud835\udc4c_ 1) and ( _\ud835\udc4b_ 2 _,\ud835\udc4c_ 2), there are essentially two possible resulting states: ( _\ud835\udc4b_ 1 \u222a _\ud835\udc4b_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4c_ 2)\nand ( _\ud835\udc4b_ 1 \u222a _\ud835\udc4c_ 2 _,\ud835\udc4c_ 1 \u222a _\ud835\udc4b_ 2), as we can regard ( _\ud835\udc4b,\ud835\udc4c_ ) and ( _\ud835\udc4c, \ud835\udc4b_ ) as the same states.\n19Even with _\ud835\udf19_ 1, we can prove the lower bound of 59 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][, which is only slightly worse than] [89] [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][.]\n\n5964 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][, which is only slightly worse than] 96 [89]\n\n96 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][.]\n\n41\n\n**Algorithm 8** PotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ )\n\n1: _\ud835\udc65_ \u2190 0\n\n2: **for all** ( _\ud835\udc36_ 1 [\u2032] _[, \ud835\udc36]_ 2 [\u2032] _[, \ud835\udc36]_ 3 [\u2032] _[, \ud835\udc36]_ 4 [\u2032][)][, a permutation of][ (] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2] _[, \ud835\udc36]_ [3] _[, \ud835\udc36]_ [4][)][, that] _[ \ud835\udc36]_ 1 [\u2032] [and] _[ \ud835\udc36]_ 2 [\u2032] [are merged first and] _[ \ud835\udc36]_ 3 [\u2032] [and] _[ \ud835\udc36]_ 4 [\u2032]\nare merged second (there are 3 \u00d7 2 = 6 ways) **do**\n\n3: Let ( _\ud835\udc4b\ud835\udc56_ [\u2032] _[,\ud835\udc4c]_ _\ud835\udc56_ [\u2032][)][ be the state of] _[ \ud835\udc36]_ _\ud835\udc56_ [\u2032] [for] _[ \ud835\udc56]_ [=][ 1] _[,]_ [ 2] _[,]_ [ 3] _[,]_ [ 4]\n\n4: _\ud835\udc4e_ 0 \u2190 0\n\n5: **for** ( _\ud835\udc4b_ 5 _,\ud835\udc4c_ 5) = ( _\ud835\udc4b_ 1 [\u2032] [\u222a] _[\ud835\udc4b]_ 2 [\u2032] _[,\ud835\udc4c]_ 1 [\u2032] [\u222a] _[\ud835\udc4c]_ 2 [\u2032][)] _[,]_ [ (] _[\ud835\udc4b]_ 1 [\u2032] [\u222a] _[\ud835\udc4c]_ 2 [\u2032] _[,\ud835\udc4c]_ 1 [\u2032] [\u222a] _[\ud835\udc4b]_ 2 [\u2032][)] **[ do]**\n\n6: _\ud835\udc4f_ 0 \u2190+\u221e\n\n7: **for all** ( _\ud835\udc50\ud835\udc4e_ [(][1][)] _[, \ud835\udc50]_ _\ud835\udc4f_ [(][1][)] [)][, the colors of two extra vertices when merging] _[ \ud835\udc36]_ 1 [\u2032] [and] _[ \ud835\udc36]_ 2 [\u2032] **[do]**\n\n8: ( _\ud835\udc4b_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][) \u2190(] _[\ud835\udc4b]_ [5][ \u222a{] _[\ud835\udc50]_ _\ud835\udc4e_ [(][1][)] [}] _[,\ud835\udc4c]_ 5 [\u222a{] _[\ud835\udc50]_ _\ud835\udc4f_ [(][1][)] [})]\n\n9: _\ud835\udc4e_ 1 \u2190 0\n\n10: **for** ( _\ud835\udc4b_ 6 _,\ud835\udc4c_ 6) = ( _\ud835\udc4b_ 3 [\u2032] [\u222a] _[\ud835\udc4b]_ 4 [\u2032] _[,\ud835\udc4c]_ 3 [\u2032] [\u222a] _[\ud835\udc4c]_ 4 [\u2032][)] _[,]_ [ (] _[\ud835\udc4b]_ 3 [\u2032] [\u222a] _[\ud835\udc4c]_ 4 [\u2032] _[,\ud835\udc4c]_ 3 [\u2032] [\u222a] _[\ud835\udc4b]_ 4 [\u2032][)] **[ do]**\n\n11: _\ud835\udc4f_ 1 \u2190+\u221e\n\n12: **for all** ( _\ud835\udc50\ud835\udc4e_ [(][2][)] _[, \ud835\udc50]_ _\ud835\udc4f_ [(][2][)] [)][, the colors of two extra vertices when merging] _[ \ud835\udc36]_ 3 [\u2032] [and] _[ \ud835\udc36]_ 4 [\u2032] **[do]**\n\n13: ( _\ud835\udc4b_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][) \u2190(] _[\ud835\udc4b]_ [6][ \u222a{] _[\ud835\udc50]_ _\ud835\udc4e_ [(][2][)] [}] _[,\ud835\udc4c]_ 6 [\u222a{] _[\ud835\udc50]_ _\ud835\udc4f_ [(][2][)] [})]\n\n14: _\ud835\udc4e_ 2 \u2190 0\n\n15: **for** ( _\ud835\udc4b_ 7 _,\ud835\udc4c_ 7) = ( _\ud835\udc4b_ 5 [\u2032] [\u222a] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032] [\u222a] _[\ud835\udc4c]_ 6 [\u2032][)] _[,]_ [ (] _[\ud835\udc4b]_ 5 [\u2032] [\u222a] _[\ud835\udc4c]_ 6 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032] [\u222a] _[\ud835\udc4b]_ 6 [\u2032][)] **[ do]**\n\n16: _\ud835\udc4f_ 2 \u2190+\u221e\n\n17: **for all** ( _\ud835\udc50\ud835\udc4e_ [(][3][)] _[, \ud835\udc50]_ _\ud835\udc4f_ [(][3][)] [)][, the colors of two extra vertices in the final merge] **[ do]**\n\n18: ( _\ud835\udc4b_ 7 [\u2032] _[,\ud835\udc4c]_ 7 [\u2032][) \u2190(] _[\ud835\udc4b]_ [7][ \u222a{] _[\ud835\udc50]_ _\ud835\udc4e_ [(][3][)] [}] _[,\ud835\udc4c]_ 7 [\u222a{] _[\ud835\udc50]_ _\ud835\udc4f_ [(][3][)] [})]\n\n19: \u0394 \u2190 _\ud835\udf19_ (( _\ud835\udc4b_ 7 [\u2032] _[,\ud835\udc4c]_ 7 [\u2032][)) \u2212] 4 [1] [(] _[\ud835\udf19]_ [(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [(] _[\ud835\udc36]_ [2][) +] _[ \ud835\udf19]_ [(] _[\ud835\udc36]_ [3][) +] _[ \ud835\udf19]_ [(] _[\ud835\udc36]_ [4][))]\n\n20: _\ud835\udc4f_ 2 \u2190 min( _\ud835\udc4f_ 2 _,_ \u0394)\n\n21: _\ud835\udc4e_ 2 \u2190 _\ud835\udc4e_ 2 + 2 [1] _[\ud835\udc4f]_ [2]\n\n22: _\ud835\udc4f_ 1 \u2190 min( _\ud835\udc4f_ 1 _, \ud835\udc4e_ 2)\n\n23: _\ud835\udc4e_ 1 \u2190 _\ud835\udc4e_ 1 + [1] 2 _[\ud835\udc4f]_ [1]\n\n24: _\ud835\udc4f_ 0 \u2190 min( _\ud835\udc4f_ 0 _, \ud835\udc4e_ 1)\n\n25: _\ud835\udc4e_ 0 \u2190 _\ud835\udc4e_ 0 + 2 [1] _[\ud835\udc4f]_ [0]\n\n26: _\ud835\udc65_ \u2190 _\ud835\udc65_ + [1]\n\n6 _[\ud835\udc4e]_ [0]\n\n27: **return** _\ud835\udc65_\n\n**The searching framework.** The following lemma, the \u201cpotential _\ud835\udf19_ 2 version\u201d of Lemma 6.4, shows that _\ud835\udf19_ 2\nalways increases by [31] 42 [in the second phase.]\n\n**Lemma 6.6.** _Let_ _\ud835\udc36_ 1 _and_ _\ud835\udc36_ 2 _be connected components, and let_ _\ud835\udc36_ := _Merge_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc63\ud835\udc4e, \ud835\udc63\ud835\udc4f_ ) _. Then,_ E[ _\ud835\udf19_ 2( _\ud835\udc36_ )] \u2265\n1 [31]\n2 [(] _[\ud835\udf19]_ [2][(] _[\ud835\udc36]_ [1][) +] _[ \ud835\udf19]_ [2][(] _[\ud835\udc36]_ [2][)) +] 42 _[holds when the state]_ [ (] _[\ud835\udc4b,\ud835\udc4c]_ [)] _[ for each][ \ud835\udc36][\ud835\udc56]_ _[neither satisfies][ \ud835\udc4b]_ [\u2286] _[\ud835\udc4c]_ _[nor][ \ud835\udc4c]_ [\u2286] _[\ud835\udc4b][.]_\n\nWe can prove this lemma similarly to Lemma 6.4, but we can also prove by running Algorithm 9 (by\ncalling _\ud835\udc54_ ((\u2205 _,_ \u2205) _,_ (\u2205 _,_ \u2205)), which will be explained later). Therefore, it suffices to search all the cases where,\nin the first phase, the expected average potential increases by less than [89] [\u2212] [31] [=] [125] [. Let] _[ \ud835\udc53]_ [(] _[\ud835\udc36][\ud835\udc56][, \ud835\udc36]_ _[\ud835\udc57]_ [)][ be the]\n\n[31] [125]\n\n42 [=] 112\n\n[89]\n\n48 [\u2212] [31] 42\n\nin the first phase, the expected average potential increases by less than 48 [\u2212] 42 [=] 112 [. Let] _[ \ud835\udc53]_ [(] _[\ud835\udc36][\ud835\udc56][, \ud835\udc36]_ _[\ud835\udc57]_ [)][ be the]\n\nexpected increase of a potential _\ud835\udf19_ 2 by merging components _\ud835\udc36\ud835\udc56_ and _\ud835\udc36_ _\ud835\udc57_ . We enumerate all the cases such that:\n\n[1] [125]\n\n6 [(] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][) +] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [3][) +] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [4][) +] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [2] _[, \ud835\udc36]_ [3][) +] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [2] _[, \ud835\udc36]_ [4][) +] _[ \ud835\udc53]_ [(] _[\ud835\udc36]_ [3] _[, \ud835\udc36]_ [4][))] _[ <]_ 112\n\n\u03941 = [1]\n\n112\n\n**Implementation and the state matrix.** In order to implement the brute force of the cases such that\n\u03941 _<_ [125] 112 [, we define] _[ state matrix][ \ud835\udc40]_ [to represent][ (] _[\ud835\udc4b][\ud835\udc56][,\ud835\udc4c][\ud835\udc56]_ [)][, the state of] _[ \ud835\udc36][\ud835\udc56]_ [, for] _[ \ud835\udc56]_ [=][ 1] _[,]_ [ 2] _[,]_ [ 3] _[,]_ [ 4.] _[ \ud835\udc40]_ [is a 4][ \u00d7] _[ \ud835\udc5a]_ [matrix]\n\n42\n\nwhere _\ud835\udc5a_ is the number of colors, defined in the following way.\n\n_\ud835\udc40_ =\n_\ud835\udc56, \ud835\udc57_\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n0 ( _\ud835\udc57_ \u2209 _\ud835\udc4b\ud835\udc56,\ud835\udc4c\ud835\udc56_ )\n\n1 ( _\ud835\udc57_ \u2208 _\ud835\udc4b\ud835\udc56, \ud835\udc57_ \u2209 _\ud835\udc4c\ud835\udc56_ )\n\n2 ( _\ud835\udc57_ \u2208 _\ud835\udc4c\ud835\udc56, \ud835\udc57_ \u2209 _\ud835\udc4b\ud835\udc56_ )\n\n3 ( _\ud835\udc57_ \u2208 _\ud835\udc4b\ud835\udc56,\ud835\udc4c\ud835\udc56_ )\n\nHere, we can assume that each column is not \u201call 0\u201d or \u201call 3\u201d (so there are 254 _[\ud835\udc5a]_ matrices with _\ud835\udc5a_ columns).\nThis is because if a color is in none or all of _\ud835\udc4b_ 1 _,\ud835\udc4c_ 1 _, . . ., \ud835\udc4b_ 4 _,\ud835\udc4c_ 4, there is no effect on the increase of potential.\nWe attempt to brute-force these matrices by DFS (depth-first search), which appends one column to the right\nin each step (corresponds to adding a new color).\n\n**Lower-bounding for the DFS.** In order to execute the DFS in a finite and realistic time, we need to apply\n\u201cpruning\u201d by showing that, for the current state matrix, it is impossible to achieve \u03941 _<_ 112 [125] [no matter how]\n\nsubsequent columns are appended.\nLet _\ud835\udc54_ ( _\ud835\udc36\ud835\udc56, \ud835\udc36_ _\ud835\udc57_ ) be the minimum value of _\ud835\udc53_ ( _\ud835\udc36\ud835\udc56, \ud835\udc36_ _\ud835\udc57_ ) when we can freely add subsequent colors to ( _\ud835\udc4b\ud835\udc56,\ud835\udc4c\ud835\udc56_ )\nand ( _\ud835\udc4b_ _\ud835\udc57,\ud835\udc4c_ _\ud835\udc57_ ). Then, LB := [1] 6 [(] _[\ud835\udc54]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][) +] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [3][) +] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [4][) +] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [2] _[, \ud835\udc36]_ [3][) +] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [2] _[, \ud835\udc36]_ [4][) +] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [3] _[, \ud835\udc36]_ [4][))][ gives]\n\nthe lower bound of \u03941 for any subsequent state matrices. Therefore, once LB \u2265 [125] 112 [is met, we do not]\n\nneed to perform the DFS for subsequent columns and can apply pruning. We can compute _\ud835\udc54_ ( _\ud835\udc36\ud835\udc56, \ud835\udc36_ _\ud835\udc57_ ) using\nAlgorithm 9, which is given by LowerBound( _\ud835\udc36\ud835\udc56, \ud835\udc36_ _\ud835\udc57, \ud835\udc5a,_ +\u221e).\n\n**Algorithm 9** LowerBound( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc5a, \ud835\udefd_ ): Function to calculate the minimum value of _\ud835\udc53_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2) when\ncolors _\ud835\udc5a_ + 1 _, \ud835\udc5a_ + 2 _, . . ._ are added, or report that the minimum value is _\ud835\udefd_ or more\n\n1: _\ud835\udc51_ 0 \u2190 (the value of \u03940 defined in Lemma 6.4 (for potential _\ud835\udf19_ 2) for the current _\ud835\udc36_ 1 _, \ud835\udc36_ 2)\n\n2: **if** _\ud835\udc51_ 0 \u2265 _\ud835\udefd_ **then**\n\n3: **return** _\ud835\udefd_ _\u22b2\ud835\udc53_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2) \u2265 _\ud835\udefd_ no matter how subsequent colors are added\n\n4: ( _\ud835\udc4b_ 1 [\u2217] _[,\ud835\udc4c]_ 1 [\u2217][)] _[,]_ [ (] _[\ud835\udc4b]_ 2 [\u2217] _[,\ud835\udc4c]_ 2 [\u2217][) \u2190] [(states of components which adds minimum possible subsequent colors into] _[ \ud835\udc36]_ [1] _[, \ud835\udc36]_ [2]\nto make it satisfy _\ud835\udc4b_ 1 \u2288 _\ud835\udc4c_ 1 _,\ud835\udc4c_ 1 \u2288 _\ud835\udc4b_ 1 _, \ud835\udc4b_ 2 \u2288 _\ud835\udc4c_ 2 _,\ud835\udc4c_ 2 \u2288 _\ud835\udc4b_ 2)\n\n5: _\ud835\udefd_ \u2190 min( _\ud835\udefd, \ud835\udc53_ (( _\ud835\udc4b_ 1 [\u2217] _[,\ud835\udc4c]_ 1 [\u2217][)] _[,]_ [ (] _[\ud835\udc4b]_ 2 [\u2217] _[,\ud835\udc4c]_ 2 [\u2217][)))]\n\n6: **for all** ( _\ud835\udc4b_ 1 [\u2032] _[,\ud835\udc4c]_ 1 [\u2032][)] _[,]_ [ (] _[\ud835\udc4b]_ 2 [\u2032] _[,\ud835\udc4c]_ 2 [\u2032][)][, the states of] _[ \ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][ after adding color] _[ \ud835\udc5a]_ [+][ 1 (there are 2][4][ \u2212] [2][ =][ 14 ways)] **[ do]**\n\n7: _\ud835\udc51_ \u2190 LowerBound(( _\ud835\udc4b_ 1 [\u2032] _[,\ud835\udc4c]_ 1 [\u2032][)] _[,]_ [ (] _[\ud835\udc4b]_ 2 [\u2032] _[,\ud835\udc4c]_ 2 [\u2032][)] _[, \ud835\udc5a]_ [+][ 1] _[, \ud835\udefd]_ [)]\n\n8: _\ud835\udefd_ \u2190 min( _\ud835\udefd, \ud835\udc51_ )\n\n9: **return** _\ud835\udefd_\n\n**Remarks on Algorithm 9.** The idea of this algorithm is that \u03940 defined in Lemma 6.4 not only gives a\nlower bound to _\ud835\udc53_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2); no matter how subsequent colors are added to ( _\ud835\udc4b_ 1 _,\ud835\udc4c_ 1) and ( _\ud835\udc4b_ 2 _,\ud835\udc4c_ 2), _\ud835\udc53_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2)\nwill not be lower than \u03940. To compute _\ud835\udc54_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2), we search all possibilities on subsequent colors by DFS,\nbut once \u03940 exceeds or equals to the current minimum value of _\ud835\udc53_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2), we do not need to perform the DFS\nfor subsequent colors and can apply pruning. Also, since most of the calls to LowerBound are identical (up\nto swapping colors), we can apply memoization to reduce redundant calculations of LowerBound.\n\n**Utilizing symmetry.** Next, we reduce the number of combinations by utilizing the \u201csymmetry\u201d that some\nstate matrices represent essentially the same state. Specifically, the following operations on a state matrix _\ud835\udc40_\ndo not essentially change the state:\n\n1. Swap two rows of _\ud835\udc40_ . (Corresponds to swapping _\ud835\udc36\ud835\udc56_ and _\ud835\udc36_ _\ud835\udc57_ )\n\n43\n\n2. Swap two columns of _\ud835\udc40_ . (Corresponds to swapping the indices of two colors)\n\n3. Choose one row, and for each element of the row, change 1 to 2 and 2 to 1. (Corresponds to swapping\n_\ud835\udc4b\ud835\udc56_ and _\ud835\udc4c\ud835\udc56_ )\n\nWe say that _\ud835\udc40_ is in _standard form_ if ( _\ud835\udc40_ 1 _,_ 1 _, . . ., \ud835\udc40_ 4 _,_ 1 _, . . ., \ud835\udc40_ 1 _,\ud835\udc5a, . . ., \ud835\udc40_ 4 _,\ud835\udc5a_ ) is lexicographically earliest\namong the state matrices that can be obtained by repeating these three kinds of operations. It is easy to see\nthat, once _\ud835\udc40_ becomes a matrix not in standard form, it will never be in standard form again after adding\nsubsequent columns. In this case, we can apply pruning in the DFS.\nWe can check if _\ud835\udc40_ is in standard form by brute force. We brute-force the choice of how the rows are\npermuted and which rows we flip 1 and 2 in (there are 4! \u00d7 2 [4] = 384 ways), and for each choice, we sort\ncolumns in lexicographical order to obtain a candidate of the standard form.\n\n**Results.** In the DFS, we search 62195 state matrices that satisfy LB _<_ [125]\n\n**Results.** In the DFS, we search 62195 state matrices that satisfy LB _<_ 112 [and are in standard form. Among]\n\nthem, 22558 state matrices contain 1 and 2 in every row, and 16829 of them actually satisfy \u03941 _<_ [125] [.]\n\n112 [.]\n\n**6.5** **The final piece: Potential decomposition**\n\nTo further improve the analysis of the lower bound, we introduce the idea that the potentials in the first and\nsecond phases can be different. We consider decomposing potential _\ud835\udf19_ as _\ud835\udf19_ = _\ud835\udf19_ _\ud835\udc34_ + _\ud835\udf19\ud835\udc35_ . Let _\ud835\udc5d\ud835\udc56, \ud835\udc4e\ud835\udc56, \ud835\udc4f\ud835\udc56_ ( _\ud835\udc56_ =\n0 _, . . ., \u210e_ ) be the average potentials _\ud835\udf19, \ud835\udf19_ _\ud835\udc34, \ud835\udf19\ud835\udc35_ of components after phase _\ud835\udc56_ . Then, the following equation holds\ndue to the telescoping sum:\n\n_\ud835\udc5d\u210e_ \u2212 _\ud835\udc5d_ 0 = ( _\ud835\udc4e\u210e_ \u2212 _\ud835\udc4e\u210e_ \u22121) + ( _\ud835\udc4f_ 1 \u2212 _\ud835\udc4f_ 0) +\n\n_\u210e_ \u22121\n\n{( _\ud835\udc4e\ud835\udc56_ \u2212 _\ud835\udc4e\ud835\udc56_ \u22121) + ( _\ud835\udc4f\ud835\udc56_ +1 \u2212 _\ud835\udc4f\ud835\udc56_ )}\n\n\u2211\ufe01\n\n_\ud835\udc56_ =1\n\nThe term ( _\ud835\udc4e\ud835\udc56_ \u2212 _\ud835\udc4e\ud835\udc56_ \u22121) + ( _\ud835\udc4f\ud835\udc56_ +1 \u2212 _\ud835\udc4f\ud835\udc56_ ) represents the increase of _\ud835\udf19_ _\ud835\udc34_ at phase _\ud835\udc56_ plus the increase of _\ud835\udf19\ud835\udc35_ at phase\n_\ud835\udc56_ + 1. Therefore, when merging _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 as in subsection 6.3, if we know that the expected (increase of\naverage _\ud835\udf19_ _\ud835\udc34_ in the first phase) + (increase of average _\ud835\udf19\ud835\udc35_ in the second phase) is always _\ud835\udc65_ or more, we know\nthat _\ud835\udc5d_ _\ud835\udc58_ \u2265 _\ud835\udc65\ud835\udc58_ \u2212 _\ud835\udc42_ (1). The new \u201cpotential increase\u201d can be calculated by modifying Line 19 of Algorithm 8\nto \u0394 \u2190{ _\ud835\udf19\ud835\udc35_ (( _\ud835\udc4b_ 7 [\u2032] _[,\ud835\udc4c]_ 7 [\u2032][)) \u2212] 2 [1] [(] _[\ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][)))} + {] 2 [1] [(] _[\ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][))) \u2212] 4 [1] [(] _[\ud835\udf19]_ _[\ud835\udc34]_ [(] _[\ud835\udc36]_ [1][) +]\n\n2 [1] [(] _[\ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][)))} + {] 2 [1]\n\n[1]\n\n2 [(] _[\ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][))) \u2212] 4 [1]\n\nto \u0394 \u2190{ _\ud835\udf19\ud835\udc35_ (( _\ud835\udc4b_ 7 [\u2032] _[,\ud835\udc4c]_ 7 [\u2032][)) \u2212] 2 [(] _[\ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19][\ud835\udc35]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][)))} + {] 2 [(] _[\ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 5 [\u2032] _[,\ud835\udc4c]_ 5 [\u2032][)) +] _[ \ud835\udf19]_ _[\ud835\udc34]_ [((] _[\ud835\udc4b]_ 6 [\u2032] _[,\ud835\udc4c]_ 6 [\u2032][))) \u2212] 4 [(] _[\ud835\udf19]_ _[\ud835\udc34]_ [(] _[\ud835\udc36]_ [1][) +]\n\n_\ud835\udf19_ _\ud835\udc34_ ( _\ud835\udc36_ 2)+ _\ud835\udf19_ _\ud835\udc34_ ( _\ud835\udc36_ 3)+ _\ud835\udf19_ _\ud835\udc34_ ( _\ud835\udc36_ 4))}. The new algorithm is denoted as PotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ _\ud835\udc34, \ud835\udf19\ud835\udc35_ ).\nIn Subsection 6.3, we only considered the case that _\ud835\udf19_ _\ud835\udc34_ = _\ud835\udf19\ud835\udc35_, so by increasing the degrees of freedom, we\ncan expect a better lower bound.\n\n**The potential setting.** We consider setting _\ud835\udf19_ _\ud835\udc34, \ud835\udf19\ud835\udc35_ in the following way:\n\n1724 ((| _\ud835\udc4b_ \\ _\ud835\udc4c_ | _,_ | _\ud835\udc4c_ \\ _\ud835\udc4b_ |) = (2 _,_ 1) _,_ (1 _,_ 2))\n\n56 ((| _\ud835\udc4b_ \\ _\ud835\udc4c_ | _,_ | _\ud835\udc4c_ \\ _\ud835\udc4b_ |) = (3 _,_ 1) _,_ (1 _,_ 3))\n\n14 [|] _[\ud835\udc4b]_ [\u2295] _[\ud835\udc4c]_ [|] (otherwise)\n\n_\ud835\udf19_ _\ud835\udc34_ ( _\ud835\udc36_ ) = [1]\n\n2 [|] _[\ud835\udc4b]_ [\u2229] _[\ud835\udc4c]_ [| +]\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\n_\ud835\udf19\ud835\udc35_ ( _\ud835\udc36_ ) = [1]\n\n[1]\n\n2 [|] _[\ud835\udc4b]_ [\u2229] _[\ud835\udc4c]_ [| +][ 1] 3\n\n3 [|] _[\ud835\udc4b]_ [\u2295] _[\ud835\udc4c]_ [|]\n\nThen, the following lemma holds:\n\n**Lemma 6.7.** _PotentialIncrease_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ _\ud835\udc34, \ud835\udf19\ud835\udc35_ ) \u2265 [91] 96 _[for any components][ \ud835\udc36]_ [1] _[, \ud835\udc36]_ [2] _[, \ud835\udc36]_ [3] _[, \ud835\udc36]_ [4] _[ where state]_\n\n( _\ud835\udc4b,\ud835\udc4c_ ) _neither satisfies \ud835\udc4b_ \u2286 _\ud835\udc4c_ _nor \ud835\udc4c_ \u2286 _\ud835\udc4b._\n\nWe assume that in Lemma 6.7, the function PotentialIncrease( _\ud835\udc36_ 1 _, \ud835\udc36_ 2 _, \ud835\udc36_ 3 _, \ud835\udc36_ 4 _, \ud835\udf19_ _\ud835\udc34, \ud835\udf19\ud835\udc35_ ) is calculated in\nthe way explained in \u201cRemarks on Algorithm 8\u201d in subsection 6.3. We note that the result may change when\nwe allow to choose a new color for _\ud835\udc50\ud835\udc4e_ [(] _[\ud835\udc56]_ [)] [when] _[ \ud835\udc4b]_ _\ud835\udc56_ +4 [\\] _[ \ud835\udc4c]_ _\ud835\udc56_ +4 [is not empty (and similarly for] _[ \ud835\udc50]_ _\ud835\udc4f_ [(] _[\ud835\udc56]_ [)] [), even if this is]\nnot an optimal strategy, because of the difference of _\ud835\udf19_ _\ud835\udc34_ and _\ud835\udf19\ud835\udc35_ . Below, we give a computer assisted proof.\n\n44\n\n**The searching framework.** We prove Lemma 6.7 in a similar way to subsection 6.4. In the second phase,\nit can be proven that _\ud835\udf19\ud835\udc35_ always increases by [1] 3 [, similarly to][ Lemma 6.6][. Therefore, we have to enumerate all]\n\nthe cases such that _\ud835\udf19_ _\ud835\udc34_ increases by at most [91] [\u2212] [1] [=] [59] [in the first phase.]\n\n[1] [59]\n\n3 [=] 96\n\n[91]\n\n96 [\u2212] [1] 3\n\n96 [in the first phase.]\n\n**The lower-bounding for** _\ud835\udf19_ _\ud835\udc34_ **.** We aim to calculate _\ud835\udc54_ ( _\ud835\udc36_ 1 _, \ud835\udc36_ 2), defined in subsection 6.4. However, the\ndifference is that _\ud835\udf19_ _\ud835\udc34_ is no longer a linear function of | _\ud835\udc4b_ \u2295 _\ud835\udc4c_ |, so each _\ud835\udc50_ \u2208 _\ud835\udc4b\ud835\udc56_ \u2295 _\ud835\udc4c\ud835\udc56_ does not directly contribute\nto \u03940. In order to cope with this issue, we consider another potential function _\ud835\udf19_ [\u2032] _\ud835\udc34_ [(] _[\ud835\udc36]_ [)][ =] [1] 2 [|] _[\ud835\udc4b]_ [\u2229] _[\ud835\udc4c]_ [| +] 4 [1] [|] _[\ud835\udc4b]_ [\u2295] _[\ud835\udc4c]_ [|]\n\n[1] [1]\n\n2 [|] _[\ud835\udc4b]_ [\u2229] _[\ud835\udc4c]_ [| +] 4\n\nto \u03940. In order to cope with this issue, we consider another potential function _\ud835\udf19_ [\u2032] _\ud835\udc34_ [(] _[\ud835\udc36]_ [)][ =] 2 [|] _[\ud835\udc4b]_ [\u2229] _[\ud835\udc4c]_ [| +] 4 [|] _[\ud835\udc4b]_ [\u2295] _[\ud835\udc4c]_ [|]\n\n(which is identical to [1] 2 _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [)][). Note that] _[ \ud835\udf19]_ [\u2032] _\ud835\udc34_ [(] _[\ud835\udc36]_ [) \u2212] 6 [1] [\u2264] _[\ud835\udf19]_ _[\ud835\udc34]_ [(] _[\ud835\udc36]_ [) \u2264] _[\ud835\udf19]_ [\u2032] _\ud835\udc34_ [(] _[\ud835\udc36]_ [)][ always holds. Then, if we define][ \u0394][0]\n\nfor _\ud835\udf19_ [\u2032] _\ud835\udc34_ [(referring to][ Table 4][, the contribution to][ \u0394][0][ for each case (from the top) becomes 0] _[,]_ 8 [1] _[,]_ [1] 8 _[,]_ [1] 4 _[,]_ [1] 8 _[,]_ [ 0), the]\n\n[1]\n\n2 _[\ud835\udf19]_ [1][(] _[\ud835\udc36]_ [)][). Note that] _[ \ud835\udf19]_ [\u2032] _\ud835\udc34_ [(] _[\ud835\udc36]_ [) \u2212] 6 [1]\n\n[1] [1]\n\n8 _[,]_ 8\n\n[1] [1]\n\n8 _[,]_ 4\n\n[1] [1]\n\n4 _[,]_ 8\n\nfor _\ud835\udf19_ [\u2032] _\ud835\udc34_ [(referring to][ Table 4][, the contribution to][ \u0394][0][ for each case (from the top) becomes 0] _[,]_ 8 _[,]_ 8 _[,]_ 4 _[,]_ 8 _[,]_ [ 0), the]\n\nincrease of _\ud835\udf19_ _\ud835\udc34_ can be lower-bounded by \u03940 \u2212 [1] [. Therefore, we can calculate] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][)][ by changing Line 1]\n\nincrease of _\ud835\udf19_ _\ud835\udc34_ can be lower-bounded by \u03940 \u2212 6 [. Therefore, we can calculate] _[ \ud835\udc54]_ [(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][)][ by changing Line 1]\n\nof Algorithm 9 to _\ud835\udc51_ 0 \u2190(the value of \u03940 for potential _\ud835\udf19_ [\u2032] _\ud835\udc34_ [for the current] _[ \ud835\udc36]_ [1] _[, \ud835\udc36]_ [2][) \u2212] 6 [1] [.]\n\n6 [.]\n\n**Results.** In the DFS, we search 1773334 state matrices that satisfy LB _<_ [59]\n\n**Results.** In the DFS, we search 1773334 state matrices that satisfy LB _<_ 96 [(where LB is defined for] _[ \ud835\udf19]_ _[\ud835\udc34]_ [) and]\n\nare in standard form. Among them, 700415 state matrices contain 1 and 2 in every row, and 415942 of them actually satisfy \u03941 _<_ [59] [(where][ \u0394][1][ is defined for] _[ \ud835\udf19]_ _[\ud835\udc34]_ [). We compute PotentialIncrease][(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2] _[, \ud835\udc36]_ [3] _[, \ud835\udc36]_ [4] _[, \ud835\udf19]_ _[\ud835\udc34][, \ud835\udf19][\ud835\udc35]_ [)]\n\ntually satisfy \u03941 _<_ 96 [(where][ \u0394][1][ is defined for] _[ \ud835\udf19]_ _[\ud835\udc34]_ [). We compute PotentialIncrease][(] _[\ud835\udc36]_ [1] _[, \ud835\udc36]_ [2] _[, \ud835\udc36]_ [3] _[, \ud835\udc36]_ [4] _[, \ud835\udf19]_ _[\ud835\udc34][, \ud835\udf19][\ud835\udc35]_ [)]\n\nfor all of them, and each call returned a result of [91] 96 [or more. In conclusion, it is shown that any randomized]\n\nonline coloring algorithm for bipartite graphs requires at least [91] [log] _[ \ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors (][Theorem 6.1][).]\n\n96 [log] _[ \ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors (][Theorem 6.1][).]\n\n**Computer checks and programs.** The programs used for the analysis and their results in this section\ncan be downloaded at `[https://github.com/square1001/online-bipartite-coloring](https://github.com/square1001/online-bipartite-coloring)`, which is the\n\nsame URL as that in section 5.\n\n### **7 Conclusion**\n\nIn this paper, we studied the online coloring of _\ud835\udc58_ -colorable graphs for _\ud835\udc58_ \u2265 5 _, \ud835\udc58_ = 4, and _\ud835\udc58_ = 2.\nIn section 3, we presented a deterministiconlinealgorithmtocolor _\ud835\udc58_ -colorablegraphswith _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\ud835\udc58]_ [(] _[\ud835\udc58]_ [\u2212][1][))] )\ncolors. The key was to create an online algorithm for locally _\u2113_ -colorable graphs with _\ud835\udc42_ ( _\ud835\udc5b_ [1][\u2212][2][/(] _[\u2113]_ [(] _[\u2113]_ [\u2212][1][)+][2][)] )\ncolors. The new algorithm also improved the competitive ratio of online coloring to _\ud835\udc42_ ( _\ud835\udc5b_ /log log _\ud835\udc5b_ ).\nIn section 4, we presented a deterministic online algorithm to color 4-colorable graphs with _\ud835\udc42_ ( _\ud835\udc5b_ [14][/][17] )\ncolors. The key was to make use of the second neighborhoods with the _double greedy method_ that uses\nFirstFit twice. We also applied the _Common & Simplify Technique_ to take advantage of dense subgraph\n\nstructures.\n\nIn section 5, we showed that a randomization of the algorithm by Lov\u00b4asz, Saks, and Trotter [21] improves\nthe performance to 1 _._ 034 log2 _\ud835\udc5b_ + _\ud835\udc42_ (1) colors. We also showed that, in section 6, no randomized algorithms\ncan achieve [91] 96 [log][2] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][ colors.]\n\nWe were unable to improve the state-of-the-art bound _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][/][3] ) colors for _\ud835\udc58_ = 3 by [18]. The main reason\nis that the graph of degree _\ud835\udc5b_ [2][/][3] is too sparse to use the Common & Simplify technique, which we described\nin subsection 4.5. Indeed, to achieve _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][/][3][\u2212] _[\ud835\udf16]_ ) colors for some _\ud835\udf16>_ 0 with this technique, we must set\nparameters ( _\ud835\udefc, \ud835\udefd_ ) satisfying _\ud835\udefc_ + _\ud835\udefd_ = 1 \u2212 _\ud835\udf16_, but the present technique requires _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][\u2212] _[\ud835\udefc]_ [\u2212] _[\ud835\udefd]_ ) colors, which is\nmuch above the requirement. Especially, we are still unable to solve the special case where there exists a\n3-coloring of _\ud835\udc3a_ that for every _\ud835\udc56_ \u2208{1 _,_ 2 _, . . ., \ud835\udc5b_ / _\ud835\udc58_ } ( _\ud835\udc58_ = _\ud835\udc5b_ [1][/][3][\u2212] _[\ud835\udf16]_ ), the ( _\ud835\udc56_ \u2212 1) _\ud835\udc58_ + 1 _,_ ( _\ud835\udc56_ \u2212 1) _\ud835\udc58_ + 2 _, . . ., \ud835\udc56\ud835\udc58_ -th\nvertices (in the arrival order) have the same color.\nFinally, we conclude this paper by highlighting several important open problems related to online graph\ncoloring. We conjecture the following:\n\n**Conjecture 7.1.** _There exists a deterministic online algorithm to color_ 3 _-colorable graphs with_ _\ud835\udc42_ [\ufffd] ( _\ud835\udc5b_ [2][/][3][\u2212] _[\ud835\udf16]_ )\n_colors (for some \ud835\udf16>_ 0 _)._\n\n45\n\n**Conjecture 7.2.** _There exists a deterministic online algorithm to color \ud835\udc58-colorable graphs with \ud835\udc5b_ [1][\u2212][1][/] _[\ud835\udc5c]_ [(] _[\ud835\udc58]_ [2] [)]\n\n_colors._\n\n**Conjecture 7.3.** _RandomizedLST uses at most_ 1 _._ 027 log2 _\ud835\udc5b_ + _\ud835\udc42_ (1) _colors for any bipartite graph \ud835\udc3a._\n\n**Conjecture 7.4.** _The optimal randomized online algorithm for coloring bipartite graphs is RandomizedLST,_\n_up to constant number of colors; therefore, no algorithm can achieve_ 1 _._ 026 log2 _\ud835\udc5b_ \u2212 _\ud835\udc42_ (1) _colors._\n\nWe hope that future researchers (or possibly AIs) solve these questions.\n\n### **Acknowledgments**\n\nThe authors thank our laboratory members Kaisei Deguchi, Tomofumi Ikeura, and Yuta Inoue for their helpful\nsuggestions for improving this paper.\n\n### **References**\n\n[1] Susanne Albers and Sebastian Schraink. Tight bounds for online coloring of basic graph classes.\nIn Kirk Pruhs and Christian Sohler, editors, _25th Annual European Symposium on Algorithms, ESA_\n_2017, September 4-6, 2017, Vienna, Austria_, volume 87 of _LIPIcs_, pages 7:1\u20137:14. Schloss Dagstuhl Leibniz-Zentrum f\u00a8ur Informatik, 2017.\n\n[2] Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed\nbandit problem. _SIAM journal on computing_, 32(1):48\u201377, 2002.\n\n[3] Marco Barreno, Blaine Nelson, Russell Sears, Anthony D Joseph, and J Doug Tygar. Can machine\nlearning be secure? In _Proceedings of the 2006 ACM Symposium on Information, computer and_\n_communications security_, pages 16\u201325, 2006.\n\n[4] Dwight R Bean. Effective coloration. _The Journal of Symbolic Logic_, 41(2):469\u2013480, 1976.\n\n[5] Maria Paola Bianchi, Hans-Joachim B\u00a8ockenhauer, Juraj Hromkovi\u02c7c, and Lucia Keller. Online coloring\nof bipartite graphs with and without advice. _Algorithmica_, 70(1):92\u2013111, 2014.\n\n[6] Joakim Blikstad, Ola Svensson, Radu Vintan, and David Wajc. Online edge coloring is (nearly) as easy\nas offline. In _Proceedings of the 56th Annual ACM Symposium on Theory of Computing_, pages 36\u201346,\n\n2024.\n\n[7] Joakim Blikstad, Ola Svensson, Radu Vintan, and David Wajc. Deterministic online bipartite edge\ncoloring. In _Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_,\npages 1593\u20131606. SIAM, 2025.\n\n[8] Joakim Blikstad, Ola Svensson, Radu Vintan, and David Wajc. Online edge coloring: Sharp thresholds.\n_to appear in FOCS 2025, arXiv preprint arXiv:2507.21560_, 2025.\n\n[9] Paul Erd\u02ddos. Graph theory and probability. _Canadian Journal of Mathematics_, 11:34\u201338, 1959.\n\n[10] Uriel Feige and Joe Kilian. Zero knowledge and the chromatic number. _Journal of Computer and_\n_System Sciences_, 57(2):187\u2013199, 1998.\n\n[11] Grzegorz Gutowski, Jakub Kozik, Piotr Micek, and Xuding Zhu. Lower bounds for on-line graph colorings. In _International Symposium on Algorithms and Computation(ISAAC)_, pages 507\u2013515. Springer,\n\n2014.\n\n46\n\n[12] Andr\u00b4as Gy\u00b4arf\u00b4as and Jen\u00a8o Lehel. On-line and first fit colorings of graphs. _Journal of Graph theory_,\n12(2):217\u2013227, 1988.\n\n[13] Magn\u00b4us M. Halld\u00b4orsson. A still better performance guarantee for approximate graph coloring. _Infor-_\n_mation Processing Letters_, 45(1):19\u201323, 1993.\n\n[14] Magn\u00b4us M Halld\u00b4orsson. Parallel and on-line graph coloring. _Journal of Algorithms_, 23(2):265\u2013280,\n1997.\n\n[15] Magn\u00b4us M Halld\u00b4orsson and Mario Szegedy. Lower bounds for on-line graph coloring. _SODA\u201992,_\n_Theoretical Computer Science_, 130(1):163\u2013174, 1994.\n\n[16] Sandy Irani. Coloring inductive graphs on-line. _FOCS\u201990 and Algorithmica_, 11:53\u201372, 1994.\n\n[17] Ken-ichi Kawarabayashi, Mikkel Thorup, and Hirotaka Yoneda. Better coloring of 3-colorable graphs.\nIn _Proceedings of the 56th Annual ACM Symposium on Theory of Computing(STOC)_, pages 331\u2013339,\n\n2024.\n\n[18] Hal A Kierstead. On-line coloring k-colorable graphs. _Israel Journal of Mathematics_, 105:93\u2013104,\n1998.\n\n[19] Hal A Kierstead. Coloring graphs on-line. _Online algorithms: the state of the art_, pages 281\u2013305,\n2005.\n\n[20] L\u00b4aszl\u00b4o Lov\u00b4asz. _Combinatorial Problems and Exercises_, volume 361. American Mathematical Society,\n1979.\n\n[21] L\u00b4aszl\u00b4o Lov\u00b4asz, Michael Saks, and William T Trotter. An on-line graph coloring algorithm with sublinear\nperformance ratio. _Discrete Mathematics_, 75(1-3):319\u2013325, 1989.\n\n[22] Tim Roughgarden. _Beyond the worst-case analysis of algorithms_ . Cambridge University Press, 2021.\n\n[23] Sundar Vishwanathan. Randomized online graph coloring. _FOCS\u201990 and Journal of algorithms_,\n13(4):657\u2013669, 1992.\n\n[24] Andrew Chi-Chin Yao. Probabilistic computations: Toward a unified measure of complexity. In _18th_\n_Annual Symposium on Foundations of Computer Science (FOCS\u201977)_, pages 222\u2013227. IEEE Computer\nSociety, 1977.\n\n47"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism for improving deterministic online graph coloring for k-colorable graphs relies on a recursive decomposition strategy. It starts by attempting a greedy FirstFit coloring with a limited palette (e.g., `n^(1-epsilon)` colors). Any vertex `v` that cannot be colored this way forms a 'hard' set `T`. These 'hard' vertices must have many neighbors in the 'easy' FirstFit-colored set `S`. The key insight is that this density implies structural properties that can be exploited. The algorithm recursively defines 'level-d sets' within `S`. A level-d set `S'` guarantees that any small induced subgraph involving `S'` is `(k-d)`-colorable. By finding progressively higher-level `(d+1)` sets (which are easier to color or guarantee a simpler induced subgraph for `T`), the problem for `T` is reduced. This is a form of induction where the 'difficulty' parameter `d` increases, making the remaining problem simpler for 'future' vertices. The large degree condition (`|N_S(v)| >= gamma_(d+1)`) is crucial: if a vertex `v` in `T` has many neighbors in `S`, its neighbors' properties in `S` (e.g., forming a `1-color set`) constrain the possible colors for `v` and its neighbors. This allows `v` and its neighbors to be passed to a sub-algorithm for `(k-1)`-colorable graphs. For `k=4`, the 'Double Greedy' runs FirstFit twice. The 'Common & Simplify' technique then exploits pairs of vertices in `T` with many common neighbors in `S` (are 'beta-common'), as their collective neighborhood in `S` becomes a `2-color set`, reducing the problem to a `(k-2)`-colorable one. The randomized approach for `k=2` avoids worst-case deterministic scenarios by making coloring choices randomly (e.g., flipping a coin between two available colors), which reduces the expected frequency of needing a 'new color' (level increase).\n\n**Explanation:** Imagine you're writing a compiler that has to process code (graph vertices) line by line, coloring syntax (assigning colors) as it comes, making sure no two connected lines (adjacent vertices) have the same color. You want to use the smallest set of colors (like a limited number of registers). The new approach uses a recursive function call structure. It first tries to color as many lines as possible using a simple greedy strategy (like `FirstFit`, using colors `1` to `N^(1-epsilon)`). Any lines that can't be colored this way are 'difficult' (the `T` set). For these `T` lines, the compiler knows they have many connections to already-colored 'easy' `S` lines. This dense connection provides information. The algorithm then identifies 'level-d sets' within `S`. Think of these as groups of `S` lines that, if you zoom in, are guaranteed to only use a few colors (`k-d` colors). The compiler then recursively calls a simpler version of itself to color the `T` lines, knowing that their connections to these 'level-d sets' simplify their coloring problem (effectively reducing the target `k` for that subproblem). It's like saying, 'Okay, this module is connected to a 'level-1' library function, so I only need to consider `k-1` registers for this module.' This is a recursive algorithm where `d` increases, simplifying the problem until it's trivial. For `k=4`, they use a 'double greedy' strategy (like running `FirstFit` twice, once for `S`, once for `T`). Then, the 'Common & Simplify' technique. If two 'difficult' lines (`u1`, `u2`) share many connections (`N_S(u1) intersect N_S(u2)`) to the 'easy' `S` lines, it means those common `S` connections can only use a restricted set of colors (e.g., 2 colors, making it a `2-color set`). This allows the `u1, u2` problem to be passed to a simpler coloring algorithm. This is akin to finding common data structures between two challenging code blocks to reuse memory (colors) more efficiently. For bipartite graphs (like graphs where lines can be split into two groups, and connections only go between groups), an existing algorithm would assign 'levels' to connected components. This new approach randomizes some coloring decisions. Imagine when you're forced to pick a new register for a line; instead of always picking the next available, you randomly pick between two. This randomization helps avoid worst-case scenarios where an 'adversary' (the graph structure itself) always forces you to use a new register. The analysis involves tracking the expected maximum 'level' of any component to prove the improved upper bound."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc51\ud835\udc56\ud835\udc53\ud835\udc53_ _> \ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ] **then**\n\n**18** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u2212 1 ;\n\n/* try to drain link queues if needed */\n\n**19** _\ud835\udc5e_ \u2190 _\ud835\udc5f\ud835\udc61\ud835\udc61_ \u2212 _\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ [ _\ud835\udc5f_ ] ; // current queuing delay"}, {"role": "assistant", "content": "**Mechanism:** This implements a basic feedback control loop. First, it uses an 'if' condition to detect an indicator of congestion (_diff_) exceeding a route-specific threshold (_alpha_). If true, a counter (_cwnd_) is decremented. Separately, it calculates queuing delay by subtracting a baseline Round Trip Time (_baseRTT_) from the current RTT (_rtt_).\n\n**Explanation:** This code acts like a simple feedback control system for network traffic. It continuously checks if there's a problem, like data piling up (_diff_), comparing it to a tolerable amount (_alpha_). This is like an `if (current_problem > threshold)` condition. If the problem is too big, it immediately tells the sender to send one less packet at a time by decrementing the congestion window (_cwnd_), which is a counter. This aims to reduce the pile-up. Concurrently, it's always measuring how long it takes a packet to go and come back (_rtt_). Knowing the absolute fastest that trip can ever be (_baseRTT_), it calculates exactly how much extra time the packet spent just waiting in queues (_q_). This provides real-time insight into the congestion experienced."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc51\ud835\udc56\ud835\udc53\ud835\udc53_ \u2265 _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ] **then**\n\n**11** _\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ]/ _\ud835\udc5f\ud835\udc61\ud835\udc61_ ;\n\n**12** Adjust_Weights() ;\n\n**13** _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc60_ [ _\ud835\udc5f_ ] \u00d7 _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ ;\n\n**14** _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ] \u2190 max{2 _,\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ]} ; // lower bound\n\n/* window adjustment */"}, {"role": "assistant", "content": "**Mechanism:** This segment implements an adaptive feedback loop to manage a resource 'r' by adjusting its processing rate and a sensitivity threshold 'alpha'. The core mechanism is a conditional trigger: if a performance discrepancy ('diff') for resource 'r' exceeds its current tolerance 'alpha[r]', a series of corrective actions are initiated.\n\n**Explanation:** When the condition 'diff >= alpha[r]' is met, it signals that the observed discrepancy for resource 'r' is significant enough to warrant intervention. The system then calculates an 'equilibrium_rate' for 'r' by dividing its `cwnd` (likely a measure of allocated capacity or 'congestion window') by its `rtt` (Round Trip Time, a latency measure). This effectively computes a target throughput that balances capacity with network delay. The `Adjust_Weights()` call suggests a global re-evaluation, possibly updating allocation policies for all resources based on current system state. Subsequently, the `alpha[r]` threshold itself is re-scaled based on a resource-specific `weights[r]` and a global `total_alpha`, allowing the system's sensitivity to adapt. Crucially, `alpha[r] = max{2, alpha[r]}` enforces a lower bound, preventing `alpha[r]` from becoming excessively small. Without this floor, the trigger condition could become hyper-sensitive, leading to constant, destabilizing adjustments for even minor fluctuations. This mechanism creates a self-tuning system that reacts to significant deviations while maintaining a minimum level of tolerance for stability."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each tree \ud835\udf0f_ \u2208 _\ud835\udc47_ _that contains edge_ ( _\ud835\udc62, \ud835\udc63_ ) **do**\n\n**18** _\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc54_ \u2190 _\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc54_ + _\ud835\udc64_ ( _\ud835\udf0f_ );\n\n**19** _\ud835\udf0f_ [\u2032] \u2190 cut-link ( _\ud835\udf0f,_ ( _\ud835\udc62, \ud835\udc63_ ));\n\n**20** Update _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] );\n\n**21** Calculate weight as _\ud835\udc64_ ( _\ud835\udf0f_ [\u2032] ) = _[\ud835\udc51]_ _\ud835\udc51_ [(] ( _[\ud835\udf0f]_ _\ud835\udf0f_ [\u2032] ) [)] _[\ud835\udc64]_ [(] _[\ud835\udf0f]_ [)][;]"}, {"role": "assistant", "content": "**Mechanism:** This loop iterates through a collection of graph structures (trees), performing a specific modification (edge removal) on those containing a target element (edge (u,v)), and then updating an aggregated metric and individual properties for the resulting sub-structures.\n\n**Explanation:** This is a `for-each` loop that processes trees. For every tree containing a specific edge (u,v), it first adds the tree's current weight to a running total (`worg`), acting like a global counter or accumulator. Next, `cut-link` is called, which functionally breaks the specified edge in the tree. In a tree, this operation always results in two disconnected components, effectively creating a new sub-tree (`\ud835\udf0f'`). Subsequently, a function `f` is updated for this new sub-tree, likely recalculating or setting its features or properties, akin to updating an object's internal state. Finally, the weight `w(\ud835\udf0f')` of this new sub-tree is calculated by scaling the original tree's weight `w(\ud835\udf0f)` by a factor `d(\ud835\udf0f', \ud835\udf0f)`. This `d` likely represents a proportional split or a 'distance' metric, distributing the original weight across the newly formed components."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**12 else**\n\n**13** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc41\ud835\udc48\ud835\udc3f\ud835\udc3f_ ; /* no available subflow */\n\n**14 end if**\n\n**15 return** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_\n\nThe theoretical aspects of _BLEST_ packet scheduling algorithm are provided in 2.2.2.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 45\n\n**Algorithm 3:** ECF\n\n**Input:** Set of available subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R, _\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc53_ _< \ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_\n\n**Output:** Best subflow, _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2208S\n\n**1** _\ud835\udc65_ _\ud835\udc53_ \u2190 _\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc45\ud835\udc47\ud835\udc47_ () ; /* find the fastest subflow _\ud835\udc65_ _\ud835\udc53_ using minRTT algorithm */\n\n**2 if** _fastest subflow \ud835\udc65_ _\ud835\udc53_ _is available_ **then**\n\n**3** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc65_ _\ud835\udc53_ ;\n\n**4 else**\n\n**5** _\ud835\udc65\ud835\udc60_ \u2190 _\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc45\ud835\udc47\ud835\udc47_ () ; /* find the second fastest subflow _\ud835\udc65\ud835\udc60_ using minRTT algorithm */\n\n**6** _\ud835\udc5b_ = 1 + _\ud835\udc36\ud835\udc4a\ud835\udc41\ud835\udc37\ud835\udc58_ _\ud835\udc53_ [;]\n\n**7** _\ud835\udeff_ = _\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udf0e\ud835\udc53_ _, \ud835\udf0e\ud835\udc60_ ) ;"}, {"role": "assistant", "content": "**Mechanism:** The ECF algorithm prioritizes network paths based on their current Round Trip Time (RTT), a direct measure of latency. It employs a greedy strategy: first attempting to utilize the absolute fastest path available. If that primary path is unavailable (e.g., due to congestion or explicit status), it swiftly switches to the second fastest path. The `minRTT()` function conceptually iterates through a collection of network paths (like a for loop over an array of path objects) and identifies the path object with the smallest RTT attribute.\n\n**Explanation:** This approach works by aggressively minimizing latency, as lower RTT directly translates to faster packet delivery. The `if/else` structure acts as a fast-failover mechanism: rather than waiting for the absolute fastest path to clear, it immediately diversifies to the next best option, maintaining overall data throughput and responsiveness. The inclusion of `CWND` (Congestion Window) and `max` on `sigma` values (likely variance of RTT) suggests dynamic adjustments to a path's 'availability' or 'quality', integrating factors like capacity and stability beyond just instantaneous speed. A path might be deemed 'unavailable' if its congestion window is too small, indicating severe network load, or if its RTT is highly variable, making a slightly slower but more stable path a better practical choice."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe present DynaExq, a runtime system that enables dynamic expertlevel quantization for Mixture-of-Experts models on memory constrained GPUs. By combining workload-aware precision management, an asynchronous expert swapping pipeline, and a stable\nmixed-precision execution framework, DynaExq aligns expert precision with real activation behavior rather than static calibration\n\nchoices. Our evaluation across diverse benchmarks shows that\n\nDynaExq preserves model quality while substantially reducing\nmemory usage and improving efficiency relative to static low-bit\nbaselines. These results demonstrate that integrating quantization\ninto the serving runtime, treating precision as a controllable system\nresource, is an effective direction for scalable and responsive MoE\ninference on commodity hardware.\n\nDynamic Expert Quantization for Scalable Mixture-of-Experts Inference\n\nFuture work includes extending precision scheduling with predictive models, exploring cross-layer correlated activation patterns,\nand integrating DynaExq into distributed MoE serving frameworks\nwhere expert placement and precision co-optimization may yield\nfurther gains.\n\n**References**\n\n[[1] Qwen3-30b-a3b-instruct-2507. https://huggingface.co/Qwen/Qwen3-30B-A3B-](https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507)\n[Instruct-2507.](https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507)\n\n[2] Qwen3-next-80b-a3b. [https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-](https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct)\n[Instruct.](https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct)\n\n[3] Balunovi\u0107, M., Dekoninck, J., Petrov, I., Jovanovi\u0107, N., and Vechev, M.\nMatharena: Evaluating llms on uncontaminated math competitions, Feb. 2025.\n\n[4] Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J.,\nEdwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger,\nG., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder,\nN., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P.,\nSuch, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., HerbertVoss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin,\nI., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J.,\nMisra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M.,\nMayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever,\nI., and Zaremba, W. Evaluating large language models trained on code, 2021.\n\n[5] Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,\nM., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training\nverifiers to solve math word problems. _arXiv preprint arXiv:2110.14168_ (2021).\n\n[6] Duanmu, H., Li, X., Yuan, Z., Zheng, S., Duan, J., Zhang, X., and Lin, D. Mxmoe:\nMixed-precision quantization for moe with accuracy and performance co-design,\n2025.\n\n[7] Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A.,\nMathur, A., Schelten, A., Yang, A., Fan, A., et al. The llama 3 herd of models.\n_arXiv e-prints_ (2024), arXiv\u20132407.\n\n[8] Frantar, E., and Alistarh, D. Qmoe: Practical sub-1-bit compression of trillionparameter models, 2023.\n\n[9] Frantar, E., Ashkboos, S., Hoefler, T., and Alistarh, D. Gptq: Accurate posttraining quantization for generative pre-trained transformers. _arXiv preprint_\n_arXiv:2210.17323_ (2022).\n\n[10] Fu, Z., Ding, N., Han, K., Yu, X., Li, X., Chen, X., Tang, Y., and Wang, Y.\nEaquant: Enhancing post-training quantization for moe models via expert-aware\noptimization, 2025.\n\n[11] Gale, T., Narayanan, D., Young, C., and Zaharia, M. Megablocks: Efficient\nsparse training with mixture-of-experts. _Proceedings of Machine Learning and_\n_Systems 5_ (2023), 288\u2013304.\n\n[12] Hu, X., Chen, Z., Yang, D., Xu, Z., Xu, C., Yuan, Z., Zhou, S., and Yu, J. Moequant:\nEnhancing quantization for mixture-of-experts large language models via expertbalanced sampling and affinity guidance, 2025.\n\n[13] Hubara, I., Nahshan, Y., Hanani, Y., Banner, R., and Soudry, D. Accurate\npost training quantization with small calibration sets. In _International conference_\n_on machine learning_ (2021), PMLR, pp. 4466\u20134475.\n\n[14] Hwang, C., Cui, W., Xiong, Y., Yang, Z., Liu, Z., Hu, H., Wang, Z., Salas, R.,\nJose, J., Ram, P., et al. Tutel: Adaptive mixture-of-experts at scale. _Proceedings_\n_of Machine Learning and Systems 5_ (2023), 269\u2013287.\n\n[15] Kim, Y. J., Fahim, R., and Awadalla, H. H. Mixture of quantized experts (moqe):\nComplementary effect of low-bit quantization and robustness, 2023.\n\n[[16] Labs, I. Autoround: Advanced quantization algorithm for llms. https://github.](https://github.com/intel/auto-round)\n[com/intel/auto-round, 2024.](https://github.com/intel/auto-round)\n\n[17] Lee, J. H., Kim, J., Kwon, S. J., and Lee, D. Flexround: Learnable rounding based\non element-wise division for post-training quantization, 2024.\n\n[18] Lin, J., Tang, J., Tang, H., Yang, S., Chen, W.-M., Wang, W.-C., Xiao, G., Dang,\nX., Gan, C., and Han, S. Awq: Activation-aware weight quantization for ondevice llm compression and acceleration. _Proceedings of machine learning and_\n_systems 6_ (2024), 87\u2013100.\n\n[19] Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C., Zhang,\nC., Ruan, C., et al. Deepseek-v3 technical report. _arXiv preprint arXiv:2412.19437_\n(2024).\n\n[20] Liu, X., Zheng, M., Cao, J., Wei, D., Lai, K., Lan, H., Song, Y., and Li, X. Efficient\npartitioning deep learning models for medical image analysis on iot devices.\nIn _Proceedings of the 2025 IEEE International Conference on Bioinformatics and_\n_Biomedicine (BIBM)_ (2025), IEEE.\n\n[21] Merity, S., Xiong, C., Bradbury, J., and Socher, R. Pointer sentinel mixture\nmodels, 2016.\n\n[22] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,\nT., Lin, Z., Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, highperformance deep learning library. _Advances in neural information processing_\n_systems 32_ (2019).\n\n[23] Rajbhandari, S., Li, C., Yao, Z., Zhang, M., Aminabadi, R. Y., Awan, A. A.,\nRasley, J., and He, Y. Deepspeed-moe: Advancing mixture-of-experts inference\nand training to power next-generation ai scale. In _International conference on_\n_machine learning_ (2022), PMLR, pp. 18332\u201318346.\n\n[24] Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael,\nJ., and Bowman, S. R. Gpqa: A graduate-level google-proof q&a benchmark. In\n_First Conference on Language Modeling_ (2024).\n\n[25] Shen, Z., Chu, K., Zhang, Y., Xiang, D., Wu, R., and Zhang, W. Expertflow:\nAdaptive expert scheduling and memory coordination for efficient moe inference,\n2025.\n\n[26] Song, X., Zhong, Z., Chen, R., and Chen, H. Promoe: Fast moe-based llm\nserving using proactive caching. _arXiv preprint arXiv:2410.22134_ (2024).\n\n[27] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,\nT., Rozi\u00e8re, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and\nefficient foundation language models. _arXiv preprint arXiv:2302.13971_ (2023).\n\n[28] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,\nKaiser, \u0141., and Polosukhin, I. Attention is all you need. _Advances in neural_\n_information processing systems 30_ (2017).\n\n[29] Wang, K., Liu, Z., Lin, Y., Lin, J., and Han, S. Haq: Hardware-aware automated\nquantization with mixed precision, 2019.\n\n[30] Wang, Y., Ma, X., Zhang, G., Ni, Y., Chandra, A., Guo, S., Ren, W., Arulraj, A.,\nHe, X., Jiang, Z., et al. Mmlu-pro: A more robust and challenging multi-task\nlanguage understanding benchmark. _Advances in Neural Information Processing_\n_Systems 37_ (2024), 95266\u201395290.\n\n[31] Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac,\nP., Rault, T., Louf, R., Funtowicz, M., et al. Transformers: State-of-the-art\nnatural language processing. In _Proceedings of the 2020 conference on empirical_\n_methods in natural language processing: system demonstrations_ (2020), pp. 38\u201345.\n\n[32] Xuan, W., Yang, R., Qi, H., Zeng, Q., Xiao, Y., Feng, A., Liu, D., Xing, Y., Wang,\nJ., Gao, F., et al. Mmlu-prox: A multilingual benchmark for advanced large\nlanguage model evaluation. _arXiv preprint arXiv:2503.10497_ (2025).\n\n[33] Xue, L., Fu, Y., Lu, Z., Mai, L., and Marina, M. Moe-infinity: Offloading-efficient\nmoe model serving. _arXiv preprint arXiv:2401.14361_ (2024).\n\n[34] Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang,\nC., Lv, C., et al. Qwen3 technical report. _arXiv preprint arXiv:2505.09388_ (2025).\n\n[35] Zhang, J., Zhang, Y., Zhang, B., Liu, Z., and Cheng, D. Moqe: Improve quantization model performance via mixture of quantization experts. _arXiv preprint_\n_arXiv:2508.09204_ (2025).\n\n[36] Zhou, Y., Lei, T., Liu, H., Du, N., Huang, Y., Zhao, V., Dai, A. M., Le, Q. V.,\nLaudon, J., et al. Mixture-of-experts with expert choice routing. _Advances in_\n_Neural Information Processing Systems 35_ (2022), 7103\u20137114."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is dynamic, workload-aware precision scaling for individual experts within an MoE model, coupled with an intelligent memory management strategy. Instead of quantizing all experts to a fixed low bit-width (static quantization), DynaExq observes the actual activation distributions (workload-aware statistics) during runtime for each active expert. Based on these observed statistics, it can dynamically adjust the numerical precision (e.g., from full floating-point down to 4-bit integers) of that specific expert's weights and activations. This is like a just-in-time compiler or a selective data compression scheme. The 'asynchronous expert swapping pipeline' is analogous to a sophisticated pre-fetcher or a double-buffering system. While one expert is processing data, the system proactively loads the next anticipated expert into GPU memory at its pre-determined dynamic precision in the background, minimizing latency. The 'stable mixed-precision execution framework' implies an underlying system that can robustly handle heterogeneous data types and operations, effectively dispatching to appropriate arithmetic units or kernels based on the current expert's bit-width without introducing instability, similar to how a modern CPU can handle both integer and floating-point instructions seamlessly.\n\n**Explanation:** Mixture-of-Experts (MoE) models gain power from having many specialized 'experts,' but this makes them very large. Traditional quantization tries to shrink them by making all numbers less precise, but this can cause some experts to lose accuracy when they really need that detail. DynaExq gets around this by making quantization smart and dynamic. It constantly watches the data that each expert is working on ('workload'). If an expert is processing simple data, DynaExq knows it doesn't need high precision, so it 'rounds off' the numbers for that expert to a very low bit-width (like going from detailed fractions to simple whole numbers). This saves a lot of memory and makes calculations faster. But if an expert is crunching complex data, DynaExq keeps its numbers more precise. This decision isn't set in stone; it adapts based on the actual statistical properties of the incoming data, avoiding a rigid, static approach. To prevent delays when switching experts, there's a clever 'asynchronous swapping' system. While one expert is busy calculating, the system is already quietly preparing the next expert that might be called, loading it into the computer's fast memory at the right precision, much like a background task preparing resources so they're instantly available when needed. The 'mixed-precision execution' means the computer can flawlessly handle calculations where different parts are using different levels of numerical detail at the same time, without getting confused."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_All proofs for theoretical results in this paper are found in the Appendix._\n\n**2.1** **Low Rank Matrix Approximations**\n\nWhen adapting high dimensional foundation models for specific tasks, updating the parameters using gradient\nbased methods has high memory requirements. LoRA uses low-rank approximations to the matrix multiplications to reduce these costs. For each matrix _Mi \u2208_ R _[m][\u00d7][n]_ in the model, a low-rank approximation can be made\nby decomposing each matrix:\n\n_Mi \u2248_ _Mi_ [0] [+] _[ A][i][B]_ _i_ _[\u22a4][,]_\n\nwhere _Mi_ [0] [:=][ StopGrad][(] _[M][i]_ [)][ is the imported matrix from the foundation model with frozen parameters and]\n_Ai \u2208_ R _[m][\u00d7][r]_ and _Bi \u2208_ R _[n][\u00d7][r]_ are low-width column matrices (i.e., _r \u226a_ min( _m, n_ )) whose parameters are\nupdated through gradient-based optimisation during task-specific adaptation. This reduces the number of\noptimisation parameters for each matrix from _mn_ to _r_ ( _m_ + _n_ ). In this paper, we use a similar low-rank matrix\napproximation for evolutionary strategies.\n\n**2.2** **Gaussian Matrix Distribution and Matrix Norms**\n\nIn this paper, we focus on evolution strategies that target _matrix parameters_ . Many variables we study are\nGaussian distributed. When working in matrix space, it is convenient to use the matrix Gaussian distribution\n(Dawid, 1981), which is defined directly over matrices _X \u2208_ R _[m][\u00d7][n]_ :\n\n1\n_N_ ( _M, U, V_ ) = ~~_mn_~~\n(2 _\u03c0_ ) 2 det( _U_\n\n_\u2212_ [1]\n2 [exp] \ufffd 2\n\n~~_n_~~ ~~_m_~~\n2 det( _U_ ) 2 det( _V_ ) 2\n\n[1] \ufffd _V_ _[\u2212]_ [1] ( _X \u2212_ _M_ ) _[\u22a4]_ _U_ _[\u2212]_ [1] ( _X \u2212_ _M_ )\ufffd [\ufffd] _,_\n\n2 [tr]\n\nwhere _M \u2208_ R _[m][\u00d7][n]_ is the mean matrix, _U \u2208_ R _[m][\u00d7][m]_ is the row covariance matrix and _V \u2208_ R _[n][\u00d7][n]_ is the\ncolumn covariance matrix. The matrix Gaussian distribution is a generalisation of the multivariate Gaussian\ndistribution _N_ ( _\u00b5,_ \u03a3) defined over vector space. Sampling a matrix _X \u223cN_ ( _M, U, V_ ) from a Gaussian matrix\ndistribution is equivalent to sampling a vector vec( _X_ ) _\u223cN_ ( _\u00b5,_ \u03a3) from a multivariate Gaussian distribution\nwith mean _\u00b5_ = vec( _M_ ) and covariance matrix \u03a3 = _V \u2297_ _U_ where _\u2297_ denotes the Kronecker product. For\nisotropic matrix Gaussian distributions with covariance matrices _U_ = _\u03c3_ [2] _Im_ and _V_ = _\u03c3_ [2] _In_, the equivalent\nmultivariate Gaussian distribution is also isotropic with \u03a3 = _\u03c3_ [2] _Imn_ . To measure distance between matrices,\nwe use the Frobenius norm:\n\n_\u2225M_ _\u2225F_ := _mi,j_ [2] _,_\n~~\ufffd\ufffd~~ _i,j_\n\n3\n\nwhich provides an upper bound on the matrix 2-norm (Petersen & Pedersen, 2008). We denote the _\u2113_ [2] vector\nnorm as _\u2225\u00b7\u2225_ .\n\n**2.3** **Evolution strategies**\n\nEvolution strategies (ES) (Rechenberg, 1978; Beyer, 1995; Beyer & Schwefel, 2002) is a set of blackbox\nmethods for optimising general systems. ES has emerged as a useful alternative to gradient-based methods,\nparticularly when a system is noisy or non-differentiable. Our problem setting focuses on fitness functions\nwhose parameters are matrices: our goal is to find a matrix _M_ _[\u22c6]_ _\u2208_ R _[m][\u00d7][n]_ that maximises the fitness function\n_M_ _[\u22c6]_ _\u2208_ arg max _M_ _\u2208_ R _m\u00d7n f_ ( _M_ ). In comparison to gradient-based methods which use derivatives of the\nfunction _f_ ( _M_ ) to update the parameters _M_ directly, evolutionary methods update a population distribution\nover the parameter space. This is achieved by learning a set of parameters _\u03b8_ to maximise the expected fitness\n_f_ ( _z_ ) under a population distribution _\u03c0_ ( _M_ _|\u03b8_ ):\n\n_J_ ( _\u03b8_ ) = E _M_ _\u223c\u03c0_ ( _M_ _|\u03b8_ ) [ _f_ ( _M_ )] _._ (1)\n\nTaking derivatives of _J_ ( _\u03b8_ ) yields the gradient:\n\n_\u2207\u03b8J_ ( _\u03b8_ ) = E _M_ _\u223c\u03c0_ ( _M_ _|\u03b8_ ) [ _\u2207M_ log _\u03c0_ ( _M_ _|\u03b8_ ) _f_ ( _M_ )] _,_\n\nwhich is used to update the population distribution\u2019s parameters using (stochastic) gradient ascent with a\nsuitable stepsize _\u03b1t_ :\n\n_\u03b8t_ +1 _\u2190_ _\u03b8t_ + _\u03b1t\u2207\u03b8J_ ( _\u03b8t_ ) _._ (2)\n\n_\u2207M_ log _\u03c0_ ( _M_ _|\u03b8_ ) is known as the score function, which avoids taking gradients directly through the fitness\nfunction in Eq. (1).\n\n**2.4** **Gaussian Matrix ES**\n\nIn this paper, we study ES using Gaussian policies: _\u03c0_ ( _M_ _|\u03b8_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ). In addition to its\nmathematical convenience, the central limit theorem means that the Gaussian distribution emerges naturally\nfrom a low-rank approximation as rank increases, even if the matrices _A_ and _B_ are themselves non-Gaussian.\nWe assume that _\u03c3_ [2] is fixed and the ES algorithm optimises over the mean matrix _\u03b8_ = _\u00b5_ which acts as a proxy\nfor the true maximum of the fitness function. By adapting well-known derivations (Wierstra et al., 2011) to the\nGaussian matrix case, we derive the ES gradient for our problem setting:\n**Proposition 1.** _Using the Gaussian matrix policy \u03c0_ ( _M_ _|\u00b5_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ) _the ES objective can be_\n_written as:_\n\n_J_ ( _\u00b5_ ) = E _E\u223cP_ ( _E_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3E_ )] _._ (3)\n\n_and the matrix gradient of the ES objective is:_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1] (4)\n\n_\u03c3_ [E] _[E][\u223c][P]_ [ (] _[E]_ [)][ [] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ .]_\n\n_where P_ ( _E_ ) _is a zero-mean standard normal p_ ( _E_ ) = _N_ (0 _, Im, In_ ) _. Moreover, the natural matrix gradient is_\n_equal to \u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) _, i.e. equivalent to Eq._ (4) _up to a factor of \u03c3_ [2] _._\n\nWe see from Eq. (4) that Gaussian matrix ES methods optimise the objective _J_ ( _\u00b5_ ) by generating search\nmatrices _E \u223c_ _P_ ( _E_ ) from a standard matrix normal distribution _N_ (0 _, Im, In_ ) around the parameter matrix\n_\u03b8_ = _\u00b5_ .\n\nWe remark that for Gaussian population distributions, the ES update in Eq. (4) is equal to the natural evolution\nstategy (NES) update up to a factor of _\u03c3_ [2] . NES (Wierstra et al., 2008; 2011) updates follow the _natural gradient_\n(Amari, 1998; Kakade, 2001) of the objective in Eq. (1). This means that for our problem setting where _\u03c3_ is\nassumed fixed and is absorbed into the stepsize in Eq. (2), Gaussian matrix ES and NES are equivalent. A key\nbenefit of the natural gradient is that it takes into account the local geometry of the underlying parameter space\nwhen updating the search distribution, making the updates invariant to the choice of parametrisation.\n\n4"}, {"role": "assistant", "content": "**Mechanism:** The method tackles parameter reduction and derivative-free optimization. For parameter reduction, a large matrix M is approximated by M0 + AB^T. M0 is a fixed base, while A (an m x r matrix) and B (an n x r matrix) are small matrices with r being much smaller than m or n. Instead of updating mn parameters of M, only r(m+n) parameters of A and B are updated. This effectively adds a low-rank 'adjustment layer' to a frozen base matrix, drastically reducing the number of variables to train. For optimization without direct gradients, Evolution Strategies (ES) is used. It works by maintaining a distribution \u03c0(M|\u00b5) (here, a Gaussian matrix distribution) over possible solution matrices M, parameterized by \u00b5 (the mean matrix). Instead of computing \u2207f(M), ES estimates \u2207\u00b5J(\u00b5) where J(\u00b5) is the *expected* fitness E[f(M)]. This is done by sampling noise matrices E (standard normal) around the current mean \u00b5, evaluating f(\u00b5 + \u03c3E) for these samples, and then using a weighted average of these noise matrices (weighted by their fitness f) to determine how to shift \u00b5. Essentially, it's a 'guess and check' method where the guesses are structured by a probability distribution, and the 'checks' (fitness values) guide the update of the distribution's mean towards higher-fitness regions.\n\n**Explanation:** When a computer model has too many internal settings (parameters) to tweak, it's like having a giant knob with millions of tiny settings. Low-rank approximation helps by saying, 'Let's keep most of the knob settings fixed and only add two much smaller, simpler attachment knobs that influence the main one, and we'll only turn those two small ones.' This drastically cuts down the number of things to adjust. For finding the *best* setting, especially when you can't tell exactly which way is 'up' (no direct derivative), Evolution Strategies come in. Imagine you're trying to find the highest point on a mountain in a thick fog. You can't see the steepest path. Instead, you throw many small, random probes (noise matrices E) around you and see how high each probe lands (fitness f). Then, you adjust your own position (\u00b5) by moving towards the average direction of the *successful* probes. If a probe lands very high, its direction pulls you more strongly. This 'probing and averaging' (the E \u22c5 f(M) term) effectively nudges your central guess \u00b5 towards the area where the probes found higher ground, without ever needing to know the exact slope of the mountain itself. The Gaussian distribution makes these probes spread out in a predictable, useful way."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**29**\n5.1 The algorithm by Lov\u00b4asz, Saks, and Trotter . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.2 The randomized algorithm and its probabilistic model . . . . . . . . . . . . . . . . . . . . . 30\n5.3 Preliminaries for the analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 Analysis 1: Considering the level-2 terminals . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.5 Analysis 2: Increasing the layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35"}, {"role": "assistant", "content": "**Mechanism:** This section systematically dissects an algorithmic approach by first grounding it in an established method, then introducing a probabilistic variant, and finally, rigorously analyzing its behavior under specific operational conditions.\n\n**Explanation:** The core idea begins with understanding an existing deterministic algorithm (Lov\u00e1sz, Saks, and Trotter). The paper then presents a 'stochastic' or randomized version, which means it incorporates an element of chance, much like a coin flip. To understand this new algorithm, a 'probabilistic model' is established, which is like defining the odds and expected outcomes for its random choices. This is crucial for predicting its average performance, rather than its worst-case. The 'preliminaries' set up the necessary mathematical definitions and tools, akin to declaring all variables and functions before writing complex code. The two analysis phases (5.4 and 5.5) are like stress-testing the algorithm: one evaluates performance on a specific sub-structure or condition ('level-2 terminals'), while the other examines how its efficiency or effectiveness changes as the problem's complexity or scale increases ('increasing layers'). This comprehensive approach reveals the algorithm's strengths and weaknesses across different scenarios."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**RL Systems for LLMs** . Several systems aim to optimize\nthe training pipeline of Reinforcement Learning from Human Feedback (RLHF) [42]. Frameworks like DeepSpeedChat [65], GEAR [60], VeRL [53], FlexRLHF [64] and NeMoAligner [52] provide scalable end-to-end solutions, supporting various alignment algorithms and parallelism techniques.\nOthers focus on specific optimizations within the pipeline.\nRLHFuse [72] employs fine-grained scheduling and stage\nfusion to improve GPU utilization. ReaLHF [35] introduces\n\n12\n\ndynamic parameter reallocation to flexibly adapt 3D parallelism strategies across RLHF stages. Their optimization\nefforts primarily target the efficient management of multiple\nmodels inherent in the RLHF process. However, they neglect\na critical performance bottleneck in the rollout phase. This\noversight renders existing systems inefficient for reasoning RL tasks. Our work addresses this gap by concentrating\nspecifically on optimizing the rollout bottleneck, utilizing\nadaptive drafter which is orthogonal to prior systems. Recent\nefforts [12, 71] attempt to alleviate the synchronization constraint in RL by allowing stale responses for model updates.\nWhile such asynchronous strategies accelerate training, they\nrisk degrading model quality. In contrast, our approach preserves the original RL algorithm, ensuring lossless training\nperformance while achieving significant efficiency gains.\n**Speculative Decoding** . Speculative decoding [5, 22, 28] accelerates LLM inference by verifying candidate tokens in\nparallel with the target model, effectively increasing the\nnumber of tokens generated per step. Enhancements to speculative decoding encompass diverse strategies. Researchers\nhave explored retrieval-based methods [13, 16, 48], which\navoid the need to train an extra draft model. Others modify\nthe target model directly: Medusa [4] integrates multiple\nprediction heads, an approach refined by Hydra [2] which\nmodels correlations between these predictions. Furthermore,\nSpecInfer [36] innovatively employs tree-based speculative\ndecoding to broaden the candidate search space. OSD [31]\nleverages knowledge distillation for the drafter model so it\nremains aligned with distribution shifts in online serving.\nAdditionally, EAGLE [25\u201327] trains separate, compact autoregressive models as dedicated draft models. Further refining\nthis approach, HASS [67] improves draft model accuracy by\nsimulating multi-step predictions during training, mitigating\nthe training-inference inconsistency issue. Recent work also\nadapts speculative idea for efficient reasoning LLM inference.\nFor example, RSD [29] employs a reward model to guide the\nspeculation, and SpecReason [43] uses a lightweight model\nto speculatively execute intermediate reasoning steps. Unlike\nthese approaches designed for inference with static models,\nwe focus on the dynamic RL training scenario where the\ntarget model is continuously updated."}, {"role": "assistant", "content": "**Mechanism:** The core problem in Reinforcement Learning (RL) training for large language models (LLMs) is the 'rollout phase' where the LLM generates sequences of text. This is inherently sequential, like a loop iterating to build a string one character at a time. Traditional RLHF systems focus on distributing tasks across multiple processors, similar to using worker threads for different parts of a factory. However, they don't speed up the actual text generation loop itself. Our work introduces an 'adaptive drafter,' which acts as a predictive buffer or a fast, heuristic pre-processor. Instead of the main, large LLM generating one token at a time, the small, quick drafter proposes a chunk of tokens. The main LLM then only needs to validate this chunk in a single parallel step, rather than generating each token sequentially. This is analogous to a fast but approximate algorithm suggesting intermediate results that a slow but precise algorithm then verifies. 'Adaptive' means this drafter dynamically improves its predictions, akin to an auto-tuning cache, ensuring high hit rates. This is 'lossless' because the main LLM's full computational path is still followed for verification, unlike asynchronous training that might use out-of-date model states, similar to using a potentially stale value from a distributed cache.\n\n**Explanation:** Existing solutions for training LLMs with RL focus on managing the different big computational steps, like making sure all the different parts of a big factory are working together smoothly. But they missed that one part of the factory, the 'rollout' section where the main product (text) is made, is very slow because it builds one piece at a time. Our system adds a small, fast 'assistant' machine (the adaptive drafter) right into this slow section. This assistant quickly guesses many pieces at once, and the main machine then only needs to quickly check if the guesses are right, instead of building each piece from scratch. This is much faster. This idea, called 'speculative decoding,' is usually used when the main machine is finished learning and just making products. But we made it work even when the main machine is still learning and changing its mind, making sure it learns just as well but much faster."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis work has been conceived during our own research on multipath protocols and more specifically on MPTCP. While\n\nanyone interested to conduct research in this field may need to skim through multiple sources, we thought it would be\n\nuseful for the reader to have a single-point of reference where all the basic information around MPTCP protocol is\n\ncollected. To this end, Section 2 has been dedicated to providing the necessary details for a preliminary introduction to\n\nthe MPTCP protocol, its structure and architectural overview, as well as the main modules determining its operation.\n\nThis section provides also detailed information on the various packet scheduling and congestion control schemes,\n\nincluding both their theoretical and algorithmic aspects. To this end, five packet scheduling (i.e., minRTT, BLEST, ECF,\n\nRR, and LLHD) and seven congestion control algorithms (i.e., Cubic, Coupled/LIA, OLIA, BALIA, wVegas, BBR, and\n\nC-MPBBR) have been examined, in an attempt to cover the theoretical aspects before moving on with their performance\n\nevaluation. Section 3 provided the overall experimentation methodology, our Mininet environment topology, as well as\n\nthe underlying protocol and kernel configuration details, which we considered when preparing our experimentation\n\ntestbed. The same section included also details of the traffic methodology, the design of the experimentation scenarios,\n\nand the performance metrics used to assess the various algorithm combinations. Section 4 presented the experimentation\n\nresults of the various packet scheduling and congestion control algorithm combinations. The score metrics conceived\n\nto assist our evaluation as well as the main evaluation criteria (e.g., goodput and per-packet delay), have been also\n\npresented within this section. Section 5 concluded the core part of this work by providing a short summary on the\n\nbest-performing packet scheduling and congestion control schemes, while Section 6 provided details on the related\n\nwork present in literature.\n\nWhile this work serves as a starting point for anyone interested in studying the preliminaries of MPTCP, such as the\n\nbasic details around the protocol operation, as well as the available packet scheduling and congestion control schemes,\n\nit is not and cannot be a single point of study; however, appropriate references are provided to the original manuscripts\n\nand IETF RFCs, which provide the entire picture.\n\nFinally, the list of packet scheduling and congestion control algorithms that have been selected for our theoretical\n\nanalysis and the experiments, contains the ones considered as foundational and best-performing for MPTCP, laying\n\nessentially the groundwork for the development of many other algorithms, either unique or variations of existing ones.\n\n**Acknowledgments**\n\nThis research has been partially supported by the EU HORIZON SNS-JU projects: 6G-SANDBOX (GA: 101096328),\n\n6G-BRICKS (GA: 101096954), and SUNRISE-6G (GA: 101139257).\n\n**References**\n\n[1] S\u00e9bastien Barr\u00e9 et al. 2011. _Implementation and assessment of modern host-based multipath solutions._ Ph. D. Dissertation. Catholic University of\n\nLouvain, Louvain-la-Neuve, Belgium.\n\n[[2] Ethan Blanton, Dr. Vern Paxson, and Mark Allman. 2009. TCP Congestion Control. RFC 5681. doi:10.17487/RFC5681](https://doi.org/10.17487/RFC5681)\n\n[3] Olivier Bonaventure, Christoph Paasch, and Gregory Detal. 2017. Use Cases and Operational Experience with Multipath TCP. RFC 8041.\n\n[doi:10.17487/RFC8041](https://doi.org/10.17487/RFC8041)\n\n[4] Lawrence Sivert Brakmo. 1996. _End-to-end congestion detection and avoidance in wide area networks_ . The University of Arizona.\n\n[5] Lawrence S. Brakmo, Sean W. O\u2019Malley, and Larry L. Peterson. 1994. TCP Vegas: new techniques for congestion detection and avoidance. _SIGCOMM_\n\n_Comput. Commun. Rev._ [24, 4 (Oct. 1994), 24\u201335. doi:10.1145/190809.190317](https://doi.org/10.1145/190809.190317)\n\n[6] C. Paasch, S. Barre, et al. 2023. _Multipath TCP in the Linux Kernel_ [. Retrieved August 28, 2025 from https://www.multipath-tcp.org](https://www.multipath-tcp.org)\n\n[7] Canonical Ubuntu. 2024. _Download Ubuntu Desktop_ [. Canonical Ltd., London, UK. https://ubuntu.com/download/desktop](https://ubuntu.com/download/desktop)\n\n[[8] Y. Cao and E. Dong. 2021. wVegas CCA - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_wvegas.c)\n\n[mptcp/mptcp_wvegas.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_wvegas.c)\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 41\n\n[9] Yu Cao, Mingwei Xu, and Xiaoming Fu. 2012. Delay-based congestion control for multipath TCP. In _2012 20th IEEE international conference on_\n\n_network protocols (ICNP)_ . IEEE, 1\u201310.\n\n[10] Neal Cardwell, Yuchung Cheng, C Stephen Gunn, Soheil Hassas Yeganeh, and Van Jacobson. 2016. Bbr: Congestion-based congestion control:\n\nMeasuring bottleneck bandwidth and round-trip propagation time. _Queue_ 14, 5 (2016), 20\u201353.\n\n[11] Neal Cardwell, Yuchung Cheng, Soheil Hassas Yeganeh, and Van Jacobson. 2017. _BBR Congestion Control_ . Internet-Draft draft-cardwell-iccrg-bbr\n[congestion-control-00. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-cardwell-iccrg-bbr-congestion-control/00/ Work in](https://datatracker.ietf.org/doc/draft-cardwell-iccrg-bbr-congestion-control/00/)\n\nProgress.\n\n[12] Neal Cardwell, Yuchung Cheng, Soheil Hassas Yeganeh, Ian Swett, and Van Jacobson. 2022. _BBR Congestion Control_ . Internet-Draft draft-cardwell\n[iccrg-bbr-congestion-control-02. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-cardwell-iccrg-bbr-congestion-control/02/](https://datatracker.ietf.org/doc/draft-cardwell-iccrg-bbr-congestion-control/02/)\n\nWork in Progress.\n\n[13] Hendrik Cech. 2020. Analyzing and realizing multipath TCP schedulers in linux. _Technical University of Munich. PDF-dokumentti. Saatavissa:_\n\n_https://www. nitindermohan. com/documents/student-thesis/HendrikCechGR. pdf [viitattu 11.3. 2025]_ (2020).\n\n[14] Yuchung Cheng, Neal Cardwell, Soheil Hassas Yeganeh, and Van Jacobson. 2022. _Delivery Rate Estimation_ . Internet-Draft draft-cheng-iccrg-delivery\n[rate-estimation-02. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-cheng-iccrg-delivery-rate-estimation/02/ Work in](https://datatracker.ietf.org/doc/draft-cheng-iccrg-delivery-rate-estimation/02/)\n\nProgress.\n\n[[15] Ask Ubuntu community. 2019. Enable TCP probe. https://askubuntu.com/questions/1164562/tcp-probe-could-not-insert-tcp-probe](https://askubuntu.com/questions/1164562/tcp-probe-could-not-insert-tcp-probe)\n\n[[16] GitHub BBR community. 2024. Google BBR. https://github.com/google/bbr](https://github.com/google/bbr)\n\n[[17] MPTCP community. 2021. minRTT - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_sched.c)\n\n[mptcp_sched.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_sched.c)\n\n[[18] MPTCP community. 2024. Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/releases](https://github.com/multipath-tcp/mptcp/releases)\n\n[[19] MPTCP GitHub community. 2020. Meta-level OFO queue. https://github.com/multipath-tcp/mptcp/issues/394](https://github.com/multipath-tcp/mptcp/issues/394)\n\n[[20] MPTCP GitHub community. 2021. Measure MPTCP OFO packets. https://github.com/multipath-tcp/mptcp/issues/460](https://github.com/multipath-tcp/mptcp/issues/460)\n\n[[21] Mininet GitHub community. 2023. Mininet source code. https://github.com/mininet/mininet](https://github.com/mininet/mininet)\n\n[[22] MPTCP GitHub community. 2023. MPTCPv0. https://github.com/multipath-tcp/mptcp](https://github.com/multipath-tcp/mptcp)\n\n[[23] MPTCP GitHub community. 2025. MPTCPv1. https://github.com/multipath-tcp/mptcp_net-next](https://github.com/multipath-tcp/mptcp_net-next)\n\n[[24] PyShark GitHub community. 2025. PyShark. https://github.com/KimiNewt/pyshark](https://github.com/KimiNewt/pyshark)\n\n[25] Mininet Project Contributors. 2022. _Mininet_ [. Retrieved September 1, 2025 from https://mininet.org/](https://mininet.org/)\n\n[[26] Martin Duke. 2023. QUIC Version 2. RFC 9369. doi:10.17487/RFC9369](https://doi.org/10.17487/RFC9369)\n\n[[27] Martin Duke and Gorry Fairhurst. 2025. Specifying New Congestion Control Algorithms. RFC 9743. doi:10.17487/RFC9743](https://doi.org/10.17487/RFC9743)\n\n[[28] Wesley Eddy. 2022. Transmission Control Protocol (TCP). RFC 9293. doi:10.17487/RFC9293](https://doi.org/10.17487/RFC9293)\n\n[29] Simone Ferlin, \u00d6zg\u00fc Alay, Olivier Mehani, and Roksana Boreli. 2016. BLEST: Blocking estimation-based MPTCP scheduler for heterogeneous\n\nnetworks. In _2016 IFIP networking conference (IFIP networking) and workshops_ . IEEE, 431\u2013439.\n\n[[30] S. Ferlin and D. Weber. 2020. BLEST Scheduler Linux Kerner Code. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_blest.c)\n\n[blest.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_blest.c)\n\n[[31] Sally Floyd. 2000. Congestion Control Principles. RFC 2914. doi:10.17487/RFC2914](https://doi.org/10.17487/RFC2914)\n\n[[32] Sally Floyd and Mark Allman. 2007. Specifying New Congestion Control Algorithms. RFC 5033. doi:10.17487/RFC5033](https://doi.org/10.17487/RFC5033)\n\n[[33] Sally Floyd, Hari Balakrishnan, and Mark Allman. 2001. Enhancing TCP\u2019s Loss Recovery Using Limited Transmit. RFC 3042. doi:10.17487/RFC3042](https://doi.org/10.17487/RFC3042)\n\n[34] Sally Floyd, Mark Handley, and Jitendra Padhye. 2000. A comparison of equation-based and AIMD congestion control. (2000).\n\n[[35] Sally Floyd, Jamshid Mahdavi, Matt Mathis, and Dr. Allyn Romanow. 1996. TCP Selective Acknowledgment Options. RFC 2018. doi:10.17487/RFC2018](https://doi.org/10.17487/RFC2018)\n\n[36] Alan Ford, Costin Raiciu, Mark J. Handley, Olivier Bonaventure, and Christoph Paasch. 2020. TCP Extensions for Multipath Operation with Multiple\n\n[Addresses. RFC 8684. doi:10.17487/RFC8684](https://doi.org/10.17487/RFC8684)\n\n[[37] The Linux Foundation. 2016. TCP Probe. https://wiki.linuxfoundation.org/networking/tcpprobe](https://wiki.linuxfoundation.org/networking/tcpprobe)\n\n[[38] The Linux Foundation. 2025. The Linux Kernel Archives. https://www.kernel.org/](https://www.kernel.org/)\n\n[39] Alexander Frommgen, Tobias Erbsh\u00e4u\u00dfer, Alejandro Buchmann, Torsten Zimmermann, and Klaus Wehrle. 2016. ReMP TCP: Low latency multipath\n\nTCP. In _2016 IEEE international conference on communications (ICC)_ . IEEE, 1\u20137.\n\n[40] Andrei Gurtov, Tom Henderson, Sally Floyd, and Yoshifumi Nishida. 2012. The NewReno Modification to TCP\u2019s Fast Recovery Algorithm. RFC\n\n[6582. doi:10.17487/RFC6582](https://doi.org/10.17487/RFC6582)\n\n[[41] S. Ha and S. Hemminger. 2021. CUBIC CCA - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/ipv4/tcp_cubic.c)\n\n[ipv4/tcp_cubic.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/ipv4/tcp_cubic.c)\n\n[42] Sangtae Ha, Injong Rhee, and Lisong Xu. 2008. CUBIC: a new TCP-friendly high-speed TCP variant. _SIGOPS Oper. Syst. Rev._ 42, 5 (July 2008), 64\u201374.\n\n[doi:10.1145/1400097.1400105](https://doi.org/10.1145/1400097.1400105)\n\n[43] Jonas Hammar. 2022. _Multipath Packet Scheduling for 5G Systems_ . Master\u2019s thesis. Department of Mathematics and Computer Science, Karlstad\n\nUniversity.\n\n[44] Michio Honda, Yoshifumi Nishida, Lars Eggert, Pasi Sarolahti, and Hideyuki Tokuda. 2009. Multipath congestion control for shared bottleneck. In\n\n_Proc. PFLDNeT workshop_, Vol. 357. 378.\n\n[45] J. D. Hunter. 2007. Matplotlib: A 2D graphics environment. _Computing in Science & Engineering_ [9, 3 (2007), 90\u201395. doi:10.1109/MCSE.2007.55](https://doi.org/10.1109/MCSE.2007.55)\n\n42 D. Dimopoulos, et al.\n\n[46] Per Hurtig, Karl-Johan Grinnemo, Anna Brunstrom, Simone Ferlin, \u00d6zg\u00fc Alay, and Nicolas Kuhn. 2018. Low-latency scheduling in MPTCP.\n\n_IEEE/ACM transactions on networking_ 27, 1 (2018), 302\u2013315.\n\n[47] Geoff Huston. 2017. _BBR TCP_ [. Retrieved September 1, 2025 from https://www.potaroo.net/ispcol/2017-05/bbr.pdf](https://www.potaroo.net/ispcol/2017-05/bbr.pdf)\n\n[[48] J. Hwang, A. Walid, Q. Peng, and Low S. 2018. BALIA CCA - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_balia.c)\n\n[mptcp_v0.96/net/mptcp/mptcp_balia.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_balia.c)\n\n[49] iPerf GitHub Community. 2025. _iPerf: A tool for active measurements of the maximum achievable bandwidth on IP networks._ [https://github.com/](https://github.com/esnet/iperf)\n\n[esnet/iperf](https://github.com/esnet/iperf)\n\n[[50] iPerf Team. 2025. iPerf. https://iperf.fr/](https://iperf.fr/)\n\n[51] Jana Iyengar, Costin Raiciu, Sebastien Barre, Mark J. Handley, and Alan Ford. 2011. Architectural Guidelines for Multipath TCP Development. RFC\n\n[6182. doi:10.17487/RFC6182](https://doi.org/10.17487/RFC6182)\n\n[[52] Jana Iyengar and Martin Thomson. 2021. QUIC: A UDP-Based Multiplexed and Secure Transport. RFC 9000. doi:10.17487/RFC9000](https://doi.org/10.17487/RFC9000)\n\n[53] Van Jacobson. 1988. Congestion avoidance and control. _ACM SIGCOMM computer communication review_ 18, 4 (1988), 314\u2013329.\n\n[54] V. Jacobson, N. Cardwell, Y. Cheng, and S-H. Yeganeh. 2021. BBR CCA - Multipath TCP Linux Kernel v0.96. [https://github.com/multipath-](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/ipv4/tcp_bbr.c)\n\n[tcp/mptcp/blob/mptcp_v0.96/net/ipv4/tcp_bbr.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/ipv4/tcp_bbr.c)\n\n[[55] V. Jacobson, N. Cardwell, Y. Cheng, S-H. Yeganeh, and I. Mahmud. 2020. C-MPBBR CCA - Multipath TCP Linux Kernel v0.96. https://github.com/](https://github.com/imtiaztee/C-MPBBR/blob/master/mptcp_c-mpbbr.c)\n\n[imtiaztee/C-MPBBR/blob/master/mptcp_c-mpbbr.c](https://github.com/imtiaztee/C-MPBBR/blob/master/mptcp_c-mpbbr.c)\n\n[56] Dominik Kaspar. 2011. _Multipath Aggregation of Heterogeneous Access Networks_ . Ph. D. Dissertation. Faculty of Mathematics and Natural Sciences,\n\nOslo, Norway.\n\n[[57] R. Khalili, N. Gast, and Boudec J-Y. 2021. OLIA CCA - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_olia.c)\n\n[96/net/mptcp/mptcp_olia.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_olia.c)\n\n[58] Ramin Khalili, Nicolas Gast, Miroslav Popovic, and Jean-Yves Le Boudec. 2014. _Opportunistic Linked-Increases Congestion Control Algorithm for_\n\n_MPTCP_ [. Internet-Draft draft-khalili-mptcp-congestion-control-05. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-khalili-](https://datatracker.ietf.org/doc/draft-khalili-mptcp-congestion-control/05/)\n\n[mptcp-congestion-control/05/ Work in Progress.](https://datatracker.ietf.org/doc/draft-khalili-mptcp-congestion-control/05/)\n\n[59] Ramin Khalili, Nicolas Gast, Miroslav Popovic, and Jean-Yves Le Boudec. 2013. MPTCP is not pareto-optimal: performance issues and a possible\n\nsolution. _IEEE/ACM Trans. Netw._ [21, 5 (Oct. 2013), 1651\u20131665. doi:10.1109/TNET.2013.2274462](https://doi.org/10.1109/TNET.2013.2274462)\n\n[60] Bruno YL Kimura, Demetrius CSF Lima, and Antonio AF Loureiro. 2020. Packet scheduling in multipath TCP: Fundamentals, lessons, and\n\nopportunities. _IEEE Systems Journal_ 15, 1 (2020), 1445\u20131457.\n\n[61] Nicolas Kuhn, Emmanuel Lochin, Ahlem Mifdaoui, Golam Sarwar, Olivier Mehani, and Roksana Boreli. 2014. DAPS: Intelligent delay-aware packet\n\nscheduling for multipath transport. In _2014 IEEE international conference on communications (ICC)_ . IEEE, 1222\u20131227.\n\n[62] Bob Lantz, Brandon Heller, and Nick McKeown. 2010. A network in a laptop: rapid prototyping for software-defined networks. In _Proceedings of the_\n\n_9th ACM SIGCOMM Workshop on Hot Topics in Networks_ (Monterey, California) _(Hotnets-IX)_ . Association for Computing Machinery, New York, NY,\n\n[USA, Article 19, 6 pages. doi:10.1145/1868447.1868466](https://doi.org/10.1145/1868447.1868466)\n\n[[63] Y. Lim and D. Weber. 2020. ECF Scheduler Linux Kerner Code. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_ecf.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_ecf.c)\n\n[64] Yeon-sup Lim, Erich M Nahum, Don Towsley, and Richard J Gibbens. 2017. ECF: An MPTCP path scheduler to manage heterogeneous paths. In\n\n_Proceedings of the 13th international conference on emerging networking experiments and technologies_ . 147\u2013159.\n\n[65] Yanmei Liu, Yunfei Ma, Quentin De Coninck, Olivier Bonaventure, Christian Huitema, and Mirja K\u00fchlewind. 2025. _Multipath Extension for QUIC_ .\n\n[Internet-Draft draft-ietf-quic-multipath-16. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-ietf-quic-multipath/16/ Work in](https://datatracker.ietf.org/doc/draft-ietf-quic-multipath/16/)\n\nProgress.\n\n[[66] T. Lubna and I. Mahmud. 2022. Delay-Data Rate Scheduler Linux Kerner Code. https://github.com/imtiaztee/DRS](https://github.com/imtiaztee/DRS)\n\n[67] Tabassum Lubna, Imtiaz Mahmud, and You-Ze Cho. 2022. Low latency and high data rate (LLHD) scheduler: a multipath TCP scheduler for dynamic\n\nand heterogeneous networks. _Sensors_ 22, 24 (2022), 9869.\n\n[68] Imtiaz Mahmud, Tabassum Lubna, Yeong-Jun Song, and You-Ze Cho. 2020. Coupled multipath BBR (C-MPBBR): A efficient congestion control\n\nalgorithm for multipath TCP. _IEEE access_ 8 (2020), 165497\u2013165511.\n\n[[69] Christoph Paasch. 2019. RR - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_rr.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_rr.c)\n\n[[70] C. Paasch and S. Barr\u00e9. 2018. LIA CCA - Multipath TCP Linux Kernel v0.96. https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_coupled.c)\n\n[mptcp_coupled.c](https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.96/net/mptcp/mptcp_coupled.c)\n\n[71] Christoph Paasch, Simone Ferlin, Ozgu Alay, and Olivier Bonaventure. 2014. Experimental evaluation of multipath TCP schedulers. In _Proceedings_\n\n_of the 2014 ACM SIGCOMM workshop on Capacity sharing workshop_ . ACM, New York, USA, 27\u201332.\n\n[72] Christoph Paasch, Ramin Khalili, and Olivier Bonaventure. 2013. On the benefits of applying experimental design to improve multipath TCP. In\n\n_Proceedings of the Ninth ACM Conference on Emerging Networking Experiments and Technologies_ (Santa Barbara, California, USA) _(CoNEXT \u201913)_ .\n\n[Association for Computing Machinery, New York, NY, USA, 393\u2013398. doi:10.1145/2535372.2535403](https://doi.org/10.1145/2535372.2535403)\n\n[[73] Dr. Vern Paxson and Mark Allman. 2000. Computing TCP\u2019s Retransmission Timer. RFC 2988. doi:10.17487/RFC2988](https://doi.org/10.17487/RFC2988)\n\n[74] Qiuyu Peng, Anwar Walid, Jaehyun Hwang, and Steven H Low. 2014. Multipath TCP: Analysis, design, and implementation. _IEEE/ACM Transactions_\n\n_on networking_ 24, 1 (2014), 596\u2013609.\n\n[[75] Ren\u00e9 Pfeiffer. 2007. Measuring TCP Congestion Windows. https://linuxgazette.net/136/pfeiffer.html](https://linuxgazette.net/136/pfeiffer.html)\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 43\n\n[76] Michele Polese, Federico Chiariotti, Elia Bonetto, Filippo Rigotto, Andrea Zanella, and Michele Zorzi. 2019. A survey on recent advances in transport\n\nlayer protocols. _IEEE Communications Surveys & Tutorials_ 21, 4 (2019), 3584\u20133608.\n\n[77] Python Core Team. 2024. _Python: A dynamic, open source programming language_ [. Python Software Foundation. https://www.python.org/ Python](https://www.python.org/)\n\nversion 3.10.\n\n[[78] Costin Raiciu, Mark J. Handley, and Damon Wischik. 2011. Coupled Congestion Control for Multipath Transport Protocols. RFC 6356. doi:10.17487/](https://doi.org/10.17487/RFC6356)\n\n[RFC6356](https://doi.org/10.17487/RFC6356)\n\n[79] Costin Raiciu, Christoph Paasch, Sebastien Barre, Alan Ford, Michio Honda, Fabien Duchene, Olivier Bonaventure, and Mark Handley. 2012.\nHow hard can it be? designing and implementing a deployable multipath {TCP}. In _9th USENIX symposium on networked systems design and_\n\n_implementation (NSDI 12)_ . USENIX, 399\u2013412.\n\n[80] Swetank Kumar Saha, Shivang Aggarwal, Rohan Pathak, Dimitrios Koutsonikolas, and Joerg Widmer. 2019. MuSher: An agile multipath-TCP\n\nscheduler for dual-band 802.11 ad/AC wireless LANs. In _The 25th Annual International Conference on Mobile Computing and Networking_ . 1\u201316.\n\n[[81] Matt Sargent, Jerry Chu, Dr. Vern Paxson, and Mark Allman. 2011. Computing TCP\u2019s Retransmission Timer. RFC 6298. doi:10.17487/RFC6298](https://doi.org/10.17487/RFC6298)\n\n[82] Stefan Savage, Neal Cardwell, David Wetherall, and Tom Anderson. 1999. TCP congestion control with a misbehaving receiver. _ACM SIGCOMM_\n\n_Computer Communication Review_ 29, 5 (1999), 71\u201378.\n\n[[83] Michael Scharf and Alan Ford. 2013. Multipath TCP (MPTCP) Application Interface Considerations. RFC 6897. doi:10.17487/RFC6897](https://doi.org/10.17487/RFC6897)\n\n[[84] Reinhard Schrage, Gilles Forget, Ruediger Geib, and Barry Constantine. 2011. Framework for TCP Throughput Testing. RFC 6349. doi:10.17487/](https://doi.org/10.17487/RFC6349)\n\n[RFC6349](https://doi.org/10.17487/RFC6349)\n\n[85] Anwar Walid, Qiuyu Peng, Jaehyun Hwang, and Steven H. Low. 2016. _Balanced Linked Adaptation Congestion Control Algorithm for MPTCP_ .\n\n[Internet-Draft draft-walid-mptcp-congestion-control-04. Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-walid-mptcp-](https://datatracker.ietf.org/doc/draft-walid-mptcp-congestion-control/04/)\n\n[congestion-control/04/ Work in Progress.](https://datatracker.ietf.org/doc/draft-walid-mptcp-congestion-control/04/)\n\n[[86] Wikipedia contributors. 2025. TCP congestion control \u2014 Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title=TCP_](https://en.wikipedia.org/w/index.php?title=TCP_congestion_control&oldid=1308091666)\n\n[congestion_control&oldid=1308091666 [Online; accessed 28-August-2025].](https://en.wikipedia.org/w/index.php?title=TCP_congestion_control&oldid=1308091666)\n\n[87] Damon Wischik, Mark Handley, and Marcelo Bagnulo Braun. 2008. The resource pooling principle. _ACM SIGCOMM Computer Communication_\n\n_Review_ 38, 5 (2008), 47\u201352.\n\n[88] Damon Wischik, Costin Raiciu, Adam Greenhalgh, and Mark Handley. 2011. Design, implementation and evaluation of congestion control for\nmultipath {TCP}. In _8th USENIX Symposium on Networked Systems Design and Implementation (NSDI 11)_ .\n\n[[89] Lisong Xu, Sangtae Ha, Injong Rhee, Vidhi Goel, and Lars Eggert. 2023. CUBIC for Fast and Long-Distance Networks. RFC 9438. doi:10.17487/RFC9438](https://doi.org/10.17487/RFC9438)\n\n[90] Mingwei Xu, Yu Cao, and Enhuan Dong. 2017. _Delay-based Congestion Control for MPTCP_ . Internet-Draft draft-xu-mptcp-congestion-control-05.\n\n[Internet Engineering Task Force. https://datatracker.ietf.org/doc/draft-xu-mptcp-congestion-control/05/ Work in Progress.](https://datatracker.ietf.org/doc/draft-xu-mptcp-congestion-control/05/)\n\n[91] Fan Yang, Qi Wang, and Paul D Amer. 2014. Out-of-order transmission for in-order arrival scheduling for multipath TCP. In _2014 28th international_\n\n_conference on advanced information networking and applications workshops_ . IEEE, 749\u2013752.\n\n[92] Ming Zhang, Junwen Lai, Arvind Krishnamurthy, Larry L Peterson, and Randolph Y Wang. 2004. A Transport Layer Approach for Improving\n\nEnd-to-End Performance and Robustness Using Redundant Paths.. In _USENIX Annual Technical Conference, General Track_ . 99\u2013112.\n\n44 D. Dimopoulos, et al.\n\n**A** **Packet Scheduling Algorithms**\n\n**Algorithm 1:** minRTT\n\n**Input:** Set of available subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R\n\n**Output:** Best subflow, _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2208S\n\n**1** _\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5a\ud835\udc56\ud835\udc5b_ \u2190 0 _\ud835\udc65\ud835\udc53\ud835\udc53\ud835\udc53\ud835\udc53\ud835\udc53\ud835\udc53\ud835\udc53\ud835\udc53_ ;\n\n**2** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc41\ud835\udc48\ud835\udc3f\ud835\udc3f_ ;\n\n**3 for** _each \ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S **do**"}, {"role": "assistant", "content": "**Mechanism:** Multipath TCP (MPTCP) allows a single data flow from an application to simultaneously utilize multiple distinct network paths, effectively creating a 'super-highway' from several individual 'roads' or subflows. Each subflow is a standard TCP connection. The two main control mechanisms discussed are packet scheduling and congestion control. Packet scheduling decides which of these available subflows an outgoing data packet should use. For instance, the 'minRTT' scheduler constantly measures the Round-Trip Time (RTT) of each subflow and then assigns packets to the path that currently has the lowest RTT, behaving like an algorithm that finds the minimum value in an array of RTTs and selects the corresponding index. 'Round Robin (RR)' scheduling, conversely, simply cycles through the available subflows in a sequential manner, distributing packets evenly. This is akin to using a counter variable that increments, then applies a modulo operation to an array of subflows to pick the next one. Congestion control, applied to each subflow, regulates the data sending rate to prevent network overload. Algorithms like Cubic or BBR operate as feedback loops: they send data, monitor network health (e.g., packet loss, latency changes, available bandwidth), and dynamically adjust internal state variables (like the 'congestion window' or sending rate) to either increase or decrease throughput. For example, detecting packet loss typically triggers a reduction in the sending rate, much like an 'if (loss_detected) { reduce_rate; }' conditional statement.\n\n**Explanation:** MPTCP's fundamental mechanism is to aggregate multiple network paths into one logical connection, like having several distinct internet cables connected to your computer that work as one bigger, faster cable. The paper breaks down how two critical parts of this system work intuitively. First, 'packet scheduling' is the intelligence that decides which piece of data (a packet) should travel over which specific path (a subflow). Imagine you have several delivery routes to your friend's house. A 'minRTT' scheduler is like a very smart dispatcher who constantly checks which route currently gets a small test package to your friend and back the fastest. It then sends your actual message pieces down that quickest route. This is essentially an ongoing 'find the minimum' operation on network delay values. A 'Round Robin' scheduler is much simpler; it just takes turns sending packets down each path, one after another, regardless of how busy they are, like a simple 'for loop' iterating through options. Second, 'congestion control' is the system that prevents any single path from becoming overloaded. Each path has its own traffic light. If the system observes too much traffic (high latency or lost packets), it tells the sender to slow down, easing the pressure. Different congestion control algorithms (like Cubic or BBR) use different rules for how they detect congestion and how aggressively they speed up or slow down. The core principle is a continuous 'sense and react' cycle: measure network conditions, infer congestion, and adjust the amount of data being sent, similar to a program continuously monitoring system resources and adjusting its behavior based on predefined thresholds."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc36\ud835\udc4a\ud835\udc41\ud835\udc37\ud835\udc58_ _\ud835\udc60_ [\u2217] _[\ud835\udc45\ud835\udc47\ud835\udc47][\ud835\udc60]_ [\u2265] [2][ \u2217] _[\ud835\udc45\ud835\udc47\ud835\udc47][\ud835\udc53]_ [+] _[ \ud835\udeff]_ **[then]**\n\n**10** _\ud835\udc64\ud835\udc4e\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54_ = 1 ; /* Wait for _\ud835\udc65_ _\ud835\udc53_ */\n\n**11** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc41\ud835\udc48\ud835\udc3f\ud835\udc3f_ ; /* no available subflow */"}, {"role": "assistant", "content": "**Mechanism:** This code implements a heuristic control mechanism for dynamic network path selection, where 'waiting' acts as a flag to pause data transmission on a highly underperforming subflow, and 'sfbest' is nulled to force a re-evaluation of optimal paths.\n\n**Explanation:** The condition `CWNDk_s * RTT_s >= 2 * RTT_f + d` is a decision point. `CWNDk_s * RTT_s` can be thought of as an estimate of the 'effective delay' or 'queue build-up time' for the current subflow `k`. It measures how much outstanding data (CWND) is taking how long (RTT) to go back and forth. This is compared against a threshold derived from the `RTT_f` of the fastest observed subflow, doubled and with an added buffer `d`. The doubling factor and buffer ensure that we only react when a subflow is *significantly* worse, not just marginally. If the current subflow's effective delay is excessively high compared to this threshold, it implies severe underperformance. In such a case, the system sets a `waiting` flag (like a boolean variable `bool waiting = true;`) to indicate that data should not be sent on this path. Concurrently, `sfbest` is set to `NULL` (similar to assigning `nullptr` or `None`), which effectively clears the pointer to the previously considered 'best' subflow, signaling that the system needs to find a new, more efficient path for future data transmission."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**3.1** **Overview**\n\nDynaExq provides adaptive expert precision control for MoE inference by treating precision as a runtime-managed resource rather\nthan a fixed configuration. Instead of relying on offline PTQ decisions that assume static activation distributions, DynaExq continuously monitors expert usage and adjusts precision according to\nlong-term activation salience. This enables hot experts to retain accurate high-precision weights, while cold experts are aggressively\ncompressed to reduce the overall HBM footprint without affecting\nthe forward path.\nAs shown in Fig. 2, DynaExq consists of four coordinated components:\n\n - (1) **Expert Precision Controller**, which aggregates router\nstatistics, identifies persistently activated experts, and issues\npromotion or demotion commands.\n\n - (2) **Asynchronous Precision Switching Pipeline**, which\ntransfers expert weights across SSD, DRAM, and HBM with full\ncompute\u2013communication overlap.\n\n - (3) **Memory Pool Manager**, which maintains deterministic,\nfragmentation-free memory allocation for mixed-precision experts.\n\n - (4) **Resource-Aware Initialization Module**, which establishes\nper-layer precision budgets that guarantee memory stability\nunder variable workloads.\n\nTogether, these components support accuracy-aware precision allocation, non-blocking transitions, and stable throughput. By decoupling precision switching from the critical compute path, DynaExq\nsustains aggressive memory savings even when expert usage shifts\n\nover time.\n\n**3.2** **Runtime Expert Precision Controller**\n\nThe controller maintains a lightweight profile of expert behavior by\nsampling router outputs during inference. After each forward pass,\nDynaExq records the selected experts and accumulates gating probabilities, providing a workload-driven view of expert importance\nrather than relying on synthetic calibration data.\nFor each expert _\ud835\udc56_, the exponential-moving-average (EMA) hotness score within a window of length _\ud835\udc47_ is:\n\n_\ud835\udc46\ud835\udc56_ [(] _[\ud835\udc61]_ [)] = _\ud835\udefc\ud835\udc46\ud835\udc56_ [(] _[\ud835\udc61]_ [\u2212][1][)] + (1 \u2212 _\ud835\udefc_ ) _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65\ud835\udc61_ ) _,_ (2)\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-2-0.png)\n\n|U|Col2|\n|---|---|\n|High-precision|Low-precision|\n|High-precision|KV-Cache|\n\n**Figure 2: System architecture of DynaExq.**\n\n**Algorithm 1** Runtime Precision Scheduling for MoE Experts\n\n1: **Input:** Router probabilities _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65\ud835\udc61_ ) for experts _\ud835\udc56_ = 1 _..\ud835\udc41_\n\n2: **State:** EMA hotness scores _\ud835\udc46\ud835\udc56_, precision state state[ _\ud835\udc56_ ] \u2208\n{HIGH _,_ LOW}\n\n3: **Parameter:** Update period _\ud835\udc47_, EMA factor _\ud835\udefc_, threshold _\ud835\udf0f_ (derived from memory budget)\n\n4: **procedure** UpdateHotness( _\ud835\udc61_ )\n\n5: **for** each activated expert _\ud835\udc56_ at step _\ud835\udc61_ **do**\n\n6: _\ud835\udc46\ud835\udc56_ \u2190 _\ud835\udefc\ud835\udc46\ud835\udc56_ + (1 \u2212 _\ud835\udefc_ ) _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65\ud835\udc61_ )\n\n7: **end for**\n\n8: **for** each inactive expert _\ud835\udc57_ **do**\n\n9: _\ud835\udc46_ _\ud835\udc57_ \u2190 _\ud835\udefc\ud835\udc46_ _\ud835\udc57_ _\u22b2_ passive decay\n\n10: **end for**\n\n11: **end procedure**\n\n12: **procedure** PrecisionSchedule( _\ud835\udc61_ )\n\n13: **if** _\ud835\udc61_ mod _\ud835\udc47_ = 0 **then**\n\n14: Sort experts by _\ud835\udc46\ud835\udc56_ in descending order\n\n15: H \u2190 top- _\ud835\udc3e_ experts with _\ud835\udc46\ud835\udc56_ \u2265 _\ud835\udf0f_\n\n16: **for** each expert _\ud835\udc56_ **do**\n\n17: **if** _\ud835\udc56_ \u2208H and state[ _\ud835\udc56_ ] = LOW **then**\n\n18: EnqeueUpgrade( _\ud835\udc56_ )\n\n19: **else if** _\ud835\udc56_ \u2209 H and state[ _\ud835\udc56_ ] = HIGH **then**\n\n20: EnqeueDowngrade( _\ud835\udc56_ )\n\n21: **end if**\n\n22: **end for**\n\n23: **end if**\n\n24: **end procedure**\n\nwhere _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65\ud835\udc61_ ) is the router probability at step _\ud835\udc61_ . This formulation\ncaptures both activation frequency and magnitude, while smoothing short-term spikes. Experts with _\ud835\udc46\ud835\udc56_ above the high-precision\nthreshold _\ud835\udf0f\u210e_ are promoted, while the remaining experts form the\nlow-precision candidate pool (as shown in Algo-1).\nTo ensure robust scheduling under fluctuating workloads, the\ncontroller operates at coarse granularity and applies smoothing to\navoid oscillations. Precision updates occur periodically rather than\nper batch, preventing thrashing when gating behavior is unstable.\n\n**MoE**\n\n**Inference**\n\n**H2D**\n\n**Transfer**\n\n**SSD**\n\n**Prefetch**\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n||**ei**|**ej**|**ek**|**em**|**en**|||\n|||||||||\n\n|Col1|Col2|Col3|downgrade|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n||**upgradeek**||||**upgrade e**|||\n||||**en**|**en**|**x**|**x**|**x**|\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n||**Fetche**|||\n||**n**|**n**|**n**|\n\n**Figure 3: An example of Asynchronous Expert Swapping**\n**Pipeline.**\n\nBecause all operations execute on the CPU and do not block GPU\nkernels, the controller imposes no latency overhead on inference.\nThese mechanisms allow DynaExq to detect persistent hot experts reliably, enforce stable precision decisions, and preserve routing fidelity under strict memory constraints.\n\n**3.3** **Asynchronous Expert Swapping Pipeline**\n\nTo support continuous inference while precision changes occur\nin the background, DynaExq employs a multi-stage asynchronous\npipeline that overlaps promotion, demotion, and prefetching with\nMoE computation. High-precision and low-precision weights are\nstored on SSD and cached in DRAM, and all transfers to HBM use\n\ndedicated CUDA streams.\n\nWhen a cold expert becomes hot, the runtime triggers a nonblocking upgrade sequence: the high-precision weight is fetched\nfrom SSD (if not cached), buffered in DRAM, and streamed into\nHBM. After the transfer completes, a lightweight registration step\nbinds the new weight to the expert\u2019s compute context, and the\nlow-precision version is reclaimed immediately. Demotion mirrors\nthis process in reverse.\nDuring inference, DynaExq always uses the last stable version\nof each expert. If a promotion is in flight, the previous representation remains active, ensuring that pipeline latency never affects\nthe forward pass. This provenance-consistent strategy prevents\ncorrectness issues and avoids compute stalls even under highly\ndynamic workloads.\nTo further hide data movement latency, DynaExq proactively\nprefetches experts predicted to become hot by leveraging crosslayer activation correlations. As illustrated in Fig. 3, SSD prefetch,\nDRAM buffering, H2D transfers, and demotions proceed concurrently beneath ongoing computation, enabling smooth precision\n\ntransitions.\n\n**3.4** **Memory Pool Management**\n\nBecause precision switching changes expert storage sizes, na\u00efvely\nusing the GPU allocator can cause fragmentation and unpredictable\nmemory growth. To prevent this, DynaExq partitions HBM into\ntwo dedicated pools for high- and low-precision experts. Each pool\nis subdivided into fixed-size blocks aligned with the corresponding data format (e.g., FP16 or INT4), enabling constant-time and\nfragmentation-free allocation.\nDuring precision transitions, DynaExq immediately reclaims the\nold representation once the new weight is successfully registered,\nensuring that no expert holds dual copies longer than necessary.\nA small transient buffer absorbs transfer bursts, allowing multiple\nin-flight promotions without exceeding the memory budget.\n\nKexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Lin, and Wei Zhang\n\nA compact CPU-side index records expert locations, precision\ntiers, and pool occupancy. Because this index is managed outside the\nGPU allocator, DynaExq avoids runtime cudaMalloc calls and eliminates allocator-induced jitter. This deterministic memory structure\nmaintains stable throughput even when experts frequently change\nprecision.\nBy imposing structure on the memory hierarchy and ensuring deterministic allocation rules, DynaExq provides predictable\nmemory behavior and safe operation under aggressive dynamic\nquantization.\n\n**3.5** **Resource-Aware Threshold Initialization**\n\nBefore inference begins, DynaExq computes safe precision budgets\nfor each MoE layer to ensure that dynamic switching never violates\nHBM constraints. Let _\ud835\udc40_ HBM denote available memory after reserving space for KV-cache, activations, and shared weights. Given the\naverage storage sizes of high-precision and low-precision experts,\n_\ud835\udc46_ [hot] and _\ud835\udc46_ [cold], and the number of experts _\ud835\udc41_, DynaExq computes\nfeasible values of _\ud835\udc5b_ hot and _\ud835\udc5b_ cold that satisfy:\n\n_\ud835\udc5b_ hot \u00b7 _\ud835\udc46_ [hot] + _\ud835\udc5b_ cold \u00b7 _\ud835\udc46_ [cold] \u2264 _\ud835\udc40_ HBM _,_\n\nWhere _\ud835\udc5b_ hot + _\ud835\udc5b_ cold = _\ud835\udc41_ and _\ud835\udf0f\u210e_ = _\ud835\udc61\ud835\udc5c\ud835\udc5d_ ( _\ud835\udc5b\u210e\ud835\udc5c\ud835\udc61,\ud835\udc46\ud835\udc56_ ). A brief warmup\nphase collects initial hotness scores, and the top- _\ud835\udc5b_ hot experts initialize the high-precision set. The threshold _\ud835\udf0f\u210e_ remains fixed while\nexpert identities may change at runtime based on observed activity.\nBy separating memory feasibility analysis from runtime scheduling, DynaExq guarantees that all precision transitions remain\nmemory-safe even under shifting workloads. This initialization step\nforms the foundation for predictable and stable mixed-precision\n\nexecution."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a dynamic, runtime-adaptive memory management system for Mixture-of-Experts (MoE) models. It fundamentally shifts from static, pre-determined precision assignments to a continuous monitoring and adjustment process.  It achieves this by: 1) tracking expert 'hotness' using an Exponential Moving Average (EMA) of router probabilities, which acts like a decaying counter, giving more weight to recent activity. This EMA score determines an expert's importance over time, smoothing out transient spikes. 2) Periodically (not per inference step) sorting experts by this score and comparing them against a memory-budget-derived threshold, `tau`, to identify which experts should be in high-precision (e.g., FP16) and which can be aggressively compressed (e.g., INT4). 3) Utilizing an asynchronous, multi-stage pipeline with dedicated CUDA streams to perform precision upgrades (e.g., fetching FP16 from SSD/DRAM to HBM) and downgrades in the background, entirely decoupled from the GPU's forward pass computation. This ensures inference continues without stalls, always using the last stable version of an expert. 4) Employing a custom memory pool manager that pre-allocates fixed-size blocks for high and low precision experts, analogous to an arena allocator, to prevent memory fragmentation and ensure deterministic allocation times. A compact CPU-side index, like a hash map, tracks expert metadata, avoiding expensive GPU memory calls. 5) Establishing initial memory budgets (`n_hot`, `n_cold`) at startup based on available HBM, ensuring that the total memory footprint never exceeds capacity, even with dynamic switching.\n\n**Explanation:** The system addresses the problem of large MoE models consuming excessive GPU High Bandwidth Memory (HBM). By treating expert precision as a dynamically managed resource, it ensures that only currently 'important' or 'hot' experts reside in HBM at high precision, while less critical 'cold' experts are aggressively quantized and potentially offloaded to slower memory tiers like DRAM or SSD. The exponential moving average (EMA) for expert 'hotness' functions like a weighted historical average, allowing the system to react to sustained usage patterns while ignoring momentary fluctuations. This `S_i(t) = alpha * S_i(t-1) + (1 - alpha) * g_i(x_t)` calculation ensures that an expert's importance slowly grows if it's consistently activated, and slowly decays if it's inactive. The system then periodically re-evaluates and sorts these scores. The asynchronous pipeline is critical; it's like having separate background threads for data transfer. When an expert needs to change precision, the old version remains active until the new version is fully prepared and registered, preventing any compute stalls. The dedicated memory pools for different precision levels, instead of general-purpose `cudaMalloc` calls, prevent the memory from becoming fragmented, which can lead to unpredictable performance and memory exhaustion. Finally, the initial memory budgeting sets a hard constraint on how many high-precision experts can ever exist, making the entire dynamic process memory-safe."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**More Application Scenarios** . In this work, we primarily\ninvestigate how speculative decoding can accelerate RL training by mitigating long-tail rollouts. We believe this technique\nalso opens promising avenues for broader applications. For\nexample: (1) _Uniformly long responses_ . When all rollouts are\nlong and no tail exists, each request demands substantial\nKV-cache capacity. This often makes the system KV-cachebound and triggers request eviction, limiting the running\nbatch size. In such cases, the workload naturally falls into\nthe \u201csweet spot\" of speculative decoding, enabling decoding\nacceleration. (2) _Multi-turn rollouts with tool-calling RL_ . In\nmulti-turn RL settings involving tool calls, partial requests\nperform GPU-free tool executions while their KV caches remain resident on the GPU. This reduces the number of active\n\ndecoding requests and again creates a favorable regime for\nspeculative decoding under our approach. (3) _Online serving_\n_and edge deployment_ . When the target model is fixed, a draft\nmodel trained via TLT can be directly deployed for inference.\nAdaptive speculative decoding remains highly effective in\nthese deployment scenarios, especially for handling variable\n\n**Figure 17. Effect of selective asynchronous checkpoint-**\n**ing and sequence packing.**\n\nload. Extending our approach to these settings is an exciting\ndirection for future work.\n\n**Can We Break RL Synchronization** ? TLT aims to improve RL training efficiency without modifying on-policy\nrequirements of the underlying algorithm. One may wonder whether it is possible to further accelerate training by\nasynchronously updating the model with partial rollouts during long decoding phases. While appealing, this approach\nrisks altering the underlying RL algorithm and potentially\nharming convergence and model performance. Asynchronous RL typically mixes multiple policy versions within a\nsingle rollout, potentially biasing gradient estimation and\nshifting the learning dynamics (e.g., drifting from on-policy\nto off-policy). Additional algorithmic modifications are required to safely accommodate such paradigm [12]. A more\nbalanced approach is to allow limited asynchrony that preserves algorithmic correctness while improving hardware\nutilization. Even under such settings, the heavy-tail rollout\nproblem remains, and our speculative decoding approach\ncan be combined with limited asynchronous RL to further\naccelerate training _without_ introducing additional loss or\npolicy staleness, leaving this as an intriguing direction for\nfuture work.\n\n**Can TLT be applied to other RL algorithms** ? GRPO represents a widely used algorithmic structure for reasoning RL.\nAlternatives such as RLOO [1], DAPO [66], REINFORCE [61],\nand REINFORCE++ [18] generally share the same overall\ntraining workflow, differing mainly in their reward formulations and use of KL-regularization. These algorithmic variations remain fully compatible with our adaptive drafter\nand spot-training design, suggesting that TLT can readily\naccelerate a broad class of RL methods."}, {"role": "assistant", "content": "**Mechanism:** Imagine you have two functions: 'expensive_function(input)' and 'cheap_function(input)'. 'expensive_function' takes a long time to run for each 'input'. 'cheap_function' is much faster but sometimes makes mistakes. Speculative decoding uses 'cheap_function' to quickly generate a *sequence* of guessed outputs. Then, 'expensive_function' is called *once* on this whole sequence. It rapidly checks if 'cheap_function's guesses were right, perhaps by performing a few simple checks in parallel. If all guesses are correct up to a certain point, 'expensive_function' effectively processes many steps in one go. If 'cheap_function' made a mistake, 'expensive_function' stops at the error, corrects it, and then 'cheap_function' tries guessing again from that corrected point. This massively reduces the number of times 'expensive_function' has to be called sequentially for individual steps, speeding up overall sequence generation.\n\n**Explanation:** In Reinforcement Learning (RL) training, the 'rollout' phase is like running a simulation for many steps to see how an agent behaves. This often involves the main policy making decisions one step at a time. Speculative decoding inserts a 'draft policy' that quickly *predicts* many future actions in a sequence. The main policy then acts as a rapid verifier. Instead of computing each action sequentially, it can validate several actions in parallel, similar to how a batch processing system works. This significantly cuts down the total computational cost of generating long rollouts, especially those 'long-tail' sequences that usually take a very long time. For scenarios where all responses are uniformly long, the system often hits a memory bottleneck (KV-cache-bound). Speculative decoding reduces the *effective* computation for each response by validating multiple steps at once, allowing more work to be done per memory access. For multi-turn tool-calling, when the main GPU is waiting for an external tool (an I/O block), the draft model can continue to 'speculate,' keeping the GPU busy with useful work rather than idling. This is akin to asynchronous I/O, where the CPU can do other tasks while waiting for disk operations. TLT (Target-Length Training) enhances this by helping train the draft model effectively. Finally, since many RL algorithms share the same basic loop of 'generate experience' then 'learn from experience,' this acceleration technique is broadly applicable to the 'generate experience' part, regardless of the specific mathematical formulation of learning. The idea of 'breaking synchronization' is about parallelizing updates, but it risks using 'stale' data (an older policy version) to update the current policy, which can destabilize learning. Speculative decoding offers speedup *within* rollout generation without altering the fundamental on-policy requirement."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ _>_ 1 **and** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ _>_ 1 **then**\n\n**30** _\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ ;"}, {"role": "assistant", "content": "**Mechanism:** This is a conditional assignment statement, analogous to an 'if' block in programming, where a variable is updated only when specific criteria are met. The mechanism relies on a logical AND operation between a current state check and a conditionally applied historical state check.\n\n**Explanation:** Think of this as a guard clause in code. We're trying to set a 'finalCount' (the final number of 'SFs' in the bottleneck) based on a 'currentCount' (the number of 'SFs' in the bottleneck). The conditions are: First, 'currentCount' must be greater than 1. Second, there's a nuanced 'implies' condition: if a flag 'cmpbbr' (like 'shouldComparePrevious') is true, then 'previousCount' (the last number of 'SFs' in the bottleneck) *must also* be greater than 1. If 'cmpbbr' is false, this second part is skipped entirely. So, the 'finalCount' is only updated if the 'currentCount' is significant, AND, if we're configured to compare, the 'previousCount' was also significant. This prevents transient spikes from being registered as stable bottlenecks, providing a more robust state update."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_Dataset Distillation_ aims to synthesize a tiny synthetic dataset of (typically) images that are optimal\nfor training. Unlike previous works designed to produce synthetic samples for training new models\n_from scratch_, our new method, _Linear Gradient Matching_, aims to distill datasets for the purpose of\ntraining **linear classifiers** in the embedding space of **pre-trained feature extractors** .\n\n**3.1** **Linear Gradient Matching**\n\nFormally, given a pre-trained self-supervised feature extractor, _\u03d5_, along with a real dataset _D_ real of\nimages _X_ real and labels _Y_ real, we wish to distill a small synthetic set _D_ syn = _{X_ syn _, Y_ syn _}_ such that\n_D_ syn can be used to train a linear classifier in feature extractor _\u03d5_ \u2019s embedding space that will have\nsimilar test-time performance to one trained on _D_ real.\n\n3\n\nInspired by previous works that aimed to match single-step gradients [55] or multi-step trajectories [6],\nour solution is designed to ensure that training on our synthetic dataset results in similar updates as\ntraining on real data. In other words, the gradients of the classification loss using synthetic images\n(with respect to the linear classifier) should match those using real images.\n\nTo achieve this, we sample a random linear classifier matrix _W \u223cN_ (0 _,_ 1) _[c][\u00d7][f]_ at each distillation step\nwhere _c_ is the number of classes and _f_ is the feature extractor _\u03d5_ \u2019s output dimension. After passing\nthe real and synthetic images through the feature extractor _\u03d5_ and linear classifier _W_, we find the real\nand synthetic classification losses where CE is the multiclass cross-entropy loss:\n\n_\u2113_ real = CE( _W\u03d5_ ( _X_ real); _Y_ real)\n(1)\n_\u2113_ syn = CE( _W\u03d5_ ( _X_ syn); _Y_ syn)\n\nWe then take the gradients of these classification losses with respect to the linear classifier _W_, and\nour _meta loss_ is then the cosine distance between them:\n\n_\u2202\u2113_ real\n_L_ meta = 1 _\u2212_ cos \ufffdvec \ufffd _\u2202W_\n\n_\u2202\u2113_ syn\n\ufffd _,_ vec \ufffd _\u2202W_\n\n(2)\n\ufffd\ufffd\n\nThis meta loss is then back-propagated through the inner gradient computation, linear classifier, and\nfeature extractor to find _\u2202L_ meta _/\u2202X_ syn and update our synthetic images. This process is repeated until\ndistillation is complete. An outline of this _Linear Gradient Matching_ method can be found in Figure 2.\n\n**3.2** **Implicit Regularization**\n\nAs noted in prior works [6, 7, 55], _Dataset Distillation_ tends to yield synthetic images that are _overfit_\nto the model used to perform the distillation. This issue manifests in what appear like adversarial\npatterns and inhibit the images\u2019 usefulness when used to train other models.\n\nOne recent work [15] proposed using a pyramid representation rather than na\u00efve pixels for image optimization problems. While the authors used this technique for CLIP inversion, we find it works remarkably well for our Dataset Distillation task. Rather than simply optimizing pixels, each synthetic sample\nis instead stored as a set of images of different resolutions _\u03c1_ = _{_ 1 _\u00d7_ 1 _,_ 2 _\u00d7_ 2 _,_ 4 _\u00d7_ 4 _, . . .,_ 256 _\u00d7_ 256 _}_ .\n\nBefore each optimization step, the composite images _X_ are \u201crendered\u201d by bilinearly upsampling\neach level of the pyramids _P_ = _{Pr|r \u2208_ _\u03c1}_ to the max resolution (256) and adding them together\nbefore smoothly clamping the pixel values with a sigmoid function:\n\n\ufffd\n\n_X_ = sigmoid\n\n\ufffd\ufffd _r\u2208\u03c1_\n\nresize256( _Pr_ )\n\n_r\u2208\u03c1_\n\n(3)\n\nFurthermore, we progressively optimize our pyramid, starting with just the lowest-resolution component and periodically adding more tiers during distillation. The effects of using the pyramid\nrepresentation are quite dramatic, as seen in Figure 5.\n\nAs an additional step to combat overfitting, we also learn our distilled images in a _decorrelated_ color\nspace, as described in prior feature visualization work [30]. In short, we apply a fixed linear transform\nto the channels of our images after the pyramid reconstruction that brings them back into the standard\ncorrelated color space. This helps ward off any potential color-based biases induced by the model\nused during distillation.\n\n**3.3** **Differentiable Augmentations**\n\nAs first noted in the work on _Differentiable Siamese Augmentation_ [53], applying differentiable\naugmentations to the synthetic images during the distillation process greatly improves the quality of\nthe distilled data. As such, we apply **horizontal flipping**, **random resized cropping**, and **Gaussian**\n**noising** to our distilled images at each step. In practice, we actually apply multiple rounds of this\naugmentation to different copies of the synthetic data at each iteration and concatenate the results.\nWe find this improves distillation since the optimization now encourages all these augmented copies\n_together_ to be the ideal training set rather than attempting to fit all pertinent information into a single\naugmented version of the images.\n\n4\n\nTrain Set ImageNet-100 ImageNet-1k\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **84.9** _\u00b1_ **0.1 91.5** _\u00b1_ **0.1 89.0** _\u00b1_ **0.0 83.4** _\u00b1_ **0.1 87.2** _\u00b1_ **0.1 63.0** _\u00b1_ **0.0 75.0** _\u00b1_ **0.1 70.3** _\u00b1_ **0.1 63.2** _\u00b1_ **0.0 67.9** _\u00b1_ **0.0**\nNeighbors 67.8 _\u00b1_ 0.3 86.0 _\u00b1_ 0.2 78.8 _\u00b1_ 0.2 77.1 _\u00b1_ 0.1 77.4 _\u00b1_ 0.2 38.8 _\u00b1_ 0.1 67.7 _\u00b1_ 0.1 49.9 _\u00b1_ 0.1 56.4 _\u00b1_ 0.0 53.2 _\u00b1_ 0.1\nCentroids 77.1 _\u00b1_ 0.1 86.9 _\u00b1_ 0.3 80.9 _\u00b1_ 0.2 77.7 _\u00b1_ 0.1 80.6 _\u00b1_ 0.2 53.9 _\u00b1_ 0.0 69.5 _\u00b1_ 0.1 58.1 _\u00b1_ 0.1 57.4 _\u00b1_ 0.0 59.7 _\u00b1_ 0.1\n\nRandom 56.6 _\u00b1_ 1.6 74.8 _\u00b1_ 2.8 64.5 _\u00b1_ 2.7 61.4 _\u00b1_ 2.6 64.3 _\u00b1_ 2.4 31.7 _\u00b1_ 0.5 50.3 _\u00b1_ 0.5 37.7 _\u00b1_ 0.4 38.8 _\u00b1_ 0.6 39.6 _\u00b1_ 0.5\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1 78.7 _\u00b1_ 0.0 83.0 _\u00b1_ 0.0 81.7 _\u00b1_ 0.1 76.5 _\u00b1_ 0.0 80.0 _\u00b1_ 0.0\n\nTable 1: **Linear Probes with One Image-per-Class:** We compare our method (Distilled) to several real-image\nbaselines on ImageNet-100 ( **left** ) and ImageNet-1k ( **right** ). Images are distilled (or selected) using the given\nmodel in each column. \u201cNeighbors\u201d are the real images with embeddings closest to those of our distilled images.\n\u201cCentroids\u201d are the real images with embedding closest to the mean of each class. \u201cRandom\u201d is a random\nselection of real images. Our method outperforms each baseline across all models and both datasets.\n\nDistill ImageNet-100 ImageNet-1k\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1 78.7 _\u00b1_ 0.0 83.0 _\u00b1_ 0.0 81.7 _\u00b1_ 0.1 76.5 _\u00b1_ 0.0 80.0 _\u00b1_ 0.0\n\nTable 2: **Cross-Model Performance of Distilled Datasets** : Here, we see ImageNet-100 ( **left** ) and ImageNet-1k\n( **right** ) distilled using a given model and then evaluated across all models. We see that images distilled from DINO\nhave the best average cross-model performance for both datasets. The distilled datasets generalize well, aside from\nan outlier pair of CLIP and MoCo. Columns are colored based on percentage of the \u201cFull Dataset\u201d benchmark."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism, 'Linear Gradient Matching,' aims to synthesize a tiny dataset D_syn such that training a simple linear classifier (W) on D_syn yields gradient updates to W that are very similar to those obtained by training on the full, real dataset D_real. This is achieved by defining a meta-loss. At each step, a random linear classifier matrix W is sampled. We then calculate the classification loss gradients with respect to W for both the real data (\u2202\u2113_real/\u2202W) and the synthetic data (\u2202\u2113_syn/\u2202W). The meta-loss is the cosine distance between the vectorized forms of these two gradients. This meta-loss is then back-propagated through the entire process, including the inner gradient computation, to update the pixels of the synthetic images X_syn. This effectively 'teaches' the synthetic images to produce the same classifier updates as the real data.  Implicit regularization techniques enhance this: a pyramid representation optimizes synthetic images across multiple resolutions (like mipmaps), reducing overfitting and promoting generality. Starting with lower resolutions and progressively adding higher-resolution components stabilizes the optimization. Learning in a decorrelated color space further regularizes by preventing reliance on spurious color correlations. Differentiable augmentations (flipping, cropping, noising) are applied to synthetic images during distillation. By optimizing multiple augmented copies simultaneously, the synthetic data is forced to encode information robust to these transformations, improving its transferability.\n\n**Explanation:** Think of it like this: you want to teach a student (the linear classifier W) how to react to new information. You have a massive textbook (real data) and you want to create a tiny cheat sheet (synthetic data) that makes the student react in exactly the same way. We use a 'probe' (the random W) to test the student's reaction. We show the student a lesson from the real textbook and see how they'd adjust their understanding (their gradient). Then, we show them a lesson from our cheat sheet and see how they'd adjust. Our goal is to make the cheat sheet's lesson cause the exact same adjustment as the real textbook's lesson. The 'meta-loss' is like a score that tells us how far off the cheat sheet's lesson is from the textbook's. We then adjust the cheat sheet itself using 'back-propagation' so it gets better at matching the textbook's lessons.  The pyramid representation is like building a picture from big, blocky shapes first, then adding finer details. This makes the picture more robust and less prone to weird, unstable pixels. Learning in a 'decorrelated color space' is like making sure the picture doesn't have any hidden color tricks that only work for one specific viewer, making it more universally understandable. Differentiable augmentations are like explicitly telling the cheat sheet: 'make sure this lesson still works even if I look at it upside down or blurry,' forcing the cheat sheet to capture the essential information in a robust way."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nA key characteristic of the VLIW architecture is its deterministic\ninstruction schedule, which is fixed statically at compile time. This\nproperty enables performance to be estimated directly from the\ninstruction sequence itself. While runtime hazards such as memory\nstalls or lock acquisition can introduce variability, the static instruction schedule provides a clear representation of the kernel\u2019s peak\npotential for our analysis. The performance of a compute core is\nevaluated by how closely its achieved throughput approaches the\ntheoretical maximum of the hardware, which can be quantified by:\n\nEfficiency = [Achieved Throu][g][h][p][ut ][(][MACs/c][y][cle][)] _._ (4)\n\nPeak Throughput (MACs/cycle)\n\nThe key challenge in kernel design is to exploit instruction-level\nparallelism (ILP) to hide _data movement latency between L1 memory_\n_and registers_ and maximize the _issue rate of_ VMAC _instructions_ . For a\nGEMM kernel, the most critical VLIW slots are:\n\n  - **1 Vector Arithmetic Unit:** Executes the VMAC instruction.\n\n  - **2 Vector Load Units:** Load vector operand from L1 memory.\n\n  - **1 Vector Store Unit:** Writes the result block back to memory.\n\nFrom an instruction-scheduling perspective, maximizing efficiency\ncorresponds to maximizing utilization of the vector arithmetic unit.\nThus, we evaluate kernel schedules using the ratio of issued VMAC\ninstructions to the total number of cycles in the code region of\ninterest, typically the microkernel.\n\n**4.1** **Accumulation Chain in Microkernel**\n\nIn general, instruction scheduling of arbitrary DAGs under resource\nconstraints is NP-hard [12] and admits no closed-form solution. This\nsection narrows the scope to the GEMM microkernel. Within this\nsetting, the instruction schedule can be well approximated using\nsimple analytical bounds to guide microkernel optimization.\nThe basic unit in our model is the _accumulation chain_, which\nrepresents the sequence of instructions required to update one\naccumulator operand of a VMAC instruction without spilling the accumulator register. All instructions are pipelined with a throughput\nof one per cycle, but may have varying latency. We decompose the\ninstruction scheduling into three phases:\n\n- **Prolog:** The period before the first VMAC instruction can be issued,\nduring which operand registers are loaded (e.g., loads of _\ud835\udc34_, _\ud835\udc35_,\nand _\ud835\udc36_ in Fig. 3). Assume there are _\ud835\udc40_ instruction types, each with\n\n2\nAIarray =\n\n2\n\n=\n\n_[\ud835\udc50]_ _\ud835\udc4e_\n\n_\ud835\udc3e_ _[\ud835\udc3f]_ [1] [+]\n\n_,_ (2)\n\n_[\ud835\udc50]_\n\n_\ud835\udc3e_\n\n_\ud835\udc4e_ _\ud835\udc4f_ _[\ud835\udc50]_\n_\ud835\udc47\ud835\udc41_ _[\ud835\udc3f]_ [2] [+] _\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ [2] [+] _\ud835\udc3e_\n\n_\ud835\udc4e_ _\ud835\udc4f_\n+ _[\ud835\udc50]_\n8 _\ud835\udc47\ud835\udc41_ _[\ud835\udc3f]_ [1] [+] 4 _\ud835\udc47\ud835\udc40\ud835\udc36_ _[\ud835\udc3f]_ [1] _\ud835\udc3e_\n\nwhich is constrained by the L1 capacity _\ud835\udc46\ud835\udc3f_ 1 = 63 KB per core:\n\n2 _\ud835\udf0c\ud835\udc4e_ _[\ud835\udc47]_ _\ud835\udc40_ _[\ud835\udc3f]_ _\ud835\udc36_ [1] _[\ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1] + 2 _\ud835\udc4f\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] + _\ud835\udc50\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ _\ud835\udc36_ [1] _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] \u2264 _\ud835\udc46\ud835\udc3f_ 1 = 63 KB _._ (3)\n\nSimilar to the analysis of AI _\ud835\udf0c_, the optimal strategy to maximize\nAIarray is to minimize _\ud835\udc47\ud835\udc3e_ _[\ud835\udc3f]_ [1] [and maximize] _[ \ud835\udf0c]_ [.]\n\n**3.3** **Limits of AI-Only Modeling**\n\nThe arithmetic intensity model predicts that performance is maximized by minimizing _\ud835\udc47\ud835\udc3e_ and maximizing _\ud835\udf0c_ . In practice, this overlooks microkernel execution: a very small _\ud835\udc47\ud835\udc3e_ introduces bubbles in\nthe compute pipeline and inflates prolog/epilog costs. To capture\n\nChengyue Wang [1], Wesley Pang [2], Xinrui Wu [1], Gregory Jun [2], Luis Romero [3], Endri Taka [4], Diana Marculescu [4], Tony Nowatzki [1], Pranathi Vasireddy [5], Joseph Melber [5], Deming Chen [2],\nConference\u201917, July 2017, Washington, DC, USA Jason Cong [1]\n\nlatency _\u2113\ud835\udc56_ and a count _\ud835\udc5b\ud835\udc56_, to be issued on _\ud835\udc48_ LD vector load slots.\nThe minimum time for all operands to become ready is\n\n\u2212 1 _,_ (5)\n\ufffd \ufffd\n\n_\ud835\udc47_ prolog \u2265 _\ud835\udc47_ load = max _\ud835\udc56_ =1 _,...,\ud835\udc40_\n\n\ufffd _\u2113_ ( _\ud835\udc56_ ) + \ufffd _\ud835\udc48\ud835\udc46_ (LD _\ud835\udc56_ )\n\nwhere instruction types are sorted in descending order of latency,\ni.e., _\u2113_ (1) \u2265 _\u2113_ (2) \u2265\u00b7 \u00b7 \u00b7, and _\ud835\udc46_ ( _\ud835\udc56_ ) = [\ufffd] _[\ud835\udc56]_ _\ud835\udc58_ =1 _[\ud835\udc5b]_ [(] _[\ud835\udc58]_ [)][ is the cumulative]\nnumber of loads from the first _\ud835\udc56_ operand types. Intuitively, the\nformula assumes all loads are independent and can be reordered\narbitrarily. The longest-latency loads are issued first so their\ndelay is hidden as much as possible, while shorter-latency loads\ncan be issued later and overlap with them. The final time is then\ndetermined by whichever group of loads (long or short) finishes\nlast. In Fig. 3, with 3 instruction types of latency _\u2113_ = 3, counts\n_\ud835\udc5b\ud835\udc36_ = 2, _\ud835\udc5b\ud835\udc34_ = _\ud835\udc5b\ud835\udc35_ = 1, and _\ud835\udc48_ LD = 2, we have _\ud835\udc46_ (1) = 2, _\ud835\udc46_ (2) = 3,\n_\ud835\udc46_ (3) = 4. Substituting gives _\ud835\udc47_ load = max(3 + \u23082/2\u2309\u2212 1 _,_ 3 + \u23083/2\u2309\u2212\n1 _,_ 3 + \u23084/2\u2309\u2212 1) = max(3 _,_ 4 _,_ 4) = 4 cycles.\n\n- **Steady State:** The region where VMAC instructions are interleaved\nwith operand loads and scheduled periodically with an _initiation_\n_interval_ of _\ud835\udc3c\ud835\udc3c_ cycles. For a single accumulation chain, _\ud835\udc3c\ud835\udc3c_ is constrained by the RAW dependency distance on the accumulator\noperand and the load bandwidth, giving\n\n_\ud835\udc3c\ud835\udc3c_ single = max\ufffd _\ud835\udc43,_ \ufffd _\ud835\udc45\ud835\udc48_ loadLD\n\n_,_ (6)\n\ufffd\ufffd\n\n![](papers/images/Can-Asymmetric-Tile-Buffering-Be-Beneficial.pdf-3-0.png)\n\n**Figure 4: Comparison of single-buffered (left) vs. double-**\n**buffered (right) input register allocation.**\n\n**Figure 5: GEMM microkernel optimizations: top-left, input**\n**sharing across a 2** \u00d7 **2 chain cluster; bottom-left, prolog\u2013epilog**\n**overlap across clusters; right, corresponding code.**\n\nwhile the other is consumed by VMAC instructions. Fig. 4 illustrates\nthis: the left schedule repeatedly reloads into the same registers,\ncreating RAW dependencies between loads and compute, while the\nright employs double buffering so that loads overlap with compute.\n\n_Sharing Input Across Chain Cluster._ To improve the microkernel\nperformance, it is important to employ multiple parallel accumulation chains so that the effective _\ud835\udc3c\ud835\udc3c_ in the steady state approaches 1,\nas modeled in Eq. (7). In practice, these chains are not fully independent: they often share common input operands from matrix _\ud835\udc34_\nor _\ud835\udc35_, which we refer to as a _chain cluster_ . When the microkernel\nshares input registers across a chain cluster, the number of loads\nper VMAC is reduced, thus alleviating pressure on the load bandwidth and lowering _\ud835\udc45_ load in Eq. (7). This reuse also reduces input\nregister usage, creating more opportunities for double buffering\nto hide load latency. The cluster size is bounded by the number\nof accumulator operands that can be held simultaneously in the\naccumulator register file. Fig. 5 (top-left) illustrates this optimization, where shared inputs feed multiple chains simultaneously; for\nexample, a 2\u00d72 chain cluster reduces the load count from 8 to 4.\n\n_Overlapping Successive Chain Clusters._ Even if the optimal _\ud835\udc3c\ud835\udc3c_ = 1\nis achieved in steady state using a chain cluster, the total latency\nstill includes the prolog and epilog phases. If successive chain clusters run sequentially, with each starting only after the previous\n\nwhere _\ud835\udc43_ is the VMAC pipeline depth, and _\ud835\udc45_ load is the number of\noperand loads per VMAC. To hide the latency _\ud835\udc43_ and improve VMAC\nthroughput, a microkernel typically employs multiple parallel\naccumulation chains interleaved in a software-pipelined schedule.\nWith _\ud835\udc36_ parallel chains interleaved, the effective _\ud835\udc3c\ud835\udc3c_ is:\n\n_\ud835\udc3c\ud835\udc3c_ parallel = max\ufffd _\ud835\udc43_ +1\u2212 _\ud835\udc36\ud835\udc36,_ \ufffd _\ud835\udc45\ud835\udc48_ loadLD\n\n_\ud835\udc48_ LD\n\n\ufffd\ufffd\n\n_\ud835\udc36_ _._ (7)\n\nThe steady-state cost is then lower-bounded by:\n\n_\ud835\udc47_ steady \u2265 _\ud835\udc3c\ud835\udc3c_ parallel \u00b7 [\ufffd] _\ud835\udc41_ accum \u2212 _\ud835\udc36_ ) _,_ (8)\n\nwhere _\ud835\udc41_ accum is the number of accumulator updates (i.e., the\nlength of the accumulation chain).\n\n- **Epilog:** The region after the last operand load where the final\nVMAC instructions complete and the accumulator results are written back to memory. For _\ud835\udc36_ accumulation chains, it consists of _\ud835\udc36_\ncompute\u2013store pairs:\n\n_\ud835\udc47_ epilog \u2265 [\ufffd] _\u2113_ vmac\u2192vst + _\u2113_ store + _\ud835\udc5b_ store \u2212 1 [\ufffd] + ( _\ud835\udc36_ \u2212 1) _,_ (9)\n\nwhere _\u2113_ vmac\u2192vst is the latency from the last VMAC to when its store\ncan be issued, _\u2113_ store is the store instruction latency, and _\ud835\udc5b_ store is\nthe number of store instructions required per accumulator.\n\n**4.2** **Modeling of Total Latency**\n\n_Double Buffering of Input Registers._ In our steady-state modeling,\nwe considered only the load bandwidth and assumed that sufficient\nregisters are available to hold parallel loads, fully hiding the load latency. This assumption is reasonable in practice, as compilers often\nperform register renaming and allocate disjoint registers to achieve\nthis effect automatically. When the compiler cannot apply such\noptimizations effectively, AIE programmers can manually pin variables to registers using the chess_storage(register) attribute.\nIn this case, ping\u2013pong buffering of input registers becomes an\nimportant technique. By alternating between two disjoint register\nsets ( _Ping_ / _Pong_ ), the microkernel can preload operands in one set\n\n![](papers/images/Can-Asymmetric-Tile-Buffering-Be-Beneficial.pdf-3-1.png)\nCan Asymmetric Tile Buffering Be Beneficial? Conference\u201917, July 2017, Washington, DC, USA\n\ncompletes, the total latency is bounded by\n\n_\ud835\udc3f\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ \u2265( _\ud835\udc47_ prolog + _\ud835\udc47_ steady + _\ud835\udc47_ epilog) \u00b7 _\ud835\udc41_ clusters _._ (10)\n\nHowever, the chain length is algorithmically constrained by the _\ud835\udc3e_\ndimension of the tile in L1 memory. When _\ud835\udc3e_ is small, the prolog and\nepilog overheads are significant relative to _\ud835\udc47_ steady. To address this,\nsuccessive clusters can overlap in a software-pipelined schedule:\nwhile one cluster is draining its epilog, the next cluster can begin its\nprolog. If the overlap ideally hides the boundary costs, the latency\nof _\ud835\udc41_ clusters chain clusters, each containing _\ud835\udc36_ chains, is bounded by\n\n_\ud835\udc3f_ total \u2265 _\ud835\udc47_ prolog + [\ufffd] _\ud835\udc47_ steady + _\ud835\udc3c\ud835\udc3c_ parallel \u00b7 _\ud835\udc36_ [\ufffd]  - _\ud835\udc41_ clusters + _\ud835\udc47_ epilog _._ (11)\n\nFig. 5 (bottom-left) illustrates this effect, where overlapping reduces\nthe gaps between chain clusters for higher utilization.\n\n**4.3** **Towards BFP16 and Mixed Precision**\n\nSince public documentation does not provide precise register behavior, we approximate parameters using microbenchmarks with\nsmall VMAC kernels and explicit register binding. For the bfp16ebs8\nVMAC instruction, we observe five accumulator registers, each holding 8 \u00d7 8 FP32 elements, with a pipeline distance of _\ud835\udc43_ = 3 cycles.\nOperand loads have a latency of 8 cycles; because bfp16ebs8 is unaligned, a VLDA.POP precedes the load whenever the access is to a\nnon-consecutive address. The latency from VMAC to store availability\nis _\u2113_ vmac\u2192vst = 6 cycles, and writing back one accumulator register\nrequires two store instructions with latency _\u2113_ store = 2 cycles.\nArchitectural constraints can reduce BFP16 kernel performance\nbelow the analytical bounds. The instruction pipeline favors sequential L1 access, because unaligned BFP16 addresses require\nextra instructions and may introduce bubbles. In addition, conversions between BFP16 and BF16 occupy accumulator registers,\nand the small accumulator file further limits concurrent load\u2013store\noperations, which creates false dependencies between successive\nclusters. Our model helps designers reason about whether performance loss stems from hardware limitations or compiler scheduling,\nand guides manual optimizations such as unrolling, register-level\ntiling, register binding, and double buffering."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is **software pipelining** and **resource balancing** on a VLIW (Very Long Instruction Word) architecture. VLIW enables static, compile-time scheduling of multiple operations per cycle, which means the compiler pre-arranges instructions to maximize parallel execution and keep functional units busy, similar to an extremely optimized, unrolled loop with explicit resource allocation. The paper's models quantify how efficiently hardware resources (like vector load units and the vector arithmetic unit) are utilized relative to their theoretical maximum throughput.\n\n**Explanation:** This paper analyzes how to squeeze the most speed out of a specialized computer chip (VLIW) for heavy math operations like matrix multiplication (GEMM). Because VLIW has a fixed schedule, we can predict performance precisely. The main challenge is to keep the 'Vector Arithmetic Unit' (the workhorse for VMAC instructions) continuously fed with data and instructions, preventing it from waiting. This means overlapping data loading from memory (L1 cache) into fast registers with computation. The 'Efficiency' equation is a simple ratio: actual work done per cycle divided by the maximum possible work. To maximize this, we model the total execution time as three phases: 'Prolog' (initial setup and data loads), 'Steady State' (the main, repeating computation loop), and 'Epilog' (final results write-back). The 'Prolog' calculation (Eq. 5) shows that the initial delay is determined by the slowest required data load, considering both individual load latencies and the available parallel load units. In the 'Steady State', the 'Initiation Interval' (II) (Eq. 6 & 7) is key. For a single calculation chain, `II` is bottlenecked by either the VMAC pipeline depth (`P`) or the rate at which operands can be loaded (`R_load / U_LD`). By using multiple parallel accumulation chains (`C`), we can 'software pipeline' them, effectively hiding the VMAC pipeline depth and bringing the `II` closer to 1 (one VMAC per cycle). This is like having `C` independent pipelines running in parallel, staggered by one cycle. Techniques like 'double buffering' (using two sets of registers, one for current computation, one for pre-fetching next data) and 'sharing inputs' (multiple chains reading the same operand from memory only once) reduce the `R_load` term, alleviating load bandwidth pressure. Finally, 'overlapping successive chain clusters' (Eq. 11 vs 10) hides the setup and teardown costs between larger blocks of computation, preventing 'bubbles' in the pipeline by starting the next block's prolog while the previous one's epilog is still draining. These strategies directly target the bottlenecks in the `II` and overall latency equations, aiming to drive `II` towards 1 and minimize overheads, thereby maximizing VMAC unit utilization."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe report below the study results. For each RQ, we report both the zero-shot and RAG-based results.\n\nWe also summarize all the results in Figure 6, which reports boxplots of all the quantitative metrics involved in this\n\nstudy.\n\n**4.1** **RQ** 1 **: Code Similarity**\n\nTable 2 reports the similarity results for the code generated by models across semantic similarity, TED, and BLEU\n\nmetrics.\n\nManuscript submitted to ACM\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-0.png)\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-1.png)\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-2.png)\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-3.png)\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-4.png)\n\n![](papers/images/Beyond-Code-Similarity-Benchmarking-the-Plausibility-Efficiency-and-Complexity-of-LLMGenerated-Smart-Contracts.pdf-9-5.png)\nBeyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts11\n\n**Zero-Shot.** We start by discussing results regarding the baseline scenario. Among all evaluated models, ChatGPT\n\n4o achieves the highest average semantic similarity with a mean of 0.6813, followed closely by Gemini (0.6707)\n\nand CodeLlama (0.6674). Deepseek-coder-v2 attains a slightly lower mean similarity of 0.6360. Overall, all models\n\ndemonstrate the ability to generate code that is substantially semantically aligned with the ground truth, with mean\n\nscores consistently exceeding 0.6. The minimum similarity values span a broader range, from as low as 0.1584 (ChatGPT\n\n4o) to 0.1811 (CodeLlama), highlighting that, in some instances, the generated functions diverge considerably from the\n\nintended semantics. By contrast, all models achieve maximum similarity values above 0.94, confirming that near-perfect\n\nsemantic matches are possible across all approaches. The standard deviations, ranging between 0.1525 and 0.1642,\n\nindicate a moderate variability in semantic fidelity, likely influenced by differences in prompt complexity and the\n\ndiversity of contract structures. Overall, these results confirm that, despite occasional discrepancies, the models generally\n\nsucceed in capturing the semantic intent of the original code.\n\nIn terms of structural similarity, the TED results are also reported in Table 2. The lowest average TED score is observed\n\nfor ChatGPT-4o with a mean of 31.6680, indicating that, on average, it produces code that is structurally closer to the\n\nreference contracts. The other models follow with very similar mean scores, ranging from 33.3541 (Deepseek-coder-v2)\n\nto 34.0905 (CodeLlama). The relatively small differences in average TED suggest a comparable level of structural fidelity\n\nacross models. All models exhibit a minimum TED of 0.0, reflecting perfect structural alignment in at least one example.\n\nConversely, the maximum values vary between 279.0 (Gemini) and 298.0 (ChatGPT-4o), indicating that, in certain\n\ncases, the structural divergence from the ground truth can be substantial. Standard deviations are consistently high\n\n(approximately 27\u201328), suggesting a substantial spread of structural similarity scores across instances. These results\n\nindicate that, while average structural alignment is moderate, individual generations can display significant structural\n\nvariance.\n\nFinally, Table 2 also presents BLEU scores, which measure token-level n-gram overlap with the reference code. The\n\nhighest average BLEU score is observed for ChatGPT-4o (mean = 0.1202), followed by Gemini (0.1087), CodeLlama\n\n(0.1055), and Deepseek-coder-v2 (0.0887). Although mean BLEU values are generally low, all models achieve high\n\nmaximum BLEU scores, with CodeLlama reaching up to 0.8844, followed by Gemini (0.8555) and ChatGPT-4o (0.8154).\n\nThese high values indicate that, in certain cases, the generated code is nearly identical to the reference in terms of token\n\nsequences. Interestingly, this indirectly means that no model can generate an exact match for any SC we considered.\n\nAll models have a minimum BLEU of 0.0, confirming that some generations are completely disconnected from the SC\n\nto be generated. The standard deviation values (ranging from 0.1043 to 0.1343) indicate moderate variation in textual\n\nsimilarity across examples.\n\n**RAG.** The models with RAG tend to show higher semantic similarity and BLEU scores while achieving lower\n\nTED as compared to the zero-shot scenario, suggesting closer alignment with the ground truth both semantically\n\nand textually. For instance, Gemini with RAG achieves the highest average semantic similarity ( **0.8392** ) and BLEU\n\n( **0.4908** ), while also reducing the mean TED to **19.1** from **33.7** in the base Gemini model. Similar trends are observed for\n\nDeepseek-coder-v2 with RAG, which raises its semantic similarity mean from **0.636** to **0.8006** and BLEU from **0.0887** to\n\n**0.4189**, reflecting substantially better alignment. In contrast, ChatGPT-4o shows more modest improvements (semantic\n\nsimilarity increasing from **0.6813** to **0.6859** ) and relatively stable BLEU and TED scores, suggesting less sensitivity to\n\nadded comments in its generation process. Notably, all improved models now reach a maximum semantic similarity of\n\n1.0, indicating that the enrichment strategy enables near-perfect matches in some cases. However, standard deviations\n\nalso tend to increase (especially in BLEU), highlighting that improvements are not uniform across all examples.\n\nManuscript submitted to ACM\n\n12 Salzano et al.\n\nTable 2. Detailed similarity statistics for considered models across three metrics: Semantic Similarity, TED, and BLEU.\n\n**Semantic Similarity** **TED** **BLEU**\n**Model**\n\nMean Min Max StdDev Mean Min Max StdDev Mean Min Max StdDev\n\nCodeLlama 0 _._ 6674 0.1811 0.9707 0 _._ 1525 34 _._ 0905 0.0 290.0 27 _._ 1880 0 _._ 1055 0.0 0.8844 0 _._ 1331\n\nCodeLlama-RAG 0 _._ 6434 0.1015 1.0000 0 _._ 2003 29 _._ 6076 0.0 292.0 28 _._ 7273 0 _._ 1743 0.0 1.0000 0 _._ 2283\n\nDeepSeek-Coder-v2 0 _._ 6360 0.1743 0.9420 0 _._ 1642 33 _._ 3541 0.0 285.0 27 _._ 9981 0 _._ 0887 0.0 0.6402 0 _._ 1043\n\nDeepSeek-Coder-v2-RAG 0 _._ 8006 0.0176 1.0000 0 _._ 1699 22 _._ 7746 0.0 243.0 26 _._ 7864 0 _._ 4189 0.0 1.0000 0 _._ 2544\n\nGemini 0 _._ 6707 0.1677 0.9813 0 _._ 1594 33 _._ 7505 0.0 279.0 28 _._ 2324 0 _._ 1087 0.0 0.8555 0 _._ 1322\n\nGemini-RAG 0 _._ 8392 0.1685 1.0000 0 _._ 1438 19 _._ 1207 0.0 264.0 26 _._ 2697 0 _._ 4908 0.0 1.0000 0 _._ 2730\n\nChatGPT-4o 0 _._ 6813 0.1584 0.9617 0 _._ 1562 31 _._ 6680 0.0 298.0 27 _._ 6579 0 _._ 1202 0.0 0.8154 0 _._ 1343\n\nChatGPT-4o-RAG 0 _._ 6859 0.0235 1.0000 0 _._ 1869 28 _._ 2008 0.0 297.0 28 _._ 5822 0 _._ 2105 0.0 1.0000 0 _._ 2417\n\nOverall, the results suggest that, in both scenarios, while the models consistently produce semantically and structurally\n\nsimilar code on average, substantial variation remains across individual generations. Moreover, our findings demonstrate\n\nthat augmenting prompts with richer comments can consistently boost the semantic and textual fidelity of generated\n\ncode, even though the impact varies by model.\n\n**4.2** **RQ** 2 **: Code plausibility**\n\nWe report the number of contracts that are able to compile and be deployed, starting from the set of 198 compilable\n\ncontracts from the ground truth, alongside the number and the percentage of output that reflects, for a given input, the\n\nsame output as the ground truth functions. Here, Table 3 summarizes the functional plausibility of code generated by\n\ndifferent LLMs.\n\n**Zero-Shot.** In the baseline scenario, functional plausibility for models consistently shows low accuracy values.\n\nGemini achieves the highest accuracy at 25.64%, though it was evaluated on a notably smaller set of contracts (11) and\n\nsamples (78) compared to other models. Notably, in this case, the number of compilable contracts decreases from 198\n\nto only 11, which raises concerns about assessing generated code purely based on semantic and structural similarity.\n\nCodeLlama and DeepSeek-Coder-v2exhibit similar performance, with 22.32% and 21.71% accuracy, respectively, from a\n\nlarger pool of generated artifacts. ChatGPT shows the lowest accuracy at 20.79%. These results indicate that generating\n\nfunctionally correct SCs from scratch remains a significant challenge for current LLMs, underscoring the need for\n\naugmented generation strategies. Generated instances with complete plausibility are considerably lower, ranging from\n\nabout 7% to 9%. This discrepancy is largely due to subtle mismatches between the generated functions and the ground\n\ntruth, especially in the way corner cases and input validation using require statements are managed. Providing insights\n\ninto this, Figure 7, which shows a ground truth function and a generated one, differs from the introduction of a require\n\nto validate input, which results in a diverse output when the input is 0.\n\nNotably, in this case, the LLM introduced a useful check, which was absent in the ground truth instance. However, in\n\nmost cases, the LLM-generated version presents fewer validations than the ground truth corresponding one, as Figure 8\n\ndisplays.\n\n**RAG.** When applying RAG, we observe a substantial improvement in functional plausibility across all models. As\n\nreported in Table 3, DeepSeek-Coder-v2-RAG demonstrates the most substantial improvement, more than doubling\n\nits accuracy from 21.71% to 45.19%. This significant gain suggests that DeepSeek-Coder-v2 particularly benefits from\n\nrelevant code examples, translating into considerably more accurate functional behavior. Gemini-RAG also shows\n\nManuscript submitted to ACM\n\nBeyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts13\n\na notable increase, rising from 25.64% to 37.01%. Importantly, the number of generated and testable contracts for\n\nGemini increased dramatically (from 11 to 130 contracts and 78 to 862 samples), indicating that RAG not only improves\n\nplausibility but also enables Gemini to produce a much larger volume of valid, testable code. ChatGPT-RAG improves\n\nfrom 20.79% to 29.00%, a substantial gain, accompanied by a significant expansion in the number of processed contracts\n\nand samples (from 59 to 101 contracts, and 606 to 938 samples). This suggests that RAG helps ChatGPT generate a\n\nbroader range of robust code. CodeLlama-RAG exhibits a more modest increase, moving from 22.32% to 23.56%. While\n\nthe accuracy improvement is slight, the marginal increase in processed samples (from 802 to 836) suggests a lesser, but\n\nstill present, benefit from RAG in this context.\n\nIn conclusion, RAG integration proves to be a critical enabler for improving the functional plausibility of generated\n\nSCs. It provides essential context, enhancing models\u2019 understanding of intent and semantic fidelity. The results highlight\n\nvarying degrees of benefit across models, with DeepSeek-Coder-v2 and Gemini showing the most pronounced gains.\n\n**4.3** **RQ** 3 **: Gas Consumption**\n\nIn order to address RQ3, we show the gas consumed by valid transactions on generated functions, alongside data\n\nregarding ground truth gas fees. Hence, Table 4 shows the gas consumption statistics for generated contracts.\n\n**Zero-Shot.** In the baseline setting, we observe substantial variability across models, reflecting differences in genera\n\ntion strategies. The mean gas consumption is generally lower than that of the ground truth. Specifically, ChatGPT and\n\n1 **function** setCurrentPrice(uint256 newPrice) **public** onlyOwner {\n\n2 currentPrice = newPrice;\n\n3 }\n\n1 **function** setCurrentPrice(uint256 _currentPrice) **public** onlyOwner {\n\n2 **require** (_currentPrice > 0, \"Price\u2423must\u2423be\u2423greater\u2423than\u2423zero\");\n\n3 currentPrice = _currentPrice;\n\n4 }\n\nFig. 7. Ground-Truth and ChatGPT-generated function with input validation.\n\n1 **function** setMtdAmount(uint256 mtdAmountInWei) **public** onlyOwner {\n\n2 **require** (mtdAmountInWei > 0, \"MTD\u2423amount\u2423must\u2423be\u2423greater\u2423than\u2423zero\");\n\n3 **require** (mtdAmount != mtdAmountInWei, \"MTD\u2423amount\u2423has\u2423not\u2423changed\");\n\n4 mtdAmount = mtdAmountInWei;\n\n5 updatePrices ();\n\n6 }\n\n1 **function** setMtdAmount(uint256 _mtdAmount) **public** onlyOwner {\n\n2 **require** (_mtdAmount != 0, \"Value\u2423must\u2423be\u2423greater\u2423than\u2423zero\");\n\n3 mtdAmount = _mtdAmount;\n\n4 }\n\nFig. 8. Ground-Truth and ChatGPT-generated function.\n\nManuscript submitted to ACM\n\n14 Salzano et al.\n\nTable 3. Plausibility results for all considered LLMs.\n\n**Model** **Contracts** **Correct Calls (%)** **100% Correct Contracts**\n\nCodeLlama 136 22.32% 7.35%\n\nCodeLlama-RAG 137 23.56% 9.49%\n\nDeepSeek-Coder-v2 140 21.71% 7.86%\n\nDeepSeek-Coder-v2-RAG 143 45.19% 23.08%\n\nChatGPT 59 20.79% 8.47%\n\nChatGPT-RAG 101 29.00% 19.80%\n\nGemini 11 25.64% 9.09%\n\nGemini-RAG 130 37.01% 13.85%\n\nCodeLlama exhibit similar average gas usage (approximately 28,000 units), while Gemini produces the most efficient\n\ncode on average, with a mean consumption of around 21,900 units per invocation.\n\nMinimum gas values range between approximately 2,200 and 11,000 units, while maximum consumption can reach\n\nnearly 64,000 units. These differences underscore the heterogeneous runtime costs produced by large language models.\n\nNotably, all models generate functions that, on average, consume less gas per call than the manually authored ground\n\ntruth contracts. This result suggests that the generated implementations tend to produce simpler execution paths and\n\npotentially omit more sophisticated runtime checks or initialization logic, which may impact functionality or safety.\n\nThe Mean High Consistency values report the average gas for functions matching ground truth outputs on at least 75%\n\nof inputs. Notably, these means remain below the ground truth average, suggesting that even higher-fidelity generations\n\ntend to use less gas overall than manually authored contracts.\n\nCompared to the non-RAG setting, all models show a consistent reduction in mean gas usage per invocation. For\n\nexample, the average gas fees for ChatGPT decrease from approximately 28,900 to 26,600 units. Similar improvements\n\nare observed for CodeLlama (from 27,800 to 25,900) and DeepSeek-Coder-v2 (from 26,700 to 25,600). These reductions\n\nsuggest that retrieval augmentation enables models to generate more concise and efficient Solidity code. Notably, the\n\ngas consumption gap between models narrows when RAG is used, indicating a convergence toward simpler and more\n\nstandardized outputs. Overall, these findings show that RAG generally contributes to modest gains in runtime efficiency,\n\nfurther lowering execution costs compared to baseline generation workflows without retrieval support. However, when\n\nfocusing on the Mean High Consistency values, the improvements are less uniform. While ChatGPT and CodeLlama\n\nbenefit from noticeable reductions, DeepSeek-Coder-v2 and Gemini show slightly higher values. This suggests that\n\nRAG may sometimes favor plausibility and completeness over raw gas optimization in functions that closely replicate\n\nreference behavior.\n\n**4.4** **RQ** 4 **: Complexity**\n\nAnswering **RQ** 4, we provide both cognitive and cyclomatic complexities for each model we used to provide insights into\n\nthe complexity of generated functions. To address this point, Table 5 reports the cognitive complexity statistics for the\n\ngenerated code, together with the distribution of differences compared to the ground truth. We start by discussing results\n\nabout the baseline setting. Thus, all models produce functions that are less cognitively complex than the real contracts\n\nManuscript submitted to ACM\n\nBeyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts15\n\nTable 4. Gas consumption statistics.\n\n**Model** **Min** **Max** **Mean** **Mean High Cons.**\n\nGround Truth 21,424.00 346,395.00 34,636.56 \u2013\n\nChatGPT 2,231.92 63,989.67 28,861.27 32,703.17\n\nChatGPT-RAG 2,569.83 51,401.00 26,595.24 29,295.13\n\nCodeLlama 2,664.83 63,147.00 27,858.41 29,155.30\n\nCodeLlama-RAG 2,664.83 51,706.33 25,929.05 27,426.41\n\nGemini 11,107.00 29,639.00 21,909.33 24,982.00\n\nGemini-RAG 2,664.83 51,435.00 24,871.26 27,856.51\n\nDeepSeek-Coder-v2 4,875.83 49,897.50 26,734.44 27,155.22\n\nDeepSeek-Coder-v2-RAG 2,408.75 46,578.00 25,643.32 28,253.26\n\n(mean = 3.00). Among them, CodeLlama exhibits the highest mean cognitive complexity (2.09), while ChatGPT-4o and\n\nGemini produce simpler code with average values around 1.79.\n\nThe difference analysis shows that, on average, the generated code tends to be simpler. CodeLlama is the only model\n\nwith a slightly positive mean difference (+0.18), suggesting that, in some cases, it can produce functions more complex\n\nthan the originals. In contrast, Gemini and DeepSeek-Coder-v2 have more negative mean differences (-0.38 and -0.30,\n\nrespectively), indicating a consistent simplification of the logic. The wide ranges observed between minimum and\n\nmaximum differences highlight substantial variability: for example, DeepSeek-Coder-v2 generates code that can be up\n\nto 10 points simpler or 6 points more complex than the ground truth, depending on the instance.\n\nTable 5 also shows the cyclomatic complexity results. All models again produce functions with simpler control flow\n\ncompared to the ground truth (mean = 3.08). The average cyclomatic complexity of the generated functions ranges\n\nbetween 2.50 and 2.60, resulting in negative mean differences across all models. For example, DeepSeek-Coder-v2 is\n\nthe model that comes closest to the ground truth in terms of branching logic, with a mean difference of -0.47 and\n\na maximum observed cyclomatic complexity of 15. Conversely, Gemini and ChatGPT-4o tend to generate functions\n\nwith consistently lower complexity, as indicated by the more negative mean differences (-0.57 and -0.56) and smaller\n\nmaximum values.\n\nWhen considering the Correct Only subset, which includes the functions where the corresponding ground truth\n\ncontracts compiled successfully, the results are largely consistent with the overall trends but show slightly reduced\n\ncomplexity scores. For example, the mean cognitive complexity decreases across all models in this subset: CodeLlama\n\ndrops from 2.09 to 1.98, DeepSeek-Coder-v2 from 1.91 to 1.88, and Gemini from 1.79 to 1.58. The same effect is\n\nobserved in cyclomatic complexity, where the mean values also become marginally lower. These reductions suggest that\n\ngenerated code aligned with compilable reference implementations is, on average, simpler in both logic and control flow.\n\nThis pattern likely reflects the relative simplicity of the subset of ground truth functions that compiled successfully,\n\nreinforcing the observation that generation outputs tend to emphasize straightforward structures over more complex\n\npatterns.\n\nThese findings indicate that the evaluated LLMs tend to generate implementations that are less complex both\n\ncognitively and structurally. This simpler style may improve readability and reduce the likelihood of introducing errors,\n\nbut it could also limit their applicability in scenarios requiring sophisticated control flows or advanced design patterns.\n\nManuscript submitted to ACM\n\n16 Salzano et al.\n\nTable 5. Cognitive and cyclomatic complexity statistics and differences compared to the ground truth. Values for \"Correct Only\"\nrepresent metrics calculated solely on compilable ground truth samples and related generations.\n\n**Cognitive Complexity** **Diff Cognitive** **Cyclomatic Complexity** **Diff Cyclomatic**\n**Model**\n\nMean Min Max StdDev Mean Min Max StdDev Mean Max Mean Max\n\nCodeLlama 2.09 1 11 1.20 +0.09 -8.0 +6.0 2.36 2.56 9 -0.52 +8\n\n_Correct Only_ _1.98_ _1_ _5_ _1.07_ _-1.02_ _-9.0_ _+4.0_ _2.01_ _2.41_ _9_ _-0.66_ _+8_\n\nCodeLlama RAG 1.79 1 7 1.12 -0.40 -9.0 +3.0 1.81 2.31 14 -0.77 +13\n\n_Correct Only_ _1.61_ _1_ _7_ _0.91_ _-1.39_ _-28.0_ _+4.0_ _2.00_ _2.12_ _11_ _-0.96_ _+10_\n\nDeepSeek-Coder-v2 1.91 1 10 1.23 -1.09 -10.0 +6.0 2.77 2.60 15 -0.48 +14\n\n_Correct Only_ _1.88_ _1_ _6_ _1.10_ _-1.12_ _-11.0_ _+5.0_ _2.25_ _2.58_ _12_ _-0.50_ _+9_\n\nDeepSeek-Coder-v2 RAG 2.64 1 24 2.26 +0.10 -13.0 +16.0 1.99 3.17 18 +0.09 +17\n\n_Correct Only_ _2.36_ _1_ _10_ _1.75_ _-0.64_ _-28.0_ _+7.0_ _1.77_ _2.68_ _10_ _-0.39_ _+9_\n\nGemini 1.79 1 4 0.79 -1.21 -4.0 +3.0 2.13 2.51 6 -0.57 +5\n\n_Correct Only_ _1.58_ _1_ _3_ _0.76_ _-1.41_ _-5.0_ _+2.0_ _1.84_ _2.40_ _5_ _-0.68_ _+4_\n\nGemini RAG 2.91 1 17 2.47 -0.11 -14.0 +7.0 1.73 2.91 17 -0.16 +16\n\n_Correct Only_ _2.39_ _1_ _10_ _2.00_ _-0.61_ _-28.0_ _+7.0_ _1.76_ _2.36_ _10_ _-0.72_ _+9_\n\nChatGPT-4o 1.79 1 6 1.04 -1.21 -7.0 +4.0 1.98 2.51 8 -0.57 +7\n\n_Correct Only_ _1.76_ _1_ _6_ _1.15_ _-1.24_ _-8.0_ _+3.0_ _1.76_ _2.45_ _8_ _-0.63_ _+5_\n\nChatGPT-4o RAG 1.87 1 8 1.14 -0.27 -8.0 +6.0 1.67 2.40 11 -0.67 +10\n\n_Correct Only_ _1.80_ _1_ _6_ _1.13_ _-1.20_ _-28.0_ _+3.0_ _1.75_ _2.29_ _11_ _-0.79_ _+10_\n\nGround Truth 3.00 1 29 2.90 \u2013 \u2013 \u2013 \u2013 3.08 18 \u2013 \u2013\n\nOn the other hand, introducing additional context through RAG resulted in higher variability and, in several cases,\n\nincreased complexity. Gemini with RAG achieved a mean cognitive complexity (2.91) close to the ground truth (3.00),\n\nsuggesting that richer prompts can encourage models to produce more complex logic. DeepSeek-Coder-v2 with RAG\n\nreached the highest maximum cognitive complexity (24), and it was the only model with a slightly positive mean\n\ndifference (+0.10), indicating that some generated functions were more complex than the reference implementations.\n\nConversely, ChatGPT-4o with RAG remained simpler on average (1.87) and showed a negative mean difference (-0.27).\n\nIn terms of cyclomatic complexity, DeepSeek-Coder-v2 with RAG also stands out as the only model exceeding the\n\nground truth mean (+0.09). All other models continued to generate functions with simpler control flow, displaying\n\nnegative mean differences between -0.16 and -0.77. The maximum cyclomatic complexity values increased substantially\n\nfor all models, confirming that RAG can lead to richer and more diverse control structures. These results indicate that\n\nretrieval-augmented prompts have the potential to narrow the gap between generated and real-world code complexity,\n\nalthough the impact varies across models: while DeepSeek-Coder-v2 and Gemini show clear responsiveness to enriched\n\ninput, ChatGPT-4o remains comparatively conservative. When considering the Correct Only subset, which includes\n\nonly those generations associated with ground truth functions that compiled successfully, the results offer additional\n\nperspective. In this scenario, the models generally produce slightly lower cognitive and cyclomatic complexity scores\n\ncompared to their full distributions. For example, Gemini shows a reduction in mean cognitive complexity from\n\n2.91 to 2.39 when restricting analysis to this subset, while DeepSeek-Coder-v2 decreases from 2.64 to 2.36. Similarly,\n\nChatGPT-4o shifts from 1.87 to 1.80. These reductions indicate that the functions linked to compilable ground truth\n\nimplementations tend to be simpler on average. The same pattern is visible for cyclomatic complexity, where the mean\n\nvalues across all models decrease when measured only on this subset.\n\nManuscript submitted to ACM\n\nBeyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts17"}, {"role": "assistant", "content": "**Mechanism:** The LLM generates code by predicting the next token based on its internal learned patterns, essentially completing a sophisticated fill-in-the-blanks puzzle. RAG (Retrieval-Augmented Generation) introduces a 'lookup' step: relevant code examples are retrieved from a database and prepended to the LLM's input. This acts like injecting specific, ground-truth-aligned 'hints' or 'templates' directly into the model's working memory before it starts generating, biasing its predictions towards the structure and content of the retrieved examples.\n\n**Explanation:** When comparing generated code to ground truth, 'similarity' functions measure different aspects. Semantic similarity is like a deep dictionary lookup, checking if the *meaning* or *purpose* of two code blocks is the same, even if the specific words are different. TED (Tree Edit Distance) is a structural comparison, like counting the insertions, deletions, or changes needed to transform one code's syntax tree into another \u2013 a lower number means more similar structure. BLEU is a textual n-gram overlap metric, like finding common phrases or sequences of characters. RAG improves these because the retrieved examples provide concrete, correct patterns, acting as a strong prior for the LLM to follow, making its output structurally and textually closer to a known good solution. For 'plausibility', meaning functional correctness (does it compile, run, and produce the same output as expected?), RAG works by supplying examples that demonstrate correct logic, including error handling or edge case management. This teaches the LLM to replicate robust behavior, moving beyond superficial similarity to functional equivalence. The impact on 'gas consumption' (computational cost) is mixed: RAG often guides to simpler, more efficient code, but if the retrieved examples add more validation (for better plausibility), gas might slightly increase. 'Complexity' (cognitive ease of understanding, cyclomatic branching paths) typically increases with RAG. By showing complex, real-world examples, RAG pushes the LLM to generate more sophisticated logic and control flow, bridging the gap between simple LLM defaults and human-engineered complexity."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each tree \ud835\udf0f_ \u2208 _\ud835\udc46_ _that contains edge_ ( _\ud835\udc62, \ud835\udc63_ ) **do**\n\n**13** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ \u02dc [\u2032] \u2212 _\ud835\udc53_ ( _\ud835\udf0f_ )/| _\ud835\udc46_ | _,_ _\ud835\udc46_ [\u2032] \u2190 _\ud835\udc46_ [\u2032] \\ _\ud835\udf0f_ ;\n\n**14** _\ud835\udf0f_ [\u2032] \u2190 wilson ( _\ud835\udc3a_ [\u2032] _,\ud835\udc5f_ );\n\n**15** _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] ) \u2190DFS ( _\ud835\udc5f,\ud835\udf0f_ [\u2032] _,\ud835\udf0f_ 0 );\n\n**16** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ \u02dc [\u2032] + _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] )/| _\ud835\udc46_ | _,_ _\ud835\udc46_ [\u2032] \u2190 _\ud835\udc46_ [\u2032] \u222a _\ud835\udf0f_ [\u2032] ;\n\n**17 return** \u02dc _\ud835\udf05_ [\u2032] _,\ud835\udc46_ [\u2032] ;\n\n_replaced with the same number of newly generated USTs from the_\n_updated graph \ud835\udc3a_ 3 _, resulting in the new sample set \ud835\udc46_ 3 _. Finally, updated_\n_samples in \ud835\udc46_ 3 _are used to approximate the_ KC _of \ud835\udc3a_ 3 _._\n\nTheorem 4.2 (Correctness of BSM for Deletion Case).\n\nE _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) [ _\ud835\udc53_ ( _\ud835\udf0f_ )] = E _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393\u2032 ) [ _\ud835\udc53_ ( _\ud835\udf0f_ ) | _\ud835\udc52_ \u2209 _\ud835\udf0f_ ] _._\n\nProof.\n\nE _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393\u2032 ) [ _\ud835\udc53_ ( _\ud835\udf0f_ ) | _\ud835\udc52_ \u2209 _\ud835\udf0f_ ] = \u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )Pr[ _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 [\u2032] ) | _\ud835\udc52_ \u2209 _\ud835\udf0f_ ]\n\n_\ud835\udf0f_ \u2208\u0393 [\u2032]\n\n**Figure 6: Illustration of BSM for Edge Deletion**\n\nProof.\n\nE [1]\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 [\u2032] ) [[] _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]][ =] |\u0393 [\u2032] |\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )\n\n_\ud835\udf0f_ \u2208\u0393 [\u2032]\n\n= [1] \ufffd\ufffd\n\n|\u0393 [\u2032] | \ufffd\n\n\u2211\ufe01\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ ) + \u2211\ufe01\n\n_\ud835\udf0f_ \u2208\u0393 _\ud835\udf0f_ \u2208\u0393 [\u2032]\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )\ufffd [\ufffd]\n\n_\ud835\udf0f_ \u2208\u0393 _\ud835\udc52_ [\u2032] \ufffd\n\n= [1]\n\n|\u0393 [\u2032] |\n\n1\n\n\u2211\ufe01 _\ud835\udf0f_ \u2208\u0393 _\ud835\udc53_ ( _\ud835\udf0f_ ) + |\u0393 [\u2032] |\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )\n\n_\ud835\udf0f_ \u2208\u0393 _\ud835\udc52_ [\u2032]\n\n= [(][1][ \u2212] _[\ud835\udc45]_ [(] _[\ud835\udc52]_ [))]\n\n|\u0393|\n\n\u2211\ufe01 _\ud835\udf0f_ \u2208\u0393 _\ud835\udc53_ ( _\ud835\udf0f_ ) + _[\ud835\udc45]_ |\u0393 [(] _\ud835\udc52_ _[\ud835\udc52]_ [\u2032] | [)]\n\n\u2211\ufe01\n\n|\u0393 _\ud835\udc52_ [\u2032] |\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )\n\n_\ud835\udf0f_ \u2208\u0393 _\ud835\udc52_ [\u2032]\n\n=(1 \u2212 _\ud835\udc45_ ( _\ud835\udc52_ )) E\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) [[] _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]]\n\n+ _\ud835\udc45_ ( _\ud835\udc52_ ) E\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 _\ud835\udc52_ ) [[] _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]] _[.]_\n\nThe second line holds because of \u0393 \u222a \u0393 _\ud835\udc52_ [\u2032] [=][ \u0393][\u2032][ and][ \u0393][ \u2229] [\u0393] _\ud835\udc52_ [\u2032] [=][ \u2205][. And]\nthe forth line can be deduced by |\u0393 _\ud835\udc52_ [\u2032][|/|][\u0393][\u2032][|][ =] _[ \ud835\udc45]_ [(] _[\ud835\udc52]_ [)][.] \n\n**Remarks.** Note that the updated samples set are not yet followed\nthe uniform distribution _\ud835\udc48_ (\u0393 [\u2032] ). Nevertheless, Theorem 4.1 guarantees that the estimator remains unbiased when we uniformly\nsample from both \u0393 [\u2032] and \u0393 _\ud835\udc52_ [\u2032] [and apply appropriate reweighting.]\nAlthough the error bound may change, we assume that the sample\nsize does not need adjustment under small updates in real-world\ndatasets. Our experiments in Section 5 confirm that this method\neffectively preserves estimation accuracy in practice.\n\n**Deletion Case.** As for deleting an edge _\ud835\udc52_, it is more easier to find the\nway to maintain samples. Only those sampled trees which contains\n_\ud835\udc52_ should not exist in new samples. So we just need to remove all\nthese tree and replace them by regular USTs for new graph. To\navoid confusion, we still use \u0393 to represent the case without edge\n_\ud835\udc52_, and \u0393 [\u2032] to represent the spanning trees of the graph that contains\nthe edge _\ud835\udc52_ . However, this time we aim to use samples from _\ud835\udc48_ (\u0393 [\u2032] )\nto approximate the results under _\ud835\udc48_ (\u0393).\n\nExample 6. _Fig. 6 illustrates the process of updating the UST-_\n_samples when an edge is deleted. When the edge_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 3) _is removed_\n_from \ud835\udc3a_ 2 _, all spanning trees that contain_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 3) _must be excluded_\n_from the updated sample set. To achieve this, we first identify all USTs_\n_in the original sample set \ud835\udc46_ 2 _that include_ ( _\ud835\udc63_ 1 _, \ud835\udc63_ 3) _. These trees are then_\n\n= E _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) [ _\ud835\udc53_ ( _\ud835\udf0f_ )]\n\n                     \n\nThe pseudo-code for the basic sample maintenance (BSM) algorithm, covering both edge insertion and deletion cases, is presented\nin Algorithm 2. For each sampled tree, both _\ud835\udc53_ ( _\ud835\udf0f_ ) and its corresponding edges need to be stored. In the case of edge insertion, we first\ncompute the effective resistance _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ) in the updated graph to\ndetermine the number of indices that need to be replaced (Lines\n3\u20134). For the computation of single-pair effective resistance, we\nemploy the state-of-the-art method Bipush [31]. For the selected\n_\ud835\udc3e_ trees that are to be discarded, their contribution to the estimator\u02dc should be subtracted (Line 6). To sample a uniform spanning\ntree that includes the newly inserted edge ( _\ud835\udc62, \ud835\udc63_ ), A modified Wilson algorithm can be applied by setting _\ud835\udc62_ and _\ud835\udc63_ as the root [5, 41]\nand then redirecting all tree edges toward the root node _\ud835\udc5f_ (Lines\n\n\u2211\ufe01 _\ud835\udf0f_ \u2208\u0393 _\ud835\udc53_ ( _\ud835\udf0f_ ) [Pr][[] _[\ud835\udf0f]_ [\u223c] Pr _[\ud835\udc48]_ [ [(] _\ud835\udc52_ [\u0393][\u2032] \u2209 [)][ \u2227] _\ud835\udf0f_ ] _[\ud835\udf0f]_ [\u2208] [\u0393][]]\n\n=\n\u2211\ufe01\n\nPr[ _\ud835\udc52_ \u2209 _\ud835\udf0f_ ]\n\n\u2211\ufe01 _\ud835\udf0f_ \u2208\u0393 _\ud835\udc53_ ( _\ud835\udf0f_ ) |\u0393 [1]\n\n=\n\u2211\ufe01\n\n[1] [|][\u0393][|]\n\n|\u0393 [\u2032] | [/] |\u0393 [\u2032] |\n\n|\u0393 [\u2032] |\n\n= [1]\n\n|\u0393|\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f_ )\n\n_\ud835\udf0f_ \u2208\u0393\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n7\u20138). Finally, we compute _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] ) for these newly generated trees\nfollowing the approach in Algorithm 1 and store them as part of\nthe updated samples (lines 9\u201310). In deletion case, we just check\nall samples whether contains ( _\ud835\udc62, \ud835\udc63_ ). For those trees with ( _\ud835\udc62, \ud835\udc63_ ), we\nreplace them with uniformly spanning trees without ( _\ud835\udc62, \ud835\udc63_ ) by using\nthe regular Wilson algorithm on the graph _\ud835\udc3a_ [\u2032], and recalculate their\ncontribution for _\ud835\udc3e_ [\u02dc] (Lines 12-16).\n\nTheorem 4.3 (Correctness and Time Complexity of BSM).\nBSM _returns an estimate_ \u02dc _\ud835\udf05_ [\u2032] _that satisfies the relative-error guarantee._\n_The overall time complexity of_ BSM _is_\n\n_\ud835\udc42_ [\ufffd] _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udf14_    - [\ufffd] Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc52_ ) [\u2212][1] + _\ud835\udc5b_ min(\u0394 _,_ log _\ud835\udc5b_ ) [\ufffd\ufffd] _,_\n\n_where \ud835\udc52_ = ( _\ud835\udc62, \ud835\udc63_ ) _is the inserted (or deleted) edge, \ud835\udc45_ ( _\ud835\udc52_ ) _denotes its_\n_effective resistance in the graph that includes \ud835\udc52, and \ud835\udc43\ud835\udc52_ _is the transition_\n_matrix with the \ud835\udc62-th and \ud835\udc63-th rows and columns removed._\n\nProof. To establish the correctness of BSM, we leverage Theorem 4.1 and Theorem 4.2 to construct an unbiased estimator for the\n\nKC of the updated graph. However, to accelerate the computation,\nwe avoid recalculating _\ud835\udc53_ ( _\ud835\udf0f_ ) for unchanged USTs, even though its\nvalue undergoes slight variations due to changes in the degrees of\nthe updated edge\u2019s endpoints. Fortunately, the resulting error in\nthe estimator \u02dc _\ud835\udf05_ [\u2032] can be bounded by \u0394, which is negligible when\nconsidering the relative error, as _\ud835\udf05_ is larger than _\ud835\udc5b_ and thus significantly greater than \u0394. Experimental results further confirm that\nthe estimation maintains a high level of accuracy.\nRegarding time complexity, only _\ud835\udc45_ ( _\ud835\udc52_ ) \u00b7 _\ud835\udc47_ USTs are updated. The\ntime complexity for constructing and querying these USTs remains\nsimilar to the static case. The only exception arises in the insertion\ncase, where the modified Wilson algorithm incurs a complexity of\n_\ud835\udc42_ (Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc52_ ) [\u2212][1] ) instead of _\ud835\udc42_ (Tr( _\ud835\udc3c_ \u2212 _\ud835\udc43\ud835\udc5f_ ) [\u2212][1] ). However, the difference\nbetween these two complexity is minimal and remains within the\nsame level. Consequently, the overall time complexity for updating\naligns with the statement of the theorem. \n\n**Discussion.** Compared to Algorithm 1, BSM selectively updates\nonly an _\ud835\udc45_ ( _\ud835\udc52_ ) fraction of the samples, and by appropriately reweighting the old and new contributions, the estimator remains unbiased.\nThis strategy substantially reduces the number of samples to be\ngenerated and the associated computations. As shown in Table 2,\nthe effective resistance is typically small (can be below 0.1 in social\nnetworks), further lowering the computational cost.\n\n**4.2** **Improved Sample Maintenance (ISM)**\n\nAlthough the basic maintenance method significantly reduces computation compared to static algorithms, replacing a portion of the\nold samples still results in some loss of information. Can we maintain an unbiased estimation while maximizing the utility of the\ncomputations contributed by these replaced trees? To address this\nquestion, we proposed Improved Sample Maintenance (ISM) methods, discussing the insertion and then deletion scenarios in order.\n\n**Insertion Case.** When considering to transform a tree that does not\ncontain edge _\ud835\udc52_ into one that does, what happens if we simply add\nedge _\ud835\udc52_ to the tree? This operation creates a cycle, and by removing\nany edge other than _\ud835\udc52_ from this cycle, a new tree that includes _\ud835\udc52_\ncan be obtained. We refer to this process as a _link-cut_ operation.\n\n|\ud835\udf49\ud835\udf49<br>\ud835\udfd2\ud835\udfd2|\u0393\u2032<br>e|\n|---|---|\n|\ud835\udf49\ud835\udfd3|\ud835\udf49\ud835\udfd3|\n|\ud835\udf49\ud835\udfd3||\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-10-0.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-10-1.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-10-2.png)\n\n**Figure 8: Link-Cut Bipartite Graph** B\n\nSpecifically, _link-cut_ ( _\ud835\udf0f,\ud835\udc52_ ) is defined as linking the edge _\ud835\udc52_ and cutting\none of the other edges in the cycle created by _\ud835\udc52_ and path in tree.\nUsing this method to generate spanning trees containing edge _\ud835\udc52_\nis not only significantly faster than the Wilson algorithm but also\npreserves parts of the tree\u2019s structure, allowing us to recompute\nonly the affected parts. As illustrated in Fig. 7a, after linking the\nedge ( _\ud835\udc62, \ud835\udc63_ ) and cutting a randomly selected edge in the cycle, all\nnodes whose paths to the root are altered lie within the subtree of\n_\ud835\udc62_ . This enables us to leverage the previous results for unaffected\nnodes, further reducing the computational cost.\nHowever, the spanning trees sampled by _link-cut_ are not uniformly distributed. To better understand this, consider an abstract\ngraph where each spanning tree is treated as a node, and an edge\nexists between two nodes if one tree can be transformed into the\n\nother through a link-cut operation. This forms a bipartite graph\nbetween \u0393 and \u0393 _\ud835\udc52_ [\u2032][, denoted as][ B][. Let][ N][B] [(] _[\ud835\udf0f]_ [)][ represents the set of]\nneighbors of a tree _\ud835\udf0f_, corresponding to the spanning trees that can\nbe obtained by performing a link-cut operation on _\ud835\udf0f_ . The degree of\neach tree _\ud835\udf0f_ \u2208 \u0393, denoted as _\ud835\udc51_ ( _\ud835\udf0f_ ), is determined by the length of the\ncycle formed when edge _\ud835\udc52_ is added to _\ud835\udf0f_ .\nClearly, if we randomly transform a tree in \u0393 into one of its\nneighbors with equal probability 1/ _\ud835\udc51_ ( _\ud835\udf0f_ ) using the link-cut operation, some trees in \u0393 _\ud835\udc52_ [\u2032] [will have higher selection probabilities than]\nothers. Fortunately, this bias can be corrected by appropriately\nweighting the tree. As illustrated in Figure 8, the non-uniformity\nof link-cut sampling arises primarily due to two factors:\n\n - The out-degree of nodes _\ud835\udf0f_ \u2208 \u0393 are different.\n\n - The in-degree of nodes _\ud835\udf0f\ud835\udc52_ \u2208 \u0393 _\ud835\udc52_ [\u2032] [are different.]\n\nBy appropriately reweighting based on these two factors, we can\nensure that the estimator remains unbiased, even though the transformation probabilities are not uniform.\n\nExample 7. _Figure 8 illustrates a link-cut bipartite graph for an_\n_evolving graph. Here_ _\ud835\udf0f_ 1 _to_ _\ud835\udf0f_ 5 _represent all spanning trees in the updated_\n_graph. Among them, \ud835\udf0f_ 1 _to \ud835\udf0f_ 3 _belong to the original tree set_ \u0393 _, while_\n\n**(a) link-cut operation**\n\n**(b) cut-link operation**\n\n**Figure 7: Illustration of link-cut and cut-link operation**\n\n1\n\ud835\udc5d\ud835\udc5d=\n\nw = [1]\n\nw = [2]\n3\n\n_\ud835\udf0f_ 4 _and \ud835\udf0f_ 5 _are new trees introduced by the update. Each edge in the_\n_bipartite graph corresponds to a possible transformation between trees_\n_via the link-cut operation._\n_Due to differences in outdegree, selecting an outgoing edge from \ud835\udf0f_ 1\n_is more likely than from \ud835\udf0f_ 3 _. Moreover, \ud835\udf0f_ 4 _can be reached from \ud835\udf0f_ 1 _,\ud835\udf0f_ 2 _,\ud835\udf0f_ 3 _,_\n_whereas \ud835\udf0f_ 5 _can only be reached from \ud835\udf0f_ 3 _. If we uniformly select a tree_\n_from_ \u0393 _and apply the link-cut operation, the probabilities of obtaining_\n_the new trees are \ud835\udc5d_ ( _\ud835\udf0f_ 4) = 6 [5] _[and][ \ud835\udc5d]_ [(] _[\ud835\udf0f]_ [5][)][ =] [1] 6 _[, which are biased.]_\n\n_By applying appropriate reweighting, we can correct for this bias to_\n_preserve the expected contributions of each tree:_ E[ _\ud835\udf0f_ 4] = [1] 3 [\u00d7] [1] 3 [+] [1] 3 [\u00d7] 3 [1] [+]\n\n13 [\u00d7] [1] 2 [\u00d7] [2] 3 [=] [1] 3 _[,]_ [ E][[] _[\ud835\udf0f]_ [5][]][ =] [1] 3 [\u00d7] [1] 2 [\u00d7][ 2][ =] 3 [1] _[.][ This ensures that the estimator]_\n\n_remains unbiased, even though the transformation probabilities are_\n_not uniform._\n\n6 [5] _[and][ \ud835\udc5d]_ [(] _[\ud835\udf0f]_ [5][)][ =] [1] 6\n\n[1] 3 [\u00d7] [1] 3\n\n[1] 3 [+] [1] 3\n\n[1] 3 [\u00d7] 3 [1]\n\n[1] 2 [\u00d7] [2] 3\n\n[1] [1]\n\n3 _[,]_ [ E][[] _[\ud835\udf0f]_ [5][]][ =] 3\n\n[2] [1]\n\n3 [=] 3\n\n[1] 3 [\u00d7] [1] 2\n\n[1] 2 [\u00d7][ 2][ =] 3 [1]\n\nTheorem 4.4.\n\nE [ _\ud835\udc53_ ( _\ud835\udf0f_ )] = [1][ \u2212] _[\ud835\udc45]_ [(] _[\ud835\udc52]_ [)] E E\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 _\ud835\udc52_ [\u2032] ) _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) \ufffd _\ud835\udf0f\ud835\udc52_ \u223c _\ud835\udc48_ (N _\ud835\udc35_ ( _\ud835\udf0f_ ))\n\nProof.\n\n_\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _[\ud835\udc51]_ [(] _[\ud835\udf0f]_ [)]\n\ufffd _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ )\n\n_._ (8)\n\ufffd\ufffd\n\n  \n\n\ufffd\ufffd\n\nE\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393)\n\nE\n\ufffd _\ud835\udf0f\ud835\udc52_ \u223c _\ud835\udc48_ (NB ( _\ud835\udf0f_ ))\n\n_\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _[\ud835\udc51]_ [(] _[\ud835\udf0f]_ [)]\n\ufffd _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ )\n\n_\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _[\ud835\udc51]_ [(] _[\ud835\udf0f]_ [)]\n\ufffd _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_\n\n= [1]\n\n|\u0393|\n\n= [1]\n\n|\u0393|\n\n= [1]\n\n|\u0393|\n\n= [1]\n\n|\u0393|\n\n1\n_\ud835\udf0f_ \u2211\ufe01 _\ud835\udc52_ \u2208\u0393 _\ud835\udc52_ [\u2032] _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ )( _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ ) [)]\n\nE\n\n\u2211\ufe01 _\ud835\udf0f_ \u2208\u0393 _\ud835\udf0f\ud835\udc52_ \u223c _\ud835\udc48_ (NB ( _\ud835\udf0f_ ))\n\n_\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _[\ud835\udc51]_ [(] _[\ud835\udf0f]_ [)]\n\ufffd _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ ) \ufffd\n\n_\ud835\udf0f\ud835\udc52_ \u2208N\u2211\ufe01B ( _\ud835\udf0f_ ) _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _\ud835\udc51_ _[\ud835\udc51]_ ( [(] _\ud835\udf0f_ _[\ud835\udf0f]_ _\ud835\udc52_ [)] )\n\n\u2211\ufe01\n\n_\ud835\udf0f_ \u2208\u0393\n\n\u2211\ufe01\n\n_\ud835\udf0f_ \u2208\u0393\n\n\ufffd\ufffd\n\ufffd\n\n1\n_\ud835\udf0f\ud835\udc52_ \u2208N\u2211\ufe01B ( _\ud835\udf0f_ ) _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ ) _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ )\n\n1\n\n_\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ )\n\n\u2211\ufe01\n\n_[\ud835\udc51]_ [(] _[\ud835\udf0f]_ [)] \ufffd\ufffd\n\n_\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ ) \ufffd\n\n_\ud835\udc45_ ( _\ud835\udc52_ ) 1\n=\n1 \u2212 _\ud835\udc45_ ( _\ud835\udc52_ ) |\u0393 _\ud835\udc52_ [\u2032] |\n\n\u2211\ufe01 _\ud835\udc53_ ( _\ud835\udf0f\ud835\udc52_ )\n\n_\ud835\udf0f\ud835\udc52_ \u2208\u0393 _\ud835\udc52_ [\u2032]\n\n_\ud835\udc45_ ( _\ud835\udc52_ )\n= E\n1 \u2212 _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393 _\ud835\udc52_ [\u2032] ) [[] _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]]\n\nAssigning the weight of trees obtained via the _link-cut_ operation\nas _\ud835\udc51_ ( _\ud835\udf0f_ )/ _\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ ) provides an estimate for _\ud835\udc53_ ( _\ud835\udf0f_ ) under the uniform\ndistribution in \u0393 _\ud835\udc52_ [\u2032][. By substituting Eq. (8) into the second term on]\nthe right-hand side of Eq. (7), we obtain an unbiased estimator of\nKC for the updated graph _\ud835\udc3a_ [\u2032] .\n\n**Deletion Case.** Similarly, we can transform a tree containing edge\n_\ud835\udc52_ into one without it through the _cut-link_ operation. _cut-link_ ( _\ud835\udf0f\ud835\udc52,\ud835\udc52_ )\ninvolves cutting _\ud835\udc52_ from a spanning tree, resulting in a 2-forest, and\nthen linking another edge from graph _\ud835\udc3a_ to reconnect the 2-forest.\nThis operation changes the paths of all nodes within the subtree\nof the newly linked edge, while other paths remain unchanged. As\nin the insertion case, we can correct the distribution by assigning\nweights, with only slight differences in implementation.\n\nTheorem 4.5.\n\n_\ud835\udc53_ ( _\ud835\udf0f_ ) _[\ud835\udc51]_ [(] _[\ud835\udf0f][\ud835\udc52]_ [)]\n\ufffd _\ud835\udc51_ ( _\ud835\udf0f_ )\n\n_._ (9)\n\ufffd\ufffd\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n**Algorithm 3:** ISM\n\n**Input:** A graph _\ud835\udc3a_ = ( _\ud835\udc49, \ud835\udc38_ ), root _\ud835\udc5f_, an updated edge ( _\ud835\udc62, \ud835\udc63_ ), original\nsample set _\ud835\udc46_\n**Output:** updated estimation \u02dc _\ud835\udf05_ [\u2032], updated sample set _\ud835\udc46_ [\u2032]\n\n**1** \u02dc _\ud835\udf05_ [\u2032] \u2190 0;\n\n**2 if** _Update is_ Ins ( _\ud835\udc62, \ud835\udc63_ ) **then**\n\n**3** Compute _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ) in _\ud835\udc3a_ \u222a( _\ud835\udc62, \ud835\udc63_ );\n\n**4** Randomly select \u2308 _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ) \u00b7 | _\ud835\udc46_ |\u2309 trees in _\ud835\udc46_ ;"}, {"role": "assistant", "content": "**Mechanism:** The fundamental goal is to maintain an unbiased Monte Carlo estimator for the Kemeny Constant of a graph, which relies on averaging a function 'f(tau)' over a sample set 'S' of Uniform Spanning Trees (USTs). When an edge is modified (inserted or deleted), the set of all possible USTs (Gamma) changes. The BSM (Basic Sample Maintenance) algorithm directly addresses this by identifying the 'invalid' trees in the sample set (those containing a deleted edge, or those that should now include an inserted edge) and replacing them with newly generated USTs from the updated graph using a Wilson algorithm variant. This replacement ensures the sample set again reflects the new uniform distribution, thus preserving the unbiased property of the estimator. The ISM (Improved Sample Maintenance) method refines this by avoiding full regeneration. For edge insertion, it uses a 'link-cut' operation: adding the new edge to an existing UST creates a cycle, and removing another edge from this cycle transforms the tree to include the new edge. This operation is faster but introduces sampling bias (not all new trees are equally likely). ISM corrects this bias by reweighting the contribution of each transformed tree by a factor 'd(tau)/d(tau_e)', where 'd(tau)' is the 'out-degree' (number of new trees 'tau' can transform into) and 'd(tau_e)' is the 'in-degree' (number of old trees that can transform into 'tau_e'). These weights effectively normalize the non-uniform probabilities, making the estimator unbiased again. This is analogous to adjusting the values in a lookup table or array to account for non-random access patterns.\n\n**Explanation:** At its core, the system wants to calculate a 'Kemeny Constant' by looking at many 'Uniform Spanning Trees' (USTs). Think of USTs as random, loop-free paths that connect everything in a network. To do this, we collect a 'sample' of these trees. When an edge (a connection) is added or removed from our network, our existing sample of trees might no longer be 'uniform' for the new network, or some might even become invalid. The 'Basic Sample Maintenance' (BSM) is like updating an array or list of objects: if an object (tree) is no longer valid or doesn't fit the new criteria, you remove it and add a brand new, randomly generated object (tree) to its place. This is done by running a tree-generation function (like a `generateNewUST()` method). The proofs show that if you replace the right proportion of trees (determined by 'effective resistance R(e)', which is the probability a random UST contains edge 'e'), the average value you calculate (your estimator) remains correct. The 'Improved Sample Maintenance' (ISM) is a cleverer update. Instead of completely replacing trees, it tries to 'mutate' them. For an edge insertion, it takes an existing tree that *doesn't* have the new edge, 'links' the new edge (creating a temporary cycle), and then 'cuts' another edge in that cycle to form a *new* valid tree that *does* have the inserted edge. This 'link-cut' operation is much faster than generating a whole new tree from scratch because it reuses most of the tree's structure. However, this mutation isn't perfectly random, meaning some new trees might be generated more often than others. To fix this, ISM applies a 'weight' to each mutated tree. This weight is like a scalar multiplier (e.g., `tree.contribution *= weightFactor`) that corrects for the bias introduced by the non-uniform mutation process, ensuring that the overall average of these weighted contributions is still accurate, even though the individual trees weren't selected perfectly uniformly."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each selected tree \ud835\udf0f_ **do**\n\n**6** _\ud835\udf0f_ [\u2032] \u2190 link-cut ( _\ud835\udf0f,_ ( _\ud835\udc62, \ud835\udc63_ ));\n\n**7** Update _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] );\n\n**8** Calculate weight as _\ud835\udc64_ ( _\ud835\udf0f_ [\u2032] ) = _\ud835\udc51_ _[\ud835\udc51]_ ( [(] _\ud835\udf0f_ _[\ud835\udf0f]_ ~~[\u2032]~~ [)] ) _[\ud835\udc64]_ [(] _[\ud835\udf0f]_ [)][;]"}, {"role": "assistant", "content": "**Mechanism:** This algorithm iterates through a collection of tree-like data structures, similar to looping over a list of graph objects in software. For each tree, it performs a 'link-cut' operation, which dynamically modifies the tree's structure by adding or removing edges. Think of it as sophisticated pointer manipulation: it can logically 'cut' an edge between two nodes, effectively splitting a tree, or 'link' two nodes to connect separate trees. This operation is designed to maintain efficiency (typically logarithmic time complexity) for large graphs by often employing underlying self-balancing binary search trees (like splay trees) to represent paths. After the tree's connections are altered, a function 'f' is updated, which represents some aggregated property or state of the tree that now needs recalculation, much like invalidating and recomputing a cached value. Finally, a new 'weight' 'w' is calculated for this modified tree, assigning it a numerical significance based on its new structure or properties.\n\n**Explanation:** This process is like having a dynamic network where connections can change rapidly. The 'link-cut' operation is an advanced method to rewire that network efficiently, similar to how a hash table rebalances itself internally but applied to graph topology. The subsequent 'update f' step ensures that any derived information about the network, like its total capacity or path length (a cached property), is consistent with the new structure. The final 'calculate weight' step then quantifies the value or cost of this new network configuration, perhaps based on its depth or connectivity, allowing for comparisons or decision-making in the larger algorithm."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**8 end for**\n\n**9 return** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_\n\nThe theoretical aspects of _minRTT_ packet scheduling algorithm are provided in 2.2.1.\n\n**Algorithm 2:** BLEST\n\n**Input:** Set of available subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R, _\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc53_ _< \ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_\n\n**Output:** Best subflow, _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2208S\n\n**1** _\ud835\udc65_ _\ud835\udc53_ \u2190 _\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**2 if** _fastest subflow \ud835\udc65_ _\ud835\udc53_ _is available_ **then**\n\n**3** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc65_ _\ud835\udc53_ ;\n\n**4 else if** _slower subflow \ud835\udc65\ud835\udc60_ _is available_ **then**\n\n**5** _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_ = _\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_ / _\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc53_ ;\n\n**6** _\ud835\udc4b_ = _\ud835\udc40\ud835\udc46\ud835\udc46_ _\ud835\udc53_ \u2217( _\ud835\udc36\ud835\udc4a\ud835\udc41\ud835\udc37_ _\ud835\udc53_ + ( _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_ \u2212 1)/2) \u2217 _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_ ;"}, {"role": "assistant", "content": "**Mechanism:** The algorithm implements a conditional path selection mechanism, prioritizing the lowest-latency subflow and falling back to a slower alternative if the primary is unavailable.\n\n**Explanation:** This is fundamentally an 'if-then-else' control flow for network path selection. It first invokes a function (like a database query or lookup in a hash map) to identify the subflow with the absolute minimum Round-Trip Time (RTT), which is its responsiveness or 'ping' time. If this fastest subflow is currently active and ready to transmit data, it's immediately chosen. If that fastest path isn't available (perhaps due to congestion or being offline), the algorithm then checks for a 'slower' subflow. The subsequent calculations determine characteristics of this slower path: 'rtts' calculates a ratio comparing the slower path's smoothed RTT to the faster one, giving an intuitive sense of its relative delay. 'X' appears to be an attempt to quantify the potential throughput or capacity of this slower path, combining Maximum Segment Size (MSS), Congestion Window (CWND), and the RTT ratio, effectively trying to estimate how much data it can push."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Dataset Distillation.** As dataset and model sizes continue to grow, so has the interest in more\nefficient forms of learning. To this end, researchers have worked towards methods of _learning_\noptimal training data such that one could train an effective model from scratch using as few\nsamples as possible. One such solution to this problem was the initial proposal of _Dataset_\n_Distillation_ [47] in which the model\u2019s final performance was expressed as a function of the _synthetic_\n_training data_ that was optimized end-to-end by back-propagating through many inner training\niterations. Follow-up works introduced proxy losses and learned synthetic images that matched\ngradients [55], feature distributions [54], training trajectories [6] and more [27, 51, 56]. Some\nworks extend dataset distillation to large models [50, 51], but these methods do not excel in the\nultra-small data regime, i.e., one image per class. For such settings, Trajectory Matching [6] and\n\n2\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-2-1.png)\n\nReal Images\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-2-0.png)\n\nFigure 2: **Linear Gradient Matching for Pre-Trained Vision Models:** Given a pre-trained self-supervised\nvision model ( _\u03d5_ ), we perform a distillation step by first passing a batch of real and synthetic data through _\u03d5_\nand a randomly-initialized linear classifier ( _W_ ) to get the real and synthetic classification losses ( _\u2113_ real and _\u2113_ syn).\nOur meta loss ( _L_ meta) is then defined as the cosine distance between the _gradients_ of these classification losses\n( _\u2113_ real and _\u2113_ syn) with respect to the random linear probe ( _W_ ). This meta loss is then back-propagated through the initial synthetic gradient calculation and used to update our synthetic images. This technique allows us to distill large\ndatasets to just a single image per class while still achieving high performance when training new linear probes.\n\nits modifications [7, 11, 16, 32, 40] still reign supreme. However, this method fails to scale up to\nlarge models due to memory constraints and instability in the bi-level optimization.\n\nThis work introduces a new problem in the space of dataset distillation: learning synthetic images\nfor the purpose of training _linear probes_ on top of _pre-trained self-supervised feature extractors_\ninstead of training randomly initialized models from scratch. Our proposed solution, _Linear Gradient_\n_Matching_, takes inspiration from prior work on gradient matching [55] and trajectory matching [6]\nbut only considers gradients of the linear classifier as opposed to the entire model.\n\n**Self-Supervised Learning.** Given that the overwhelming majority of available visual data lacks\nany useful labels, _Self-Supervised Learning_ has become the defacto method of pre-training neural\nnetworks to be later used for down-stream tasks. In recent years, several different paradigms of\nself-supervised training have emerged, including contrastive learners [5, 8\u201310, 18, 31], masked\nauto-encoders [17, 37], vision-language models [34, 41, 44, 52], and hybrid approaches [13, 14].\nDespite the various training methods, researchers have noticed that these different models tend\nto learn similar representations, even across different modalities, and dubbed this observation the\n\u201cPlatonic Representation Hypothesis\u201d [20].\n\nIn this work, we focus on distilling datasets using four pre-trained self-supervised models in\nparticular: CLIP [34], DINO-v2 [31], EVA-02 [13], and MoCo-v3 [10]. Since our feature extractors\nwere pre-trained in a purely self-supervised manner, our linear probes still only see a single _labeled_\nsample per class while achieving competitive performance."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism centers on crafting synthetic input images such that a simple, untrained 'decision layer' (a linear classifier) attached to an already intelligent 'feature extractor' (a pre-trained self-supervised model) learns its classification rules by observing these synthetic images. Critically, these synthetic images are designed to induce the *exact same adjustment signal* for the decision layer's internal parameters (weights) as if it were observing the full set of real training images. This 'adjustment signal' is the gradient of the classification loss with respect to the decision layer's weights. We repeatedly refine the synthetic images by measuring the 'direction similarity' (cosine distance) between the gradients produced by real data versus synthetic data, and then updating the synthetic images to minimize this distance. Since the feature extractor already provides robust, high-level representations, the decision layer only needs to learn to draw simple boundaries in this well-structured feature space. Focusing the gradient matching solely on this lightweight decision layer drastically simplifies the optimization problem.\n\n**Explanation:** Imagine you have an advanced machine (`phi`, the pre-trained self-supervised model) that can look at any image and output a unique 'fingerprint' \u2013 a compact numerical description of what's in the image. This machine is already incredibly good at understanding visual patterns because it learned from countless unlabeled images. Now, you want to build a simple 'gatekeeper' (`W`, the linear classifier) on top of this machine to sort these fingerprints into categories (e.g., 'cat fingerprint,' 'dog fingerprint'). Instead of feeding the gatekeeper thousands of real fingerprints, we want to create just a few 'master' synthetic fingerprints. When the gatekeeper sees a real fingerprint and tries to sort it, it figures out how much it needs to 'tweak' its internal sorting rules to do better. This 'tweak direction' is its gradient. Our method iteratively generates synthetic images (and thus synthetic fingerprints). For each synthetic fingerprint, we calculate the gatekeeper's 'tweak direction.' We then compare this synthetic 'tweak direction' to the 'tweak direction' that would be produced by *real* fingerprints. By using a 'direction similarity score' (cosine distance), we continuously adjust our synthetic images until their fingerprints cause the gatekeeper to want to 'tweak' its rules in *exactly the same way* as the real fingerprints. Because the main machine (`phi`) is so good at making sense of images, the gatekeeper only needs to learn very simple, clear rules from these perfectly crafted synthetic fingerprints, allowing it to classify accurately even with just one synthetic image per category."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nOur findings do not imply that there has been no progress in improving spatial supersensing. Cambrian S reports\nthat Gemini-2.5-Flash, used as a generic long-context video model, achieves around 41.5% accuracy on 60-minute\n\n7\n\n                               VSR videos \u2013 similar in magnitude to Cambrian S model with predictive memory on the same split \u2013 despite having\nno benchmark-specific inference design exposed to users (see Figure 11 in (Yang et al., 2025b)). This illustrates that\n\n                                       substantial VSR performance can arise from generic large scale video training and long context, without explicit\n\n         supersensing targeted inference. Our main emphasis in this work is that (1) current spatial supersensing benchmarks\ndo not sufficiently evaluate their spatial supersensing capabilities, and (2) current methods are specifically designed\nto target these benchmark idiosyncracies. For VSI-Super in particular, models can score well by encoding rules such\nas \u201cfour object insertions\u201d or \u201crooms never repeat\u201d rather than by building a stable internal map that survives\nrevisits and perturbations. Looking forwards, we suggest some design principles that might partially fix these issues:\n\n**Invariance checks should be built in.** Benchmarks that claim to test long-horizon reasoning or spatial\nsupersensing should include transformations that keep the ground truth fixed but alter superficial structure.\nExamples include repeating scenes, inserting revisits after long delays, shuffling segments with the same layout, or\nchanging playback speed. Our proposed _VSC-Repeat_ shows how these checks reveal shortcuts: repeating the same\nvideo several times should leave the unique-object count unchanged, yet we find Cambrian-S\u2019 inference pipeline\novercounts objects as if each segment were new. Designing such checks alongside benchmarks, and reporting\nperformance under these perturbed conditions, makes it harder for methods to rely on benchmark-specific quirks.\n\n**Use more natural long-form video.** VSC aims to test accumulation of information and global coherence\nover long horizons, but its construction relies on \u201csurprise\u201d boundaries and curated episodes with non-repeating\nenvironments. This choice simplifies both data generation and inference, but it also encourages shortcuts that equate\nboundaries with environment changes. A more direct test of spatial supersensing would use truly long, continuous\nvideos in which surprise does not reliably signal new environments \u2013 e.g., egocentric traversals of buildings, streets,\nor synthetic worlds with natural revisits and loops (Singh et al., 2016; Grauman et al., 2024). In such settings,\nmethods cannot safely treat every boundary as a new room and must track identity and layout explicitly.\n\n**Emphasizing Open-Endedness and Independence of Modalities.** Benchmarks should stay aligned with\nrealistic use cases. Benchmarks that collapse rich, open-ended tasks into narrow MCQs risk overstating practical\ncapability and obscuring model limitations (Balepur et al., 2025; Chandak et al., 2025). In multimodal understanding,\nmost work has focused on inter-modality dependencies (how different modalities jointly relate to the output). However,\ninformation available in a single modality is often critical: We do not want self-driving cars to stop only when both\nvideo and audio agree that there is a pedestrian ahead. We believe more work should model both intra-modality\n(the contribution of each modality on its own) and inter-modality dependencies (their joint relationships with the\ntarget task) to advance multimodal learning (Madaan et al., 2025, 2024; Zverev et al., 2025).\n\n**Meta-evaluation should be routine.** Our tools\u2014 _NoSense_ for VSR and _VSC-Repeat_ for VSC\u2014act as simple\nstress tests of what benchmarks and methods actually require. We view this kind of meta-evaluation as analogous to\nablation studies for models and believe it should be standard for benchmarks. For any proposed spatial supersensing\ntask, we should ask: what is the simplest streaming baseline that exploits obvious regularities? Which invariances\nshould hold, and do methods respect them? How does performance change when we break assumptions about\nsegment length, revisit frequency, or segment structure? Answering these will help separate genuine advances in\nworld modeling from improvements tied to a specific data generator. Posing such questions has led to immense\nprogress before in computer vision (Beyer et al., 2020), language modelling (Gema et al., 2025; Ghosh et al., 2025;\nNezhurina et al., 2024), compositionality (Udandarao et al., 2025; Hsieh et al., 2023) and reasoning (Hochlehnert\net al., 2025; Yao et al., 2025), and can hopefully further spur spatial supersensing as a more robust paradigm."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism being criticized is that current 'spatial supersensing' models exploit artifacts in benchmark design rather than constructing robust, stable internal representations of an environment. This is akin to a software program hardcoding specific 'if-then' rules based on observed data patterns, instead of building a flexible data structure (like a `HashMap` or a graph) that can handle variations. For instance, in `VSI-Super`, models might learn 'four object insertions' as a rule, which is a shortcut based on data generation rather than true spatial reasoning. When 'invariance checks' are introduced (e.g., repeating the same video segment), models are forced to maintain a consistent internal state (e.g., a unique object count) across superficial input changes. If a model overcounts objects upon revisiting a scene, it's treating each visual segment as a new context, similar to creating a new object in memory instead of referencing an existing one. 'Natural long-form video' challenges models to explicitly track identity and layout over time, preventing them from using event boundaries as proxies for 'new environment' markers, thereby requiring a more persistent, graph-like mapping of locations and objects.\n\n**Explanation:** Currently, models designed to 'understand' video spaces often take shortcuts. Instead of building a mental map like a human would, they look for predictable patterns in how the test videos are made. For example, if a benchmark always shows new 'rooms' after a specific type of video cut, the model learns to associate 'cut' with 'new room' and just resets its mental count, rather than tracking if it's revisited an old room. This is like a program that always assumes a new `segment_ID` means a new data entry, instead of checking if that `segment_ID` might actually refer to a previously seen `object_ID`. The proposed solutions aim to break these shortcuts. By introducing 'invariance checks' (like showing the same scene multiple times but slightly altered), we force the model to maintain a consistent internal state \u2013 essentially, requiring it to use a `pointer` to an existing 'room object' rather than creating a new one every time the visual input changes slightly. Using truly long, continuous video means the model can't rely on simple 'boundary' triggers; it must build a persistent, global 'map' (like a `graph data structure` where nodes are locations and edges are paths) and explicitly track objects and their identities across revisits, much like how a `hash map` would store and retrieve information about unique items regardless of how many times they appear in an input stream."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**More Application Scenarios** . In this work, we primarily\ninvestigate how speculative decoding can accelerate RL training by mitigating long-tail rollouts. We believe this technique\nalso opens promising avenues for broader applications. For\nexample: (1) _Uniformly long responses_ . When all rollouts are\nlong and no tail exists, each request demands substantial\nKV-cache capacity. This often makes the system KV-cachebound and triggers request eviction, limiting the running\nbatch size. In such cases, the workload naturally falls into\nthe \u201csweet spot\" of speculative decoding, enabling decoding\nacceleration. (2) _Multi-turn rollouts with tool-calling RL_ . In\nmulti-turn RL settings involving tool calls, partial requests\nperform GPU-free tool executions while their KV caches remain resident on the GPU. This reduces the number of active\n\ndecoding requests and again creates a favorable regime for\nspeculative decoding under our approach. (3) _Online serving_\n_and edge deployment_ . When the target model is fixed, a draft\nmodel trained via TLT can be directly deployed for inference.\nAdaptive speculative decoding remains highly effective in\nthese deployment scenarios, especially for handling variable\n\n**Figure 17. Effect of selective asynchronous checkpoint-**\n**ing and sequence packing.**\n\nload. Extending our approach to these settings is an exciting\ndirection for future work.\n\n**Can We Break RL Synchronization** ? TLT aims to improve RL training efficiency without modifying on-policy\nrequirements of the underlying algorithm. One may wonder whether it is possible to further accelerate training by\nasynchronously updating the model with partial rollouts during long decoding phases. While appealing, this approach\nrisks altering the underlying RL algorithm and potentially\nharming convergence and model performance. Asynchronous RL typically mixes multiple policy versions within a\nsingle rollout, potentially biasing gradient estimation and\nshifting the learning dynamics (e.g., drifting from on-policy\nto off-policy). Additional algorithmic modifications are required to safely accommodate such paradigm [12]. A more\nbalanced approach is to allow limited asynchrony that preserves algorithmic correctness while improving hardware\nutilization. Even under such settings, the heavy-tail rollout\nproblem remains, and our speculative decoding approach\ncan be combined with limited asynchronous RL to further\naccelerate training _without_ introducing additional loss or\npolicy staleness, leaving this as an intriguing direction for\nfuture work.\n\n**Can TLT be applied to other RL algorithms** ? GRPO represents a widely used algorithmic structure for reasoning RL.\nAlternatives such as RLOO [1], DAPO [66], REINFORCE [61],\nand REINFORCE++ [18] generally share the same overall\ntraining workflow, differing mainly in their reward formulations and use of KL-regularization. These algorithmic variations remain fully compatible with our adaptive drafter\nand spot-training design, suggesting that TLT can readily\naccelerate a broad class of RL methods."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism relies on a 'draft' model generating speculative tokens that, if validated by the 'target' model, effectively reduce the number of computation steps required from the slower target model. This is akin to a cache hit in software: if the draft's output is correct, the target model only performs a quick verification, significantly faster than full generation. For uniformly long responses, this increases the effective token generation rate per main model forward pass, amortizing the KV-cache cost over more output tokens. In multi-turn tool-calling, the draft model leverages periods where the main model has reduced active decoding requests due to GPU-free operations, allowing more dedicated cycles for validation and accelerating the remaining active requests. For asynchrony, attempting to update the main model with partial rollouts introduces bias by mixing different policy versions, akin to an outdated pointer corrupting data, which harms convergence. TLT avoids this by only accelerating token generation, not policy updates. TLT's broad applicability stems from operating at the high-level training workflow (data generation and processing) which is shared across many RL algorithms, rather than specific reward functions or regularization methods.\n\n**Explanation:** Speculative decoding works by having a fast, smaller model (the 'draft' model) predict several tokens ahead. The main, powerful model (the 'target' model) then quickly checks if these predictions are correct. If they are, it accepts multiple tokens at once. This is like a smart software pre-fetcher or a highly optimized cache: if the pre-fetched data (draft tokens) is correct, the main processor (target model) saves a lot of work. This is particularly useful when systems are constrained by memory (KV-cache-bound), as it effectively gets more output tokens for each expensive main model operation, making better use of the allocated memory. It also helps when some parts of the system are waiting (e.g., tool calls), as the active parts can get a speed boost because the main model has fewer concurrent tasks to validate, or the draft model can efficiently use cycles. The reason you can't just update the main model whenever a small piece of data is ready (asynchronous updates) is that it's like trying to build a complex structure with blueprints that keep changing mid-construction; the fundamental learning rules break down, leading to a shaky or incorrect final structure. However, TLT's approach maintains these rules by only accelerating the generation process, not the learning update process. Because many RL algorithms follow a similar step-by-step data generation pattern, TLT's method of accelerating this generation is broadly compatible, acting like a universal speed-up for data collection."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc5a\ud835\udc5c\ud835\udc51\ud835\udc52_ = _\ud835\udc36\ud835\udc40\ud835\udc43\ud835\udc35\ud835\udc35\ud835\udc45_\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc35\ud835\udc38_\ud835\udc35\ud835\udc4a_ **and** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65_ = 3 **then**\n\n**24** _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc5f_ _ _\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61_ = _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ \u2217(1 \u2212 100 _\ud835\udefc_ [)][ ;]\n\n**25** _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc62\ud835\udc5d\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61_ = _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ \u2217(1 + 100 _\ud835\udefc_ [)][ ;]"}, {"role": "assistant", "content": "**Mechanism:** This mechanism establishes dynamic upper and lower bounds for a bandwidth value (`bw_of_SFthis`) based on a percentage deviation (`alpha`). It acts as a configurable window or tolerance band around a baseline, ensuring the bandwidth operates within acceptable limits under specific conditions.\n\n**Explanation:** The code snippet creates a 'guardrail' system for a bandwidth measurement. It's triggered only when a specific 'probing' mode is active and at a particular stage (cycle_index 3). Once triggered, it calculates a permissible range. `bw_of_SFthis` serves as the center point of this range. The `alpha` parameter, treated as a percentage (divided by 100), defines how wide this range is. For instance, if `alpha` is 10, the lower limit will be 10% below `bw_of_SFthis`, and the upper limit will be 10% above. This is analogous to setting thresholds in an 'if-else' statement in programming, or defining acceptable error margins in a control loop, effectively creating a 'soft' constraint on a critical variable to maintain system stability or desired performance."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe evaluate our method on various datasets, including ImageNet-1k [12] and ImageNet-100 [42] for\nour primary results, Spawrious [26] and Waterbirds [38] for a study on adversarial datasets, Stanford\nDogs [21] and CUB-200-2011 [45] for fine-grained visual classification, and ArtBench [24] to test\nthe method\u2019s out-of-distribution capabilities. The majority of our experiments use four pre-trained\nself-supervised feature extractors as backbones: CLIP [34], DINO-v2 [31], EVA-02 [14], and MoCov3 [10]. In all our experiments, we distill the given dataset for 5000 iterations before training linear\nprobes to convergence on the resulting synthetic images. All experiments are conducted at 224 _\u00d7_ 224\nresolution and use the \u201cViT-B\u201d version of the given model. All distilled datasets by default use 10\nsets of augmentations per batch except for ImageNet-1k, for which only 3 sets of augmentations are\nused due to compute constraints. For further implementation details, please see the Appendix.\n\n**Evaluation and Baselines.** To measure our method\u2019s performance on a given feature extractor,\nwe randomly initialize a linear classifier and optimize it to convergence using the distilled images\nbefore evaluating on the test set. The same procedure is used to evaluate real-image baselines. In\nprior works on self-supervised learning [31], the evaluation consists of a grid search across a number\nof hyper-parameters, including from which layer(s) the features used to train the linear probe should\nbe taken from. For simplicity, we instead use only the features from the backbone\u2019s _last layer_ and\nkeep the training hyper-parameters consistent across the training of all linear probes.\n\nWe compare our method against three real-image baselines. For the **Neighbors** baseline, we choose\nthe real image for each class whose _distill-model_ embedding is closest to that of the corresponding\nsynthetic image produced by our method. Similarly, for **Centroids**, we take the real training image\nwith embedding closest to the _mean_ embedding for each class. Lastly, for **Random**, we simply select\na random image for each class and average the performance over 10 different seeds.\n\n5\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-4-0.png)\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-5-1.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-5-0.png)\n\nFigure 3: Performing more rounds of differentiable\naugmentation on the synthetic data during each distillation step improves both the single-model and crossmodel performance of the distilled images.\n\n|Distil<br>Centr|Col2|Col3|Distil<br>Centr|\n|---|---|---|---|\n|30<br>20<br>10|0|10<br>20|10<br>20|\n\nFigure 4: We distill ImageNet-Fruits and observe the\nPCA of the training image embeddings. Each color\nrepresents a class. Note that the distilled images typically lie on the edge or outside of their class\u2019s cluster.\n\n**4.1** **Linear Gradient Matching Out-Performs Real-Image Baselines**\n\nFirst, we evaluate our method on the original dataset distillation task: using a backbone model\nto distill a dataset and then training a model _of the same architecture_ on the resulting synthetic\nimages. Note that this setting differs from previous dataset distillation works in that we use a\n_pre-trained backbone_ distillation and reuse that backbone during evaluation by training a new\nrandomly-initialized linear classifier on top of it.\n\nIn Table 1, we see results for the single-model setting when distilling ImageNet-100 and ImageNet-1k.\nAcross both datasets and all four models, **our method convincingly out-performs all real-image**\n**baselines** . In particular, our method enables a linear probe trained on top of DINO-v2 [31] to reach\n**75% test accuracy** on ImageNet-1k while only ever having seen a **single labeled image per class** .\nIn comparison, training on the full dataset of 1.3 million real images reaches just 7 points higher at\n83%. Similar results are seen for the other models and datasets as well.\n\nIn Figure 4 we visualize the _embeddings_ of the distilled images relative to the real training data\nby plotting the 2D principal component analysis (PCA). For the sake of visual clarity, we use\nImageNet-Fruits [6, 7], a toy dataset of 10 fruit classes from ImageNet-1k. The embeddings in this\nfigure are from the same model used to distill the dataset (DINO-v2). We observe that the embeddings\nof the distilled images tend to lie far away from their respective class\u2019s centroid, often falling on\nthe outside edge of the class\u2019s distribution. We hypothesize that this is due in-part to the distillation\nembedding _highly-discriminative_ features within the synthetic images.\n\n**4.2** **Distilled Images Generalize Across Models**\n\nNext, we investigate the cross-model generalization capabilities of our distilled datasets. That is, we\nfirst distill a dataset using one backbone model (e.g., CLIP) and then evaluate the synthetic images\u2019 performance on the _other_ models (DINO-v2, EVA-02, MoCo-v3) that were not seen during distillation.\n\nWe visualize these results in Table 2. The diagonal elements are equivalent to the first row of Table 1\nand represent single-model performance while the off-diagonals show cross-model capabilities. We\nsee that the distilled datasets tend to generalize well to unseen models save for an outlier between\nCLIP and Moco, possibly due to poor model _alignment_ (Section 4.6). We also observe that the highestaccuracy model on the full dataset (DINO) also has the distilled dataset with the best cross-model performance, suggesting that a model\u2019s quality affects the generalization capabilities of its distilled data.\n\n**4.3** **Regularization and Augmentation Enable High Performance**\n\nIn this section, we quantitatively (Figure 3) and qualitatively (Table 5) analyze the effects of the\nvarious regularization and augmentation techniques included in our distillation process. Table 3 shows\nthe effects of ablating various components when evaluating using the same model used to distill ( **top** )\n\n6\n\nTrain Set ImageNet-100\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nFull (Ours) **84.9** _\u00b1_ **0.1 91.5** _\u00b1_ **0.1 89.0** _\u00b1_ **0.0 83.4** _\u00b1_ **0.1 87.2** _\u00b1_ **0.1**\n-Decorrelate 82.6 _\u00b1_ 0.1 **91.3** _\u00b1_ **0.2 89.0** _\u00b1_ **0.1** 83.2 _\u00b1_ 0.1 86.5 _\u00b1_ 0.1\n\n-Pyramid 83.5 _\u00b1_ 0.2 91.0 _\u00b1_ 0.3 87.9 _\u00b1_ 0.1 80.5 _\u00b1_ 0.1 85.7 _\u00b1_ 0.1\n-Augment 58.4 _\u00b1_ 0.2 82.6 _\u00b1_ 0.4 74.0 _\u00b1_ 0.3 59.6 _\u00b1_ 0.5 68.6 _\u00b1_ 0.4\n\nFull (Ours) **75.4** _\u00b1_ **0.3 80.9** _\u00b1_ **0.1** 76.6 _\u00b1_ 0.1 78.2 _\u00b1_ 0.1 **77.8** _\u00b1_ **0.2**\n-Decorrelate 69.4 _\u00b1_ 0.4 79.5 _\u00b1_ 0.1 **76.8** _\u00b1_ **0.1 79.9** _\u00b1_ **0.2** 76.4 _\u00b1_ 0.2\n\n-Pyramid 57.3 _\u00b1_ 0.2 74.5 _\u00b1_ 0.2 68.5 _\u00b1_ 0.2 68.1 _\u00b1_ 0.2 67.1 _\u00b1_ 0.2\n-Augment 35.3 _\u00b1_ 0.4 31.6 _\u00b1_ 0.2 34.3 _\u00b1_ 0.5 32.2 _\u00b1_ 0.5 33.3 _\u00b1_ 0.4\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1\n\nTable 3: **Evaluating Ablations:** While all three components\nprovide improvements, the Augmentation has the most dramatic effect, especially in the cross-model setting. Likewise,\nthe Pyramid optimization seems to matter more in the crossmodel setting than the same-model setting by mitigating overfitting to the model used during distillation.\n\nFigure 5: **Visualizing Ablations:** Removing\nvarious components of our pipeline causes\nvisual degradation in the distilled images.\n\nand averaging performances across the other three models ( **bottom** ). Figure 5 visualizes the distilled\nPineapple class from ImageNet-100 under the same ablations.\n\n**Color Decorrelation** Inspired by prior work in feature visualization [30] and motivated by a desire\nto spare our synthetic images from any color-related biases imposed by the model used to distill\nthem, we apply a color decorrelation technique to our distillation process. In Figure 5, we see that the\nimages distilled without the color decorrelation (column 2) look less realistic than those using our\nfull method (column 1); they are over saturated and contain high levels of incorrect colors (blue in\nthis example). Quantitatively, however, this component has the lowest effect of the three analyzed in\nthis section. While generally slightly helpful, it only offers a large improvement in the cross-model\nsetting when distilling using CLIP.\n\n**Pyramid Representation** It has been shown in prior work [7] that pixel-based optimization for\ndataset distillation does not scale well to higher resolutions; the synthetic images tend to become\nriddled with high-frequency patterns that inhibit their usefulness as training data. As discussed in\nSection 3.2, we instead adopt a pyramid representation for the distillation process. In Figure 5, we\nsee samples distilled from ImageNet-100 optimized using either the pyramid (column 1) or na\u00efve\npixel representation (column 3). We encourage the reader to zoom in and observe the high-frequency\npatterns and overall lack of coherence in the pixel-based images. In Table 3, we see that the images\ndistilled without the pyramid representation do indeed make far worse training data in the cross-model\nsetting, causing the model to overfit to the high-frequency patterns.\n\n**Differentiable Augmentations** Since its first proposal [53], the incorporation of differentiable\naugmentations during the distillation process has proven critical to the efficacy of the synthesized\nimages as training data. As such, we also perform differentiable augmentations in this work, as\ndescribed in Section 3.3. In Figure 5, we see samples from ImageNet-100 distilled both with (column 1) and without (column 4) augmentations. Visually, we observe that the images distilled _without_\naugmentations lack much meaningful structure and appear to simply be blobs of color with just a hint\nof geometry. In Table 3, we see that the lack of augmentations _severely_ limits the synthetic images\u2019\nusefulness as training data, even when evaluation on the same model used to distill.\n\nAs earlier discussed, we also apply _multiple rounds_ of augmentations at each distillation step and\nconcatenate the multiple augmented versions together to form the synthetic batch. Figure 3 illustrates\nhow the number of _augmentations per batch_ affects both the single-model and cross-model performance of the distilled data. Specifically, we see that when distilling ImageNet-100 with DINO-v2,\nraising the number of augmentations per batch from 1 to 5 and eventually 10 steadily increases the\ndistilled images\u2019 effectiveness as training data both on the backbone model used to distill (DINO-v2)\nand the other unseen models (CLIP, EVA-02, MoCo-v3).\n\n7\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-3.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-4.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-5.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-6.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-7.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-8.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-9.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-10.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-14.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-15.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-16.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-17.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-18.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-19.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-20.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-21.png)\n\nFigure 6: **Distilling Datasets with Spurious Correlations:** The 4-class \u201cSpawrious\u201d dataset contains spurious\nbackground correlations in the training set that are then subverted in the test set ( **left** ). A DINO linear\nprobe trained on the full training set performs well, reaching 78% test accuracy, while a MoCo probe fails\ncatastrophically, only reaching 36%. The distilled images ( **right** ) hint as to why: those distilled with DINO-v2\nstill contain mostly decipherable dog breeds while the MoCo-v3 counterparts focus almost entirely on the\nbackground environments. These images likely reflect the same biases held by the models used to distill them.\n\nTrain Set Spawrious WaterBirds\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **43.1** _\u00b1_ **6.4 80.8** _\u00b1_ **3.1 36.5** _\u00b1_ **3.1 32.7** _\u00b1_ **2.3 48.3** _\u00b1_ **3.7 77.9** _\u00b1_ **0.2 82.1** _\u00b1_ **2.9 78.0** _\u00b1_ **0.8 77.8** _\u00b1_ **0.0 79.0** _\u00b1_ **1.0**\nNeighbors **41.7** _\u00b1_ **4.6 76.9** _\u00b1_ **1.2 40.7** _\u00b1_ **2.7 33.0** _\u00b1_ **3.4 48.1** _\u00b1_ **3.0 74.6** _\u00b1_ **6.5** 67.3 _\u00b1_ 5.8 **74.3** _\u00b1_ **3.3** 45.2 _\u00b1_ 11.4 65.3 _\u00b1_ 6.8\nCentroids **44.8** _\u00b1_ **5.0 80.2** _\u00b1_ **2.7 38.1** _\u00b1_ **3.3 30.5** _\u00b1_ **1.6 48.4** _\u00b1_ **3.2 69.8** _\u00b1_ **8.6** 65.7 _\u00b1_ 3.4 64.6 _\u00b1_ 7.9 62.0 _\u00b1_ 5.2 65.5 _\u00b1_ 6.3\n\nRandom **46.2** _\u00b1_ **4.4** 68.1 _\u00b1_ 8.1 **33.3** _\u00b1_ **5.3 31.8** _\u00b1_ **2.5 44.9** _\u00b1_ **5.1** 71.9 _\u00b1_ 4.5 57.1 _\u00b1_ 8.6 59.8 _\u00b1_ 13.3 67.4 _\u00b1_ 5.7 64.0 _\u00b1_ 8.0\n\nFull Dataset 50.4 _\u00b1_ 0.3 78.1 _\u00b1_ 0.1 50.1 _\u00b1_ 0.4 35.8 _\u00b1_ 0.0 53.6 _\u00b1_ 0.2 86.0 _\u00b1_ 0.1 95.5 _\u00b1_ 0.1 90.4 _\u00b1_ 0.2 74.3 _\u00b1_ 0.1 86.5 _\u00b1_ 0.1\n\nTable 4: **Performance on Datasets with Spurious Background Correlations:** The Spawrious ( **left** ) and Waterbirds ( **right** ) training sets contain intentionally adversarial background correlations that are then subverted in the\ntest sets. On Spawrious, our method no longer out-performs the real-image baselines as with the standard datasets\n(Table 1). This is perhaps due to the synthetic data adopting the models\u2019 biases and overfitting to the backgrounds\non the training sets. We also see interesting interpretability results in the images themselves (Figure 6).\n\n**4.4** **Distilling Adversarial Datasets Reveals Interpretable Model Weaknesses**\n\nThe \u201cSpawrious\u201d dataset [26] consists of four classes of dog breeds and is designed to evaluate a\nmodel\u2019s ability to focus on the relevant content of an image rather than spurious correlations. In the\ntraining data, each breed is paired with its own unique environment: (Bulldog, Forest), (Corgi, Desert),\n(Dachshund, Mountain), and (Labrador, Snow). However, in the test set, the environments are intentionally different: (Bulldog, Mountain), (Corgi, Forest), (Dachshund, Snow), and (Labrador, Desert).\nWe also experiment with a similarly constructed data, \u201cWaterbirds\u201d [38] consisting of just two classes\n(land birds and water birds) with similarly spurious background correlations.\n\nQuantitative results on these datasets are shown in Table 4. Our method generally outperforms the\nreal-image baselines, but to a significantly smaller extent than on the standard datasets (Table 1). We\nalso observe that when training on the full Spawrious dataset, DINO-v2 [31] _far_ out-performs the\nrest of the models (81% test accuracy) with MoCo-v3 [10] doing dramatically worse (37%), both to\ndegrees far greater than seen when training on standard datasets (as in Table 1).\n\nBy _distilling_ Spawrious with our method, we gain potential insights as to why we might see such\ndramatic results. As seen in Figure 6, the images distilled with DINO-v2 contain clear (albeit\nabstract) depictions of the correct dog breeds. On the other hand, those yielded by MoCo-v3 are\nalmost entirely indecipherable, with the only clear portions being the spurious backgrounds from the\ntraining set. This interpretability result gives a clue towards explaining MoCo-v3\u2019s poor performance\non this dataset; the model clearly seems to focus on the spurious background correlations present\nin the training set rather than the relevant subjects, causing catastrophic overfitting.\n\n**4.5** **Distillation Excels in Fine-Grained Visual Classification**\n\nWhile computer vision methods are typically benchmarked against datasets containing broad categories of objects, such as ImageNet [12], much research also focuses on the task of Fine-Grained\nVisual Classification (FGVC) wherein datasets consist of many closely related classes that can be\n\n8\n\nFigure 7: **Distilling Fine-Grained Datasets:** Our distillation method captures the details necessary to teach a\nclassifier to distinguish between highly similar classes. Pictured above are just 10 of the 120 classes distilled\nfrom the Stanford Dogs [21] dataset ( **top** ) and 10 of the 200 classes distilled from Caltech-UCSD Birds [45]\n[using DINO-v2. For the full distilled datasets, please see the Appendix or our project page.](http://georgecazenavette.github.io/linear-gm)\n\nTrain Set Stanford Dogs CUB-2011\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **52.1** _\u00b1_ **0.2 83.0** _\u00b1_ **0.1 74.8** _\u00b1_ **0.1 69.6** _\u00b1_ **0.2 69.9** _\u00b1_ **0.2 62.2** _\u00b1_ **0.2 86.0** _\u00b1_ **0.1 74.1** _\u00b1_ **0.2 42.5** _\u00b1_ **0.2 66.2** _\u00b1_ **0.2**\nNeighbors 33.4 _\u00b1_ 0.1 71.3 _\u00b1_ 0.2 58.5 _\u00b1_ 0.2 56.3 _\u00b1_ 0.1 54.9 _\u00b1_ 0.2 39.4 _\u00b1_ 0.1 76.9 _\u00b1_ 0.0 52.6 _\u00b1_ 0.3 28.1 _\u00b1_ 0.0 49.2 _\u00b1_ 0.1\nCentroids 43.3 _\u00b1_ 0.1 73.0 _\u00b1_ 0.2 60.9 _\u00b1_ 0.2 55.2 _\u00b1_ 0.2 58.1 _\u00b1_ 0.2 54.3 _\u00b1_ 0.2 78.5 _\u00b1_ 0.2 59.9 _\u00b1_ 0.3 30.2 _\u00b1_ 0.1 55.7 _\u00b1_ 0.2\n\nRandom 23.3 _\u00b1_ 1.5 51.9 _\u00b1_ 1.8 38.3 _\u00b1_ 1.8 36.6 _\u00b1_ 1.4 37.5 _\u00b1_ 1.6 37.5 _\u00b1_ 1.6 64.4 _\u00b1_ 1.5 44.3 _\u00b1_ 1.5 19.1 _\u00b1_ 0.5 41.3 _\u00b1_ 1.3\n\nFull Dataset 76.9 _\u00b1_ 0.1 88.6 _\u00b1_ 0.1 82.6 _\u00b1_ 0.1 72.3 _\u00b1_ 0.5 80.1 _\u00b1_ 0.2 77.5 _\u00b1_ 0.7 90.2 _\u00b1_ 0.2 84.0 _\u00b1_ 0.3 43.7 _\u00b1_ 0.8 73.8 _\u00b1_ 0.5\n\nTable 5: **Performance on Fine-Grained Datasets:** Our distillation method captures the most discriminative\naspects of each class, thereby enabling a down-stream classifier to correctly identify samples from datasets\nwhere all classes are closely related. In particular, the performance gap between our method and the real-image\nbaselines is even higher on these fine-grained datasets (Stanford Dogs [21] and CUB-200-2011 [45]) than on the\nstandard ImageNet benchmarks.\n\nchallenging for even human experts to distinguish. Such datasets require models to learn fine-grained\nfeatures in order to identify the subtle differences between each class.\n\nWe apply our linear method to two common FGVC datasets: Stanford Dogs [21] and Caltech-UCSD\nBirds-200-2011 [45]. Samples of these datasets distilled using DINO-v2 can be seen in Figure 7. As\nseen in Table 5, in this more challenging fine-grained setting, our method outperforms the real-image\nbaselines to a _significantly higher_ degree than on the standard ImageNet benchmarks (Table 1). It\nseems as though the distillation process\u2019s ability to store didactic information in a single image\nper class is even more relevant in this setting since any one real image is less likely to contain the\ninformation necessary to distinguish its entire respective class from the other highly similar classes.\n\n**4.6** **Cross-Model Performance Predicts Model Alignment**\n\nRecent research has suggested an \u201calignment\u201d of various self-supervised models despite large\ndifferences in their training methods or even data modalities. The notion that all these models are\nindeed converging to a unified embedding space has been dubbed the \u201cPlatonic Representation\nHypothesis\u201d [20]. While the representations of today\u2019s models are not yet perfectly synchronized, it\nis still of interest to measure the degree to which they are aligned.\n\nIn the hypothesis\u2019s titular work, the authors introduce a method of measuring the alignment of two\nmodels called \u201cmutual _k_ nearest neighbors.\u201d In short, this method finds each sample\u2019s _k_ nearest\nneighbors in the embedding spaces of each model and then computes the fraction of neighbors that\nare shared between the two.\n\nWhen we distill images with a given model A and measure the 1 nearest neighbor performance\n(since there is just one image per class) on a different model B, we find that the normalized test\naccuracy is strongly correlated with the mutual _k_ -nn alignment between models A and B, as seen\nin Table 6. This is an interesting interpretability result showing that the cross-model performance of\na distilled dataset highly depends on the alignment between the two models. Given this dependency,\nour distillation method then acts as a method of _visualizing_ how well these models align by backing\nthe discrepancies in the embedding space out to image space. For example, given the two least\naligned models (CLIP and MoCo), we can see in Figure 1 that even for different sets of classes, the\ntwo models clearly distill very different _styles_ of images, alluding towards their misalignment.\n\n9\n\nDistill Normalized _k_ -NN Accuracy\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3\n\nSource Model Alignment\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-9-0.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-9-1.png)\n\nTable 6: **Distilled datasets predict model alignment.** We distill ImageNet-1k and find the synthetic data\u2019s\n_cross-model_ performance ( **left** ) by evaluating on a model other than the one used during distillation. We find that\nthis cross-model performance correlates well with the _alignment_ between models\u2019 embedding spaces ( **right** ).\nNote the similarity of the per-row trends between the two tables. Rows are colored from highest to lowest.\n\nFigure 8: **Distilling Out-of-Distribution Datasets:** Despite only ever being trained on the real-world images\nin ImageNet-1k [12], our method can still use DINO-v1 [5] to distill out-of-distribution datasets such as\nArtBench [24] that have no overlapping content. We see that the distillation is not simply \u201ccopying\u201d samples\nfrom the dataset by comparing to the nearest real neighbor in the model\u2019s embedding space and observing the\nstark differences. This interpretability insight granted by our method highlights DINO\u2019s remarkable ability to\ngeneralize beyond its training distribution.\n\n**4.7** **Self-Supervised Backbones can Distill Out-of-Distribution Datasets**\n\nNote that while we have thus far been discussing DINO-v2, this section in particular will reference\nDINO-v1 since this version\u2019s training set is open-sourced. Since DINO-v1 [5] was only trained on\nImageNet [12], a dataset of nearly all \u201creal-world\u201d images, we can easily test its ability to distill an\n**out-of-distribution** dataset such as ArtBench [24] that consists of 10 classes of art styles. In Figure 8,\nwe visualize the distilled images ( **top** ) as well as the nearest neighbor in DINO-v1\u2019s embedding\nspace. Surprisingly, despite having previously only ever seen \u201creal-world\u201d images from ImageNet,\nDINO-v1 is still able to effectively distill ArtBench into a single image per class. Furthermore, we\nconfirm that the distilling is not simply \u201ccopying\u201d real images from the training set by observing\nthe stark differences between the synthetic images and their nearest neighbors. This is especially\napparent in the cases of Realism, Renaissance, and Romanticism where the nearest neighbors are\nblack and white while the distilled images are colorful."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves synthesizing images by backpropagating a classification loss through a fixed pre-trained feature extractor into the pixel space of the synthetic image. This process, often called 'gradient matching', iteratively adjusts the synthetic pixels to produce features (embeddings) that cause a linear classifier to correctly identify the class. Regularization techniques like a pyramid representation and differentiable augmentations are crucial. The pyramid representation allows for multi-scale image generation, preventing high-frequency noise and enhancing structural coherence, while differentiable augmentations ensure the synthetic image is robust to transformations, effectively encoding more generalizable information.\n\n**Explanation:** Think of a pre-trained model as a powerful `hash_function` that takes any image and converts it into a unique, compact numerical vector, or 'embedding'. This `hash_function` is fixed. Our goal is to create just one tiny synthetic image per class (like a 'super-flashcard') such that its `hash_function` output (its embedding) is the best possible representation for that class. We start with a random synthetic image for each class. In a long `loop`, we feed these synthetic images through our `hash_function` to get their embeddings. Then, a simple `linear_classifier` (like a simple `if-else` rule based on these numbers) tries to guess the class. If it guesses wrong, we calculate how 'wrong' it was. Instead of changing the `hash_function` itself, we take that 'wrongness' signal and trace it *back* to the pixels of our synthetic image, telling the pixels to 'tweak yourselves' slightly so that next time, when you go through the `hash_function` and into the `linear_classifier`, the guess is better. This 'tweaking' process happens thousands of times. The pyramid representation is like building a house: you don't start by painting individual atoms; you lay out the big structure first, then add walls, then paint. This avoids pixel-level noise. Differentiable augmentations are like showing the `linear_classifier` many slightly different versions of the same 'super-flashcard' (rotated, zoomed) all at once, forcing the single card to contain enough information to be recognized from any angle. This makes the synthetic images incredibly effective and generalizable, even across different `hash_functions`."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\u2212_ 22 _\u2212_ 49\n\nLunarLander DDPG _\u2212_ 117 _._ 0 _\u00b1_ 45 _._ 3 _\u2212_ 29 _._ 9 _\u00b1_ 35 _._ 8 26 _._ 3 _\u00b1_ 98 _._ 4 **37** _._ **1** _\u00b1_ **78** _._ **4** \u2013 **1** _._ **0** 6 _._ 7 5 _._ 7 12 23 **27**\n\nPPO _\u2212_ **6** _._ **9** _\u00b1_ **132** _._ **3** _\u2212_ 19 _._ 0 _\u00b1_ 113 _._ 4 _\u2212_ 71 _._ 9 _\u00b1_ 87 _._ 3 _\u2212_ 40 _._ 6 _\u00b1_ 42 _._ 5 7 _._ 3 **6** _._ **7** 9 _._ 0 6 _._ 8 5 4 **28**\n\nTRPO _\u2212_ 15 _._ 0 _\u00b1_ 89 _._ 0 21 _._ 9 _\u00b1_ 80 _._ 5 79 _._ 0 _\u00b1_ 93 _._ 2 **94** _._ **1** _\u00b1_ **112** _._ **8 5** _._ **5** 7 _._ 0 8 _._ 7 6 _._ 3 41 **48** 27\n\nAnt DDPG 140 _._ 6 _\u00b1_ 113 _._ 9 278 _._ 9 _\u00b1_ 136 _._ 8 **412** _._ **4** _\u00b1_ **150** _._ **0** 377 _._ 7 _\u00b1_ 115 _._ 4 5 _._ 0 **4** _._ **0** 4 _._ 2 4 _._ 8 3 4 **11**\n\nPPO 822 _._ 6 _\u00b1_ 35 _._ 8 842 _._ 4 _\u00b1_ 42 _._ 4 768 _._ 3 _\u00b1_ 97 _._ 3 **863** _._ **7** _\u00b1_ **67** _._ **4 5** _._ **0** 7 _._ 2 9 _._ 0 6 _._ 8 **39** _\u2212_ 31 19\n\nTRPO **897** _._ **6** _\u00b1_ **41** _._ **2** 808 _._ 8 _\u00b1_ 62 _._ 0 771 _._ 2 _\u00b1_ 69 _._ 1 837 _._ 6 _\u00b1_ 47 _._ 1 8 _._ 7 8 _._ 0 **5** _._ **0** 7 _._ 7 20 _\u2212_ 67 **24**\n\nHalfCheetah DDPG 576 _._ 3 _\u00b1_ 749 _._ 9 909 _._ 0 _\u00b1_ 331 _._ 4 **1137** _._ **8** _\u00b1_ **185** _._ **6** 931 _._ 0 _\u00b1_ 345 _._ 4 10 _._ 0 **7** _._ **0** 8 _._ 6 8 _._ 0 43 **52** 26\n\nPPO **97** _._ **1** _\u00b1_ **377** _._ **9** 34 _._ 2 _\u00b1_ 596 _._ 5 _\u2212_ 1004 _._ 3 _\u00b1_ 409 _._ 5 95 _._ 5 _\u00b1_ 561 _._ 8 **5** _._ **7** 7 _._ 4 10 _._ 0 6 _._ 8 _\u2212_ 16 **48** _\u2212_ 14\n\nTRPO 228 _._ 4 _\u00b1_ 416 _._ 1 81 _._ 2 _\u00b1_ 524 _._ 3 40 _._ 9 _\u00b1_ 708 _._ 6 **391** _._ **9** _\u00b1_ **314** _._ **9** 7 _._ 3 6 _._ 0 7 _._ 0 **5** _._ **3** 6 _\u2212_ 4 **17**\n\nHopper DDPG 1189 _._ 6 _\u00b1_ 600 _._ 4 1048 _._ 7 _\u00b1_ 555 _._ 5 1394 _._ 5 _\u00b1_ 727 _._ 7 **1492** _._ **2** _\u00b1_ **562** _._ **9** 7 _._ 8 **4** _._ **5** 5 _._ 8 6 _._ 3 _\u2212_ **3** _\u2212_ 16 _\u2212_ 8\nPPO **825** _._ **5** _\u00b1_ **71** _._ **4** 802 _._ 8 _\u00b1_ 49 _._ 6 338 _._ 9 _\u00b1_ 330 _._ 7 634 _._ 3 _\u00b1_ 281 _._ 6 **8** _._ **4** 9 _._ 0 9 _._ 0 10 _._ 0 _\u2212_ 42 _\u2212_ **25** _\u2212_ 88\n\nTRPO **1196** _._ **3** _\u00b1_ **464** _._ **7** 856 _._ 5 _\u00b1_ 526 _._ 0 646 _._ 5 _\u00b1_ 283 _._ 6 724 _._ 4 _\u00b1_ 219 _._ 2 **8** _._ **2** 9 _._ 0 \u2013 \u2013 _\u2212_ 20 **19** _\u2212_ 8\n\nWalker2D DDPG 113 _._ 6 _\u00b1_ 90 _._ 7 **299** _._ **4** _\u00b1_ **74** _._ **8** 248 _._ 7 _\u00b1_ 145 _._ 6 267 _._ 6 _\u00b1_ 88 _._ 5 8 _._ 0 5 _._ 0 **4** _._ **9** 5 _._ 4 _\u2212_ **41** _\u2212_ 80 _\u2212_ 44\n\nPPO 185 _._ 6 _\u00b1_ 107 _._ 2 110 _._ 8 _\u00b1_ 40 _._ 2 **199** _._ **3** _\u00b1_ **108** _._ **2** 126 _._ 4 _\u00b1_ 25 _._ 1 4 _._ 4 1 _._ 8 1 _._ 8 **1** _._ **2** _\u2212_ 89 _\u2212_ 86 _\u2212_ **63**\n\nTRPO **260** _._ **2** _\u00b1_ **207** _._ **4** 192 _._ 6 _\u00b1_ 133 _._ 2 141 _._ 6 _\u00b1_ 54 _._ 4 231 _._ 4 _\u00b1_ 182 _._ 4 3 _._ 0 **2** _._ **2** 2 _._ 4 2 _._ 4 _\u2212_ 45 _\u2212_ **19** _\u2212_ 56\n\nHumanoid DDPG _\u2212_ 120 _._ 1 _\u00b1_ 26 _._ 7 42 _._ 6 _\u00b1_ 12 _._ 5 51 _._ 6 _\u00b1_ 14 _._ 3 **57** _._ **1** _\u00b1_ **14** _._ **3** \u2013 3 _._ 7 **2** _._ **8** 3 _._ 1 **50** 45 48\n\nPPO **58** _._ **0** _\u00b1_ **7** _._ **1** 48 _._ 2 _\u00b1_ 6 _._ 9 47 _._ 9 _\u00b1_ 9 _._ 1 48 _._ 3 _\u00b1_ 7 _._ 5 8 _._ 1 1 _._ 9 2 _._ 2 **1** _._ **1** 3 **7** 4\n\nTRPO **68** _._ **8** _\u00b1_ **6** _._ **4** 44 _._ 8 _\u00b1_ 6 _._ 2 47 _._ 8 _\u00b1_ 6 _._ 9 47 _._ 0 _\u00b1_ 7 _._ 2 8 _._ 0 **2** _._ **0** 3 _._ 0 3 _._ 0 _\u2212_ 21 _\u2212_ **14** _\u2212_ 28\n\nTable 1: Comparison across environments and algorithms. _Avg. Return_ reports final mean _\u00b1_ std over seeds; _Rounds to 0.95\u00d7Best_\ncounts iterations to reach 95% of the best average return; _Variability \u2193_ _(%)_ measures relative reduction in return variance. **Bold**\nindicates best performance; dash (\u2013) indicates not reached within budget. Abbreviations: Base (vanilla baseline), LB (Lookback),\nMU (MixUp), TP (Three-Points).\n\n**Theorem 2.** _We set \u03b7_ = _O_ (1 _/\u221aT_ ) _and run 1(Lookback) for_\n\n_T steps. If the bias \u03f5\u03b8 satisfies \u03f5\u03b8 \u2264O_ (1 _/T_ ) _, then we have_\n\nmin _t\u2264T_ min _{_ E _\u2225\u2207V_ _[\u03c0][\u03b8t]_ _\u2225_ 2 _,_ E _\u2225\u2207V_ _[\u03c0][\u03b8t]_ _\u2225_ 2 [2] _[} \u2264O]_ \ufffd ~~_\u221a_~~ 1 _T_\n\n_._\n\ufffd\n\nThe result shows that our algorithm converges to a stationary point, as long as the value estimation is accurate enough.\nMoreover, due to the gradient dominance property of the\nvalue function (Agarwal et al. 2021), our result also implies\nthe global optimality of the learned policy."}, {"role": "assistant", "content": "**Mechanism:** The mechanism relies on a carefully decaying learning rate and a value estimation process that becomes increasingly accurate over time. This combination ensures that the iterative policy improvement steps converge to a stationary point, and crucially, the 'gradient dominance property' of the value function then guarantees this stationary point is the global optimum, not just a local maximum.\n\n**Explanation:** Think of it like trying to find the highest peak in a huge, bumpy mountain range. Our algorithm, 'Lookback,' is designed to systematically climb. The first part, `\u03b7 = O(1/\u221aT)`, is like how we adjust our step size. Initially, we take bigger steps to explore the mountain quickly (when 'T' is small, `1/\u221aT` is larger). But as we climb for longer (T increases), we take smaller, more careful steps (as `1/\u221aT` gets smaller). This prevents us from overshooting the peak or getting stuck in tiny wobbles near the top. This is a common pattern in iterative algorithms to guarantee we eventually settle down. The second part, `\u03f5\u03b8 \u2264 O(1/T)`, is about our 'compass' \u2013 how well we know which direction is truly 'up.' It says that our compass's error needs to shrink over time. If our estimate of 'goodness' gets more precise as we learn more (like updating a hash map with better information over time), then our steps are well-guided. Together, these conditions guarantee that we'll eventually reach a 'stationary point' \u2013 a place where there's no immediate 'up' direction left to climb. The 'gradient dominance property' is the crucial mathematical cheat code for reinforcement learning here. It essentially states that for this specific type of 'mountain' (the value function), any peak you find where there's no more 'up' direction *must* be the highest peak in the entire range. So, our algorithm doesn't just find a good spot; it finds the best possible spot globally."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Design Principles & Goals** . To facilitate practical adoption,\nTLT adheres to four key design principles:\n(a) _Lossless Guarantee_ . System optimizations must be lossless,\npreserving the mathematical equivalence in both rollout and\ntraining stages compared to the original algorithm, thereby\navoiding asynchronous staleness or lossy approximations.\n(b) _Interference-Free_ . The adaptive drafter workload must not\ninterfere with the primary RL workload. Drafter updates\nare performed opportunistically (as spot tasks) and can be\nsmoothly preempted to minimize impact on the RL workload.\n(c) _Automatic and Simple_ . Manually setting up the draft model\nand configuring its speculative hyperparameters are burdensome and often lead to suboptimal performance. Thus, TLT\nfeatures an automated workflow for ease of use.\n\n(d) _Generalizable and Scalable_ . The design must be adaptable\nto various popular reasoning RL algorithms (e.g., GRPO [51],\nRLOO [1]). Furthermore, TLT should scale effectively and deliver continuous system performance improvements across\ndifferent model sizes, architectures, and cluster scales.\nIn addition, TLT has three primary objectives: (1) Mitigate\nthe long-tail problem to accelerate reasoning RL training; (2)\nEnhance cluster utilization and minimize resource waste; (3)\nProduce a high-performance draft model for future deployment with speculative decoding at no extra cost.\n\n4\n\n**Architecture & Workflow** . Figure 6 illustrates the overall\narchitecture of TLT and its workflow. The system is composed of two tightly integrated components: the Adaptive\nDrafter (\u00a74) and the Adaptive Rollout Engine (\u00a75).\nThe rollout process exhibits two key characteristics: a\nlong-tail distribution of sequence lengths and progressively\nshrinking batch sizes as responses complete. To adapt to\nthese dynamics, the Adaptive Rollout Engine maintains a\npool of pre-captured CUDAGraphs for both target and draft\nmodels, managed by the Adaptive SD Manager. This manager\nleverages the proposed BEG-MAB tuner to automatically\nselect appropriate SD strategies for each input batch. As\nshown in the top of Figure 6, the selected drafter CUDAGraph\ngenerates candidate tokens (\u2460), which are then passed to the\ncorresponding target CUDAGraph for parallel verification\n\n  (\u2461 \u2462). The engine measures acceptance length and step\nlatency (\u2463), feeding these signals back to the SD Manager\n(\u2464) to refine strategy selection in real time.\nMeanwhile, the Adaptive Drafter module is responsible for\ncontinuously updating the lightweight draft model without\ninterfering with the main rollout workload. A centralized\nWorker Coordinator monitors the state of rollout workers.\n\nWhen idle resources appear during the long-tail stage, the\ncoordinator opportunistically launches Spot Trainer tasks.\nThe training tasks use the Online DataBuffer, which caches\nhidden states and input embeddings from ongoing and prior\nsteps\u2019 rollout. The draft model receives efficient updates\nusing techniques such as zero-padding packing and selective asynchronous checkpointing. This design ensures that\ndrafter updates can be preempted and resumed seamlessly,\nexploiting wasted bubbles.\nBy systematically combining adaptive rollout with opportunistic drafter training, TLT achieves substantial speedups\nfor reasoning RL without compromising model quality, yielding a valuable draft model as a free by-product."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around 'speculative decoding' combined with adaptive resource scheduling. A lightweight 'draft model' proposes multiple future tokens in parallel. These speculative tokens are then verified by the heavier 'target model' simultaneously. If the draft's predictions are correct for 'k' tokens, the target model essentially skips 'k' computational steps, achieving a speedup by processing multiple tokens at once. If incorrect, the target model proceeds from the last correct token.\n\n**Explanation:** The efficiency gain comes from parallelizing the verification of speculative predictions. Instead of the target model generating one token at a time, the draft model quickly generates a hypothesis of several future tokens. The target model then checks these in bulk. This is analogous to a CPU's branch prediction: if the guess is right, you execute a large block of code instantly; if wrong, you only pay a small penalty to revert and compute correctly. The 'Adaptive Rollout Engine' manages this by caching optimized computational graphs (CUDAGraphs, like pre-compiled, highly efficient functions) for both models. A 'BEG-MAB tuner' dynamically selects the optimal speculative decoding strategy for each incoming batch based on its characteristics (like sequence length and batch size), learning from past performance (acceptance length and step latency feedback). This addresses the 'long-tail problem' where varying sequence lengths make static processing inefficient. Furthermore, the 'Adaptive Drafter' trains opportunistically: it's like a background process that utilizes idle GPU cycles (the 'wasted bubbles' that occur during the long-tail stages) to update the draft model, using cached intermediate computations from the main rollout. This ensures the draft model is continuously improving without interfering with the primary workload, much like a low-priority thread filling compute gaps."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section introduces the Adaptive Drafter component of\nTLT, focusing on how it creates, trains, and utilizes draft\nmodels to accelerate the reasoning RL process without interference with the primary RL workload.\n\n**4.1** **Draft Model**\n\nTLT utilizes a compact, specialized model trained to mimic\nthe target LLM\u2019s token generation behavior, enabling efficient and accurate speculative execution.\n**Model Architecture** . To maximize efficiency, TLT adopts a\nhighly lightweight, _single-layer_ model design for the drafter\n\n[26, 27, 67]. In this context, a \"layer\" refers to one complete\ntransformer decoder block, including attention and feedforward components. This approach differs from vanilla speculative decoding [5, 22], which often uses a separate, smaller\nmulti-layer LLM from the same family (e.g., Qwen2.5-0.5B\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-4-0.png)\n\n\u2465Training\nStrategies \u2463HiddenStates \u2464LossFunc\nTime Test\n\nEagle [26] Last layer L1 + CE loss N.A.\nHASS [67] Last layer L1 + CE loss 3 steps\n\nTop, mid and\nEagle-3 [27] CE loss only 7 steps\nbottom layers\n\n**Figure 7. Draft Model Training** . _Upper_ : Unified training\nworkflow using target model hidden states. _Lower_ : Specific\nconfigurations of different training strategies.\n\nfor a Qwen2.5-32B target). The vanilla approach has drawbacks: suitable and accurate small drafters may not exist for\nevery target LLM, not to mention that these smaller models can still incur substantial drafting latency. For instance,\nwhile Qwen2.5-32B has 64 layers, Qwen2.5-0.5B still contains\n24 layers. Although the parameter count is reduced significantly (64\u00d7 in this case), latency remains dominated by the\nsequential computation across multiple layers. Experiments\ndemonstrate that TLT\u2019s single-layer draft model, sharing approximately the same parameter count as the Qwen2.5-0.5B\ndrafter, is significantly faster (2.4\u00d7).\nAs illustrated in Figure 7 (blue block), the TLT drafter\nmirrors the target model\u2019s architecture but incorporates\nonly a single, trainable decoder layer. It reuses the target\nmodel\u2019s original Embedding and LM Head layers, keeping\ntheir weights frozen during training. Consequently, only the\nsingle decoder layer\u2019s parameters are updated, representing\na small fraction (approximately 1/layer_num) of the target\nmodel\u2019s total parameters. This architectural design significantly reduces both training and inference overhead. The\neffectiveness of such single-layer drafters is corroborated by\nprior work [2, 14, 25\u201327, 67], which has shown their capability to closely align with the target model\u2019s auto-regressive\ndistribution and achieve high acceptance rates for speculative tokens. During operation, the trained drafter takes\nhidden states from the target model and auto-regressively\ndrafts subsequent tokens for verification.\n**Training Process** . TLT builds a unified training framework\nthat supports diverse draft model training strategies and integrates seamlessly with the RL workflow. As depicted in\nFigure 7, the training process leverages data generated during\n\n5\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-5-0.png)\n\nTrainer is designed to counteract this drift without hindering the primary RL workflow. To achieve this goal, TLT\nincorporates the following novel designs:\n**Worker Coordinator** . It aims to bridge the gap between the\nRollout Engine and the Spot Trainer, coordinating resource\nallocation, particularly repurposing GPU resources that become idle during the long-tail phase of rollout. In TLT, a\n_worker_ is the basic unit of resource management, defined\nas one rollout instance. For example, when rollout uses a\nfull DGX-H100 node with TP=8, a single worker represents\n8 GPUs. The coordinator follows a centralized model im\nplemented with ZeroMQ [17], where a single coordinator\nprocess (rank 0) maintains the global state and workers communicate through asynchronous request-reply patterns. By\nmonitoring active request counts and worker states, the coordinator determines when workers can be migrated from\nrollout to opportunistic drafter training. Each worker cycles\nbetween three states\u2014 _BUSY_ (serving rollout), _IDLE_ (inference finished and memory released), and _TRAINING_ (engaged in drafter updates)\u2014and notifies the coordinator on\nevery transition. Once the number of idle workers exceeds\na configurable threshold, the coordinator promotes them to\ntraining mode and initiates drafter training.\nTraining initiation follows a leader-election pattern, where\nthe first eligible worker sets up the training session and later\nworkers can join if they belong to the same data-parallel\ngroup. When rollout completes, the coordinator immediately\nhalts any ongoing drafter training and performs a graceful\nshutdown to ensure proper cleanup. This design ensures\nthat idle GPU cycles during long-tail rollouts are effectively\nexploited without interfering with the primary RL workflow.\n**Spot Training with DataBuffer** . Figure 8 contrasts our\nSpot Trainer approach with standard RL workflows. Vanilla\nRL (a) involves a sequential process: rollout, target & reference model inference for KL divergence calculation, and\ntarget model training (reward calculation is fast and omitted\nfor brevity). A naive integration of drafter training (b) typically adds it as another sequential step, although reusing\nsome prefilling computations but still incurs extra overhead.\nIn contrast, the Spot Trainer (c) operates on the principle\nthat draft model training can proceed effectively without\nwaiting for all generated responses to complete, allowing\ntraining to execute in a non-blocking manner. Due to the\nlong-tail distribution in reasoning RL tasks, a majority of\nresponses are generated significantly faster than the longest\nones. The Spot Trainer leverages this observation by using\npartial of responses to train the draft model. However, relying only on early finishes means the drafter rarely sees very\nlong sequences, which can introduce distribution mismatch.\nTo address this, TLT introduces the DataBuffer, which decouples drafter training from rollout completion. The DataBuffer\ncaches hidden states and tokens produced during the inference stage and loads them with minimal overhead. Crucially,\nit supports _one-step offset_ sampling: we persist the buffer\n\n|Rollout with Adaptive SD|Reference|Target|Target Training|\n|---|---|---|---|\n|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|\n\n**Figure 8. Spot Trainer Workflow** . Block lengths are illustrative and not strictly proportional to execution time.\nNote that target model prefilling during drafter training is\noptional since hidden states from the rollout engine can be\nused directly.\n\nthe RL workflow. Specifically, input prompts are first processed by the target model to generate rollout responses (\u2460,\n\u2461). During the subsequent prefilling (i.e., inference) phase,\nhidden states are collected from specific layers of the target model (\u2462). These collected hidden states, concatenated\nwith input token embeddings, are then passed through a\nlightweight linear layer for dimension reduction. Then the\noutput features serve as input to the drafter\u2019s single decoder\nlayer for training (\u2463). Given the target model\u2019s significantly\nlarger size (over 20\u00d7 than the draft model), its prefilling cost\ncan be far more expensive than one drafter training iteration.\nIn TLT, we cache the hidden states generated during the\ninherent RL inference phase to host memory and reuse them,\nthereby eliminating this overhead.\nTLT also accommodates multiple training objectives. The\nframework can apply an L1 loss between the hidden states\nof the target and draft models to align their representations,\na cross-entropy (CE) loss on the output logits to match token\npredictions, or a combination of both (\u2464). The computed loss\nis then backpropagated to update only the drafter\u2019s decoder\nlayer, while embeddings and the LM head remain tied to the\ntarget model (\u2465).\nAdditionally, several training strategies are supported\nwithin this unified pipeline in TLT. For instance, EAGLE\n\n[26] uses only the last layer\u2019s hidden states; HASS [67] further enhance the training by feeding the output feature of\ndraft model back into itself for multiple time (i.e., trainingtime test); EAGLE-3 [27] further fuses multi-layer hidden\nstates from the target model, aiming for better acceptance\nrates. Despite these differences, all these variants can be\nnaturally expressed within our training framework. In this\nwork, we use the EAGLE model as the default, as it offers\nhigh accepted lengths and faster convergence with much\nlower training cost.\n\n**4.2** **Spot Trainer**\n\nThe key challenge in applying speculative decoding within\nRL training is the _evolving target model_ ( **C1** ), causing a fixed\ndraft model to quickly become stale and ineffective. Spot\n\n6\n\nDepth = 1 Depth = 2 Depth = 3 Depth = 4\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-6-0.png)\n\n|8|4|16|6|32|8|48|8|\n|---|---|---|---|---|---|---|---|\n|S1:{V=8, D=4}|S1:{V=8, D=4}|S2:{V=16, D=6}|S2:{V=16, D=6}|S3:{V=32, D=8}|S3:{V=32, D=8}|S4:{V=48, D=8}|S4:{V=48, D=8}|\n\n|Prompt<br>Climate|change<br>(04)<br>.<br>control<br>(025)<br>.<br>DraftingStage|will<br>(012)<br>.<br>is<br>(025)<br>.<br>can<br>(006)<br>.<br>systems<br>(013)<br>.|a<br>(015)<br>.<br>very<br>(005)<br>.<br>are<br>(004)<br>.<br>often<br>(002)<br>.|global<br>(007)<br>.<br>serious<br>(003)<br>.<br>urgent<br>(001)<br>.<br>important<br>(002)<br>.|Col6|\n|---|---|---|---|---|---|\n|Climate<br>**Prompt**|control<br>(0.25)<br>change<br>(0.4)<br>**Drafting Stage**|will<br>(0.12)<br>is<br>(0.25)<br>can<br>(0.06)<br>systems<br>(0.13)|a<br>(0.15)<br>very<br>(0.05)<br>are<br>(0.04)<br>often<br>(0.02)|Drafted Token<br>(Prob.)<br>Token to Verify<br>(Prob.)|Drafted Token<br>(Prob.)<br>Token to Verify<br>(Prob.)|\n\n**Figure 9. Example of Tree Decoding** . We set topK=2,\nDraft_Depth=4, and Tokens_to_Verify=8 in this example.\nProb. denotes token probability given by the draft model.\n\nacross RL steps and prioritize long sequences from the previous step to compensate for the scarcity of long-tail data in the\ncurrent partial set. Although these samples are slightly stale,\nthey remain effective for drafter training. Our experiments\nshow that combining partial current-step data with buffered\nlong sequences attains performance comparable to training\non the full response set. Drafter updates are scheduled as\nlow-priority \u201cspot tasks\u201d on idle GPUs, effectively harvesting\ncompute freed by the long tail while keeping the main RL\nworkflow non-blocking.\n**Selective Asynchronous Checkpointing** . A key design\nfeature of the Spot Trainer is its preemptibility, allowing\nit to utilize idle resources without blocking the main RL\nworkload. However, preemptions may lead to substantial\nloss of the draft model\u2019s training progress. To address this,\nthe Spot Trainer utilizes asynchronous checkpointing: when\ntriggered, the process of saving the draft model\u2019s state is offloaded to a background thread. Moreover, we optimize this\nprocess by filtering out frozen layers (e.g., embeddings and\nthe LM head) and dumping only the trainable parameters, significantly reducing checkpointing latency. This mechanism\nminimizes work lost due to preemption through frequent\nand efficient checkpointing.\n**Sequence Packing** . The training data inherently consists\nof sequences with variable lengths. Standard batching techniques often require padding sequences to a uniform length,\nleading to inefficiency of computation, communication, and\nmemory. To maximize GPU utilization during opportunistic\ndrafter training, the Spot Trainer employs sequence packing\n\n[20]. This technique concatenates multiple variable-length\nsequences into a single packed sequence, removing padding\nwhile using attention masks to preserve sequence integrity\nduring parallel processing. This enables efficient processing of the unbalanced training data within the limited, preemptible time slots available for spot training."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an extremely lightweight, single-layer 'drafter' model that mimics the token generation probabilities of a larger, more complex 'target' LLM. Instead of replicating the target LLM's full architecture, the drafter takes the target model's intermediate internal states (hidden states) as its input, effectively 'inheriting' the complex contextual processing done by the main model's preceding layers. It then uses its single decoder layer to predict the next token distribution. This approach leverages the fact that the 'next token' prediction logic can be encapsulated and learned by a shallow network, given a sufficiently rich input context from the deeper model. This single trainable layer, combined with frozen embedding and LM head layers from the target model, drastically reduces the parameter count and computational cost during both training and inference. The 'Spot Trainer' dynamically manages computational resources, acting like a preemptive scheduler for drafter training. It identifies idle GPU cycles from the primary RL workload and uses them opportunistically to update the drafter. This is akin to a background process that runs only when system resources are available, without interrupting the foreground high-priority task.\n\n**Explanation:** The drafter model works by learning to transform a rich, high-dimensional 'summary' of the main model's understanding (its hidden states) into a probability distribution over the next possible tokens. It's trained to align its internal representation (via L1 loss on hidden states) and its output predictions (via cross-entropy loss on logits) with those of the main model. This training data (hidden states and tokens) is efficiently cached from the main model's prior passes, like memoizing the results of an expensive function call, preventing redundant calculations. The 'Spot Trainer' ensures the drafter remains accurate as the main model evolves. It's a dynamic resource allocation system: a 'Worker Coordinator' functions as a central `scheduler` that monitors GPU availability. When a 'worker' (a set of GPUs) completes its main task and becomes `IDLE`, the coordinator flags it for drafter training. This training isn't blocked by slow, long sequences; a 'DataBuffer' acts as a `prioritized replay buffer`, storing past examples (especially crucial long sequences) to ensure the drafter learns from a diverse set of experiences, even if current data is limited to short, quick responses. If the main workload suddenly requires resources, 'Selective Asynchronous Checkpointing' saves the drafter's progress rapidly in a background `thread`, only saving the small fraction of trainable parameters. Finally, 'Sequence Packing' treats many variable-length input sequences like a single, tightly packed array, allowing the GPU to process them efficiently without wasted computations on `padding` tokens, akin to optimizing data layout for cache efficiency."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**38**\n\nG.1 Reinforcement Learning Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\nG.2 Multi Agent Reinforcement Learning Experiments . . . . . . . . . . . . . . . . . . . . . . 39\n\nG.3 Reasoning Fine-tuning Experiments: Countdown . . . . . . . . . . . . . . . . . . . . . . . 41\n\nG.4 Reasoning Fine-tuning Experiments: GSM8K . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\n18\n\n**A** **Proofs**\n\nIn our proofs, we use the integral notation \ufffd to denote the integral over the corresponding R _d_ space, for\nexample, for a matrix _E \u2208_ R _[m][\u00d7][n]_, \ufffd _f_ ( _E_ ) _dE_ = \ufffdR _[m][\u00d7][n][ f]_ [(] _[E]_ [)] _[dE]_ [ and for a vector] _[ E][ \u2208]_ [R] _[mn]_ [,] \ufffd _f_ ( _v_ ) _dv_ =\n\nexample, for a matrix _E \u2208_ R _[m][\u00d7][n]_, \ufffd _f_ ( _E_ ) _dE_ = \ufffdR _[m][\u00d7][n][ f]_ [(] _[E]_ [)] _[dE]_ [ and for a vector] _[ E][ \u2208]_ [R] _[mn]_ [,] \ufffd _f_ ( _v_ ) _dv_ =\n\n\ufffdR _[mn][ f]_ [(] _[v]_ [)] _[dv]_ [.]\n\n**A.1** **ES Matrix Gradient Deviations**\n\n**Proposition 1.** _Using the Gaussian matrix policy \u03c0_ ( _M_ _|\u00b5_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ) _the ES objective can be_\n_written as:_\n\n_J_ ( _\u00b5_ ) = E _E\u223cP_ ( _E_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3E_ )] _._\n\n_and the matrix gradient of the ES objective is:_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[E][\u223c][P]_ [ (] _[E]_ [)][ [] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ .]_\n\n_where P_ ( _E_ ) _is a zero-mean standard normal p_ ( _E_ ) = _N_ (0 _, Im, In_ ) _. Moreover, the natural matrix gradient is_\n_equal to \u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) _, i.e. equivalent to Eq._ (4) _up to a factor of \u03c3_ [2] _._\n\n_Proof._ We start by deriving the derivative of the ES objective from Eq. (1). Taking the derivative with respect\n\nto _\u00b5_ :\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _f_ ( _M_ ) _\u2207\u00b5\u03c0_ ( _M_ _|\u00b5_ ) _dM,_\n\ufffd\n\n= _f_ ( _M_ ) _\u2207\u00b5_ log _\u03c0_ ( _M_ _|\u00b5_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM._\n\ufffd\n\nNow,\n\n1\n_\u2207\u00b5_ log _\u03c0_ ( _M_ _|\u00b5_ ) = _\u2207\u00b5 \u2212_ 2 _\u03c3_ [2] [tr] \ufffd( _M \u2212_ _\u00b5_ ) _[\u22a4]_ ( _M \u2212_ _\u00b5_ )\ufffd _,_\n\nR _[mn][ f]_ [(] _[v]_ [)] _[dv]_ [.]\n\n= _\u2212_ [1]\n\n_\u03c3_ [2] [(] _[M][ \u2212]_ _[\u00b5]_ [)] _[,]_\n\nwhere we have used Petersen & Pedersen (2008, Eq. 103) for the matrix derivative of the trace, hence:\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n( _M \u2212_ _\u00b5_ )\n\n_f_ ( _M_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM._\n\n\ufffd _\u03c3_\n\nWe make the transformation of variables _E_ = _[M]_ _[\u2212][\u00b5]_ :\n\n_\u03c3_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_E \u00b7 f_ ( _M_ ) _p_ ( _E_ ) _dE,_\n\ufffd\n\nwhere\n\n_p_ ( _E_ ) = _\u03c3_ _[mn]_ _\u03c0_ ( _M_ = _\u00b5_ + _\u03c3E|\u00b5_ )\n\n_\u2212_ [1]\nexp\n2 \ufffd 2\n\n1\n\n= ~~_mn_~~\n(2 _\u03c0_ ) 2\n\n[1] \ufffd _E_ _[\u22a4]_ _E_ \ufffd [\ufffd] _,_\n\n2 [tr]\n\n= _N_ (0 _, Im, In_ ) _,_\n\nas required. Using the same transformation of variables, the alternative form of the matrix Gaussian ES\nobjective follows immediately:\n\n_J_ ( _\u00b5_ ) = _f_ ( _M_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM,_\n\ufffd\n\n= _f_ ( _M_ = _\u00b5_ + _\u03c3E_ ) _P_ ( _E_ ) _dE._\n\ufffd\n\n19\n\nWe now derive the natural policy gradient for a Gaussian policy to prove our final claim. It is convenient to work\nin vector space rather than matrix space. In vector form, the natural gradient is defined as _F_ ( _\u00b5v_ ) _[\u2212]_ [1] _\u2207\u00b5v_ _J_ ( _\u00b5v_ )\nwhere _F_ ( _\u00b5v_ ) is the Fisher information matrix of the distribution:\n\n_F_ ( _\u00b5v_ ) := E _v\u223c\u03c0_ ( _v|\u00b5v_ ) \ufffd _\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) _\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) _[\u22a4]_ [\ufffd] _,_\n\nwhere _\u00b5v_ = vec( _M_ ) and _\u03c0_ ( _v|\u00b5v_ ) = _N_ ( _\u00b5v, \u03c3_ [2] _Imn_ ) for our Gaussian case. Deriving the score function:\n\n_\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) = _\u2212_ 2 _\u03c3_ [1] [2] _[\u2207][\u00b5][v]_ _[\u2225][\u00b5][v][ \u2212]_ _[v][\u2225]_ [2] _[,]_\n\n= [1]\n\n_\u03c3_ [2] [(] _[v][ \u2212]_ _[\u00b5][v]_ [)] _[,]_\n\nHence the Fisher information matrix is:\n\n_F_ ( _\u00b5v_ ) = _\u03c3_ [1][4] [E] _[v][\u223c][\u03c0]_ [(] _[v][|][\u00b5][v]_ [)] \ufffd( _v \u2212_ _\u00b5v_ )( _v \u2212_ _\u00b5v_ ) _[\u22a4]_ [\ufffd] _,_\n\nThis yields the natural gradient:\n\n= [1]\n\n_\u03c3_ [2] _[I][mn][.]_\n\n_F_ ( _\u00b5v_ ) _[\u2212]_ [1] _\u2207\u00b5v_ _J_ ( _\u00b5v_ ) = _\u03c3_ [2] _\u2207\u00b5v_ _J_ ( _\u00b5v_ ) _._\n\nConverting back to matrix form, the natural gradient is thus _\u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) as required.\n\n**Theorem 1.** _Let Assumption 1 hold. Then for finite r:_\n\n_gLR_ := _\u2207\u00b5JLR_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[y]_ [ = (] _[\u00b5]_ [ +] _[ \u03c3Z]_ [)] _[x]_ [)]] _[ .]_\n\n_where Z is generated by sampling A \u223c_ _p_ ( _A_ ) _, B \u223c_ _p_ ( _B_ ) _, \u03f5 \u223c_ _p_ ( _\u03f5_ ) _and making the transformation Z_ =\n_AB_ _[\u22a4]_\n\n+ _\u03f5._\n~~_\u221a_~~ _r_\n\n_Proof._ We first prove that the density _p_ ( _Z_ ) of the pushforward distribution of _p_ ( _A_ ), _p_ ( _B_ ) and _p_ ( _\u03f5_ ) under the\nmapping ( _A, B, \u03f5_ ) : _\u2192_ _Z_ = _[AB]_ ~~_\u221a_~~ _r_ _[\u22a4]_ + _\u03f5_ exists. As _r_ is finite, _p_ ( _\u03f5_ ) is a Gaussian with well-defined density and _Z_\n\nis a sum two independent variables _[AB]_ ~~_\u221a_~~ _r_ _[\u22a4]_ and _\u03f5_ . The density _p_ ( _Z_ ) is thus given by the convolution (see, for\n\nexample, Durrett (2010, Theorem 2.1.11)):\n\n_p_ ( _Z_ ) = E _A\u223cp_ ( _A_ ) _,B\u223cp_ ( _B_ )\n\n_p_ _\u03f5_ = _Z \u2212_ _[AB][\u22a4]_ _,_\n\ufffd \ufffd ~~_\u221ar_~~ \ufffd\ufffd\n\nwhich integrates to 1 over R _[m][\u00d7][n]_ and, since _p_ ( _\u03f5_ ) is everywhere positive, is also everywhere positive. The\ndistribution of _Z_ is thus absolutely continuous with respect to the Lebesgue measure in R _[m][\u00d7][n]_ and the density\n_p_ ( _Z_ ) is well-defined. To derive the gradient, we make the transformation of variables _Z_ _[\u2032]_ = _\u00b5_ + _\u03c3Z_ :\n\n_J_ LR( _\u00b5_ ) = _p_ ( _Z_ _[\u2032]_ ) _f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _,_\n\ufffd\n\nwhere _p_ ( _Z_ _[\u2032]_ ) = _\u03c3_ _[mn]_ 1 _[p]_ [(] _[Z]_ [ =] _[ Z][\u2032]_ _\u03c3_ _[\u2212][\u00b5]_ ) Taking derivatives with respect to _\u00b5_ :\n\n1\n_\u2207\u00b5J_ LR( _\u00b5_ ) = \ufffd _\u03c3_ _[mn]_ _[\u2207][\u00b5][p]_ \ufffd _Z_ = _[Z]_ _[\u2032][ \u2212]_ _\u03c3_ _[\u00b5]_ \ufffd _f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _,_\n\n= _p_ ( _Z_ _[\u2032]_ ) _\u2207\u00b5_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd \ufffd _\u03c3_\n\n_f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _._\n\ufffd\n\nFrom the chain rule:\n\n_\u2207\u00b5_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd _\u03c3_\n\n= _\u2212_ [1]\n\ufffd _\u03c3_\n\n[1] _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\n_\u03c3_ _[\u2207][Z]_ [ log] _[ p]_ \ufffd _\u03c3_\n\n_,_\n\ufffd\n\n_\u03c3_\n\n20\n\nhence:\n\n_f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _._\n\ufffd\n\n_\u2207\u00b5J_ LR( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_p_ ( _Z_ _[\u2032]_ ) _\u2207Z_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd \ufffd _\u03c3_\n\nMaking the reverse transformation of variables _Z_ = _[Z][\u2032]_ _\u03c3_ _[\u2212][\u00b5]_ :\n\n_\u2207\u00b5J_ LR( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_p_ ( _Z_ ) _\u2207Z_ log _p_ ( _Z_ ) _f_ ( _y_ = ( _\u00b5_ + _\u03c3Z_ ) _x_ ) _dZ,_\n\ufffd\n\n= _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[y]_ [ = (] _[\u00b5]_ [ +] _[ \u03c3Z]_ [)] _[x]_ [)]] _[,]_\n\nas required.\n\n**A.2** **Error Rate Analysis**\n\nFor convenience, we work with random vectors in our analysis. Using the vec operator, we analyse the vector\n_v_ _[r]_ = vec( _Z_ _[r]_ ) where:\n\nvec( _M_ ) = [ _m_ 1 _,_ 1 _, . . . m_ 1 _,m, m_ 2 _,_ 1 _, . . . mm,n_ ] _[\u22a4]_ _._\n\nFor a vector _v \u2208_ R _[mn]_, we define the mat operator as:\n\n\uf8f9\n\n_,_\n\uf8fa\uf8fa\uf8fa\uf8fb\n\nmat( _v_ ) =\n\n_v_ 1 _vm_ +1 _. . ._ _v_ ( _n\u2212_ 1) _m_ +1\n\n\uf8ee _v_ 2 _vm_ +2 _. . ._ _v_ ( _n\u2212_ 1) _m_ +2\n\n... ... ... ...\n\n\uf8ef\uf8ef\uf8ef\uf8f0 _vm_ _v_ 2 _m_ _\u00b7 \u00b7 \u00b7_ _vmn_\n\nso mat(vec( _M_ )) = _M_ . Using Eq. (6), write _v_ _[r]_ as a standardised sum of _r_ independent, zero-mean random\nvectors. Let\n\n_ui_ = vec \ufffd _aib_ _[\u22a4]_ _i_ [+] _[ \u03f5][i]_ \ufffd _,_ (10)\n\nwhere recall _ai_ and _bi_ are the _i_ th column vectors of _A_ and _B_ and _\u03f5i_ is an _m\u00d7n_ random matrix with independent\nGaussian elements drawn from _N_ (0 _,_ _[\u03c3]_ _\u03f5_ [2] _/r_ ), so:\n\n1\n_v_ _[r]_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd _u_ _[r]_ _i_ _[.]_\n\n_i_ =1\n\nWe will use the fact that the Frobenius norm becomes the _\u2113_ -2 norm in vector space:\n\n~~\ufffd~~ _mi,j_ [2] = ~~\ufffd~~\n\n_i,j_ \ufffd _k_\n\n_\u2225M_ _\u2225F_ = ~~\ufffd~~\n\ufffd _i,j_\n\nvec( _M_ ) _k_ 2 = _\u2225_ vec( _M_ ) _\u2225._ (11)\n\n_k_\n\nDenoting the covariance matrix of _p_ ( _u_ ) as \u03a3 _[r]_, the central limit theorem proves that the distribution of _v_ _[r]_\n\nconverges in distribution to a zero-mean Gaussian _N_ (0 _,_ \u03a3 _r_ ). In Lemma 1, derive the covariance matrix for \u03a3 _[r]_ .\nOur analysis uses an Edgeworth expansion (Bhattacharya & Ranga Rao, 1976) to characterise precisely the rate\nat which _p_ ( _v_ _[r]_ ) converges to the limiting Gaussian distribution. In Lemma 2, we make an Edgeworth expansion\nof _p_ ( _v_ _[r]_ ) to show that it is dominated by _O_ \ufffd 1 _r_ \ufffd terms and higher. These are then used to prove Lemma 3,\n\nwhich allows us to bound the integral of the remainder of the Edgeworth expansion, thereby characterising\nhow fast _p_ ( _v_ _[r]_ ) converges to the limiting Gaussian distribution.\n**Lemma 1.** _Let Assumption 1 hold and u be defined in Eq._ (10) _. Then the variable u has diagonal covariance_\n\n_matrix:_\n\n\u03a3 _[r]_ = _\u03c3_ 0 [4] [+] _[\u03c3]_ _\u03f5_ [2]\n\ufffd _r_\n\n_Imn_ =: _\u03c3r_ [2] _[I][mn][,]_\n\ufffd\n\n_Moreover, the variable u has a finite_ 4 _th-order absolute moment:_\n\nE _u\u223cp_ ( _u_ ) \ufffd _\u2225u\u2225_ [4][\ufffd] _< \u221e._\n\n21\n\n_Proof._ Under the vec operator, the vector _u_ can be written element wise as:\n\n_u_ = [ _a_ 1 _b_ 1 + _\u03f5_ 1 _,_ 1 _, a_ 2 _b_ 1 + _\u03f5_ 2 _,_ 1 _, . . . amb_ 1 + _\u03f5m,_ 1 _, a_ 1 _b_ 2 + _\u03f5_ 1 _,_ 2 _, . . . ambn_ + _\u03f5m,n_ ] _[\u22a4]_ _._\n\nWe note that all elements in the vector _u_ have zero mean, and so the covariance matrix is the expectation of the\nouter product:\n\n\u03a3 _[r]_ = E _u\u223cp_ ( _u_ ) \ufffd _uu_ _[\u22a4]_ [\ufffd] _._\n\nThe diagonal elements of \u03a3 _[r]_ are:\n\nE _ai,bj_ _,\u03f5j,i_ \ufffd( _aibj_ + _\u03f5j,i_ ) [2][\ufffd] = E _ai,bj_ _,\u03f5j,i_ \ufffd _a_ [2] _i_ _[b]_ [2] _j_ [+ 2] _[a][i][b][j][\u03f5][j,i]_ [+ (] _[\u03f5][j,i]_ [)][2][\ufffd] _,_\n\n= E _ai,bj_ \ufffd _a_ [2] _i_ _[b]_ [2] _j_ \ufffd + E _\u03f5j,i_ \ufffd( _\u03f5j,i_ ) [2][\ufffd] _,_\n\n= _\u03c3_ 0 [4] [+] _[ \u03c3]_ _r\u03f5_ [2] _[.]_ (12)\n\nAs all elements of _a_, _b_ and _\u03f5_ are zero-mean, off-diagonal elements are zero:\n\nE _ai,bj_ _,ak,bl,\u03f5j,i,\u03f5k,l_ [( _aibj_ + _\u03f5j,i_ ) ( _akbl_ + _\u03f5k,l_ )]\n\n=E _ai,bj_ _,ak,bl_ [ _aibjakbl_ ] + E _ai,bj_ _,\u03f5k,l_ [ _aibj\u03f5k,l_ ]\n\n+ E _ak,bl,\u03f5j,i_ [ _ak, bl, \u03f5j,i_ ] + E _\u03f5j,i,\u03f5l,k_ [ _\u03f5j,i\u03f5k,l_ ] _,_\n\n=E _ai,bj_ _,ak,bl_ [ _aibjakbl_ ] + E _\u03f5j,i,\u03f5l,k_ [ _\u03f5j,i\u03f5k,l_ ] _,_\n\n=0 _i \u0338_ = _k_ or _j \u0338_ = _l._ (13)\n\nUsing Eqs. (12) and (13), our first result follows:\n\n\u03a3 _[r]_ = _\u03c3_ 0 [4] [+] _[ \u03c3]_ _\u03f5_ [2]\n\ufffd _r_\n\n_Imn._\n\ufffd\n\nNow, as _u_ is a vector of elements which are sums and products of variables which all have finite 4th order\nmoments from Assumption 1, it immediately follows that _u_ has finite 4th order absolute moments.\n\nUsing Lemma 1, we see the asymptotic Gaussian density of _v_ _[r]_ is:\n\n1\n\n_\u2212_ _[\u2225][v][r][\u2225]_ [2]\nexp\n(2 _\u03c0_ ) _[mn]_ _\u03c3r_ [2] \ufffd 2 _\u03c3r_ [2]\n\n1\n_g_ ( _v_ _[r]_ ) =\n~~\ufffd~~ (2 _\u03c0_ )\n\n2 _\u03c3r_ [2]\n\n_._ (14)\n\ufffd\n\nWe now derive a 4th order Edgeworth expansion for _p_ ( _v_ _[r]_ ) and its score function, which expands _p_ ( _v_ _[r]_ ) in terms\nof the limiting distribution _g_ ( _v_ _[r]_ ) plus remainder terms. Our proof reveals that 3rd order cumulants control all\nterms in the expansion that decay at rate _O_ \ufffd ~~_\u221a_~~ 1 _r_ \ufffd. As 3rd order cumulants are all zero due to symmetry in\n\nAssumption 1, the overall decay rate is controlled by _O_ \ufffd 1 _r_ \ufffd terms associated with 4th order cumulants. It is\n\nfor this reason that we obtain a faster convergence rate than the standard central limit theorem.\n**Lemma 2.** _Let Assumption 1 hold and let v_ _[r]_ = _vec_ ( _Z_ _[r]_ ) _and ui be defined in Eq._ (10) _. Let g_ ( _v_ _[r]_ ) _denote_\n_limiting Gaussian density in Eq._ (14) _. Then, the Egdeworth expansion of p_ ( _v_ _[r]_ ) _is:_\n\n_p_ ( _v_ _[r]_ ) = _g_ ( _v_ _[r]_ ) + [1]\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[,,]_\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\n_where:_\n\n_\u2225vr\u2225_ 2\n_Hi,j,k,l_ ( _v_ _[r]_ _, \u03c3r_ ) := exp\n\ufffd 2 _\u03c3r_ [2]\n\n_\u2202_ [4]\n\ufffd _\u2202vi_ _[r][\u2202v][r]_\n\n_\u2202_ [4]\n\n_\u2212_ _[\u2225][v][r][\u2225]_ [2]\nexp\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd 2 _\u03c3r_ [2]\n\n2 _\u03c3r_ [2]\n\n\ufffd\n\n_is a 4th order Hermite polynomial for g_ ( _v_ _[r]_ ) _(Laplace, 1811; Hall, 1992; Withers, 2000) and \u03c1_ ( _v_ _[r]_ ) _is o_ \ufffd 1 _r_ \ufffd _._\n\n22\n\n_Proof._ We denote the characteristic function of _p_ ( _u_ _[r]_ _i_ [)][ as:]\n\n_\u03c6U r_ ( _\u03c9_ ) = exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _u_ \ufffd _p_ ( _u_ ) _du._\n\ufffd\n\nNow, make the transformation of variables _x_ _[r]_ _i_ [=] ~~_\u221a_~~ _u_ _[r]_ _ir_, hence _p_ ( _x_ _[r]_ _i_ [) =] _[ \u221a]_ ~~_[r]_~~ _[p]_ [(] _[u][r]_ _i_ [=] _[ \u221a]_ ~~_[r]_~~ _[x][r]_ _i_ [)][ and denote the]\ncharacteristic function of _x_ _[r]_ _i_ [as] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)][. Using the time-scaling property of the Fourier transform, we can]\nderive the characteristic function of _x_ _[r]_ _i_ [in terms of] _[ \u03c6][U][ r]_ [(] _[\u03c9]_ [)][:]\n\n_\u03c6X_ _[r]_ ( _\u03c9_ ) = exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _x_ \ufffd _p_ ( _x_ ) _dx,_\n\ufffd\n\n= _[\u221a]_ _r_ exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _x_ \ufffd _p_ ( _u_ = _[\u221a]_ _rx_ ) _dx,_\n\ufffd\n\n1\n= _[\u221a]_ _r_ exp _\u2212i\u03c9_ _[\u22a4]_ _[u]_ _p_ ( _u_ ) _du,_\n\ufffd ~~_\u221ar_~~ \ufffd ~~_\u221ar_~~ \ufffd\n\n= exp _\u2212i\u03c9_ _[\u22a4]_ _[u]_\n\ufffd \ufffd ~~_\u221ar_~~\n\n_p_ ( _u_ ) _du,_\n\ufffd\n\n_\u03c9_\n= _\u03c6U r_ _._ (15)\n\ufffd ~~_\u221ar_~~ \ufffd\n\nNow, as _v_ _[r]_ = [\ufffd] _[r]_ _i_ =1 _[x]_ _i_ _[r]_ [, we use the property that the density of a sum of] _[ r]_ [ independent random variables]\nis given by the _r_ -fold convolution of the individual PDFs. As convolution in the spatial domain is equal to\nmultiplication in the frequency domain, the density _p_ ( _v_ _[r]_ ) is:\n\n_p_ ( _v_ _[r]_ ) = _F_ _[\u2212]_ [1] [( _\u03c6X_ _r_ ) _[r]_ ] ( _v_ _[r]_ ) _,_\n\n= _F_ _[\u2212]_ [1] [exp ( _r_ log _\u03c6X_ _[r]_ )] ( _v_ _[r]_ ) _,_\n\n= _F_ _[\u2212]_ [1] [exp ( _rKX_ _[r]_ [)] (] _[v][r]_ [)] _[,]_ (16)\n\nwhere _KX_ _[r]_ [(] _[\u03c9]_ [) := log] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)][ is the] _[ cumulant generating function]_ [ (also known as the second characteristic]\nfunction) for _Xi_ _[r]_ [. From Eq. (][15][):]\n\n_KX_ _[r]_ [(] _[\u03c9]_ [) = log] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)] _[,]_\n\n_\u03c9_\n= log _\u03c6U r_\n\ufffd ~~_\u221ar_~~\n\n_,_\n\ufffd\n\n_\u03c9_\n= _KU_ _[r]_ _,_\n\ufffd ~~_\u221ar_~~ \ufffd\n\nwhere _KU r_ ( _\u00b7_ ) is the cumulant generating function for _u_ _[r]_ _i_ [. We now make a 4th order Taylor series expansion]\n\nof _rKU r_ \ufffd ~~_\u221a_~~ _\u03c9r_ \ufffd about _\u03c9_ = 0:\n\n_\u03c9_\n_rKU r_ = _r KU r_ (0)\n\ufffd ~~_\u221ar_~~ \ufffd \ufffd ~~\ufffd~~ \ufffd ~~\ufffd~~\n\n=log 1=0\n\n_\u2202KU_ _[r]_ ( _\u03c9_ = 0)\n_\u03c9i_ _\u2202\u03c9i_\n_i_\n\n+ _[\u221a]_ _r_ \ufffd\n\n_[r]_ ( _\u03c9_ = 0) + [1]\n\n_\u2202\u03c9i_ 2!\n\n2!\n\n_\u2202\u03c9i\u2202\u03c9j_\n\n_\u2202_ [2] _KU_ _[r]_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j_ _\u2202\u03c9i\u2202\u03c9j_\n\n_i,j_\n\n\ufffd\n\n1\n+\n3! ~~_[\u221a]_~~ ~~_r_~~\n\n_\u2202_ [3] _KU r_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j\u03c9k_ _\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_\n\n_i,j,k_\n\n\ufffd\n\n_KU r_ ( _\u03c9_ = 0) + [1]\n\n_\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_ 4!\n\n4! _r_\n\n_KU r_ ( _\u03c9_ = 0) 1\n\n+ _o_\n_\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_ \ufffd _r_\n\n_r_\n\n_\u2202_ [4] _KU r_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l_ _\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_\n\n_i,j,k,l_\n\n\ufffd\n\n_,_\n\ufffd\n\n_\u03c9i\u03ba_ [1] _i_ [+] 2! [1]\n_i_\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03ba_ [3] _i,j,k_\n\n_i,j,k_\n\n= _[\u221a]_ _r_\n\ufffd\n\n2!\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03ba_ [2] _i,j_ [+] 3! ~~_[\u221a]_~~ ~~_r_~~\n\n_i,j_\n\n+ [1]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_r_\n\n_,_\n\ufffd\n\n_\u03c9i\u03ba_ [1] _i_ [+] 2! [1]\n_i_\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03ba_ [3] _i,j,k_ [+] _[ R]_ [(] _[\u03c9]_ [)] _[,]_ (17)\n\n_i,j,k_\n\n= _[\u221a]_ _r_\n\ufffd\n\n2!\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03ba_ [2] _i,j_ [+] 3! ~~_[\u221a]_~~ ~~_r_~~\n\n_i,j_\n\n23\n\n[(] _[\u03c9]_ [=0][)]\nwhere _\u03ba_ _[n]_ _\u00b7_ [is an] _[ n]_ [-th order cumulant (i.e.] _[ \u03ba][n]_ _i_ [:=] _[ \u2202K][U]_ _\u2202\u03c9_ _[r]_ _i_ ) and\n\n_R_ ( _\u03c9_ ) := [1]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_r_\n\n_,_\n\ufffd\n\n1\ndenotes the 4th order polynomial and _o_ \ufffd _r_\n\n1\ndenotes the 4th order polynomial and _o_ \ufffd _r_ \ufffd denotes the higher order remainder terms. We now state some facts\n\nabout cumulants to simplify the above expansion. For a symmetric random vector like _u_ _[r]_ under Assumption 3,\nall odd-order cumulants are zero, i.e. _\u03ba_ _[i]_ _\u00b7_ [= 0][ for odd] _[ i]_ [ (][McCullagh][,][ 2013][;][ 1987][). The second-order cumulant]\nterm coincides with the covariance matrix product: [\ufffd] _[\u03c9][i][\u03c9][j][\u03ba]_ [2] [=] _[ \u2212][\u03c9][\u22a4]_ [\u03a3] _[r][\u03c9]_ [ (][McCullagh][,][ 1987][). Moreover,]\n\nterm coincides with the covariance matrix product: [\ufffd] _i,j_ _[\u03c9][i][\u03c9][j][\u03ba]_ [2] _i,j_ [=] _[ \u2212][\u03c9][\u22a4]_ [\u03a3] _[r][\u03c9]_ [ (][McCullagh][,][ 1987][). Moreover,]\n\nas 4th order moments of _u_ _[r]_ exist from Lemma 1 then all cumulants up to including order 4 exist since\ncumulants are polynomial functions of the moments (Leonov & Shiryaev, 1959; McCullagh, 1987). Finally,\nwe use _\u03c9_ _[\u22a4]_ \u03a3 _[r]_ _\u03c9_ = _\u2225\u03c9\u2225_ [2] _\u03c3r_ [2] [from Lemma][ 1][. Substituting these results into Eq. (][17][) and using] _[ R]_ [(] _[\u03c9]_ [)][ to denote]\nyields:\n\n_\u03c9_\n_rKU r_\n\ufffd ~~_\u221ar_~~\n\n= _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] + _R_ ( _\u03c9_ ) _,_\n\ufffd 2\n\n= _\u21d2_ exp ( _rKX_ _[r]_ [(] _[\u03c9]_ [)) = exp] _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] + _R_ ( _\u03c9_ ) _,_\n\ufffd 2 \ufffd\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n1 + [1]\n\uf8ed 4!\n\nexp ( _R_ ( _\u03c9_ )) _,_\n\ufffd\n\n1\n1 + _R_ ( _\u03c9_ ) + _o_\n\ufffd\ufffd \ufffd _r_\n\n_,_\n\ufffd\ufffd\n\n\ufffd [\uf8eb]\n\n_r_\n\n_,_\n\n\ufffd [\uf8f6]\n\n\uf8f8\n\n\ufffd [\uf8f6]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\nwhere we have used the Taylor series expansion of exp( _x_ ) about _x_ = 0 to derive the fourth line. Substituting\ninto Eq. (16) yields:\n\n_p_ ( _v_ _[r]_ ) = exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp ( _rKX_ _[r]_ [(] _[\u03c9]_ [))] _[ d\u03c9,]_\n\ufffd\n\n\ufffd [\uf8eb]\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n1 + [1]\n\uf8ed 4!\n\n_r_\n\n_d\u03c9,_\n\n\ufffd [\uf8f6]\n\n\uf8f8\n\n\ufffd [\uf8f6]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_d\u03c9_\n\ufffd\n\n+ [1]\n\n4! _r_\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_\n\n_i,j,k,l_\n\n\ufffd\n\n_\u03c9i\u03c9j\u03c9k\u03c9l_ exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n1\n_d\u03c9_ + _o_ _,_\n\ufffd \ufffd _r_ \ufffd\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] _d\u03c9_\n\ufffd \ufffd 2 \ufffd\n\n1\n_d\u03c9_ + _o_\n\ufffd \ufffd _r_\n\n_._\n\ufffd\n\n+ [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_\n\nexp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\nNow, recognising that exp _\u2212_ _[\u2225][\u03c9][\u2225]_ 2 [2] _[\u03c3]_ _r_ [2] is the characteristic function for _g_ ( _v_ _[r]_ ) yields our desired result:\n\ufffd \ufffd\n\n_p_ ( _v_ _[r]_ ) = _F_ _[\u2212]_ [1] [ _F_ [ _g_ ]]( _v_ _[r]_ ) + [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202_ [4] 1\n\n_F_ _[\u2212]_ [1] [ _F_ [ _g_ ]]( _v_ _[r]_ ) + _o_\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) + [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202_ [4] 1\n\n_g_ ( _v_ _[r]_ ) + _o_\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) + [1]\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[,]_\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\n24\n\nwhere _\u03c1_ ( _v_ _[r]_ ) denotes the remainder terms.\n\nWe now provide uniform bounds on the remainder term of the expansion using the techniques of (Bhattacharya\n& Ranga Rao, 1976, Theorem 19.2) and analyse convergence rate of the limiting Gaussian distribution to a\nunit Gaussian:\n**Lemma 3.** _Let \u03c3_ 0 [2] = 1 _, let g_ ( _v_ _[r]_ ) _be the limiting Gaussian from Eq._ (14) _, let f_ ( _v_ _[r]_ ) _be a bounded function and_\n_let g\u221e_ ( _v_ _[r]_ ) = _N_ (0 _, Imn_ ) _. Let Assumptions 1 and 2 hold and let v_ _[r]_ = _vec_ ( _Z_ _[r]_ ) _and ui be defined in Eq._ (10) _._\n_Define the Edgeworth remainder as:_\n\n_R_ ( _v_ _[r]_ ) = _p_ ( _v_ _[r]_ ) _\u2212_ _g_ ( _v_ _[r]_ ) _._\n\n_Then:_\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_\n\ufffd \ufffd _r_\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_ _,_\n\ufffd _r_ \ufffd\n\n1\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd \ufffd _r_\n\n_r_\n\n_r_\n\n_._\n\ufffd\n\n_Proof._ We start by bounding \ufffd _f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ . From Lemma 2, we have shown that the Edgeworth\nexpansion for _p_ ( _v_ _[r]_ ) is controlled by 4th order cumulants and higher, that is;\n\n_p_ ( _v_ _[r]_ ) = _g_ ( _v_ _[r]_ ) + [1]\n\n\ufffd _\u03ba_ [4] _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[.]_ (18)\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\nWe show that the three assumptions needed to apply Bhattacharya & Ranga Rao (1976, Theorem 20.1) to\nobtain our result using Eq. (18). Firstly, the boundedness assumption of the integrand holds:\n\n_\u2225f_ ( _v_ _[r]_ ) _v_ _[r]_ _\u2225_\nsup _\u2264_ sup\n_v_ _[r]_ 1+ _\u2225v_ _[r]_ _\u2225_ _v_ _[r][ f]_ [(] _[v][r]_ [)] _[ <][ \u221e][.]_\n\nSecondly, the sampling regularity assumption that _ui_ (as defined in Eq. (10)) is zero-mean i.i.d. (satisfied\nunder Assumption 1) with finite 4th order moments (satisfied from Lemma 1) holds. Let _\u03c6U_ ( _\u03c9_ ) denote\nthe characteristic function of _p_ ( _u_ ), then the final assumption we need to verify is Cramer\u2019s condition:\nlim sup _\u2225\u03c9\u2225\u2192\u221e_ _\u03c6U_ ( _\u03c9_ ) _<_ 1, which is satisfied from the Riemann-Lebesgue lemma Folland (1999, Theorem 8.22) because _p_ ( _u_ ) is absolutely continuous under Assumption 1). Our first result thus follows from\napplying Bhattacharya & Ranga Rao (1976, Theorem 20.1):\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_ _._\n\ufffd \ufffd _r_ \ufffd\n\n_r_\n\n_._\n\ufffd\n\nWe now derive our second result. Let _d_ := _[mn]_\n\n2 [. As] _[ g][\u221e]_ [(] _[v][r]_ [)][ and] _[ g]_ [(] _[v][r]_ [)][ are both Gaussians:]\n\n1\n_g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) =\n\ufffd _\u03c3r_\n\n_d_ _\u2225vr\u2225_ 2\nexp\n\ufffd \ufffd 2\n\n_r\u2225_ 2 _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\n2 2 _\u03c3_ [2]\n\n2 _\u03c3r_ [2]\n\n_,_\n\ufffd\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_d_ _\u2225vr\u2225_ 2\nexp\n\ufffd \ufffd 2\n\n_d_ 2\n1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n2 _r\u2225_ 2 _\u2212_ _rr\u2225_ + _v_ _[r]_ _\u03c3\u2225_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_,_\n\ufffd\n\n_d_ 2\nexp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_d_ 2\nexp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n_,_\n\ufffd\n\n_\u2212_ 1 _,_\n\ufffd \ufffd\n\n2\nwhere we have substituted for _\u03c3r_ [2] = 1 + _[\u03c3]_ _r_ _[\u03f5]_ from Lemma 1, hence:\n\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\n_\u2212_ 1 _dv_ _[r]_ _._\n\ufffd \ufffd\n\n_r_\n= _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ )\n\ufffd \ufffd _r_ + _\u03c3\u03f5_ [2]\n\n25\n\n_d_ 2\n1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_d_\nExpanding \ufffd _r_ + _r\u03c3\u03f5_ [2] \ufffd using the binomial expansion:\n\n_d_\n\n_r_ _\u03c3\u03f5_ [2]\n\n= 1 _\u2212_\n\n\ufffd _r_ + _\u03c3\u03f5_ [2] \ufffd \ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_d_\n\n_,_\n\ufffd\n\n_d\u03c3\u03f5_ [2] _d\u03c3\u03f5_ 2\n\n_r_ + _\u03c3\u03f5_ [2] [+] _[ o]_ \ufffd _r_ + _\u03c3_\n\n_d\u03c3\u03f5_ [2]\n= 1 _\u2212_\n\n_r_ + _\u03c3\u03f5_ [2]\n\n_,_\n\ufffd\n\n1\n= 1 + _O_\n\ufffd _r_\n\n_,_\n\ufffd\n\nhence:\n\n_vf_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) 1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd\ufffd\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n1\n= 1 + _O_\n\ufffd \ufffd _r_\n\n_\u2212_ 1 _dv_ _[r]_ _._\n\ufffd \ufffd\n\nIt therefore suffices to show:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\nIt therefore suffices to show:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n1\n_\u2212_ 1 _dv_ _[r]_ = _O_\n\ufffd \ufffd \ufffd _r_\n\n_._\n\ufffd\n\nUsing the identity exp( _x_ ) _\u2212_ 1 _\u2264_ _x_ exp( _x_ ) for _x \u2265_ 0:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2] _\u2212_\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_\u2212_ 1 _dv_ _[r]_\n\ufffd \ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n_\u2264_ _|f_ ( _v_ _[r]_ ) _|\u2225v\u2225g\u221e_ ( _v_ _[r]_ ) _[\u03c3]_ [2]\n\ufffd 2( _r_ + _\u03c3_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n2\n\n_\u03f5_ _[\u2225][v][r][\u2225]_ [2] _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n_[\u03c3]_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] ) [exp] \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n_dv_ _[r]_\n\ufffd\n\n= _g\u221e_ ( _v_ _[r]_ ) _[\u03c3]_ _\u03f5_ [2] _[|][f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3]\n\ufffd 2( _r_ + _\u03c3_ [2] )\n\n2\n\n_[f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3] exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_dv_ _[r]_\n\ufffd\n\n= 1 _\u03c3\u03f5_ [2] _[|][f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3]\n\ufffd (2 _\u03c0_ ) _[d]_ 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_[f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3] _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\nexp\n2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd 2\n\n_[r][\u2225]_ [2] _\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n+ _[\u03c3]_ [2]\n2 _r_ + _\u03c3_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_,_\n\ufffd\n\n_\u03f5_\n_\u2264_ sup [(][2] _[\u03c0]_ [)] _[d][\u03c3]_ [2]\n_v_ _[|][f]_ [(] _[v][r]_ [)] _[|]_ 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_\u2225v_ _[r]_ _\u2225_ [3] exp _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2\n\n_r_\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_dv_ _[r]_\n\ufffd\ufffd\n\n_,_\n\n\ufffd ~~\ufffd~~ \ufffd ~~\ufffd~~\n= _O_ (1)\n\n1\n= _O_\n\ufffd _r_\n\n_,_\n\ufffd\n\nwhere our final line follows from the fact that fixed polynomials are integrable under the Gaussian distribution\nand _f_ ( _v_ _[r]_ ) is bounded by assumption, hence:\n\n1 1\n_vf_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = 1 + _O_ _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_ _,_\n\ufffd \ufffd \ufffd _r_ \ufffd\ufffd\ufffd\ufffd \ufffd _r_ \ufffd\ufffd\n\n_r_\n\n1\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd\ufffd\ufffd\ufffd \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\ufffd\n\n1\n= _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd _r_\n\n_,_\n\ufffd\n\nas required.\n\nUsing Lemma 3, we have all ingredients needed derive our main about the convergence result, which follows\nafter some algebra on the norm:\n**Theorem 2.** _Let Assumptions 1 and 2 hold and set \u03c3_ 0 = 1 _, then:_\n\n\u02c6 1\n_\u2225g_ True _\u2212_ _g_ LR _[r]_ _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n26\n\n_._\n\ufffd\n\n_Proof._ We start by converting the norm to vector form using Eq. (11):\n\n_\u03c3_ ( _g_ True _\u2212_ _g_ LR _[r]_ [) =][ E] _[E]_ [[] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ \u2212]_ [E] _[Z][r]_ [ [] _[Z]_ _[r][f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3Z]_ [)]] _[,]_\n\n= E _v_ [ _vf_ ( _\u00b5, v_ )] _\u2212_ E _vr_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] _,_ (19)\n\nwhere _f_ ( _\u00b5, v_ ) := _f_ ( _M_ = _\u00b5_ + _\u03c3_ mat( _v_ )) and _v_ = vec( _E_ ) is the vectorisation of variable _E_, which is distributed\nas _v \u223c_ _g\u221e_ ( _v_ ) =: _N_ (0 _, Imn_ ). Let _R_ ( _v_ _[r]_ ) denote the difference between _p_ ( _v_ _[r]_ ) and the limiting Gaussian\n\n1 _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\n(2 _\u03c0_ ) _[mn]_ _\u03c3r_ [2] [exp] \ufffd 2 _\u03c3r_ [2]\n\n:\n\ufffd\n\ndistribution _g_ ( _v_ _[r]_ ) := 1\n~~_\u221a_~~ (2 _\u03c0_ )\n\n2 _\u03c3r_ [2]\n\n_R_ ( _v_ _[r]_ ) := _p_ ( _v_ _[r]_ ) _\u2212_ _g_ ( _v_ _[r]_ ) _._\n\nUsing this notation:\n\nE _vr_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] = _p_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd\n\n= ( _g_ ( _v_ _[r]_ ) + _R_ ( _v_ _[r]_ )) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ + _R_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\nwhere _g_ ( _v_ _[r]_ ) is the limiting Gaussian density from Eq. (14) and _R_ ( _v_ _[r]_ ) is the Edgeworth remainder term as\ndefined in Lemma 2. Now, applying Lemma 3 to both integrals:\n\n1\nE _v_ _[r]_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] = _g\u221e_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd _r_\n\n1\n=E _v_ [ _vf_ ( _\u00b5, v_ )] + _O_ _._\n\ufffd _r_ \ufffd\n\nSubstituting into Eq. (19) yields our desired result:\n\n_,_\n\ufffd\n\n1\n_\u03c3_ ( _g_ True _\u2212_ _g_ LR _[r]_ [) =] _[ O]_\n\ufffd _r_\n\n_,_\n\ufffd\n\n_._\n\ufffd\n\n\u02c6 1\n= _\u21d2\u2225g_ True _\u2212_ _g_ LR _[r]_ _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n**B** **Mean Field Score Function Approximator**\n\n**B.1** **Bessel Functions**\n\nWe will use _n_ th order Bessel functions of the second kind _Kn_ ( _z_ ) (Basset, 1892; Macdonald, 1899; Watson,\n1944), which are conveniently represented by the integral equations:\n\n_\u221e_\n_Kn_ ( _z_ ) = exp( _\u2212z_ cosh _\u03b8_ ) cosh( _n\u03b8_ ) _d\u03b8._\n\ufffd0\n\nBessel functions are the solutions to systems of differential equations that occur naturally in phenomena\nwhere there is strong radial symmetry, typically involving the propagation of spherical waves from points\nlike the ripples formed from water droplets (Whitham, 1999). For our setting, Bessel functions describe the\nprobability density of the product of rotationally invariant random variables, whose solution is analogous to\nthe interference pattern of two spherical wave propagators.\n\nUsing the representation, we find the derivative of the zeroth order function takes the recursive form:\n\n_dK_ 0( _z_ )\n\nexp( _\u2212z_ cosh _\u03b8_ ) cosh( _\u03b8_ ) _d\u03b8_ = _\u2212K_ 1( _z_ ) _._ (20)\n0\n\n_\u221e_\n_dz_ 0( _z_ ) = _\u2212_ \ufffd0\n\nMore generally, the derivative of the _n_ th order Bessel function is Watson (1944, Section 3.71, Eq. 4):\n\n_dKn_ ( _z_ )\n\n_z_ _[K][n]_ [(] _[z]_ [)] _[ \u2212]_ _[K][n]_ [+1][(] _[z]_ [)] _[.]_ (21)\n\n_n_ _z_\n\n= _[n]_\n_dz_ _z_\n\n27\n\n**B.2** **Derivation of Mean-field Approximators**\n\nTo derive a mena-field approximation, we assume that the elements of _A_ and _B_ are drawn independently from\nthe set of generalised Gaussian distributions (GGDs):\n**Assumption 3.** _Assume each element ai,j \u223cGG_ ( _s, p_ ) _and bi,j \u223cGG_ ( _s, p_ ) _of A and B be independently_\n_distributed according to the zero-mean generalised Gaussian distribution GG_ ( _s, p_ ) _with density:_\n\n_p_ exp _\u2212_ _x_\n\n2 _s_ \u0393 1 \ufffd \ufffd\ufffd\ufffd _s_\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n_p_\n_GG_ ( _x|s, p_ ) =\n\n_s_\n\n_p_ [\ufffd]\n\n_,_\n\ufffd\ufffd\ufffd\n\n_where_ 0 _< s < \u221e_ _is the scale parameter, p >_ 0 _the shape parameter and_ \u0393( _\u00b7_ ) _is the gamma function._\n\nWe observe common distributions emerge from the set of GGDs including the Laplace for _p_ = 1, the Gaussian\nfor _p_ = 2 and the uniform over [ _\u2212s,_ + _s_ ] in the limit _p \u2192\u221e_ .\n\nIf we make the assumption that all elements of _Z_ are independent (this is true as _r_ grows) then we can write\n_p_ ( _Z_ _[r]_ ) _\u2248_ _p_ \u02c6( _Z_ ) := [\ufffd] _[m]_ _i_ =1 \ufffd _nj_ =1 _[p]_ [(] _[z][i,j]_ [)][ as the product of the marginal distributions. Under this approximation,]\nthe score function can be defined element-wise as:\n\n[ _\u2207Z_ log _p_ ( _Z_ _[r]_ )] _i,j \u2248_ _S_ [\u02c6] ( _zi,j_ ) := _\u2202zi,j_ log _p_ ( _zi,j_ ) _._\n\nUsing this approximation we apply the score function _S_ [\u02c6] ( _\u00b7_ ) element-wise to the matrix _Z_ :\n\n\u02c6\n_g_ LR _\u2248_ _g_ MF := _\u2212\u03c3_ E _Z\u223cp_ ( _Zr_ ) \ufffd _f_ ( _y_ = ( _\u00b5_ + _\u03c3Z_ ) _x_ ) _\u00b7_ _S_ [\u02c6] _\u2299_ ( _Z_ )\ufffd _._\n\nFor _r_ = 1, _S_ [\u02c6] ( _\u00b7_ ) has a convenient analytic form for all members of the set of GGDs with _\u03c3\u03f5 \u2248_ 0:\n**Theorem 3.** _Let Assumption 3 hold with \u03c3\u03f5_ = 0 _and r_ = 1 _. Then the distribution over marginals p_ ( _zi,j_ ) _is:_\n\n_p_\n\n_p_ 2 _|zi,j|_ 2\n_p_ ( _zi,j_ ) = 2 _[K]_ 0\n_s_ \u0393 1 \ufffd _s_ _[p]_\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd\n\n_,_ (22)\n\n_where K_ 0 ( _\u00b7_ ) _is the zeroth-order modified Bessel function of the second kind and the marginal score function is_\n_defined element-wise as:_\n\n\ufffd\n\n_p_ _p_\n\n_\u00b7_ _[p]_ 2 _|zi,j|_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_K_ 1\n\n\u02c6\n_S_ ( _zi,j_ ) = _\u2212_\n\n_K_ 0\n\n_p_\n2 _|zi,j_ _|_ 2\n\n_s_ _[p]_\n\ufffd\n\n_p_\n2 _|zi,j_ _|_ 2\n\n_s_ _[p]_\n~~\ufffd~~\n\n_._\n_s_ _[p]_\n\n_Proof._ For _r_ = 1, we denote the elements of vector _A_ as _ai_ and elements of vector _B_ as _bj_, then the elements\nof matrix _Z_ = _AB_ _[\u22a4]_ are: _zi,j_ = _aibj_ . We now derive the distribution the unnormalised variables: _zi,j_ using\nthe formula for the distribution of the product of two independent random variables (Rohatgi, 1976; Grimmett\n& Stirzaker, 1993):\n\n_\u221e_\n\n_p_ ( _ai_ ) _p_ _bj_ = _[z][i][,j]_\n_\u2212\u221e_ \ufffd _ai_\n\n_\u221e_\n_p_ ( _zi,j_ ) =\n\ufffd\n\n_ai_\n\n1\n\ufffd _|ai|_ _[da][i][,]_\n\n2\n\n_\u221e_\n\ufffd\n\n\ufffd\ufffd\ufffd\ufffd\n\n_p_ [\ufffd] 1\n\n_|ai|_ _[da][i][,]_\n\n_p_ [\ufffd] 1\n\n_|a_\n\n=\n\n\uf8eb\n\n_p_\n\n2 _s_ \u0393\n\n\uf8ed\n\n2 _s_ \u0393 1\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n\uf8f6\n\n\uf8f8\n\nexp _\u2212_ _ai_\n_\u2212\u221e_ \ufffd \ufffd\ufffd\ufffd _s_\n\n_s_\n\n_p_ [\ufffd] exp _\u2212_ _zi,j_\n\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd _ais_\n\n_p_ [\ufffd] 1\n\n_|ai|_ _[da][i][,]_\n\n_p_ [\ufffd] 1\n\n_|a_\n\n=2\n\n\uf8eb\n\n_p_\n\n2 _s_ \u0393\n\n\uf8ed\n\n2 _s_ \u0393 1\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n\uf8f6\n\n\uf8f8\n\n2\n\n_\u221e_\n\ufffd0\n\nexp _\u2212_ _ai_\n0 \ufffd \ufffd\ufffd\ufffd _s_\n\n_s_\n\n_p_ [\ufffd] exp _\u2212_ _zi,j_\n\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd _ais_\n\n\ufffd\ufffd\ufffd\ufffd\n\n28\n\nwhere we have used symmetry of the integrand about 0 to derive the final line. Now, making the substitution\n_x_ = \ufffd _asi_ \ufffd _p_, we have:\n\n1\n\n_dai_ _p_ _[\u2212]_ [1]\n\n_dx_ [=] _[ sx]_\n\n_dai_\n\n_p_ 1\n\n_,_ _ai_ = _sx_ _p_\n_p_\n\nhence:\n\n1\n\ufffd _x_ _[dx.]_\n\n_|zi,j|_ _[p]_\n\n[1]\n\n_x_ _s_ [2] _[p]_\n\n_p_ 1\n_p_ ( _zi,j_ ) = _s_ \u0393 1 2 2\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd0 _\u221e_\n\n_\u221e_\n\nexp _\u2212x \u2212_ [1]\n0 \ufffd _x_\n\n_s_ [2] _[p]_\n\nNow, we use the identity (Temme, 1996, Theorem 9.42):\n\n1\n\ufffd _x_ _[dx,]_\n\n1\n\ufffd _x_\n\n_K_ 0( _x_ ) = [1]\n\n2\n\n\ufffd0 _\u221e_\n\n_\u221e_\n\nexp _\u2212x \u2212_ _[z]_ [2]\n0 \ufffd 4 _x_\n\n4 _x_\n\n_p_\n2\nwith _z_ = [2] _[|][z]_ _s_ _[i][,j][p]_ _[|]_ to yield:\n\n_p_\n\n_p_ 2 _|zi,j|_ 2\n_p_ ( _zi,j_ ) = 2 _[K]_ 0\n_s_ \u0393 1 \ufffd _s_ _[p]_\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd\n\n_,_\n\nas required for Eq. (22). Now we derive the marginal score function by applying the chain rule:\n\n\ufffd\n\n_,_\n\n\ufffd\n\n_\u2202zi,j_ log _p_ ( _zi,j_ ) = _\u2202zi,j_ log _K_ 0\n\n_p_\n2 _|zi,j|_ 2\n\n_s_ _[p]_\n\ufffd\n\n= _\u2202z_ log _K_ 0\n\n= _\u2202z_ log _K_ 0\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j][|]_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j][|]_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n_p|zi,j|_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n\n_,_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n_\u2202zi,j_ 2 _|zi,j|_ 2 _,_\n_s_ _[p]_\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j]_ _[|]_\n_s_ _[p]_\n\ufffd\n\n\ufffd\n\n_\u2202zK_ 0\n\n=\n\n_p_\n\n_K_ 0 _z_ = [2] _[|][z]_ _s_ _[i][,j][p]_ _[|]_ 2\n\n~~\ufffd~~\n\n_p_\n\n_\u00b7_ _[p][|][z][i][,j][|]_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_,_\n_s_ _[p]_\n\n_p_\n\n_K_ 1 2 _|zsi,j_ _[p]_ _|_ 2\n= _\u2212_ \ufffd _p_\n\n_K_ 0 2 _|zsi,j_ _[p]_ _|_ 2\n\n~~\ufffd~~\n\n\ufffd\n\n_p_\n\n_\u00b7_ _[p][|][z][i][,j][|]_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_,_\n_s_ _[p]_\n\nwhere we have used the identity _\u2202zK_ 0( _x_ ) = _\u2212K_ 1( _x_ ) from Eq. (20)\n\nFor _r >_ 1 we can derive _S_ [\u02c6] ( _\u00b7_ ) for the Gaussian sampling case:\n**Theorem 4.** _Let Assumption 3 hold with \u03c3\u03f5_ = 0 _and p_ = 2 _. Then the distribution over marginals p_ ( _zi,j_ ) _is:_\n\n_r\u2212_ 1\n\n2\n\n_p_ ( _zi,j_ ) = [2] _[\u221a]_ ~~_[r]_~~ _[|\u221a]_ ~~_[r]_~~ _[z][i][,j][|]_ _r_\n\n2\n\n_._\n\ufffd\n\n2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\ufffd _s_ [2]\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n_and the score function is:_\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n_zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n_S_ \u02c6( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _, ._\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n29\n\n_Proof._ Let _ui,j_ = ~~_\u221a_~~ 1 _r_ _zi,j_ . Using the transformation of variables, we derive the density for _zi,j_ from _p_ ( _ui,j_ )\nusing: _p_ ( _zi,j_ ) = _[\u221a]_ ~~_r_~~ _p_ ( _ui,j_ = _[\u221a]_ ~~_r_~~ _zi,j_ ). Each element _ui,j_ is the sum of _r_ independent variables _ui,j,l_ := _ai,lbj,l_\ndistributed according to Eq. (22) with _p_ = 2:\n\n_r_\n\ufffd _ui,j,l_\n\n_l_ =1\n\n_ui,j_ =\n\n_r_ 1\n\ufffd _l_ =1 _ai,lbj,l_ = ~~_\u221ar_~~\n\nFrom Eq. (22), the distribution of each _ui,j,l_ is:\n\n2\n_p_ ( _ui,j,l_ ) =\n_s_ [2] _\u03c0_ _[K]_ [0]\n\n2 _|ui,j,l|_\n\ufffd _s_ [2]\n\n\ufffd\n\nWe use the fact that the PDF of a sum of _r_ independent random variables is given by the _r_ -fold convolution of\nthe individual PDFs. As convolution in the spatial domain is equal to multiplication in the frequency domain,\nthe PDF _p_ ( _ui,j_ ) follows by taking Fourier transform of _p_ ( _ui,j,l_ ), taking the power _r_ and then taking the inverse\nFourier transform:\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n_r_\n( _ui,j_ ) _,_\n\ufffd\ufffd \ufffd\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2] _\u03c0_\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n_r_\n_F_ _[\u2212]_ [1] _F_ _K_ 0\n\ufffd \ufffd \ufffd\n\nwhere _F_ [ _f_ ( _\u00b7_ )]( _\u03c9_ ) and _F_ _[\u2212]_ [1] [ _f_ [\u02c6] ( _\u00b7_ )]( _x_ ) denotes the Fourier and inverse Fourier transforms. Taking the Fourier\ntransform of the Bessel function:\n\n_F_ _K_ 0\n\ufffd\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n( _\u03c9_ ) = exp( _\u2212i\u03c9_ _[\u22a4]_ _x_ ) _K_ 0\n\ufffd\ufffd \ufffd\n\n2 _|x|_\n\ufffd _s_ [2]\n\n_dx,_\n\ufffd\n\n2 _|x|_\n\ufffd _s_ [2]\n\n_dx,_\n\ufffd\n\n= cos( _\u03c9x_ ) _K_ 0\n\ufffd\n\n= cos( _\u03c9x_ ) _K_ 0\n\ufffd\n\n2 _|x|_\n\n_dx \u2212_ _i_ sin( _\u03c9x_ ) _K_ 0\n\n\ufffd _s_ [2] \ufffd \ufffd\n\n2 _|x|_\n\n_dx,_\n\n\ufffd _s_ [2] \ufffd\n\n_dx,_ (23)\n\ufffd\n\n_\u221e_\n= 2 cos( _\u03c9x_ ) _K_ 0\n\ufffd0\n\n2 _x_\n\ufffd _s_ [2]\n\n2 _|x|_\nwhere we have used the fact thatsecond line is zero. Using a standard result, we can evaluate the integral in Eq. ( _K_ 0 \ufffd _s_ [2] \ufffd is an even function of _x_ and so its integral with23) Gradshte sin(\u02d8\u0131n et al. _\u03c9x_ ) ( in the2015,\n\n6.671 Integral 14):\n\n_F_ _K_ 0\n\ufffd\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n_\u03c0_\n( _\u03c9_ ) =\n\ufffd\ufffd _\u03c9_ [2] +\n~~\ufffd~~\n\n2\n_\u03c9_ [2] + ~~\ufffd~~ _s_\n\n_s_ 2 [2] ~~\ufffd~~ 2 _[,]_\n\n30\n\nhence:\n\n_s_ 2 [2] ~~\ufffd~~ 2 ~~[\ufffd]~~ ~~_[r]_~~ 2\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2] _\u03c0_\n\n_r_\n_F_ _[\u2212]_ [1]\n\ufffd\n\n\uf8ee\n\n_\u03c0_ _[r]_\n\n2\n\uf8ef\uf8f0 ~~\ufffd~~ _\u03c9_ [2] + ~~\ufffd~~ _s_ [2]\n\n\uf8f9\n\n\uf8fa ( _ui,j_ ) _,_\n\uf8fb\n\n\uf8f9\n\n2\n\n\uf8fb ( _ui,j_ ) _,_\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_\n_F_ _[\u2212]_ [1]\n\ufffd\n\n\uf8ee\n\n\uf8f0\n\n\ufffd\n\n_[r]_\n\n2 [\uf8f9]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\n\ufffd\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\nexp( _i\u03c9ui,j_ )\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\ncos( _\u03c9ui,j_ )\n\ufffd\ufffd\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n_s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9_\n\n\ufffd\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n+ _i_ sin( _\u03c9ui,j_ )\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_,_\n\n\ufffd\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\ncos( _\u03c9ui,j_ )\n\ufffd\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_r_ 1\n\ufffd _\u03c0_\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_ (24)\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_\u221e_\n\ncos( _\u03c9ui,j_ )\n\n\ufffd0\n\n\ufffd0 _\u221e_\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\nwhere we have used the fact that the integrand is an even function and so its integral with sin( _\u03c9zi,j_ ) is zero\nto derive the penultimate line. To evaluate the integral in Eq. (24) we apply Gradshte\u02d8\u0131n et al. (2015, 3.771\nIntegral 2):\n\n_r_ 1\n\n_\u00b7_\n\ufffd ~~_\u221a\u03c0_~~ \u0393 ~~\ufffd~~ 2 _r_\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n2\n_s_ _|ui,j|_\n2 _r_ ~~\ufffd~~ \ufffd 4\n\n2\n\n_\u00b7 K r\u2212_ 1\n\n2 _|ui,j|_\n\n_,_\n\n\ufffd _s_ [2] \ufffd\n\n4\n\n\ufffd _[r][\u2212]_ 2 [1]\n\n2\n\n_r\u2212_ 1\n= 2 _|ui,j|_ 2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|ui,j|_\n\n_._\n\n\ufffd _s_ [2] \ufffd\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n2\n\nUsing the transformation of variables yields our desired results:\n\n_p_ ( _zi,j_ ) = _[\u221a]_ _rp_ ( _ui,j_ = _[\u221a]_ _rzi,j_ ) _,_\n\n_r\u2212_ 1\n\n2\n\n= [2] _[\u221a]_ ~~_[r]_~~ _[|\u221a]_ ~~_[r]_~~ _[z][i][,j][|]_\n\n2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\n_._\n\n\ufffd _s_ [2] \ufffd\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n2\n\nNow, we derive the score function:\n\n_,_\n\ufffd\n\n_\u2202zi,j_ log _p_ ( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n2\n\n2 _\u00b7 \u2202zi,j_ log _|_ _[\u221a]_ _rzi,j|_ + _\u2202zi,j_ log _K r\u2212_ 2 1\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\ufffd _s_ [2]\n\n_x_ = [2] _[|]_ ~~_[\u221a]_~~ _[rz][i][,j]_ _[|]_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n+ [2] _[\u2202][z][i,j]_ _[|\u221a]_ ~~_[r]_~~ _[z][i,j][|]_\n2 _zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n_\u2202xK r\u2212_ 1\n\n_[|\u221a]_ ~~_[r]_~~ _[z][i,j][|]_ 2\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n_x_ = [2] _[|]_ ~~_[\u221a]_~~ _[rz][i][,j]_ _[|]_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n+ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _\u2202xK r\u2212_ 2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n31\n\nNow, from Eq. (21):\n\n_[\u2212]_ [1]\n\n2 [(] _[x]_ [)] _[ \u2212]_ _[K][ r]_ [+] 2 [1]\n\n_\u2202xK r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_r\u2212_ 1\n\n_r\u2212_\n\n2 _x_ _[K][ r][\u2212]_ [1]\n\n[+][1]\n\n2 [(] _[x]_ [)]\n\n=\n\n_K r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_,_\n\n_K r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_[ \u2212]_ [1] _\u2212_ _K_ _r_ +2 1\n\n2 _x_ _K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n+1\n\n2 [(] _[x]_ [)]\n\n_\u2212_ 1\n\n2 [(] _[x]_ [)] _[,]_\n\n_K r\u2212_ 1\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_K r\u2212_ 1\n\n_[ \u2212]_ [1]\n\n+ [(] _[r][ \u2212]_ [1][)][si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ 2 _|zi,j|_\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n= _\u21d2_ _\u2202zi,j_ log _p_ ( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n[1][)][si][g][n][(] _[z][i][,j]_ [)]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _|zi,j|_ _s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_K r\u2212_ 1\n\n_[ \u2212]_ [1]\n\n+ [(] _[r][ \u2212]_ [1][)]\n2 _zi,j_ 2 _zi,j_\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n= _[r][ \u2212]_ [1]\n\n_[ \u2212]_ [1][)]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ _s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n_[ \u2212]_ [1]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n_zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\nas required.\n\n32\n\n**C** **EGG Architecture**\n\nIn the following section, we detail the design of our EGG model, which follows the high-level structure of\nmodern pre-layernorm decoder-only language models, but replaces self-attention with a modified minGRU and\nstandard layernorms with a custom variant to enable pure integer training. See Algorithm 2 for an overview of\nthe forward pass of the EGG architecture.\n\n**Algorithm 2** EGG forward pass\n\n**Require:** Input token _t \u2208_ U8, input state _s \u2208_ I _[l]_ 8 _[\u00d7][D]_, network parameters _\u03b8_\n**Ensure:** Output vector _y \u2208_ I _[D]_ 8 [and output state] _[ s][\u2032][ \u2208]_ [I] _[l]_ 8 _[\u00d7][D]_\n_s_ _[\u2032]_ _\u2190_ I _[l]_ 8 _[\u00d7][D]_ initialized to 0\n_y \u2190_ EMBED( _\u03b8_ emb _, t_ )\n**for** _i \u2208{_ 0 _, . . ., l \u2212_ 1 _}_ **do**\n\n_y_ _[\u2032]_ _, s_ _[\u2032]_ _i_ _[\u2190]_ [GRU][(] _[\u03b8]_ [gru] _[,i][,]_ [ LN][(] _[\u03b8]_ [ln1] _[,i][, y]_ [)] _[, s][i]_ [)]\n_y \u2190_ I8(I32( _y_ _[\u2032]_ ) + I32( _y_ ))\n_y_ _[\u2032]_ _\u2190_ MLP( _\u03b8_ mlp _,i,_ LN( _\u03b8_ ln2 _,i, y_ ))\n_y \u2190_ I8(I32( _y_ _[\u2032]_ ) + I32( _y_ ))\n**end for**\n_y \u2190_ LN( _\u03b8_ lnout _,i, y_ )@ _\u03b8_ head _[T]_\n\n**C.1** **Notation and Operations**\n\nWe use the constant _l \u2208_ E [+] to denote the number of layers of the model and _D_ = 4 _[d]_ as the hidden dimension\nof the model, where _d \u2208_ E [+] .\n\nWe use I _n_ to denote an _n_ -bit signed integer and U _n_ to denote an _n_ -bit unsigned integer. We denote casting\nvector _\u20d7x_ to format I _n_ as I _n_ ( _\u20d7x_ ), which implicitly includes clipping to the bounds of the datatype. To ensure\nsymmetry between positive and negative values of each datatype, we consider the value _\u2212_ 2 _[n][\u2212]_ [1] to be invalid\nfor datatype I _n_ ; for instance, for 8-bit signed integers we only allows value from -127 to 127.\n\nWe use the following operations:\n\n    - _\u20d7x_ @ _M_ indicating scaled vector-matrix multiplication of I _[n]_ 8 _[\u00d7]_ [I] _[n,m]_ 8 _\u2192_ I _[m]_ 8 [, corresponding to int8 tensor]\ncore multiplication with int32 accumulation and scaling. The details of this operation are described\nin the next subsection.\n\n    - _a \u00b7 b_ indicates dot product with int32 accumulation, I _[n]_ 8 _[\u00d7]_ [ I] _[n]_ 8 _[\u2192]_ [I][32][, and] _[ a][ \u2299]_ _[b]_ [ indicates the Hadamard]\n(elementwise) product.\n\n    - Standard integer operations: + for addition, _\u2212_ for subtraction, and _\u2299_ for element-wise multiplication.\n\n    - _|x|_ indicates taking the element-wise absolute value of _x_, I _[n]_ _\u2192_ I _[n]_ .\n\n    - sign( _x_ ) indicates taking the element-wise sign of _x_, giving 1 for positive values, -1 for negative\nvalues, and 0 for zero.\n\n   - sum( _x_ ) indicates taking the sum of all elements in _x_ (casting to I32 to prevent overflow): I _[n]_ _\u2192_ I32.\n\n    - _x \u226b_ _n_ indicates an elementwise bitwise right shift by _n_, which is typically equivalent to 2 _[\u2212][n]_ _x_ .\nSimilarly, _x \u226a_ _n_ indicates a bitwise left shift by _n_, which is typically equivalent to 2 _[n]_ _x_ .\n\n    - Square-bracket indexing. For instance _M_ [ _x, y_ ] extracts the element at index _x_ in axis 0 and index _y_\nin axis 1, following the zero-based indexing convention.\n\n**C.2** **Parameter Initialization**\n\nThe standard initialization for matrix parameters in our model is rounding 16 times a sample from the standard\nnormal, and casting to I8. This can be precomputed on a CPU since this is only done once at the start of\ntraining.\n\n33\n\nThe egg model has the following parameters (where an additional subscript of _i_ indicates that there is a version\nof this parameter for each layer of the model):\n\n    - _\u03b8_ emb _\u2208_ I [256] 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ head _\u2208_ I [256] 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ lnout _\u2208_ I _[D]_ 8 [, initialized to 16 for each element.]\n\n    - _\u03b8_ ln1 _,i, \u03b8_ ln2 _,i \u2208_ I _[D]_ 8 [, initialized to 16 for each element]\n\n    - _\u03b8_ mlp _,i,_ 1 _\u2208_ I [4] 8 _[D][\u00d7][D]_ and _\u03b8_ mlp _,i,_ 2 _\u2208_ I _[D]_ 8 _[\u00d7]_ [4] _[D]_, following standard initialization.\n\n    - _\u03b8_ GRU _,i,_ [Wf,Uf,Wh,Uh] _\u2208_ I _[D]_ 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ GRU _,i,_ [bfm bh] _\u2208_ I _[D]_ 8 [, initialized to 0 for each element.]\n\nIn total there are 513 _D_ + _l_ (4 _D_ + 12 _D_ [2] ) parameters in the model.\n\n**C.3** **Matrix Multiplication**\n\nTensor cores in GPUs are able to calculate fast vector-matrix multiplications with int32 accumulation as\n_xM \u2208_ I _[m]_ 32 [where] _[ x][ \u2208]_ [I] _[n]_ 8 [and] _[ M][ \u2208]_ [I] _[n]_ 8 _[\u00d7][m]_ . For our purposes, we define _x_ @ _M_ as a scaled multiplication:\n\n_x_ @ _M_ := I8( _[xM]_\n\n16 ~~_[\u221a]_~~ ~~_n_~~ [)] _[.]_\n\nNote that when _n_ = 4 _[d]_, the division operation just becomes a right-shift by 4 + _d_, which is fast to calculate.\n\nWe choose this scaled matrix multiplication because we initialize _M_ to 16 times standard normal samples for\neach element, so dividing by 16 _[\u221a]_ ~~_n_~~ preserves the magnitude of _x_ for the output. In particular, if all elements\nof _x_ and _M_ are drawn from independently from the standard normal distribution multiplied by 16, the central\nlimit theorem tells us that the expected value per element of the output will be 256 _[\u221a]_ ~~_n_~~ ~~,~~ so dividing by 16 _[\u221a]_ ~~_n_~~\npreserves the standard deviation of 16.\n\n**C.4** **Embedding**\n\nOur embedding function takes as input an embedding matrix _\u03b8_ emb _\u2208_ I [256] 8 _[\u00d7][D]_ and an input token _t \u2208_ U8, and\nsimply outputs the vector corresponding to that token: _\u03b8_ emb[ _t_ ] _\u2208_ I _[D]_ 8 [.]\n\n**C.5** **Layer Normalization (LN)**\n\nOur layer normalization operation involves multiplying our input _x \u2208_ I _[D]_ 8 [with a weight] _[ \u03b8]_ [ln] _[\u2208]_ [I] _[D]_ 8 [before]\ndividing by the mean absolute value of _x_ .\n\nWe decide to divide by the mean absolute value of the input instead of the more more common root-meansquared since square roots are expensive on integers. Note that the _L_ 1 norm after dividing the input by the\nmean absolute value (when using real numbers) is _D_ instead of 1, which we intentionally choose to preserve\nmore bits of information given the limited range of I8.\n\nWe calculate the mean absolute value of input _x_ as:\n\n_x_ mav = I8(sum( _|x|_ ) _\u226b_ (2 _d_ )) _,_\n\nNote that we can safely cast the mean absolute value to an I8 without overflow given the properties of the\nmean of a set, though we lose precision due to truncating the fractional component.\n\nThe output of layernorm is calculated as:\n\nDIVIDE(I16( _x_ ) _\u2299_ I16( _\u03b8_ ln) _, x_ mav) _._\n\nSince division is an expensive operation, we precompute it using a lookup table. Note that the product of two\nI8 values will always remain in the dynamic range of I16, so our lookup table will be of shape 2 [16] _\u00d7_ 2 [8] .\n\n34\n\n**C.6** **MLP**\n\nEach MLP block consists of two weight parameters: _\u03b8_ 1 _\u2208_ I [4] 8 _[D][\u00d7][D]_ and _\u03b8_ 2 _\u2208_ I _[D]_ 8 _[\u00d7]_ [4] _[D]_ . Given an input _x \u2208_ I _[D]_ 8 [,]\nwe calculate the output as:\n\n( _x_ @ _\u03b8_ 1 _[T]_ [)@] _[\u03b8]_ 2 _[T]_ _[.]_\n\nNote that we do not use an activation function, because the @ operation is already nonlinear due to the saturated\nconversion from I32 to I8\n\n**C.7** **GRU**\n\nEach GRU block accepts an input vector and state _x, s_ _\u2208_ I _[D]_ 8 consists of 6 weight parameters:\n_\u03b8_ Wf _, \u03b8_ Uf _, \u03b8_ Wh _, \u03b8_ Uh _\u2208_ I _[D]_ 8 _[\u00d7][D]_ and _\u03b8_ bf _, \u03b8_ bh _\u2208_ I _[D]_ 8 [.]\n\nUsing these weight matrices, we calculate the following vectors:\n\n_f_ = _\u03c3_ (I8(I32( _x_ @ _\u03b8_ Wf _[T]_ [) +][ I][32][(] _[s]_ [@] _[\u03b8]_ Uf _[T]_ [) +][ I][32][(] _[\u03b8]_ [bf][)))] _[,]_\n\n\u02c6\n_f_ = I8(((I32( _f_ ) + 127) _\u2299_ I32( _s_ )) _\u226b_ 8) _,_\n\n\u02c6\n_h_ = _\u03d5_ (I8(I32( _x_ @ _\u03b8_ Wh _[T]_ [) +][ I][32][( \u02c6] _[f]_ [@] _[\u03b8]_ Uh _[T]_ [) +][ I][32][(] _[\u03b8]_ [bh][)))] _[,]_\n\n_h_ = _s_ + I8(((I32( _f_ ) + 127) _\u2299_ (I32( _h_ [\u02c6] ) _\u2212_ I32( _s_ ))) _\u226b_ 8) _,_\n\nwhere _h_ is the output and the new hidden state. In the typical GRU, _\u03c3_ stands for the sigmoid function while _\u03d5_\nstands for the hyperbolic tangent, but we find that setting these as identity operations is sufficient due to the\nnonlinearity already present in the clipped addition. One can view this clipped addition operation as scaled\nand shifted version of the \u201chard\" tanh and sigmoid operators.\n\nTo explain why we perform these operations, we can analyze this relative to the original GRU. The _f_ vector\nfor the standard GRU has all elements between 0 and 1 due to the sigmoid, but our elements are between -127\nand 127. Therefore, to calculate _f_ [\u02c6] (which is typically just _f \u2299_ _s_ ), we first add 127 to _f_, getting the range\nbetween 0 and 254 before multiplying by _s_ before bit-shifting right by 8 again to bring our values back to the\nI8 dynamic range. We apply similar logic to calculate the final _h_, which is typically just _h_ = _s_ + _f \u2299_ ( _h_ [\u02c6] _\u2212_ _s_ )\nbut needs to be rescaled to keep the int8 dynamic range.\n\n**C.8** **Fitness Calculation in Integer Types**\n\nThe \u201cfitness\u201d used in language model pretraining is the log-likelihood of correctly generating the next token,\ntreating the outputs of the language model as logits (unnormalized log probabilities). If _t_ _[\u2032]_ _\u2208_ U8 is the next\ntoken to predict and _y \u2208_ I [256] 8 are the logits, we can calculate the log likelihood as follows:\n\n_y_ _[\u2032]_ = I32( _y_ ) + 128 _,_\n\n_o_ = _y_ _[\u2032]_ [ _t_ _[\u2032]_ ] _\u2212_ LOG2[sum(EXP2[ _y_ _[\u2032]_ ])] _,_\n\nwhere _o_ is the loss for one token. We implement EXP2 and LOG2 as lookup tables, where\n\nEXP2[ _i_ ] = 16 _\u00d7_ 2 _[i/]_ [16] _,_\n\nLOG2[ _i_ ] = 16 _\u00d7_ log2( _i/_ 16) _._\n\nNote that each element in EXP2 for any U8 input requires at most 20 bits, so the sum of exponents across all\npossible choices is at most 28 bits, meaning we have to precompute LOG2 for 2 [28] values.\n\n**D** **EGG Pretraining with Integer EGGROLL**\n\nThe core ideas of EGGROLL still apply in this integer-based training setting, but we have to make some\nmodifications to ensure it only uses integer operations.\n\n35\n\n**D.1** **Adding EGGROLL Perturbations**\n\nFor parameter _\u03b8 \u2208_ I _[m]_ 8 _[\u00d7][n]_ that represents a matrix multiplication, we first sample rank-1 perturbation vectors\nfor each index in the batch: _A \u2208_ I _[m]_ 8 [and] _[ B][ \u2208]_ [I] _[n]_ 8 [. We sample these vectors from the standard random normal]\nmultiplied by 16 and rounded to the nearest I8 (clipping if necessary). To prevent the use of floating-point\narithmetic on the accelerator, we pre-generate a large matrix of these random values, randomly indexing into it\nto get the perturbation vectors.\n\nGiven an input _x \u2208_ I _[n]_ 8 [, instead of calculating] _[ x]_ [@] _[\u03b8][T]_ [, we calculate]\n\nI8( _[x\u03b8][T]_ [ + ][((] _[x][ \u00b7][ B]_ [)][I][32][(] _[A]_ [)] _[ \u226b]_ [(][4 + \u02c6] _[\u03c3]_ [))] ) _._\n\n16 ~~_[\u221a]_~~ ~~_n_~~\n\nThe value of \u02c6 _\u03c3_ is a hyperparameter, related to the _\u03c3_ in the main paper as _\u03c3_ = 2 _[\u2212][\u03c3]_ [\u02c6] . Note that the batched\nforward pass remains efficient since it still simply performs a batched vector-vector dot product in int8 (with\nint32 accumulate) and a batched vector-scalar product in int32.\n\nWe apply this same logic to the embedding matrix, since we can interpret _\u03b8_ [ _t_ ] as one_hot( _t_ ) _\u03b8_ and still apply\nour rank-1 updates in that context. In practice, this means replacing _x \u00b7 B_ with _B_ [ _t_ ].\n\n**D.2** **Fitness Shaping**\n\nWe employ a simple fitness shaping scheme based on antithetical pairs. Specifically, given raw fitnesses\n_s_ [+] _, s_ _[\u2212]_, for the positive and negative sample of the antithetical pair respectively, the transformed fitness for the\nnoise is:\nsign( _s_ [+] _\u2212_ _s_ _[\u2212]_ ) _,_\n\nNote that the only possible values for the fitness after shaping are _{\u2212_ 1 _,_ 0 _,_ 1 _}_ .\n\n**D.3** **Parameter Update**\n\nFor parameter _\u03b8 \u2208_ I _[m]_ 8 _[\u00d7][n]_ that represents a matrix multiplication (or embedding vector), suppose the sampled\nbatch of rank-1 perturbation vectors are _A \u2208_ I _[N]_ 8 _[\u00d7][m]_ and _B \u2208_ I _[N]_ 8 _[\u00d7][n]_, and let the fitnesses after shaping be\n_F \u2208_ I _[N]_ 8 [. Then we calculate an intermediate value] _[ E][ \u2208]_ [I] _[m]_ 32 _[\u00d7][n]_ as:\n\n_E_ = ( _F \u2299_ _A_ ) _[T]_ _B._\n\nWe use _E_ to determine if each element of _\u03b8_ should be increased or decreased. In particular, when the absolute\nvalue of _E_ is above a pre-specified threshold we move _\u03b8_ by one discrete bin in the direction of the sign of\n_E_ . Since there are only 255 unique values for each element in I8, restricting updates to single bins improves\nstability without compromising the ability for a parameter to get to any other value with relatively few\nupdates.\n\nWe currently do not incorporate any momentum or other optimizer states, but this remains critical future work\nto improve the speed of convergence for pure integer training.\n\n**E** **EGG Ablations**\n\n**E.1** **Data Efficient Training**\n\nIn our main experiments, we give a unique training sequence to each antithetical pair. However, after fitness\nshaping only 1 bit is extracted per antithetical pair, so we may be able to reuse training sequences across\nmultiple members of the population. When we let each sequence be used for at most 512 members of the\npopulation, we get the loss curves in Fig. 6. At large population sizes, at 4096 and above, we see similar\nperformance despite using 256 times less data. At small population sizes, we see instability, likely due to the\nfact that reusing the same training sequence across the entire population would lead to \u201coverfitting\u201d to the\ntraining sequence instead of generalizing.\n\n36\n\nData Efficient Pure Integer Pretraining: Test Loss\n\n8\n\n7\n\n10 [5]\n\n10 [4]\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-36-0.png)\n\n6\n\n10 [3]\n\n5\n\n10 [2]\n\n4\n\n10 [1]\n\n0 200 400 600 800 1000\nTraining Step\n\nFigure 6: Test loss curves when reusing each sequence across 512 members of the population. Dashed lines indicate the\noriginal experiments where each antithetical pair receives a different sequence.\n\n**E.2** **Controlling For Data Across Population Sizes**\n\nTo determine whether the benefits of large population sizes are due to receiving more data or more unique\nperturbations, we run an experiment where smaller population sizes receive the same amount of data per step\nas the default for 32768. For instance, for a population size of 2, this means there is just one antithetical\npair of perturbations but each is evaluated across 16384 data sequences. In principle, this means that each\nperturbation could have a cleaner fitness estimate. We plot results for population sizes of 2, 64, 512, 4096, and\n32768 in Fig. 7.\n\nData Controlled Pure Integer Pretraining: Test Loss\n\n10 [5]\n\n8\n\n10 [4]\n\n7\n\n10 [3]\n\n6\n\n10 [2]\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-36-1.png)\n\n10 [1]\n\n5\n\n10 [0]\n\n4\n\n10 [\u22121]\n\n0 200 400 600 800 1000\nTraining Step\n\nFigure 7: Test losses when different population sizes receive the same amount of data.\n\nWe find that maximizing the number of unique perturbations is critical for pretraining performance. Training\nis incredibly unstable at a population size of 2, which is analogous to zeroth order optimization, implying that\npretraining would have been infeasible with prior zeroth order optimization approaches for LLM training or\nother ES works. In particular, Qiu et al. (2025) manages to get satisfactory speed with na\u00efve ES in reasoning\ntasks by reusing the same perturbation hundreds of times and having a small population size, but Fig. 7\ndemonstrates that this strategy would not work for pretraining from scratch.\n\n37\n\n**F** **EGGROLL Speed**\n\nAll timings were done on a single GPU on a GH200 (equivalent to a single H100) for a linear model with\ndimension 8192 in bfloat16, allowing a maximum batch size of 1024. For the graph in Fig. 2a, we pre-generate\nthe noises instead of integrating the noise generation into the forward pass.\n\n100\n\n80\n\n60\n\n40\n\n20\n\nNormalized Training Speeds\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-37-0.png)\n\n0\nEGGROLL PPO OpenES\n\nFigure 8: Relative speed of EGGROLL, when including jax noise regeneration.\n\nIn Fig. 8, we consider the impact of regenerating noises on-the-fly using jax PRNG. The darker area and value\nin parenthesis for EGGROLL and OpenES indicate the speed when regenerating noises on-the-fly, while the\nfull bar indicates the speed when the noises are already generated.\n\nWe regenerate noises on the fly in our primary jax codebase, but pre-generating the EGGROLL perturbations\nbeforehand is also a practical possibility since low-rank perturbations only require a small amount of memory,\nproportional to the square root of the size of the original parameter matrices.\n\n**G** **Experimental Details**\n\n**G.1** **Reinforcement Learning Experiments**\n\nWe present here the hyperparameter ranges we used for hyperparameter optimization, as well as all hyperparameter settings for all the experiments. All RL experiments were run on an NVIDIA L40S GPU. For PPO,\nwe use the same methodology to tune the hyperparameters as we did for OpenES and EGGROLL as described\nin Section 6.2. We report the ranges and the final hyperparameters here. We train PPO agents using Rejax\n(Liesen et al., 2024).\n\n38\n\n|CartPole-v1|Col2|\n|---|---|\n|||\n||EggRoll<br>OpenES<br>PPO|\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-5.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-9.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-12.png)\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.75\n\n1.50\n\n1.25\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\nPendulum-v1\n\n0 2 4\nSteps 1e8\n\nCraftax Classic\n\n0 2 4\nSteps 1e8\n\nJumanji Snake\n\n0 2 4\nSteps 1e8\n\nNavix DoorKey (8x8)\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n\u22120.25\n\n\u22120.50\n\n\u22120.75\n\nBrax Ant\n\n0 2 4\nSteps 1e8\n\nCraftax Symbolic\n\n0 2 4\nSteps 1e8\n\nKinetix Hard Pinball (l)\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nBrax Inverted Double Pendulum\n\n1.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nJumanji Knapsack\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Over Ball (s)\n\n1.04\n\n1.02\n\n1.00\n\n0.98\n\n0.96\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nNavix Dynamic Obstacles Random (6x6)\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\nBrax Humanoid\n\n0 2 4\nSteps 1e8\n\nJumanji 2048\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Control Left (m)\n\n0 2 4\nSteps 1e8\n\nNavix FourRooms (8x8)\n\n0 2 4\nSteps 1e8\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-6.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-7.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-8.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-10.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-11.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-13.png)\n\nFigure 9: Comparison of reinforcement learning results: Mean returns for each environment and algorithm across 10 random\nseeds. The returns are evaluated using the mean of the parameters. HPO was conducted for each algorithm/environment\npair. The shaded region is the standard error of the mean.\n\n**G.2** **Multi Agent Reinforcement Learning Experiments**\n\nWe train on three cooperative Multi Particle Environments (MPEs) (Lowe et al., 2017) implemented in\nJaxMARL (Rutherford et al., 2023) with feed-forward networks of width 64 and depth 3, performing Bayesian\nhyperparameter optimization for each environment and algorithm. All runs were executed on NVIDIA\nA100-SXM4-40GB GPUs. We find that the optimal batch size is consistent across algorithms on the same\nenvironment. Figure 11 shows that EGGROLL with rank 1 trains up to 2.4 times faster than OpenES for large\nbatch sizes while staying competitive in performance.\n\n39\n\nCartPole-v1\n\n400\n\n300\n\n200\n\n100\n\n0\nEggRoll OpenES\n\nBrax Inverted Double Pendulum\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-1.png)\n\n300\n\n200\n\n100\n\n0\nEggRoll OpenES\n\nCraftax Classic\n\nPendulum-v1\n\nBrax Ant\n\nBrax Humanoid\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-3.png)\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nCraftax Symbolic\n\n30000\n\n10000\n\n7500\n\n5000\n\n2500\n\n0\nEggRoll OpenES\n\nJumanji 2048\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-5.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-6.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-7.png)\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\nJumanji Knapsack\n\n15000\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nJumanji Snake\n\n600\n\n400\n\n200\n\n0\nEggRoll OpenES\n\nKinetix Thrust Control Left (m)\n\n20000\n\n10000\n\n0\nEggRoll OpenES\n\nKinetix Hard Pinball (l)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-8.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-9.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-10.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-11.png)\n\n1500\n\n1000\n\n4000\n\n3000\n\n2000\n\n1000\n\n15000\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nNavix Dynamic Obstacles Random (6x6)\n\n500\n\n0\nEggRoll OpenES\n\nKinetix Thrust Over Ball (s)\n\n4000\n\n40000\n\n20000\n\n0\nEggRoll OpenES\n\nNavix DoorKey (8x8)\n\n0\nEggRoll OpenES\n\nNavix FourRooms (8x8)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-12.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-13.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-14.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-15.png)\n\n1500\n\n1000\n\n500\n\n0\nEggRoll OpenES\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\n400\n\n200\n\n0\nEggRoll OpenES\n\nFigure 10: Comparison of reinforcement learning results: Mean and standard deviation of training time.\n\nTable 1: Hyperparameter Ranges for EGGROLL and OpenES\n\n**Hyperparameter** **Values**\npop_size 512, 1024, 2048, 4096\nn_parallel_evaluations 1, 4, 8\nrank 1, 2, 4\noptimizer adamw, sgd, adam\nlearning_rate 1e-3, 1e-2, 1e-1\nlr_decay 0.995, 0.999, 0.9995, 1.0\nsigma 0.05, 0.2, 0.5\nsigma_decay 0.995, 0.999, 0.9995, 1.0\nrank_transform true, false\ndeterministic_policy true, false\n\n40\n\nTable 2: Hyperparameter Ranges for PPO\n\n**Hyperparameter** **Values**\nclip_eps 0.1, 0.2, 0.3\nent_coef 0, 0.0001, 0.001\ngae_lambda 0.9, 0.95, 0.98\ngamma 0.95, 0.99, 0.995, 0.999\nlearning_rate 0.0001, 0.0003, 0.001\nmax_grad_norm 0.5, 1, 2\nlayer_size 256\nn_layers 3\nnormalize_observations true\nnormalize_rewards false\nnum_envs 64, 128, 256\nnum_epochs 4, 8, 16\nnum_minibatches 16, 32, 64\nnum_steps 64, 128, 256\nreward_normalization_discount 0.99\nskip_initial_evaluation false\nvf_coef 0.5, 0.75, 1\n\nTable 3: CartPole-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.1 0.1\nlr_decay 0.9995 0.9995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 2048 512\noptimizer sgd adamw\nrank 4 /\n\nrank_transform false true\nsigma 0.2 0.5\nsigma_decay 0.999 0.9995\n\n**G.3** **Reasoning Fine-tuning Experiments: Countdown**\n\nTable 4: Pendulum-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.01 0.01\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 4096 4096\noptimizer adam adamw\nrank 4 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 0.995 1\n\nWe ran a Bayesian hyper-parameter sweep (Snoek et al., 2012) for both GRPO and EGGROLL and used\nthe best set found to run the experiments in figure 5a. For GRPO we swept over sampling temperature and\nlearning rate, whereas for EGGROLL we swept over the standard deviation of the ES sampling ( _\u03c3_ ) and the\nlearning rate scale. The best hyper-parameters found are detailed on tables 26 (EGGROLL) and 27 (GRPO).\nAll of the experiments run in 8 hours on a NVIDIA H200 GPU.\n\nWe also run an experiment where we increase the number of GPUs to 8 and use a bigger model, RWKV 7g7B,\non the Countdown task, allowing for stronger final performance. Notably, we compare to the results reported\nby Qiu et al. (2025) on Countdown. Figure 12 shows that starting from our significantly weaker model (RWKV\n7g7B v.s. Qwen 2.5-7B), we are able to train to a higher validation accuracy (72.9%), v.s. the ones reported\nfor training with GRPO (52.8%) and Open ES (66.8%). Qiu et al. (2025) do not report the wall clock time or\nthe hardware used for their experiments which makes it difficult to establish a fair comparison.\n\n41\n\nTable 5: brax/ant\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.1\nlr_decay 0.9995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 8\npop_size 2048 512\noptimizer adam adam\nrank 1 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 0.9995 0.9995\n\nTable 7: brax/inverted_double_pendulum\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true true\nlearning_rate 0.1 0.1\nlr_decay 1 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 1\npop_size 2048 4096\noptimizer adam adam\nrank 2 /\n\nrank_transform true true\nsigma 0.5 0.05\nsigma_decay 0.995 1\n\nTable 9: craftax/Craftax-Symbolic-AutoReset-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.1\nlr_decay 0.999 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 512 1024\noptimizer sgd adam\nrank 4 /\n\nrank_transform true false\nsigma 0.05 0.5\nsigma_decay 0.999 1\n\nTable 6: brax/humanoid\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true false\nlearning_rate 0.1 0.1\nlr_decay 1 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 8\npop_size 4096 1024\noptimizer adam sgd\nrank 1 /\n\nrank_transform true true\nsigma 0.2 0.2\nsigma_decay 0.9995 0.995\n\nTable 8: craftax/Craftax-Classic-Symbolic-AutoReset-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.001\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 8\npop_size 2048 4096\noptimizer sgd adamw\nrank 1 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 1 0.995\n\nTable 10: jumanji/Game2048-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.1 0.01\nlr_decay 1 0.999\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 4\npop_size 1024 1024\noptimizer adamw adamw\nrank 1 /\n\nrank_transform false true\nsigma 0.5 0.05\nsigma_decay 0.9995 0.9995\n\n42\n\nTable 11: jumanji/Knapsack-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.01\nlr_decay 0.999 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 1024 2048\noptimizer sgd adamw\nrank 4 /\n\nrank_transform true true\nsigma 0.05 0.5\nsigma_decay 1 0.995\n\nTable 13: kinetix/l/hard_pinball\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true true\nlearning_rate 0.01 0.01\nlr_decay 0.995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 1\npop_size 2048 512\noptimizer sgd sgd\nrank 4 /\n\nrank_transform true true\nsigma 0.05 0.5\nsigma_decay 0.999 0.9995\n\nTable 15: kinetix/s/h1_thrust_over_ball\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.01\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 1\npop_size 512 2048\noptimizer adamw sgd\nrank 1 /\n\nrank_transform true true\nsigma 0.5 0.05\nsigma_decay 0.9995 1\n\n**G.4** **Reasoning Fine-tuning Experiments: GSM8K**\n\nTable 12: jumanji/Snake-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.001 0.001\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 1\npop_size 4096 2048\noptimizer adam sgd\nrank 1 /\n\nrank_transform true false\nsigma 0.05 0.2\nsigma_decay 0.9995 1\n\nTable 14: kinetix/m/h17_thrustcontrol_left\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.001\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 512 1024\noptimizer sgd adam\nrank 4 /\n\nrank_transform true true\nsigma 0.5 0.5\nsigma_decay 1 0.999\n\nTable 16: navix/Navix-DoorKey-8x8-v0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.01\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 8\npop_size 1024 2048\noptimizer adamw adam\nrank 1 /\n\nrank_transform false true\nsigma 0.05 0.05\nsigma_decay 1 1\n\nWe used the hyper-parameters found for Countdown as a starting point and reduced the learning rates for\nboth GRPO and EGGROLL using linear search until we found the best performing one on the validation set.\n\n43\n\nTable 17: navix/Navix-Dynamic-Obstacles-6x6-Randomv0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.01\nlr_decay 0.999 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 512 4096\noptimizer adam adam\nrank 2 /\n\nrank_transform false false\nsigma 0.05 0.2\nsigma_decay 1 0.995\n\nTable 18: navix/Navix-FourRooms-v0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.001\nlr_decay 0.999 0.9995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 4\npop_size 2048 2048\noptimizer sgd adam\nrank 4 /\n\nrank_transform true false\nsigma 0.05 0.05\nsigma_decay 0.9995 0.9995\n\nTable 19: PPO Hyperparameters (Set 1)\n\nHyperparameter CartPole Pendulum Ant Humanoid IDP CraftaxClassic CraftaxSymbolic Game2048\nactivation pqn pqn pqn pqn pqn pqn pqn pqn\nclip_eps 0.2 0.1 0.2 0.3 0.1 0.2 0.2 0.3\nent_coef 0.0001 0.001 0 0.0001 0.0001 0.0001 0 0.001\ngae_lambda 0.9 0.95 0.95 0.9 0.98 0.98 0.9 0.9\ngamma 0.995 0.999 0.995 0.95 0.99 0.95 0.95 0.99\nlearning_rate 0.0003 0.0003 0.0003 0.0001 0.001 0.001 0.0003 0.0003\nmax_grad_norm 0.5 1 0.5 2 2 2 2 2\nlayer_size 256 256 256 256 256 256 256 256\nn_layers 3 3 3 3 3 3 3 3\nnormalize_obs true true true true true true true true\nnormalize_rew false false false false false false false false\nnum_envs 256 256 64 256 64 128 256 64\nnum_epochs 4 16 8 4 4 4 4 8\nnum_minibatches 32 16 32 64 64 32 32 16\nnum_steps 128 256 128 64 128 128 64 64\nrew_norm_discount 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\nskip_initial_eval false false false false false false false false\nvf_coef 0.5 1 1 0.75 1 0.5 0.75 0.75\n\nOur experiments for GSM8K run on 8 NVIDIA H200 GPUS for 8 hours each. We also increase the standard\ndeviation, _\u03c3_, parameter for ES (from 7 _\u00d7_ 10 _[\u2212]_ [4] to 2 _\u00d7_ 10 _[\u2212]_ [3] ) as the significantly bigger population sizes (8096\nv.s. 512) allow for much more stable training and aggressive exploration.\n\n44\n\nTable 20: PPO Hyperparameters (Set 2)\n\nHyperparameter Knapsack Snake HardPinball ThrustLeft ThrustBall DoorKey DynamicObs FourRooms\nactivation pqn pqn pqn pqn pqn pqn pqn pqn\nclip_eps 0.1 0.3 0.1 0.2 0.2 0.1 0.1 0.1\nent_coef 0.0001 0.001 0.0001 0.0001 0.0001 0.0001 0.001 0.001\ngae_lambda 0.9 0.95 0.9 0.9 0.95 0.98 0.98 0.9\ngamma 0.99 0.999 0.99 0.995 0.999 0.95 0.999 0.99\nlearning_rate 0.0001 0.0001 0.0001 0.0001 0.0001 0.0003 0.001 0.001\nmax_grad_norm 0.5 0.5 1 2 0.5 0.5 1 1\nlayer_size 256 256 256 256 256 256 256 256\nn_layers 3 3 3 3 3 3 3 3\nnormalize_obs true true true true true true true true\nnormalize_rew false false false false false false false false\nnum_envs 256 128 256 256 64 64 128 256\nnum_epochs 4 4 16 16 16 16 4 8\nnum_minibatches 64 16 16 32 16 64 16 32\nnum_steps 128 128 64 128 64 256 128 256\nrew_norm_discount 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\nskip_initial_eval false false false false false false false false\nvf_coef 0.75 0.75 0.5 0.5 0.5 0.75 0.5 0.75\n\nSimple Reference\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-2.png)\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 4096)\n\nSimple Speaker Listener\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 512)\n\n\u221240\n\n\u221250\n\n\u221260\n\n2.0\n\n1.5\n\n1.0\n\n0.5\n\n0.0\n\n\u221240\n\n\u221260\n\n\u221280\n\n15\n\n10\n\n5\n\n0\n\nSimple Spread\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 128)\n\n\u221250\n\n\u2212100\n\n\u2212150\n\n5\n\n4\n\n3\n\n2\n\n1\n\n0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-5.png)\n\nFigure 11: Training curves and wall clock times for cooperative Multi Particle Environments. Hyperparameter optimization\nyielded equal batch sizes for all algorithms on the same environment. All EGGROLL runs used rank 1 perturbations.\nShaded regions are standard errors of mean values.\n\nTable 21: Hyperparameter Ranges Used in MPE Sweeps\nfor EGGROLL and OpenES\n\nHyperparameter Values\nactivation pqn, tanh\npop_size 128, 512, 1024, 2048, 4096\nlearning_rate 0.01, 0.05, 0.1, 0.5\nlr_decay 0.3, 0.7, 1.0\nsigma 0.1, 0.2, 0.3, 0.4, 0.5\nrank_transform true, false\n\nTable 22: Hyperparameter Ranges Used in MPE Sweeps\nfor IPPO\n\nHyperparameter Values\nactivation relu, tanh\npop_size 128, 512, 1024, 2048, 4096\nlearning_rate 5e-5, 1e-4, 2.5e-4, 1e-3\nentropy_coef 0.001, 0.005, 0.01\n\n45\n\nTable 23: MPE Simple Spread v3\n\nHyperparameter eggroll open_es ippo\nactivation tanh tanh tanh\n\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.7 0.7 linear\nlayer_size 64 64 64\nn_layers 3 3 3\npop_size 128 128 128\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform false false sigma 0.5 0.5 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.01\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\nTable 24: MPE Simple Speaker Listener v4\n\nHyperparameter eggroll open_es ippo\nactivation tanh tanh relu\n\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.7 0.3 linear\nlayer_size 64 64 64\nn_layers 3 3 64\npop_size 512 512 512\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform true true sigma 0.5 0.5 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.005\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\nTable 25: MPE Simple Reference v3\n\nHyperparameter eggroll open_es ippo\nactivation pqn tanh relu\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.3 0.3 linear\nlayer_size 64 64 64\nn_layers 3 3 3\npop_size 4096 4096 4096\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform false true sigma 0.1 0.3 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.01\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\n46\n\nHyperparameter Value\n\nModel RWKV 7g1.5B\nOptimizer Gradient descent\nES standard deviation _\u03c3_ 7 _\u00d7_ 10 _[\u2212]_ [4]\n\nRank _r_ 1\n\nLearning-rate scale _\u03b7_ scale 0.125\nPopulation size 256\nParallel generations per GPU 1536\nPrompts per epoch 6\nGeneration / thinking length 1000 tokens\nTrain / val temperature 0 / 0\nParallel validations 128\n\nTable 26: Key hyperparameters for EGGROLL training on Countdown with FastRWKV-7g1.5B.\n\nHyperparameter Value\n\nModel RWKV 7g1.5B\nOptimizer Radam\nLearning rate _\u03b7_ 3 _\u00d7_ 10 _[\u2212]_ [6]\n\nGenerations per prompt _G_ 8\nParallel generations per GPU 64\nPrompts per epoch 8\nGeneration length 1000 tokens\nNumber of minibatches 4\n\nPPO clip parameter _\u03f5_ clip 0.2\nTrain / val temperature 1 / 0\nParallel validations 128\n\nTable 27: Key hyperparameters for GRPO training on Countdown with AssociativeScanRWKV-7g1.5B.\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-46-0.png)\n\n0.2\n\n0 100 200 300 400 500\n\nEpoch\n\nEGGROLL: RWKV-g0:7g7B\n\nFigure 12: Validation score training curve of an RWKV 7g7B model on countdown using 8 GPUS and a population size of\n8096. Notably, we are able to outperform a stronger base model trained with GRPO and OpenES.\n\n47\n\nHyperparameter Value\n\nModel RWKV 7g7B\nES standard deviation _\u03c3_ 2 _\u00d7_ 10 _[\u2212]_ [3]\n\nRank _r_ 1\n\nLearning-rate scale _\u03b7_ scale 0.06\nGenerations per prompt _G_ 512\nParallel generations per GPU 1024\nTotal parallel generations 8192\nPrompts per epoch 16\nGeneration length 1000 tokens\nNoise reuse factor 1\n\nFreeze non-LoRA params True\nTrain / val temperature 0 / 0\nParallel validations 128\n\nTable 28: Key hyperparameters for multi-GPU EGGROLL training on GSM8K with FastRWKV-7g7B.\n\nHyperparameter Value\n\nModel RWKV 7g7B\nLearning rate _\u03b7_ 1 _\u00d7_ 10 _[\u2212]_ [6]\n\nGenerations per prompt _G_ 8\nParallel generations per GPU 32\nTotal parallel generations 256\nPrompts per epoch 32\nGeneration length 1000 tokens\nNumber of minibatches 16\n\nNumber of workers (processes) 8\nPPO clip parameter _\u03f5_ clip 0.2\nTrain / val temperature 1 / 0\nParallel validations 128\n\nTable 29: Key hyperparameters for multi-GPU GRPO training on GSM8K with AssociativeScanRWKV-7g7B.\n\n48"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism for integer-only operations involves replacing floating-point arithmetic with fixed-point integer arithmetic, managed through scaled matrix multiplications, mean absolute value-based layer normalization, and lookup tables for non-linear activations (like EXP2 and LOG2). The evolutionary strategy (EGGROLL) then searches this integer parameter space efficiently.\n\n**Explanation:** The challenge is that computers usually do math with 'floating-point' numbers (like 3.14), which are very precise but can be slow and use lots of power. This paper introduces the 'EGG' architecture and 'EGGROLL' training to work exclusively with 'integer' numbers (like 3 or 14). Think of it like this: all numbers are stored as `int8` (a small integer range). When you multiply two `int8` numbers, the result can be a larger integer (`int32`), but then it's immediately scaled and clipped back down to `int8`. This `int32` accumulation and then `int8` clipping is inherently non-linear, acting like a 'hard' activation function. For more complex non-linearities (like exponentiation or logarithms), they pre-calculate all possible results and store them in 'lookup tables' (like a hash map), so the model just 'looks up' the answer instead of calculating it every time. Layer normalization, which usually involves square roots, is simplified to dividing by the 'mean absolute value' of the vector, which is also integer-friendly. For training, EGGROLL works by perturbing these integer parameters with small, rank-1 integer 'wiggles' (`A` and `B` vectors), evaluates the model's performance, and then updates the parameters by simply shifting them up or down by one integer 'bin' based on whether the wiggle improved performance. The mathematical proofs (Edgeworth expansion) show that even with these discrete, integer-only wiggles, the method still converges to optimal solutions efficiently, sometimes faster than standard methods due to the symmetry of the underlying distributions making some error terms zero. The advantage is specialized hardware (like GPU Tensor Cores) can do these integer multiplications extremely fast."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc56\ud835\udc60_ _ _\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e_ **and** ( _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc61_ _>_ 0 **or**\n_\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ \u2265 _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ )) ;"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a multi-faceted congestion detection trigger, operating like a robust 'if' statement in code. It first ensures that any current measurement or transmission window (represented by 'is_full_length') is complete, preventing false positives from partial data. Then, it checks for *either* explicit packet loss ('packets_lost > 0'), which is an undeniable sign of network oversubscription, *or* if the amount of data already sent but not yet acknowledged ('prior_inflight') has exceeded a dynamically calculated upper bound. This upper bound, 'BBR_Inflight(BBR.pacing_gain)', acts like a flexible 'threshold' variable that adjusts based on how aggressively the system is trying to fill the pipe (its 'pacing_gain').\n\n**Explanation:** This condition essentially implements a decision-making gate, similar to how a 'switch' statement or a series of 'if-else if' blocks might control program flow. It's designed to detect when a network connection is either explicitly overloaded or operating at its perceived maximum capacity. The 'is_full_length' flag is a prerequisite, much like ensuring a data buffer is completely filled before processing it. Without it, any subsequent checks would be on incomplete data, leading to inaccurate conclusions. If this fundamental condition is met, the system then checks for two critical indicators of network stress. The first, 'packets_lost > 0', is a straightforward boolean check: if any data disappeared, it's a clear signal to react. The second, 'prior_inflight >= BBR_Inflight(BBR.pacing_gain)', is more subtle. It compares the number of unacknowledged bytes currently in transit ('prior_inflight') against a calculated ceiling. This ceiling, 'BBR_Inflight', isn't static; it's like a dynamically adjustable 'max_queue_size' variable, scaled by 'BBR.pacing_gain' (a multiplier indicating current aggressiveness). If the actual 'prior_inflight' hits or exceeds this flexible ceiling, even without explicit loss, it suggests the network path is full, or we are probing its absolute limit. This dual check allows the system to react not just to explicit errors but also to signs of imminent saturation, much like a traffic controller anticipating congestion before a full standstill."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**2.1** **Mixture-of-Experts (MoE) Architecture**\n\nMixture-of-Experts (MoE) architectures scale model capacity by\nactivating only a small subset of expert subnetworks for each input token. This sparse-computation paradigm enables models to\nreach hundreds of billions or even trillions of parameters without\nincurring proportional compute costs. Formally, the output of an\nMoE layer is:\n\n_\ud835\udc38_ _[\ud835\udc5f]_ _\ud835\udc57_ [(] _[\ud835\udc65]_ [)] _[\ud835\udc54][\ud835\udc57]_ [(] _[\ud835\udc65]_ [)] _[,]_ (1)\n_\ud835\udc57_ \u2208K\n\nThis requirement dominates the HBM footprint, as inactive experts\nconsume memory without contributing computation. Low-bit posttraining quantization (PTQ) appears attractive for reducing this\noverhead, but current MoE PTQ methods apply a _static_ bit-width\nto all experts. Such rigidity prevents the precision allocation from\nreflecting runtime activation behavior: heavily used experts may\nexperience accuracy degradation under aggressive compression,\nwhereas rarely used experts still occupy high-precision storage.\nRecent MoE-serving systems mitigate memory pressure through\nexpert offloading and caching, but they similarly assume that expert\nprecision is fixed. As a result, expert placement and scheduling\ndecisions remain decoupled from precision choices, limiting their\nability to exploit activation sparsity and to adapt when workload\ndistributions shift. This mismatch reveals a fundamental gap: MoE\ninference requires a mechanism that manages expert precision as\na _runtime resource_, ensuring accuracy for hot-path experts while\nrespecting strict memory budgets.\nA practical solution must therefore:\n\n - _(1) adapt precision according to sustained activation trends_ .\n\n - _(2) maintain strict memory safety during precision changes_ .\n\n - _(3) carry out all transitions without interfering with the forward_\n\n_pass_ .\n\nThese constraints motivate the design of DynaExq.\n\n**2.3** **Challenges**\n\nEnabling online precision adjustment for MoE experts on resourceconstrained GPUs raises several system-level challenges:\n\n - (1) **Workload-aware precision scheduling** : The system must\ntrack expert usage continuously and adjust precision decisions\nwithout relying on offline calibration or fixed activation assump\ntions.\n\n_\ud835\udc66_ =\n\n_\ud835\udc5a_\n\u2211\ufe01\n\n\u2211\ufe01 _\ud835\udc38\ud835\udc56_ _[\ud835\udc60]_ [(] _[\ud835\udc65]_ [)] _[\ud835\udc54][\ud835\udc56]_ [(] _[\ud835\udc65]_ [) +] \u2211\ufe01\n\n_\ud835\udc56_ =1 \u2208K\n\nwhere K = topk({ _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65_ )} _[\ud835\udc5a]_ _\ud835\udc56_ =1 [)][ denotes the set of top-] _[\ud835\udc58]_ [routed experts]\nselected by the gating network. _\ud835\udc38\ud835\udc56_ _[\ud835\udc60]_ [(] _[\ud835\udc65]_ [)][ and] _[ \ud835\udc38][\ud835\udc5f]_ _\ud835\udc57_ [(] _[\ud835\udc65]_ [)][ represent shared]\nand routed expert functions, respectively, and _\ud835\udc54\ud835\udc56_ ( _\ud835\udc65_ ) is the routing\nprobability.\nAlthough this design offers substantial representational flexibility, it introduces inherent system challenges. Expert activations are\nhighly skewed and shift with input distribution, creating heavytailed utilization patterns across layers.\n\n**2.2** **Motivations**\n\nWhile only a few experts are activated per token, all experts must\nremain resident in GPU memory to allow unrestricted routing.\n\nDynamic Expert Quantization for Scalable Mixture-of-Experts Inference\n\n - (2) **Non-blocking precision transitions** : Upgrades and downgrades must proceed asynchronously and in parallel with inference to prevent stalls or latency spikes.\n\n - (3) **Fragmentation and bandwidth management** : Precision\nchanges alter expert memory size, requiring structured memory\nmanagement and efficient data movement to prevent fragmentation and bandwidth contention.\n\n - (4) **Resource-adaptive thresholding** : Promotion and demotion policies must align with available HBM capacity while\nremaining robust to short-term activation fluctuations.\n\nThese challenges shape the design of DynaExq, whose architecture\nand runtime mechanisms are presented in the next section."}, {"role": "assistant", "content": "**Mechanism:** The core problem is managing GPU High Bandwidth Memory (HBM) for Mixture-of-Experts (MoE) models. While MoEs are computationally sparse (only a subset of 'experts' are active per input), *all* experts must be resident in HBM for unrestricted routing. Current quantization applies a static bit-width, which is like declaring all variables as `float32` regardless of their usage or required precision. The mechanism proposed is dynamic precision allocation: monitoring expert activation frequency (like hit counts in a cache) and adjusting their data type (e.g., `float32` to `int8`) at runtime. Frequently accessed 'hot' experts retain high precision, while rarely used 'cold' experts are aggressively compressed. This requires a memory manager that can resize and relocate memory blocks associated with expert weights asynchronously, similar to a garbage collector or a dynamic array resizing operation, but without pausing the ongoing computation.\n\n**Explanation:** MoE architectures gain scale by having a large collection of specialized sub-networks, called experts. A 'gating network' acts like a sophisticated `if/else` or `switch` statement, directing each piece of input data to only a few of these experts. The trick, however, is that even though only a few experts are 'active' at any moment, the entire collection of experts' data (their 'weights') must be loaded into the GPU's fast memory (HBM) so they can be instantly available if the gating network decides to route to them. This creates a huge memory bottleneck. The current solution of simply making all experts smaller (quantization) is rigid; it's like deciding all numbers in your program will be `short integers` even if some need `long doubles` for accuracy. This paper's insight is that expert usage is highly skewed and changes over time. Therefore, their memory footprint should also be dynamic. The system needs to continuously track which experts are frequently used (like a `HashMap` tracking access counts). 'Hot' experts maintain their high-precision (e.g., `float32`), while 'cold' experts are compressed to lower precision (e.g., `int8`), freeing up memory. This is a form of adaptive memory management, where data types are managed as a runtime resource. It's complex because these precision changes (which effectively change the size of memory blocks) must happen without interrupting the ongoing forward pass of the neural network, preventing system stalls, and efficiently managing memory fragmentation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section is dedicated to the overall evaluation of the packet scheduling and congestion control algorithms. We\n\nfirst present a subset of figures, illustrating how the MPTCP packet scheduling algorithms performed across different\n\ncongestion control algorithm (CCA) combinations, under some representative scenarios which resemble real-world\n\nnetwork conditions. Then, we define two new metrics to assess the performance of the packet scheduling and the\n\ncongestion control algorithms, that is, the _PS_score_ and the _CCA_score_, respectively. The _PS_score_ metric is based on\n\nthe normalized goodput in order to assess the performance level of each packet scheduling algorithm within each\n\nscenario family. The _CCA_score_ metric, which is based on the normalized _PS_score_, is used to assess the performance\n\nof the congestion control algorithms across all sccenario families. This metric provides the means to quantify the\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 27\n\nperformance of each CCA through the normalized score that the underlying packet scheduling algorithms achieved\n\nusing the respective CCA. The _CCA_score_ indicates, in essence, how much \"space\" each CCA provides to the underlying\n\npacket scheduling algorithms to unveil their sophisticated scheduling logic. If a congestion control algorithm suppresses\n\nthe congestion window of a subflow, then the packet scheduling algorithm cannot perform any better than applying\n\nits logic on the resources that the CCA makes available to the scheduler; this means that a bad congestion control\n\nalgorithmic logic is anticipated to incur a poor performance outcome, regardless of the packet scheduling algorithm\u2019s\n\nintrinsic properties.\n\nOnce we identify the \"best\" three congestion control algorithms, we proceed with a fine-grained assessment of the\n\nvarious packet scheduling algorithms when combined with each of the highest-score CCAs. The _normalized goodput_ and\n\nthe _per-packet delay_ are the main metrics against which all packet scheduling algorithms are evaluated. The Matplotlib\n\npython library has been used for the visualization of the results [45].\n\nNoteworthy here is that we have deliberately decided to maintain different axes\u2019 scale when plotting the values\n\nof some parameters across the various CCAs, such as the SRTT, the MPTCP OFO queue size, and the number of\n\nretransmissions. This allows to increase the granularity and, consequently, the visibility of the results, preventing subtle\n\nvariations from being shadowed by any neighboring CCA\u2019s more coarse results within the same figure.\n\n**4.1** **Cross-CCA packet scheduling overview**\n\nFrom the 1,015 unique tests executed (5,075 tests / 5 iterations per test), we have selected to present in this work a\n\nsubset of the most representative scenarios. To this end, we hereby present:\n\ni. a scenario involving homogeneous paths,\n\nii. a scenario involving paths experiencing intense heterogeneity, and\n\niii. a scenario involving path conditions of mixed heterogeneity.\n\n_Homogeneous scenario._ Figure 5 presents the results of a scenario derived from the _homogeneous_ scenario family,\n\nwhere both subflows traverse paths which experience common networking characteristics. When an equal delay of\n\n5ms is present on both paths, minRTT, ECF, and RR outperform LLHD and BLEST under LIA CC, and its variations\n\nOLIA and BALIA. All schedulers follow the same performance pattern across these three CCs. It is evident that even\n\nwhen the CCA (i.e., LIA/OLIA/BALIA) leaves the congestion window of both subflows open, BLEST, which bases its\n\ndecisions on send window blocking estimations, selects to equally limit the use of both subflows, underutilizing the\n\navailable bandwidth of both paths, and eventually underperforming. wVegas, which is a delay-based CC, is highly\n\nsensitive to delay, interpreting it to congestion and capping aggressively the congestion window of both subflows; the\n\naggregate goodput achieved by all schedulers is limited compared to the one achieved under the use of other CCAs. On\n\nthe contrary, the use of Cubic, which is a loss-based uncoupled CCA, provides a clear benefit to all schedulers. BLEST\u2019s\n\nperformance improvements can be credited to the uncoupled nature of Cubic, that is, there is no upper bound for the\n\naggregate congestion window of the two subflows, as is the case for coupled CCAs. Thus, each of the subflows maintains\n\nits individual congestion window which is treated by the employed CCA as if it were for a singe path flow belonging to\n\na normal TCP connection. This makes MPTCP unfair to single path TCP flows, since each MPTCP subflow can allocate\n\na portion of BW equal to that of a single path TCP flow, ultimately leading single path TCP flows to starvation when\n\nsingle path TCP and MPTCP subflows coexist in the same bottleneck link. In this sub-scenario, BBR allows all schedulers\n\nto reach high and stable performance; it is also noticeable that BBR\u2019s accurate estimations of the bottleneck bandwidth\n\nand RTT lead to scheduling decisions which incur the lowest SRTT and very low OFO queue occupancy across all the\n\n28 D. Dimopoulos, et al.\n\nemployed CCAs. C-MPBBR, which is a coupled variant of BBR for MPTCP (ensuring that MPTCP has a clear benefit over\n\nand is fair to SP-TCP), incurs a lower goodput aggregation to all schedulers\u2019 performance, when compared to uncoupled\n\nBBR. The fairness C-MPBBR achieves across the two MPTCP subflows traversing the same bottleneck link, can be\n\nclearly seen in the measured SRTT of the subflows for each scheduler; however, its coupled nature and fairness benefits\n\ncome at the cost of a more restricted aggregate congestion window which limits the performance of all schedulers over\n\nthe two subflows. The overall _\ud835\udc52_ 1_ _\u210e\ud835\udc5c\ud835\udc5a_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66_ scenario\u2019s verdict can be summarized as follows:\n\n   - minRTT, ECF, and RR exhibit high performance under LIA/OLIA/BALIA CCAs\n\n   - BLEST is sensitive to delay and underperforms the rest when any one of the LIA/OLIA/BALIA is the employed\n\nCCA\n\n   - wVegas is a delay-based CCA and reacts more aggressively to delay, restricting the available congestion window,\n\nand leading all schedulers to low goodput aggregation over the two paths\n\n   - all schedulers perform comparably well under Cubic\n\n   - all schedulers perform comparably well and stably under BBR\n\n   - C-MPBBR bounds the coupled congestion window in favor of fairness and MPTCP\u2019s benefit over SPTCP; this has\n\na considerable impact on the performance of all schedulers when compared to that achieved with C-MPBBR\u2019s\n\nrivals (i.e., uncoupled BBR and Cubic)\n\nFig. 5. Homogeneous scenario - BW/RTT/PLR - _\ud835\udc46\ud835\udc39_ 1 : 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /5 _\ud835\udc5a\ud835\udc60_ /0% _, \ud835\udc46\ud835\udc39_ 2 : 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /5 _\ud835\udc5a\ud835\udc60_ /0%\n\n_Intense_heterogeneity scenario._ Figure 6 presents the results of a scenario derived from the _intense_heterogeneity_\n\nscenario family, where the two subflows traverse paths with intense-heterogeneity networking characteristics. The\n\nadditional presence of delay on a path (i.e., SF2) on top of intense bandwidth restrictions and packet loss, has a\n\ndetrimental effect on the goodput of all schedulers, when combined with any one of the traditional loss- and delay-based\n\nCCAs. All schedulers fail to efficiently utilize the available bandwidth of the affected path (SF2) when combined with\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-27-0.png)\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 29\n\nany one of the LIA/OLIA/BALIA/wVegas/Cubic; this result is mainly credited to the effects of the congestion control\n\napproaches that the aforementioned CCAs follow; that is, increasing the congestion window during the CA (congestion\n\navoidance) phase, which in turn allows intermediate buffers to be filled up, and then trying to tackle the congestion\n\nthey created by drastically decreasing the congestion window, which deteriorates the already adverse conditions even\n\nfurther. Under such circumstances, schedulers cannot perform any better than trying to efficiently utilize the resources\n\nthat the CCA makes available; CCA has a great impact (either positive or negative) on the final performance. The\n\ncraftsmanship in the design of BBR and C-MPBBR, lies in the way they estimate the bottleneck bandwidth and the\n\nround-trip propagation time, thus pacing traffic (via the cwnd) at the highest possible rate which, however, does not lead\n\nto buffer formation; when buffers start being occupied, BBR can detect the RTT increase and adjust the rate efficiently\n\nuntil the queue is drained and a lower RTT is measured. This different logic allows BBR to sustain traffic rate close\n\nto Kleinrock\u2019s optimal operating point, avoiding the post-congestion control operation of traditional CCAs (AIMD).\n\nBBR and C-MPBBR are rather adjusting traffic smoothly by avoiding high queue occupancies and the subsequently\n\nincreased congestion; this allows all schedulers to unleash their full potential and apply their scheduling logic towards\n\nhigh goodput rates. In this sub-scenario, minRTT, ECF, RR, and LLHD perform comparably well, achieving close to\n\noptimal goodput; BLEST is not limited by the CCA decisions, but rather applies its algorithmic logic, which is based on\n\nlimiting or eliminating the use of a slow path if this is anticipated to cause HoL and, consequently, MPTCP send window\n\nblocking (due to inflight data carried over the slower path). According to this logic, BLEST selects not to use the affected\n\npath (SF2), underutilizing its available bandwidth and thus exhibiting the lowest performance among schedulers. The\n\noverall _\ud835\udc52_ 7_ _\ud835\udc56\ud835\udc5b\ud835\udc61_ _ _\u210e\ud835\udc52\ud835\udc61_ _ _\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66_ scenario\u2019s verdict can be summarized as follows:\n\n   - the decisions of traditional delay- and loss-based CCAs (i.e., LIA/OLIA/BALIA/wVegas/Cubic) have a severe\n\nimpact on any scheduler\u2019s performance; when these CCAs have to deal with intense delay in conjunction with\n\ncapped bandwidth and packet loss, their decisions have a disastrous effect on the final goodput, irrespective of\n\nthe employed scheduler\n\n   - BBR (and its MPTCP coupled variant C-MPBBR) are designed in a way that does not aggressively suppress the\n\ncongestion window of an already adversely impacted flow, thus allowing schedulers to achieve and sustain\n\nhigh goodput\n\n   - BLEST avoids the use of the slow path, either because the congestion window of the respective subflow is\n\nsuppressed by a traditional CCA (i.e., LIA/OLIA/BALIA/wVegas/Cubic), or because of its own algorithmic logic\n\nto avoid slow paths in case this is expected to cause send window blocking\n\n   - RR experiences the highest number of retransmissions among schedulers\n\n_Mixed_heterogeneity scenario._ Figure 7 presents the results of a scenario derived from the _mixed_heterogeneity_\n\nscenario family, where the two subflows traverse paths experiencing mixed-heterogeneity networking conditions [13] . In\n\nthis particular mixed delay- and loss-induced heterogeneity sub-scenario, there is a clear distinction between schedulers\u2019\n\nachieved goodput across CCAs, illustrating the effect that the various CCAs may have in scheduling. The highest\n\nscheduling performance is achieved when schedulers are combined with BBR; in that case, all schedulers (except for\n\nRR) achieve comparably high goodput over both subflows. Equally high goodput rates (to those observed with BBR) are\n\nreached by schedulers in case of uncoupled loss-based CCA Cubic; RR however is severely degraded. The next higher\n\n13Mixed heterogeneity scenarios emulate complex networking conditions where each of the paths is superior to the other when considering only a single\nfactor; be it the allocated bandwidth, or the experienced RTT, or the packet loss rate. In such cases, however, it is sometimes not evident beforehand\nwhich path is eventually going to render an overall better performance.\n\n30 D. Dimopoulos, et al.\n\nFig. 6. Intense heterogeneity scenario - BW/RTT/PLR - _\ud835\udc46\ud835\udc39_ 1 : 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /0 _\ud835\udc5a\ud835\udc60_ /0% _, \ud835\udc46\ud835\udc39_ 2 : 50 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /20 _\ud835\udc5a\ud835\udc60_ /0 _._ 5%\n\ngoodput rates are achieved when schedulers are combined with C-MPBBR; all (except RR) are performing comparably\n\nhigh, but they experience some goodput restriction over the higher-delay path (SF1), as compared to that achieved\n\nwith BBR. This can be credited to the restrictions that C-MPBBR\u2019s coupled nature imposes on the subflows that are\n\nconsidered to be traversing the same bottleneck path. With the couped loss-based OLIA, the goodput achieved over SF2\n\nis slightly restricted (compared to the one achieved with BBR / C-MPBBR / Cubic), since the coupled nature of OLIA in\n\nconjunction with its more aggressive reaction to the packet loss detected over SF2, lead to further cwnd restrictions. The\n\nsame goodput pattern among schedulers, with a higher goodput restriction over SF2, is also visible with BALIA, while\n\nwith LIA, SF2\u2019s goodput is limited even further. Finally, wVegas has a detrimental effect on schedulers\u2019 performance; all\n\nschedulers underperform over both subflows, being able to eventually reach an aggregate goodput which is less than a\n\nhalf of the one achieved with BBR. The overall _\ud835\udc52_ 5_ _\ud835\udc5a\ud835\udc56\ud835\udc65_ _ _\u210e\ud835\udc52\ud835\udc61_ _ _\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66_ scenario\u2019s verdict can be summarized as follows:\n\n   - minRTT, BLEST, ECF, and LLHD perform comparably to one another, within each CCA combination\n\n   - BBR, C-MPBBR, and Cubic provide ideal conditions to the underlying schedulers, allowing them to achieve\n\nvery high goodput rates\n\n   - OLIA is the third best (in terms of schedulers\u2019 performance) CCA, allowing all schedulers to reach high goodput\n\nrates; goodput over the lossy path (SF2) is restricted more due to the loss-based nature of OLIA which caps the\n\ncwnd to tackle congestion, not being able to distinguish random loss from actual link congestion\n\n   - BALIA and LIA limit the SF2 cwnd further, leading all schedulers to moderate performance\n\n   - wVegas has a detrimental effect upon all schedulers\u2019 performance, due to its delay-based congestion inference\n\n   - RR experiences the highest number of retransmissions and underperforms, regardless of CCA selection\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-29-0.png)\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 31\n\nFig. 7. Mixed heterogeneity scenario - BW/RTT/PLR - _\ud835\udc46\ud835\udc39_ 1 : 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /10 _\ud835\udc5a\ud835\udc60_ /0% _, \ud835\udc46\ud835\udc39_ 2 : 100 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ /2 _\ud835\udc5a\ud835\udc60_ /0 _._ 5%\n\n**4.2** **PS and CCA score metrics**\n\nAs mentioned earlier, to evaluate the performance of the various packet scheduling and congestion control algorithms,\n\nwe have introduced two new metrics; the _PS_score_ and the _CCA_score_, respectively.\n\n_PS_score._ For each scheduler, we first calculate the _average goodput_ it achieved in each sub-scenario of each broader\n\nscenario family, over the five identical execution runs. Then, we calculate a _PS_score_ for each packet scheduler per\n\nscenario family; the _PS_score_ is actually the _normalized aggregate goodput_ for each scheduler in each scenario family,\n\nand is given by the formula:\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-30-0.png)\n\n(20)\n\ufffd\n\n_\ud835\udc43\ud835\udc46_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ =\n\u2211\ufe01\n\n# _\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b_\n\n_\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b_ _ _\ud835\udc4e\ud835\udc63\ud835\udc54_ _ _\ud835\udc3a\ud835\udc43_\n\ufffd # _\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_ \u2217 _\ud835\udc61\u210e\ud835\udc52\ud835\udc5c\ud835\udc5f\ud835\udc52\ud835\udc61\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _ _\ud835\udc54\ud835\udc5d_\n\nwhere _#subscen_ denotes the number of sub-scenarios included in each respective scenario family, _subscen_avg_GP_ is\n\nthe average goodput achieved over the five identical iterations of each respective sub-scenario, _#subscen_in_ScenFam_\n\ndenotes the number of sub-scenarios included within a broader scenario family, and the _theoretical_max_gp_ denotes the\n\ntheoretical maximum aggregate goodput over the two subflows that is, 200 _\ud835\udc40\ud835\udc4f\ud835\udc5d\ud835\udc60_ . This way, _\ud835\udc43\ud835\udc46_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ \u2208[0 _,_ 1) .\n\n_CCA_score._ A similar approach has been followed in order to define a metric which would allow us to assess the\n\nperformance of the congestion control algorithms. We first present how each congestion control algorithm performed\n\nwithin each broader scenario family. This kind of assessment is essentially showcasing how the packet scheduling\n\nalgorithms performed under each respective congestion control algorithm within each broader scenario family. Thus,\n\neach CCA\u2019s _CCA_score_per_ScenFam_ is computed based on the average _PS_score_ of the packet scheduling algorithms\n\n32 D. Dimopoulos, et al.\n\nwhen combined with the respective CCA. The _CCA_score_per_ScenFam_ is provided by the following formula:\n\n(21)\n\ufffd\n\n_\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ _ _\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_ = \u2211\ufe01\n\n# _\ud835\udc60\ud835\udc50\u210e\ud835\udc52\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc52\ud835\udc5f\ud835\udc60_\n\n_\ud835\udc43\ud835\udc46_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_\n\ufffd # _\ud835\udc60\ud835\udc50\u210e\ud835\udc52\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc52\ud835\udc5f\ud835\udc60_\n\nwhere _#schedulers_ denotes the number of all packet scheduling algorithms, and _PS_score_ is the respective score each\n\npacket scheduling algorithm received for this scenario family. For this metric, it also applies that _\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ _ _\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_ \u2208\n\n[0 _,_ 1).\n\n**4.3** **Congestion control assessment**\n\nThe _\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ _ _\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_ reached by each congestion control algorithm in each scenario family, is depicted in\n\nFigure 8.\n\nFig. 8. CCA score per scenario family\n\nOnce an overview had been obtained on how each congestion control algorithm performed within each scenario\n\nfamily, it was interesting to identify the three best-performing CCAs across all scenario families. To this end, we defined\n\nthe _CCA_score_ which is essentially an average over the scores each congestion control algorithm has been assigned for\n\nits performance within each scenario family. _CCA_score_ is consequently a _cross-scenario-family_ score indication, given\n\nby the formula:\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-31-0.png)\n\n(22)\n\ufffd\n\n_\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ =\n\u2211\ufe01\n\n# _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_\n\n_\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ _ _\ud835\udc5d\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_\n\ufffd # _\ud835\udc46\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc39\ud835\udc4e\ud835\udc5a_\n\nwhere _#ScenFam_ is the number of the different scenario families.\n\nThe drawback, however, of the above-mentioned metric is the fact that it does not consider how poorly each\n\ncongestion control algorithm performed in its worst-case scenario family. Thus, to allow also for performance stability\n\nacross the various scenario families, we combined the _CCA_score_ with its respective _coefficient of variation (CV)_, which\n\nprovides insight on the extent of variability in relation to the mean. Figure 9 illustrates the coefficient of variation for\n\neach individual _CCA_score_ .\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 33\n\nThe lower the coefficient of variation, the higher the performance stability of each CCA across the various sub\n\nscenarios. Dividing each CCA\u2019s _CCA_score_ by its respective coefficient-of-variation value, we derive an _overall score_ for\n\neach congestion control algorithm, which allowed us to identify the best three in terms of goodput and performance\n\nstability across scenario families. The _CCA_overall_score_ is then given by the below formula:\n\n_\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_ = _[\ud835\udc36\ud835\udc36\ud835\udc34]_ [_] _[\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52]_ (23)\n\n_\ud835\udc36\ud835\udc36\ud835\udc34_ _ _\ud835\udc36\ud835\udc49_\n\nFigure 10 illustrates each congestion control algorithm\u2019s _CCA_overall_score_ . This way, we have been then able to\n\nidentify the three best-performing congestion control algorithms: **C-MPBBR**, **BBR**, and **OLIA** .\n\nFig. 9. CCA_score CV Fig. 10. CCA_overall_score\n\n**4.4** **Packet scheduling assessment - Goodput**\n\nHaving identified the three best-performing CCAs, we have then been able to delve into the packet scheduling algorithms\u2019\n\nperformance evaluation. The _PS_score_ metric is indicative on how each scheduler performed within each scenario family,\n\nunder each of the best three congestion control algorithms. Figure 11 illustrates each packet scheduling algorithm\u2019s\n\nperformance score per CCA, and per scenario family.\n\nA more granular _PS_score_ analysis per scenario family is provided for each one of the BBR, C-MPBBR, and OLIA\n\nCCAs, within Figures 12, 13, and 14, respectively.\n\nAn alternative view of each packet scheduling algorithm\u2019s score per scenario family for each of the top three CCAs,\n\nis provided via the _PS_score_ heatmaps showcased within Figures 15, 16, and 17, respectively.\n\nOne of the main purposes of this work, has been to provide a clear view on how each packet scheduler performs across\n\nall scenario families for each of the best-performing CCA. To this end, Figure 18 illustrates the _Empirical Complementary_\n\n_Cumulative Distribution Function (ECCDF)_, which depicts each scheduler\u2019s probability to perform above a specific level\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-32-0.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-32-1.png)\n34 D. Dimopoulos, et al.\n\nFig. 11. PS_score\n\nFig. 12. PS_score per scenario family for BBR\n\nof goodput, for each of the top-three CCAs (i.e., BBR, C-MPBBR, and OLIA); ECCDF considers goodput probability\n\nacross all scenario families and sub-scenarios.\n\n**4.5** **Packet scheduling assessment - Per-Packet Delay**\n\nBesides the evaluation in terms of goodput, we found it also useful to provide insight on how each packet scheduling\n\nalgorithm would perform in case of interactive applications. A key metric for this type of applications is the experienced\n\n_per-packet delay (PPD)_ . For this purpose, we provide a high-level view of each packet scheduling algorithm\u2019s [14] perfor\n\nmance in terms of per-packet delay in Figure 19; a more fine-grained numerical evaluation of each packet scheduling\n\nalgorithms per-packet delay for each of the best-three congestion control algorithms (i.e., BBR, C-MPBBR, and OLIA)\n\ncan be found in Figures 20, 21, and 22, respectively.\n\n14\"Packet Scheduling Algorithm\" is abbreviated as _PSA_ within figure captions.\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-33-0.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-33-1.png)\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 35\n\nFig. 13. PS_score per scenario family for C-MPBBR\n\nFig. 14. PS_score per scenario family for OLIA\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-34-0.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-34-1.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-34-2.png)\n\nFig. 15. PS_score heatmap per scenario\nfamily for BBR\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-34-3.png)\n\nFig. 16. PS_score heatmap per scenario\nfamily for C-MPBBR\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-34-4.png)\n\nFig. 17. PS_score heatmap per scenario\nfamily for OLIA\n\nFinally, Figure 23 depicts the _Empirical Cumulative Distribution function (ECDF)_, which provides a metric of scheduler\u2019s\n\nprobability to achieve below a specific level of average per-packet delay, for each one of the top-three CCAs (i.e., BBR,\n\nC-MPBBR, and OLIA); ECDF considers the _average per-packet delay_ across all scenario families and sub-scenarios.\n\n36 D. Dimopoulos, et al.\n\nFig. 18. ECCDF depicting packet scheduler goodput probability across scenario families, for BBR, C-MPBBR, and OLIA\n\nFig. 19. Qualitative view of each PSA\u2019s PPD per scenario family for BBR, C-MPBBR, and OLIA\n\nFig. 20. PPD of each PSA per scenario family for BBR\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-35-0.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-35-1.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-35-2.png)\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 37\n\nFig. 21. PPD of each PSA per scenario family for C-MPBBR\n\nFig. 22. PPD of each PSA per scenario family for OLIA\n\nFig. 23. ECDF depicting packet schedulers\u2019 PPD probability across scenario families, for BBR, C-MPBBR, and OLIA.\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-36-0.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-36-1.png)\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-36-2.png)\n38 D. Dimopoulos, et al."}, {"role": "assistant", "content": "**Mechanism:** This study evaluates the symbiotic relationship between MPTCP's packet scheduling (PS) and congestion control (CCA) layers. The core mechanism is that a CCA dictates the 'available bandwidth' (congestion window) for each subflow, effectively setting an upper bound on what a PS can achieve. A well-designed CCA provides consistent 'headroom' for the PS to apply its logic, whereas a restrictive or unstable CCA renders the PS's sophisticated decisions ineffective.\n\n**Explanation:** MPTCP allows a single data stream to use multiple network paths (subflows) simultaneously. Packet schedulers (PS) decide which packet goes over which subflow, aiming for optimal goodput and low delay. Congestion control algorithms (CCA) monitor each subflow for signs of congestion (like increased delay or packet loss) and adjust the rate at which data can be sent (the congestion window, `cwnd`). The critical insight is that if a CCA aggressively shrinks `cwnd`, the PS has little opportunity to make intelligent routing decisions, as its resources are artificially constrained. The paper introduces `PS_score` as a normalized goodput for schedulers and `CCA_score` as an average `PS_score` achieved under a given CCA, indicating how effectively a CCA allows schedulers to perform. To account for robustness, an `overall_score` combines the `CCA_score` with its coefficient of variation (standard deviation / mean), favoring CCAs that offer both high average performance and stability across varied network conditions. Algorithms like BBR and C-MPBBR excel because, unlike traditional loss- or delay-reactive CCAs, they proactively estimate bottleneck bandwidth and round-trip time, pacing traffic to avoid buffer filling and congestion entirely. This predictive approach maintains a more stable and higher `cwnd`, giving schedulers consistent resources to work with, rather than oscillating between aggressive growth and drastic reductions characteristic of AIMD-based CCAs."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5d_\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc46\ud835\udc39_ __\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ \u2265 5 **and** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_ _>_ 1 **and**\n_\ud835\udc4f\ud835\udc64_\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ = _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_\ud835\udc4e\ud835\udc59\ud835\udc59_\ud835\udc46\ud835\udc39\ud835\udc60_ **then**\n\n**20** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc46\ud835\udc39_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ = 5 ;"}, {"role": "assistant", "content": "**Mechanism:** This snippet defines a conditional control mechanism, operating like a state transition guard. It uses a logical 'AND' to combine three specific conditions related to network traffic or service flows (SFs) and their associated bandwidth (bw). If all conditions are met, it triggers a specific action that modifies a counter. The conditions are: 1) a counter for 'lowest bandwidth SFs' has reached or exceeded a threshold of 5, 2) there are multiple total service flows active, and 3) the currently examined service flow is identified as having the absolute lowest bandwidth among all active flows. This is a gating function.\n\n**Explanation:** This code acts as a decision point within a system monitoring network flows. It checks if we've already observed at least 5 instances of the lowest-bandwidth traffic flows (like a `for` loop `if (count >= 5)`), if there's more than just a single active connection (ensuring relevance in a multi-user/multi-service scenario), and if the *current* connection being processed is indeed one of those slowest ones. If all these conditions are true, the system explicitly caps or resets the 'lowest bandwidth SF count' to 5. This isn't just a check; it's a programmatic assignment. It ensures that once a sufficient number (5) of lowest-bandwidth flows have been identified under specific circumstances, this counter doesn't keep increasing, effectively stabilizing the state at a '5 lowest bandwidth flows detected' signal, preventing over-counting or potentially unnecessary further processing. This saturation behavior acts like a flag to a broader system that a particular bottleneck condition has been met and registered."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nRecurrent Neural Networks (RNNs) [6] are a specialized class of neural architectures designed to\n\nprocess sequential or time-dependent data. Unlike feedforward networks, which assume indepen\ndence among input samples, RNNs incorporate temporal dependencies by maintaining a hidden\n\nstate that evolves over time.\n\nShown at Fig. 1, at each timestep _\ud835\udc61_, the network receives an input feature vector _\ud835\udc65\ud835\udc61_ and updates\n\nits hidden state _\u210e\ud835\udc61_ . The dimensionality of this hidden state is a tunable hyperparameter of the\n\nmodel. Conceptually, the hidden state acts as a form of memory, encoding relevant information\n\nfrom previous timesteps and enabling the model to capture temporal context across the sequence.\n\n![](papers/images/A-LatencyConstrained-Gated-Recurrent-Unit-GRU-Implementation-in-the-Versal-AI-Engine.pdf-1-0.png)\n\n(a) A Recurrent Neural Network operating in a feedback loop on the left and the equivalent \"unroll in\ntime\" on the right.\n\n![](papers/images/A-LatencyConstrained-Gated-Recurrent-Unit-GRU-Implementation-in-the-Versal-AI-Engine.pdf-1-1.png)\n\n(b) A graphical representation\nof the data flow between gates\n\ninside the GRU \"cell\"\n\n**Figure 1** : Recurrent Neural Networks (RNNs) and the Gated Recurrent Unit (GRU)\n\n\u2013 2 \u2013\n\nThe Gated Recurrent Unit (GRU) [7], along with the Long Short-Term Memory (LSTM) [8],\n\nrepresents one of the most widely used RNN variants and use gating mechanisms. Specifically,\n\nthe Update gate ( _\ud835\udc67\ud835\udc61_ ) and the Reset gate ( _\ud835\udc5f\ud835\udc61_ ), which regulate information flow through the network.\n\nThese gates are implemented via linear transformations followed by nonlinear activation functions.\n\nThe reset gate determines how much of the previous hidden state should be forgotten, while the\nupdate gate controls how much of the candidate new hidden state ( _\u210e_ [\u02dc] _\ud835\udc61_ ) should contribute to the\n\ncurrent hidden state.\n\nMathematically, the GRU can be expressed as:\n\n_\ud835\udc67\ud835\udc61_ = _\ud835\udf0e_ ( _\ud835\udc4a\ud835\udc67\ud835\udc65\ud835\udc61_ + _\ud835\udc48\ud835\udc67_ _\u210e\ud835\udc61_ \u22121 + _\ud835\udc4f\ud835\udc67_ )\n\n_\ud835\udc5f\ud835\udc61_ = _\ud835\udf0e_ ( _\ud835\udc4a\ud835\udc5f_ _\ud835\udc65\ud835\udc61_ + _\ud835\udc48\ud835\udc5f_ _\u210e\ud835\udc61_ \u22121 + _\ud835\udc4f\ud835\udc5f_ )\n\n\u02dc\n_\u210e\ud835\udc61_ = tanh( _\ud835\udc4a\u210e\ud835\udc65\ud835\udc61_ + _\ud835\udc48\u210e_ ( _\ud835\udc5f\ud835\udc61_ \u2299 _\u210e\ud835\udc61_ \u22121) + _\ud835\udc4f\u210e_ \u02dc)\n\n_\u210e\ud835\udc61_ = (1 \u2212 _\ud835\udc67\ud835\udc61_ ) \u2299 _\u210e\ud835\udc61_ \u22121 + _\ud835\udc67\ud835\udc61_ \u2299 _\u210e_ [\u02dc] _\ud835\udc61_\n\nwhere _\ud835\udf0e_ (\u00b7) denotes the sigmoid activation, tanh(\u00b7) the hyperbolic tangent, and \u2299 the element-wise\n\n(Hadamard) product.\n\nBecause each timestep depends on the previous hidden state, GRUs remain inherently sequential\n\nin computation, limiting parallelization. Moreover, within a single timestep, dependencies among\n\nthe gates impose additional sequential constraints that can reduce computational efficiency on\n\nhardware. Typical latencies for a forward pass on GPUs are in the order of milliseconds[9]."}, {"role": "assistant", "content": "**Mechanism:** At its core, a Recurrent Neural Network (RNN) operates like a `for` loop that iterates through sequential input data, maintaining a persistent internal data structure (the 'hidden state' or `ht`) that is updated in each iteration. GRUs enhance this by introducing two control vectors, `resetGate` (`rt`) and `updateGate` (`zt`), both of which have values element-wise clamped between 0 and 1 by a sigmoid function. The `resetGate` modulates the previous `ht-1` before it contributes to the calculation of a *candidate* new hidden state (`h_tilde`). It's like an element-wise `if (resetGate[i] < threshold) then forget_this_part_of_old_state`. The `updateGate` then acts as a precise mixer. It linearly interpolates between the old hidden state (`ht-1`) and this new `candidate` state (`h_tilde`), effectively deciding for each piece of information in the hidden state how much of the past to retain versus how much of the new information to integrate. This selective gating allows the system to 'remember' important information over long sequences and 'forget' irrelevant details without constant decay.\n\n**Explanation:** Think of `ht` as a dynamic `float` array (like a `List<float>` or `float[]` in programming) that holds the aggregated context, passed from one time step to the next in a sequence. The `sigma` function (sigmoid) applied to the gates `zt` and `rt` acts like a `clamp(value, 0.0f, 1.0f)` operation, turning arbitrary inputs into percentages or 'dimmer switch' settings. The `resetGate` (`rt`) is a vector of these dimmer switches that is multiplied element-wise (like a `zip` and `multiply` operation on two arrays) with the previous hidden state `ht-1`. If an element in `rt` is near 0, the corresponding part of `ht-1` is effectively 'zeroed out' or 'forgotten' when calculating the *candidate* new hidden state (`h_tilde`). The `tanh` function then compresses this `h_tilde` into a range of -1 to 1, normalizing it. Finally, the `updateGate` (`zt`) controls the final `ht`. It implements a weighted average: `ht = (1 - zt) * ht-1 + zt * h_tilde`. If an element in `zt` is 1, the corresponding part of `ht` fully adopts the new `h_tilde`. If it's 0, it completely retains `ht-1`. This is akin to a `Lerp` (linear interpolation) function, allowing the system fine-grained control over which parts of its 'memory' array are updated and which are preserved across time, addressing the 'vanishing/exploding gradient' problem in simpler RNNs by controlling information flow."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ /* Close _\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ whose _\ud835\udc47\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc37\ud835\udc52\ud835\udc59_ _ _\ud835\udc45\ud835\udc61_ _< \ud835\udefd_ \u2217 _\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_\nfor five successive ProbeBw states */\n\n**Fulfilling Goal 2 (MPTCP fairness):**\n\n**22** _\ud835\udefc_ = 20, _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = 0 ;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism employs a conditional feedback loop to manage the allocation of resources (subflows) in a multipath environment, such as MPTCP. It continuously monitors the performance of each subflow, evaluating a metric like 'Total_Del_Rt' (likely related to delay or inefficiency). When a subflow's performance consistently falls below a predefined fraction (beta) of the absolute best-performing subflow (indicated by 'highest_bw_among_all_SFs') for a specified number of consecutive observation intervals ('five successive ProbeBw states'), the underperforming subflow is terminated. This is analogous to a watchdog timer or a circuit breaker that trips when conditions are outside a normal operating range for a sustained period.\n\n**Explanation:** The core idea is to prune inefficient branches from the overall connection. By comparing a subflow's individual performance against the 'champion' subflow, the system identifies consistently weak links. The 'beta' threshold acts as a sensitivity knob, determining how much worse a subflow can be before it's considered for closure. The 'five successive ProbeBw states' introduces hysteresis, preventing premature disconnections due to transient network fluctuations, similar to a simple moving average or a counter in a `for` loop that requires a condition to be true 'n' times before taking action. This ensures that only genuinely underperforming paths are removed, freeing up resources and preventing them from dragging down the aggregated connection's fairness and overall throughput. The initial parameter settings (_\ud835\udefc_ = 20, _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = 0) suggest an initial state for further fairness calculations, possibly indicating an empty bottleneck or a base value for an adaptive algorithm."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc60\ud835\udc53\ud835\udc56_ __\ud835\udc36\ud835\udc4a\ud835\udc41\ud835\udc37_\ud835\udc4e\ud835\udc63\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52_ **and** _\ud835\udefe_\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f_ _> \ud835\udefe_\ud835\udc5a\ud835\udc4e\ud835\udc65_ **then**\n\n**16** _\ud835\udefe\ud835\udc5a\ud835\udc4e\ud835\udc65_ \u2190 _\ud835\udefe_ _ _\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f_ ;\n\n**17** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_ \u2190 _\ud835\udc60\ud835\udc53\ud835\udc56_ ;"}, {"role": "assistant", "content": "**Mechanism:** This code snippet implements a fundamental 'maximum finding' or 'best-so-far tracking' pattern within an iterative process.\n\n**Explanation:** At its core, this is an `if` statement nested within what would typically be a loop. It maintains two state variables: `gamma_max`, which stores the highest value encountered for a performance metric (`gamma`), and `sfbest`, which 'points' to or stores the specific configuration parameter (`sfi`) that yielded that `gamma_max`. The condition `CWND_available` acts as a guard clause, ensuring that only valid or ready `sfi` candidates are considered for comparison. If a new `sfi` and its associated `gamma_curr` meet the availability criteria and `gamma_curr` is strictly greater than the currently recorded `gamma_max`, then `gamma_max` is updated to `gamma_curr`, and `sfbest` is updated to `sfi`. This is a classic pattern for selecting an optimal choice (e.g., best path, best configuration, highest score) from a series of options by iteratively comparing and updating a 'record-holder'."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nRecent advances in natural language processing have been driven\nby the rapid scaling of large language models (LLMs) [20, 27, 28].\nAmong them, Mixture-of-Experts (MoE) architectures [36] provide\nan attractive path to efficiency by activating only a small subset of\nexperts per token while preserving a high overall parameter capacity. Modern MoE models, such as Qwen-MoE [34] and DeepSeekMoE [19], consistently outperform dense counterparts [7], yet their\ndeployment remains constrained by memory footprint. To support\ndynamic routing, all experts must reside in GPU memory, causing\ninactive experts to dominate the total parameter load. For example,\nQwen3-30B-A3B requires roughly 57GB of weights to be present on\ndevice despite using only about 3B (6.1GB) parameters per token. As\nMoE layers contribute more than 98% of the model size, compressing experts is essential for running such models on memory-limited\nconsumer GPUs like the RTX-5090 or A6000.\n\nPost-training quantization (PTQ) provides a practical means to\nreduce memory usage via low-bit representations. Methods such as\nAWQ [18] and GPTQ [9] demonstrate strong compression on dense\n\n\u2217Corresponding author. Email: wei.13.zhang@uconn.edu\n\nLLMs, and recent efforts extend PTQ to MoE experts. Techniques including MoQE [15], MxMoE [6], EaQuant [10], and QMoE [8] push\nprecision down to 2\u20134 bits or even sub-1-bit regimes. Although it\nincurs about a 6 _._ 7% accuracy drop compared with the full-precision\nmodel. In addition, all prior MoE quantization remains _static_ : expert\nbit-widths are fixed offline, based on limited calibration data, and\ncannot adjust to the highly dynamic activation patterns observed\nduring inference. As a result, hot experts may suffer unnecessary\ndegradation under aggressive quantization, while cold experts retain oversized representations that waste scarce HBM capacity.\nThis work introduces **DynaExq** (Dynamic Expert Exchange\nQuantization), a runtime system that treats precision as a _first-class,_\n_dynamically managed resource_ . DynaExq is motivated by the observation that expert activation patterns shift substantially across\ninputs and workloads. As shown in Fig. 1, only a small subset\nof experts remains consistently active within each layer, whereas\nmost experts are rarely selected. By exploiting this temporal sparsity, DynaExq assigns precision adaptively: frequently activated\n(hot) experts retain high precision to maintain routing accuracy,\nwhereas infrequently used (cold) experts are aggressively quantized\nor offloaded to reduce memory pressure. This runtime precision realignment enables substantial compression without compromising\nmodel fidelity.\nDynaExq comprises two core mechanisms and two supporting\ncomponents. The _Expert Precision Controller_ maintains a slidingwindow profile of expert activity and issues promotion or demotion\ndecisions based on workload trends and memory feasibility. The\n_Asynchronous Swapping Pipeline_ performs precision transitions in\nthe background by staging weights across SSD, DRAM, and HBM\nusing dedicated CUDA streams, ensuring that expert switching\nnever interrupts the forward path. To guarantee allocator determinism, DynaExq adopts a dual-pool memory layout that isolates\nhigh- and low-precision experts, combined with a static threshold\ninitialization procedure that respects per-layer HBM budgets.\nTogether, these mechanisms allow DynaExq to deliver adaptive\nquantization, stable routing behavior, and high-throughput inference for large MoE models on a single commodity GPU. The key\ncontributions of this work are:\n\n - We present **DynaExq**, a runtime system that tightly couples\nexpert quantization with activation-aware precision scheduling for single-GPU MoE inference, managing expert precision\nonline based on router statistics and memory budgets.\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-6.png)\n\n**(a) Wikitext**\n\n**(d) Wikitext**\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-5.png)\n\n**(b) GSM8K**\n\n**(e) GSM8K**\n\nKexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Lin, and Wei Zhang\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-4.png)\n\n**(c) HumanEval**\n\n**(f) HumanEval**\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-14.png)\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-15.png)\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-1-16.png)\n\n**Figure 1: Expert activation distributions across layers and workloads. Each subplot shows routing frequency for 128 experts in**\n**layer 1 and layer 47.**\n\n - We introduce a multi-stage **asynchronous swapping pipeline**\nthat overlaps data movement, quantization, and computation\nto ensure non-blocking precision transitions.\n\n - We develop a **structured memory pool** that eliminates fragmentation and enables efficient concurrent expert promotions\nand demotions under tight memory constraints."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves dynamically adjusting the memory representation (precision) of specialized processing modules ('experts') within a larger model. The system continuously profiles the activation frequency of each expert. Experts that are frequently invoked ('hot') are maintained in a high-precision, memory-intensive format (e.g., full floating-point). Conversely, experts that are rarely invoked ('cold') are aggressively compressed by reducing their bit-width (quantized) or even offloaded to slower storage tiers (SSD, DRAM). This dynamic adjustment is managed by an 'Expert Precision Controller' that makes promotion/demotion decisions based on observed activity and available memory budgets. An 'Asynchronous Swapping Pipeline' handles the background movement and conversion of expert weights between different memory locations and precision levels, using dedicated processing streams to prevent the main computational path from stalling. To ensure stable memory management, a 'Structured Memory Pool' segregates high- and low-precision experts into distinct regions, akin to having separate memory heaps for different object types, preventing fragmentation during dynamic precision changes.\n\n**Explanation:** Think of it like a smart caching system for code or data. Instead of always keeping every single function in its most detailed, high-resolution form in fast memory, this system observes which specific functions (experts) are actually being called most often during execution. The frequently used functions are kept fully detailed and ready for immediate, high-quality execution. The rarely used functions are compressed into a smaller, less detailed version, or moved to a slower storage disk. If a compressed function suddenly becomes popular, a background process (like a dedicated thread) quickly decompresses it and moves its full version back into fast memory, all without interrupting the main program. This works because not all parts of the large model are equally important or active at any given moment, allowing selective memory allocation based on real-time usage patterns, much like a CPU's memory manager swapping pages, but applied at a much finer, module-specific granularity."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\ncapture fundamen- **0**\ntal properties that must hold for valid reasoning, including logical coherence (not simultaneously believing \"the design is stable\" and \"the design will collapse\"), compositionality (understanding \"red LEGO\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|Col18|Col19|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||||||~~Score~~<br>~~Present~~<br>Partially Present|~~Score~~<br>~~Present~~<br>Partially Present|~~Score~~<br>~~Present~~<br>Partially Present|~~Score~~<br>~~Present~~<br>Partially Present|~~Score~~<br>~~Present~~<br>Partially Present|\n||||||||||||||||||||\n||||||||||||||||||||\n\ncockpit\" by combining concepts of color, Figure 2: Distribution of cognitive element presence across\nmaterial, and function). **2)** **Meta-** 1,598 arXiv LLM Reasoning papers. _Partially present_ indi**cognitive controls** encompass the execu- cates that there is evidence that the behavior was considered\ntive functions that select and monitor rea- in the design (motivation, method, evaluation) of the paper but\nsoning strategies, such as recognizing when was not the primary focus. _Present_ indicates that there is eviyou lack necessary pieces (self-awareness), dence that the behavior was a conscious and significant design\ndeciding whether to plan the entire de- decision. Details provided in Section 5.\nsign upfront versus building exploratively\n(strategy selection). **3) Reasoning representations** desrcibe how knwoledge is organized: hierarchically\n(decomposing \"spaceship\" into \"body,\" \"wings,\" \"cockpit\"), causally (understanding that inadequate support\ncauses structural collapse), or spatially (tracking how pieces connect in 3D space). **4) Reasoning oper-**\n**ations** specify the procedures that construct and transform these representations, such as verifying each\nconnection works, backtracking when a wing design fails, or abstracting the principle that heavier components need more support points. Organizing these theories through Marr\u2019s (1982) levels of analysis (focusing\non computational and algorithmic levels) yields 28 specific cognitive elements spanning the space of human\n\nDistribution of Cognitive Elements Considered by LLM Reasoning Papers"}, {"role": "assistant", "content": "**Mechanism:** Effective LLM reasoning demands capabilities akin to a well-structured software program with robust error handling and flexible data management. Logical coherence operates like a set of boolean flags and conditional `if` statements, ensuring that the model's internal 'state' doesn't simultaneously hold contradictory propositions (e.g., `is_stable` cannot be true if `will_collapse` is also true). Compositionality functions like object instantiation or combining elements from a hash map: understanding 'red LEGO cockpit' involves accessing and combining attributes of 'red' (color), 'LEGO' (material), and 'cockpit' (function) into a higher-order concept or structured data type. Metacognitive controls are analogous to a top-level `control_flow` manager, selecting different algorithms or subroutines based on an internal 'self-awareness' signal (e.g., `if (lack_info_flag) then (call search_strategy)`). Reasoning representations are the underlying data structures for knowledge: hierarchical could be a `tree` or nested `objects`; causal a `graph` with directed edges; and spatial a `3D array` or coordinate system. Reasoning operations are the `methods` or `functions` that manipulate these structures: `validate_connection()`, `undo_last_action()` (backtracking), or `extract_principle()` (abstraction).\n\n**Explanation:** Fundamentally, robust reasoning in an LLM isn't just about pattern matching, but about mimicking structured problem-solving. This means moving beyond a simple `token-in, token-out` prediction engine to one that internally maintains consistent states (coherence), builds meaning from constituent parts (compositionality), dynamically selects its problem-solving approach (metacognition), organizes its knowledge in appropriate data structures (representations), and applies specific algorithms to process that knowledge (operations). Without these, an LLM risks generating inconsistent, uninterpretable, or inefficient responses, much like a poorly architected program. The mechanism is about transforming associative statistical models into functional, logic-constrained systems."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _< \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ **or** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ _< \ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ **then**\n\n**152** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ ;\n\n**153** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51, \ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc40\ud835\udc56\ud835\udc5b\ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ ) ;\n\n**154** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc40\ud835\udc5c\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc39\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**155** BBR_Update_Target_Cwnd():\n\n**156** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61_ _ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ ) ;\n\n**157** BBR_Inflight(gain):"}, {"role": "assistant", "content": "**Mechanism:** This code implements a conditional additive growth mechanism for the congestion window (cwnd), constrained by a minimum floor and a dynamically calculated target ceiling. This system works by allowing the transmission window to expand, either to fill underutilized capacity or during an initial discovery phase, while periodically forcing a contraction to accurately measure network latency, ultimately ensuring efficient data flow.\n\n**Explanation:** The 'if' condition acts as a gateway for `cwnd` growth. It allows `cwnd` to increase if it's below its calculated 'target' capacity (`BBR.target_cwnd`), or if the connection is in an early, exploratory phase (`BBR.delivered < InitialCwnd`). When permitted, `cwnd` grows additively by `packets_delivered`, similar to how a buffer might expand as data arrives. The `max` function ensures `cwnd` never falls below `BBRMinPipeCwnd`, preventing a complete stall, much like a minimum allocated memory size. The `BBR_Modulate_Cwnd_For_Probe_RTT()` function (a method call) is critical: it periodically reduces `cwnd` to drain network queues, enabling a 'clean' measurement of Round-Trip Time (RTT). This RTT is vital for BBR's core function of estimating the true bandwidth-delay product. Finally, `BBR_Update_Target_Cwnd()` recalculates `BBR.target_cwnd`, which acts as a dynamic upper bound for the actual `cwnd`. This target is based on the `BBR_Inflight` calculation (likely an estimation of the bandwidth-delay product) multiplied by a `cwnd_gain`. The `cwnd_gain` is a key tunable parameter that dictates how aggressively the system attempts to fill the pipe, allowing for phases like aggressive startup (gain > 1) or RTT probing (gain < 1)."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ ; /* no valid RTT samples yet */\n\n**160** _\ud835\udc5e\ud835\udc62\ud835\udc4e\ud835\udc5b\ud835\udc61\ud835\udc4e_ = 3 \u2217 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc52\ud835\udc5b\ud835\udc51_ _ _\ud835\udc5e\ud835\udc62\ud835\udc4e\ud835\udc5b\ud835\udc61\ud835\udc62\ud835\udc5a_ ;\n\n**161** _\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51_ _ _\ud835\udc4f\ud835\udc51\ud835\udc5d_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ \u2217 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ ;"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is to precisely model the network path as a 'pipe' with a specific capacity, rather than just reacting to packet loss. By estimating the 'Bottleneck Bandwidth' (BtlBw) and the 'Round-Trip Propagation Time' (RTprop), the system calculates the 'Bandwidth-Delay Product' (BDP). The BDP represents the maximum volume of data that can be 'in-flight' within the network pipe without overflowing buffers or encountering artificial delays. This is analogous to knowing the flow rate and length of a water pipe to determine its total volume capacity. The 'quanta' calculation serves as an adaptive 'batch size' for sending data, possibly to probe the network more effectively or to ensure that the sending rate is sufficient to fully utilize the estimated bandwidth, akin to a loop sending chunks of data rather than individual items.\n\n**Explanation:** Traditional network congestion control often works like driving a car and only slowing down *after* you see brake lights (packet loss). This approach is different: it's like a sophisticated GPS figuring out the exact speed limit and distance of the road ahead *before* you even start, to know exactly how many cars (data packets) you can have on the road at once without causing a jam. The 'estimated_bdp' is the 'volume' of the network 'pipe', determined by how fast the slowest part of the pipe can carry data (BtlBw) and how long it takes for a signal to travel to the other end and back (RTprop). By knowing this volume, the system can send just enough data to keep the pipe full but not overflowing. The 'quanta' factor essentially groups smaller units into a larger sending 'batch' to make sure enough data is pushed into the pipe efficiently, like sending a small array of bytes in one go instead of single bytes."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**38**\n\nG.1 Reinforcement Learning Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\nG.2 Multi Agent Reinforcement Learning Experiments . . . . . . . . . . . . . . . . . . . . . . 39\n\nG.3 Reasoning Fine-tuning Experiments: Countdown . . . . . . . . . . . . . . . . . . . . . . . 41\n\nG.4 Reasoning Fine-tuning Experiments: GSM8K . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\n18\n\n**A** **Proofs**\n\nIn our proofs, we use the integral notation \ufffd to denote the integral over the corresponding R _d_ space, for\nexample, for a matrix _E \u2208_ R _[m][\u00d7][n]_, \ufffd _f_ ( _E_ ) _dE_ = \ufffdR _[m][\u00d7][n][ f]_ [(] _[E]_ [)] _[dE]_ [ and for a vector] _[ E][ \u2208]_ [R] _[mn]_ [,] \ufffd _f_ ( _v_ ) _dv_ =\n\nexample, for a matrix _E \u2208_ R _[m][\u00d7][n]_, \ufffd _f_ ( _E_ ) _dE_ = \ufffdR _[m][\u00d7][n][ f]_ [(] _[E]_ [)] _[dE]_ [ and for a vector] _[ E][ \u2208]_ [R] _[mn]_ [,] \ufffd _f_ ( _v_ ) _dv_ =\n\n\ufffdR _[mn][ f]_ [(] _[v]_ [)] _[dv]_ [.]\n\n**A.1** **ES Matrix Gradient Deviations**\n\n**Proposition 1.** _Using the Gaussian matrix policy \u03c0_ ( _M_ _|\u00b5_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ) _the ES objective can be_\n_written as:_\n\n_J_ ( _\u00b5_ ) = E _E\u223cP_ ( _E_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3E_ )] _._\n\n_and the matrix gradient of the ES objective is:_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[E][\u223c][P]_ [ (] _[E]_ [)][ [] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ .]_\n\n_where P_ ( _E_ ) _is a zero-mean standard normal p_ ( _E_ ) = _N_ (0 _, Im, In_ ) _. Moreover, the natural matrix gradient is_\n_equal to \u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) _, i.e. equivalent to Eq._ (4) _up to a factor of \u03c3_ [2] _._\n\n_Proof._ We start by deriving the derivative of the ES objective from Eq. (1). Taking the derivative with respect\n\nto _\u00b5_ :\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _f_ ( _M_ ) _\u2207\u00b5\u03c0_ ( _M_ _|\u00b5_ ) _dM,_\n\ufffd\n\n= _f_ ( _M_ ) _\u2207\u00b5_ log _\u03c0_ ( _M_ _|\u00b5_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM._\n\ufffd\n\nNow,\n\n1\n_\u2207\u00b5_ log _\u03c0_ ( _M_ _|\u00b5_ ) = _\u2207\u00b5 \u2212_ 2 _\u03c3_ [2] [tr] \ufffd( _M \u2212_ _\u00b5_ ) _[\u22a4]_ ( _M \u2212_ _\u00b5_ )\ufffd _,_\n\nR _[mn][ f]_ [(] _[v]_ [)] _[dv]_ [.]\n\n= _\u2212_ [1]\n\n_\u03c3_ [2] [(] _[M][ \u2212]_ _[\u00b5]_ [)] _[,]_\n\nwhere we have used Petersen & Pedersen (2008, Eq. 103) for the matrix derivative of the trace, hence:\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n( _M \u2212_ _\u00b5_ )\n\n_f_ ( _M_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM._\n\n\ufffd _\u03c3_\n\nWe make the transformation of variables _E_ = _[M]_ _[\u2212][\u00b5]_ :\n\n_\u03c3_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_E \u00b7 f_ ( _M_ ) _p_ ( _E_ ) _dE,_\n\ufffd\n\nwhere\n\n_p_ ( _E_ ) = _\u03c3_ _[mn]_ _\u03c0_ ( _M_ = _\u00b5_ + _\u03c3E|\u00b5_ )\n\n_\u2212_ [1]\nexp\n2 \ufffd 2\n\n1\n\n= ~~_mn_~~\n(2 _\u03c0_ ) 2\n\n[1] \ufffd _E_ _[\u22a4]_ _E_ \ufffd [\ufffd] _,_\n\n2 [tr]\n\n= _N_ (0 _, Im, In_ ) _,_\n\nas required. Using the same transformation of variables, the alternative form of the matrix Gaussian ES\nobjective follows immediately:\n\n_J_ ( _\u00b5_ ) = _f_ ( _M_ ) _\u03c0_ ( _M_ _|\u00b5_ ) _dM,_\n\ufffd\n\n= _f_ ( _M_ = _\u00b5_ + _\u03c3E_ ) _P_ ( _E_ ) _dE._\n\ufffd\n\n19\n\nWe now derive the natural policy gradient for a Gaussian policy to prove our final claim. It is convenient to work\nin vector space rather than matrix space. In vector form, the natural gradient is defined as _F_ ( _\u00b5v_ ) _[\u2212]_ [1] _\u2207\u00b5v_ _J_ ( _\u00b5v_ )\nwhere _F_ ( _\u00b5v_ ) is the Fisher information matrix of the distribution:\n\n_F_ ( _\u00b5v_ ) := E _v\u223c\u03c0_ ( _v|\u00b5v_ ) \ufffd _\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) _\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) _[\u22a4]_ [\ufffd] _,_\n\nwhere _\u00b5v_ = vec( _M_ ) and _\u03c0_ ( _v|\u00b5v_ ) = _N_ ( _\u00b5v, \u03c3_ [2] _Imn_ ) for our Gaussian case. Deriving the score function:\n\n_\u2207\u00b5v_ log _\u03c0_ ( _v|\u00b5v_ ) = _\u2212_ 2 _\u03c3_ [1] [2] _[\u2207][\u00b5][v]_ _[\u2225][\u00b5][v][ \u2212]_ _[v][\u2225]_ [2] _[,]_\n\n= [1]\n\n_\u03c3_ [2] [(] _[v][ \u2212]_ _[\u00b5][v]_ [)] _[,]_\n\nHence the Fisher information matrix is:\n\n_F_ ( _\u00b5v_ ) = _\u03c3_ [1][4] [E] _[v][\u223c][\u03c0]_ [(] _[v][|][\u00b5][v]_ [)] \ufffd( _v \u2212_ _\u00b5v_ )( _v \u2212_ _\u00b5v_ ) _[\u22a4]_ [\ufffd] _,_\n\nThis yields the natural gradient:\n\n= [1]\n\n_\u03c3_ [2] _[I][mn][.]_\n\n_F_ ( _\u00b5v_ ) _[\u2212]_ [1] _\u2207\u00b5v_ _J_ ( _\u00b5v_ ) = _\u03c3_ [2] _\u2207\u00b5v_ _J_ ( _\u00b5v_ ) _._\n\nConverting back to matrix form, the natural gradient is thus _\u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) as required.\n\n**Theorem 1.** _Let Assumption 1 hold. Then for finite r:_\n\n_gLR_ := _\u2207\u00b5JLR_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[y]_ [ = (] _[\u00b5]_ [ +] _[ \u03c3Z]_ [)] _[x]_ [)]] _[ .]_\n\n_where Z is generated by sampling A \u223c_ _p_ ( _A_ ) _, B \u223c_ _p_ ( _B_ ) _, \u03f5 \u223c_ _p_ ( _\u03f5_ ) _and making the transformation Z_ =\n_AB_ _[\u22a4]_\n\n+ _\u03f5._\n~~_\u221a_~~ _r_\n\n_Proof._ We first prove that the density _p_ ( _Z_ ) of the pushforward distribution of _p_ ( _A_ ), _p_ ( _B_ ) and _p_ ( _\u03f5_ ) under the\nmapping ( _A, B, \u03f5_ ) : _\u2192_ _Z_ = _[AB]_ ~~_\u221a_~~ _r_ _[\u22a4]_ + _\u03f5_ exists. As _r_ is finite, _p_ ( _\u03f5_ ) is a Gaussian with well-defined density and _Z_\n\nis a sum two independent variables _[AB]_ ~~_\u221a_~~ _r_ _[\u22a4]_ and _\u03f5_ . The density _p_ ( _Z_ ) is thus given by the convolution (see, for\n\nexample, Durrett (2010, Theorem 2.1.11)):\n\n_p_ ( _Z_ ) = E _A\u223cp_ ( _A_ ) _,B\u223cp_ ( _B_ )\n\n_p_ _\u03f5_ = _Z \u2212_ _[AB][\u22a4]_ _,_\n\ufffd \ufffd ~~_\u221ar_~~ \ufffd\ufffd\n\nwhich integrates to 1 over R _[m][\u00d7][n]_ and, since _p_ ( _\u03f5_ ) is everywhere positive, is also everywhere positive. The\ndistribution of _Z_ is thus absolutely continuous with respect to the Lebesgue measure in R _[m][\u00d7][n]_ and the density\n_p_ ( _Z_ ) is well-defined. To derive the gradient, we make the transformation of variables _Z_ _[\u2032]_ = _\u00b5_ + _\u03c3Z_ :\n\n_J_ LR( _\u00b5_ ) = _p_ ( _Z_ _[\u2032]_ ) _f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _,_\n\ufffd\n\nwhere _p_ ( _Z_ _[\u2032]_ ) = _\u03c3_ _[mn]_ 1 _[p]_ [(] _[Z]_ [ =] _[ Z][\u2032]_ _\u03c3_ _[\u2212][\u00b5]_ ) Taking derivatives with respect to _\u00b5_ :\n\n1\n_\u2207\u00b5J_ LR( _\u00b5_ ) = \ufffd _\u03c3_ _[mn]_ _[\u2207][\u00b5][p]_ \ufffd _Z_ = _[Z]_ _[\u2032][ \u2212]_ _\u03c3_ _[\u00b5]_ \ufffd _f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _,_\n\n= _p_ ( _Z_ _[\u2032]_ ) _\u2207\u00b5_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd \ufffd _\u03c3_\n\n_f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _._\n\ufffd\n\nFrom the chain rule:\n\n_\u2207\u00b5_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd _\u03c3_\n\n= _\u2212_ [1]\n\ufffd _\u03c3_\n\n[1] _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\n_\u03c3_ _[\u2207][Z]_ [ log] _[ p]_ \ufffd _\u03c3_\n\n_,_\n\ufffd\n\n_\u03c3_\n\n20\n\nhence:\n\n_f_ ( _y_ = _Z_ _[\u2032]_ _x_ ) _dZ_ _[\u2032]_ _._\n\ufffd\n\n_\u2207\u00b5J_ LR( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_p_ ( _Z_ _[\u2032]_ ) _\u2207Z_ log _p_ _Z_ = _[Z]_ _[\u2032][ \u2212]_ _[\u00b5]_\n\ufffd \ufffd _\u03c3_\n\nMaking the reverse transformation of variables _Z_ = _[Z][\u2032]_ _\u03c3_ _[\u2212][\u00b5]_ :\n\n_\u2207\u00b5J_ LR( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_\n\n_p_ ( _Z_ ) _\u2207Z_ log _p_ ( _Z_ ) _f_ ( _y_ = ( _\u00b5_ + _\u03c3Z_ ) _x_ ) _dZ,_\n\ufffd\n\n= _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[y]_ [ = (] _[\u00b5]_ [ +] _[ \u03c3Z]_ [)] _[x]_ [)]] _[,]_\n\nas required.\n\n**A.2** **Error Rate Analysis**\n\nFor convenience, we work with random vectors in our analysis. Using the vec operator, we analyse the vector\n_v_ _[r]_ = vec( _Z_ _[r]_ ) where:\n\nvec( _M_ ) = [ _m_ 1 _,_ 1 _, . . . m_ 1 _,m, m_ 2 _,_ 1 _, . . . mm,n_ ] _[\u22a4]_ _._\n\nFor a vector _v \u2208_ R _[mn]_, we define the mat operator as:\n\n\uf8f9\n\n_,_\n\uf8fa\uf8fa\uf8fa\uf8fb\n\nmat( _v_ ) =\n\n_v_ 1 _vm_ +1 _. . ._ _v_ ( _n\u2212_ 1) _m_ +1\n\n\uf8ee _v_ 2 _vm_ +2 _. . ._ _v_ ( _n\u2212_ 1) _m_ +2\n\n... ... ... ...\n\n\uf8ef\uf8ef\uf8ef\uf8f0 _vm_ _v_ 2 _m_ _\u00b7 \u00b7 \u00b7_ _vmn_\n\nso mat(vec( _M_ )) = _M_ . Using Eq. (6), write _v_ _[r]_ as a standardised sum of _r_ independent, zero-mean random\nvectors. Let\n\n_ui_ = vec \ufffd _aib_ _[\u22a4]_ _i_ [+] _[ \u03f5][i]_ \ufffd _,_ (10)\n\nwhere recall _ai_ and _bi_ are the _i_ th column vectors of _A_ and _B_ and _\u03f5i_ is an _m\u00d7n_ random matrix with independent\nGaussian elements drawn from _N_ (0 _,_ _[\u03c3]_ _\u03f5_ [2] _/r_ ), so:\n\n1\n_v_ _[r]_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd _u_ _[r]_ _i_ _[.]_\n\n_i_ =1\n\nWe will use the fact that the Frobenius norm becomes the _\u2113_ -2 norm in vector space:\n\n~~\ufffd~~ _mi,j_ [2] = ~~\ufffd~~\n\n_i,j_ \ufffd _k_\n\n_\u2225M_ _\u2225F_ = ~~\ufffd~~\n\ufffd _i,j_\n\nvec( _M_ ) _k_ 2 = _\u2225_ vec( _M_ ) _\u2225._ (11)\n\n_k_\n\nDenoting the covariance matrix of _p_ ( _u_ ) as \u03a3 _[r]_, the central limit theorem proves that the distribution of _v_ _[r]_\n\nconverges in distribution to a zero-mean Gaussian _N_ (0 _,_ \u03a3 _r_ ). In Lemma 1, derive the covariance matrix for \u03a3 _[r]_ .\nOur analysis uses an Edgeworth expansion (Bhattacharya & Ranga Rao, 1976) to characterise precisely the rate\nat which _p_ ( _v_ _[r]_ ) converges to the limiting Gaussian distribution. In Lemma 2, we make an Edgeworth expansion\nof _p_ ( _v_ _[r]_ ) to show that it is dominated by _O_ \ufffd 1 _r_ \ufffd terms and higher. These are then used to prove Lemma 3,\n\nwhich allows us to bound the integral of the remainder of the Edgeworth expansion, thereby characterising\nhow fast _p_ ( _v_ _[r]_ ) converges to the limiting Gaussian distribution.\n**Lemma 1.** _Let Assumption 1 hold and u be defined in Eq._ (10) _. Then the variable u has diagonal covariance_\n\n_matrix:_\n\n\u03a3 _[r]_ = _\u03c3_ 0 [4] [+] _[\u03c3]_ _\u03f5_ [2]\n\ufffd _r_\n\n_Imn_ =: _\u03c3r_ [2] _[I][mn][,]_\n\ufffd\n\n_Moreover, the variable u has a finite_ 4 _th-order absolute moment:_\n\nE _u\u223cp_ ( _u_ ) \ufffd _\u2225u\u2225_ [4][\ufffd] _< \u221e._\n\n21\n\n_Proof._ Under the vec operator, the vector _u_ can be written element wise as:\n\n_u_ = [ _a_ 1 _b_ 1 + _\u03f5_ 1 _,_ 1 _, a_ 2 _b_ 1 + _\u03f5_ 2 _,_ 1 _, . . . amb_ 1 + _\u03f5m,_ 1 _, a_ 1 _b_ 2 + _\u03f5_ 1 _,_ 2 _, . . . ambn_ + _\u03f5m,n_ ] _[\u22a4]_ _._\n\nWe note that all elements in the vector _u_ have zero mean, and so the covariance matrix is the expectation of the\nouter product:\n\n\u03a3 _[r]_ = E _u\u223cp_ ( _u_ ) \ufffd _uu_ _[\u22a4]_ [\ufffd] _._\n\nThe diagonal elements of \u03a3 _[r]_ are:\n\nE _ai,bj_ _,\u03f5j,i_ \ufffd( _aibj_ + _\u03f5j,i_ ) [2][\ufffd] = E _ai,bj_ _,\u03f5j,i_ \ufffd _a_ [2] _i_ _[b]_ [2] _j_ [+ 2] _[a][i][b][j][\u03f5][j,i]_ [+ (] _[\u03f5][j,i]_ [)][2][\ufffd] _,_\n\n= E _ai,bj_ \ufffd _a_ [2] _i_ _[b]_ [2] _j_ \ufffd + E _\u03f5j,i_ \ufffd( _\u03f5j,i_ ) [2][\ufffd] _,_\n\n= _\u03c3_ 0 [4] [+] _[ \u03c3]_ _r\u03f5_ [2] _[.]_ (12)\n\nAs all elements of _a_, _b_ and _\u03f5_ are zero-mean, off-diagonal elements are zero:\n\nE _ai,bj_ _,ak,bl,\u03f5j,i,\u03f5k,l_ [( _aibj_ + _\u03f5j,i_ ) ( _akbl_ + _\u03f5k,l_ )]\n\n=E _ai,bj_ _,ak,bl_ [ _aibjakbl_ ] + E _ai,bj_ _,\u03f5k,l_ [ _aibj\u03f5k,l_ ]\n\n+ E _ak,bl,\u03f5j,i_ [ _ak, bl, \u03f5j,i_ ] + E _\u03f5j,i,\u03f5l,k_ [ _\u03f5j,i\u03f5k,l_ ] _,_\n\n=E _ai,bj_ _,ak,bl_ [ _aibjakbl_ ] + E _\u03f5j,i,\u03f5l,k_ [ _\u03f5j,i\u03f5k,l_ ] _,_\n\n=0 _i \u0338_ = _k_ or _j \u0338_ = _l._ (13)\n\nUsing Eqs. (12) and (13), our first result follows:\n\n\u03a3 _[r]_ = _\u03c3_ 0 [4] [+] _[ \u03c3]_ _\u03f5_ [2]\n\ufffd _r_\n\n_Imn._\n\ufffd\n\nNow, as _u_ is a vector of elements which are sums and products of variables which all have finite 4th order\nmoments from Assumption 1, it immediately follows that _u_ has finite 4th order absolute moments.\n\nUsing Lemma 1, we see the asymptotic Gaussian density of _v_ _[r]_ is:\n\n1\n\n_\u2212_ _[\u2225][v][r][\u2225]_ [2]\nexp\n(2 _\u03c0_ ) _[mn]_ _\u03c3r_ [2] \ufffd 2 _\u03c3r_ [2]\n\n1\n_g_ ( _v_ _[r]_ ) =\n~~\ufffd~~ (2 _\u03c0_ )\n\n2 _\u03c3r_ [2]\n\n_._ (14)\n\ufffd\n\nWe now derive a 4th order Edgeworth expansion for _p_ ( _v_ _[r]_ ) and its score function, which expands _p_ ( _v_ _[r]_ ) in terms\nof the limiting distribution _g_ ( _v_ _[r]_ ) plus remainder terms. Our proof reveals that 3rd order cumulants control all\nterms in the expansion that decay at rate _O_ \ufffd ~~_\u221a_~~ 1 _r_ \ufffd. As 3rd order cumulants are all zero due to symmetry in\n\nAssumption 1, the overall decay rate is controlled by _O_ \ufffd 1 _r_ \ufffd terms associated with 4th order cumulants. It is\n\nfor this reason that we obtain a faster convergence rate than the standard central limit theorem.\n**Lemma 2.** _Let Assumption 1 hold and let v_ _[r]_ = _vec_ ( _Z_ _[r]_ ) _and ui be defined in Eq._ (10) _. Let g_ ( _v_ _[r]_ ) _denote_\n_limiting Gaussian density in Eq._ (14) _. Then, the Egdeworth expansion of p_ ( _v_ _[r]_ ) _is:_\n\n_p_ ( _v_ _[r]_ ) = _g_ ( _v_ _[r]_ ) + [1]\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[,,]_\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\n_where:_\n\n_\u2225vr\u2225_ 2\n_Hi,j,k,l_ ( _v_ _[r]_ _, \u03c3r_ ) := exp\n\ufffd 2 _\u03c3r_ [2]\n\n_\u2202_ [4]\n\ufffd _\u2202vi_ _[r][\u2202v][r]_\n\n_\u2202_ [4]\n\n_\u2212_ _[\u2225][v][r][\u2225]_ [2]\nexp\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd 2 _\u03c3r_ [2]\n\n2 _\u03c3r_ [2]\n\n\ufffd\n\n_is a 4th order Hermite polynomial for g_ ( _v_ _[r]_ ) _(Laplace, 1811; Hall, 1992; Withers, 2000) and \u03c1_ ( _v_ _[r]_ ) _is o_ \ufffd 1 _r_ \ufffd _._\n\n22\n\n_Proof._ We denote the characteristic function of _p_ ( _u_ _[r]_ _i_ [)][ as:]\n\n_\u03c6U r_ ( _\u03c9_ ) = exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _u_ \ufffd _p_ ( _u_ ) _du._\n\ufffd\n\nNow, make the transformation of variables _x_ _[r]_ _i_ [=] ~~_\u221a_~~ _u_ _[r]_ _ir_, hence _p_ ( _x_ _[r]_ _i_ [) =] _[ \u221a]_ ~~_[r]_~~ _[p]_ [(] _[u][r]_ _i_ [=] _[ \u221a]_ ~~_[r]_~~ _[x][r]_ _i_ [)][ and denote the]\ncharacteristic function of _x_ _[r]_ _i_ [as] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)][. Using the time-scaling property of the Fourier transform, we can]\nderive the characteristic function of _x_ _[r]_ _i_ [in terms of] _[ \u03c6][U][ r]_ [(] _[\u03c9]_ [)][:]\n\n_\u03c6X_ _[r]_ ( _\u03c9_ ) = exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _x_ \ufffd _p_ ( _x_ ) _dx,_\n\ufffd\n\n= _[\u221a]_ _r_ exp \ufffd _\u2212i\u03c9_ _[\u22a4]_ _x_ \ufffd _p_ ( _u_ = _[\u221a]_ _rx_ ) _dx,_\n\ufffd\n\n1\n= _[\u221a]_ _r_ exp _\u2212i\u03c9_ _[\u22a4]_ _[u]_ _p_ ( _u_ ) _du,_\n\ufffd ~~_\u221ar_~~ \ufffd ~~_\u221ar_~~ \ufffd\n\n= exp _\u2212i\u03c9_ _[\u22a4]_ _[u]_\n\ufffd \ufffd ~~_\u221ar_~~\n\n_p_ ( _u_ ) _du,_\n\ufffd\n\n_\u03c9_\n= _\u03c6U r_ _._ (15)\n\ufffd ~~_\u221ar_~~ \ufffd\n\nNow, as _v_ _[r]_ = [\ufffd] _[r]_ _i_ =1 _[x]_ _i_ _[r]_ [, we use the property that the density of a sum of] _[ r]_ [ independent random variables]\nis given by the _r_ -fold convolution of the individual PDFs. As convolution in the spatial domain is equal to\nmultiplication in the frequency domain, the density _p_ ( _v_ _[r]_ ) is:\n\n_p_ ( _v_ _[r]_ ) = _F_ _[\u2212]_ [1] [( _\u03c6X_ _r_ ) _[r]_ ] ( _v_ _[r]_ ) _,_\n\n= _F_ _[\u2212]_ [1] [exp ( _r_ log _\u03c6X_ _[r]_ )] ( _v_ _[r]_ ) _,_\n\n= _F_ _[\u2212]_ [1] [exp ( _rKX_ _[r]_ [)] (] _[v][r]_ [)] _[,]_ (16)\n\nwhere _KX_ _[r]_ [(] _[\u03c9]_ [) := log] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)][ is the] _[ cumulant generating function]_ [ (also known as the second characteristic]\nfunction) for _Xi_ _[r]_ [. From Eq. (][15][):]\n\n_KX_ _[r]_ [(] _[\u03c9]_ [) = log] _[ \u03c6][X]_ _[r]_ [(] _[\u03c9]_ [)] _[,]_\n\n_\u03c9_\n= log _\u03c6U r_\n\ufffd ~~_\u221ar_~~\n\n_,_\n\ufffd\n\n_\u03c9_\n= _KU_ _[r]_ _,_\n\ufffd ~~_\u221ar_~~ \ufffd\n\nwhere _KU r_ ( _\u00b7_ ) is the cumulant generating function for _u_ _[r]_ _i_ [. We now make a 4th order Taylor series expansion]\n\nof _rKU r_ \ufffd ~~_\u221a_~~ _\u03c9r_ \ufffd about _\u03c9_ = 0:\n\n_\u03c9_\n_rKU r_ = _r KU r_ (0)\n\ufffd ~~_\u221ar_~~ \ufffd \ufffd ~~\ufffd~~ \ufffd ~~\ufffd~~\n\n=log 1=0\n\n_\u2202KU_ _[r]_ ( _\u03c9_ = 0)\n_\u03c9i_ _\u2202\u03c9i_\n_i_\n\n+ _[\u221a]_ _r_ \ufffd\n\n_[r]_ ( _\u03c9_ = 0) + [1]\n\n_\u2202\u03c9i_ 2!\n\n2!\n\n_\u2202\u03c9i\u2202\u03c9j_\n\n_\u2202_ [2] _KU_ _[r]_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j_ _\u2202\u03c9i\u2202\u03c9j_\n\n_i,j_\n\n\ufffd\n\n1\n+\n3! ~~_[\u221a]_~~ ~~_r_~~\n\n_\u2202_ [3] _KU r_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j\u03c9k_ _\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_\n\n_i,j,k_\n\n\ufffd\n\n_KU r_ ( _\u03c9_ = 0) + [1]\n\n_\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_ 4!\n\n4! _r_\n\n_KU r_ ( _\u03c9_ = 0) 1\n\n+ _o_\n_\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_ \ufffd _r_\n\n_r_\n\n_\u2202_ [4] _KU r_ ( _\u03c9_ = 0)\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l_ _\u2202\u03c9i\u2202\u03c9j\u2202\u03c9k_\n\n_i,j,k,l_\n\n\ufffd\n\n_,_\n\ufffd\n\n_\u03c9i\u03ba_ [1] _i_ [+] 2! [1]\n_i_\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03ba_ [3] _i,j,k_\n\n_i,j,k_\n\n= _[\u221a]_ _r_\n\ufffd\n\n2!\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03ba_ [2] _i,j_ [+] 3! ~~_[\u221a]_~~ ~~_r_~~\n\n_i,j_\n\n+ [1]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_r_\n\n_,_\n\ufffd\n\n_\u03c9i\u03ba_ [1] _i_ [+] 2! [1]\n_i_\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03ba_ [3] _i,j,k_ [+] _[ R]_ [(] _[\u03c9]_ [)] _[,]_ (17)\n\n_i,j,k_\n\n= _[\u221a]_ _r_\n\ufffd\n\n2!\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03ba_ [2] _i,j_ [+] 3! ~~_[\u221a]_~~ ~~_r_~~\n\n_i,j_\n\n23\n\n[(] _[\u03c9]_ [=0][)]\nwhere _\u03ba_ _[n]_ _\u00b7_ [is an] _[ n]_ [-th order cumulant (i.e.] _[ \u03ba][n]_ _i_ [:=] _[ \u2202K][U]_ _\u2202\u03c9_ _[r]_ _i_ ) and\n\n_R_ ( _\u03c9_ ) := [1]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_r_\n\n_,_\n\ufffd\n\n1\ndenotes the 4th order polynomial and _o_ \ufffd _r_\n\n1\ndenotes the 4th order polynomial and _o_ \ufffd _r_ \ufffd denotes the higher order remainder terms. We now state some facts\n\nabout cumulants to simplify the above expansion. For a symmetric random vector like _u_ _[r]_ under Assumption 3,\nall odd-order cumulants are zero, i.e. _\u03ba_ _[i]_ _\u00b7_ [= 0][ for odd] _[ i]_ [ (][McCullagh][,][ 2013][;][ 1987][). The second-order cumulant]\nterm coincides with the covariance matrix product: [\ufffd] _[\u03c9][i][\u03c9][j][\u03ba]_ [2] [=] _[ \u2212][\u03c9][\u22a4]_ [\u03a3] _[r][\u03c9]_ [ (][McCullagh][,][ 1987][). Moreover,]\n\nterm coincides with the covariance matrix product: [\ufffd] _i,j_ _[\u03c9][i][\u03c9][j][\u03ba]_ [2] _i,j_ [=] _[ \u2212][\u03c9][\u22a4]_ [\u03a3] _[r][\u03c9]_ [ (][McCullagh][,][ 1987][). Moreover,]\n\nas 4th order moments of _u_ _[r]_ exist from Lemma 1 then all cumulants up to including order 4 exist since\ncumulants are polynomial functions of the moments (Leonov & Shiryaev, 1959; McCullagh, 1987). Finally,\nwe use _\u03c9_ _[\u22a4]_ \u03a3 _[r]_ _\u03c9_ = _\u2225\u03c9\u2225_ [2] _\u03c3r_ [2] [from Lemma][ 1][. Substituting these results into Eq. (][17][) and using] _[ R]_ [(] _[\u03c9]_ [)][ to denote]\nyields:\n\n_\u03c9_\n_rKU r_\n\ufffd ~~_\u221ar_~~\n\n= _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] + _R_ ( _\u03c9_ ) _,_\n\ufffd 2\n\n= _\u21d2_ exp ( _rKX_ _[r]_ [(] _[\u03c9]_ [)) = exp] _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] + _R_ ( _\u03c9_ ) _,_\n\ufffd 2 \ufffd\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n_\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n= exp\n\ufffd 2\n\n1 + [1]\n\uf8ed 4!\n\nexp ( _R_ ( _\u03c9_ )) _,_\n\ufffd\n\n1\n1 + _R_ ( _\u03c9_ ) + _o_\n\ufffd\ufffd \ufffd _r_\n\n_,_\n\ufffd\ufffd\n\n\ufffd [\uf8eb]\n\n_r_\n\n_,_\n\n\ufffd [\uf8f6]\n\n\uf8f8\n\n\ufffd [\uf8f6]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\nwhere we have used the Taylor series expansion of exp( _x_ ) about _x_ = 0 to derive the fourth line. Substituting\ninto Eq. (16) yields:\n\n_p_ ( _v_ _[r]_ ) = exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp ( _rKX_ _[r]_ [(] _[\u03c9]_ [))] _[ d\u03c9,]_\n\ufffd\n\n\ufffd [\uf8eb]\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n1 + [1]\n\uf8ed 4!\n\n_r_\n\n_d\u03c9,_\n\n\ufffd [\uf8f6]\n\n\uf8f8\n\n\ufffd [\uf8f6]\n\n4! _r_\n\n1\n\n\ufffd _\u03c9i\u03c9j\u03c9k\u03c9l\u03ba_ [4] _i,j,k,l_ [+] _[ o]_ \ufffd _r_\n\n_i,j,k,l_\n\n\ufffd\n\n_d\u03c9_\n\ufffd\n\n+ [1]\n\n4! _r_\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_\n\n_i,j,k,l_\n\n\ufffd\n\n_\u03c9i\u03c9j\u03c9k\u03c9l_ exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\n1\n_d\u03c9_ + _o_ _,_\n\ufffd \ufffd _r_ \ufffd\n\n= exp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2] _d\u03c9_\n\ufffd \ufffd 2 \ufffd\n\n1\n_d\u03c9_ + _o_\n\ufffd \ufffd _r_\n\n_._\n\ufffd\n\n+ [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_\n\nexp( _i\u03c9_ _[\u22a4]_ _v_ _[r]_ ) exp _\u2212_ _[\u2225][\u03c9][\u2225]_ [2] _[\u03c3]_ _r_ [2]\n\ufffd \ufffd 2\n\nNow, recognising that exp _\u2212_ _[\u2225][\u03c9][\u2225]_ 2 [2] _[\u03c3]_ _r_ [2] is the characteristic function for _g_ ( _v_ _[r]_ ) yields our desired result:\n\ufffd \ufffd\n\n_p_ ( _v_ _[r]_ ) = _F_ _[\u2212]_ [1] [ _F_ [ _g_ ]]( _v_ _[r]_ ) + [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202_ [4] 1\n\n_F_ _[\u2212]_ [1] [ _F_ [ _g_ ]]( _v_ _[r]_ ) + _o_\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) + [1]\n\n4! _r_\n\n_\u2202_ [4]\n_\u03ba_ [4]\n_i,j,k,l_ \ufffd _i,j,k,l_ _\u2202vi_ _[r][\u2202v]_ _j_ _[r]_\n\n\ufffd\n\n_\u2202_ [4] 1\n\n_g_ ( _v_ _[r]_ ) + _o_\n_\u2202vi_ _[r][\u2202v]_ _j_ _[r][\u2202v]_ _k_ _[r][\u2202v]_ _l_ _[r]_ \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) + [1]\n\n_\u03ba_ [4]\n\n\ufffd _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[,]_\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\n24\n\nwhere _\u03c1_ ( _v_ _[r]_ ) denotes the remainder terms.\n\nWe now provide uniform bounds on the remainder term of the expansion using the techniques of (Bhattacharya\n& Ranga Rao, 1976, Theorem 19.2) and analyse convergence rate of the limiting Gaussian distribution to a\nunit Gaussian:\n**Lemma 3.** _Let \u03c3_ 0 [2] = 1 _, let g_ ( _v_ _[r]_ ) _be the limiting Gaussian from Eq._ (14) _, let f_ ( _v_ _[r]_ ) _be a bounded function and_\n_let g\u221e_ ( _v_ _[r]_ ) = _N_ (0 _, Imn_ ) _. Let Assumptions 1 and 2 hold and let v_ _[r]_ = _vec_ ( _Z_ _[r]_ ) _and ui be defined in Eq._ (10) _._\n_Define the Edgeworth remainder as:_\n\n_R_ ( _v_ _[r]_ ) = _p_ ( _v_ _[r]_ ) _\u2212_ _g_ ( _v_ _[r]_ ) _._\n\n_Then:_\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_\n\ufffd \ufffd _r_\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_ _,_\n\ufffd _r_ \ufffd\n\n1\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd \ufffd _r_\n\n_r_\n\n_r_\n\n_._\n\ufffd\n\n_Proof._ We start by bounding \ufffd _f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ . From Lemma 2, we have shown that the Edgeworth\nexpansion for _p_ ( _v_ _[r]_ ) is controlled by 4th order cumulants and higher, that is;\n\n_p_ ( _v_ _[r]_ ) = _g_ ( _v_ _[r]_ ) + [1]\n\n\ufffd _\u03ba_ [4] _i,j,k,l_ _[H][i,j,k,l]_ [(] _[v][r][, \u03c3][r]_ [) +] _[ \u03c1]_ [(] _[v][r]_ [)] _[.]_ (18)\n\n_i,j,k,l_\n\n4! _r_ _[g]_ [(] _[v][r]_ [)] \ufffd\n\nWe show that the three assumptions needed to apply Bhattacharya & Ranga Rao (1976, Theorem 20.1) to\nobtain our result using Eq. (18). Firstly, the boundedness assumption of the integrand holds:\n\n_\u2225f_ ( _v_ _[r]_ ) _v_ _[r]_ _\u2225_\nsup _\u2264_ sup\n_v_ _[r]_ 1+ _\u2225v_ _[r]_ _\u2225_ _v_ _[r][ f]_ [(] _[v][r]_ [)] _[ <][ \u221e][.]_\n\nSecondly, the sampling regularity assumption that _ui_ (as defined in Eq. (10)) is zero-mean i.i.d. (satisfied\nunder Assumption 1) with finite 4th order moments (satisfied from Lemma 1) holds. Let _\u03c6U_ ( _\u03c9_ ) denote\nthe characteristic function of _p_ ( _u_ ), then the final assumption we need to verify is Cramer\u2019s condition:\nlim sup _\u2225\u03c9\u2225\u2192\u221e_ _\u03c6U_ ( _\u03c9_ ) _<_ 1, which is satisfied from the Riemann-Lebesgue lemma Folland (1999, Theorem 8.22) because _p_ ( _u_ ) is absolutely continuous under Assumption 1). Our first result thus follows from\napplying Bhattacharya & Ranga Rao (1976, Theorem 20.1):\n\n1\n_f_ ( _v_ _[r]_ ) _v_ _[r]_ _R_ ( _v_ _[r]_ ) _dv_ _[r]_ = _O_ _._\n\ufffd \ufffd _r_ \ufffd\n\n_r_\n\n_._\n\ufffd\n\nWe now derive our second result. Let _d_ := _[mn]_\n\n2 [. As] _[ g][\u221e]_ [(] _[v][r]_ [)][ and] _[ g]_ [(] _[v][r]_ [)][ are both Gaussians:]\n\n1\n_g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) =\n\ufffd _\u03c3r_\n\n_d_ _\u2225vr\u2225_ 2\nexp\n\ufffd \ufffd 2\n\n_r\u2225_ 2 _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\n2 2 _\u03c3_ [2]\n\n2 _\u03c3r_ [2]\n\n_,_\n\ufffd\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_r_\n\n=\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_d_ _\u2225vr\u2225_ 2\nexp\n\ufffd \ufffd 2\n\n_d_ 2\n1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n2 _r\u2225_ 2 _\u2212_ _rr\u2225_ + _v_ _[r]_ _\u03c3\u2225_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_,_\n\ufffd\n\n_d_ 2\nexp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_d_ 2\nexp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n_,_\n\ufffd\n\n_\u2212_ 1 _,_\n\ufffd \ufffd\n\n2\nwhere we have substituted for _\u03c3r_ [2] = 1 + _[\u03c3]_ _r_ _[\u03f5]_ from Lemma 1, hence:\n\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\n_\u2212_ 1 _dv_ _[r]_ _._\n\ufffd \ufffd\n\n_r_\n= _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ )\n\ufffd \ufffd _r_ + _\u03c3\u03f5_ [2]\n\n25\n\n_d_ 2\n1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_d_\nExpanding \ufffd _r_ + _r\u03c3\u03f5_ [2] \ufffd using the binomial expansion:\n\n_d_\n\n_r_ _\u03c3\u03f5_ [2]\n\n= 1 _\u2212_\n\n\ufffd _r_ + _\u03c3\u03f5_ [2] \ufffd \ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_d_\n\n_,_\n\ufffd\n\n_d\u03c3\u03f5_ [2] _d\u03c3\u03f5_ 2\n\n_r_ + _\u03c3\u03f5_ [2] [+] _[ o]_ \ufffd _r_ + _\u03c3_\n\n_d\u03c3\u03f5_ [2]\n= 1 _\u2212_\n\n_r_ + _\u03c3\u03f5_ [2]\n\n_,_\n\ufffd\n\n1\n= 1 + _O_\n\ufffd _r_\n\n_,_\n\ufffd\n\nhence:\n\n_vf_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _[\u2212]_ [1] _g_ ( _v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) 1 + exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd\ufffd\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\n1\n= 1 + _O_\n\ufffd \ufffd _r_\n\n_\u2212_ 1 _dv_ _[r]_ _._\n\ufffd \ufffd\n\nIt therefore suffices to show:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] )\n\nIt therefore suffices to show:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n1\n_\u2212_ 1 _dv_ _[r]_ = _O_\n\ufffd \ufffd \ufffd _r_\n\n_._\n\ufffd\n\nUsing the identity exp( _x_ ) _\u2212_ 1 _\u2264_ _x_ exp( _x_ ) for _x \u2265_ 0:\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2] _\u2212_\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n2\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_\u2212_ 1 _dv_ _[r]_\n\ufffd \ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n_\u2264_ _|f_ ( _v_ _[r]_ ) _|\u2225v\u2225g\u221e_ ( _v_ _[r]_ ) _[\u03c3]_ [2]\n\ufffd 2( _r_ + _\u03c3_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n2\n\n_\u03f5_ _[\u2225][v][r][\u2225]_ [2] _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n_[\u03c3]_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] ) [exp] \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n_dv_ _[r]_\n\ufffd\n\n= _g\u221e_ ( _v_ _[r]_ ) _[\u03c3]_ _\u03f5_ [2] _[|][f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3]\n\ufffd 2( _r_ + _\u03c3_ [2] )\n\n2\n\n_[f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3] exp _\u03c3\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd 2( _r_ + _\u03c3\u03f5_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_dv_ _[r]_\n\ufffd\n\n= 1 _\u03c3\u03f5_ [2] _[|][f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3]\n\ufffd (2 _\u03c0_ ) _[d]_ 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_[f]_ [(] _[v][r]_ [)] _[|\u2225][v][r][\u2225]_ [3] _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\nexp\n2( _r_ + _\u03c3\u03f5_ [2] ) \ufffd 2\n\n_[r][\u2225]_ [2] _\u03f5_ _[\u2225][v][r][\u2225]_ [2]\n\n+ _[\u03c3]_ [2]\n2 _r_ + _\u03c3_ [2]\n\n2( _r_ + _\u03c3\u03f5_ [2] )\n\n_,_\n\ufffd\n\n_\u03f5_\n_\u2264_ sup [(][2] _[\u03c0]_ [)] _[d][\u03c3]_ [2]\n_v_ _[|][f]_ [(] _[v][r]_ [)] _[|]_ 2( _r_ + _\u03c3\u03f5_ [2] )\n\n_\u2225v_ _[r]_ _\u2225_ [3] exp _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\ufffd \ufffd 2\n\n_r_\n\ufffd _r_ + _\u03c3\u03f5_ [2]\n\n_dv_ _[r]_\n\ufffd\ufffd\n\n_,_\n\n\ufffd ~~\ufffd~~ \ufffd ~~\ufffd~~\n= _O_ (1)\n\n1\n= _O_\n\ufffd _r_\n\n_,_\n\ufffd\n\nwhere our final line follows from the fact that fixed polynomials are integrable under the Gaussian distribution\nand _f_ ( _v_ _[r]_ ) is bounded by assumption, hence:\n\n1 1\n_vf_ ( _v_ _[r]_ ) _g_ ( _v_ _[r]_ ) _dv_ _[r]_ = 1 + _O_ _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_ _,_\n\ufffd \ufffd \ufffd _r_ \ufffd\ufffd\ufffd\ufffd \ufffd _r_ \ufffd\ufffd\n\n_r_\n\n1\n_v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd\ufffd\ufffd\ufffd \ufffd _r_\n\n_r_\n\n_,_\n\ufffd\ufffd\n\n1\n= _v_ _[r]_ _f_ ( _v_ _[r]_ ) _g\u221e_ ( _v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd _r_\n\n_,_\n\ufffd\n\nas required.\n\nUsing Lemma 3, we have all ingredients needed derive our main about the convergence result, which follows\nafter some algebra on the norm:\n**Theorem 2.** _Let Assumptions 1 and 2 hold and set \u03c3_ 0 = 1 _, then:_\n\n\u02c6 1\n_\u2225g_ True _\u2212_ _g_ LR _[r]_ _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n26\n\n_._\n\ufffd\n\n_Proof._ We start by converting the norm to vector form using Eq. (11):\n\n_\u03c3_ ( _g_ True _\u2212_ _g_ LR _[r]_ [) =][ E] _[E]_ [[] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ \u2212]_ [E] _[Z][r]_ [ [] _[Z]_ _[r][f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3Z]_ [)]] _[,]_\n\n= E _v_ [ _vf_ ( _\u00b5, v_ )] _\u2212_ E _vr_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] _,_ (19)\n\nwhere _f_ ( _\u00b5, v_ ) := _f_ ( _M_ = _\u00b5_ + _\u03c3_ mat( _v_ )) and _v_ = vec( _E_ ) is the vectorisation of variable _E_, which is distributed\nas _v \u223c_ _g\u221e_ ( _v_ ) =: _N_ (0 _, Imn_ ). Let _R_ ( _v_ _[r]_ ) denote the difference between _p_ ( _v_ _[r]_ ) and the limiting Gaussian\n\n1 _\u2212_ _[\u2225][v][r][\u2225]_ [2]\n\n(2 _\u03c0_ ) _[mn]_ _\u03c3r_ [2] [exp] \ufffd 2 _\u03c3r_ [2]\n\n:\n\ufffd\n\ndistribution _g_ ( _v_ _[r]_ ) := 1\n~~_\u221a_~~ (2 _\u03c0_ )\n\n2 _\u03c3r_ [2]\n\n_R_ ( _v_ _[r]_ ) := _p_ ( _v_ _[r]_ ) _\u2212_ _g_ ( _v_ _[r]_ ) _._\n\nUsing this notation:\n\nE _vr_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] = _p_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd\n\n= ( _g_ ( _v_ _[r]_ ) + _R_ ( _v_ _[r]_ )) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd\n\n= _g_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ + _R_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ _,_\n\ufffd \ufffd\n\nwhere _g_ ( _v_ _[r]_ ) is the limiting Gaussian density from Eq. (14) and _R_ ( _v_ _[r]_ ) is the Edgeworth remainder term as\ndefined in Lemma 2. Now, applying Lemma 3 to both integrals:\n\n1\nE _v_ _[r]_ [ _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ )] = _g\u221e_ ( _v_ _[r]_ ) _v_ _[r]_ _f_ ( _\u00b5, v_ _[r]_ ) _dv_ _[r]_ + _O_\n\ufffd \ufffd _r_\n\n1\n=E _v_ [ _vf_ ( _\u00b5, v_ )] + _O_ _._\n\ufffd _r_ \ufffd\n\nSubstituting into Eq. (19) yields our desired result:\n\n_,_\n\ufffd\n\n1\n_\u03c3_ ( _g_ True _\u2212_ _g_ LR _[r]_ [) =] _[ O]_\n\ufffd _r_\n\n_,_\n\ufffd\n\n_._\n\ufffd\n\n\u02c6 1\n= _\u21d2\u2225g_ True _\u2212_ _g_ LR _[r]_ _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n**B** **Mean Field Score Function Approximator**\n\n**B.1** **Bessel Functions**\n\nWe will use _n_ th order Bessel functions of the second kind _Kn_ ( _z_ ) (Basset, 1892; Macdonald, 1899; Watson,\n1944), which are conveniently represented by the integral equations:\n\n_\u221e_\n_Kn_ ( _z_ ) = exp( _\u2212z_ cosh _\u03b8_ ) cosh( _n\u03b8_ ) _d\u03b8._\n\ufffd0\n\nBessel functions are the solutions to systems of differential equations that occur naturally in phenomena\nwhere there is strong radial symmetry, typically involving the propagation of spherical waves from points\nlike the ripples formed from water droplets (Whitham, 1999). For our setting, Bessel functions describe the\nprobability density of the product of rotationally invariant random variables, whose solution is analogous to\nthe interference pattern of two spherical wave propagators.\n\nUsing the representation, we find the derivative of the zeroth order function takes the recursive form:\n\n_dK_ 0( _z_ )\n\nexp( _\u2212z_ cosh _\u03b8_ ) cosh( _\u03b8_ ) _d\u03b8_ = _\u2212K_ 1( _z_ ) _._ (20)\n0\n\n_\u221e_\n_dz_ 0( _z_ ) = _\u2212_ \ufffd0\n\nMore generally, the derivative of the _n_ th order Bessel function is Watson (1944, Section 3.71, Eq. 4):\n\n_dKn_ ( _z_ )\n\n_z_ _[K][n]_ [(] _[z]_ [)] _[ \u2212]_ _[K][n]_ [+1][(] _[z]_ [)] _[.]_ (21)\n\n_n_ _z_\n\n= _[n]_\n_dz_ _z_\n\n27\n\n**B.2** **Derivation of Mean-field Approximators**\n\nTo derive a mena-field approximation, we assume that the elements of _A_ and _B_ are drawn independently from\nthe set of generalised Gaussian distributions (GGDs):\n**Assumption 3.** _Assume each element ai,j \u223cGG_ ( _s, p_ ) _and bi,j \u223cGG_ ( _s, p_ ) _of A and B be independently_\n_distributed according to the zero-mean generalised Gaussian distribution GG_ ( _s, p_ ) _with density:_\n\n_p_ exp _\u2212_ _x_\n\n2 _s_ \u0393 1 \ufffd \ufffd\ufffd\ufffd _s_\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n_p_\n_GG_ ( _x|s, p_ ) =\n\n_s_\n\n_p_ [\ufffd]\n\n_,_\n\ufffd\ufffd\ufffd\n\n_where_ 0 _< s < \u221e_ _is the scale parameter, p >_ 0 _the shape parameter and_ \u0393( _\u00b7_ ) _is the gamma function._\n\nWe observe common distributions emerge from the set of GGDs including the Laplace for _p_ = 1, the Gaussian\nfor _p_ = 2 and the uniform over [ _\u2212s,_ + _s_ ] in the limit _p \u2192\u221e_ .\n\nIf we make the assumption that all elements of _Z_ are independent (this is true as _r_ grows) then we can write\n_p_ ( _Z_ _[r]_ ) _\u2248_ _p_ \u02c6( _Z_ ) := [\ufffd] _[m]_ _i_ =1 \ufffd _nj_ =1 _[p]_ [(] _[z][i,j]_ [)][ as the product of the marginal distributions. Under this approximation,]\nthe score function can be defined element-wise as:\n\n[ _\u2207Z_ log _p_ ( _Z_ _[r]_ )] _i,j \u2248_ _S_ [\u02c6] ( _zi,j_ ) := _\u2202zi,j_ log _p_ ( _zi,j_ ) _._\n\nUsing this approximation we apply the score function _S_ [\u02c6] ( _\u00b7_ ) element-wise to the matrix _Z_ :\n\n\u02c6\n_g_ LR _\u2248_ _g_ MF := _\u2212\u03c3_ E _Z\u223cp_ ( _Zr_ ) \ufffd _f_ ( _y_ = ( _\u00b5_ + _\u03c3Z_ ) _x_ ) _\u00b7_ _S_ [\u02c6] _\u2299_ ( _Z_ )\ufffd _._\n\nFor _r_ = 1, _S_ [\u02c6] ( _\u00b7_ ) has a convenient analytic form for all members of the set of GGDs with _\u03c3\u03f5 \u2248_ 0:\n**Theorem 3.** _Let Assumption 3 hold with \u03c3\u03f5_ = 0 _and r_ = 1 _. Then the distribution over marginals p_ ( _zi,j_ ) _is:_\n\n_p_\n\n_p_ 2 _|zi,j|_ 2\n_p_ ( _zi,j_ ) = 2 _[K]_ 0\n_s_ \u0393 1 \ufffd _s_ _[p]_\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd\n\n_,_ (22)\n\n_where K_ 0 ( _\u00b7_ ) _is the zeroth-order modified Bessel function of the second kind and the marginal score function is_\n_defined element-wise as:_\n\n\ufffd\n\n_p_ _p_\n\n_\u00b7_ _[p]_ 2 _|zi,j|_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_K_ 1\n\n\u02c6\n_S_ ( _zi,j_ ) = _\u2212_\n\n_K_ 0\n\n_p_\n2 _|zi,j_ _|_ 2\n\n_s_ _[p]_\n\ufffd\n\n_p_\n2 _|zi,j_ _|_ 2\n\n_s_ _[p]_\n~~\ufffd~~\n\n_._\n_s_ _[p]_\n\n_Proof._ For _r_ = 1, we denote the elements of vector _A_ as _ai_ and elements of vector _B_ as _bj_, then the elements\nof matrix _Z_ = _AB_ _[\u22a4]_ are: _zi,j_ = _aibj_ . We now derive the distribution the unnormalised variables: _zi,j_ using\nthe formula for the distribution of the product of two independent random variables (Rohatgi, 1976; Grimmett\n& Stirzaker, 1993):\n\n_\u221e_\n\n_p_ ( _ai_ ) _p_ _bj_ = _[z][i][,j]_\n_\u2212\u221e_ \ufffd _ai_\n\n_\u221e_\n_p_ ( _zi,j_ ) =\n\ufffd\n\n_ai_\n\n1\n\ufffd _|ai|_ _[da][i][,]_\n\n2\n\n_\u221e_\n\ufffd\n\n\ufffd\ufffd\ufffd\ufffd\n\n_p_ [\ufffd] 1\n\n_|ai|_ _[da][i][,]_\n\n_p_ [\ufffd] 1\n\n_|a_\n\n=\n\n\uf8eb\n\n_p_\n\n2 _s_ \u0393\n\n\uf8ed\n\n2 _s_ \u0393 1\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n\uf8f6\n\n\uf8f8\n\nexp _\u2212_ _ai_\n_\u2212\u221e_ \ufffd \ufffd\ufffd\ufffd _s_\n\n_s_\n\n_p_ [\ufffd] exp _\u2212_ _zi,j_\n\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd _ais_\n\n_p_ [\ufffd] 1\n\n_|ai|_ _[da][i][,]_\n\n_p_ [\ufffd] 1\n\n_|a_\n\n=2\n\n\uf8eb\n\n_p_\n\n2 _s_ \u0393\n\n\uf8ed\n\n2 _s_ \u0393 1\n~~\ufffd~~ _p_ ~~\ufffd~~\n\n\uf8f6\n\n\uf8f8\n\n2\n\n_\u221e_\n\ufffd0\n\nexp _\u2212_ _ai_\n0 \ufffd \ufffd\ufffd\ufffd _s_\n\n_s_\n\n_p_ [\ufffd] exp _\u2212_ _zi,j_\n\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd _ais_\n\n\ufffd\ufffd\ufffd\ufffd\n\n28\n\nwhere we have used symmetry of the integrand about 0 to derive the final line. Now, making the substitution\n_x_ = \ufffd _asi_ \ufffd _p_, we have:\n\n1\n\n_dai_ _p_ _[\u2212]_ [1]\n\n_dx_ [=] _[ sx]_\n\n_dai_\n\n_p_ 1\n\n_,_ _ai_ = _sx_ _p_\n_p_\n\nhence:\n\n1\n\ufffd _x_ _[dx.]_\n\n_|zi,j|_ _[p]_\n\n[1]\n\n_x_ _s_ [2] _[p]_\n\n_p_ 1\n_p_ ( _zi,j_ ) = _s_ \u0393 1 2 2\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd0 _\u221e_\n\n_\u221e_\n\nexp _\u2212x \u2212_ [1]\n0 \ufffd _x_\n\n_s_ [2] _[p]_\n\nNow, we use the identity (Temme, 1996, Theorem 9.42):\n\n1\n\ufffd _x_ _[dx,]_\n\n1\n\ufffd _x_\n\n_K_ 0( _x_ ) = [1]\n\n2\n\n\ufffd0 _\u221e_\n\n_\u221e_\n\nexp _\u2212x \u2212_ _[z]_ [2]\n0 \ufffd 4 _x_\n\n4 _x_\n\n_p_\n2\nwith _z_ = [2] _[|][z]_ _s_ _[i][,j][p]_ _[|]_ to yield:\n\n_p_\n\n_p_ 2 _|zi,j|_ 2\n_p_ ( _zi,j_ ) = 2 _[K]_ 0\n_s_ \u0393 1 \ufffd _s_ _[p]_\n~~\ufffd~~ ~~\ufffd~~ _p_ ~~\ufffd\ufffd~~\n\n\ufffd\n\n_,_\n\nas required for Eq. (22). Now we derive the marginal score function by applying the chain rule:\n\n\ufffd\n\n_,_\n\n\ufffd\n\n_\u2202zi,j_ log _p_ ( _zi,j_ ) = _\u2202zi,j_ log _K_ 0\n\n_p_\n2 _|zi,j|_ 2\n\n_s_ _[p]_\n\ufffd\n\n= _\u2202z_ log _K_ 0\n\n= _\u2202z_ log _K_ 0\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j][|]_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j][|]_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n_p|zi,j|_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n\n_,_\n_s_ _[p]_\n\n\ufffd\n\n_p_\n_\u2202zi,j_ 2 _|zi,j|_ 2 _,_\n_s_ _[p]_\n\n_p_\n2\n_z_ = [2] _[|][z][i][,j]_ _[|]_\n_s_ _[p]_\n\ufffd\n\n\ufffd\n\n_\u2202zK_ 0\n\n=\n\n_p_\n\n_K_ 0 _z_ = [2] _[|][z]_ _s_ _[i][,j][p]_ _[|]_ 2\n\n~~\ufffd~~\n\n_p_\n\n_\u00b7_ _[p][|][z][i][,j][|]_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_,_\n_s_ _[p]_\n\n_p_\n\n_K_ 1 2 _|zsi,j_ _[p]_ _|_ 2\n= _\u2212_ \ufffd _p_\n\n_K_ 0 2 _|zsi,j_ _[p]_ _|_ 2\n\n~~\ufffd~~\n\n\ufffd\n\n_p_\n\n_\u00b7_ _[p][|][z][i][,j][|]_ 2 _[\u2212]_ [1] sign( _zi,j_ )\n~~\ufffd~~ _s_ _[p]_\n\n_,_\n_s_ _[p]_\n\nwhere we have used the identity _\u2202zK_ 0( _x_ ) = _\u2212K_ 1( _x_ ) from Eq. (20)\n\nFor _r >_ 1 we can derive _S_ [\u02c6] ( _\u00b7_ ) for the Gaussian sampling case:\n**Theorem 4.** _Let Assumption 3 hold with \u03c3\u03f5_ = 0 _and p_ = 2 _. Then the distribution over marginals p_ ( _zi,j_ ) _is:_\n\n_r\u2212_ 1\n\n2\n\n_p_ ( _zi,j_ ) = [2] _[\u221a]_ ~~_[r]_~~ _[|\u221a]_ ~~_[r]_~~ _[z][i][,j][|]_ _r_\n\n2\n\n_._\n\ufffd\n\n2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\ufffd _s_ [2]\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n_and the score function is:_\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n_zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n_S_ \u02c6( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _, ._\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n29\n\n_Proof._ Let _ui,j_ = ~~_\u221a_~~ 1 _r_ _zi,j_ . Using the transformation of variables, we derive the density for _zi,j_ from _p_ ( _ui,j_ )\nusing: _p_ ( _zi,j_ ) = _[\u221a]_ ~~_r_~~ _p_ ( _ui,j_ = _[\u221a]_ ~~_r_~~ _zi,j_ ). Each element _ui,j_ is the sum of _r_ independent variables _ui,j,l_ := _ai,lbj,l_\ndistributed according to Eq. (22) with _p_ = 2:\n\n_r_\n\ufffd _ui,j,l_\n\n_l_ =1\n\n_ui,j_ =\n\n_r_ 1\n\ufffd _l_ =1 _ai,lbj,l_ = ~~_\u221ar_~~\n\nFrom Eq. (22), the distribution of each _ui,j,l_ is:\n\n2\n_p_ ( _ui,j,l_ ) =\n_s_ [2] _\u03c0_ _[K]_ [0]\n\n2 _|ui,j,l|_\n\ufffd _s_ [2]\n\n\ufffd\n\nWe use the fact that the PDF of a sum of _r_ independent random variables is given by the _r_ -fold convolution of\nthe individual PDFs. As convolution in the spatial domain is equal to multiplication in the frequency domain,\nthe PDF _p_ ( _ui,j_ ) follows by taking Fourier transform of _p_ ( _ui,j,l_ ), taking the power _r_ and then taking the inverse\nFourier transform:\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n_r_\n( _ui,j_ ) _,_\n\ufffd\ufffd \ufffd\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2] _\u03c0_\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n_r_\n_F_ _[\u2212]_ [1] _F_ _K_ 0\n\ufffd \ufffd \ufffd\n\nwhere _F_ [ _f_ ( _\u00b7_ )]( _\u03c9_ ) and _F_ _[\u2212]_ [1] [ _f_ [\u02c6] ( _\u00b7_ )]( _x_ ) denotes the Fourier and inverse Fourier transforms. Taking the Fourier\ntransform of the Bessel function:\n\n_F_ _K_ 0\n\ufffd\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n( _\u03c9_ ) = exp( _\u2212i\u03c9_ _[\u22a4]_ _x_ ) _K_ 0\n\ufffd\ufffd \ufffd\n\n2 _|x|_\n\ufffd _s_ [2]\n\n_dx,_\n\ufffd\n\n2 _|x|_\n\ufffd _s_ [2]\n\n_dx,_\n\ufffd\n\n= cos( _\u03c9x_ ) _K_ 0\n\ufffd\n\n= cos( _\u03c9x_ ) _K_ 0\n\ufffd\n\n2 _|x|_\n\n_dx \u2212_ _i_ sin( _\u03c9x_ ) _K_ 0\n\n\ufffd _s_ [2] \ufffd \ufffd\n\n2 _|x|_\n\n_dx,_\n\n\ufffd _s_ [2] \ufffd\n\n_dx,_ (23)\n\ufffd\n\n_\u221e_\n= 2 cos( _\u03c9x_ ) _K_ 0\n\ufffd0\n\n2 _x_\n\ufffd _s_ [2]\n\n2 _|x|_\nwhere we have used the fact thatsecond line is zero. Using a standard result, we can evaluate the integral in Eq. ( _K_ 0 \ufffd _s_ [2] \ufffd is an even function of _x_ and so its integral with23) Gradshte sin(\u02d8\u0131n et al. _\u03c9x_ ) ( in the2015,\n\n6.671 Integral 14):\n\n_F_ _K_ 0\n\ufffd\n\n2 _|\u00b7|_\n\ufffd _s_ [2]\n\n_\u03c0_\n( _\u03c9_ ) =\n\ufffd\ufffd _\u03c9_ [2] +\n~~\ufffd~~\n\n2\n_\u03c9_ [2] + ~~\ufffd~~ _s_\n\n_s_ 2 [2] ~~\ufffd~~ 2 _[,]_\n\n30\n\nhence:\n\n_s_ 2 [2] ~~\ufffd~~ 2 ~~[\ufffd]~~ ~~_[r]_~~ 2\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2] _\u03c0_\n\n_r_\n_F_ _[\u2212]_ [1]\n\ufffd\n\n\uf8ee\n\n_\u03c0_ _[r]_\n\n2\n\uf8ef\uf8f0 ~~\ufffd~~ _\u03c9_ [2] + ~~\ufffd~~ _s_ [2]\n\n\uf8f9\n\n\uf8fa ( _ui,j_ ) _,_\n\uf8fb\n\n\uf8f9\n\n2\n\n\uf8fb ( _ui,j_ ) _,_\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_\n_F_ _[\u2212]_ [1]\n\ufffd\n\n\uf8ee\n\n\uf8f0\n\n\ufffd\n\n_[r]_\n\n2 [\uf8f9]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\n\ufffd\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\nexp( _i\u03c9ui,j_ )\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\ncos( _\u03c9ui,j_ )\n\ufffd\ufffd\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n_s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9_\n\n\ufffd\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n+ _i_ sin( _\u03c9ui,j_ )\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_,_\n\n\ufffd\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_r_ 1\n\ufffd 2 _\u03c0_\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\ncos( _\u03c9ui,j_ )\n\ufffd\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\n_r_ 1\n\ufffd _\u03c0_\n\n2\n\n=\n\ufffd _s_ [2]\n\n2\n\n=\n\ufffd _s_ [2]\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\n_d\u03c9,_ (24)\n\n\ufffd\n\n2 [\ufffd] _[\u2212]_ _[r]_ 2\n\ufffd\n\n_\u221e_\n\ncos( _\u03c9ui,j_ )\n\n\ufffd0\n\n\ufffd0 _\u221e_\n\n\ufffd\n\n2\n_\u03c9_ [2] +\n\ufffd _s_ [2]\n\n_s_ [2]\n\nwhere we have used the fact that the integrand is an even function and so its integral with sin( _\u03c9zi,j_ ) is zero\nto derive the penultimate line. To evaluate the integral in Eq. (24) we apply Gradshte\u02d8\u0131n et al. (2015, 3.771\nIntegral 2):\n\n_r_ 1\n\n_\u00b7_\n\ufffd ~~_\u221a\u03c0_~~ \u0393 ~~\ufffd~~ 2 _r_\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n2\n_p_ ( _ui,j_ ) =\n\ufffd _s_ [2]\n\n2\n_s_ _|ui,j|_\n2 _r_ ~~\ufffd~~ \ufffd 4\n\n2\n\n_\u00b7 K r\u2212_ 1\n\n2 _|ui,j|_\n\n_,_\n\n\ufffd _s_ [2] \ufffd\n\n4\n\n\ufffd _[r][\u2212]_ 2 [1]\n\n2\n\n_r\u2212_ 1\n= 2 _|ui,j|_ 2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|ui,j|_\n\n_._\n\n\ufffd _s_ [2] \ufffd\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n2\n\nUsing the transformation of variables yields our desired results:\n\n_p_ ( _zi,j_ ) = _[\u221a]_ _rp_ ( _ui,j_ = _[\u221a]_ _rzi,j_ ) _,_\n\n_r\u2212_ 1\n\n2\n\n= [2] _[\u221a]_ ~~_[r]_~~ _[|\u221a]_ ~~_[r]_~~ _[z][i][,j][|]_\n\n2\n\n_r_ _\u00b7 K r\u2212_ 2 1\n\n2 ~~\ufffd~~\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\n_._\n\n\ufffd _s_ [2] \ufffd\n\n_s_ _[r]_ [+1] ~~_[\u221a]_~~ ~~_\u03c0_~~ \u0393 _r_\n~~\ufffd~~ 2\n\n2\n\nNow, we derive the score function:\n\n_,_\n\ufffd\n\n_\u2202zi,j_ log _p_ ( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n2\n\n2 _\u00b7 \u2202zi,j_ log _|_ _[\u221a]_ _rzi,j|_ + _\u2202zi,j_ log _K r\u2212_ 2 1\n\n2 _|\u221a_ ~~_r_~~ _zi,j|_\n\ufffd _s_ [2]\n\n_x_ = [2] _[|]_ ~~_[\u221a]_~~ _[rz][i][,j]_ _[|]_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n+ [2] _[\u2202][z][i,j]_ _[|\u221a]_ ~~_[r]_~~ _[z][i,j][|]_\n2 _zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n_\u2202xK r\u2212_ 1\n\n_[|\u221a]_ ~~_[r]_~~ _[z][i,j][|]_ 2\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n_x_ = [2] _[|]_ ~~_[\u221a]_~~ _[rz][i][,j]_ _[|]_\n\ufffd _s_ [2] \ufffd\n\n_[ \u2212]_ [1]\n\n+ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _\u2202xK r\u2212_ 2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n31\n\nNow, from Eq. (21):\n\n_[\u2212]_ [1]\n\n2 [(] _[x]_ [)] _[ \u2212]_ _[K][ r]_ [+] 2 [1]\n\n_\u2202xK r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_r\u2212_ 1\n\n_r\u2212_\n\n2 _x_ _[K][ r][\u2212]_ [1]\n\n[+][1]\n\n2 [(] _[x]_ [)]\n\n=\n\n_K r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_,_\n\n_K r\u2212_ 1\n\n2 [(] _[x]_ [)]\n\n_[ \u2212]_ [1] _\u2212_ _K_ _r_ +2 1\n\n2 _x_ _K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n+1\n\n2 [(] _[x]_ [)]\n\n_\u2212_ 1\n\n2 [(] _[x]_ [)] _[,]_\n\n_K r\u2212_ 1\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_K r\u2212_ 1\n\n_[ \u2212]_ [1]\n\n+ [(] _[r][ \u2212]_ [1][)][si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ 2 _|zi,j|_\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n= _\u21d2_ _\u2202zi,j_ log _p_ ( _zi,j_ ) = _[r][ \u2212]_ [1]\n\n[1][)][si][g][n][(] _[z][i][,j]_ [)]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _|zi,j|_ _s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n_K r\u2212_ 1\n\n_[ \u2212]_ [1]\n\n+ [(] _[r][ \u2212]_ [1][)]\n2 _zi,j_ 2 _zi,j_\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n= _[r][ \u2212]_ [1]\n\n_[ \u2212]_ [1][)]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n2 _zi,j_ _s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\n_[ \u2212]_ [1]\n\n_\u2212_ [2] _[\u221a]_ ~~_[r]_~~ [si][g][n][(] _[z][i][,j]_ [)]\n_zi,j_ _s_ [2]\n\n_K r\u2212_ 1\n\n= _[r][ \u2212]_ [1]\n\n[g][n][(] _[z][i][,j]_ [)] _K_ _r_ +2 1\n\n_s_ [2]\n\n2\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_\n\ufffd _s_ [2] \ufffd\n\n2 _|_ ~~_[\u221a]_~~ _rzi,j_ _|_ _,_\n~~\ufffd~~ _s_ [2] ~~\ufffd~~\n\n2\n\nas required.\n\n32\n\n**C** **EGG Architecture**\n\nIn the following section, we detail the design of our EGG model, which follows the high-level structure of\nmodern pre-layernorm decoder-only language models, but replaces self-attention with a modified minGRU and\nstandard layernorms with a custom variant to enable pure integer training. See Algorithm 2 for an overview of\nthe forward pass of the EGG architecture.\n\n**Algorithm 2** EGG forward pass\n\n**Require:** Input token _t \u2208_ U8, input state _s \u2208_ I _[l]_ 8 _[\u00d7][D]_, network parameters _\u03b8_\n**Ensure:** Output vector _y \u2208_ I _[D]_ 8 [and output state] _[ s][\u2032][ \u2208]_ [I] _[l]_ 8 _[\u00d7][D]_\n_s_ _[\u2032]_ _\u2190_ I _[l]_ 8 _[\u00d7][D]_ initialized to 0\n_y \u2190_ EMBED( _\u03b8_ emb _, t_ )\n**for** _i \u2208{_ 0 _, . . ., l \u2212_ 1 _}_ **do**\n\n_y_ _[\u2032]_ _, s_ _[\u2032]_ _i_ _[\u2190]_ [GRU][(] _[\u03b8]_ [gru] _[,i][,]_ [ LN][(] _[\u03b8]_ [ln1] _[,i][, y]_ [)] _[, s][i]_ [)]\n_y \u2190_ I8(I32( _y_ _[\u2032]_ ) + I32( _y_ ))\n_y_ _[\u2032]_ _\u2190_ MLP( _\u03b8_ mlp _,i,_ LN( _\u03b8_ ln2 _,i, y_ ))\n_y \u2190_ I8(I32( _y_ _[\u2032]_ ) + I32( _y_ ))\n**end for**\n_y \u2190_ LN( _\u03b8_ lnout _,i, y_ )@ _\u03b8_ head _[T]_\n\n**C.1** **Notation and Operations**\n\nWe use the constant _l \u2208_ E [+] to denote the number of layers of the model and _D_ = 4 _[d]_ as the hidden dimension\nof the model, where _d \u2208_ E [+] .\n\nWe use I _n_ to denote an _n_ -bit signed integer and U _n_ to denote an _n_ -bit unsigned integer. We denote casting\nvector _\u20d7x_ to format I _n_ as I _n_ ( _\u20d7x_ ), which implicitly includes clipping to the bounds of the datatype. To ensure\nsymmetry between positive and negative values of each datatype, we consider the value _\u2212_ 2 _[n][\u2212]_ [1] to be invalid\nfor datatype I _n_ ; for instance, for 8-bit signed integers we only allows value from -127 to 127.\n\nWe use the following operations:\n\n    - _\u20d7x_ @ _M_ indicating scaled vector-matrix multiplication of I _[n]_ 8 _[\u00d7]_ [I] _[n,m]_ 8 _\u2192_ I _[m]_ 8 [, corresponding to int8 tensor]\ncore multiplication with int32 accumulation and scaling. The details of this operation are described\nin the next subsection.\n\n    - _a \u00b7 b_ indicates dot product with int32 accumulation, I _[n]_ 8 _[\u00d7]_ [ I] _[n]_ 8 _[\u2192]_ [I][32][, and] _[ a][ \u2299]_ _[b]_ [ indicates the Hadamard]\n(elementwise) product.\n\n    - Standard integer operations: + for addition, _\u2212_ for subtraction, and _\u2299_ for element-wise multiplication.\n\n    - _|x|_ indicates taking the element-wise absolute value of _x_, I _[n]_ _\u2192_ I _[n]_ .\n\n    - sign( _x_ ) indicates taking the element-wise sign of _x_, giving 1 for positive values, -1 for negative\nvalues, and 0 for zero.\n\n   - sum( _x_ ) indicates taking the sum of all elements in _x_ (casting to I32 to prevent overflow): I _[n]_ _\u2192_ I32.\n\n    - _x \u226b_ _n_ indicates an elementwise bitwise right shift by _n_, which is typically equivalent to 2 _[\u2212][n]_ _x_ .\nSimilarly, _x \u226a_ _n_ indicates a bitwise left shift by _n_, which is typically equivalent to 2 _[n]_ _x_ .\n\n    - Square-bracket indexing. For instance _M_ [ _x, y_ ] extracts the element at index _x_ in axis 0 and index _y_\nin axis 1, following the zero-based indexing convention.\n\n**C.2** **Parameter Initialization**\n\nThe standard initialization for matrix parameters in our model is rounding 16 times a sample from the standard\nnormal, and casting to I8. This can be precomputed on a CPU since this is only done once at the start of\ntraining.\n\n33\n\nThe egg model has the following parameters (where an additional subscript of _i_ indicates that there is a version\nof this parameter for each layer of the model):\n\n    - _\u03b8_ emb _\u2208_ I [256] 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ head _\u2208_ I [256] 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ lnout _\u2208_ I _[D]_ 8 [, initialized to 16 for each element.]\n\n    - _\u03b8_ ln1 _,i, \u03b8_ ln2 _,i \u2208_ I _[D]_ 8 [, initialized to 16 for each element]\n\n    - _\u03b8_ mlp _,i,_ 1 _\u2208_ I [4] 8 _[D][\u00d7][D]_ and _\u03b8_ mlp _,i,_ 2 _\u2208_ I _[D]_ 8 _[\u00d7]_ [4] _[D]_, following standard initialization.\n\n    - _\u03b8_ GRU _,i,_ [Wf,Uf,Wh,Uh] _\u2208_ I _[D]_ 8 _[\u00d7][D]_, following standard initialization.\n\n    - _\u03b8_ GRU _,i,_ [bfm bh] _\u2208_ I _[D]_ 8 [, initialized to 0 for each element.]\n\nIn total there are 513 _D_ + _l_ (4 _D_ + 12 _D_ [2] ) parameters in the model.\n\n**C.3** **Matrix Multiplication**\n\nTensor cores in GPUs are able to calculate fast vector-matrix multiplications with int32 accumulation as\n_xM \u2208_ I _[m]_ 32 [where] _[ x][ \u2208]_ [I] _[n]_ 8 [and] _[ M][ \u2208]_ [I] _[n]_ 8 _[\u00d7][m]_ . For our purposes, we define _x_ @ _M_ as a scaled multiplication:\n\n_x_ @ _M_ := I8( _[xM]_\n\n16 ~~_[\u221a]_~~ ~~_n_~~ [)] _[.]_\n\nNote that when _n_ = 4 _[d]_, the division operation just becomes a right-shift by 4 + _d_, which is fast to calculate.\n\nWe choose this scaled matrix multiplication because we initialize _M_ to 16 times standard normal samples for\neach element, so dividing by 16 _[\u221a]_ ~~_n_~~ preserves the magnitude of _x_ for the output. In particular, if all elements\nof _x_ and _M_ are drawn from independently from the standard normal distribution multiplied by 16, the central\nlimit theorem tells us that the expected value per element of the output will be 256 _[\u221a]_ ~~_n_~~ ~~,~~ so dividing by 16 _[\u221a]_ ~~_n_~~\npreserves the standard deviation of 16.\n\n**C.4** **Embedding**\n\nOur embedding function takes as input an embedding matrix _\u03b8_ emb _\u2208_ I [256] 8 _[\u00d7][D]_ and an input token _t \u2208_ U8, and\nsimply outputs the vector corresponding to that token: _\u03b8_ emb[ _t_ ] _\u2208_ I _[D]_ 8 [.]\n\n**C.5** **Layer Normalization (LN)**\n\nOur layer normalization operation involves multiplying our input _x \u2208_ I _[D]_ 8 [with a weight] _[ \u03b8]_ [ln] _[\u2208]_ [I] _[D]_ 8 [before]\ndividing by the mean absolute value of _x_ .\n\nWe decide to divide by the mean absolute value of the input instead of the more more common root-meansquared since square roots are expensive on integers. Note that the _L_ 1 norm after dividing the input by the\nmean absolute value (when using real numbers) is _D_ instead of 1, which we intentionally choose to preserve\nmore bits of information given the limited range of I8.\n\nWe calculate the mean absolute value of input _x_ as:\n\n_x_ mav = I8(sum( _|x|_ ) _\u226b_ (2 _d_ )) _,_\n\nNote that we can safely cast the mean absolute value to an I8 without overflow given the properties of the\nmean of a set, though we lose precision due to truncating the fractional component.\n\nThe output of layernorm is calculated as:\n\nDIVIDE(I16( _x_ ) _\u2299_ I16( _\u03b8_ ln) _, x_ mav) _._\n\nSince division is an expensive operation, we precompute it using a lookup table. Note that the product of two\nI8 values will always remain in the dynamic range of I16, so our lookup table will be of shape 2 [16] _\u00d7_ 2 [8] .\n\n34\n\n**C.6** **MLP**\n\nEach MLP block consists of two weight parameters: _\u03b8_ 1 _\u2208_ I [4] 8 _[D][\u00d7][D]_ and _\u03b8_ 2 _\u2208_ I _[D]_ 8 _[\u00d7]_ [4] _[D]_ . Given an input _x \u2208_ I _[D]_ 8 [,]\nwe calculate the output as:\n\n( _x_ @ _\u03b8_ 1 _[T]_ [)@] _[\u03b8]_ 2 _[T]_ _[.]_\n\nNote that we do not use an activation function, because the @ operation is already nonlinear due to the saturated\nconversion from I32 to I8\n\n**C.7** **GRU**\n\nEach GRU block accepts an input vector and state _x, s_ _\u2208_ I _[D]_ 8 consists of 6 weight parameters:\n_\u03b8_ Wf _, \u03b8_ Uf _, \u03b8_ Wh _, \u03b8_ Uh _\u2208_ I _[D]_ 8 _[\u00d7][D]_ and _\u03b8_ bf _, \u03b8_ bh _\u2208_ I _[D]_ 8 [.]\n\nUsing these weight matrices, we calculate the following vectors:\n\n_f_ = _\u03c3_ (I8(I32( _x_ @ _\u03b8_ Wf _[T]_ [) +][ I][32][(] _[s]_ [@] _[\u03b8]_ Uf _[T]_ [) +][ I][32][(] _[\u03b8]_ [bf][)))] _[,]_\n\n\u02c6\n_f_ = I8(((I32( _f_ ) + 127) _\u2299_ I32( _s_ )) _\u226b_ 8) _,_\n\n\u02c6\n_h_ = _\u03d5_ (I8(I32( _x_ @ _\u03b8_ Wh _[T]_ [) +][ I][32][( \u02c6] _[f]_ [@] _[\u03b8]_ Uh _[T]_ [) +][ I][32][(] _[\u03b8]_ [bh][)))] _[,]_\n\n_h_ = _s_ + I8(((I32( _f_ ) + 127) _\u2299_ (I32( _h_ [\u02c6] ) _\u2212_ I32( _s_ ))) _\u226b_ 8) _,_\n\nwhere _h_ is the output and the new hidden state. In the typical GRU, _\u03c3_ stands for the sigmoid function while _\u03d5_\nstands for the hyperbolic tangent, but we find that setting these as identity operations is sufficient due to the\nnonlinearity already present in the clipped addition. One can view this clipped addition operation as scaled\nand shifted version of the \u201chard\" tanh and sigmoid operators.\n\nTo explain why we perform these operations, we can analyze this relative to the original GRU. The _f_ vector\nfor the standard GRU has all elements between 0 and 1 due to the sigmoid, but our elements are between -127\nand 127. Therefore, to calculate _f_ [\u02c6] (which is typically just _f \u2299_ _s_ ), we first add 127 to _f_, getting the range\nbetween 0 and 254 before multiplying by _s_ before bit-shifting right by 8 again to bring our values back to the\nI8 dynamic range. We apply similar logic to calculate the final _h_, which is typically just _h_ = _s_ + _f \u2299_ ( _h_ [\u02c6] _\u2212_ _s_ )\nbut needs to be rescaled to keep the int8 dynamic range.\n\n**C.8** **Fitness Calculation in Integer Types**\n\nThe \u201cfitness\u201d used in language model pretraining is the log-likelihood of correctly generating the next token,\ntreating the outputs of the language model as logits (unnormalized log probabilities). If _t_ _[\u2032]_ _\u2208_ U8 is the next\ntoken to predict and _y \u2208_ I [256] 8 are the logits, we can calculate the log likelihood as follows:\n\n_y_ _[\u2032]_ = I32( _y_ ) + 128 _,_\n\n_o_ = _y_ _[\u2032]_ [ _t_ _[\u2032]_ ] _\u2212_ LOG2[sum(EXP2[ _y_ _[\u2032]_ ])] _,_\n\nwhere _o_ is the loss for one token. We implement EXP2 and LOG2 as lookup tables, where\n\nEXP2[ _i_ ] = 16 _\u00d7_ 2 _[i/]_ [16] _,_\n\nLOG2[ _i_ ] = 16 _\u00d7_ log2( _i/_ 16) _._\n\nNote that each element in EXP2 for any U8 input requires at most 20 bits, so the sum of exponents across all\npossible choices is at most 28 bits, meaning we have to precompute LOG2 for 2 [28] values.\n\n**D** **EGG Pretraining with Integer EGGROLL**\n\nThe core ideas of EGGROLL still apply in this integer-based training setting, but we have to make some\nmodifications to ensure it only uses integer operations.\n\n35\n\n**D.1** **Adding EGGROLL Perturbations**\n\nFor parameter _\u03b8 \u2208_ I _[m]_ 8 _[\u00d7][n]_ that represents a matrix multiplication, we first sample rank-1 perturbation vectors\nfor each index in the batch: _A \u2208_ I _[m]_ 8 [and] _[ B][ \u2208]_ [I] _[n]_ 8 [. We sample these vectors from the standard random normal]\nmultiplied by 16 and rounded to the nearest I8 (clipping if necessary). To prevent the use of floating-point\narithmetic on the accelerator, we pre-generate a large matrix of these random values, randomly indexing into it\nto get the perturbation vectors.\n\nGiven an input _x \u2208_ I _[n]_ 8 [, instead of calculating] _[ x]_ [@] _[\u03b8][T]_ [, we calculate]\n\nI8( _[x\u03b8][T]_ [ + ][((] _[x][ \u00b7][ B]_ [)][I][32][(] _[A]_ [)] _[ \u226b]_ [(][4 + \u02c6] _[\u03c3]_ [))] ) _._\n\n16 ~~_[\u221a]_~~ ~~_n_~~\n\nThe value of \u02c6 _\u03c3_ is a hyperparameter, related to the _\u03c3_ in the main paper as _\u03c3_ = 2 _[\u2212][\u03c3]_ [\u02c6] . Note that the batched\nforward pass remains efficient since it still simply performs a batched vector-vector dot product in int8 (with\nint32 accumulate) and a batched vector-scalar product in int32.\n\nWe apply this same logic to the embedding matrix, since we can interpret _\u03b8_ [ _t_ ] as one_hot( _t_ ) _\u03b8_ and still apply\nour rank-1 updates in that context. In practice, this means replacing _x \u00b7 B_ with _B_ [ _t_ ].\n\n**D.2** **Fitness Shaping**\n\nWe employ a simple fitness shaping scheme based on antithetical pairs. Specifically, given raw fitnesses\n_s_ [+] _, s_ _[\u2212]_, for the positive and negative sample of the antithetical pair respectively, the transformed fitness for the\nnoise is:\nsign( _s_ [+] _\u2212_ _s_ _[\u2212]_ ) _,_\n\nNote that the only possible values for the fitness after shaping are _{\u2212_ 1 _,_ 0 _,_ 1 _}_ .\n\n**D.3** **Parameter Update**\n\nFor parameter _\u03b8 \u2208_ I _[m]_ 8 _[\u00d7][n]_ that represents a matrix multiplication (or embedding vector), suppose the sampled\nbatch of rank-1 perturbation vectors are _A \u2208_ I _[N]_ 8 _[\u00d7][m]_ and _B \u2208_ I _[N]_ 8 _[\u00d7][n]_, and let the fitnesses after shaping be\n_F \u2208_ I _[N]_ 8 [. Then we calculate an intermediate value] _[ E][ \u2208]_ [I] _[m]_ 32 _[\u00d7][n]_ as:\n\n_E_ = ( _F \u2299_ _A_ ) _[T]_ _B._\n\nWe use _E_ to determine if each element of _\u03b8_ should be increased or decreased. In particular, when the absolute\nvalue of _E_ is above a pre-specified threshold we move _\u03b8_ by one discrete bin in the direction of the sign of\n_E_ . Since there are only 255 unique values for each element in I8, restricting updates to single bins improves\nstability without compromising the ability for a parameter to get to any other value with relatively few\nupdates.\n\nWe currently do not incorporate any momentum or other optimizer states, but this remains critical future work\nto improve the speed of convergence for pure integer training.\n\n**E** **EGG Ablations**\n\n**E.1** **Data Efficient Training**\n\nIn our main experiments, we give a unique training sequence to each antithetical pair. However, after fitness\nshaping only 1 bit is extracted per antithetical pair, so we may be able to reuse training sequences across\nmultiple members of the population. When we let each sequence be used for at most 512 members of the\npopulation, we get the loss curves in Fig. 6. At large population sizes, at 4096 and above, we see similar\nperformance despite using 256 times less data. At small population sizes, we see instability, likely due to the\nfact that reusing the same training sequence across the entire population would lead to \u201coverfitting\u201d to the\ntraining sequence instead of generalizing.\n\n36\n\nData Efficient Pure Integer Pretraining: Test Loss\n\n8\n\n7\n\n10 [5]\n\n10 [4]\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-36-0.png)\n\n6\n\n10 [3]\n\n5\n\n10 [2]\n\n4\n\n10 [1]\n\n0 200 400 600 800 1000\nTraining Step\n\nFigure 6: Test loss curves when reusing each sequence across 512 members of the population. Dashed lines indicate the\noriginal experiments where each antithetical pair receives a different sequence.\n\n**E.2** **Controlling For Data Across Population Sizes**\n\nTo determine whether the benefits of large population sizes are due to receiving more data or more unique\nperturbations, we run an experiment where smaller population sizes receive the same amount of data per step\nas the default for 32768. For instance, for a population size of 2, this means there is just one antithetical\npair of perturbations but each is evaluated across 16384 data sequences. In principle, this means that each\nperturbation could have a cleaner fitness estimate. We plot results for population sizes of 2, 64, 512, 4096, and\n32768 in Fig. 7.\n\nData Controlled Pure Integer Pretraining: Test Loss\n\n10 [5]\n\n8\n\n10 [4]\n\n7\n\n10 [3]\n\n6\n\n10 [2]\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-36-1.png)\n\n10 [1]\n\n5\n\n10 [0]\n\n4\n\n10 [\u22121]\n\n0 200 400 600 800 1000\nTraining Step\n\nFigure 7: Test losses when different population sizes receive the same amount of data.\n\nWe find that maximizing the number of unique perturbations is critical for pretraining performance. Training\nis incredibly unstable at a population size of 2, which is analogous to zeroth order optimization, implying that\npretraining would have been infeasible with prior zeroth order optimization approaches for LLM training or\nother ES works. In particular, Qiu et al. (2025) manages to get satisfactory speed with na\u00efve ES in reasoning\ntasks by reusing the same perturbation hundreds of times and having a small population size, but Fig. 7\ndemonstrates that this strategy would not work for pretraining from scratch.\n\n37\n\n**F** **EGGROLL Speed**\n\nAll timings were done on a single GPU on a GH200 (equivalent to a single H100) for a linear model with\ndimension 8192 in bfloat16, allowing a maximum batch size of 1024. For the graph in Fig. 2a, we pre-generate\nthe noises instead of integrating the noise generation into the forward pass.\n\n100\n\n80\n\n60\n\n40\n\n20\n\nNormalized Training Speeds\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-37-0.png)\n\n0\nEGGROLL PPO OpenES\n\nFigure 8: Relative speed of EGGROLL, when including jax noise regeneration.\n\nIn Fig. 8, we consider the impact of regenerating noises on-the-fly using jax PRNG. The darker area and value\nin parenthesis for EGGROLL and OpenES indicate the speed when regenerating noises on-the-fly, while the\nfull bar indicates the speed when the noises are already generated.\n\nWe regenerate noises on the fly in our primary jax codebase, but pre-generating the EGGROLL perturbations\nbeforehand is also a practical possibility since low-rank perturbations only require a small amount of memory,\nproportional to the square root of the size of the original parameter matrices.\n\n**G** **Experimental Details**\n\n**G.1** **Reinforcement Learning Experiments**\n\nWe present here the hyperparameter ranges we used for hyperparameter optimization, as well as all hyperparameter settings for all the experiments. All RL experiments were run on an NVIDIA L40S GPU. For PPO,\nwe use the same methodology to tune the hyperparameters as we did for OpenES and EGGROLL as described\nin Section 6.2. We report the ranges and the final hyperparameters here. We train PPO agents using Rejax\n(Liesen et al., 2024).\n\n38\n\n|CartPole-v1|Col2|\n|---|---|\n|||\n||EggRoll<br>OpenES<br>PPO|\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-5.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-9.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-12.png)\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.75\n\n1.50\n\n1.25\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\nPendulum-v1\n\n0 2 4\nSteps 1e8\n\nCraftax Classic\n\n0 2 4\nSteps 1e8\n\nJumanji Snake\n\n0 2 4\nSteps 1e8\n\nNavix DoorKey (8x8)\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n\u22120.25\n\n\u22120.50\n\n\u22120.75\n\nBrax Ant\n\n0 2 4\nSteps 1e8\n\nCraftax Symbolic\n\n0 2 4\nSteps 1e8\n\nKinetix Hard Pinball (l)\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nBrax Inverted Double Pendulum\n\n1.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nJumanji Knapsack\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Over Ball (s)\n\n1.04\n\n1.02\n\n1.00\n\n0.98\n\n0.96\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0 2 4\nSteps 1e8\n\nNavix Dynamic Obstacles Random (6x6)\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\nBrax Humanoid\n\n0 2 4\nSteps 1e8\n\nJumanji 2048\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Control Left (m)\n\n0 2 4\nSteps 1e8\n\nNavix FourRooms (8x8)\n\n0 2 4\nSteps 1e8\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-6.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-7.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-8.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-10.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-11.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-38-13.png)\n\nFigure 9: Comparison of reinforcement learning results: Mean returns for each environment and algorithm across 10 random\nseeds. The returns are evaluated using the mean of the parameters. HPO was conducted for each algorithm/environment\npair. The shaded region is the standard error of the mean.\n\n**G.2** **Multi Agent Reinforcement Learning Experiments**\n\nWe train on three cooperative Multi Particle Environments (MPEs) (Lowe et al., 2017) implemented in\nJaxMARL (Rutherford et al., 2023) with feed-forward networks of width 64 and depth 3, performing Bayesian\nhyperparameter optimization for each environment and algorithm. All runs were executed on NVIDIA\nA100-SXM4-40GB GPUs. We find that the optimal batch size is consistent across algorithms on the same\nenvironment. Figure 11 shows that EGGROLL with rank 1 trains up to 2.4 times faster than OpenES for large\nbatch sizes while staying competitive in performance.\n\n39\n\nCartPole-v1\n\n400\n\n300\n\n200\n\n100\n\n0\nEggRoll OpenES\n\nBrax Inverted Double Pendulum\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-1.png)\n\n300\n\n200\n\n100\n\n0\nEggRoll OpenES\n\nCraftax Classic\n\nPendulum-v1\n\nBrax Ant\n\nBrax Humanoid\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-3.png)\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nCraftax Symbolic\n\n30000\n\n10000\n\n7500\n\n5000\n\n2500\n\n0\nEggRoll OpenES\n\nJumanji 2048\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-5.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-6.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-7.png)\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\nJumanji Knapsack\n\n15000\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nJumanji Snake\n\n600\n\n400\n\n200\n\n0\nEggRoll OpenES\n\nKinetix Thrust Control Left (m)\n\n20000\n\n10000\n\n0\nEggRoll OpenES\n\nKinetix Hard Pinball (l)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-8.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-9.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-10.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-11.png)\n\n1500\n\n1000\n\n4000\n\n3000\n\n2000\n\n1000\n\n15000\n\n10000\n\n5000\n\n0\nEggRoll OpenES\n\nNavix Dynamic Obstacles Random (6x6)\n\n500\n\n0\nEggRoll OpenES\n\nKinetix Thrust Over Ball (s)\n\n4000\n\n40000\n\n20000\n\n0\nEggRoll OpenES\n\nNavix DoorKey (8x8)\n\n0\nEggRoll OpenES\n\nNavix FourRooms (8x8)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-12.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-13.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-14.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-39-15.png)\n\n1500\n\n1000\n\n500\n\n0\nEggRoll OpenES\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\n3000\n\n2000\n\n1000\n\n0\nEggRoll OpenES\n\n400\n\n200\n\n0\nEggRoll OpenES\n\nFigure 10: Comparison of reinforcement learning results: Mean and standard deviation of training time.\n\nTable 1: Hyperparameter Ranges for EGGROLL and OpenES\n\n**Hyperparameter** **Values**\npop_size 512, 1024, 2048, 4096\nn_parallel_evaluations 1, 4, 8\nrank 1, 2, 4\noptimizer adamw, sgd, adam\nlearning_rate 1e-3, 1e-2, 1e-1\nlr_decay 0.995, 0.999, 0.9995, 1.0\nsigma 0.05, 0.2, 0.5\nsigma_decay 0.995, 0.999, 0.9995, 1.0\nrank_transform true, false\ndeterministic_policy true, false\n\n40\n\nTable 2: Hyperparameter Ranges for PPO\n\n**Hyperparameter** **Values**\nclip_eps 0.1, 0.2, 0.3\nent_coef 0, 0.0001, 0.001\ngae_lambda 0.9, 0.95, 0.98\ngamma 0.95, 0.99, 0.995, 0.999\nlearning_rate 0.0001, 0.0003, 0.001\nmax_grad_norm 0.5, 1, 2\nlayer_size 256\nn_layers 3\nnormalize_observations true\nnormalize_rewards false\nnum_envs 64, 128, 256\nnum_epochs 4, 8, 16\nnum_minibatches 16, 32, 64\nnum_steps 64, 128, 256\nreward_normalization_discount 0.99\nskip_initial_evaluation false\nvf_coef 0.5, 0.75, 1\n\nTable 3: CartPole-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.1 0.1\nlr_decay 0.9995 0.9995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 2048 512\noptimizer sgd adamw\nrank 4 /\n\nrank_transform false true\nsigma 0.2 0.5\nsigma_decay 0.999 0.9995\n\n**G.3** **Reasoning Fine-tuning Experiments: Countdown**\n\nTable 4: Pendulum-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.01 0.01\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 4096 4096\noptimizer adam adamw\nrank 4 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 0.995 1\n\nWe ran a Bayesian hyper-parameter sweep (Snoek et al., 2012) for both GRPO and EGGROLL and used\nthe best set found to run the experiments in figure 5a. For GRPO we swept over sampling temperature and\nlearning rate, whereas for EGGROLL we swept over the standard deviation of the ES sampling ( _\u03c3_ ) and the\nlearning rate scale. The best hyper-parameters found are detailed on tables 26 (EGGROLL) and 27 (GRPO).\nAll of the experiments run in 8 hours on a NVIDIA H200 GPU.\n\nWe also run an experiment where we increase the number of GPUs to 8 and use a bigger model, RWKV 7g7B,\non the Countdown task, allowing for stronger final performance. Notably, we compare to the results reported\nby Qiu et al. (2025) on Countdown. Figure 12 shows that starting from our significantly weaker model (RWKV\n7g7B v.s. Qwen 2.5-7B), we are able to train to a higher validation accuracy (72.9%), v.s. the ones reported\nfor training with GRPO (52.8%) and Open ES (66.8%). Qiu et al. (2025) do not report the wall clock time or\nthe hardware used for their experiments which makes it difficult to establish a fair comparison.\n\n41\n\nTable 5: brax/ant\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.1\nlr_decay 0.9995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 8\npop_size 2048 512\noptimizer adam adam\nrank 1 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 0.9995 0.9995\n\nTable 7: brax/inverted_double_pendulum\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true true\nlearning_rate 0.1 0.1\nlr_decay 1 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 1\npop_size 2048 4096\noptimizer adam adam\nrank 2 /\n\nrank_transform true true\nsigma 0.5 0.05\nsigma_decay 0.995 1\n\nTable 9: craftax/Craftax-Symbolic-AutoReset-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.1\nlr_decay 0.999 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 4\npop_size 512 1024\noptimizer sgd adam\nrank 4 /\n\nrank_transform true false\nsigma 0.05 0.5\nsigma_decay 0.999 1\n\nTable 6: brax/humanoid\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true false\nlearning_rate 0.1 0.1\nlr_decay 1 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 8\npop_size 4096 1024\noptimizer adam sgd\nrank 1 /\n\nrank_transform true true\nsigma 0.2 0.2\nsigma_decay 0.9995 0.995\n\nTable 8: craftax/Craftax-Classic-Symbolic-AutoReset-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.001\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 8\npop_size 2048 4096\noptimizer sgd adamw\nrank 1 /\n\nrank_transform false false\nsigma 0.05 0.05\nsigma_decay 1 0.995\n\nTable 10: jumanji/Game2048-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false true\nlearning_rate 0.1 0.01\nlr_decay 1 0.999\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 4\npop_size 1024 1024\noptimizer adamw adamw\nrank 1 /\n\nrank_transform false true\nsigma 0.5 0.05\nsigma_decay 0.9995 0.9995\n\n42\n\nTable 11: jumanji/Knapsack-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.01\nlr_decay 0.999 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 1024 2048\noptimizer sgd adamw\nrank 4 /\n\nrank_transform true true\nsigma 0.05 0.5\nsigma_decay 1 0.995\n\nTable 13: kinetix/l/hard_pinball\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy true true\nlearning_rate 0.01 0.01\nlr_decay 0.995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 1\npop_size 2048 512\noptimizer sgd sgd\nrank 4 /\n\nrank_transform true true\nsigma 0.05 0.5\nsigma_decay 0.999 0.9995\n\nTable 15: kinetix/s/h1_thrust_over_ball\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.01\nlr_decay 0.995 0.995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 1\npop_size 512 2048\noptimizer adamw sgd\nrank 1 /\n\nrank_transform true true\nsigma 0.5 0.05\nsigma_decay 0.9995 1\n\n**G.4** **Reasoning Fine-tuning Experiments: GSM8K**\n\nTable 12: jumanji/Snake-v1\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.001 0.001\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 8 1\npop_size 4096 2048\noptimizer adam sgd\nrank 1 /\n\nrank_transform true false\nsigma 0.05 0.2\nsigma_decay 0.9995 1\n\nTable 14: kinetix/m/h17_thrustcontrol_left\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.1 0.001\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 512 1024\noptimizer sgd adam\nrank 4 /\n\nrank_transform true true\nsigma 0.5 0.5\nsigma_decay 1 0.999\n\nTable 16: navix/Navix-DoorKey-8x8-v0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.01\nlr_decay 0.9995 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 1 8\npop_size 1024 2048\noptimizer adamw adam\nrank 1 /\n\nrank_transform false true\nsigma 0.05 0.05\nsigma_decay 1 1\n\nWe used the hyper-parameters found for Countdown as a starting point and reduced the learning rates for\nboth GRPO and EGGROLL using linear search until we found the best performing one on the validation set.\n\n43\n\nTable 17: navix/Navix-Dynamic-Obstacles-6x6-Randomv0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.01\nlr_decay 0.999 1\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 1\npop_size 512 4096\noptimizer adam adam\nrank 2 /\n\nrank_transform false false\nsigma 0.05 0.2\nsigma_decay 1 0.995\n\nTable 18: navix/Navix-FourRooms-v0\n\nHyperparameter eggroll open_es\nactivation pqn pqn\ndeterministic_policy false false\nlearning_rate 0.01 0.001\nlr_decay 0.999 0.9995\nlayer_size 256 256\nn_layers 3 3\nn_parallel_evaluations 4 4\npop_size 2048 2048\noptimizer sgd adam\nrank 4 /\n\nrank_transform true false\nsigma 0.05 0.05\nsigma_decay 0.9995 0.9995\n\nTable 19: PPO Hyperparameters (Set 1)\n\nHyperparameter CartPole Pendulum Ant Humanoid IDP CraftaxClassic CraftaxSymbolic Game2048\nactivation pqn pqn pqn pqn pqn pqn pqn pqn\nclip_eps 0.2 0.1 0.2 0.3 0.1 0.2 0.2 0.3\nent_coef 0.0001 0.001 0 0.0001 0.0001 0.0001 0 0.001\ngae_lambda 0.9 0.95 0.95 0.9 0.98 0.98 0.9 0.9\ngamma 0.995 0.999 0.995 0.95 0.99 0.95 0.95 0.99\nlearning_rate 0.0003 0.0003 0.0003 0.0001 0.001 0.001 0.0003 0.0003\nmax_grad_norm 0.5 1 0.5 2 2 2 2 2\nlayer_size 256 256 256 256 256 256 256 256\nn_layers 3 3 3 3 3 3 3 3\nnormalize_obs true true true true true true true true\nnormalize_rew false false false false false false false false\nnum_envs 256 256 64 256 64 128 256 64\nnum_epochs 4 16 8 4 4 4 4 8\nnum_minibatches 32 16 32 64 64 32 32 16\nnum_steps 128 256 128 64 128 128 64 64\nrew_norm_discount 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\nskip_initial_eval false false false false false false false false\nvf_coef 0.5 1 1 0.75 1 0.5 0.75 0.75\n\nOur experiments for GSM8K run on 8 NVIDIA H200 GPUS for 8 hours each. We also increase the standard\ndeviation, _\u03c3_, parameter for ES (from 7 _\u00d7_ 10 _[\u2212]_ [4] to 2 _\u00d7_ 10 _[\u2212]_ [3] ) as the significantly bigger population sizes (8096\nv.s. 512) allow for much more stable training and aggressive exploration.\n\n44\n\nTable 20: PPO Hyperparameters (Set 2)\n\nHyperparameter Knapsack Snake HardPinball ThrustLeft ThrustBall DoorKey DynamicObs FourRooms\nactivation pqn pqn pqn pqn pqn pqn pqn pqn\nclip_eps 0.1 0.3 0.1 0.2 0.2 0.1 0.1 0.1\nent_coef 0.0001 0.001 0.0001 0.0001 0.0001 0.0001 0.001 0.001\ngae_lambda 0.9 0.95 0.9 0.9 0.95 0.98 0.98 0.9\ngamma 0.99 0.999 0.99 0.995 0.999 0.95 0.999 0.99\nlearning_rate 0.0001 0.0001 0.0001 0.0001 0.0001 0.0003 0.001 0.001\nmax_grad_norm 0.5 0.5 1 2 0.5 0.5 1 1\nlayer_size 256 256 256 256 256 256 256 256\nn_layers 3 3 3 3 3 3 3 3\nnormalize_obs true true true true true true true true\nnormalize_rew false false false false false false false false\nnum_envs 256 128 256 256 64 64 128 256\nnum_epochs 4 4 16 16 16 16 4 8\nnum_minibatches 64 16 16 32 16 64 16 32\nnum_steps 128 128 64 128 64 256 128 256\nrew_norm_discount 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\nskip_initial_eval false false false false false false false false\nvf_coef 0.75 0.75 0.5 0.5 0.5 0.75 0.5 0.75\n\nSimple Reference\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-2.png)\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 4096)\n\nSimple Speaker Listener\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 512)\n\n\u221240\n\n\u221250\n\n\u221260\n\n2.0\n\n1.5\n\n1.0\n\n0.5\n\n0.0\n\n\u221240\n\n\u221260\n\n\u221280\n\n15\n\n10\n\n5\n\n0\n\nSimple Spread\n\n0 2 4\nSteps 1e8\n\nIPPO OpenES EGGROLL\n(Batch Size = 128)\n\n\u221250\n\n\u2212100\n\n\u2212150\n\n5\n\n4\n\n3\n\n2\n\n1\n\n0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-44-5.png)\n\nFigure 11: Training curves and wall clock times for cooperative Multi Particle Environments. Hyperparameter optimization\nyielded equal batch sizes for all algorithms on the same environment. All EGGROLL runs used rank 1 perturbations.\nShaded regions are standard errors of mean values.\n\nTable 21: Hyperparameter Ranges Used in MPE Sweeps\nfor EGGROLL and OpenES\n\nHyperparameter Values\nactivation pqn, tanh\npop_size 128, 512, 1024, 2048, 4096\nlearning_rate 0.01, 0.05, 0.1, 0.5\nlr_decay 0.3, 0.7, 1.0\nsigma 0.1, 0.2, 0.3, 0.4, 0.5\nrank_transform true, false\n\nTable 22: Hyperparameter Ranges Used in MPE Sweeps\nfor IPPO\n\nHyperparameter Values\nactivation relu, tanh\npop_size 128, 512, 1024, 2048, 4096\nlearning_rate 5e-5, 1e-4, 2.5e-4, 1e-3\nentropy_coef 0.001, 0.005, 0.01\n\n45\n\nTable 23: MPE Simple Spread v3\n\nHyperparameter eggroll open_es ippo\nactivation tanh tanh tanh\n\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.7 0.7 linear\nlayer_size 64 64 64\nn_layers 3 3 3\npop_size 128 128 128\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform false false sigma 0.5 0.5 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.01\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\nTable 24: MPE Simple Speaker Listener v4\n\nHyperparameter eggroll open_es ippo\nactivation tanh tanh relu\n\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.7 0.3 linear\nlayer_size 64 64 64\nn_layers 3 3 64\npop_size 512 512 512\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform true true sigma 0.5 0.5 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.005\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\nTable 25: MPE Simple Reference v3\n\nHyperparameter eggroll open_es ippo\nactivation pqn tanh relu\ndeterministic_policy true true false\nlearning_rate 0.01 0.01 0.001\nlr_decay 0.3 0.3 linear\nlayer_size 64 64 64\nn_layers 3 3 3\npop_size 4096 4096 4096\noptimizer adamw adamw adam\nrank 1 1 \nrank_transform false true sigma 0.1 0.3 n_minibatches - - 4\nupdate_epochs - - 4\ngamma - - 0.99\ngae_lambda - - 0.95\nepsilon_clip - - 0.2\nentropy_coef - - 0.01\nvalue_coef - - 0.5\nmax_grad_norm - - 0.5\n\n46\n\nHyperparameter Value\n\nModel RWKV 7g1.5B\nOptimizer Gradient descent\nES standard deviation _\u03c3_ 7 _\u00d7_ 10 _[\u2212]_ [4]\n\nRank _r_ 1\n\nLearning-rate scale _\u03b7_ scale 0.125\nPopulation size 256\nParallel generations per GPU 1536\nPrompts per epoch 6\nGeneration / thinking length 1000 tokens\nTrain / val temperature 0 / 0\nParallel validations 128\n\nTable 26: Key hyperparameters for EGGROLL training on Countdown with FastRWKV-7g1.5B.\n\nHyperparameter Value\n\nModel RWKV 7g1.5B\nOptimizer Radam\nLearning rate _\u03b7_ 3 _\u00d7_ 10 _[\u2212]_ [6]\n\nGenerations per prompt _G_ 8\nParallel generations per GPU 64\nPrompts per epoch 8\nGeneration length 1000 tokens\nNumber of minibatches 4\n\nPPO clip parameter _\u03f5_ clip 0.2\nTrain / val temperature 1 / 0\nParallel validations 128\n\nTable 27: Key hyperparameters for GRPO training on Countdown with AssociativeScanRWKV-7g1.5B.\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-46-0.png)\n\n0.2\n\n0 100 200 300 400 500\n\nEpoch\n\nEGGROLL: RWKV-g0:7g7B\n\nFigure 12: Validation score training curve of an RWKV 7g7B model on countdown using 8 GPUS and a population size of\n8096. Notably, we are able to outperform a stronger base model trained with GRPO and OpenES.\n\n47\n\nHyperparameter Value\n\nModel RWKV 7g7B\nES standard deviation _\u03c3_ 2 _\u00d7_ 10 _[\u2212]_ [3]\n\nRank _r_ 1\n\nLearning-rate scale _\u03b7_ scale 0.06\nGenerations per prompt _G_ 512\nParallel generations per GPU 1024\nTotal parallel generations 8192\nPrompts per epoch 16\nGeneration length 1000 tokens\nNoise reuse factor 1\n\nFreeze non-LoRA params True\nTrain / val temperature 0 / 0\nParallel validations 128\n\nTable 28: Key hyperparameters for multi-GPU EGGROLL training on GSM8K with FastRWKV-7g7B.\n\nHyperparameter Value\n\nModel RWKV 7g7B\nLearning rate _\u03b7_ 1 _\u00d7_ 10 _[\u2212]_ [6]\n\nGenerations per prompt _G_ 8\nParallel generations per GPU 32\nTotal parallel generations 256\nPrompts per epoch 32\nGeneration length 1000 tokens\nNumber of minibatches 16\n\nNumber of workers (processes) 8\nPPO clip parameter _\u03f5_ clip 0.2\nTrain / val temperature 1 / 0\nParallel validations 128\n\nTable 29: Key hyperparameters for multi-GPU GRPO training on GSM8K with AssociativeScanRWKV-7g7B.\n\n48"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around 'integer-only' arithmetic and a 'guess-and-check' parameter update strategy. For computation, the model primarily uses 8-bit integers (I8). Modern GPUs have specialized circuits (tensor cores) that can perform matrix multiplication on these integers extremely fast, accumulating results in 32-bit integers. The trick is managing precision loss and dynamic range. They achieve this by scaling operations (like a division by 16 * sqrt(n) after a matrix product) and relying on the implicit 'clipping' that occurs when casting a 32-bit result back to an 8-bit integer. This clipping acts as a built-in, hard activation function, replacing the need for expensive floating-point sigmoids or hyperbolic tangents. Layer Normalization avoids square roots by normalizing with the mean absolute value, which is integer-friendly and bit-shiftable. For learning, instead of directly computing complex gradients, EGGROLL adds small, structured 'rank-1' integer perturbations (noise) to the model's parameters. By evaluating the model with both positive and negative versions of this noise (antithetical pairs), it generates a simple {-1, 0, 1} feedback signal. This signal, combined with the noise, guides parameter updates in discrete, single-bin steps, aligning perfectly with the integer-only architecture and simplifying the update logic.\n\n**Explanation:** This approach works by redesigning the entire computation to be hardware-efficient for integer operations. Think of a computer's processor having a super-fast way to add and multiply whole numbers, but a slower way for numbers with decimals. This paper re-architects the model so it only uses those super-fast whole-number operations. For instance, 'x @ M' isn't just a matrix multiplication; it's a specialized hardware instruction that's incredibly fast for I8 inputs, accumulating in I32. When the result is too big for I8, it's 'clipped', which acts like an automatic activation function without needing a separate calculation. Layer normalization avoids floating-point square roots by using the sum of absolute values, which can be done with simple integer addition and bit shifts. For updating the model's parameters, instead of calculating tiny, precise 'gradients' (which require many decimal places), it uses a system of 'structured random guesses'. It makes a small, integer-based random change to the model, tries it out, and gets a simple +1, -1, or 0 score. This score then tells the model to adjust its parameters by a single 'click' up or down. This 'discrete' update ensures consistency with integer arithmetic and avoids the precision issues inherent in continuous floating-point adjustments."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = 1 **and** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ _>_ 1 **then**\n\n**32** _\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ ;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism performs a conditional capacity adjustment or restoration. It acts like a state machine with a memory component.\n\n**Explanation:** The code checks two conditions: first, if the current resource constraint ('SFs in bottleneck') is at its absolute minimum (set to 1), and second, if an external or historical reference (`cmpbbr->last_number_of_SFs_in_bottleneck`) indicates that a larger capacity (greater than 1) was previously available or is suggested. If both conditions are true, the system dynamically updates the 'final number of SFs in bottleneck' to reflect that larger historical/external capacity. This prevents a system from becoming pathologically stuck at a single-unit bottleneck if a multi-unit capacity is known to be viable, essentially overriding a current minimum setting with a proven larger value. It's akin to a 'rollback' or 'expansion' logic using a pointer (`cmpbbr`) to access a stored historical value."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**16**\n3.1 Preliminary tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.1.1 Particle Tracing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.1.2 Different Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.1.3 Particle Projection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2 Implementation of the coupled harmonics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.2.1 Changes in the matrix system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.3 Coupled projection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.3.1 Gaussian distribution on the W7-A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n\n3.3.2 Gaussian distribution on the W7-X . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n\n3.4 Convergence Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.5 FFT acceleration of the matrix construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3.6 The RTree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves simulating the paths of particles and their collective behavior. When individual elements exhibit interconnected, oscillatory behavior (coupled harmonics), the linear algebraic system describing them becomes non-diagonal, implying direct dependencies between variables that were previously independent. This changes the system's characteristic response and requires solving a larger, more complex matrix system. To accelerate computations involving periodic or spatially distributed data, the FFT transforms operations like convolutions into element-wise products, drastically reducing computational complexity. For spatial querying, the RTree acts as a hierarchical spatial index, similar to a multi-dimensional hash map, allowing rapid retrieval of objects within a given bounding box, thereby avoiding exhaustive searches.\n\n**Explanation:** This section outlines the methodological steps for a simulation. It starts with validating fundamental particle behaviors and their transformations (projections). The key challenge addressed is integrating 'coupled harmonics,' meaning that multiple oscillatory components in the system are interdependent, requiring a unified mathematical framework often represented by changes in a matrix system where elements interact. This interdependence affects how particles are 'projected' onto a surface, reflecting their collective rather than individual states. Crucially, the paper leverages two computational speed-ups: Fast Fourier Transform (FFT) to accelerate the construction of matrices (likely for systems involving convolutions or cyclic properties), and an RTree, which is a spatial partitioning data structure, to quickly find particles or data within specific regions of space, analogous to how a database index speeds up queries on geographic coordinates."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61_\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ **then**\n\n**167** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51, \ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ + _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ ) ;\n\n**168** BBR_Modulate_Cwnd_For_ProbeRTT():"}, {"role": "assistant", "content": "**Mechanism:** This mechanism ensures that the sending capacity (congestion window) is adaptively expanded to at least match the currently observed network utilization, preventing self-imposed bandwidth limitations, while also enabling periodic recalibration of true network latency.\n\n**Explanation:** The `cwnd = max(cwnd, packets_in_flight + packets_delivered)` line behaves like an upward-only adjustment for the congestion window. It ensures that the current `cwnd` (which limits how much data can be in transit) is always at least as large as the actual amount of data observed to be actively flowing through the network: `packets_in_flight` (data sent but not yet acknowledged) plus `packets_delivered` (data just acknowledged). This effectively means `cwnd` tracks and grows with the actual pipe capacity demonstrated by recent successful transmissions, preventing the sender from underutilizing the network. It's a simple `if` condition and assignment, like `if (packets_in_flight + packets_delivered > cwnd) cwnd = packets_in_flight + packets_delivered;`. The `BBR_Modulate_Cwnd_For_ProbeRTT()` function call is a distinct, scheduled process where the system intentionally and temporarily reduces `cwnd` to a minimal value to clear any self-induced queues, allowing it to measure the true, unqueued Round-Trip Time (RTT), which is critical for BBR's rate control logic."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ == _\ud835\udc37\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b_ **and** _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ \u2264 _\ud835\udc35\ud835\udc35\ud835\udc45_\ud835\udc3c\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ (1 _._ 0) **then**\n\n**90** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc38\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc35\ud835\udc4a_ () ; /* we estimate queue is drained */\n\n**91** BBR_Update_RTprop():\n\n**92** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc56\ud835\udc5f\ud835\udc52\ud835\udc51_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () _> \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ + _\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d\ud835\udc39\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc3f\ud835\udc52\ud835\udc5b_ ;"}, {"role": "assistant", "content": "**Mechanism:** This segment describes a state transition in a network congestion control algorithm, specifically moving from a 'drain' state to a 'probe bandwidth' state, coupled with a mechanism for refreshing a critical latency measurement.\n\n**Explanation:** The condition `BBR.state == Drain` indicates that the system is actively trying to empty any standing queue in the network path. The additional check `packets_in_flight <= BBR_Inflight (1.0)` serves as a crucial heuristic, confirming that the queue has indeed been reduced to a minimal level (approaching the bandwidth-delay product) and not just entered the drain state. When this condition is met, the system transitions to `BBR_Enter_ProbeBW()`, which is an exploration phase. This is akin to a control loop trying to find the upper bound of a system's capacity by incrementally increasing its output until a limit is detected, rather than merely reacting to congestion. The `BBR_Update_RTprop()` function manages the round-trip propagation time (RTprop), which is the true, non-queuing latency of the path. The line `_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc56\ud835\udc5f\ud835\udc52\ud835\udc51_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () _> \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ + _\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d\ud835\udc39\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc3f\ud835\udc52\ud835\udc5b_` acts as a cache invalidation or a 'time-to-live' (TTL) mechanism. If the last RTprop measurement is older than a predefined duration (`RTpropFilterLen`), it's marked as expired, prompting a re-measurement to ensure the algorithm always uses the most current baseline latency, vital for accurate bandwidth estimation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n( _\u03b3k_ _[j][\u2217]_\n\n_\u0338_\n\n_[\u2217]_\n\n2 **[then]** _[ \u03b4][ \u2190\u2212]_ [(] _[\u03b3]_ _k_ _[j][\u2217]_\n\n_\u0338_\n\n_k_ _[j]_ _[\u2212]_ _[v]_ [(] _[{][j][\u2217][}]_ [))] _[ <]_ _[\u03b4]_ 2 _[\u2217]_\n\n_\u0338_\n\n**if** ( _\u03b3k_ _[\u2212]_ _[v]_ [(] _[{][j][\u2217][}]_ [))] _[ <]_ 2 **[then]** _[ \u03b4][ \u2190\u2212]_ [(] _[\u03b3]_ _k_ _[\u2212]_ _[v]_ [(] _[{][j][\u2217][}]_ [))]\n\n**else**\n\n_\u0338_\n\n_\u03b4 \u2190\u2212_ _[\u03b4][\u2217]_\n\n2\n**end**\n\n_\u0338_\n\n**7** _\u03b3k_ _[i][\u2217]_ +1 _[\u2190\u2212]_ _[\u03b3]_ _k_ _[i][\u2217]_ [+] _[ \u03b4]_ [.]\n\n_\u0338_\n\n**8** _\u03b3k_ _[j][\u2217]_\n\n_\u0338_\n\n_k_ _[j][\u2217]_ +1 _[\u2190\u2212]_ _[\u03b3]_ _k_ _[j][\u2217]_\n\n_\u0338_\n\n_k_ _[\u2212]_ _[\u03b4]_ [.]\n\n_\u0338_\n\n**9** _k \u2190\u2212_ _k_ + 1.\n**until** _\u03b4_ _[\u2217]_\n_v_ ( _N_ ) _[\u2264]_ _[\u03f5]_\n**end**\n\nWe reproduce here Stearns\u2019 Theorem in an alternative version, as given by Faigle et al. (2001).\n\n**Theorem 7.1** (Stearns (1968)) **.** _Let {\u20d7\u03b3_ 0 _,\u20d7\u03b3_ 1 _,\u20d7\u03b3_ 2 _, . . .} be a sequence of vectors such that \u20d7\u03b3k arises from_\n_\u20d7\u03b3k\u2032\u2212_ 1 _by a transfer_ (2.2) _, and if an infinite number of these transfers are maximal, then \u20d7\u03b3k converges to an_\n_element_ **x** _\u2208_ K( _v_ ) _._\n\nThe Stearns\u2019 algorithm runs as follows: During each iteration step, the pair of players with the largest\ndifference in the maximum surpluses is singled out to give them the opportunity to balance their claims.\nThe player with the smallest maximum surplus makes a side-payment to the opponent who has a larger dissatisfaction measured in terms of the excess at the proposed sharing of the proceeds of mutual cooperation.\nWe realize that at each step only a single pair of players has the opportunity to balance their claims with the\nimplication that after each iteration step the unbalancedness in the bilateral claims will be reduced. In the\nlimit, this approach converges to a kernel point. However, computing a kernel element requires an infinite\n\n14\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nnumber of maximal transfers as the side-payments carried out become arbitrarily small. These properties\nof his method have some negative consequences on the convergence speed for floating-point arithmetic.\n\n### 8 ELLIPSOID METHOD: RUNTIME COMPLEXITY FOR RATIONAL DATA\n\nIt is well-known that the runtime complexity for the ellipsoid method has a polynomial-time worst-case\nruntime complexity of _O_ ( _n_ [6] _\u00b7 L_ ). For a linear programming problem in _n_ variables with rational coefficients, the runtime of the ellipsoid method is polynomial in the following factors:\n\n1. _n_ : Representing the number of variables (dimension of the space).\n\n2. _m_ : Representing the number of constraints.\n\n3. _L_ : Representing the size of the input data, often measured as the number of bits required to encode\nthe coefficients of the matrix **A** and vectors **b** and **c** .\n\n4. Operations per iteration: Each iteration involves matrix and vector arithmetic. When the input is\nrational, these operations must be performed using multi-precision arithmetic, which is slower than\nfixed-precision arithmetic. The time for these operations depends polynomially on the bit size of the\nnumbers involved.\n\n5. Growth of bit length: The numbers representing the centers of gravity and matrices of the ellipsoids\ngrow in size during the runtime of the algorithm. It can be established that the input bit length _L_\nbounds this growth polynomially.\n\nThe combination of a polynomial number of iterations and polynomial-time operations per iteration\n(when accounting for multi-precision arithmetic) leads to an overall polynomial-time algorithm.\n\nNote that the above analysis of algorithms dealing with rational numbers requires a computational\nmodel that can handle these factors with arbitrary precision. The standard for this is the Turing machine\nmodel, where the input is encoded as a finite string of bits. A rational number, _p/q_, is encoded by storing\nthe binary representation of its integer numerator _p_ and denominator _q_ . The size of a rational number is\nthe total number of bits required for this representation. In terms of a rational number model, this means\nthat every operation with a rational number depends on the precision and therefore cannot require constant\ntime.\n\nFor a feasibility problem where a convex set _K_ is either empty or contains a ball of radius _r_ and is\ncontained in a ball of radius _R_, the number of iterations required is _O_ ( _n_ [2] log( _R/r_ )). In addition, for linear\nprogramming problems with integer coefficients, this translates to a number of iterations that is polynomial\nin _n_ and the size of the input _L_ .\n\n### 9 ELLIPSOID METHOD: RUNTIME COMPLEXITY FOR REAL DATA\n\nWhen considering linear programming problems with real-valued data, the runtime complexity of the ellipsoid method is typically analyzed within a specific computational model, such as the real RAM (Random\nAccess Machine) model. Unlike the Turing machine model, which deals with finite bit lengths, the real\nRAM model assumes that real numbers can be stored and manipulated with infinite precision in constant\ntime. Though a real RAM model is Turing complete, which means that a real RAM model is in principle\ncapable of performing all calculations that are feasible within a Turing machine model. In such a model,\nthe runtime is not expressed in terms of the input\u2019s bit length _L_ but instead depends on the number of\nvariables _n_, the number of constraints _m_, and the required precision, _\u03f5_ . To summarize, the runtime of the\nellipsoid method for the real RAM model is expressed in the following factors:\n\n15\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\n1. _n_ : Representing the number of variables.\n\n2. _m_ : Representing the number of constraints.\n\n3. _R_ : Representing the radius of an initial ball known to contain the solution.\n\n4. _r_ : Representing the radius of a ball that is either contained in the feasible region or demonstrates\nthat the feasible region is empty.\n\n5. _\u03f5_ : Representing the desired precision.\n\nThen, the number of iterations required for the ellipsoid method to find an _\u03f5_ -approximate solution for\na convex optimization problem is proportional to _O_ ( _n_ [2] log( _R/r\u03f5_ )).\n\nIn each iteration, the algorithm performs a fixed number of operations, primarily matrix-vector and\nmatrix-matrix multiplications, which can be done in polynomial-time in _n_ . While the method\u2019s polynomial\nworst-case complexity holds in theory, this is generally not a good indicator of its practical performance.\nIn practice, it is often outperformed by other methods, such as interior-point methods with a runtime\ncomplexity of _O_ ( _n_ [3] _\u00b7 L_ ), which can be more robust to numerical issues. Even the simplex algorithm,\nthough theoretically exponential, is regularly much faster in practice.\n\n### 10 UNBOUNDED COMPLEXITY IN THE REAL RAM MODEL\n\nThe theoretical analysis of the ellipsoid method in the real RAM model hides the practical challenges of\nusing real-valued data with computers, which use finite-precision floating-point arithmetic.\n\nThe ellipsoid method\u2019s runtime depends on the required precision, _\u03f5_ . The number of iterations is\nproportional to _O_ ( _n_ [2] log( _R/r\u03f5_ )), where _R_ is the radius of the initial ellipsoid and _r_ is the radius of the\nlargest ball contained in the feasible region. In the real RAM model, the concept of input size is based on\nthe number of variables and constraints, but not on the precision of the numbers, because infinite precision\nis assumed, so that every operation with a real number takes constant time. As _\u03f5_ can be arbitrarily small,\nthe logarithm term log(1 _/\u03f5_ ) can be arbitrarily large, making the number of iterations and thus the runtime\nunbounded. For example, if one requires a solution with twice as many decimal places, the number of\niterations increases. With real numbers, there is no inherent limit to how much precision might be required.\nThis implies numerical instability issues with floating-point arithmetic.\n\nWhen focusing on the theoretical analysis of the real RAM model, it assumes that real numbers can be\nrepresented and manipulated with perfect, infinite precision. As a consequence, the following problems\narise when implementing this on a physical computer with finite-precision floating-point arithmetic:\n\n1. Accumulation of error: It is causative that the ellipsoid method is sensitive to numerical precision\nissues. Its immanent iterative nature results in the fact that small errors from floating-point arithmetic\ncan accumulate over many steps, potentially causing the algorithm to fail or produce an inaccurate\nresult. This pathological behavior is attributable to the iterative process of repeatedly updating a\nmatrix that describes the ellipsoid\u2019s shape and orientation. During each matrix updating, small\nrounding errors are introduced due to floating-point arithmetic. Over many iterations, these errors\naccumulate and can corrupt the matrix, causing the algorithm to fail or converge to an incorrect\nsolution.\n\n2. Loss of properties: This is causal because the core function of the algorithm relies on the matrix\ndefining the ellipsoid being positive definite. Floating-point errors can cause this property to be lost\nduring matrix updates, rendering the algorithm\u2019s mathematical foundations unsound during practical\ncomputations.\n\n16\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nIt is essentially thanks to the research of Traub and Wo\u00b4zniakowski (1982) that this connection was\nelucidated by demonstrating the theoretical unbounded complexity of the ellipsoid method in the real\nRAM model. They provided a 2 _\u00d7_ 2 linear programming example where the number of steps grows with\nthe size of the input coefficients. In the integer model, the coefficients\u2019 bit length, _L_, is finite, so the\nnumber of steps is polynomial in _L_ and thus bounded. Moreover, in the real number model, the bit length\nof coefficients is not part of the input measure. As the number of bits required to represent the coefficients\ngrows, the number of steps increases, demonstrating unbounded complexity. This counterexample proved\nthat the ellipsoid algorithm is not polynomial in the real RAM model.\n\nAs a consequence, the ellipsoid method is in practice very slow and numerically unstable, especially\nfor larger problems.\n\n### 11 REDUCED GAME AND SUBMODULAR FUNCTION MINIMIZATION METHOD\n\nMaggiorano et al. (2025) conceived a different method for trying to compute the nucleolus for the class of\nconvex games. However, their strategy to determine the nucleolus for this game class is, in the first stage,\nsimilar to the one invented by Faigle et al. (2001); they used the least-core as a catcher of the nucleolus.\nYet, instead of using the ellipsoid method for computing the least-core value, they applied a submodular\nfunction minimization approach in testing the feasibility of the least-core constraints in polynomial-time.\nFrom the feasible region of the least-core, the search space is narrowed and bounded to approach by an\nalternative method the computation of the nucleolus for a convex game. This is referring to a simplified\nversion of the Davis/Maschler reduced game that is induced by the convexity property of the underlying\ngame. Hence, the authors decided against Maschler\u2019s approximation method for the (pre-)kernel, making a\nbet to disregard the computation of all surpluses _sij_ ( **x** _, v_ ) over all distinct pairs of players for any allocation\n**x** _\u2208_ R _[n]_ at the cost of being forced to restrict the computation of the nucleolus on the domain of convex\ngames and the risk of being forced to close a gap in their proposed method. By their suggestion for\ncomputing the nucleolus, the structural properties of convex games are exploited. This allows them to refer\nto the Davis/Maschler reduced game approach to single out the presumptive nucleolus of a convex game.\nIn particular, the process iteratively solves a sequence of Davis/Maschler reduced games by leveraging\nsubmodular function minimization for solving the arising linear programming problems associated with\nthe least-cores from the emerging Davis/Maschler reduced games.\n\nSo far so good, their intended strategy in computing the nucleolus of a convex game, if it would work;\nhowever, we shall observe in a while that this strategy fails. But first, let us examine some other interesting\ningredients of their algorithm.\n\nIn particular, although it is not necessary to query a separation oracle for checking whether a point\nis in the feasible set of the arising least-cores or to provide separating hyperplanes as with the ellipsoid\nmethod. The procedure of submodular function minimization requires, nevertheless, querying an oracle\nfor computing and outputting coalitional values. On the positive side, the proposed submodular function\nminimization approach does not need any assumption made on the existence of any polynomial-time algorithm to assure a polynomial runtime in the nucleolus computation. This puts this model on a more sound\nand solid logical foundation in contrast to the method suggested by Faigle et al. (2001), thereby avoiding\nthe **Principle of Explosion** [1] if the assumption is void (for further details, we refer to Meinhardt (2021)).\n\n1This principle is also subsumed under ex falso sequitur quodlibet (e.f.s.q), i.e., from falsehood, anything follows. If the\nantecedence (premise) is inconsistent, it cannot be a true statement. Then, drawing a conclusion is meaningless because\nanything is inferable. Hence, this says that an inconsistent model is useless.\n\n17\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nIn addition, the model can be applied for infinite precision models, implying that neither knowledge of the\nencoding length of the largest number in the model nor knowledge about the total number of bits to encode\nthe problem is necessary.\n\nNext, we restate for the reader\u2019s convenience Algorithm 1 from the work of Maggiorano et al. (2025)\nthat should, according to the claim of the authors, compute the nucleolus of a convex game.\n\n**Algorithm 11.1:** Presumed Algorithm for Calculating the Nucleolus based on RGP\n\n**Data:** A convex TU Game _\u27e8_ _N, v \u27e9_, given through an evaluation oracle.\n**Result:** Presumed nucleolus _\u03bd_ ( _N, v_ ) of the game _\u27e8_ _N, v \u27e9_ .\n**begin**\n\n**0** Initialization: Set _k \u2190\u2212_ 1\n\n**1** Set _v_ _[k]_ _\u2190\u2212_ _v_\n\n**2** Set _N_ _[k]_ _\u2190\u2212_ _N_\n\n**3** Select _i \u2208_ _N_\n\n**repeat**\n\n**while** _|N_ _[k]_ _| >_ 1 **do**\n\n**4** Compute an essential coalition _S_ _[k]_ and the least-core value _\u03f5_ _[k]_ of game _\u27e8_ _N_ _[k]_ _, v_ _[k]_ _\u27e9_ .\n\n**5** Define _N_ _[k]_ [+1] _\u2190\u2212_ _S_ _[k]_ if _i \u2208_ _S_ _[k]_ ; otherwise, _N_ _[k]_ [+1] _\u2190\u2212_ _N_ _[k]_ _\\S_ _[k]_ .\n\n**6** Define _T_ _[k]_ := _N_ _[k]_ _\\N_ _[k]_ [+1], and _\u20d7x_ _[k]_ := _\u03bd_ ( _N_ _[k]_ _, v_ _[k]_ ) (resume that _v_ _[k]_ ( _T_ _[k]_ ) is known).\n\n**7** Define _v_ _[k]_ [+1] _\u2190\u2212_ _vN_ _[k]_ _[k]_ [+1] _, \u20d7x_ _[k]_ [ as]\n\n_vN_ _[k]_ [+1] _[k]_ [+1] _, \u20d7x_ _[k]_ [(] _[T]_ [) := max] \ufffd _v_ _[k]_ ( _T_ ) _, v_ _[k]_ ( _T \u222a_ _T_ _[k]_ ) _\u2212_ _x_ _[k]_ ( _T_ _[k]_ )\ufffd _,_ if _T \u2282_ _N_ _[k]_ [+1] .\n\n**8** Set _k \u2190\u2212_ _k_ + 1\n\n**end**\n\n**9** _\u03bdi_ ( _N, v_ ) _\u2190\u2212_ _v_ _[k]_ ( _N_ _[k]_ )\n\n**until** _i = n_\n\n**end**\n\nHowever, if we dive more deeply into the details of their purported method to compute the nucleolus\nand their associated proof, we have to recognize that their Method 11.1 is not about the computation of\nthe nucleolus for convex games. It is, in the best case only about its verification. In fact, it is a partial\napplication of the Davis/Maschler reduced game property (RGP) to least-core elements of the convex\ngame _\u27e8_ _N, v \u27e9_ . This can be easily grasped by focusing our attention at level _k_ = 1. Then, the least-core\nvalue of the original convex game is specified in association with an arbitrary optimal allocation _\u20d7x_ that\nsatisfies these constraints. Nevertheless, the authors claim that they have found the nucleolus of the game\n_\u03bd_ ( _N_ [1] _, v_ [1] ) = _\u03bd_ ( _N, v_ ) in line 6 of Algorithm 11.1. Even by inspection of their purported proof, this claim\nis argumentatively fortified. Unfortunately, this argument used by the authors is obviously wrong. In this\nrespect, we need to ask why one should proceed with their method to compute the nucleolus of a convex\ngame when it was already found at the first stage, viz., _k_ = 1; this makes no sense.\n\nFirstly, to decipher the error of the procedure, observe that their proof to assess the correctness of\nAlgorithm 11.1 is based on an incorrect application of RGP, which does not lead to a correct computation\nof the nucleolus. For although the Davis/Maschler reduced game property (RGP) is attributed, for instance,\nto several solution concepts like the core and the pre-kernel (cf. Peleg (1986)), and by the work of Sobolev\n(1975) also to the pre-nucleolus, the authors solely attribute, through their Proposition 2.2, this property to\nthe pre-nucleolus.\n\nIn this context, it is well-known through Maschler et al. (1972) that a Davis/Maschler reduced game\n_\u27e8_ _S, vS, \u20d7x \u27e9_ is convex for a core allocation _\u20d7x_ whenever the default game _\u27e8_ _N, v \u27e9_ is convex. Thus, the con\n\n18\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nvexity property of the Davis/Maschler reduced game is not only restricted to the nucleolus _\u20d7x_ := _\u03bd_ ( _N, v_ ) of\nthe original game _\u27e8_ _N, v \u27e9_ as the authors claim by their Proposition 2.3. It also holds for all reduced games\nthat can be derived from a core allocation of a convex game, i.e., the statement holds for all _\u20d7x \u2208_ C( _N, v_ )\n\u2013 including the nucleolus \u2013 whenever _\u27e8_ _N, v \u27e9_ is convex. The same argument also applies to the formula\napplied by the authors in line 7 of Algorithm 11.1. Interestingly, although the author recognized these\nfacts in the appendix of their work, they completely ignored the implications in their proofs.\n\nContrary to all facts from the literature, they apply, through Proposition 2.2, their own version of RGP.\nThis states that the restriction of the computed nucleolus to the components of coalition _N_ _[k]_ is also the\nnucleolus of the reduced game _\u27e8_ _N_ _[k]_ _, vN_ _k, \u20d7x \u27e9_ . This is, of course, a true statement. However, it puts aside\nthat RGP holds even for all core allocations and not only for the nucleolus.\n\nThis implies that the authors are faced with a serious selection issue, which would only be unproblematic when the least-core of a convex game would be a singleton, which cannot be assured in general\n(see Example 13.1 in connection with Figure 1, for instance). That is to say, their argument that they have\nimposed on the nucleolus applies to all allocations within the core and, therefore, even to all allocations\nin the least-core. As a consequence, the authors cannot guarantee that their algorithm correctly singles\nout the nucleolus of a convex game rather than a profane member of the core that is even an allocation of\nthe least-core. At best, this can only be ensured while supplying the algorithm with the known nucleolus\nof the convex game or that the least-core of the game consists of a single point. By these arguments, we\nconclude that their method might be useful in the verification of a computed candidate of the nucleolus for\na convex game, but not more.\n\nIn this regard, the authors claimed to have provided a first strongly polynomial-time algorithm for\ncomputing the nucleolus of convex games. If anything, these authors can only be credited with having\nsketched an algorithm suitable for checking the nucleolus of a convex game in strongly polynomial time,\nbut not for its computation. Since, according to the arguments above, this cannot be guaranteed with their\nflawed method. Even the suitability to verify the nucleolus needs further adjustment to the algorithm, as it\nrequires knowledge about the maximum surpluses _sij_ ( **x** _, v_ ) over all pairs of players. To simplify matters,\nwe assume the suitability in the sequel to finalize our analysis.\n\nNevertheless, let us take a closer look at the runtime complexity of verifying the nucleolus of a convex\ngame by their method. The estimated total runtime complexity of their approach is about _O_ (Total Runtime) =\n_O_ ( _n_ [4] _\u00b7_ SFM), where SFM denotes a placeholder for a subroutine for submodular function minimization.\nThat means that the overall algorithm for verifying the nucleolus for convex games makes _O_ ( _n_ [4] ) calls\nto the SFM subroutine. One of the best-known subroutines for submodular function minimization at our\ntime can be attributed to the work of Lee et al. (2015) [2] . This algorithm of submodular function minimization has a runtime complexity of _O_ ( _n_ [3] _\u00b7_ log [2] _n \u00b7_ EO + _n_ [4] _\u00b7_ log _[O]_ [(1)] _n_ ), where EO denotes the time\nto evaluate the submodular function on any given subset. Implying that the overall runtime complexity\nof the method proposed by Maggiorano et al. (2025) is given by _O_ ( _n_ [7] _\u00b7_ log [2] _n \u00b7_ EO + _n_ [8] _\u00b7_ log _[O]_ [(1)] _n_ ), or\nas _O_ [\u02dc] ( _n_ [7] _\u00b7_ EO + _n_ [8] ) while ignoring logarithmic factors. Applying an even more favorable polynomialtime estimation of _O_ [\u02dc] ( _n_ [8] ) for their computational approach to test the nucleolus for convex games, this\nimplies that an exponential-time algorithm with an upper bound given by _O_ [\u02dc] (2 _[n]_ ) is outperformed by their\nalgorithm for convex games when 44 players are involved. This is still too large a number for today\u2019s\ndouble-precision computers, so their approach cannot have any practical relevance. Even worse, when\nrelying on the more unfavorable polynomial-time estimation of _O_ ( _n_ [7] _\u00b7_ log [2] _n \u00b7_ EO + _n_ [8] _\u00b7_ log _[O]_ [(1)] _n_ ), let\nus expect that this turning point is achieved for their algorithm beyond the 51-player threshold depending on a bad estimation of EO. This means that one can only expect that their algorithm outperforms an\n\n2Other polynomial-time methods from this line of research are attributable to Chakrabarty et al. (2019); van den Brand (2020)\n\n19\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nexponential-time algorithm with an upper bound of _O_ (2 _[n]_ ) only for the case of quadruple-precision computers. Implying that their approach, though it has, of course, some theoretical flavor, has no practical\nvalue on today\u2019s double-precision computers, although they claim that their approach outperforms by a\nfactor of _n_ [3] the ellipsoid method proposed by Faigle et al. (2001). But this is also what one can expect\nfrom a simple test routine.\n\n### 12 METHOD BY INDIRECT FUNCTION REPRESENTATION\n\nThe Fenchel-Moreau-based approach of Algorithm 3.1, though originally conceived to compute a prekernel element, can, as a byproduct, also be applied to compute the pre-nucleolus for all game classes for\nwhich it is known that the pre-kernel is single-valued. That is to say, not only for convex games, but also\nfor almost-convex games or veto-rich games, just to mention some important game classes with a single\npre-kernel point.\nTo delineate the essential features of Algorithm 3.1, we account for the fact that only _n_ ( _n \u2212_ 1) _/_ 2 + 1\nconstraints are needed, instead of considering a linear problem with an exponentially long set of equations\nby the ellipsoid method. This drastically reduces the order of the constraint set from _O_ (2 _[n]_ ) to _O_ ( _n_ [2] ), so\nthat the overdetermined system of equations can be reformulated into a continuous but non-differentiable\nobjective function. Moreover, the domain of this objective function partitions into a finite set of payoff\nequivalence classes, i.e., convex regions. Within each of these equivalence classes, the complex, nondifferentiable objective function that characterizes the pre-kernel simplifies into a regular quadratic and\nconvex function, allowing us to iteratively solve a system of quadratic convex minimization problems\nassociated with these classes, rather than a single, complex, non-convex problem. Thus, by means of\npayoff equivalence class, the original difficult problem becomes a finite sequence of well-behaved convex\nquadratic minimization problems. At each iteration step, a solution vector of a quadratic optimization\nproblem of type (3.13) is determined, allowing for the simultaneous diminishing of all differences in the\nexcesses among the pair of players. Therefore, just a linear equation of the form **Q x** = **a** must be solved\nby infinite precision via the mapping of 3.15 with a polynomial-time worst-case runtime complexity of\n_O_ ( _n_ [3] ).\n\nFurthermore, under a regime of orthogonal projections, the search space is filtrated for updating the\npayoff vector such that convergence to a pre-kernel element occurs cycle-free. Hence, the application of\northogonal projections ensures that at each step, the updated payoff vector is moved toward a balanced\nstate (where surpluses are equalized) within a subspace corresponding to the current equivalence class.\nThe imposed filtration of the vector space of excess configurations leads to carrying out, instead of an\n_n_ _\u2212_\ninfinite number of transfers, just a finite number of at most (\ufffd2\ufffd 1) side-payments among the pair\nof players to successfully terminate the search process (cf. Meinhardt (2013, Theorem 9.1.2)). Here,\neach iteration step on the payoff space is translated into the vector space of excess configuration while\nincreasing the dimension of the search space at least by one. Typically, this process requires at most\n( _n_ + 1) iterations for an _n_ -player game, instead of the worst-case scenario of \ufffd _n_ 2\ufffd _\u2212_ 1 steps. Hence,\na fast convergence is guaranteed, which is a significant improvement over iterative methods like that of\nMaschler\u2019s approximation method that can have unpredictable or slower convergence.\n\nBy the Fenchel-Moreau-based approach to compute the pre-nucleolus of a game with a single-valued\npre-kernel, one avoids relying on the least-core as a search space that contains the pre-nucleolus. Thereby,\none can dispense with the ellipsoid method or submodular function minimization. Rather, the method\nfocuses directly on the balancedness condition of the maximum surpluses condition, implying that no\nintermediate bound as a pre-nucleolus catcher is needed. It directly navigates toward a pre-kernel element\n\n20\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nwithout needing to first restrict the search to a smaller and bounded set. This implies that the approach\nis more efficient because it is a specialized, elegant, and highly optimized algorithm for the pre-kernel\nthat can also be applied for the pre-nucleolus computation for the indicated game classes. It uses a dual\ncharacterization based on Fenchel-Moreau conjugation but applies it in a structured way that avoids the\ncomplexity and potential inefficiencies of more generic convex optimization methods of this type. Hence,\nthis method is not a general-purpose sequential QP method. It is a highly tailored algorithm specifically\nfor the pre-kernel computation. The power of this approach stems from the specific dual characterization,\nachieved through the indirect function as an increasing polyhedral convex function, which enables us to\nidentify the structure of the pre-kernel.\nMoreover, if it is similar to the work of Faigle et al. (2001) assured that all maximum surpluses _sij_ ( **x** _, v_ )\nover all distinct pairs of players for any allocation **x** _\u2208_ R _[n]_ can be computed by a polynomial-time algorithm. Then, it is also possible to specify the set of lexicographically smallest most significant coalitions (3.10) on the quotient space _dom h/ \u223c_ in polynomial-time. Since finding the smallest or largest item\nin an unsorted array is of linear time in the size of the array. Yet, the assumption made about the maximum\nsurpluses conceals a crucial logical weakness, which will manifest itself as a logical deficiency once it\nproves to be invalid. Similar to the assumption introduced by Faigle et al. to overcome the **NP** -hardness\nissue of computing a pre-kernel point or the pre-nucleolus by their method. Nevertheless, we do not consider the assumption made on the maximum surpluses _sij_ ( **x** _, v_ ) as critical. As the practical relevance of\ntheir computation was proven by our MATLAB software tool MatTuGames (cf. Meinhardt (2025a)) for\nlarge numbers of _n_ up to 35, exploiting successfully the physical limits of our computer resources with 3\nTB of main memory in a reasonable time.\n\nFurthermore, no querying of an oracle in any form is necessary; this is already accomplished by\nthe polynomial-time algorithm for determining all possible maximum surpluses _sij_ ( **x** _, v_ ) at allocation\n**x** . Therefore, there is absolutely no need to evaluate submodular functions or coalitional values by an\noracle. In addition, the model is dealing with infinite precision instead of arbitrary precision. Therefore,\nneither any knowledge about the encoding length of the largest number in the model nor some knowledge\nabout the total number of bits to encode the problem is required. To this end, what we consider a major\nadvantage over the discussed algorithms from above is that no restriction to narrow and bound the search\nspace by a pre-nucleolus catcher is needed. Thus, no additional structure of the problem needs to be evaluated or a separation oracle needs to be queried. It should be evident that exploiting too much structure of\na problem must have negative side effects on the performance of an algorithm. In this context, there is also\nno need to exploit any form of combinatorial property like that of extended polymatroids, or a structural\nproperty of a game class like convexity. This is owed to the fact that the regime of orthogonal projection\nprovides for the filtration of the search space naturally and bounds the number of iteration steps to converge\nto the pre-nucleolus. Then, Algorithm 3.1 is reduced to an algorithm that sends, via the mapping (3.15),\na point _\u20d7\u03b3_ to a point _\u20d7\u03b3\u25e6_ _\u2208_ _M_ ( _h\u20d7\u03b3_ ), i.e., into the solution set of a quadratic optimization problem. This\ncan be accomplished by solving a linear equation with a runtime complexity of _O_ ( _n_ [3] ), which indicates a\npolynomial-time algorithm.\n\nTo compare the algorithms, we have to recognize that the proposed method by Maggiorano et al.\n(2025) might only be applicable for verifying the pre-nucleolus of convex games after implementing some\ndecisive modifications. Obviously, their flawed approach does not even apply to TU games, which are\nnot convex. But when focusing on convex games, we know that the pre-kernel coincides with the prenucleolus in this game class. Hence, computing the sole pre-kernel point, one has found the pre-nucleolus,\nwhichever method one has used. Therefore, whenever one has found the pre-nucleolus for convex games\nby Algorithm 3.1 solving a sequence of linear equations of type (3.15) with a runtime complexity of\n\n21\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\n_O_ ( _n_ [3] ) and at most _n_ + 1 iteration steps (cf. Algorithm 8.1.1 of Meinhardt (2013, Chapter 8)), one has\nscaled much better than solving an iterative process of linear programming problems for nothing having\nruntime complexity of _O_ [\u02dc] ( _n_ [7] _\u00b7_ EO+ _n_ [8] ) with 2 _\u00b7n\u2212_ 2 iteration steps. In contrast to the above, this algorithm\noutperforms an exponential-time algorithm with an upper bound of _O_ (2 _[n]_ ) when 10 players are involved,\nwhich demonstrates even its practical relevance on modern computer architecture.\n\n### 13 REPLICATION OF THE PRE-NUCLEOLUS\n\nAs we mentioned above, the Fenchel-Moreau-based algorithm is even useful for the computation of the\npre-nucleolus whenever it is known that the pre-kernel is a single point, i.e., it coincides with the prenucleolus. Even though it was conceived as a highly tailored algorithm specifically for the pre-kernel\ncomputation. At first glance, this seems to significantly limit the application of this method in determining\nthe pre-nucleolus if we do not possess this kind of knowledge. However, we shall demonstrate that this\nmethod has a much broader flexibility than one might expect, as we resume with the replication results\nof Meinhardt (2024). In this context, replication means showing that a specific solution point from one\ngame can also be found as a solution in a different but related game, even when the parameters of the\noriginal game are modified.\n\nUsing the above structure induced by the Fenchel-Moreau-based characterization of the pre-kernel,\nMeinhardt (2024) could establish a major replication result for a single-valued pre-kernel. This is to say,\nfor the game classes where the pre-kernel coincides with the pre-nucleolus of the game. Roughly speaking,\nthis study explores how a specific point within the pre-imputation set, i.e., the pre-nucleolus of the game,\ncan be replicated whenever the pre-kernel consists of a single point. Turned differently, it can be shown\nthat this point is even the sole pre-kernel point and, therefore, the pre-nucleolus, in a different but related\ngame under certain conditions. Note that such a related game need not have the same game properties as\nthe original game, though it is established that it possesses the same single-valued pre-kernel.\n\nApart from the single-valuedness of the pre-kernel, one of these specific conditions leverages that the\npayoff equivalence class that contains the single pre-kernel point must be full-dimensional, meaning that\nthe payoff equivalence class has a non-empty interior. This non-empty interior condition of the unique\npre-kernel point allows inscribing a full-dimensional ellipsoid within the payoff equivalence class from\nwhich a null space in the game space can be identified. Through these variation bounds, the range within\nthe game space is specified that leaves the pre-kernel element invariant against the group action on the\nset of equivalent ordered bases. This means within this range, the game parameter can be varied without\naffecting the pre-kernel properties of this payoff vector. To put it differently, a variation of the game\nparameter within these bounds does not destroy the pre-kernel properties of the solution from the default\ngame. Implying that these bounds specify a redistribution of the bargaining power among coalitions while\nsupporting the selected pre-imputation still as a pre-kernel point. Even though the values of the maximum\nsurpluses have been varied, the set of most effective coalitions remains unaltered by the parameter change.\nThis indicates that a bargaining outcome related to this specific pre-kernel point remains stable against a\nvariation in the game parameter space, and obstruction is held to account. Hence, a set of related games\ncan be determined that are linearly independent and possess the selected pre-kernel element of the default\ngame as well as a pre-kernel point. And a fortiori, as its pre-nucleolus.\n\nBy Meinhardt (2024), these results have been generalized. There it was established that even on\nthe convex hull comprising the default and related games in the game space, the pre-kernel must be a\nsingle point and is identical with the element specified by the default game. Furthermore, the pre-kernel\ncorrespondence restricted on this convex subset in the game space must be single-valued and consequently\n\n22\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\ncontinuous. Hence, the nucleolus is an invariant (stable) solution on a subdomain of the game space\nfollowing the pre-kernel fairness standards (axioms), and compliance is reality and obstruction held to\n\naccount.\n\nTo deepen the understanding of compliance on non-binding agreements, we refer the reader to Meinhardt (2018), where, from a Cournot situation, four cooperative game models are discussed, each of which\nrepresents different aspiration levels of partners involved in a negotiation process of splitting the monopoly\nproceeds. The bargaining difficulties are demonstrated that might arise when agents are not acting selfconstraint, and what consequences this imposes on the stability of a fair agreement.\n\n**Example 13.1.** To present for the reader a summary of the ease and the elegance of a Fenchel-Moreaubased approach for computing the pre-nucleolus of a game with a single-valued pre-kernel, we shall consolidate this knowledge in a manually derived step-by-step procedure for a game example that we have\nborrowed from the literature. Besides the pre-nucleolus computation, we also demonstrate the flexibility\nof this approach by discussing the associated replication results. By doing so, we consider a four-person\nconvex game, which we have picked up from the work of Maggiorano et al. (2025). This game is specified\nby\n\n_v_ ( _S_ ) :=\n\n\uf8f1\uf8f4\uf8f43 if _S_ = _{_ 1 _,_ 2 _}, {_ 2 _,_ 3 _}, {_ 2 _,_ 3 _,_ 4 _},_\n\uf8f4\n\uf8f46 if _S_ = _{_ 1 _,_ 2 _,_ 3 _}, {_ 1 _,_ 2 _,_ 4 _}_ ;\n\uf8f2\uf8f4\uf8f410 if _S_ = _N,_\n\n\uf8f4\n\uf8f4\uf8f30 otherwise _,_\n\nfor all _S \u2286_ _N_ with _N_ = _{_ 1 _,_ 2 _,_ 3 _,_ 4 _}_ . To visualize some results, in the Figure 1, we have plotted\nthe core of game _v_ as a yellow polytope with its 11 vertices in connection with the imputation set\n(skeleton-like triangle). Secondly, the least-core as a line segment, which is given by the convex hull\n_conv {{_ 3 _,_ 3 _,_ 2 _,_ 2 _}, {_ 2 _,_ 4 _,_ 2 _,_ 2 _}}_, is included in the graphic. Thirdly, the Shapley value (blue enlarged dot),\nthe modiclus (cyan enlarged dot), and the pre-nucleolus (red enlarged dot), which is identical to the nucleolus, are drawn. The least-core has an _\u03f5_ -value of _\u2212_ 2, which is indicated in the headline of the figure.\nFurthermore, all mentioned point solutions are core members. The nucleolus is in the center of the leastcore, i.e., the line segment spanned by the extreme points of the least-core. [3] .\n\nFurther inspection reveals that this game has a veto-player, who is player two. A property that is\nmuch easier to test than convexity, especially for large values of _n_ . Hence, apart from convexity, the\ngame is even a veto-rich game, which gives an additional cause that the pre-kernel must coalesce with\nthe pre-nucleolus (cf. Arin and Feltkamp (1997)), whereas its outcome is given by the point _\u03bd_ ( _v_ ) =\nPK( _v_ ) = (5 _/_ 2 _,_ 7 _/_ 2 _,_ 2 _,_ 2). Obviously, the set of lexicographically smallest most significant coalitions\nS( _\u03bd_ ( _v_ )) = _{{_ 1 _}, {_ 3 _}, {_ 4 _}, {_ 2 _,_ 3 _}, {_ 1 _,_ 2 _,_ 3 _}, {_ 1 _,_ 2 _,_ 4 _}}_ is balanced. From this set, a boundary vector _[\u20d7]_ _b_ =\n(5 _/_ 2 _,_ 2 _,_ 2 _,_ 11 _/_ 2 _,_ 8 _,_ 8) is obtained by _\u03bd_ ( _v_ )( _S_ ) for _S \u2208_ S( _\u03bd_ ( _v_ )). Define matrix **A** by [ **1** _S_ ] _S\u2208_ S( _\u03bd_ ( _v_ )), then\nthe solution of the system **A x** = _[\u20d7]_ _b_ reproduces the pre-nucleolus. Moreover, this imputation is even an\ninterior point of the payoff equivalence class composed by this collection. To see this, select an _\u03f5 >_ 0\nsufficiently small and let **z** _\u2208_ R [4] s.t. _z_ ( _N_ ) = 0; then one can establish that S( _\u03bd_ ( _v_ )+ _\u03f5_ **z** ) = S( _\u03bd_ ( _v_ )) holds.\nThus, the non-empty interior condition is valid. Due to Meinhardt (2024, Theorem 4.1), a redistribution of\nthe bargaining power among coalitions can be obtained while supporting the imputation (5 _/_ 2 _,_ 7 _/_ 2 _,_ 2 _,_ 2)\nstill as a pre-kernel element for a set of related games. In order to get a null space N **W**, we set the\nparameter _\u00b5_ to _\u2212_ 1 _._ 5. In this case, the rank of matrix **W** must be equal to 4, and we could derive 10 from\nat most 11-linear independent games, which replicate the point (5 _/_ 2 _,_ 7 _/_ 2 _,_ 2 _,_ 2) as a pre-kernel element.\n\n3The figure has been generated with our Mathematica Package TuGames implemented within Meinhardt (2023).\n\n23\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nFigure 1: The Imputation Set, Core, Least-Core, Nucleolus, Shapley value and Modiclus of Game _v_\n\nMoreover, Meinhardt (2024, Theorem 4.4) even states that this point is also the sole pre-kernel point;\nhence, the pre-kernel coincides with the pre-nucleolus for these games.\n\nTable 13.1: List of Games [f] with the same single-valued Pre-Kernel (Nucleolus) [a] as _v_\n\n_\u00b5_ = _\u2212_ 1 _._ 5\nGame _{_ 1 _}_ _{_ 2 _}_ _{_ 1 _,_ 2 _}_ _{_ 3 _}_ _{_ 1 _,_ 3 _}_ _{_ 2 _,_ 3 _}_ _{_ 1 _,_ 2 _,_ 3 _}_ _{_ 4 _}_\n\n_v_ 0 0 3 0 0 3 6 0\n\n_v_ 1 -16/27 -39/46 272/107 1/45 -38/83 65/27 271/45 1/45\n_v_ 2 -21/79 15/29 125/31 3/47 -28/95 216/79 285/47 3/47\n_v_ 3 -21/52 7/52 381/143 -23/32 -50/31 135/52 169/32 -23/32\n_v_ 4 -13/43 14/139 169/64 -9/52 15/74 116/43 303/52 -9/52\n_v_ 5 -13/43 14/139 169/64 -9/52 15/74 116/43 303/52 -9/52\n_v_ 6 -13/43 14/139 169/64 -9/52 15/74 116/43 303/52 -9/52\n_v_ 7 -6/61 2/61 273/97 4/23 1/48 177/61 142/23 4/23\n_v_ 8 -6/61 2/61 273/97 4/23 1/48 177/61 142/23 4/23\n_v_ 9 -6/61 2/61 273/97 4/23 1/48 177/61 142/23 4/23\n_v_ 10 -6/61 2/61 273/97 4/23 1/48 177/61 142/23 4/23\nContinued on next page\n\n24\n\n![](papers/images/PolynomialTime-Algorithms-for-Computing-the-Nucleolus-An-Assessment.pdf-24-0.png)\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\n**Table 13.1 \u2013 continued from previous page**\n\n_\u00b5_ = _\u2212_ 1 _._ 5\nGame _{_ 1 _,_ 4 _}_ _{_ 2 _,_ 4 _}_ _{_ 1 _,_ 2 _,_ 4 _}_ _{_ 3 _,_ 4 _}_ _{_ 1 _,_ 3 _,_ 4 _}_ _{_ 2 _,_ 3 _,_ 4 _}_ _N_ CV [d] SCV [e] CR [f]\n\n_v_ 0 0 6 0 0 3 10 Y Y Y\n\n_v_ 1 -33/79 -35/52 271/45 -3/37 -47/88 317/136 10 N Y Y\n_v_ 2 -83/152 9/38 285/47 23/65 -7/57 93/32 10 N Y Y\n_v_ 3 -96/95 -17/36 169/32 -79/68 -237/142 94/37 10 N Y Y\n_v_ 4 -61/45 29/53 303/52 -7/20 -6/7 91/29 10 N Y Y\n_v_ 5 13/90 -20/21 303/52 -7/20 9/14 95/58 10 N Y Y\n_v_ 6 13/90 29/53 303/52 -7/20 9/14 91/29 10 N Y Y\n_v_ 7 4/29 25/93 142/23 -81/89 -19/25 123/58 10 N Y Y\n_v_ 8 4/29 25/93 142/23 23/39 -19/25 105/292 10 N Y Y\n_v_ 9 4/29 25/93 142/23 23/39 37/50 123/58 10 N Y Y\n_v_ 10 4/29 25/93 142/23 23/39 37/50 105/29 10 N Y Y\n\na Pre-Kernel and Pre-Nucleolus: (5 _/_ 2 _,_ 7 _/_ 2 _,_ 2 _,_ 2)\nb Modiclus: _\u03c2_ _\u2217_ ( _N, v_ ) = (5 _/_ 2 _,_ 5 _,_ 5 _/_ 2 _,_ 0)\nc Shapley Value: _\u03d5_ ( _N, v_ ) = (11 _/_ 4 _,_ 17 _/_ 4 _,_ 7 _/_ 4 _,_ 5 _/_ 4)\nd CV: Convex Game.\n\ne SCV: Semi Convex Game.\nf CR: Game with non-empty Core.\ng Note: Computation performed with MatTuGames (cf. Meinhardt (2025a)).\n\nFrom Table 13.1, we realize that the pre-nucleolus is stable against an induced variation in the game\nparameter. More precisely, the pre-nucleolus is invariant against a parameter variation within the specific\ninterval of _\u00b5 \u2208_ ( _\u2212_ 1 _._ 5 _,_ 1 _._ 4). To get an idea about the underlying bargain stability, we just mention here\nthat the convex hull of the collection of games _{v, . . ., v_ 10 _}_ form a subset in the game space \u2013 the game\nsetting has not changed, and with it not the figure of argumentation during the bargaining process; only the\nbargaining power of the coalitions has been changed without affecting the outcome of the game. Within\nthis convex set, each TU game has exactly the above element as its sole pre-kernel point. This implies\nthat we have identified a stable bargaining scenario where a settlement of an agreement is not problematic\nwhile referring to the principles of distributive justice (axioms) related to the pre-kernel. The agreement\nbased on these principles remains stable after having varied the parameter set within the specified range.\nTherefore, the selected agreement point cannot be obstructed by the principles that describe the pre-kernel\nwithin this subset of the game space. Though the figure of argumentation has not referred to the norms of\ndistributive arbitration based on the nucleolus, the nucleolus as a bargaining outcome is stable due to its\ncoincidence with the pre-kernel, and the incentive to cooperate remains valid.\n\nTo illustrate how Algorithm 3.1 works to compute the pre-nucleolus for games with a single-valued\npre-kernel, let us focus on the pre-selected efficient payoff vector **y** 0 = (10 _,_ 0 _,_ 0 _,_ 0) _[\u22a4]_ to see how we can\napply this method for our specific example. By doing so, we look at the maximum surpluses for all pairs\nof players. For any pair of players _i, j \u2208_ _N, i \u0338_ = _j_, the maximum surplus of player _i_ over player _j_ with\nrespect to any pre-imputation **x** is given by the maximum excess at **x** over the set of coalitions containing\nplayer _i_ but not player _j_ . Thus,\n\n_sij_ ( **x** _, v_ ) := max where G _ij_ := _{S | i \u2208_ _S_ and _j /\u2208_ _S}._\n_S\u2208_ G _ij_ _[e][v]_ [(] _[S,]_ **[ x]** [)]\n\nThe expression _sij_ ( **x** _, v_ ) describes the maximum amount at the pre-imputation **x** that player _i_ can gain\nwithout the cooperation of player _j_ .\nFrom the excess vector _exc_ ( **y** 0), we now get the subsequent set of lexicographically smallest coalitions\nfor each pair of players\n\n25\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nS( **y** 0) = _{{_ 1 _}, {_ 1 _,_ 2 _,_ 4 _}, {_ 1 _,_ 2 _,_ 3 _}, {_ 2 _}, {_ 2 _,_ 3 _}, {_ 2 _,_ 3 _}, {_ 2 _,_ 3 _}, {_ 2 _,_ 3 _}, {_ 3 _}, {_ 2 _,_ 3 _,_ 4 _}, {_ 4 _}, {_ 4 _}},_\n\nwhereas the order of the pairs of players in S( **y** 0) is given by\n\n_{_ (1 _,_ 2) _,_ (1 _,_ 3) _,_ (1 _,_ 4) _,_ (2 _,_ 3) _,_ (2 _,_ 4) _,_ (3 _,_ 4) _,_ (2 _,_ 1) _,_ (3 _,_ 1) _,_ (3 _,_ 2) _,_ (4 _,_ 1) _,_ (4 _,_ 2) _,_ (4 _,_ 3) _}._\n\nTo see how the selection process for the collection S( **y** 0) works, let us exemplarily consider the pair\nof players (1 _,_ 2). Focusing on this pair, we single out these coalitions that support the claim of player 1\nwithout counting on the cooperation of player 2. These are the coalitions _{{_ 1 _}, {_ 1 _,_ 3 _}, {_ 1 _,_ 4 _}, {_ 1 _,_ 3 _,_ 4 _}}_ all\nhaving an excess of _\u2212_ 10. Thus, all coalitions have maximum surplus, and the collection has a cardinality\nlarger than 1. If the collection has not a sole element, we have to apply two steps to find the lexicographically smallest coalition for the pair (1 _,_ 2). For the preceding case, both steps coincide, however. In order\nto proceed, we determine all the coalitions that have the smallest cardinality, which is coalition _{_ 1 _}_ . Since\nthis set is unique, we have also determined the coalition that has a lexicographically minimum value in\nstep one. Otherwise, at step two, we have to single out the lexicographically smallest coalition from an\nambiguous collection. To observe how we have to proceed if this set is not unique, let us hypothetically\nassume for this purpose that the excess of coalition _{_ 1 _}_ is smaller than _\u2212_ 10. This implies that coalition _{_ 1 _}_ is deleted from the list since it does not have maximum surplus. Hence, the collection has been\nmodified to _{{_ 1 _,_ 3 _}, {_ 1 _,_ 4 _}, {_ 1 _,_ 3 _,_ 4 _}}_ . All of them have maximum surpluses, the smallest cardinality of a\ncoalition from this collection is now 2, and we single out the coalitions _{{_ 1 _,_ 3 _}, {_ 1 _,_ 4 _}}_ and take finally\nthe lexicographical minimum, which is _{{_ 1 _,_ 3 _}}_ .\nFor the reverse pair (2 _,_ 1), we find out that coalition _{_ 2 _,_ 3 _}_ supports best the claim of player 2 without\ntaking into account the cooperation of player 1. Proceeding the same way for the remaining pairs, then\nwe derive a matrix **E** by **E** _ij_ = **1** _Sji \u2212_ **1** _Sij_ for each _i, j \u2208_ _N, i < j_, and **E** 0 = **1** _N_ . Notice that\n**1** _S_ : _N \ufffd\u2192{_ 0 _,_ 1 _}_ is the characteristic vector given by **1** _S_ ( _k_ ) := 1 if _k \u2208_ _S_ ; otherwise, **1** _S_ ( _k_ ) := 0. Then,\nmatrix **E** is defined by\n\n4 _\u00d7_ 7\n**E** := [ **E** 1 _,_ 2 _, . . .,_ **E** 3 _,_ 4 _,_ **E** 0] _\u2208_ R _._\n\nWe realize that vector **E** 1 _,_ 2 is given by (0 _,_ 1 _,_ 1 _,_ 0) _[\u22a4]_ _\u2212_ (1 _,_ 0 _,_ 0 _,_ 0) _[\u22a4]_ = ( _\u2212_ 1 _,_ 1 _,_ 1 _,_ 0) _[\u22a4]_ and **E** 0 = (1 _,_ 1 _,_ 1 _,_ 1) _[\u22a4]_ .\nA similar procedure applies to the remaining pairs of players; matrix **E** is quantified by\n\n\uf8f9\n\n_._\n\uf8fa\uf8fa\uf8fb\n\n**E** =\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n_\u2212_ 1 _\u2212_ 1 _\u2212_ 1 0 0 0 1\n\n1 0 0 _\u2212_ 1 _\u2212_ 1 _\u2212_ 1 1\n\n1 1 0 1 _\u2212_ 1 _\u2212_ 1 1\n\n0 _\u2212_ 1 1 0 1 1 1\n\nA column vector **a** can be obtained by **E** _\u20d7\u03b1 \u2208_ R _[n]_, whereas the vector _\u20d7\u03b1_ is given by\n\n_\u03b1ij_ := ( _v_ ( _Sji_ ) _\u2212_ _v_ ( _Sij_ )) _\u2208_ R _,_\n\nfor all _i, j \u2208_ _N, i < j_, and _\u03b1_ 0 := _v_ ( _N_ ). Therefore, vector _\u20d7\u03b1_ is given by\n\n(3 _, \u2212_ 3 _, \u2212_ 3 _,_ 0 _, \u2212_ 3 _, \u2212_ 3 _,_ 10) _[\u22a4]_ _._\n\n.\n\n26\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nFrom this matrix, we construct matrix **Q** by **E E** _[\u22a4]_ . Inserting its numbers, matrix **Q** is specified by\n\n\uf8f9\n\n_._\n\uf8fa\uf8fa\uf8fb\n\n**Q** =\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n4 0 _\u2212_ 1 1\n\n0 5 3 _\u2212_ 1\n\n_\u2212_ 1 3 6 _\u2212_ 2\n\n1 _\u2212_ 1 _\u2212_ 2 5\n\nThe column vector **a** is given by (13 _,_ 19 _,_ 16 _,_ 4) _[\u22a4]_ .\nSolving this system of linear equations **Q x** _\u2212_ **a** = **0**, or alternatively **E** _[\u22a4]_ **x** _\u2212_ _\u20d7\u03b1_ = **0**, we get as a\nsolution **y** 1 = (128 _/_ 37 _,_ 98 _/_ 37 _,_ 91 _/_ 37 _,_ 60 _/_ 37) _[\u22a4]_, which is not a pre-imputation. Since the corresponding\nexcess vector is given through\n\n_exc_ ( **y** 1) = (0 _, \u2212_ 128 _/_ 37 _, \u2212_ 98 _/_ 37 _, \u2212_ 115 _/_ 37 _, \u2212_ 91 _/_ 37 _, \u2212_ 219 _/_ 37 _, \u2212_ 78 _/_ 37 _, \u2212_ 95 _/_ 37 _,_\n\n_\u2212_ 60 _/_ 37 _, \u2212_ 188 _/_ 37 _, \u2212_ 158 _/_ 37 _, \u2212_ 64 _/_ 37 _, \u2212_ 151 _/_ 37 _, \u2212_ 279 _/_ 37 _, \u2212_ 138 _/_ 37 _, \u2212_ 7 _/_ 37) _._\n\nWe observe that the excess of the grand coalition is negative with _\u2212_ 7 _/_ 37 because of the violation of\nthe efficiency property. Therefore, the maximum surpluses can not be balanced. Hence, we need at least\nan additional iteration step to complete.\nFor the second iteration step, we use the vector **y** 1 = (128 _/_ 37 _,_ 98 _/_ 37 _,_ 91 _/_ 37 _,_ 60 _/_ 37) _[\u22a4]_ while applying\nthe procedure from above to get matrix **E** by\n\n_._\n\uf8fa\uf8fa\uf8fb\n\n\uf8f9\n\n**E** =\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n_\u2212_ 1 _\u2212_ 1 _\u2212_ 1 _\u2212_ 1 0 0 1\n\n1 0 _\u2212_ 1 _\u2212_ 1 _\u2212_ 1 _\u2212_ 1 1\n\n1 1 _\u2212_ 1 1 _\u2212_ 1 _\u2212_ 1 1\n\n0 _\u2212_ 1 1 _\u2212_ 1 1 1 1\n\nWith _\u20d7\u03b1_ given by (3 _, \u2212_ 3 _, \u2212_ 6 _, \u2212_ 6 _, \u2212_ 3 _, \u2212_ 3 _,_ 10) _[\u22a4]_ . Quantifying now matrix **Q** through\n\n\uf8f9\n\n_._\n\uf8fa\uf8fa\uf8fb\n\n**Q** =\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n5 2 _\u2212_ 1 2\n\n2 6 4 _\u2212_ 1\n\n_\u2212_ 1 4 7 _\u2212_ 4\n\n2 _\u2212_ 1 _\u2212_ 4 6\n\nThe column vector **a** is given by (22 _,_ 31 _,_ 16 _,_ 7) _[\u22a4]_ . Solving this system of linear equations, **Q x** _\u2212_ **a** = **0**,\nwe get as a solution **y** 2 = (329 _/_ 127 _,_ 423 _/_ 127 _,_ 255 _/_ 127 _,_ 279 _/_ 127) _[\u22a4]_ . The corresponding excess vector is\ngiven through\n\n_exc_ ( **y** 2) = (0 _, \u2212_ 329 _/_ 127 _, \u2212_ 423 _/_ 127 _, \u2212_ 371 _/_ 127 _, \u2212_ 255 _/_ 127 _, \u2212_ 584 _/_ 127 _, \u2212_ 297 _/_ 127 _, \u2212_ 245 _/_ 127 _,_\n\n_\u2212_ 279 _/_ 127 _, \u2212_ 608 _/_ 127 _, \u2212_ 702 _/_ 127 _, \u2212_ 269 _/_ 127 _, \u2212_ 534 _/_ 127 _, \u2212_ 863 _/_ 127 _, \u2212_ 576 _/_ 127 _, \u2212_ 16 _/_ 127) _._\n\nWe can check out that the maximum surpluses are still not balanced. Hence, we need an additional step\nto finally converge to the pre-nucleolus. By doing so, we solve the system of linear equations specified by\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n\uf8f9\n\n=\n\uf8fa\uf8fa\uf8fb\n\n\uf8f9\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n31\n\n37\n\n13\n\n10\n\n\uf8f9\n\n\uf8fa\uf8fa\uf8fb\n\n\uf8f9\n\n_\u00b7_\n\uf8fa\uf8fa\uf8fb\n\n**Q x** = **a** = _\u21d2_\n\n\uf8ee64 46 02 11\n\n0 2 7 _\u2212_ 4\n\n\uf8ef\uf8ef\uf8f01 1 _\u2212_ 4 6\n\n27\n\n_x_ 1\n\n_x_ 2\n\n_x_ 3\n\n_x_ 4\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nThe solution vector of this system of linear equations is given by **y** 3 = (5 _/_ 2 _,_ 7 _/_ 2 _,_ 2 _,_ 2) _[\u22a4]_ . By the subsequent symmetric matrix below, we can easily check out that the maximum surpluses at **y** 3 are balanced.\n\n\uf8f9\n\n_._\n\uf8fa\uf8fa\uf8fb\n\n**MSurp** =\n\n\uf8ee\n\n\uf8ef\uf8ef\uf8f0\n\n0 _\u2212_ 5 _/_ 2 _\u2212_ 2 _\u2212_ 2\n_\u2212_ 5 _/_ 2 0 _\u2212_ 2 _\u2212_ 2\n_\u2212_ 2 _\u2212_ 2 0 _\u2212_ 2\n\n_\u2212_ 2 _\u2212_ 2 _\u2212_ 2 0\n\nHence, we have found the sole pre-kernel element of the game, which is also the nucleolus, because of\nzero-monotonicity of convex games.\n\nNotice that in this specific case, we needed only three iteration steps to complete, which is below the\ntheoretical-expected upper bound of iteration steps since by Theorem 9.2.1 of Meinhardt (2013, p. 222),\nwe have \ufffd42\ufffd _\u2212_ 1 = 6 _\u2212_ 1 = 5 to expect. Notice, this method is applicable for any _n_ -person TU game\n(cf. Meinhardt (2013, Appendix A)) and has also been proven to be useful in finding an N-shaped prekernel (cf. Meinhardt (2014)).\n\n### 14 SUMMARY ASSESSMENT OF THE ALGORITHMS\n\nThe conducted assessment has established that the new combinatorial algorithm of Maggiorano et al.\n(2025) does not offer an efficient method to compute the nucleolus of convex games. This is owed to\nthe fact that the authors have incorrectly applied the RGP so that the algorithm cannot lead to a correct\ncomputation of the nucleolus. Instead of providing a combinatorial and strongly polynomial algorithm,\noffering an alternative to the less practical ellipsoid method used by Faigle et al. (2001), their approach\nis at best suitable in testing the correctness of a presumed nucleolus solution. But even this needs further\ncrucial corrections on the proposed algorithm. Despite its possible usefulness in the verification of a\ncomputed nucleolus solution, their suggested method possesses the intrinsic defect that it relies on the\nleast-core to catch the nucleolus of a convex game. This makes it necessary to impose a submodular\nfunction minimization approach in testing the feasibility of the least-core constraints in polynomial-time.\nThereby resulting in a relatively high order of _O_ [\u02dc] ( _n_ [8] ) in its runtime complexity even when one of the bestknown general SFM algorithms is taken as a basis. All this makes their proposed method impractical even\nwhen considering only testing purposes on today\u2019s double-precision computers.\n\nThough conceived as a highly tailored algorithm specifically for the pre-kernel computation, the\nFenchel-Moreau-based algorithm invented by Meinhardt (2013) is also applicable for the pre-nucleolus\ncomputation for the specific game classes with a single-valued pre-kernel. That is to say, when the prekernel and pre-nucleolus coincide, then this approach can be used to find this unique point. For this specific\ncase, Meinhardt\u2019s method with a runtime complexity of _O_ ( _n_ [3] ) is a more efficient approach than the general combinatorial testing algorithm for the nucleolus on convex games as proposed by Maggiorano et al.\n(2025). Unfortunately, although the Fenchel-Moreau-based method, while effective for all game classes\nwith a single-valued pre-kernel, might not have been recognized as a general-purpose, robust algorithm\nfor the pre-nucleolus in the broader theoretical literature.\n\nThis is incomprehensible, since, as shown by Meinhardt (2013, 2018, 2024, 2025b), this approach\noffers many more benefits, such as providing a simple, tractable computation method for the pre-kernel and\npre-nucleolus. Besides a dual pre-kernel characterization, it offers a vast theoretical advantage as it eases\nthe analysis of the pre-kernel and related solutions considerably. For this, the study by Meinhardt (2024)\nwas revisited using an example from the literature in this regard. The focus is on how variations in game\nparameters, specifically coalition values, affect the pre-kernel solution, and in particular, the pre-nucleolus\n\n28\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nof a convex game. It is demonstrated for this example that under the non-empty interior condition, an\nexposed pre-kernel element from a default game can be maintained as a pre-kernel solution in a related\ngame, even when coalition values are altered. This replication result is achieved by identifying a null\nspace within the game space, allowing for variations in coalition values without disrupting the pre-kernel\nproperties of the solution. This invokes the following implications for the pre-nucleolus:\n\n1. **Replication of a Pre-Kernel Point** : If the pre-kernel of a TU game consists of a single point and, in\naddition, it belongs to a payoff equivalence class with a non-empty interior, then it is replicable as a\npre-kernel solution in a related game. Hence, the pre-nucleolus of the default game was replicated.\n\n2. **Stability of Pre-Kernel Properties** : The replication allows for variations in game parameters (like\ncoalitional values) without altering the fundamental pre-kernel properties of the selected solution,\neffectively supporting the pre-imputation as a pre-kernel point. Hence, the default pre-nucleolus of\nthe original game is a stable bargaining outcome.\n\n3. **Continuity of the Pre-Kernel Correspondence** : It is established that the pre-kernel correspondence (the mapping from games to pre-kernel points) can be single-valued and continuous on restricted subsets of the game space. Hence, the pre-nucleolus solution is stable on the convex domain\nof related games.\n\nFinally, for the example, it was demonstrated how this pre-nucleolus can be manually computed by a\nstep-by-step procedure using the underlying structure of the Fenchel-Moreau conjugation approach.\n\n### REFERENCES\n\nJ. Arin and V. Feltkamp. The Nucleolus and Kernel of Veto-Rich Transferable Utility Games. _International Journal of Game_\n_Theory_ [, 26:61\u201373, 1997. URL https://doi.org/10.1007/BF01262513.](https://doi.org/10.1007/BF01262513)\n\n[D. Chakrabarty, Y. T. Lee, A. Sidford, S. Singla, and S. C.-W. Wong. Faster Matroid Intersection, 2019. URL https://](https://arxiv.org/abs/1911.10765)\n[arxiv.org/abs/1911.10765.](https://arxiv.org/abs/1911.10765)\n\nM. Davis and M. Maschler. The Kernel of a Cooperative Game. _Naval Research Logistic Quarterly_, 12:223\u2013259, 1965.\n\nU. Faigle, W. Kern, and J. Kuipers. Note: Computing the nucleolus of min-cost spanning tree games is NP-hard. _International_\n_Journal of Game Theory_ [, 27(3):443\u2013450, 1998. doi: 10.1007/s001820050083. URL https://doi.org/10.1007/](https://doi.org/10.1007/s001820050083)\n\n[s001820050083.](https://doi.org/10.1007/s001820050083)\n\nU. Faigle, W. Kern, and J. Kuipers. On the Computation of the Nucleolus of a Cooperative Game. _International Journal of Game_\n_Theory_ [, 30(1):79\u201398, 2001. doi: 10.1007/s001820100065. URL https://doi.org/10.1007/s001820100065.](https://doi.org/10.1007/s001820100065)\n\nD. Granot, M. Maschler, G. Owen, and W.R. Zhu. The kernel/nucleolus of a standard tree game. _International Journal of Game_\n_Theory_ [, 25(3):219\u2013244, 1996. URL https://doi.org/10.1007/BF01247104.](https://doi.org/10.1007/BF01247104)\n\nM. Gr\u00f6tschel, L. Lov\u00e1sz, and A. Schrijver. The Ellipsoid Method and its consequences in Combinatorial Optimization. _Combi-_\n_natorica_ [, 1:169\u2013197, 1981. doi: 10.1007/BF02579273. URL https://doi.org/10.1007/BF02579273.](https://doi.org/10.1007/BF02579273)\n\nM. Gr\u00f6tschel, L. Lov\u00e1sz, and A. Schrijver, editors. _Geometric Algorithms and Combinatorial Optimization_ . SpringerVerlag, Berlin, 2 edition, 2012. doi: 10.1007/978-3-642-78240-4. [URL https://doi.org/10.1007/](https://doi.org/10.1007/978-3-642-78240-4)\n\n[978-3-642-78240-4.](https://doi.org/10.1007/978-3-642-78240-4)\n\nW. Kern and D. Paulusma. Matching games: The least core and the nucleolus. _Mathematics of Operations Research_, 28(2):\n[294\u2013308, 2003. ISSN 0364765X, 15265471. URL http://www.jstor.org/stable/4127022.](http://www.jstor.org/stable/4127022)\n\nL. Khachiyan. A polynomial time Algorithm in Linear Programming. _Doklady Akademii Nauk SSR_, 244:1093\u20131096, 1979.\nEnglish Translation: Soviet Mathematics Doklady 20: 191\u2013194.\n\n29\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nK. Kido. A nonlinear Approximation of the Nucleolus. In W. Takahashi and T. Tanaka, editors, _Proceedings of the International_\n_Conference on Nonlinear Analysis and Convex Analysis_, pages 307\u2013317, Tokyo, 2004. Yokohama Publishers, Yokohama,\nJapan.\n\nK. Kido. Convergence Theorems for _lp_ -Norm Minimizers with respect to _p_ . _Journal of Optimization Theory and Applications_,\n125:577\u2013589, 2005.\n\nK. Kido. A Modified Kohlberg Criterion and a Nonlinear Method to compute the Nucleolus of a Cooperative Game. _Taiwanese_\n_Journal of Mathematics_, 12:1581\u20131590, 2008.\n\nE. Kohlberg. The Nucleolus as a Solution of a Minimization Problem. _SIAM, Journal of Applied Mathematics_, 23:34\u201339, 1972.\n\nA Kopelowitz. Computation of the Kernels of Simple Games and the Nucleolus of _N_ -Person Games. Technical report, RM 31,\nResearch Program in Game Theory and Mathematical Economics, The Hebrew University of Jerusalem, 1967. mimeo.\n\nY. T. Lee, A. Sidford, and S. C.-W. Wong. A Faster Cutting Plane Method and its Implications for Combinatorial and Convex\n[Optimization, 2015. URL https://arxiv.org/abs/1508.04874.](https://arxiv.org/abs/1508.04874)\n\nG. Maggiorano, A. Sosso, and G. Stauffer. A Strongly Polynomial-Time Combinatorial Algorithm for the Nucleolus in Convex\n[Games, 2025. URL https://arxiv.org/abs/2509.02380.](https://arxiv.org/abs/2509.02380)\n\nJ-E. Martinez-Legaz. Dual Representation of Cooperative Games based on Fenchel-Moreau Conjugation. _Optimization_, 36:\n291\u2013319, 1996.\n\nM. Maschler, B. Peleg, and L.S. Shapley. The Kernel and Bargaining Set for Convex Games. _International Journal of Game_\n_Theory_, 1:73\u201393, 1972.\n\nM. Maschler, B. Peleg, and L. S. Shapley. Geometric Properties of the Kernel, Nucleolus, and Related Solution Concepts.\n_Mathematics of Operations Research_, 4:303\u2013338, 1979.\n\nN. Megiddo. Computational Complexity of the Game Theory Approach to Cost Allocation for a Tree. _Mathematics of Operations_\n_Research_ [, 3(3):189\u2013196, 1978. URL https://doi.org/10.1287/moor.3.3.189.](https://doi.org/10.1287/moor.3.3.189)\n\nH. I. Meinhardt. _The Pre-Kernel as a Tractable Solution for Cooperative Games: An Exercise in Algorithmic Game Theory_,\nvolume 45 of _Theory and Decision Library: Series C_ . Springer Publisher, Heidelberg/Berlin, 2013. ISBN 978-3-642-39548[2. doi: 10.1007/978-3-642-39549-9. URL https://doi.org/10.1007/978-3-642-39549-9.](https://doi.org/10.1007/978-3-642-39549-9)\n\nH. I. Meinhardt. A Note on the Computation of the Pre-Kernel for Permutation Games. Technical Report MPRA-59365, Karlsruhe\n[Institute of Technology (KIT), May 2014. URL http://mpra.ub.uni-muenchen.de/59365/.](http://mpra.ub.uni-muenchen.de/59365/)\n\nH. I. Meinhardt. _The Pre-Kernel as a Fair Division Rule for Some Cooperative Game Models_, pages 235\u2013266. Springer\n[International Publishing, Cham, 2018. ISBN 978-3-319-61603-2. doi: 10.1007/978-3-319-61603-2_11. URL https:](https://doi.org/10.1007/978-3-319-61603-2_11)\n[//doi.org/10.1007/978-3-319-61603-2_11.](https://doi.org/10.1007/978-3-319-61603-2_11)\n\nH. I. Meinhardt. Deduction Theorem: The Problematic Nature of Common Practice in Game Theory. _arXiv e-prints_, art.\n[arXiv:1908.00409, Aug 2021. URL https://arxiv.org/abs/1908.00409v2.](https://arxiv.org/abs/1908.00409v2)\n\n[H. I. Meinhardt. TuGames: A Mathematica Package for Cooperative Game Theory, 2023. URL https://github.com/](https://github.com/himeinhardt/TuGames)\n[himeinhardt/TuGames.](https://github.com/himeinhardt/TuGames)\n\nH. I. Meinhardt. On the Replication of the Pre-Kernel and Related Solutions. _Computational Economics_, 64:871\u2013946, 2024.\n[URL http://dx.doi.org/10.1007/s10614-023-10428-w. Online available 2023.](http://dx.doi.org/10.1007/s10614-023-10428-w)\n\n[H. I. Meinhardt. MatTuGames: A Matlab Toolbox for Cooperative Game Theory, 2025a. URL http://www.mathworks.](http://www.mathworks.com/matlabcentral/fileexchange/35933-mattugames)\n[com/matlabcentral/fileexchange/35933-mattugames.](http://www.mathworks.com/matlabcentral/fileexchange/35933-mattugames)\n\nH. I. Meinhardt. Analysis of Cooperative Games with Matlab and Mathematica. Technical report, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany, 2025b. mimeo.\n\nA. Meseguer-Artola. Using the Indirect Function to characterize the Kernel of a TU-Game. Technical report, Departament\nd\u2019Economia i d\u2019Hist\u00f2ria Econ\u00f2mica, Universitat Aut\u00f2noma de Barcelona, Nov. 1997. mimeo.\n\n30\n\n_Polynomial-Time Algorithms for Computing the Nucleolus_\n\nG. Owen. A Note on the Nucleolus. _International Journal of Game Theory_ [, 3(2):101\u2013103, 1974. URL https://doi.org/](https://doi.org/10.1007/BF01766395)\n[10.1007/BF01766395.](https://doi.org/10.1007/BF01766395)\n\nB. Peleg. On the Reduced Game Property and its Converse. _International Journal of Game Theory_, 15:187\u2013200, 1986.\n\nB. Peleg and P. Sudh\u00f6lter. _Introduction to the Theory of Cooperative Games_, volume 34 of _Theory and Decision Library: Series_\n_C_ . Springer-Verlag, Heidelberg, 2 edition, 2007.\n\nR. Rockafellar. _Convex Analysis_ . Princeton University Press, Princeton, 1970.\n\nL. S. Shapley. Cores of Convex Games,. _International Journal of Game Theory_, 1:11\u201326, 1971.\n\nA. J. Sobolev. The Characterization of Optimality Principles in Cooperative Games by Functional Equations. In N. N. Vorobjev,\neditor, _Matematicheskie Metody v Sotsial\u2019nykh Naukakh, Proceedings of the Seminar_, pages 94\u2013151, Vilnius, 1975. Institute\nof Physics and Mathematics, Academy of Sciences of the Lithuanian SSR. (in Russian, English summary).\n\nT. Solymosi. The Kernel is in the Least Core for Permutation Games. _Central European Journal of Operations Research_,\n[pages 1\u201315, March 2014. ISSN 1435-246X. doi: 10.1007/s10100-014-0342-y. URL http://dx.doi.org/10.1007/](http://dx.doi.org/10.1007/s10100-014-0342-y)\n[s10100-014-0342-y.](http://dx.doi.org/10.1007/s10100-014-0342-y)\n\nT. Solymosi and T.E.S Raghavan. An Algorithm for Finding the Nucleolus of Assignment Games. _International Journal of Game_\n_Theory_, 6:94\u2013151, 1994.\n\nR.E. Stearns. Convergent Transfer Schemes for _N_ -Person Games. _Transaction of the American Mathematical Society_, 134:\n449\u2013459, 1968.\n\nP. Sudh\u00f6lter and J. A. M. Potters. The semireactive Bargaining Set of a Cooperative Game. _International Journal of Game_\n_Theory_ [, 30:117\u2013139, 2001. doi: 10.1007/s001820100068. URL https://doi.org/10.1007/s001820100068.](https://doi.org/10.1007/s001820100068)\n\nJ. F. Traub and H. Wo\u00b4zniakowski. Complexity of linear programming. _Operations Research Letters_, 1(2):59\u201362, 1982.\n[ISSN 0167-6377. doi: https://doi.org/10.1016/0167-6377(82)90047-5. URL https://www.sciencedirect.com/](https://www.sciencedirect.com/science/article/pii/0167637782900475)\n[science/article/pii/0167637782900475.](https://www.sciencedirect.com/science/article/pii/0167637782900475)\n\n[J. van den Brand. A Deterministic Linear Program Solver in Current Matrix Multiplication Time, 2020. URL https://](https://arxiv.org/abs/1910.11957)\n[arxiv.org/abs/1910.11957.](https://arxiv.org/abs/1910.11957)\n\n31"}, {"role": "assistant", "content": "**Mechanism:** The Fenchel-Moreau-based approach directly optimizes a non-differentiable objective function by reformulating it into a sequence of tractable quadratic convex minimization problems, rather than using iterative approximation or set-reduction methods like ellipsoids or least-core. This is achieved by partitioning the problem's domain into 'payoff equivalence classes' where the objective function behaves like a simple quadratic, allowing direct algebraic solution via linear systems (Qx=a). Orthogonal projections filter the search space to ensure cycle-free convergence by dimension increment, effectively guiding the solution towards the pre-kernel. For suitable game classes, this translates to finding the pre-nucleolus.\n\n**Explanation:** Stearns' algorithm is an iterative 'balancing act': it identifies the pair of players with the largest difference in 'surpluses' (dissatisfaction) and makes a side-payment to reduce this imbalance. This is a greedy, local optimization, but it can be slow and requires infinite transfers for exact convergence, similar to an iterative refinement loop that never truly finishes in floating-point. The Ellipsoid method works by maintaining an N-dimensional ellipsoid guaranteed to contain the solution. It uses a 'separation oracle' (like a conditional statement in code) to check if a test point is feasible; if not, it generates a hyperplane (a line or plane) that cuts the ellipsoid, creating a new, smaller one containing the solution. For rational data, this requires multi-precision arithmetic (like `BigInt` objects) where operations take time proportional to bit length, making the polynomial complexity dependent on input size `L`. For 'real' data, if infinite precision is assumed (Real RAM model), its runtime becomes unbounded because arbitrary precision (epsilon) can be requested, which logarithmically increases iterations (log(1/epsilon)). Crucially, in finite-precision (floating-point), accumulation of small rounding errors can cause the ellipsoid's defining matrix to lose its positive definite property (a mathematical requirement for it to be a valid ellipsoid), making the algorithm unstable and potentially fail. Maggiorano et al. attempted to use submodular function minimization (SFM, a subroutine for specific optimization problems) to check the feasibility of the 'least-core' (a region containing the nucleolus) within 'reduced games'. However, the paper argues their application of the Reduced Game Property (RGP) is flawed; RGP holds for all core allocations, not just the nucleolus, leading to a 'selection issue' where the algorithm might pick any core element, not necessarily the nucleolus. Thus, it cannot reliably compute the nucleolus, only verify a candidate. Meinhardt's Fenchel-Moreau approach, instead of searching a 'catcher' set like the least-core, directly tackles the 'balancedness condition' of maximum surpluses. It leverages dual characterization to transform the complex, non-differentiable problem into simpler, convex quadratic problems within specific regions (payoff equivalence classes). This allows direct solution of `Qx=a` (a matrix equation solvable by standard linear algebra methods like Gaussian elimination, often implemented with `O(n^3)` complexity). The use of orthogonal projections ensures fast, cycle-free convergence by systematically reducing the 'excess configuration' space. For games where the pre-kernel is unique (which implies it's the pre-nucleolus), this method is efficient and robust, demonstrated even to produce stable solutions under parameter changes due to the 'full-dimensional payoff equivalence class' property."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n( _\ud835\udc5d_ ( _\ud835\udc63_ ) _, \ud835\udc63_ ) \u2208 _\ud835\udf0f_ 0 **then**\n\n**23** vol_sum. _\ud835\udc34\ud835\udc51\ud835\udc51_ (DFSin[ _\ud835\udc5d_ ( _\ud835\udc63_ )], DFSout[ _\ud835\udc5d_ ( _\ud835\udc63_ )], vol[ _\ud835\udc63_ ]\u22122 _\ud835\udc5a_ ) ;"}, {"role": "assistant", "content": "**Mechanism:** This snippet executes a conditional update operation within a graph traversal context, likely a Depth First Search (DFS). It adds a computed value to an aggregate sum (`vol_sum`) if a specific edge condition is met.\n\n**Explanation:** The condition `(p(v), v) \u2208 \u03c40` acts as a guard clause: it checks if the edge connecting the parent node `p(v)` to the current node `v` belongs to a predefined set `\u03c40`. If true, an `Add` method is invoked on `vol_sum`. This `Add` function takes three arguments: `DFSin[p(v)]` (the DFS entry timestamp or index of the parent), `DFSout[p(v)]` (the DFS exit timestamp or index of the parent), and an adjusted volume `vol[v] - 2m`. This structure suggests `vol_sum` is a data structure like a segment tree or Fenwick tree, where `DFSin` and `DFSout` define a range, and `vol[v] - 2m` is a value to be propagated or added across that range, effectively associating a modified value from the current node `v` with the processing interval or subtree of its parent `p(v)`."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc4e\ud835\udc61\ud835\udc52_ == _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc35\ud835\udc4a_ **and** _\ud835\udc35\ud835\udc35\ud835\udc45_\ud835\udc3c\ud835\udc60_\ud835\udc41\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_\ud835\udc43\u210e\ud835\udc4e\ud835\udc60\ud835\udc52_ () **then**\n\n**62** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc34\ud835\udc51\ud835\udc63\ud835\udc4e\ud835\udc5b\ud835\udc50\ud835\udc52_ _ _\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc43\u210e\ud835\udc4e\ud835\udc60\ud835\udc52_ () ;\n\n**63** BBR_Is_Next_Cycle_Phase():\n\n**64** _\ud835\udc56\ud835\udc60_ _ _\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e_ = ( _\ud835\udc41\ud835\udc5c\ud835\udc64_ () \u2212 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ ) _> \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ ;"}, {"role": "assistant", "content": "**Mechanism:** This code manages a state transition in a cyclical algorithm based on two conditions: the current operational state and a time-based duration check.\n\n**Explanation:** This block controls when the BBR algorithm advances its internal cycle phase. It first checks if the current state is `ProbeBW`, meaning it's actively trying to discover network capacity. Concurrently, it calls `BBR_Is_Next_Cycle_Phase()` which acts like a timer. This function determines if a 'full length' of time, specifically longer than the `BBR.RTprop` (Round Trip Propagation time), has elapsed since the current cycle phase began (`BBR.cycle_stamp`). If both conditions are met, the `_Advance_Cycle_Phase_()` function is called. This mechanism ensures that the system waits for at least one full round-trip observation period before changing its behavior, allowing it to gather sufficient feedback from the network. It's akin to a timed state machine where a phase change is guarded by both an active state and a minimum temporal window, preventing premature transitions that could destabilize network performance."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section presents the Adaptive Rollout Engine, which\ndynamically adjusts SD strategies in response to real-time\nworkload characteristics. It supports both learning-based\n\n|B1|B2|Col3|B3|Col5|B4|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n|8|16|16|32|32|48|4<br>6<br>|\n\n**Figure 10. Memory footprint of CUDA Graph for SD** .\nS1\u223cS4 denote different SD strategies, B1\u223cB4 represent batchsize buckets. Memory and throughput values are illustrative.\n\nand model-free SD, and incorporates a bucketed multi-armed\nbandit (MAB) tuner to automatically configure strategies.\n\n**5.1** **Adaptive SD Manager**\n\n**Tree-based Drafting** . Unlike linear drafting, which processes a single sequence, tree-based drafting extends this\nsingle-branch paradigm by enabling parallel exploration of\nmultiple speculative paths. Following [25, 36], we build the\ncandidate tree based on the draft model\u2019s confidence score\n\n(token probability), as illustrated in Figure 9. Starting from\nthe input prompt (\"Climate\"), the draft model predicts potential next tokens. The tree-based approach explores the\ntopK most likely options at each step (e.g., topK=2 yields\n\"change\" and \"control\"), and this branching continues for\nDraft_Depth steps, creating a tree of candidate sequences.\nFinally, the Tokens_to_Verify=8 highest-confidence tokens\nwithin the tree are chosen and submitted to the target model\nfor parallel verification. By exploring and verifying multiple potential sequences simultaneously, tree-based drafting substantially increases the number of accepted tokens\nper verification step, thereby improving overall generation\nthroughput with more effective utilization of parallel compute resources.\n**Adaptivity is Necessary** . While the SD is primarily designed to accelerate the long-tail stage, we observe that SD\ncan also deliver speedups at moderate batch sizes (Table 2).\nHowever, this requires adaptive adjustment of SD strategies\naccording to the decoding batch size and workload characteristics. Prior work [25, 26, 67] mainly focuses on batchsize=1\nscenarios, which limits its applicability in real-world scenarios. RL rollout naturally involve highly dynamic batch sizes:\nthey begin large and then shrink rapidly as short responses\ncomplete. Static SD strategies are therefore both inefficient\nand unsafe, as they may cause Out-of-Memory (OOM) failures under large batches. To address this, the Adaptive SD\nManager continuously tunes SD parameters\u2014choosing safe\nstrategies to prevent OOM, maximizing throughput by learning effective strategies for each workload, and balancing\n\n7\n\nspeculative gains against computational overhead. In addition, to handle large batch sizes where SD offers little benefit,\nit employs an elastic mechanism that activates SD only when\nthe remaining request count drops below a configurable\nthreshold (default: 32).\n**Memory-Efficient CUDAGraph Capture** . To accelerate\nLLM decoding, CUDAGraph is commonly adopted, providing substantial speedup by recording CUDA operations and\nreplaying them as a single unit, which reduces per-kernel\nlaunch costs during inference. However, CUDAGraph requires capturing a separate static graph for each batch size\nand strategy, including both target and draft models. This inflexible paradigm leads to a considerable memory footprint.\nUnder the Multiple-Strategy setting (Figure 10 (b)), memory\nusage grows linearly with the number of strategies, leaving\ninsufficient space for model weights and KV caches, which\nis unacceptable in practice.\nTo accommodate more SD strategies without incurring\nprohibitive memory costs, we propose Bucketed CUDAGraph\nCapture (Figure 10 (c)), which incorporates three key optimizations: (1) Bucketed batch sizes. Instead of capturing a\nstatic graph for every possible batch size, we exploit strategyspecific characteristics (e.g., larger batch sizes typically require verifying fewer tokens) and group batch sizes into\n\n\u223c\nseveral buckets (e.g., B1 B4). (2) Disaggregated capture for\ntarget and draft models. Since some configurations affect\nonly one model (e.g., topK impacts only the drafter, while\nTokens_to_Verify affects only the target), we capture graphs\nfor target and draft models separately to avoid multiplicative\nmemory consumption. (3) Merged captures across strategies. When different strategies share identical parameter\nsettings, we merge their batchsize buckets into a single captured graph, eliminating redundant memory overhead. By\nintegrating these optimizations, we substantially reduce the\nCUDAGraph memory footprint (Table 3) while improving\nrollout throughput. The throughput gain stems from leveraging prior knowledge to avoid evaluating suboptimal strategies that are unsuitable for specific batch sizes.\n\n**5.2** **Auto-Tune Algorithm**\n\n**Bucketed** _\ud835\udf16_ **-Greedy MAB** . Multi-Armed Bandit (MAB) algorithms are a classical framework for online decision-making,\nexcelling at maximizing cumulative gains when selecting\nactions (\u201carms\u201d) with uncertain rewards [54, 57]. Each \"arm\"\ncorresponds to a specific speculative decoding configuration\ntuple: (Draft_Depth, topK, Tokens_to_Verify), and the \"reward\" reflects the efficiency within the generation step (i.e.,\naccepted_token_num/step_latency).\nTo automate the selection of SD strategies, we design\na new online tuning algorithm, Bucketed-Epsilon-Greedy\n(BEG) MAB Selector (Algorithm 1). BEG adopts an _\ud835\udf16_ -greedy\npolicy tailored to speculative decoding workloads. It buckets\nstrategies according to their Tokens_to_Verify and dynamically match them to batchsize ranges. Specifically, strategies\n\n**Algorithm 1** Bucketed-Epsilon-Greedy (BEG) MAB Selector\n\n**Input: Strategies:** S, **Batch Thresholds:** T = { _\ud835\udc61_ 1 _, . . .,\ud835\udc61\ud835\udc5a_ }, **Ex-**\n**ploration:** _\ud835\udf16_, **Window Size:** _\ud835\udc64_\n**Output:** Selected strategy _\ud835\udc60_ [\u2217]\n\n1: **procedure** Initialize(S _,_ T _,\ud835\udf16,\ud835\udc64_ )\n2: GroupByVerifyTokens(S) \u2192{S1 _, . . .,_ S _\ud835\udc5a_ } (sorted by Tokens_to_Verify, descending)\n3: Define buckets B _\ud835\udc56_ = [ _\ud835\udc61\ud835\udc56,\ud835\udc61\ud835\udc56_ +1\u22121] for _\ud835\udc56_ _< \ud835\udc5a_ and B _\ud835\udc5a_ = [ _\ud835\udc61\ud835\udc5a,_ \u221e)\n4: Map bucket B _\ud835\udc56_ \u21a6\u2192 group S _\ud835\udc56_\n5: **for all** _\ud835\udc60_ \u2208S **do**\n\n6: _\ud835\udc45\ud835\udc60,\ud835\udc34\ud835\udc60_ \u2190 deque ( _\ud835\udc64_ ) \u25b7 _init double-ended queue (size \ud835\udc64)_\n\n7: **procedure** Record( elapsed_time, accept_lens, batch_size)\n8: ~~_\ud835\udc4e_~~ \u2190 [\ufffd\ufffd] accept_lens [\ufffd] /batch_size + 1\n9: _\ud835\udc5f\ud835\udc60_ \u2190 ~~_\ud835\udc4e_~~ \u00d7 batch_size/elapsed_time\n10: Append _\ud835\udc5f\ud835\udc60_ to _\ud835\udc45\ud835\udc60_ ; Append ~~_\ud835\udc4e_~~ to _\ud835\udc34\ud835\udc60_ - _reward & acc_len_\n\n11: **procedure** SelectStrategy(batch_size)\n12: _\ud835\udc49_ \u2190{ _\ud835\udc60_ \u2208S _\ud835\udc56_ | batch_size \u2208B _\ud835\udc56_ } - _candidate strategies_\n13: **if** | _\ud835\udc49_ | = 1 **then**\n14: **return** the unique _\ud835\udc60_ \u2208 _\ud835\udc49_\n\n15: Draw _\ud835\udc62_ \u223c Uniform(0 _,_ 1)\n16: **if** _\ud835\udc62_ _< \ud835\udf16_ **then**\n\n17: **return** random _\ud835\udc60_ \u2208 _\ud835\udc49_ - _explore_\n18: **else**\n\n19: **return** arg max _\ud835\udc60_ \u2208 _\ud835\udc49_ Median( _\ud835\udc45\ud835\udc60_ ) - _exploit_\n\nS are grouped by Tokens_to_Verify into S1 _, . . .,_ S _\ud835\udc5a_, and\neach group is mapped to a batch-size bucket B _\ud835\udc56_ . During rollout, the current batch size determines the relevant candidate\nset _\ud835\udc49_ . If | _\ud835\udc49_ | = 1, the strategy is fixed; otherwise, BEG selects\nbetween exploration and exploitation. With probability _\ud835\udf16_, a\nstrategy is drawn uniformly at random from _\ud835\udc49_ (exploration).\nWith probability 1 \u2212 _\ud835\udf16_, BEG selects the strategy maximizing\nthe median reward over a sliding window of size _\ud835\udc64_ (exploitation). The reward (line: 9) balances accept rate and latency\ncost. Maintaining deques of recent rewards ensures adaptation to non-stationary dynamics across RL training.\nBy combining bucketed strategy selection, lightweight _\ud835\udf16_  greedy exploration, and sliding-window reward estimation,\nBEG reduces the overhead of exhaustive exploration while\nadapting efficiently to workload variations. This enables TLT\nto scale across diverse batchsizes and speculative decoding\nstrategies without manual tuning.\n\n**5.3** **Model-free Drafter**\n\n**Leveraging Similarity across Rollouts** . During the RL\nrollout stage, candidate responses generated for the same\nprompt often exhibit evident _sequence similarity_ and contain repetitive patterns, such as common mathematical notation or code syntax structures. This observation suggests\nthat frequent, short-range token dependencies can be predicted effectively using retrieval methods. To leverage this,\nTLT incorporates a complementary, non-parametric drafting\nstrategy alongside the primary learning-based drafter. This\nmodel-free drafter operates by dynamically building an ngram retrieval database populated from the rollout responses\n\n8\n\nspecific to each prompt. Based on the immediate context (the\npreceding n-grams), it efficiently predicts common subsequent token sequences by querying this database.\nWithin TLT, the model-free drafter serves as both a robust\nbaseline and an essential fallback mechanism. The Strategy\nSelector dynamically activates this retrieval-based drafter\nwhenever the learning-based drafter is unavailable (e.g., during initial training steps) or predicted to be inefficient. This\ndual-drafter approach ensures that speculative decoding acceleration remains active throughout all stages of the RL\nprocess, contributing to persistent efficiency gains."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is adaptive control over speculative decoding (SD) strategies, driven by real-time workload characteristics. Tree-based drafting uses a probabilistic branch-and-bound-like approach; instead of a single path, it explores multiple top-K token predictions from a draft model, forming a candidate tree. It then prunes this tree by selecting a fixed number of high-confidence tokens for parallel verification, effectively turning a sequential decoding step into a parallel one. Adaptivity is a feedback loop: the system observes current batch sizes and resource usage (like memory), and based on pre-defined thresholds or learned efficiency metrics, it switches between different SD configurations (Draft_Depth, topK, Tokens_to_Verify). This is critical because larger batch sizes dramatically increase memory pressure. CUDAGraph capture optimizes GPU kernel launch overhead by recording a sequence of operations into a single callable unit. The memory problem arises because each unique (batch size, SD strategy) combination requires a separate static graph, leading to a combinatorial explosion. The solution involves reducing the number of unique graphs needed: 'bucketing' maps a range of batch sizes to a single graph (like a `switch` statement over an `enum` of batch size categories), 'disaggregation' separates target and draft model graphs (reducing `N_configs_total` to `N_target_configs + N_draft_configs`), and 'merging' reuses graphs if different strategies yield identical underlying GPU operations (like multiple pointers to the same object). The auto-tuning uses a Bucketed Epsilon-Greedy Multi-Armed Bandit (MAB). This is an explore-exploit algorithm: with probability `epsilon`, it randomly selects an SD strategy from a 'bucket' (a subset of strategies grouped by `Tokens_to_Verify` and matched to a batch-size range). Otherwise, it 'exploits' by choosing the strategy with the best median reward (accepted tokens per step latency) from a sliding window of recent performance. This sliding window acts like a FIFO queue, allowing the system to adapt to changing performance characteristics over time.\n\n**Explanation:** This system makes LLM generation faster by intelligently pre-guessing parts of the response. Instead of predicting one word at a time, it uses a 'draft' model to quickly suggest several possible next words, like branches on a tree. It then picks the most confident ones from these branches and sends them all at once to the main, 'target' model for a quick check. This is much faster because the main model can verify many words in parallel. The system also knows that sometimes you have many requests at once (a large 'batch size'), and sometimes only a few. It intelligently changes its guessing strategy based on the batch size. For example, with many requests, it might be more conservative to avoid using up all the computer's memory. With fewer requests, it can be more aggressive to maximize speed. To make these speedups work without using too much computer memory, especially on the GPU, it employs clever tricks for recording sequences of GPU operations. Instead of recording a separate sequence for every tiny variation in guessing strategy or batch size, it groups similar situations together and reuses recorded sequences. For instance, if a batch of 8, 10, or 12 requests all behave similarly enough, they'll use the same recorded sequence, saving a lot of memory. This also applies to different parts of the guessing process (drafting vs. verifying) and even different strategies if they happen to use the same underlying steps. Finally, the system automatically learns the best guessing strategy for any given situation. It does this by trying different strategies sometimes ('exploration') and sticking with the best-performing ones most of the time ('exploitation'), continually updating its knowledge based on how fast and accurate each strategy proves to be, and adapting as the workload changes."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**The AIePS developemnt Lifecycle and Role of Data Anno-**\n**tation.** The development of AI-enabled systems involves multiple stages, data collection, annotation, model training, evaluation, deployment, and monitoring [9, 23]. Among these, data\nannotation\u2014the transformation of raw sensor data into labelled\n\ndatasets\u2014is a crucial and resource-intensive phase [11]. By labelling\nimages, point clouds, or sensor sequences with bounding boxes, segmentation masks, or object classes, annotators create the ground\ntruth essential for model learning, where annotation quality directly impacts performance, generalisation, and decision accuracy\nin safety-critical domains [12, 15].\n\n**Data Annotation Error.** The annotation errors are incor\nrect, incomplete, or inconsistent labels in training or validation\n\ndata [17, 19], arising from human variability, ambiguous guidelines, limited tools, or weak quality assurance [13, 22]. Examples\ninclude misclassifying pedestrians on scooters, inconsistently labelling occlusions, or omitting small objects, all of which introduce\nnoise that weakens model learning [31, 40]. These errors can propagate throughout the AI lifecycle, leading to false detections, sensor\nmisinterpretations, and reduced safety in real-world driving [7, 41].\n\n**Data Quality Dimensions.** Research identifies three core\ndimensions of data quality: completeness, accuracy, and consistency as key indicators of reliable data representation [2, 3, 27, 37].\nOriginally established in information systems [27, 37], this framework now underpins modern AI models and annotation quality\nassessment. Our taxonomy builds upon these classical dimensions.\nCompleteness reflects whether all required data are present and\nrelevant real-world entities or attributes are captured [2, 3]. In\nannotation, missing objects or scenarios ( _e.g.,_ pedestrians in poor\nlighting) represent completeness errors that reduce dataset representativeness. Accuracy measures how closely annotations ( _e.g.,_\nbounding boxes, segmentation masks) match true real-world conditions [2, 27]; misaligned boxes or incorrect labels exemplify accuracy errors. Consistency concerns uniformity across annotators,\nscenes, or systems [2, 3]. Inconsistent labelling of similar objects\nor frames constitutes a consistency error that undermines reproducibility, fairness, and reliability.\n\n**Annotation Quality Across the AI Lifecycle in Industrial**\n**Supply Chains.** AIePS development spans a complex supply chain\nof OEMs, Tier-1, and Tier-2 suppliers [11, 15]. Each uses distinct\nannotation tools, standards, and quality controls, resulting in heterogeneous datasets where early-stage errors can propagate through\nmodel training, validation, and integration [22]. Consequently, annotation quality represents a dynamic, lifecycle-spanning assurance\nchallenge that directly influences the dependability, maintainability,\nand trustworthiness of AI-enabled systems [10, 31]."}, {"role": "assistant", "content": "**Mechanism:** Data annotation creates the 'ground truth' mapping between raw input signals (like image pixels or sensor readings) and their intended semantic meaning (labels like 'pedestrian', 'bounding box coordinates'). This transforms unstructured data into structured data records that serve as the direct learning targets for machine learning models.\n\n**Explanation:** When a machine learning model 'learns', it's essentially trying to derive a mathematical function that takes raw input as an argument and consistently returns the correct label as its output. Data annotation errors fundamentally corrupt the input-output pairs the model uses to infer this function. Consider the three types: 'Completeness' is like having missing values in critical fields of a database table. If your dataset for 'cars' doesn't include any red cars, the model's derived function for 'car' will be incomplete and struggle with red cars in the real world. 'Accuracy' is akin to having incorrect values in those fields \u2013 labeling a 'cat' as a 'dog' means the function learns to associate 'cat-like' features with the 'dog' output, directly distorting its internal representations. 'Consistency' is like having the same data represented in multiple, conflicting formats within the database \u2013 sometimes 'true' is 'T', sometimes '1', sometimes 'True'. The model sees this as noise, making it harder to converge on a single, robust mathematical rule for generalization. Each error type introduces noise or omissions that prevent the algorithm from accurately discovering the underlying data distribution or the correct input-output mapping, resulting in a less performant, less reliable derived function."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Experimental Setup**\n\nOur experiments use AMD Ryzen\u2122AI 9 HX 370 (Strix Point NPU).\nWe program the NPU using the IRON API and the MLIR-AIE\ntoolchain [14] to measure performance under three precision configurations: **Config 1:** BF16\u2013BFP16 mixed-precision. Input _\ud835\udc34_ and\noutput _\ud835\udc36_ are in BF16, weights _\ud835\udc35_ are in BFP16, and accumulation is\nperformed in BF16. **Config 2:** _\ud835\udc34_, _\ud835\udc35_, and _\ud835\udc36_ are all stored in BFP16,\nwith accumulation also performed in BFP16. **Config 3:** _\ud835\udc34_, _\ud835\udc35_, and _\ud835\udc36_\nare all stored in BFP16, with accumulation performed in BF16.\n\n**6.2** **Kernel Performance**\n\nTable 1 summarizes both microkernel-level performance (Perfmicro,\nEffmicro) and full core-level performance (Perfcore, Effcore) across\ndifferent combinations of _\ud835\udc47\ud835\udc3e_ and _\ud835\udf0c_, evaluated under precision Config 1 with L1 tile sizes _\ud835\udc47\ud835\udc40\ud835\udc34_ = 128 and _\ud835\udc47\ud835\udc41_ = 128. For _\ud835\udc47\ud835\udc3e_ = 64, the\n\nChengyue Wang [1], Wesley Pang [2], Xinrui Wu [1], Gregory Jun [2], Luis Romero [3], Endri Taka [4], Diana Marculescu [4], Tony Nowatzki [1], Pranathi Vasireddy [5], Joseph Melber [5], Deming Chen [2],\nConference\u201917, July 2017, Washington, DC, USA Jason Cong [1]\n\n**Table 2: Whole-array BF16/BFP16 GEMM speedup across configurations.**\n\nPrecision Source Problem size(M\u00d7K\u00d7N) ( _\ud835\udc47\ud835\udc40\ud835\udc36_ _[\ud835\udc3f]_ [1] L1 tile size [\u00d7] _[\ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1] [\u00d7] _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] [)] _\ud835\udf0c_ Used Buffer(KB) Buffer if _\ud835\udf0c_ = 1 (Tflops)Perfcore Compute-bound(Tflops) AI(op/B)array Memory-bound(Tflops) Perf(Tflops)array\n\nBF16-INT4 Ryzen AI 2048\u00d74096\u00d74096 Unknown 1 Unk Unk Unk Unk Unk Unk 10.4\n\nMLIR-AIE 8192\u00d74224\u00d74096 64\u00d788\u00d764 1 50.4 50.4 0.32 **10.2** 216 14.1 4.8 (1.00\u00d7)\n\nConfig 1\n\n2048\u00d74096\u00d72048 64\u00d764\u00d7128 1 54.5 54.5 0.95 30.5 273 **17.8** 17.3 (3.61\u00d7)\nOurs 2048\u00d74480\u00d72048 64\u00d7224\u00d764 4 57.4 111 0.96 30.7 217 **14.1** 12.3 (2.56\u00d7)\n4096\u00d74096\u00d72048 128\u00d764\u00d7128 4 60.3 91 0.95 30.4 410 **26.6** 24.3 (4.54\u00d7)\n\nMLIR-AIE 7680\u00d74096\u00d78192 96\u00d7128\u00d764 1 58.5 58.5 0.38 **12.2** 333 21.7 10.2 (1.00\u00d7)\nConfig 2 Ours 4096\u00d74096\u00d72048 128\u00d764\u00d7128 1 54 54 0.84 **26.9** 504 32.8 25.9 (2.54\u00d7)\n\n4096\u00d74096\u00d72048 256\u00d764\u00d7128 8 58.5 90 0.73 **23.3** 728 47.3 22.3 (2.19\u00d7)\n3072\u00d74096\u00d71536 192\u00d7128\u00d796 6 56.3 101 1.06 **33.9** 562 36.5 31.3 (3.07\u00d7)\n\nConfig 3 Ours 3072\u00d74096\u00d72048 96\u00d764\u00d7128 1 57 57 1.00 32 418 **27.2** 27.0 (2.65\u00d7)\n4096\u00d74096\u00d72048 128\u00d764\u00d7128 4 56.5 70 0.90 **28.8** 504 32.8 28.5 (2.79\u00d7)\n\nconfigurations _\ud835\udf0c_ = 1 and _\ud835\udf0c_ = 2 exceed the available 63 KB L1\nmemory capacity, and for _\ud835\udc47\ud835\udc3e_ = 32, _\ud835\udf0c_ = 1 also exceeds it.\nOverall, the measured results closely follow the analytical trends\npredicted in Section 5. As expected, microkernel efficiency Effmicro\ndepends only on _\ud835\udc47\ud835\udc3e_ and is almost invariant across _\ud835\udf0c_ . For a fixed\n_\ud835\udc47\ud835\udc3e_, increasing _\ud835\udf0c_ consistently reduces core efficiency Effcore because\nlarger asymmetry increases the number of microkernel switches\nand amplifies launch overheads. For example, at _\ud835\udc47\ud835\udc3e_ = 8, Effcore\ndecreases by 25.6% (from 0 _._ 156 to 0 _._ 116) as _\ud835\udf0c_ increases from 1 to 8.\nAt _\ud835\udc47\ud835\udc3e_ = 64, the reduction is much smaller, only 5.8% (from 0 _._ 511\nto 0 _._ 482), because a larger _\ud835\udc47\ud835\udc3e_ yields longer kernel execution and\ntherefore better amortization of the switching cost. In contrast, for a\nfixed _\ud835\udf0c_, a larger _\ud835\udc47\ud835\udc3e_ improves both the efficiency of the microkernel\nand the core by extending the steady state and reducing the relative\nimpact of the prolog/epilog cycles. At _\ud835\udf0c_ = 4, Effcore increases from\n0 _._ 134 at _\ud835\udc47\ud835\udc3e_ = 8 to 0 _._ 511 at _\ud835\udc47\ud835\udc3e_ = 64, a 3 _._ 8\u00d7 improvement. These results match the theoretical prediction that core efficiency improves\nwith larger _\ud835\udc47\ud835\udc3e_ while increasing _\ud835\udf0c_ reduces efficiency.\nAdditionally, MLIR-AIE [9] achieves only 0.32 TFLOPS on a\nsingle core, while our best design reaches 0.92 TFLOPS\u2014a 2.88\u00d7\nimprovement. Their approach relies primarily on compiler-driven\noptimization, which is ineffective for BFP16, while our kernel design\napplies manual scheduling techniques such as unrolling, registerlevel tiling, explicit register binding, and double buffering.\n\n**Table 3: Performance of whole-array GEMM under varying**\n**matrix problem sizes.**\n\nM K N Performance (Tflops)\n\n1024 2048 2048 19.2\n\n1024 4096 2048 21.8\n\n1024 8192 2048 23.3\n\n2048 2048 2048 21.8\n\n2048 4096 2048 23.3\n\n2048 8192 2048 24.0\n\n4096 2048 2048 23.2\n\n4096 4096 2048 24.3\n\n4096 8192 2048 24.6\n\n**6.3** **Whole Array Performance**\n\nTable 2 reports full-array GEMM throughput across three configurations, comparing our kernels against both the AMD MLIR-AIE [9]\n\nand the BF16\u2013INT4 backend used in AMD Ryzen AI [8] (DynamicDispatch [7]). For each problem size, the table lists the measured\nsingle-core throughput, the compute-bound limit (Perfcore \u00d7 32\ncores), the arithmetic intensity, and the corresponding memorybound limit ( AIarray \u00d7 off-chip bandwidth), as defined in Eq. 12.\nAcross all configurations, our kernels substantially outperform\nthe state-of-the-art MLIR-AIE and Ryzen AI baselines. In Config 1,\nour best design reaches 24.3 TFLOPS, a 4.54\u00d7 speedup over MLIRAIE\u2019s 4.8 TFLOPS. Config 2 shows similar gains, with throughput\nup to 31.3 TFLOPS (3.07\u00d7 over the 10.2 TFLOPS baseline). Config 3 achieves 28.5 TFLOPS, exceeding the MLIR-AIE Config 2 by\n2.79\u00d7 while simultaneously offering higher accumulation precision.\nCompared to the Ryzen AI BF16\u2013INT4 GEMM (10.4 TFLOPS), our\nConfig 1 BF16\u2013BFP16 GEMM delivers 24.3 TFLOPS, providing a\n2.4\u00d7 improvement while using higher precision.\nWe can observe the impact of ATB in Table 2. In Config 1, all three\nconfigurations are memory-bound. ATB enables the 128\u00d764\u00d7128\ntile, which would require 91 KB and be infeasible under symmetric\nbuffering. With ATB, this configuration becomes valid and improves\nthroughput from 17.3 to 24.3 TFLOPS\u2014a 40% gain. Fixing _\ud835\udf0c_ = 4\nalso highlights the effect of _\ud835\udc47\ud835\udc3e_ : the 64 \u00d7 224 \u00d7 64 kernel achieves\nonly 56% of the throughput of the 128\u00d764\u00d7128 tile, since larger _\ud835\udc47\ud835\udc3e_\nforces smaller ( _\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc41_ ) and reduces AI. These observations match\nthe theoretical prediction that memory-bound kernels benefit from\nsmaller _\ud835\udc47\ud835\udc3e_ and larger _\ud835\udf0c_, which enable larger ( _\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc41_ ).\nConfig 2 is mostly compute-bound and shows the trade-off between AI and core efficiency. Although 256\u00d764\u00d7128 has higher\nAI, its lower core efficiency limits performance; the 192\u00d7128\u00d796\ntile, with larger _\ud835\udc47\ud835\udc3e_, reaches 31.3 TFLOPS. ATB is again essential:\nwithout it, this configuration would require 101 KB and would not\nfit in L1, and ATB provides a 21% throughput gain over the symmetric case. Config 3 further shows that ATB can move GEMM from\nmemory-bound to compute-bound. The final performance does not\nincrease noticeably because the kernel is already compute-bound.\nIn summary, when memory-bound, ATB helps increase arithmetic\nintensity through larger ( _\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc41_ ); when compute-bound, ATB\nhelps improve core efficiency through larger _\ud835\udc47\ud835\udc3e_ .\nFinally, Table 3 reports the performance of our Config 1 ATB\nkernel ( _\ud835\udf0c_ = 4, 128 \u00d7 64 \u00d7 128 L1 tile) across different problem dimensions. Performance scales smoothly with matrix size, achieving up\n\nCan Asymmetric Tile Buffering Be Beneficial? Conference\u201917, July 2017, Washington, DC, USA\n\nto 24.6 TFLOPS on large GEMMs and remaining above 19.2 TFLOPS\nfor smaller problems."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is Asymmetric Tile Buffering (ATB) applied to on-chip L1 memory for General Matrix Multiplication (GEMM) operations. Instead of symmetrically partitioning the L1 cache for input matrices (A, B) and output (C), ATB dynamically and unevenly allocates buffer space. This asymmetry allows the system to prioritize larger buffer allocations for data tiles that are either more frequently accessed or have specific dimensions that better utilize the limited L1 capacity for a given problem size and tiling strategy. By tailoring the L1 buffer sizes to the actual data access patterns and tile dimensions, ATB maximizes data locality and reduces expensive off-chip memory accesses.\n\n**Explanation:** Think of the L1 cache as a small, super-fast scratchpad for the NPU. For large matrix multiplications (GEMM), the full matrices won't fit, so they are broken into smaller 'tiles' that can. The challenge is efficiently moving and storing these tiles on the scratchpad. Traditionally, you might assign fixed, equally sized slots for input tiles (A, B) and output tiles (C). This paper proposes Asymmetric Tile Buffering (ATB), which is like having flexible slots. If the computation needs many A-tiles and fewer B-tiles at a certain stage (or vice-versa), ATB can expand A's slot and shrink B's slot. This allows more relevant data to reside on the fast L1 memory, reducing the number of times the NPU has to go to slower main memory. For 'memory-bound' operations (where fetching data is the bottleneck), ATB enables larger output tiles (TMC, TN) to fit, improving arithmetic intensity. For 'compute-bound' operations (where calculation speed is the bottleneck), ATB facilitates larger inner loop dimensions (TK), which amortizes overheads and improves core efficiency. The paper also explores different numerical precisions (BF16, BFP16) to see how using fewer bits affects both memory footprint and performance."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**19 end for**\n\n**20 return** _\ud835\udc60\ud835\udc53\ud835\udc4f\ud835\udc52\ud835\udc60\ud835\udc61_\n\nThe theoretical aspects of _LLHD_ packet scheduling algorithm are provided in 2.2.5.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 47\n\n**Algorithm 6:** ReMP TCP (redundant)\n\n**Input:** Set of subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R\n\n**Output:** _\ud835\udc60\ud835\udc53\ud835\udc56, \ud835\udc60\ud835\udc53\ud835\udc57_ \u2208S\n\n**1 for** _each segment to be transmitted_ **do**"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is parallelized redundant transmission. For each data segment that needs to be transmitted, the algorithm allows for sending identical copies over multiple independent subflows (network paths) simultaneously or near-simultaneously. This creates a race condition where the first successful delivery of a segment satisfies the requirement.\n\n**Explanation:** At a fundamental level, this algorithm addresses network unreliability and latency variability by not putting all its eggs in one basket. Instead of sending a data segment along a single chosen path and waiting for an acknowledgment, it can push the same segment across several available subflows. Think of it like a `for each segment` loop where, for a given segment, you initiate multiple parallel `send` operations, each targeting a different subflow. If subflow A is slow, subflow B might deliver the segment faster. The 'redundant' aspect means you're intentionally sending duplicates. The system then accepts the first arriving copy and discards subsequent duplicates, ensuring that the fastest available path dictates the effective latency for that segment while providing high resilience against individual path failures or significant packet loss on other paths. This behavior is akin to a distributed `try-until-success` mechanism, but with parallel attempts rather than sequential retries."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_message_ ( _`iteration`_ _`number`_ _,_ opp( _j_ ) _, r_ opp( _j_ ) _\u2192j_ ) _signed by_ opp( _j_ ) _is received from j_\n**then**\n\n**7** Node _i_ sets _Rj \u2190{r_ opp( _j_ ) _\u2192j \u2295_ _rj\u2192j}_ ;"}, {"role": "assistant", "content": "**Mechanism:** Authenticated message reception and state-combining update using a bitwise operation.\n\n**Explanation:** When node 'i' receives a message from node 'j', it first implicitly authenticates the sender (or the message's origin point 'opp(j)') via a signature. This is akin to checking a digital certificate's validity before processing an encrypted stream. The message contains specific data points, including 'r_opp(j)\u2192j'. Upon successful reception and implied authentication, node 'i' updates a local state variable, 'Rj', associated with node 'j'. This update is not a simple overwrite but a combination of the newly received 'r_opp(j)\u2192j' and 'i''s existing local state concerning 'j', denoted 'rj\u2192j', using a bitwise XOR-like operation (represented by '\u2295'). This combination ensures that 'Rj' continuously evolves to reflect information from both sides, crucial for maintaining shared secrets or commitments in a distributed system, much like updating a value in a hash map where the new value is derived from the old value and incoming data using a specific function."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each interval k \u2208_ [ _s_ ] _/W such that j \u2208Nqk and_ _I_ [\u02c6] _k_ = _I_ [\u02c6] _j_ + 1 **do**\n\n**8** set mapping _pk \u2190_ _j_ .\n\n**9** remove interval _j_ from remaining interval set _W_ i.e., update _W \u2190W/{j}_ .\n\n**10 return** _{I_ [\u02c6] 1 _,...,_ _I_ [\u02c6] _s}_\n\nWe now prove Lemma 2 by formally verifying the three properties using our constructed procedure.\n\n_Proof._ _Proof of Lemma 2_ . The constructed procedure (Algorithm 2) terminates after _s_ steps, producing\n\na complete assignment ( _I_ [\u02c6] 1 _,...,_ _I_ [\u02c6] _s_ ). We next verify that this assignment satisfies all three desired properties\n\nin the statement of the lemma.\n\n_(i)_ LOCAL-DOMINANCE _:_ For each interval _i \u2208_ [ _s_ ], consider _j_ 1 _,j_ 2 _,_ _\u00b7\u00b7\u00b7 \u2208Ni_ in the order in which they are\n\nremoved from the algorithm: for the _k_ -th removed interval _jk \u2208Ni_, at that time the cardinality _|Ni_ _[W][|]_ [ is]\n\n_|Ni| \u2212_ _k_ + 1, which guarantees that _I_ [\u02c6] _jk_ is at least _|Ni| \u2212_ _k_ + 1 by construction. Thus, LOCAL-DOMINANCE\n\nis satisfied.\n\n_(ii)_ GLOBAL-DOMINANCE _:_ We verify this property by the following induction argument. Consider the\n\nreverse order of intervals removed from the remaining interval set _W_ in the algorithm, i.e., we set _W_ = _\u2205_ as\n\nthe base case and then add intervals back to _W_ in the reverse order in which they have been removed in the\n\nalgorithm. Our induction hypothesis is that restricting to intervals in _W_, GLOBAL-DOMINANCE holds, i.e.,\n\nfor any decreasing and concave function \u03a8 [\u00af],\n\n\ufffd\n\n_i\u2208W_ \u00af\u03a8(\u02c6 _Ii_ ) _\u2265_ \ufffd\n\n\u00af\u03a8( _|Ni_ _[W][|]_ [)] _[.]_ (4)\n_i\u2208W_\n\n- _Base Case (W_ = _\u2205):_ In this case, the induction hypothesis holds trivially.\n\n- _Inductive Step:_ Suppose the induction hypothesis holds before we add interval _i_ with assignment _I_ [\u02c6] _i_ back\n\nto _W_ . Let _m_ \u225c _I_ [\u02c6] _i \u2212_ 1. To make it clear, let _W_ to be the remaining interval set before we add interval _i_,\n\nand _W_ _[\u2032]_ to be the remaining interval set after we add interval _i_, i.e., _W_ _[\u2032]_ = _W \u222a{i}_ . Next we analyze the\n\nincrement of both sides in inequality (4) after we add interval _i_ into _W_ . The left-hand side of inequality (4)\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n19\n\nincreases by \u03a8( [\u00af] _m_ + 1). For the right-hand side, since _I_ [\u02c6] _i_ = _m_ + 1, there exist _m_ intervals _j_ 1 _,j_ 2 _,...jm \u2208W_\n\nwhich cover position _aqi_, and _i < jk_ (otherwise, _jk_ should be removed earlier than _i_ in the algorithm) for all\n\n_k \u2208_ [ _m_ ]. This implies that interval _i_ covers position _ajk_ for all _k \u2208_ [ _m_ ]. Without loss of generality, we assume\n\n_j_ 1 _< j_ 2 _< \u00b7\u00b7\u00b7 < jm_ . We have _|Nj_ _[W]_ _k_ _[| \u2265]_ _[k]_ [ for all] _[ k][ \u2208]_ [[] _[m]_ []][. Hence, after adding interval] _[ i]_ [ into] _[ W]_ [, the right-hand]\n\nside of inequality (4) increases by\n\n_k\u2208_ [ _m_ ]\n\n\u00af\u03a8( _|Ni_ _[W][\u2032]_ _|_ ) + \ufffd\n\n( _b_ )\n= \u03a8( [\u00af] _|Ni_ _[W][\u2032]_ _|_ ) + \ufffd\n\n_k\u2208_ [ _m_ ] \ufffd\u00af\u03a8( _|Nj Wk_ _[|]_ [ + 1)] _[ \u2212]_ [\u00af\u03a8(] _[|N]_ _j_ _[ W]_ _k_ _[|]_ [)] \ufffd [(] _\u2264_ _[c]_ [)] \u03a8(1) + [\u00af] \ufffd\n\n_k\u2208_ [ _m_ ] [(\u00af\u03a8(] _[k]_ [ + 1)] _[ \u2212]_ [\u00af\u03a8(] _[k]_ [)) = \u00af\u03a8(] _[m]_ [ + 1)]\n\n\ufffd\u00af\u03a8( _|Nj_ _[W]_ _k_ _[\u2032][|]_ [)] _[ \u2212]_ [\u00af\u03a8(] _[|N]_ _j_ _[ W]_ _k_ _[|]_ [)] \ufffd\n\n_j\u2208W_\n\n( _a_ )\n\ufffd\u00af\u03a8( _|Nj_ _[W][\u2032]_ _|_ ) _\u2212_ \u03a8( [\u00af] _|Nj_ _[W][|]_ [)] \ufffd _\u2264_ \u03a8( [\u00af] _|Ni_ _[W][\u2032]_ _|_ ) + \ufffd\n\nwhere inequality (a) holds since _|Nj_ _[W]_ _k_ _[\u2032][| \u2265|N]_ _j_ _[ W]_ _k_ _[|]_ [ and][ \u00af\u03a8][ is decreasing; equality (b) holds since] _[ |N]_ _j_ _[ W]_ _k_ _[\u2032][|]_ [ =]\n\n_|Nj_ _[W]_ _k_ _[|]_ [ + 1][ by construction; and inequality (c) holds since][ \u00af\u03a8][ is decreasing, concave and] _[ |N]_ _j_ _[ W]_ _k_ _[| \u2265]_ _[k]_ [ for all]\n\n_k \u2208_ [ _m_ ]. Applying the induction hypothesis (before we add interval _i_ ), the inductive statement (after we add\n\ninterval _i_ ) holds, which finishes the induction as desired.\n\n_(iii)_ PARTITION-MONOTONICITY _:_ We first show that the predecessor mapping _{pi}i\u2208_ [ _s_ ] satisfies two key\n\nproperties: (a) each interval has at most one successor _j_ (i.e., _pj_ = _i_ ), and (b) every interval _i_ with _I_ [\u02c6] _i >_ 1\n\nhas a predecessor (i.e., _pi \u2208_ [ _s_ ]). Consequently, the _p_ -links decompose the set of intervals into disjoint chains\n\nalong which the assigned labels decrease by exactly one. This yields a valid partition _{A_ 1 _,...,A\u03ba}_ such\n\nthat _{I_ [\u02c6] _i_ : _i \u2208_ _A\u2113}_ = _{_ 1 _,_ 2 _,...,_ _|A\u2113|}_ for each _\u2113_, thereby guaranteeing PARTITION-MONOTONICITY. Next, we\n\nestablish claims (a) and (b) separately.\n\n**Proof of claim (a).** We show claim (a) by contradiction. Suppose there exist intervals _i_, _j_ 1 and _j_ 2 such that\n\n_pj_ 1 = _pj_ 2 = _i_ . By the construction of Algorithm 2, _I_ [\u02c6] _j_ 1 = _I_ [\u02c6] _j_ 2 = _I_ [\u02c6] _i_ + 1. Now, consider case by case.\n\n- _Case 1 (i < j_ 1 _or i < j_ 2 _):_ Without loss of generality, we assume _i < j_ 1, and the case _i < j_ 2 is symmetric.\n\nBy the construction of Algorithm 2, _pj_ 1 = _i_ implies _i \u2208Nqj_ 1 . This leads to a contradiction because if _i < j_ 1,\n\nthe interval _i_ should be removed earlier than the interval _j_ 1 in Algorithm 2 which implies _I_ [\u02c6] _i \u2265_ _I_ [\u02c6] _j_ 1.\n\n- _Case2 (j_ 1 _,j_ 2 _< i):_\n\n    - _Case 2a (qj_ 1 _< qj_ 2 _or qj_ 2 _< qj_ 1 _):_ Without loss of generality, we assume _qj_ 1 _< qj_ 2 ( _qj_ 2 _< qj_ 1 is similar):\n\n     - _Case 2a1 (interval j_ 1 _is removed before interval j_ 2 _):_ In this case, consider the moment when\n\nAlgorithm 2 removes _j_ 1 due to interval _qj_ 1. By the construction of Algorithm 2, since _j_ 1 is removed before\n\n_j_ 2, it implies _|Nq_ _[W]_ _j_ 1 _[|][ >][ |N]_ _q_ _[ W]_ _j_ 2 _[|]_ [. Thus,][ \u02c6] _[I][j]_ 1 [is strictly larger than][ \u02c6] _[I][j]_ 2 [, a contradiction.]\n\n     - _Case 2a2 (interval j_ 2 _is removed before interval j_ 1 _):_ In this case, consider the moment when\n\nAlgorithm 2 removes _j_ 2 due to interval _qj_ 2. Notice that interval _j_ 2 also covers position _aqj_ 1, i.e., _j_ 2 _\u2208Nqj_ 1 .\n\nBy the construction of Algorithm 2, since _j_ 2 is removed before _j_ 1, it implies _|Nq_ _[W]_ _j_ 1 _[| \u2264|N]_ _q_ _[ W]_ _j_ 2 _[|]_ [. Thus, once]\n\nAlgorithm 2 removes _j_ 2, _|Nq_ _[W]_ _j_ 1 _[/][{][j]_ [2] _[}]_ _|_ (which is an upper bound of _I_ [\u02c6] _j_ 1) becomes strictly smaller than _|Nq_ _[W]_ _j_ 2 _[|]_\n\n(which is equal to _I_ [\u02c6] _j_ 2), a contradiction.\n\n    - _Case 2b (qj_ 1 = _qj_ 2 _):_ Without loss of generality, we assume interval _j_ 1 is removed before interval\n\n_j_ 2, and the case where interval _j_ 2 is removed before interval _j_ 1 is symmetric. Let _q_ _[\u2217]_ = _qj_ 1 = _qj_ 2. Consider\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n20\n\nthe moment when Algorithm 2 removes _j_ 1 due to _q_ _[\u2217]_ . By the construction of Algorithm 2, _I_ [\u02c6] _j_ 1 = _|Nq_ _[W][\u2217]_ _[|]_ [ and]\n_I_ \u02c6 _j_ 2 _\u2264|Nq_ _[W][\u2217]_ _[/][{][j]_ [1] _[}]_ _|_ = _|Nq_ _[W][\u2217]_ _[| \u2212]_ [1][. Thus,][ \u02c6] _[I][j]_ 1 _[>]_ [ \u02c6] _[I][j]_ 2 [, which is a contradiction.]\n\n**Proof of claim (b).** For any interval _i_ with _I_ [\u02c6] _i >_ 1, consider the next removed interval _j_ among _Nqi_ after\n\nAlgorithm 2 removes interval _i_ . It is sufficient to show _I_ [\u02c6] _j_ = _I_ [\u02c6] _i \u2212_ 1, which implies that Algorithm 2 sets\n\n_pi_ = _j_ when it removes interval _j_ . Since _j_ is the next interval removed among _Nqi_ after interval _i_, we have\n_I_ \u02c6 _i \u2212_ 1 _\u2264_ _I_ \u02c6 _j \u2264_ _I_ \u02c6 _i_ . To show \u02c6 _Ij <_ \u02c6 _Ii_, we use the proof by contradiction. Suppose \u02c6 _Ij_ = \u02c6 _Ii_ . If _i \u2208Nqj_, then\n\nat the moment when Algorithm 2 removes _i_, we have _I_ [\u02c6] _i_ = _|Nq_ _[W]_ _i_ _[| \u2265|N]_ _q_ _[ W]_ _j_ _[| \u2265]_ _[I]_ [\u02c6] _[j]_ [+ 1 = \u02c6] _[I][i]_ [+ 1][, which is a]\n\ncontradiction. If _i \u0338\u2208Nqj_, since _i < j_, we have mapping _qi < qj_ and at the moment when Algorithm 2 removes\n\n_i_, _|Nq_ _[W]_ _i_ _[|]_ [ = \u02c6] _[I][i]_ [= \u02c6] _[I][j]_ _[\u2264N]_ _q_ _[ W]_ _j_ _[|]_ [, a contradiction.] \n### **5. Conclusion**\n\n**Summary & takeaways.** We studied real-time assortment planning under both endogenous and exogenous\n\ninventory shocks. We introduced an extension of the inventory balancing algorithm for this problem, called\n\nBatched Inventory Balancing (BIB). This new algorithm keeps track of the exogenous inventory shock of\n\neach product separately by smartly batching units of this product into buckets in an adaptive fashion. It then\n\npenalizes the price of different units of the product using a concave penalty function with the (normalized)\n\ninventory of the bucket of the unit as input. We analyzed the BIB algorithm with general concave penalty\n\nfunctions. The analysis in the prior work for online assortment (without inventory shocks) breaks as inventory\n\nlevels are not monotone and the function does not satisfy a certain differential equation. To handle this\n\nchallenge, we considered an LP benchmark that depends on the execution of the BIB algorithm, designed a\n\nbatch-based randomized dual-fitting primal-dual analysis, and most interestingly proposed a reduction from\n\nthe correct randomized dual construction in our problem to another algorithmic yet combinatorial problem.\n\nThis combinatorial problem, called Interval Assignment Problem (IAP), searches for a certain re-assignment\n\nof the bucket inventory levels, so that the new inventory levels are always monotone and can be used in a\n\nprimal-dual analysis as before. We concluded by showing how to solve the IAP in polynomial time. We then\n\nshow how to put all the pieces together and obtain a universal bound comparable to Golrezaei et al. (2014),\n\nbut with both endogenous and exogenous inventory shock.\n\n**Open problems & directions.** There are several promising technical directions for future research stem\n\nming from our work, including: extending the model to stochastic or heterogeneous return durations; incor\n\nporating inventory holding or restocking costs; handling negative inventory shocks; studying joint inven\n\ntory\u2013assortment control; and exploring application-specific operational replenishment policies. A more\n\ndetailed discussion of these open problems is provided in Section EC.5.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n21\n\n### **References**\n\nGagan Aggarwal, Gagan Goel, Chinmay Karande, and Aranyak Mehta. Online vertex-weighted bipartite matching and single-bid\n\nbudgeted allocations. In _Proceedings of the twenty-second annual ACM-SIAM symposium on Discrete Algorithms_, pages 1253\u2013\n\n1264. SIAM, 2011.\n\nJackie Baek and Will Ma. Bifurcating constraints to improve approximation ratios for network revenue management with reusable\n\nresources. _Operations Research_, 70(4):2226\u20132236, 2022.\n\nFernando Bernstein, A G\u00a8urhan K\u00a8ok, and Lei Xie. Dynamic assortment customization with limited inventories. _Manufacturing &_\n\n_Service Operations Management_, 17(4):538\u2013553, 2015.\n\nBenjamin E Birnbaum and Claire Mathieu. On-line bipartite matching made simple. _Sigact News_, 39(1):80\u201387, 2008.\n\nAgostino Bruzzone, Antonio Cimino, Rafael Diaz, and Francesco Longo. Inventory control with products returns: a state of the art\n\noverview. In _Proceedings of the 2010 Spring Simulation Multiconference_, pages 1\u20137, 2010.\n\nJinzhi Bu, Huanan Zhang, and Stefanus Jasin. Asymptotic optimality of simple replenishment policies for a lost-sales inventory\n\nsystem with delivery lead time and purchase returns. _Available at SSRN_, 2023.\n\nCarri W Chan and Vivek F Farias. Stochastic depletion problems: Effective myopic policies for a class of dynamic optimization\n\nproblems. _Mathematics of Operations Research_, 34(2):333\u2013350, 2009.\n\nMarisa P de Brito and Rommert Dekker. Modelling product returns in inventory control\u2014exploring the validity of general assump\n\ntions. _International Journal of Production Economics_, 81:225\u2013241, 2003.\n\nSteven Delong, Alireza Farhadi, Rad Niazadeh, Balasubramanian Sivan, and Rajan Udwani. Online bipartite matching with reusable\n\nresources. _Mathematics of Operations Research_, 49(3):1825\u20131854, 2024.\n\nNikhil R Devanur, Kamal Jain, and Robert D Kleinberg. Randomized primal-dual analysis of ranking for online bipartite matching.\n\nIn _Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms_, pages 101\u2013107. Society for Industrial\n\nand Applied Mathematics, 2013.\n\nFarbod Ekbatani, Yiding Feng, and Rad Niazadeh. Online resource allocation with buyback: Optimal algorithms via primal-dual. In\n\n_Proceedings of the 24th ACM Conference on Economics and Computation_, pages 583\u2013583, 2023.\n\nYiding Feng and Rad Niazadeh. Batching and optimal multistage bipartite allocations. _Management Science_, 71(5):4108\u20134130,\n\n2025.\n\nYiding Feng, Rad Niazadeh, and Amin Saberi. Near-optimal bayesian online assortment of reusable resources. _Operations Research_,\n\n72(5):1861\u20131873, 2024.\n\nNegin Golrezaei, Hamid Nazerzadeh, and Paat Rusmevichientong. Real-time optimization of personalized assortments. _Management_\n\n_Science_, 60(6):1532\u20131551, 2014.\n\nXiao-Yue Gong, Vineet Goyal, Garud N Iyengar, David Simchi-Levi, Rajan Udwani, and Shuangyu Wang. Online assortment\n\noptimization with reusable resources. _Management Science_, 2021.\n\nVineet Goyal, Garud Iyengar, and Rajan Udwani. Asymptotically optimal competitive ratio for online allocation of reusable\n\nresources. _Operations Research_, 2025.\n\nZhiyi Huang, Zhihao Gavin Tang, Xiaowei Wu, and Yuhao Zhang. Online vertex-weighted bipartite matching: Beating 1-1/e with\n\nrandom arrivals. _ACM Transactions on Algorithms (TALG)_, 15(3):1\u201315, 2019.\n\nGanesh Janakiraman and Robin O Roundy. Lost-sales problems with stochastic lead times: Convexity results for base-stock policies.\n\n_Operations Research_, 52(5):795\u2013803, 2004.\n\nBilly Jin and Will Ma. Online bipartite matching with advice: Tight robustness-consistency tradeoffs for the two-stage model.\n\n_Advances in Neural Information Processing Systems_, 35:14555\u201314567, 2022.\n\nBilly Jin and David P Williamson. Improved analysis of ranking for online vertex-weighted bipartite matching in the random order\n\nmodel. In _International Conference on Web and Internet Economics_, pages 207\u2013225. Springer, 2021.\n\n**Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n22\n\nBala Kalyanasundaram and Kirk R Pruhs. An optimal deterministic algorithm for online b-matching. _Theoretical Computer Science_,\n\n233(1-2):319\u2013325, 2000.\n\nSuho Kang, Ziyang Liu, and Rajan Udwani. A black-box approach for exogenous replenishment in online resource allocation. In\n\n_International Conference on Integer Programming and Combinatorial Optimization_, pages 326\u2013340. Springer, 2025.\n\nRichard M Karp, Umesh V Vazirani, and Vijay V Vazirani. An optimal algorithm for on-line bipartite matching. In _Proceedings of_\n\n_the twenty-second annual ACM symposium on Theory of computing_, pages 352\u2013358. ACM, 1990.\n\nAlys Jiaxin Liang, Stefanus Jasin, and Joline Uichanco. Combining a smart pricing policy with a simple replenishment policy:\n\nManaging uncertainties in the presence of stochastic purchase returns. _Available at SSRN 3563847_, 2020.\n\nAlys Jiaxin Liang, Stefanus Jasin, and Xiuli Chao. Assortment and inventory planning under dynamic (stockout-based) substitution\n\nin the presence of customer returns: A fluid analysis. _Available at SSRN 4468430_, 2023.\n\nIrene Lo, Vahideh Manshadi, Scott Rodilitz, and Ali Shameli. Commitment on volunteer crowdsourcing platforms: Implications for\n\ngrowth and engagement. _Manufacturing & Service Operations Management_, 26(5):1787\u20131805, 2024.\n\nWill Ma and David Simchi-Levi. Algorithms for online matching, assortment, and pricing with tight weight-dependent competitive\n\nratios. _Operations Research_, 68(6):1787\u20131803, 2020.\n\nVahideh Manshadi and Scott Rodilitz. Online policies for efficient volunteer crowdsourcing. _Management Science_, 68(9):6572\u2013\n\n6590, 2022.\n\nVahideh Manshadi, Scott Rodilitz, Daniela Saban, and Akshaya Suresh. Online algorithms for matching platforms with multichannel\n\ntraffic. _Management Science_, 2024.\n\nAranyak Mehta. Online matching and ad allocation. _Foundations and Trends\u00ae in Theoretical Computer Science_, 8(4):265\u2013368,\n\n2013.\n\nAranyak Mehta and Debmalya Panigrahi. Online matching with stochastic rewards. In _2012 IEEE 53rd Annual Symposium on_\n\n_Foundations of Computer Science_, pages 728\u2013737. IEEE, 2012.\n\nAranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani. Adwords and generalized online matching. _Journal of the ACM_\n\n_(JACM)_, 54(5):22\u2013es, 2007.\n\nSentao Miao. Managing the inventory with product return: An approximation algorithm. _Available at SSRN_, 2023.\n\nKumar Muthuraman, Sridhar Seshadri, and Qi Wu. Inventory management with stochastic lead times. _Mathematics of Operations_\n\n_Research_, 40(2):302\u2013327, 2015.\n\nAlvin E Roth. _Online and matching-based market design_ . Cambridge University Press, 2023.\n\nPaat Rusmevichientong, Mika Sumida, and Huseyin Topaloglu. Dynamic assortment optimization for reusable products with random\n\nusage durations. _Management Science_, 66(7):2820\u20132844, 2020.\n\nDavid Simchi-Levi, Zeyu Zheng, and Feng Zhu. On greedy-like policies in online matching with reusable network resources and\n\ndecaying rewards. _Management Science_, 2025.\n\nVincent P Simpson. Optimum solution structure for a repairable inventory problem. _Operations research_, 26(2):270\u2013281, 1978.\n\nJing-Sheng Song, Geert-Jan Van Houtum, and Jan A Van Mieghem. Capacity and inventory management: Review, trends, and\n\nprojections. _Manufacturing & Service Operations Management_, 22(1):36\u201346, 2020.\n\nRajan Udwani. Adwords with unknown budgets and beyond. _Management Science_, 71(2):1009\u20131026, 2025.\n\nVijay V Vazirani. Towards a practical, budget-oblivious algorithm for the adwords problem under small bids. In _43rd IARCS Annual_\n\n_Conference on Foundations of Software Technology and Theoretical Computer Science_, page 21, 2023.\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec1\n\n## **This page is intentionally blank. The e-companion (EC) starts next page.**\n\nec2 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n### **EC.1. Further Related Work**\n\nOnline assortment has an extensively growing literature recently, both under the prior-free/adversarial and\n\nthe Bayesian settings. For non-reusable products, Bernstein et al. (2015) study a model with two products,\n\ni.i.d. consumer types and Poisson arrivals. Chan and Farias (2009) study a model with non-stationary con\n\nsumer types. Golrezaei et al. (2014) propose inventory balancing algorithms for assortment\u2014inspired by\n\nthe seminal work of Mehta et al. (2007) for online ad allocation\u2014and analyze their performance guarantee\n\nin the adversarial setting using a primal-dual approach. This analysis is later improved and generalized to\n\nthe case where there are finite steps in the penalty function Ma and Simchi-Levi (2020). For online assort\n\nment of reusable products, Rusmevichientong et al. (2020); Baek and Ma (2022); Feng et al. (2024) study\n\nthe Bayesian setting under various modeling assumptions. Gong et al. (2021); Goyal et al. (2025) study\n\nthe adversarial setting with stationary rental fees and rental duration distributions. Simchi-Levi et al. (2025)\n\nintroduce a more general framework in the adversarial setting with decaying rental fees and rental duration\n\ndistributions.\n\nVazirani (2023); Udwani (2025) study a variant of AdWords problem (cf. Mehta et al., 2007; Mehta, 2013),\n\nwhere the budget (aka., capacity) of each offline node is initially unknown to the online algorithms, and is\n\nonly revealed to the algorithms immediately after it is exhausted. They present the competitive ratio analysis\n\nfor Perturbed Greedy algorithm and Generalized Perturbed Greedy algorithm. Manshadi et al. (2024) intro\n\nduce a new variant of the online matching with stochastic reward (cf. Mehta and Panigrahi, 2012). In their\n\nmodel, a fixed fraction of online nodes are single-minded (i.e., each of them has a single incident edge). They\n\nshow the non-optimality of the Inventory Balancing (IB) in this model, and propose a new modification \u2013\n\nAdaptive Capacity (AC) \u2013 with improved competitive ratio. In all Vazirani (2023); Manshadi et al. (2024);\n\nUdwani (2025), the online algorithms suffer some specific forms of uncertainty about the capacities of offline\n\nnodes. However, our model is fundamentally different from them and thus not directly comparable.\n\nOur results are also comparable to the literature on online bipartite matching (with vertex arrival) and\n\nits extensions. Delong et al. (2024) is the most related, where the authors consider the adversarial arrival\n\nsetting without replenishment under small capacity (in particular, the capacity equals one) and restricts to\n\nproblem instances with identical duration across offline nodes (aka products) and time. The paper proposes\n\nintegral matching algorithms that achieve competitive ratios slightly better than 1/2, but still not optimal.\n\nIn contrast, our paper allows for heterogeneous duration across offline nodes (aka products) and achieves\n\nan asymptotically optimal competitive ratio (rather than looking at the small capacity regime). We refer the\n\nreader to related surveys and books (cf. Mehta, 2013; Roth, 2023) for a comprehensive study of the online\n\nbipartite matching literature.\n\nAs mentioned earlier, a major source of exogenous shocks to inventory is customer returns, either from\n\nthe original channel or from other channels. The impact of customer returns on inventories and assortments\n\nhas been studied in the literature, e.g. recent work of Liang et al. (2023, 2020); Miao (2023). See Bruz\n\nzone et al. (2010) for an overview of the older literature on inventory control with returns. In addition, we\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec3\n\ninterpret endogenous shocks as replenishment of sold units of the product when the retailer employs a sim\n\nple discrete-period restocking policy with a fixed lead time. This is in fact a simplification and there is a\n\nlong literature in supply chain and inventory theory on various forms of replenishment policies; for exam\n\nple, see Bruzzone et al. (2010); Bu et al. (2023) for a literature review. Simple restocking with fixed lead\n\ntime is a special case of stochastic lead time, which has been studied in the literature, e.g. Janakiraman and\n\nRoundy (2004); Muthuraman et al. (2015). Also, a more practical restocking policy is base-stock with a\n\nlower-threshold (Simpson, 1978; Song et al., 2020), e.g., restocking only when _\u03b1_ fraction or _k_ number of\n\nunits is sold (instead of each time a unit is sold). We leave further investigations on these models for future\n\nresearch. Recently, Kang et al. (2025) extended the framework developed in this paper to more general set\n\ntings (e.g., endogenous inventory shocks with i.i.d. stochastic durations). Their work builds directly on our\n\ncore ideas and demonstrates a general reduction framework that lifts a broad class of algorithms\u2014and their\n\naccompanying theoretical guarantees\u2014from the setting without exogenous shocks to one that accommodates\n\narbitrary exogenous inventory shocks.\n\n### **EC.2. Discussion on Practical Relevance**\n\nThe online assortment planning model with endogenous and exogenous shocks studied in this paper is rather\n\ngeneral and rooted in various applications. In this section, we discuss several such applications in detail and\n\nexplain the micro-foundations behind both endogenous and exogenous shocks in each context.\n\n**Online platforms with rental or reusable products (e.g., cloud computing, car sharing, and hospitality**\n\n**services).** Rental-based platforms such as AWS (cloud computing), Zipcar (car sharing), and Airbnb (short\n\nterm rentals) are natural instances of online assortment with inventory shocks. When a user selects a server\n\ninstance, vehicle, or home listing, that unit immediately becomes unavailable for a period equal to the rental\n\nduration. This leads to an _endogenous shock_, as the temporary depletion of inventory is triggered directly by\n\nthe platform\u2019s own allocation decision. Once the usage period ends, the same unit returns to the available\n\ninventory, replenishing supply. Meanwhile, _exogenous shocks_ occur when new resources unexpectedly enter\n\nthe system\u2014for example, when a new host lists a property on Airbnb, when additional vehicles are relocated\n\nto a specific city, or when unused cloud servers are released from internal operations and become available\n\nto external customers. The assortment planner must dynamically adjust which items to display to incoming\n\nusers, accounting for both the predictable restocking of rented items and the uncertain inflow of new supply.\n\n**Dynamic resource allocation in public-service and humanitarian operations.** In social-impact and\n\npublic-sector contexts\u2014such as refugee resettlement, housing allocation, or hospital bed management\u2014\n\nresources are inherently reusable. A resource (e.g., a case manager, a housing unit, or a hospital bed) becomes\n\navailable again once a prior case or patient exits, which creates an _endogenous shock_ . At the same time,\n\n_exogenous shocks_ occur when additional capacity arrives due to new government funding, emergency shel\n\nters, or partner institutions joining the network. The central planner\u2019s task is to decide, in real time, which\n\nec4 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\nclients or cases to match with available resources given uncertain future arrivals of both clients and capacity.\n\nThis is effectively an assortment problem over a dynamically fluctuating inventory, directly mapping to our\n\nframework with both endogenous and exogenous shocks.\n\n**Volunteer nudging and matching platforms.** Many volunteer coordination platforms (e.g., Catchafire or\n\nFood Rescue U.S.) face an online assignment problem where _volunteers_ serve as reusable resources and\n\n_jobs or requests_ arrive sequentially over time. When the platform nudges a volunteer to accept a task, that\n\nvolunteer becomes temporarily unavailable for the task duration, producing an _endogenous shock_ . After\n\ncompleting the task, she becomes available again to accept new opportunities. At the same time, _exoge-_\n\n_nous shocks_ occur as new volunteers join, existing volunteers extend their commitment hours, or additional\n\npartner organizations contribute workforce capacity. The platform\u2019s decision at each arrival corresponds to\n\nan online \u201cassortment\u201d of volunteers or tasks\u2014deciding which subset of volunteers to nudge for each new\n\njob while ensuring balanced utilization and avoiding fatigue. Here, endogenous shocks capture temporary\n\nunavailability caused by engagement decisions, whereas exogenous shocks capture new volunteer inflows\n\ndriven by external outreach or seasonal events. The platform\u2019s goal of maximizing completed jobs subject to\n\ndynamic volunteer availability aligns precisely with our model\u2019s structure.\n\n**Inventory-sharing and circular-economy systems.** In sharing-economy or circular supply systems,\n\nresources such as tools, clothing, or electronics are repeatedly lent out, repaired, or refurbished, creating\n\n_endogenous shocks_ that replenish inventory. Each time a borrowed or refurbished unit completes its cycle, it\n\nre-enters the pool of available items. In addition, _exogenous shocks_ occur through donation campaigns, buy\n\nback programs, or asset transfers from partner organizations. For instance, in a shared-equipment platform\n\nlike Fat Llama [15], a camera lent to a user for three days returns afterward (endogenous), while new listings\n\nor donated items are added unpredictably (exogenous). The platform must dynamically decide which items\n\nto display to maximize engagement while balancing short-term utilization against uncertain restocking and\n\ninflow rates.\n\n**Freelance and gig-economy marketplaces.** In marketplaces such as Upwork, Uber, or DoorDash, workers\n\nor service providers act as reusable capacity. When a driver accepts a trip or a freelancer takes on a project,\n\nshe becomes unavailable for a stochastic service duration\u2014an _endogenous shock_ arising directly from the\n\nplatform\u2019s allocation. After completion, the provider re-enters the pool, replenishing supply. Simultaneously,\n\nthe platform experiences _exogenous shocks_ as new drivers sign on, existing workers log back in after a break,\n\nor temporary policy changes (e.g., surge incentives, weather effects) alter availability. The platform\u2019s control\n\nresembles an assortment decision: which jobs to display or assign to which subset of available providers\n\nto optimize earnings and reliability. The interplay between reusable labor capacity (endogenous restocking)\n\nand unpredictable supply inflows (exogenous additions) is naturally captured by our model.\n\n[15 https://fatllama.com/us](https://fatllama.com/us)\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec5\n\n**Omni-channel and online retail with returns and restocking.** In omni-channel retailing, inventories \u201ccome\n\nand go\u201d through multiple operational processes. When an online sale is made, the retailer may automati\n\ncally place a replenishment order with a supplier, which arrives after a lead time\u2014an _endogenous shock_ that\n\nreplenishes the same product based on the previous allocation. Meanwhile, _exogenous shocks_ arise when\n\nadditional units are returned from other sales channels (e.g., physical stores or marketplaces), or when inven\n\ntory records are corrected due to system discrepancies or shipping cancellations. For example, a pair of shoes\n\nsold online might be restocked from the distribution center after three days (endogenous), while at the same\n\ntime another pair may be returned to the warehouse due to a customer refund (exogenous). The retailer\u2019s\n\nonline assortment (which items to feature or promote) must thus remain robust to both predictable restock\n\ning cycles and unpredictable inflows, motivating assortment algorithms that adapt to both types of inventory\n\nshocks. [16]\n\n### **EC.3. Numerical Experiments**\n\nIn this section, we provide numerical justifications for the performance of our BIB algorithm on synthetic\n\ninstances.\n\n**Policies.** In our numerical experiments, we compare the revenue of five different policies:\n\n1. _Batched Inventory Balancing_ (BIB): this is the family of policies (Algorithm 1) parameterized by\n\npenalty function \u03a8 and batch-size threshold _\u03b3_ proposed in Section 3. It generalizes the classic Inventory\n\nBalancing (IB) when there are inventory shocks. It achieves the asymptotic optimal competitive ratio\n\n[1] _e_ _[\u2248]_ [0] _[.]_ [632][ under exponential penalty function][ \u03a8(] _[x]_ [) =] _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_\n\nof 1 _\u2212_ [1]\n\n_[\u2212][e]_\n\n1 _\u2212e_ and batch-size threshold _\u03b3_ = _[\u221a]_ ~~_c_~~ 0\n\n(Section 3.3).\n\n2. _Static-Capacity Inventory Balancing_ (SCIB): this is the family of policies parameterized by penalty\n\nfunction \u03a8. It generalizes the classic IB when there are inventory shocks. Specifically, for each time\n\nperiod _t_ and product _i_, the marginal revenue of all its units is discounted by the same factor of\n\n\u03a8(min _{_ _[I][i,t]_ _/ci,_ 1 _}_ ). Here _Ii,t_ is the inventory level of product _i_ at time period _t_ . See Algorithm 3 for its\n\nformal description.\n\n3. _Dynamic-Capacity Inventory Balancing_ (DCIB): this is the family of policies parameterized by\n\npenalty function \u03a8. It generalizes the classic IB when there are inventory shocks. Specifically, for each\n\ntime period _t_ and product _i_, the marginal revenue of all its units is discounted by the same factor of\n\n\u03a8 \ufffd _Ii,t/_ ( _ci_ + [\ufffd] _t_ _[\u2032]_ _\u2208_ [ _t_ ] _[\u03be][i,t][\u2032]_ [)] \ufffd. Here _Ii,t_ is the inventory level of product _i_ at time period _t_, and _\u03bei,t_ is the new\n\nunits of product _i_ added due to exogenous shocks. See Algorithm 4 for its formal description.\n\n16 Notably, lead times are not fixed in practical applications, but for the purpose of theoretical tractability we consider a simplified model with fixed lead times (i.e., fixed duration). We explore the change in durations in our numerical simulations. See Section EC.3.2. As it turns out, our algorithm is robust to moderate fluctuations in the duration.\n\nec6 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n4. _Unit-Specific Inventory Balancing_ (USIB): this is the family of policies parameterized by penalty\n\nfunction \u03a8. Each new unit of each product added due to exogenous shocks are treated as a new type of\n\nproducts. This is equivalent to the IBB algorithm (Algorithm 1) with batch size threshold _\u03b3_ = 1 (which\n\nautomatically does not distinguish between \u201ccharging\u201d and \u201cready\u201d batches as well). It generalizes the\n\nclassic IB when there are inventory shocks.\n\n5. _Myopic Greedy_ (GREED): this is the policy that offers the (myopic) optimal assortment given the\n\navailable products at each time. This policy is a special case of IB when \u03a8( _x_ ) = 1 _{x >_ 0 _}_ . Its compet\n\nitive ratio is at most 0.5.\n\n**Algorithm 3:** STATIC-CAPACITY INVENTORY BALANCING\n\n**Input:** penalty function \u03a8\n\n**1 for** _each time period t \u2208_ [ _T_ ] **do**\n\n/* consumer _t_ with choice model _\u03d5t_ arrives. */\n\n/* _\u03bei,t_ new units of product _i_ are added due to exogenous shock. */\n\n**2** update inventory level _{Ii,t}i\u2208_ [ _n_ ] of all products at time period _t_ .\n\n**3** solve _St \u2190_ arg max _S\u2208S_ \ufffd _i\u2208S_ _[r][i]_ [\u03a8(min] _[{][I][i,t][/][c][i][,]_ [1] _[}]_ [)] _[ \u00b7][ \u03d5][t]_ [(] _[S,i]_ [)][.]\n\n**4** allocate assortment _St_ to consumer _t_ .\n\n**Algorithm 4:** DYNAMIC-CAPACITY INVENTORY BALANCING\n\n**Input:** penalty function \u03a8\n\n**1 for** _each time period t \u2208_ [ _T_ ] **do**\n\n/* consumer _t_ with choice model _\u03d5t_ arrives. */\n\n/* _\u03bei,t_ new units of product _i_ are added due to exogenous shock. */\n\n**2** update inventory level _{Ii,t}i\u2208_ [ _n_ ] of all products at time period _t_ .\n\n_i\u2208S_ _[r][i]_ [\u03a8] \ufffd _Ii,t/_ ( _ci_ + [\ufffd]\n\n**3** solve _St \u2190_ arg max _S\u2208S_ \ufffd\n\n_t_ _[\u2032]_ _\u2208_ [ _t_ ] _[\u03be][i,t][\u2032]_ [)] \ufffd _\u00b7 \u03d5t_ ( _S,i_ ).\n\n**4** allocate assortment _St_ to consumer _t_ .\n\n**EC.3.1. Numerical Performance under Stylized Instances**\n\nIn this section, we first numerically illustrate that three natural modifications of IB \u2014 Static-Capacity Inven\n\ntory Balancing (SCIB), Dynamic-Capacity Inventory Balancing (DCIB) and Unit-Specific Inventory Bal\n\nancing (USIB) \u2014 cannot achieve the optimal asymptotic competitive ratio (1 _\u2212_ [1] _/e_ ) even if we consider\n\nonline bipartite matching instances (i.e., the special case of online assortment where choice model _\u03d5_ ( _S,i_ ) _\u2208_\n\n_{_ 0 _,_ 1 _}_ and _\u03d5_ ( _S,i_ ) = 1 only if _S_ = _{i}_ ) with large initial inventories and no endogenous inventory shock\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec7\n\n(i.e., _di_ = _\u221e_ for every product _i_ ). Then we examine the numerical performance of different policies on these\n\nconstructed instances.\n\n**EC.3.1.1. Competitive ratio upper bound of 0.552 for SCIB.** Our constructed instance _G_ ( _N,r,s_ ) is\n\nparameterized by _N \u2208_ N and _r,s \u2208_ [0 _,_ 1]. In this instance, there are _N_ + 1 product subgroups _{U\u2113}\u2113\u2208_ [0: _N_ ],\n\nindexed by [0 : _N_ ]. Each product subgroup _U\u2113_ with _\u2113_ _\u2208_ [0 : _N_ ] contains _n\u2113_ products, and each product _i_ in\n\nsubgroup _U\u2113_ has identical per unit price _ri_ \u225c _r_ _[\u2113]_ and identical initial inventory _ci_ \u225c _c_ . Here _c_ is a large enough\n\nconstant. On the other side, there are 2 _N_ + 1 consumer subgroups _{Vk}k\u2208_ [0:2 _N_ ] indexed by [0 : 2 _N_ ]. Each\n\nconsumer subgroup _Vk_ with _k \u2208_ [0 : 2 _N_ ] contains _mk_ consumers, who arrive sequentially.\n\nConsumer subgroup _V_ 0 has size _m_ 0 \u225c _c_ _\u00b7_ _n_ 0. For each _i \u2208_ [ _n_ 0] and each time period _t \u2208_ [( _i_ _\u2212_ 1) _c_ +1 : _ic_ ], a\n\nnew consumer from subgroup _V_ 0 who accepts every product from [ _n_ 0 _\u2212_ _i_ + 1] _\u2286_ _U_ 0 (i.e., the first _n_ 0 _\u2212_ _i_ + 1\n\nproducts of _U_ 0) arrives.\n\nAll remaining consumer subgroups _{Vk}k\u2208_ [2 _N_ ] and products subgroups _{Uk}\u2113\u2208_ [ _N_ ] are constructed recur\n\nsively based on the execution of Dynamic-Capacity Inventory Balancing. [17] Specifically, for each _\u2113_ _\u2208_ [ _N_ ],\n\n  - Consider time period _t\u2113_ \u225c [\ufffd] _k\u2208_ [0:2( _\u2113\u2212_ 1)] _[m][k]_ [, i.e., the time period when the first consumer from consumer]\n\nsubgroup _V_ 2 _\u2113\u2212_ 1 arrives. Let _xi,t\u2113_ be the number of available units of product _i \u2208_ _U\u2113\u2212_ 1 at the beginning\n\nof time period _t\u2113_ in the algorithm. For each product _i \u2208_ _U\u2113\u2212_ 1, there are _\u03bei,t\u2113_ \u225c max _{s \u00b7 c \u2212_ _xi,t\u2113,_ 0 _}_\n\nnew units added due to the exogenous inventory shocks. As a sanity check, for each product _i \u2208_ _U\u2113\u2212_ 1\n\nwith _\u03bei,t\u2113_ _>_ 0, its inventory level becomes _sc_ and has a discount factor of \u03a8( _s_ ) in the algorithm. With\n\n\u225c [\ufffd]\nslight abuse of notation, let _\u03be\u2113_ _i\u2208U\u2113\u2212_ 1 _[\u03be][i,t]_ _\u2113_ [be the total number of new units added for products from]\n\nproduct subgroup _U\u2113\u2212_ 1.\n\n  - Product subgroup _U\u2113_ has size _n\u2113_ \u225c _c\u00b7_ ~~\ufffd~~ 1 _\u2212_ \u03a8 _[\u2212]_ _\u03be_ [1] _\u2113_ ~~\ufffd~~ \u03a8( ~~_r_~~ _s_ ) ~~\ufffd\ufffd~~, where \u03a8 _[\u2212]_ [1] is the inverse function of penalty\n\nfunction \u03a8. [18]\n\n  - Consumer subgroup _V_ 2 _\u2113\u2212_ 1 have size _m_ 2 _\u2113\u2212_ 1 \u225c _\u03be\u2113_ . For each new unit added for products from product\n\nsubgroup _U\u2113\u2212_ 1 at time period _t\u2113_ due to exogenous shocks, there is a consumer in consumer subgroup\n\n_V_ 2 _\u2113\u2212_ 1 who accepts product _i \u2208_ _U\u2113\u2212_ 1 of this unit and one product _i_ _[\u2032]_ _\u2208_ _U\u2113_ . Here product _i_ _[\u2032]_ is constructed\n\nsuch that for each product _i_ _[\u2032]_ _\u2208_ _U\u2113_, there are exactly _n\u03be\u2113\u2113_ [consumers from] _[ V]_ [2] _[\u2113][\u2212]_ [1][ accepts this product.]\n\nUnder this construction, for each consumer in _V_ 2 _\u2113\u2212_ 1, suppose she accepts product _i \u2208_ _U\u2113\u2212_ 1 and product\n\n_i_ _[\u2032]_ _\u2208_ _U\u2113_, the algorithm allocates product _i_ _[\u2032]_ _\u2208_ _U\u2113_ to her and collects price _r_ _[\u2113]_, since the discounted price\n\nof product _i_ _[\u2032]_ _\u2208_ _U\u2113_ is larger than the discounted price of product _i \u2208_ _U\u2113\u2212_ 1 due to the construction of\n\n17 Since the algorithm is deterministic, it suffices for us to construct instance _G_ ( _N,r,s_ ) adaptively, based on the execution of the\nalgorithm.\n\n18 In the construction of instance _G_ ( _N,r,s_ ), we impose the requirement that \u03a8( _rs_ ) _\u2208_ [0 _,_ 1] for parameters _r,s \u2208_ [0 _,_ 1]. Note that\n\nunder this requirement, together with the assumption that penalty function \u03a8 is exponential function, the inverse function \u03a8 _[\u2212]_ [1] and\n_n\u2113_ are well-defined.\n\nec8 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n_n\u2113_ . More specifically, note that the inventory level of product _i_ _[\u2032]_ when serving this consumer is at least\n\n_c \u2212_ _[\u03be][\u2113]_\n\n_n\u2113_ [. Thus, the discounted price of product] _[ i][\u2032]_ [ is at least]\n\n_\u03be\u2113_\n_ri\u2032_ \u03a8 1 _\u2212_\n\ufffd _c \u00b7 n\u2113_\n\n_\u03be\u2113_\n= _r_ _[\u2113]_ \u03a8 1 _\u2212_\n\ufffd \ufffd _c \u00b7 n\u2113_\n\n= _r_ _[\u2113]_ [\u03a8][(] _[s]_ [)] = _r_ _[\u2113][\u2212]_ [1] \u03a8( _s_ ) = _ri_ \u03a8( _s_ )\n\ufffd _r_\n\nwhere the first and last equalities hold due to the construction of _ri,ri\u2032_ from subgroups _U\u2113\u2212_ 1 _,U\u2113_ ; and\n\nthe second equality holds due to the construction of _n\u2113_ . Because of this allocation in the algorithm,\n\nafter serving all consumers from consumer subgroup _V_ 2 _\u2113\u2212_ 1, the inventory level of each product from\n\nproduct subgroup _U\u2113_ is the same, which is equal to _c \u2212_ _n_ _[\u03be][\u2113]_ _\u2113_ [.]\n\n- Consumer subgroup _V_ 2 _\u2113_ has size _m_ 2 _\u2113_ \u225c _c \u00b7 n\u2113_ . For the _i_ -th consumer in consumer subgroup _V_ 2 _\u2113_, she\n\naccepts the first _n\u2113_ _\u2212\u230a_ _c_ _[i]_ _[\u230b]_ [products of product subgroup] _[ U][\u2113]_ [.]\n\nThe clairvoyant optimum policy assigns a perfect matching between consumer subgroup _V_ 2 _\u2113_ and product\n\nsubgroup _U\u2113_ for every _\u2113_ _\u2208_ [0 : _N_ ], and assigns every consumer from consumer subgroup _V_ 2 _\u2113\u2212_ 1 with a unit\n\nof her acceptable product from product subgroup _U\u2113\u2212_ 1 that is added at time period _t\u2113_ due to exogenous\n\nshocks for every _\u2113_ _\u2208_ [ _N_ ]. Hence, the total revenue of the clairvoyant optimum policy is [\ufffd] _\u2113\u2208_ [0: _N_ ] _[r][\u2113]_ _[\u00b7][ c][ \u00b7][ n][\u2113]_ [+]\n\n\ufffd _\u2113_ _N_ _[r][\u2113][\u2212]_ [1] _[ \u00b7][ \u03be][\u2113]_ [.]\n\nshocks for every _\u2113_ _\u2208_ [ _N_ ]. Hence, the total revenue of the clairvoyant optimum policy is [\ufffd]\n\n_\u2113\u2208_ [ _N_ ] _[r][\u2113][\u2212]_ [1] _[ \u00b7][ \u03be][\u2113]_ [.]\n\nOn the other end, SCIB is sub-optimal because of the revenue loss from two parts. First, it only assigns\n\nan imperfect matching between consumer subgroup _V_ 2 _\u2113_ and product subgroup _U\u2113_ for every _\u2113_ _\u2208_ [0 : _N_ ].\n\nMoreover, for every _\u2113_ _\u2208_ [ _N_ ] and every consumer from consumer subgroup _V_ 2 _\u2113\u2212_ 1, the algorithm allocates a\n\nunit of her acceptable product from product subgroup _U\u2113_ .\n\nBased on the aforementioned instance construction, we numerically evaluate the performance SCIB with\n\nexponential penalty function \u03a8( _x_ ) = _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_ on instance _G_ (20 _,_ 0 _._ 5 _,_ 0 _._ 32) with _n_ 0 = 500, sufficiently large _c_\n\nand obtain a competitive ratio upper bound of 0.552.\n\n**EC.3.1.2. Competitive ratio upper bound of 0.53 for DCIB.** Our constructed instance _G_ [\u02c6] ( _N,r,s_ ) is\n\nparameterized by _N \u2208_ N and _r,s \u2208_ [0 _,_ 1]. The construction of _G_ [\u02c6] ( _N,r,s_ ) is almost the same as _G_ ( _N,r,s_ )\n\nabove, expect that we set _\u03bei,t\u2113_ \u225c _s\u00b7c_ 1 _\u2212\u2212xsi,t\u2113_ for every _\u2113_ _\u2208_ [ _N_ ] and _i \u2208_ _U\u2113\u2212_ 1. Under this modification of _{\u03bei,t\u2113}_,\n\nwe still ensure that for every _\u2113_ _\u2208_ [ _N_ ] and every consumer from consumer subgroup _V_ 2 _\u2113\u2212_ 1, DCIB allocates a\n\nunit of her acceptable product from product subgroup _U\u2113_, while the clairvoyant optimum policy allocates a\n\nunit of her acceptable product from product subgroup _U\u2113\u2212_ 1.\n\nBased on the aforementioned instance construction, we numerically evaluate the performance DCIB with\n\nexponential penalty function \u03a8( _x_ ) = _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_ on instance _G_ [\u02c6] (20 _,_ 0 _._ 5 _,_ 0 _._ 3) with _n_ 0 = 500, sufficiently large _c_\n\nand obtain a competitive ratio upper bound of 0.53.\n\n**EC.3.1.3. Competitive ratio upper bound of 0.5 for USIB.** Consider an instance _G_ [\u00af] ( _\u03f5_ ) with 2 products.\n\nProduct 1 has price per unit _r_ 1 \u225c 1 and a large enough initial inventory _c_ 1 \u225c _c_ . Product 2 has price per unit\n\n_r_ 2 \u225c 1 _\u2212_ _\u03f5_ and infinite initial inventory _c_ 2 \u225c _\u221e_ . There are _T_ \u225c _c_ + 2 _c_ [2] time periods. At each time period\n\n_t \u2208{c_ + 1 _,c_ + 3 _,...,T \u2212_ 1 _}_, a new unit of product 1 is added due to exogenous inventory shock.\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec9\n\nFor every time period _t \u2208_ [ _c_ ], a consumer who only accepts product 1 arrives. For every time period\n\n_t \u2208{c_ + 1 _,c_ + 3 _,...,T \u2212_ 1 _}_, a consumer who accepts both products 1 and 2 arrives. For every time period\n\n_t \u2208{c_ + 2 _,c_ + 4 _,...,T_ _}_, a consumer who only accepts product 1 arrives.\n\nThe clairvoyant optimum policy allocates a unit of product 1 to every consumer _t \u2208_ [ _t_ ] _\u222a{c_ + 2 _,c_ +\n\n4 _,...,T_ _}_ and collect per unit price _r_ 1 = 1. Meanwhile, it allocates a unit of product 2 to every consumer\n\n_t \u2208{c_ + 1 _,c_ + 3 _,...,T \u2212_ 1 _}_ and collect per unit price _r_ 2 = 1 _\u2212_ _\u03f5_ . Hence, the total revenue of the clairvoyant\n\noptimum policy is _T \u2212_ _[T]_ _[\u2212]_ 2 _[c]_ _[\u03f5]_ [ =] _[ c]_ [ + 2] _[c]_ [2] _[ \u2212]_ _[c]_ [2] _[\u03f5]_ [.]\n\nOn the other end, USIB allocates a unit of product 1 to every consumer _t \u2208_ [ _t_ ] _\u222a{c_ + 1 _,c_ + 3 _,...,T \u2212_ 1 _}_,\n\nand allocates nothing to every consumer _t \u2208{c_ + 2 _,c_ + 4 _,...,T_ _}_ . Consequently, the total revenue of the\n\nalgorithm is _c_ + _[T]_ _[\u2212]_ 2 _[c]_ = _c_ + _c_ [2] .\n\n_c_ + _c_ [2]\nPutting two pieces together, the competitive ratio of the algorithm on this constructed instance is [2] _\u2212_\n\n_c_ +2 _c_ [2] _\u2212c_ [2] _\u03f5_\n\nwhich converges to [1] [as] _[ \u03f5]_ [ goes to zero and] _[ c]_ [ goes to infinity.]\n\n2 [as] _[ \u03f5]_ [ goes to zero and] _[ c]_ [ goes to infinity.]\n\n**EC.3.1.4. Comparison between policies on constructed instances.** Finally, we examine all policies on\n\nthe aforementioned instances _G_ ( _N,r,s_ ), _G_ [\u02c6] ( _N,r,s_ ), _G_ [\u00af] ( _\u03f5_ ), which numerically upper bound the competitive\n\nratio of SCIB, DCIB, USIB, respectively (Sections EC.3.1.1 to EC.3.1.3). BIB, SCIB, DCIB and USIB all\n\nuse exponential penalty function \u03a8( _x_ ) = _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_ [, and the batch-size threshold] _[ \u03b3]_ [ in][ BIB][ is set as] _[ \u03b3]_ [ = 10][.]\n\nWe record the revenue of different policies in Table EC.1. It can be seen that in all three instances, all four\n\nIB policies outperform the myopic greedy policy (GREED). In particular, the revenue gap between BIB and\n\nGREED are 15.3%, 12.0%, 103.1% for three instances, respectively. It can also be observed that BIB has\n\nthe most robust performance for all three instances. In instances _G_ (10 _,_ 0 _._ 5 _,_ 0 _._ 32) and _G_ [\u02c6] (10 _,_ 0 _._ 5 _,_ 0 _._ 3), BIB\n\noutperforms SCIB and DCIB significantly, and is close to USIB (which is equivalent to BIB with _\u03b3_ = 1).\n\nIn instance _G_ [\u00af] (0 _._ 1), BIB outperforms USIB significantly, and is close to SCIB and DCIB.\n\n**Table EC.1** Comparing the average revenue of different policies (Section EC.3.1). Instances _G_ ( _N,r,s_ ), _G_ [\u02c6] ( _N,r,s_ ), _G_ [\u00af] ( _\u03f5_ ) are\n\nconstructed to upper bound the competitive ratio of SCIB, DCIB, USIB, respectively. For instances _G_ ( _N,r,s_ ) and _G_ [\u02c6] ( _N,r,s_ ), we\n\nset _n_ 0 = 100 and _c_ = 50. For instance _G_ [\u00af] ( _\u03f5_ ), we set _c_ = 50.\n\n\u02c6 \u00af\n_G_ (10 _,_ 0 _._ 5 _,_ 0 _._ 32) _G_ (10 _,_ 0 _._ 5 _,_ 0 _._ 3) _G_ (0 _._ 1)\n\nBIB 5607.72 6295.95 4570.50\n\nSCIB 5103.57 5765.26 4800.00\n\nDCIB 5103.57 5515.90 4800.00\n\nUSIB 5848.45 6658.80 2250.00\n\nGREED 4864.29 5622.82 2250.00\n\nec10 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n**EC.3.2. Numerical Performance under Random Instances**\n\nIn this section, we examine the numerical performance of different policies on the following randomly gen\n\nerated instances.\n\n**Experimental setup.** We generate the following assortment instances. There are six products indexed by\n\n[6] and _T_ = 3000 time periods. Each product _i \u2208_ [6] has an identical initial inventory _c_ 0 = 30 and per unit\n\nprice _ri_ drawn uniformly between 10 and 25. Without loss of generality, we reindex products such that _ri_ is\n\ndecreasing in _i \u2208_ [6]. Each product _i \u2208_ [6] has identical endogenous inventory shock with lead time _di_ = _T/_ 3\n\nand exogenous inventory shock _\u03bei,t_ drawn i.i.d. from geometric distribution Geo(0 _._ 98) for every time period\n\n_t \u2208_ [ _T_ ].\n\nThere are six types of consumers indexed by 1 : 6. For each consumer type _j \u2208_ [6], it is associated with\n\na \u201cconsideration set\u201d [ _j_ ] and each product _i \u2208_ [ _j_ ] is selected based on a Multinomial Logit (MNL) choice\n\nmodel. Specifically, if assortment _S \u2286_ [6] is offered, consumers of type _j \u2208_ [6] selects each product _i \u2208_ _S_\n\nwith probability _\u03d5_ [(] _[j]_ [)] ( _S,i_ ) = _\u03b1i_ [(] _[j]_ [)] _[/]_ [(] _[\u03b1]_ 0 [(] _[j]_ [)] + [\ufffd] _i_ _[\u2032]_ _\u2208S_ _[\u03b1]_ _i_ [(] _[\u2032][j]_ [ )][)] [, where] _[ \u03b1]_ _i_ [(] _[j]_ [)] = 0 if _i > j_ (i.e., she does not select\n\na product outside of her consideration set), and _\u03b1i_ [(] _[j]_ [)] is drawn uniformly between 0.9 and 1.1 if _i \u2208_ [ _j_ ].\n\nFinally, the outside option (i.e., selecting nothing) is picked by constant probability 0.1 by setting _\u03b1_ 0 [(] _[j]_ [)] so\n\nthat _\u03b1_ 0 [(] _[j]_ [)] _[/]_ [(] _[\u03b1]_ 0 [(] _[j]_ [)] [+][ \ufffd] _i_ _[\u2032]_ _\u2208S_ _[\u03b1]_ _i_ [(] _[\u2032][j]_ [ ) = 0][)] _[.]_ [1][.]\n\nIn each time period _t \u2208_ [ _T_ ], a new consumer is sampled from the following stochastic process similar to\n\nRusmevichientong et al. (2020). We divide the whole time horizon into 3 equal-length phases, each with 6\n\nequal-length chunks. Thus, there are in total 18 chunks with equal length _\u03c4_ = _T/_ 18. Let _\u03c4_ [(] _[j]_ [)] = (6 _\u2212_ _j_ ) _\u03c4_ + 1\n\nfor every _j \u2208_ [6]. At each time period _t \u2208_ [ _T_ ], let _t_ _[\u2032]_ = _t_ mod ( _T/_ 3) _\u2208_ [ _T/_ 3], a consumer of type _j \u2208_ [6]\n\narrives with probability proportional to _e_ _[\u2212]_ [0] _[.]_ [001] _[\u03ba][|][t][\u2032][\u2212][\u03c4]_ [(] _[j]_ [)] _[|]_ . Here, _\u03ba_ is a parameter that controls the arrival pattern\n\nof the consumer types. Specifically, _\u03ba_ = 0 corresponds to i.i.d. arrival of types from the uniform distribution;\n\nand the arrival becomes more heterogeneous with convergence towards a deterministic arrival in descending\n\norder of types in every phase as _\u03ba_ increases.\n\nWe consider four scenarios corresponding to _\u03ba \u2208_ [4]. For each scenario, we consider running policies\n\nover independent sample paths of the input (including exogenous inventory shocks, type realizations, and\n\nconsumer choices) by doing 20 iterations of the Monte-Carlo simulation. Batched Inventory Balancing,\n\nStatic-Capacity Inventory Balancing, Dynamic-Capacity Inventory Balancing and Unit-Specific Inventory\n\nBalancing all use exponential penalty function \u03a8( _x_ ) = _[e]_ [1] 1 _[\u2212]_ _\u2212_ _[x]_ _e_ _[\u2212][e]_ [, and the batch-size threshold] _[ \u03b3]_ [ in Batched]\n\nInventory Balancing is set as _\u03b3_ = 10.\n\nIn addition to the aforementioned experimental setup, we also consider two further variants, both of which\n\nextend beyond the model analyzed in our theoretical results. In the first variant, we allow for _negative exoge-_\n\n_nous inventory shocks_ . (Such shocks can be interpreted as unexpected damage to currently available product\n\nunits.) Specifically, after drawing _\u03bei,t_ from the geometric distribution Geo(0 _._ 98), we flip its sign (i.e., set\n\n_\u03bei,t \u2190\u2212\u03bei,t_ ) with probability 0 _._ 2. In the second variant, we allow for _i.i.d. stochastic endogenous inventory_\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec11\n\n**Table EC.2** Comparing the average revenue of different policies (Section EC.3.2) in the original setup.\n\n_\u03ba_ = 0 _\u03ba_ = 1 _\u03ba_ = 2 _\u03ba_ = 3\n\nBIB 27836.91 32308.41 29972.79 23121.82\n\nSCIB 27747.12 32197.73 29775.70 22914.32\n\nDCIB 27852.76 32316.99 30101.17 23170.69\n\nUSIB 27017.10 31385.22 29070.33 22572.46\n\nGREED 25999.49 30184.01 27926.82 21502.78\n\n_shocks_ . Specifically, for each consumer and her selected product unit, we draw a random duration indepen\n\ndently from the geometric distribution Geo(3 _/T_ ), which has an expected value of _T/_ 3.\n\n**Results.** We record the revenues of all 20 iterations of the Monte-Carlo simulation for each experiment setup.\n\nFor the original setup, we use \u201cbox and whisker\u201d plots to demonstrate the median revenues and the result\n\ning confidence intervals (Figure EC.1) and compute the average revenue as an estimate for the expected\n\nrevenue of each policy (Table EC.2). It is clear from both Figure EC.1 and Table EC.2 that all four IB poli\n\ncies outperform the myopic greedy policy and the largest revenue gap is 7.1%, 7.0%, 7.8%, 7.8% for all four\n\nscenarios _\u03ba \u2208_ [4], respectively. Among all four IB policies, Unit-Specific Inventory Balancing has the lowest\n\nrevenue, Static-Capacity Inventory Balancing has the second lowest revenue. Batched Inventory Balancing\n\nand Dynamic-Capacity Inventory Balancing have almost the same best revenue.\n\nFor the variant with negative exogenous inventory shocks, we compute the average revenue as an estimate\n\nof the expected revenue for each policy in Table EC.3. The numerical patterns observed in the original setup\n\nlargely carry over: all four IB policies consistently outperform the myopic greedy benchmark. However,\n\nthe revenue gap between the IB policies and the greedy policy becomes smaller. In particular, the largest\n\nimprovements are approximately 1 _._ 9%, 1 _._ 8%, 1 _._ 7%, and 2 _._ 1% for the four scenarios _\u03ba \u2208_ [4], respectively.\n\nAmong the IB policies, Unit-Specific Inventory Balancing always yields the lowest revenue, while Static\n\nCapacity Inventory Balancing and Dynamic-Capacity Inventory Balancing perform better and, together with\n\nBatched Inventory Balancing, achieve nearly identical top performance. More specifically, Batched Inventory\n\nBalancing attains the highest revenue when _\u03ba_ = 1 _,_ 2, Static-Capacity Inventory Balancing is best for _\u03ba_ = 3,\n\nand Dynamic-Capacity Inventory Balancing is best for _\u03ba_ = 4.\n\nFor the variant with geometrically distributed endogenous inventory shocks, the average revenues of all\n\npolicies are reported in Table EC.4. Consistent with the previous setups, all four IB policies outperform the\n\nmyopic greedy benchmark. The largest revenue improvements are about 6 _._ 3%, 6 _._ 0%, 5 _._ 5%, and 4 _._ 7% for the\n\nfour scenarios _\u03ba \u2208_ [4], respectively. Among the IB policies, Unit-Specific Inventory Balancing again yields\n\nthe lowest revenue, while Batched Inventory Balancing, Static-Capacity Inventory Balancing, and Dynamic\n\nCapacity Inventory Balancing remain closely matched and achieve highly competitive performance across\n\nall scenarios, with only minor variations in which policy attains the highest revenue.\n\nec12 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n(a) _\u03ba_ = 0 (b) _\u03ba_ = 1\n\n(c) _\u03ba_ = 2 (d) _\u03ba_ = 3\n\n**Figure EC.1** Box and whisker comparison of revenue under different policies (Section EC.3.2); Results are based on 20 iterations\n\nof Monte-Carlo simulation.\n\n**Table EC.3** Comparing the average revenue of different policies (Section EC.3.2) with negative exogenous inventory shocks.\n\n_\u03ba_ = 0 _\u03ba_ = 1 _\u03ba_ = 2 _\u03ba_ = 3\n\nBIB 13061.32 18746.69 20766.04 20000.45\n\nSCIB 13056.95 18746.49 20782.17 20002.64\n\nDCIB 13046.72 18744.64 20765.96 20007.51\n\nUSIB 12844.23 18498.98 20542.71 19673.44\n\nGREED 12816.43 18409.63 20435.91 19602.96\n\n### **EC.4. Illustrative Examples for the Interval Assignment Problem**\n\n![](papers/images/Robustness-of-Online-Inventory-Balancing-to-Inventory-Shocks.pdf-33-0.png)\n\n![](papers/images/Robustness-of-Online-Inventory-Balancing-to-Inventory-Shocks.pdf-33-1.png)\n\n![](papers/images/Robustness-of-Online-Inventory-Balancing-to-Inventory-Shocks.pdf-33-2.png)\n\n![](papers/images/Robustness-of-Online-Inventory-Balancing-to-Inventory-Shocks.pdf-33-3.png)\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec13\n\n**Table EC.4** Comparing the average revenue of different policies (Section EC.3.2) with geometrically distributed stochastic\n\nendogenous inventory shocks.\n\n_\u03ba_ = 0 _\u03ba_ = 1 _\u03ba_ = 2 _\u03ba_ = 3\n\nBIB 13061.32 18746.69 20766.04 20000.45\n\nSCIB 13056.95 18746.49 20782.17 20002.64\n\nDCIB 13046.72 18744.64 20765.96 20007.51\n\nUSIB 12844.23 18498.98 20542.71 19673.44\n\nGREED 12816.43 18409.63 20435.91 19602.96\n\nIn this section, we present instances of the interval assignment problem (IAP) to illuminate its combinato\n\nrial structure, motivate the need for a carefully constructed assignment, and the execution of our proposed\n\nAlgorithm 2.\n\n**The failure of real consumption levels.** As explained in Section 4.2 and in the proof of Theorem 1, the\n\noutput of the IAP is used to define a transformed version of the consumption level (i.e., total initial inven\n\ntory minus the remaining inventory at the time of allocation). This raises a natural question: does the real\n\nconsumption level\u2014defined as _|Ni|_ = _|{j_ : _ai \u2208_ [ _aj,bj_ ] _}|_ for each interval _i_ \u2014already satisfy the three\n\ndefining properties of the IAP, namely LOCAL-DOMINANCE, GLOBAL-DOMINANCE, and PARTITION\n\nMONOTONICITY? The answer is negative. The following example demonstrates that the naive assignment\n_I_ \u02c6 _i_ = _|Ni|_ may violate PARTITION-MONOTONICITY, even though it satisfies the other two properties by\n\nconstruction.\n\nEXAMPLE EC.1 (A PATH OF OVERLAPPING INTERVALS). Consider four intervals arranged in a \u201cpath\u201d\n\nwhere each overlaps only with its immediate predecessor and successor:\n\n[ _a_ 1 _,b_ 1] = [1 _,_ 4] _,_ [ _a_ 2 _,b_ 2] = [3 _,_ 6] _,_ [ _a_ 3 _,b_ 3] = [5 _,_ 8] _,_ [ _a_ 4 _,b_ 4] = [7 _,_ 10] _._\n\nHere, the left endpoints are strictly increasing ( _a_ 1 _< a_ 2 _< a_ 3 _< a_ 4), and for each _i_, the coverage set _Ni_ = _{j_ :\n\n_ai \u2208_ [ _aj,bj_ ] _}_ satisfies _N_ 1 = _{_ 1 _}_, _N_ 2 = _{_ 1 _,_ 2 _}_, _N_ 3 = _{_ 2 _,_ 3 _}_, and _N_ 4 = _{_ 3 _,_ 4 _}_ . An illustration is provided in\n\nFigure EC.2.\n\nUnder the naive assignment _I_ [\u02c6] _i_ = _|Ni|_, we obtain ( _I_ [\u02c6] 1 _,_ _I_ [\u02c6] 2 _,_ _I_ [\u02c6] 3 _,_ _I_ [\u02c6] 4) = (1 _,_ 2 _,_ 2 _,_ 2) for Example EC.1. This\n\nassignment satisfies LOCAL-DOMINANCE (each coverage set contains labels that dominate _{_ 1 _,...,_ _|Ni|}_ )\n\nand GLOBAL-DOMINANCE (since _I_ [\u02c6] _i_ = _|Ni|_, the inequality holds with equality for any decreasing concave\n\npenalty). However, it _violates_ PARTITION-MONOTONICITY: there is only one interval labeled \u201c1\u201d, yet three\n\nintervals labeled \u201c2\u201d. Consequently, it is impossible to partition the intervals into groups such that each group\n\nof size _m_ contains exactly the labels _{_ 1 _,_ 2 _,...,m}_ .\n\nThis failure is significant because PARTITION-MONOTONICITY plays a crucial role in aligning the primal\n\nand dual objective values in the proof of Theorem 1. Without it, setting the dual variables equal to the\n\nec14 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\n_a_ 2\n\n_b_ 2\n\n_a_ 4\n\n_b_ 4\ntime\n\nPredecessor links: _p_ 2 = 1, _p_ 4 = 3\n\n**Figure EC.2** Example EC.1: A path of four overlapping intervals. Each interval overlaps only with its immediate neighbor. Both\n\nendpoints ( _ai,bi_ ) for each interval _i_ are marked in red. The bold number inside each interval indicates its IAP\n\nassignment _I_ [\u02c6] _i_, and the blue dashed arrows illustrate the predecessor links _pj_ = _i_ that define the partition satisfying\n\nPARTITION-MONOTONICITY.\n\nreal consumption levels would not recover the tight approximation guarantee established by Golrezaei et al.\n\n(2014) in the special case with no endogenous shock.\n\nIn contrast, Algorithm 2 produces a valid IAP assignment for Example EC.1. Specifically, it outputs\n\n( _I_ [\u02c6] 1 _,_ _I_ [\u02c6] 2 _,_ _I_ [\u02c6] 3 _,_ _I_ [\u02c6] 4) = (2 _,_ 1 _,_ 2 _,_ 1), which satisfies all three properties. It constructs this assignment in the follow\ning order: _I_ [\u02c6] 3 _\u2190_ 2, _I_ [\u02c6] 1 _\u2190_ 2, _I_ [\u02c6] 4 _\u2190_ 1, and _I_ [\u02c6] 2 _\u2190_ 1. As illustrated in Figure EC.2, the resulting labels enable a\n\npartition into two disjoint chains\u2014 _{_ 1 _,_ 2 _}_ and _{_ 3 _,_ 4 _}_ \u2014each of which satisfies PARTITION-MONOTONICITY.\n\n**The failure of a simple greedy procedure.** Example EC.1 demonstrates that the naive assignment based on\n\nreal consumption levels is insufficient, thereby motivating the need for an algorithm that explicitly enforces\n\nall three properties of IAP.\n\nA natural follow-up question is whether a simpler algorithm\u2014beyond the full IAP construction\u2014might\n\nsuffice. One such candidate is the following _greedy_ procedure: process the intervals in increasing order\n\nof their left endpoints, and for each interval, assign the _smallest_ positive integer that maintains LOCAL\n\nDOMINANCE with respect to all previously processed coverage sets. The rationale is that LOCAL\n\nDOMINANCE only constrains intervals whose left endpoints have already been encountered, making a for\n\nward greedy choice seemingly safe.\n\nIndeed, for Example EC.1, this greedy procedure yields the assignment (1 _,_ 2 _,_ 1 _,_ 2), which satisfies LOCAL\n\nDOMINANCE, GLOBAL-DOMINANCE, and PARTITION-MONOTONICITY. However, as the next example\n\nshows, this procedure does not generalize: on more complex instances, the greedy assignment may satisfy\n\nLOCAL-DOMINANCE but violate PARTITION-MONOTONICITY, and thus fail to meet the full requirements\n\nof the IAP.\n\nEXAMPLE EC.2 (A BINARY-TREE STRUCTURE OF INTERVALS). Consider seven intervals arranged in\n\na complete binary tree of depth 3 (i.e., three levels), defined as follows:\n\nLevel 1 (root): [ _a_ 1 _,b_ 1] = [1 _,_ 14] _,_\n\nLevel 2 (children of root): [ _a_ 2 _,b_ 2] = [2 _,_ 7] _,_ [ _a_ 5 _,b_ 5] = [8 _,_ 13] _,_\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec15\n\n_a_ 1\n\n_b_ 1\n\n|Col1|Col2|Col3|\n|---|---|---|\n||**3**||\n||**2**<br>**1**<br>**1**<br>2<br>_b_2|**2**<br>**1**<br>**1**<br>2<br>_b_2|\n\n_a_ 3 _b_ 3 _a_ 4 _b_ 4\n\n_a_ 6 _b_ 6 _a_ 7 _b_ 7\n\ntime\n\nPredecessor links: _p_ 2 = 1, _p_ 3 = 2, _p_ 6 = 5\n\n**Figure EC.3** Example EC.2: A complete binary-tree hierarchy of seven intervals. Each parent fully contains its two children.\n\nBoth endpoints ( _ai,bi_ ) for each interval _i_ are marked in red. The bold number inside each interval indicates its IAP\n\nassignment _I_ [\u02c6] _i_, and the blue dashed arrows illustrate the predecessor links _pj_ = _i_ that define the partition satisfying\n\nPARTITION-MONOTONICITY.\n\nLevel 3 (leaves): [ _a_ 3 _,b_ 3] = [3 _,_ 4] _,_ [ _a_ 4 _,b_ 4] = [5 _,_ 6] _,_ [ _a_ 6 _,b_ 6] = [9 _,_ 10] _,_ [ _a_ 7 _,b_ 7] = [11 _,_ 12] _._\n\nwhere the left endpoints are strictly increasing ( _a_ 1 _< a_ 2 _< \u00b7\u00b7\u00b7 < a_ 6 _< a_ 7). Each interval is fully contained\n\nwithin its parent, and for every _i_, the coverage set _Ni_ = _{j_ : _ai \u2208_ [ _aj,bj_ ] _}_ consists precisely of interval _i_ and\n\nall its ancestors in the tree. An illustration is provided in Figure EC.3.\n\nFor Example EC.2, the aforementioned greedy procedure yields the assignment (1 _,_ 2 _,_ 3 _,_ 3 _,_ 2 _,_ 3 _,_ 3), [19] which\n\nsatisfies LOCAL-DOMINANCE, GLOBAL-DOMINANCE, but violates PARTITION-MONOTONICITY: there is\n\nonly one interval labeled \u201c1\u201d, yet two intervals labeled \u201c2\u201d, and four intervals labeled \u201c3\u201d. Consequently, it\n\nis impossible to partition the intervals into groups such that each group of size _m_ contains exactly the labels\n\n_{_ 1 _,_ 2 _,...,m}_ .\n\nIn contrast, although more involved, Algorithm 2 produces a valid IAP assignment for Example EC.2.\n\nSpecifically, it outputs assignment (3 _,_ 2 _,_ 1 _,_ 1 _,_ 2 _,_ 1 _,_ 1), which satisfies all three properties. [20] It constructs this\n\nassignment in the following order: _I_ [\u02c6] 1 _\u2190_ 3, _I_ [\u02c6] 5 _\u2190_ 2, _I_ [\u02c6] 2 _\u2190_ 2, _I_ [\u02c6] 7 _\u2190_ 1, _I_ [\u02c6] 6 _\u2190_ 1, _I_ [\u02c6] 4 _\u2190_ 1, and _I_ [\u02c6] 3 _\u2190_ 1. As illus\n\ntrated in Figure EC.3, the resulting labels enable a partition into disjoint chains\u2014 _{_ 1 _,_ 2 _,_ 3 _}_, _{_ 5 _,_ 6 _}_, _{_ 4 _}_, and\n\n_{_ 7 _}_ \u2014each of which satisfies PARTITION-MONOTONICITY.\n\n### **EC.5. Open Problems**\n\nOur analysis of online assortment under inventory shocks is built on a clean abstraction of reusability\u2014\n\nwhere endogenous shocks model the automatic return of allocated units after a fixed usage duration\u2014and\n\nexogenous shocks capture unpredictable inflows of new supply. While this model captures a wide range of\n\n19 The real consumption levels induce the same assignment, which violates PARTITION-MONOTONICITY, for Example EC.2.\n\n20 In Example EC.2, the valid IAP assignment (3 _,_ 2 _,_ 1 _,_ 1 _,_ 2 _,_ 1 _,_ 1) can be considered as the inventory level. However, this does not\nimply that the real inventory level is always valid for IAP assignment. To see this, consider a modification of Example EC.2 in which\nthe left endpoints are reordered\u2014specifically, set _a_ 3 = 1 and _a_ 1 = 3, while keeping all other left and right endpoints unchanged.\nIn this modified example, the inventory level becomes (1 _,_ 2 _,_ 3 _,_ 1 _,_ 2 _,_ 1 _,_ 1). Although this assignment satisfies GLOBAL-DOMINANCE\nand PARTITION-MONOTONICITY, it _violates_ LOCAL-DOMINANCE: for interval 4, the coverage set _N_ 4 includes intervals whose\nassigned values are insufficient to dominate the required set _{_ 1 _,...,_ _|N_ 4 _|}_ .\n\nec16 e-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_\n\napplications, several natural extensions arise from both practical considerations and theoretical curiosity. We\n\noutline four promising directions for future work.\n\n**Negative inventory shocks and loss modeling.** Our current model assumes non-negative exogenous shocks.\n\nHowever, in real-world settings, inventory may be unexpectedly reduced due to damage, spoilage, theft, or\n\nsystem errors\u2014phenomena we model as _negative exogenous shocks_ . As shown in Section EC.3, BIB exhibits\n\nstrong empirical performance even when negative shocks are introduced. From a theoretical perspective,\n\nnegative shocks introduce nonlinearity into the inventory dynamics (e.g., the \u201cavailable inventory\u201d is the\n\nmax of zero and prior inventory minus shock), which complicates the design of a tractable LP benchmark.\n\nDeveloping competitive algorithms with formal guarantees under such adverse shocks\u2014potentially by com\n\nbining our batching ideas with robustness techniques from convex optimization and duality analysis\u2014is a\n\ncompelling direction for future research. [21]\n\n**Stochastic and heterogeneous return durations.** Our analysis assumes deterministic and homogeneous\n\nusage durations _di_ . However, in many applications (e.g., gig platforms, hospital beds, rental markets), the\n\nduration a unit remains unavailable is random and may vary across allocations. Recent work by Kang et al.\n\n(2025) shows that our batched framework can be lifted via a black-box reduction to settings with i.i.d.\n\nstochastic return times, preserving the 1 _\u2212_ 1 _/e_ competitive ratio under mild conditions. An open question is\n\nwhether similar guarantees can be obtained for adversarial or highly heterogeneous duration distributions, or\n\nwhether new algorithmic ideas are required.\n\n**Endogenous shocks from operational replenishment policies.** In omni-channel retail and supply chain\n\nsettings, endogenous inventory replenishment often stems not from usage-driven returns but from opera\n\ntional policies such as ( _s,S_ )-type or threshold-based restocking. In such models, a replenishment order is\n\ntriggered when on-hand inventory falls below a threshold, and units arrive after a (possibly stochastic) lead\n\ntime. Extending our framework to accommodate such endogenous dynamics would require reinterpreting\n\nthe \u201creturn duration\u201d as a lead time and incorporating the replenishment decision into the adversary\u2019s power\n\nor the algorithm\u2019s control.\n\n**Incorporating inventory holding and restocking costs.** Our objective focuses solely on revenue maximiza\n\ntion, ignoring potential costs associated with holding inventory or placing restocking orders. Extending the\n\nmodel to include holding costs (e.g., per-unit-per-period) or fixed restocking costs would shift the objective\n\ntoward profit maximization and likely favor more conservative allocation policies. Integrating such costs into\n\nthe primal-dual analysis\u2014perhaps via modified penalty functions or cost-aware dual variables\u2014remains an\n\nintriguing challenge.\n\n21 Using a standard charging argument, the myopic greedy policy (equivalently, the Inventory Balancing algorithm with penalty\nfunction \u03a8( _x_ ) = 1 _{x >_ 0 _}_ ) can be shown to be 0 _._ 5-competitive under adversarial negative shocks.\n\ne-companion to **Feng, Niazadeh, Saberi:** _Robustness of Online Inventory Balancing to Inventory Shocks_ ec17\n\n**Joint inventory-assortment control under shocks.** In our model, exogenous shocks are fully adversarial\n\nand uncontrollable. However, in practice, platforms may exert partial control over inventory inflows\u2014for\n\nexample, by procuring additional units, triggering returns, or managing volunteer sign-up campaigns. A nat\n\nural generalization is a _joint inventory-assortment control_ problem, where the decision maker simultaneously\n\nchooses both the assortment and an inventory action (e.g., order quantity, promotional effort) at each time\n\nstep. Developing competitive algorithms for this richer setting would require coupling the batched inventory\n\nbalancing framework with dynamic inventory control techniques."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a constructive proof using Algorithm 2 to establish three critical properties for an 'Interval Assignment Problem' (IAP): LOCAL-DOMINANCE, GLOBAL-DOMINANCE, and PARTITION-MONOTONICITY. Algorithm 2 assigns integer labels (I_hat_i) to 'intervals' (representing resource states or inventory buckets) in an iterative, somewhat greedy fashion, determining an interval's label based on its local 'coverage' and existing assignments, then removing it from consideration. The PARTITION-MONOTONICITY property is particularly intricate, requiring that a 'predecessor' mapping (p_j = i, effectively like pointers) decomposes the intervals into disjoint chains where labels strictly decrease by one along each chain (e.g., 3 -> 2 -> 1). This is proven by contradiction, showing that any deviation from this chain structure (e.g., two intervals pointing to the same predecessor with the same label increment) would contradict the state of local coverage counts at the moment of assignment/removal.\n\n**Explanation:** This paper shows *how* we can assign meaningful 'importance scores' (the I_hat values) to different inventory segments, or 'intervals', over time. Instead of just counting current inventory, which can be misleading, Algorithm 2 carefully processes these intervals. Think of it like a sophisticated loop that iteratively picks an interval, calculates its I_hat value based on what other intervals 'cover' it at that precise moment (similar to how a hash map might store local counts), and then removes it. This dynamic assignment ensures that: (i) LOCAL-DOMINANCE: an interval's assigned score reflects its relative 'busyness' or coverage, like a local ranking. (ii) GLOBAL-DOMINANCE: in aggregate, these scores maintain a desired mathematical relationship (an inequality with a concave function), which is vital for the overall performance of the inventory system. This is proven by an induction that 'reverses' the algorithm, showing how adding intervals back preserves a key property. (iii) PARTITION-MONOTONICITY: this is the real trick. It ensures that the assigned scores form a perfectly structured hierarchy. Imagine you have levels 1, 2, 3... and for every item at level 'X', there's a unique 'parent' item at level 'X-1'. This creates neat, unbroken 'chains' of importance. This 'chain-linking' mechanism is fundamental because it allows the authors to perform a 'primal-dual' analysis, mathematically connecting the algorithm's choices to an optimal benchmark. Without this specific, non-obvious construction (as demonstrated by simpler greedy algorithms failing), the strong performance guarantees wouldn't hold. The numerical tests confirm that this complex assignment method yields significantly better results than simpler, intuitive approaches."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc37\ud835\udc52\ud835\udc59_ **_** _\ud835\udc45\ud835\udc61_ **_** _\ud835\udc5c\ud835\udc53_ **_** _\ud835\udc46\ud835\udc39\ud835\udc56_ ;\n\n**8** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ + + ;\n\n**9** _\ud835\udc47\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc37\ud835\udc52\ud835\udc59_ _ _\ud835\udc45\ud835\udc61_ + = _\ud835\udc37\ud835\udc52\ud835\udc59_ _ _\ud835\udc45\ud835\udc61_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc56_ ;"}, {"role": "assistant", "content": "**Mechanism:** This describes a simple iterative aggregation. It's a fundamental loop structure where a total_sum variable accumulates values from individual elements in a collection. Each SF_i contributes its Del_Rt to the Total_Del_Rt.\n\n**Explanation:** Think of it like a 'for' loop or 'foreach' loop. You start with 'Total_Del_Rt = 0'. Then, for every 'SF_i' (like iterating through an array or list of objects), you retrieve its specific 'Del_Rt_of_SF_i' (a property of that object). You then update 'Total_Del_Rt' by adding this individual 'Del_Rt_of_SF_i' to it, essentially performing 'Total_Del_Rt = Total_Del_Rt + Del_Rt_of_SF_i' until all 'SF_i's have been processed. This mechanism is crucial for generating system-wide metrics from component-level data."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _< \ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ __\ud835\udc5a\ud835\udc4e\ud835\udc65_ **and** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc52_ **then**\n\n**11** _\ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2217 [(][2][\u2212] 2 _[\ud835\udefd]_ [)]"}, {"role": "assistant", "content": "**Mechanism:** This mechanism acts as a conditional, adaptive ceiling reduction for a network flow's maximum allowed transmission window. It's akin to a high-watermark adjustment. When a flow's current usage ('cwnd') is below a pre-established maximum ('Wlast_max') and the system prioritizes rapid stabilization ('fast_convergence'), the maximum allowed window is scaled down. The scaling factor `(2 - 2^beta)` is key; if `beta` is positive, this factor is less than one, ensuring `Wlast_max` is reduced to a fraction of the current 'cwnd'.\n\n**Explanation:** Think of `Wlast_max` as a persistent 'max_capacity' variable, and `cwnd` as `current_usage`. This is a conditional `if (current_usage < max_capacity && global_fast_converge_flag == true)` block. Inside, `max_capacity` is updated as `max_capacity = current_usage * scaling_factor;`. The `scaling_factor` (derived from `beta`) ensures that the `max_capacity` isn't just `current_usage`, but a potentially smaller value, making it more conservative. This prevents `max_capacity` from becoming 'stuck' at an outdated high value if the connection temporarily reduces its `cwnd`. By immediately bringing `max_capacity` down, it helps to prevent a potential future overshoot if `cwnd` were to suddenly increase again. It essentially prunes the upper bound of a connection's potential growth, making the system more reactive to changes in actual usage and facilitating quicker convergence to a fairer or more stable state across all network flows, similar to how a garbage collector might deallocate memory that is no longer truly needed to free up resources."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_All proofs for theoretical results in this paper are found in the Appendix._\n\n**2.1** **Low Rank Matrix Approximations**\n\nWhen adapting high dimensional foundation models for specific tasks, updating the parameters using gradient\nbased methods has high memory requirements. LoRA uses low-rank approximations to the matrix multiplications to reduce these costs. For each matrix _Mi \u2208_ R _[m][\u00d7][n]_ in the model, a low-rank approximation can be made\nby decomposing each matrix:\n\n_Mi \u2248_ _Mi_ [0] [+] _[ A][i][B]_ _i_ _[\u22a4][,]_\n\nwhere _Mi_ [0] [:=][ StopGrad][(] _[M][i]_ [)][ is the imported matrix from the foundation model with frozen parameters and]\n_Ai \u2208_ R _[m][\u00d7][r]_ and _Bi \u2208_ R _[n][\u00d7][r]_ are low-width column matrices (i.e., _r \u226a_ min( _m, n_ )) whose parameters are\nupdated through gradient-based optimisation during task-specific adaptation. This reduces the number of\noptimisation parameters for each matrix from _mn_ to _r_ ( _m_ + _n_ ). In this paper, we use a similar low-rank matrix\napproximation for evolutionary strategies.\n\n**2.2** **Gaussian Matrix Distribution and Matrix Norms**\n\nIn this paper, we focus on evolution strategies that target _matrix parameters_ . Many variables we study are\nGaussian distributed. When working in matrix space, it is convenient to use the matrix Gaussian distribution\n(Dawid, 1981), which is defined directly over matrices _X \u2208_ R _[m][\u00d7][n]_ :\n\n1\n_N_ ( _M, U, V_ ) = ~~_mn_~~\n(2 _\u03c0_ ) 2 det( _U_\n\n_\u2212_ [1]\n2 [exp] \ufffd 2\n\n~~_n_~~ ~~_m_~~\n2 det( _U_ ) 2 det( _V_ ) 2\n\n[1] \ufffd _V_ _[\u2212]_ [1] ( _X \u2212_ _M_ ) _[\u22a4]_ _U_ _[\u2212]_ [1] ( _X \u2212_ _M_ )\ufffd [\ufffd] _,_\n\n2 [tr]\n\nwhere _M \u2208_ R _[m][\u00d7][n]_ is the mean matrix, _U \u2208_ R _[m][\u00d7][m]_ is the row covariance matrix and _V \u2208_ R _[n][\u00d7][n]_ is the\ncolumn covariance matrix. The matrix Gaussian distribution is a generalisation of the multivariate Gaussian\ndistribution _N_ ( _\u00b5,_ \u03a3) defined over vector space. Sampling a matrix _X \u223cN_ ( _M, U, V_ ) from a Gaussian matrix\ndistribution is equivalent to sampling a vector vec( _X_ ) _\u223cN_ ( _\u00b5,_ \u03a3) from a multivariate Gaussian distribution\nwith mean _\u00b5_ = vec( _M_ ) and covariance matrix \u03a3 = _V \u2297_ _U_ where _\u2297_ denotes the Kronecker product. For\nisotropic matrix Gaussian distributions with covariance matrices _U_ = _\u03c3_ [2] _Im_ and _V_ = _\u03c3_ [2] _In_, the equivalent\nmultivariate Gaussian distribution is also isotropic with \u03a3 = _\u03c3_ [2] _Imn_ . To measure distance between matrices,\nwe use the Frobenius norm:\n\n_\u2225M_ _\u2225F_ := _mi,j_ [2] _,_\n~~\ufffd\ufffd~~ _i,j_\n\n3\n\nwhich provides an upper bound on the matrix 2-norm (Petersen & Pedersen, 2008). We denote the _\u2113_ [2] vector\nnorm as _\u2225\u00b7\u2225_ .\n\n**2.3** **Evolution strategies**\n\nEvolution strategies (ES) (Rechenberg, 1978; Beyer, 1995; Beyer & Schwefel, 2002) is a set of blackbox\nmethods for optimising general systems. ES has emerged as a useful alternative to gradient-based methods,\nparticularly when a system is noisy or non-differentiable. Our problem setting focuses on fitness functions\nwhose parameters are matrices: our goal is to find a matrix _M_ _[\u22c6]_ _\u2208_ R _[m][\u00d7][n]_ that maximises the fitness function\n_M_ _[\u22c6]_ _\u2208_ arg max _M_ _\u2208_ R _m\u00d7n f_ ( _M_ ). In comparison to gradient-based methods which use derivatives of the\nfunction _f_ ( _M_ ) to update the parameters _M_ directly, evolutionary methods update a population distribution\nover the parameter space. This is achieved by learning a set of parameters _\u03b8_ to maximise the expected fitness\n_f_ ( _z_ ) under a population distribution _\u03c0_ ( _M_ _|\u03b8_ ):\n\n_J_ ( _\u03b8_ ) = E _M_ _\u223c\u03c0_ ( _M_ _|\u03b8_ ) [ _f_ ( _M_ )] _._ (1)\n\nTaking derivatives of _J_ ( _\u03b8_ ) yields the gradient:\n\n_\u2207\u03b8J_ ( _\u03b8_ ) = E _M_ _\u223c\u03c0_ ( _M_ _|\u03b8_ ) [ _\u2207M_ log _\u03c0_ ( _M_ _|\u03b8_ ) _f_ ( _M_ )] _,_\n\nwhich is used to update the population distribution\u2019s parameters using (stochastic) gradient ascent with a\nsuitable stepsize _\u03b1t_ :\n\n_\u03b8t_ +1 _\u2190_ _\u03b8t_ + _\u03b1t\u2207\u03b8J_ ( _\u03b8t_ ) _._ (2)\n\n_\u2207M_ log _\u03c0_ ( _M_ _|\u03b8_ ) is known as the score function, which avoids taking gradients directly through the fitness\nfunction in Eq. (1).\n\n**2.4** **Gaussian Matrix ES**\n\nIn this paper, we study ES using Gaussian policies: _\u03c0_ ( _M_ _|\u03b8_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ). In addition to its\nmathematical convenience, the central limit theorem means that the Gaussian distribution emerges naturally\nfrom a low-rank approximation as rank increases, even if the matrices _A_ and _B_ are themselves non-Gaussian.\nWe assume that _\u03c3_ [2] is fixed and the ES algorithm optimises over the mean matrix _\u03b8_ = _\u00b5_ which acts as a proxy\nfor the true maximum of the fitness function. By adapting well-known derivations (Wierstra et al., 2011) to the\nGaussian matrix case, we derive the ES gradient for our problem setting:\n**Proposition 1.** _Using the Gaussian matrix policy \u03c0_ ( _M_ _|\u00b5_ ) = _N_ ( _\u00b5, Im\u03c3_ [2] _, In\u03c3_ [2] ) _the ES objective can be_\n_written as:_\n\n_J_ ( _\u00b5_ ) = E _E\u223cP_ ( _E_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3E_ )] _._ (3)\n\n_and the matrix gradient of the ES objective is:_\n\n_\u2207\u00b5J_ ( _\u00b5_ ) = _\u2212_ [1] (4)\n\n_\u03c3_ [E] _[E][\u223c][P]_ [ (] _[E]_ [)][ [] _[E][ \u00b7][ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3E]_ [)]] _[ .]_\n\n_where P_ ( _E_ ) _is a zero-mean standard normal p_ ( _E_ ) = _N_ (0 _, Im, In_ ) _. Moreover, the natural matrix gradient is_\n_equal to \u03c3_ [2] _\u2207\u00b5J_ ( _\u00b5_ ) _, i.e. equivalent to Eq._ (4) _up to a factor of \u03c3_ [2] _._\n\nWe see from Eq. (4) that Gaussian matrix ES methods optimise the objective _J_ ( _\u00b5_ ) by generating search\nmatrices _E \u223c_ _P_ ( _E_ ) from a standard matrix normal distribution _N_ (0 _, Im, In_ ) around the parameter matrix\n_\u03b8_ = _\u00b5_ .\n\nWe remark that for Gaussian population distributions, the ES update in Eq. (4) is equal to the natural evolution\nstategy (NES) update up to a factor of _\u03c3_ [2] . NES (Wierstra et al., 2008; 2011) updates follow the _natural gradient_\n(Amari, 1998; Kakade, 2001) of the objective in Eq. (1). This means that for our problem setting where _\u03c3_ is\nassumed fixed and is absorbed into the stepsize in Eq. (2), Gaussian matrix ES and NES are equivalent. A key\nbenefit of the natural gradient is that it takes into account the local geometry of the underlying parameter space\nwhen updating the search distribution, making the updates invariant to the choice of parametrisation.\n\n4"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism combines two ideas: first, reducing the complexity of optimizing large matrices by using low-rank approximations (M = M\u2080 + A*B\u1d40), effectively freezing the majority of the matrix (M\u2080) and only adjusting a much smaller, composable set of parameters (A and B). This drastically cuts the parameter count (from m*n to r*(m+n)). Second, it uses Evolution Strategies (ES) to optimize these reduced parameters when direct gradient computation of the fitness function is difficult or impossible. ES works by maintaining a distribution over the parameters (a Gaussian matrix distribution in this case) and iteratively adjusting the distribution's mean (\u00b5) based on the fitness scores of samples drawn from it. The gradient for updating \u00b5 is estimated by correlating sampled parameter perturbations with their fitness, rather than directly differentiating the fitness function.\n\n**Explanation:** Think of a huge 2D array (matrix) that needs fine-tuning for a specific task. Instead of storing and processing every cell, we 'patch' it by adding a much smaller, editable matrix (A*B\u1d40) to the original, fixed one (M\u2080). This dramatically reduces the number of cells we need to worry about. Now, to find the best values for this small patch, we don't calculate a complex slope (derivative) for every cell to see how to move it. Instead, we have a 'search function' that generates many slightly different versions of the patch, all centered around our current best guess (\u00b5). We try each version, see how good the result is (fitness), and then slightly adjust our 'best guess' (\u00b5) for the next round. This adjustment is based on a weighted average: if a particular 'jitter' (E) on our patch led to a high score, we shift \u00b5 a bit in that jitter's direction. The 'Gaussian Matrix Distribution' ensures these jitters are mostly small and close to our current guess, but with some spread to explore. It's like tuning a parameter-generating machine by observing its output's performance, rather than directly calculating how each internal knob affects the final score."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ == _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ **then**\n\n**102** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3b\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc52_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**103** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc56\ud835\udc51\ud835\udc59\ud835\udc52_ _ _\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**104** BBR_Enter_Probe_RTT():\n\n**105** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ ;\n\n**106** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = 1 ;\n\n**107** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = 1 ;\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 55\n\n**ACK-arrival function definitions (cont. 3/4):**\n\n**108** BBR_Handle_Probe_RTT():\n\n/* Ignore low rate samples during ProbeRTT: */\n\n**109** _\ud835\udc36.\ud835\udc4e\ud835\udc5d\ud835\udc5d_ _ _\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc51_ = ( _\ud835\udc35\ud835\udc4a.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ + _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ ) ? : 1 ;"}, {"role": "assistant", "content": "**Mechanism:** The ProbeRTT state is a temporary phase where BBR deliberately reduces its 'aggressiveness' in filling the network pipe. By setting both `pacing_gain` and `cwnd_gain` to 1.0, the algorithm stops actively pushing to discover new bandwidth or increase its sending window. This effectively drains any standing queues in the network, exposing the true minimum Round Trip Time (RTT). The `BBR.idle_restart = false` setting prevents premature exiting due to application-limited scenarios, while the `C.app_limited` check, coupled with the comment 'Ignore low rate samples during ProbeRTT', indicates a mechanism to filter out potentially misleading RTT measurements that occur when the application isn't providing enough data to saturate the link, ensuring the recorded RTT accurately reflects network characteristics, not sender limitations.\n\n**Explanation:** This code defines the BBR algorithm's `ProbeRTT` state, which functions like a diagnostic mode. When BBR decides to enter or is currently in this state (controlled by the `BBR.state` variable, similar to an enum or state variable in a program), it adjusts its internal parameters. Specifically, setting `BBR.pacing_gain` and `BBR.cwnd_gain` to 1.0 means it temporarily stops multiplying its calculated bandwidth and congestion window. These gains normally allow BBR to explore for more capacity, but in `ProbeRTT`, the goal is to *contract* or stabilize, allowing any existing data queues to empty out. Think of it as a brief pause in expansion. This draining reveals the raw RTT, free from queueing delays. The `BBR_Handle_Probe_RTT` function further refines this by filtering RTT measurements, especially when the application isn't sending data fast enough (`C.app_limited`). This prevents BBR from misinterpreting a low sending rate (which can make RTT appear higher) as a true network characteristic. It's a crucial feedback loop to ensure RTT estimations are precise."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nFigure 7: Presence rate of each reasoning element for humans and randomly sampled LLMs. We filtered the presence judgments for _strongly_\n_present_ elements. X-axis is sorted based on the presence gap between\nhumans and LLMs.\n\n**Results and Analysis.** Table 4 reveals substantial heterogeneity in how models respond to cognitive\nstructure guidance. Modern, capable reasoning models (particularly the Qwen3 family and larger R1-Distill\nvariants) demonstrate significant improvements, with gains reaching up to 60% on ill-structured problem\ntypes (e.g., +60.0% for Qwen3-14B on dilemmas, +60.0% for R1-Distill-Qwen-32B on dilemmas). Notably,\nthese improvements concentrate most strongly on complex, open-ended problems (dilemmas, case analysis,\ndiagnostic reasoning) where explicit structural scaffolding appears most beneficial.\n\nHowever, this effectiveness is highly dependent on model capacity and architectural sophistication. Smaller\nor less capable models, particularly Hermes-3-Llama-3-8B and DeepScaleR-1.5B, show pronounced performance _degradation_ across most problem types, with losses exceeding 50% in several categories (e.g., -72.0%\nfor both models on algorithmic problems). This suggests a capability threshold: models must possess sufficient reasoning flexibility and instruction-following ability to productively adapt their processes to detailed\nstructural guidance. Below this threshold, explicit scaffolding appears to constrain rather than enhance rea\n\n20\n\nsoning, potentially by overwhelming limited cognitive resources or conflicting with ingrained problem-solving\nheuristics.\n\nThe pattern of improvements also illuminates problem-type specificity. Well-structured problems (algorithmic, rule-using) show more modest or even negative effects across models, while ill-structured problems\nexhibit the strongest positive responses in capable systems. This asymmetry likely reflects two factors: (1)\nwell-structured problems may already elicit relatively optimal reasoning patterns from models, leaving less\nroom for improvement, and (2) ill-structured problems benefit more from explicit organizational scaffolding\nthat helps models navigate ambiguous problem spaces.\n\nCollectively, these findings provide strong preliminary evidence that **optimal cognitive reasoning struc-**\n**tures aligned to problem characteristics can substantially enhance model performance** \u2014but only\nwhen models possess the architectural sophistication to leverage such guidance effectively. This suggests a\npromising direction for adaptive reasoning systems that dynamically apply problem-type-specific cognitive\nscaffolding to capable foundation models."}, {"role": "assistant", "content": "**Mechanism:** The mechanism involves providing a structured input prompt that acts as a pre-processor for the model's internal token generation process. For complex, open-ended problems, this guidance effectively prunes the vast search space of potential next tokens, directing the model's attention and probabilistic choices towards more relevant or structured sequences. It functions akin to supplying a highly specific function signature or a defined data structure for input parameters to a complex algorithm, thereby channeling its computational resources more efficiently.\n\n**Explanation:** When a large language model (LLM) tackles a problem, it's essentially predicting the next most probable word based on everything it's seen so far. For complex, ambiguous problems, the number of 'good' next words is enormous. Providing 'cognitive structure guidance' is like giving the model an explicit step-by-step program or a 'to-do list' as part of its input. For powerful models, this program helps them navigate the vast possibilities by focusing their 'computation' on relevant paths, much like a well-designed hash map allows for quick lookups by reducing the search space. However, smaller models have limited 'working memory' (context window and parameter capacity). The extensive guidance can act like an overly long and complex function call for a micro-controller: it might overwhelm its 'RAM' (context window), pushing out critical problem details, or conflict with its simpler, hard-coded 'if-then' processing rules, leading to performance degradation rather than improvement. For simpler, well-structured problems, the model might already have an efficient internal 'algorithm' (learned pattern), so adding external guidance is redundant and can introduce noise, similar to adding unnecessary conditional checks to an already optimized loop."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nUsing an NVIDIA V100 GPU, baseline training of 100K\nsteps took 10\u201330 min, with the TP variant adding only about\n20% wall-clock time. Figure 5 shows how the evaluation\nbudget shapes learning. At small _E_ (10-20), the Monte Carlo\nestimates exhibit noisy, spurious updates and wide confidence\nbands. This results in large fluctuations and wide confidence\nbands. At the other extreme, very large _E_ (e.g., 200), the\nalgorithm advances only slowly once the noise floor is suppressed. Intermediate values ( _E_ = 50\u2013100) suppress the\nworst of the noise without over-constraining the update rule,\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-6-1.png)\n\nFigure 4: Average return over training in the UnityML Reacher\nenvironment, showing profiling-enhanced DDPG not only converges\nfaster but also maintains greater stability compared to its vanilla\ncounterpart.\n\nyielding both rapid early gains and a much narrower variance\nenvelope. So roughly, pushing _E_ well beyond this critical\nscale offers diminishing returns. Once the estimation error\nis negligible, further rollouts merely add computational cost\nand slow down true policy updates. This reflects the batchsize trade-off in SGD (McCandlish et al. 2018), where a\ntask-dependent _critical batch size_ marks the point beyond\nwhich additional samples no longer improve data efficiency.\nBy analogy, one can think of a _critical evaluation budget_\n_E_ crit, and choose _E \u2248_ _E_ crit, to optimally balance variance\nreduction against responsiveness. Our framework complements other recent monotonic improvement goals (Xie et al.\n2025) without relying on stochastic density ratios, hence applies uniformly to both stochastic and deterministic settings."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around managing the signal-to-noise ratio in gradient estimation. When the 'evaluation budget' (E) is small, the Monte Carlo estimates of the policy gradient are highly variant, introducing significant 'noise' into the update direction. This noise causes erratic, unstable policy updates. Increasing 'E' reduces this variance, providing a more accurate gradient signal. However, each increase in 'E' also increases the computational cost per update step. The 'critical evaluation budget' (E_crit) marks the inflection point where the reduction in gradient estimation error no longer justifies the increased computational expense per step. Beyond E_crit, the gradient direction is already sufficiently stable, so further evaluations primarily slow down the rate of learning by increasing the time per step, without significant gains in update quality.\n\n**Explanation:** Think of our learning algorithm as trying to find the highest point on a bumpy, foggy landscape. Each step it takes is guided by a 'measurement' (the evaluation budget 'E') that tells it which way is 'up'. If 'E' is very small, it's like taking a single, quick measurement in thick fog: the reading is often wrong due to random fluctuations (noise), causing the algorithm to zigzag wildly or even go downhill. If 'E' is very large, it's like taking hundreds of measurements and averaging them perfectly to get an extremely precise 'up' direction. While each step is accurate, it takes a very long time to get that precise measurement, slowing down overall progress. The 'critical evaluation budget' is the sweet spot, similar to choosing an optimal 'batch size' in a loop for processing data. It's enough measurements to get a reasonably clear picture of 'up' (suppressing most of the noise) so the algorithm climbs steadily without excessive wobbling, but not so many that it spends all its time measuring instead of moving. This balances the quality of the 'pointer' (gradient direction) with the speed of processing each 'pointer update', leading to faster and more stable overall progress. This applies broadly because it doesn't rely on complex statistical assumptions about data distributions."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc60\ud835\udc53\ud835\udc56_ __\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2212 _\ud835\udc60\ud835\udc53\ud835\udc56_ __\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ \u2265 _\ud835\udc5b\ud835\udc62\ud835\udc5a_\ud835\udc60\ud835\udc52\ud835\udc54\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc60_ \u2217 _\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc56_ **then**\n\n**4** send ( _\ud835\udc5b\ud835\udc62\ud835\udc5a_ _ _\ud835\udc60\ud835\udc52\ud835\udc54\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc60_ - _\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc56_ ) bytes on _\ud835\udc60\ud835\udc53\ud835\udc56_ ; /* _\ud835\udc60\ud835\udc53\ud835\udc56_ has sufficient cwnd space */"}, {"role": "assistant", "content": "**Mechanism:** This mechanism performs a basic flow control check, ensuring that the amount of data to be sent does not exceed the available capacity within the current congestion window of a network connection.\n\n**Explanation:** The expression `_\ud835\udc60\ud835\udc53\ud835\udc56_ __\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2212 _\ud835\udc60\ud835\udc53\ud835\udc56_ __\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_` calculates the currently available bytes in the network's congestion window for a specific flow `sfi`. This is akin to checking how much free space is left in a fixed-size buffer. The value `_\ud835\udc5b\ud835\udc62\ud835\udc5a_\ud835\udc60\ud835\udc52\ud835\udc54\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc60_ \u2217 _\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc56_` represents the total size of the data segments we intend to send. The `if` condition acts like a gate: `if (available_buffer_space >= data_to_write)`. If the condition is true, the `send` operation proceeds to transmit the calculated number of bytes, ensuring we don't 'overflow' the network's allowed capacity, thereby preventing congestion and packet loss. It's a fundamental conditional check before a resource-consuming operation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this work, we asked a simple question: _do current spatial supersensing benchmarks and methods in fact require_\n_spatial supersensing?_ For VSI-Super and Cambrian-S, the answer is largely _no_ . We uncover behaviors that\nillustrate benchmark\u2013model co-adaptation. VSI-Super rewards bespoke inference recipes\u2014one for recall and one for\ncounting\u2014that match the dataset\u2019s generative assumptions. A model can score well by encoding rules such as \u201cthere\nare four object insertions\u201d or \u201crooms never repeat\u201d, rather than by learning capabilities that transfer when these\nassumptions change. On the other hand, the success of _NoSense_ shows the strength of contrastive vision\u2013language\nrepresentations as perception components of streaming systems. A simple SigLIP-based baseline can reproduce\nmuch of what current spatial supersensing methods achieve, with little machinery beyond pretrained vision and text\nencoders. Taken together, these findings indicate VSI-Super does not yet operationalize spatial supersensing: trivial\n\n8\n\nadmissible baselines can saturate key tasks without performing any long-horizon spatial integration. A genuine first\nstep toward supersensing requires demonstrating at least one capability that trivial retrieval-based methods cannot\nachieve. Until then, we should view performance of future methods on VSI-Super with caution for claims about\nspatial supersensing or long-horizon world modeling.\n\nGoing forward, we view _world-model evaluation_ as an important research problem, alongside world-modeling itself.\nProgress in spatial supersensing will require benchmarks that are robust to trivial transformations, explicitly require\nrevisits to previous states and long-horizon integration, along with routinely stress-testing with adversarial baselines\nand perturbations. Our analyses move in this direction by exposing the fragility of current evaluations and by\npointing to concrete, more faithful tests of video world models.\n\n**Limitations**\n\nOur analysis has two main limitations. Empirically, we study a single benchmark family (VSI-Super) and one\nprimary method (Cambrian-S). Other datasets or algorithms may behave differently, so our conclusions about\nspatial supersensing may not generalize. Conceptually, we diagnose failure modes and propose design principles, but\nwe do not introduce a validated replacement benchmark. Building such benchmarks remains an open challenge and\nwill require iterative cycles of task design, adversarial probing, and model development.\n\n**Acknowledgments**\n\nThe authors would like to thank (in no particular order): Sebastian Dziadzio, Adhiraj Ghosh, Shashwat Goel,\nMatthias K\u00a8ummerer, Thao Nguyen, and Ronald Skorobogat for helpful feedback and comments on our draft. We\nthank the authors of Cambrian-S for engaging with our work and for their constructive feedback. This work is\nfunded by the Federal Ministry of Education and Research (BMBF), FKZ: 01IS24079A. VU was supported by\na Google PhD Fellowship in Machine Intelligence. VU also thanks the European Laboratory for Learning and\nIntelligent Systems (ELLIS) PhD program for support. AH and VU thank the International Max Planck Research\nSchool for Intelligent Systems (IMPRS-IS) for support. AH acknowledges funding by the Federal Ministry of\nEducation and Research (BMBF), FKZ: 01IS24079A. AP and MB acknowledge acknowledges financial support\nby the Federal Ministry of Research, Technology and Space (BMFTR), FKZ: 16IS24085B and Open Philanthropy\nFoundation funded by the Good Ventures Foundation. This research utilized compute resources at the T\u00a8ubingen\nMachine Learning Cloud, DFG FKZ INST 37/1057-1 FUGG.\n\n**References**\n\nNishant Balepur, Rachel Rudinger, and Jordan Lee Boyd-Graber. Which of these best describes multiple choice evaluation\nwith llms? a) forced b) flawed c) fixable d) all of the above. _arXiv preprint arXiv:2502.14127_, 2025. 8\n\nLucas Beyer, Olivier J H\u00b4enaff, Alexander Kolesnikov, Xiaohua Zhai, and A\u00a8aron van den Oord. Are we done with imagenet?\n_arXiv preprint arXiv:2006.07159_, 2020. 8\n\nEllis Brown, Jihan Yang, Shusheng Yang, Rob Fergus, and Saining Xie. Benchmark designers should\u201d train on the test set\u201d\nto expose exploitable non-visual shortcuts. _arXiv preprint arXiv:2511.04655_, 2025. 2\n\nShyamal Buch, Crist\u00b4obal Eyzaguirre, Adrien Gaidon, Jiajun Wu, Li Fei-Fei, and Juan Carlos Niebles. Revisiting the\u201d video\u201d\nin video-language understanding. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_,\npages 2917\u20132927, 2022. 2\n\nNikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, and Jonas Geiping. Answer matching outperforms multiple\nchoice for language model evaluation. _arXiv preprint arXiv:2507.02856_, 2025. 8\n\nMostafa Dehghani, Yi Tay, Alexey A Gritsenko, Zhe Zhao, Neil Houlsby, Fernando Diaz, Donald Metzler, and Oriol Vinyals.\nThe benchmark lottery. _arXiv preprint arXiv:2107.07002_, 2021. 2\n\nRobert Geirhos, J\u00a8orn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A\nWichmann. Shortcut learning in deep neural networks. _Nature Machine Intelligence_, 2020. 2\n\n9\n\nAryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena,\nXuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, et al. Are we done with mmlu? In _Proceedings of_\n_the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human_\n_Language Technologies (Volume 1: Long Papers)_, pages 5069\u20135096, 2025. 8\n\nAdhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, and Matthias Bethge. Onebench\nto test them all: Sample-level benchmarking over open-ended capabilities. In _Proceedings of the 63rd Annual Meeting of_\n_the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 32445\u201332481, 2025. 8\n\nYash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the v in vqa matter: Elevating the\nrole of image understanding in visual question answering. In _Proceedings of the IEEE conference on computer vision and_\n_pattern recognition_, pages 6904\u20136913, 2017. 2\n\nKristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, Triantafyllos Afouras, Kumar Ashutosh,\nVijay Baiyya, Siddhant Bansal, Bikram Boote, Eugene Byrne, Zach Chavis, Joya Chen, Feng Cheng, Fu-Jen Chu, Sean\nCrane, Avijit Dasgupta, Jing Dong, Maria Escobar, Cristhian Forigua, Abrham Gebreselasie, Sanjay Haresh, Jing Huang,\nMd Mohaiminul Islam, Suyog Jain, Rawal Khirodkar, Devansh Kukreja, Kevin J Liang, Jia-Wei Liu, Sagnik Majumder,\nYongsen Mao, Miguel Martin, Effrosyni Mavroudi, Tushar Nagarajan, Francesco Ragusa, Santhosh Kumar Ramakrishnan,\nLuigi Seminara, Arjun Somayazulu, Yale Song, Shan Su, Zihui Xue, Edward Zhang, Jinxu Zhang, Angela Castillo, Changan\nChen, Xinzhu Fu, Ryosuke Furuta, Cristina Gonzalez, Prince Gupta, Jiabo Hu, Yifei Huang, Yiming Huang, Weslie\nKhoo, Anush Kumar, Robert Kuo, Sach Lakhavani, Miao Liu, Mi Luo, Zhengyi Luo, Brighid Meredith, Austin Miller,\nOluwatumininu Oguntola, Xiaqing Pan, Penny Peng, Shraman Pramanick, Merey Ramazanova, Fiona Ryan, Wei Shan,\nKiran Somasundaram, Chenan Song, Audrey Southerland, Masatoshi Tateno, Huiyu Wang, Yuchen Wang, Takuma Yagi,\nMingfei Yan, Xitong Yang, Zecheng Yu, Shengxin Cindy Zha, Chen Zhao, Ziwei Zhao, Zhifan Zhu, Jeff Zhuo, Pablo\nArbelaez, Gedas Bertasius, Dima Damen, Jakob Engel, Giovanni Maria Farinella, Antonino Furnari, Bernard Ghanem,\nJudy Hoffman, C.V. Jawahar, Richard Newcombe, Hyun Soo Park, James M. Rehg, Yoichi Sato, Manolis Savva, Jianbo\nShi, Mike Zheng Shou, and Michael Wray. Ego-exo4d: Understanding skilled human activity from first- and third-person\nperspectives. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages\n19383\u201319400, June 2024. 8\n\nHasan Abed Al Kader Hammoud, Ameya Prabhu, Ser-Nam Lim, Philip HS Torr, Adel Bibi, and Bernard Ghanem. Rapid\nadaptation in online continual learning: Are we evaluating it right? In _2023 IEEE/CVF International Conference on_\n_Computer Vision (ICCV)_, pages 18806\u201318815. IEEE, 2023. 2\n\nAndreas Hochlehnert, Hardik Bhatnagar, Vishaal Udandarao, Samuel Albanie, Ameya Prabhu, and Matthias Bethge. A\nsober look at progress in language model reasoning: Pitfalls and paths to reproducibility. _arXiv preprint arXiv:2504.07086_,\n2025. 8\n\nCheng-Yu Hsieh, Jieyu Zhang, Zixian Ma, Aniruddha Kembhavi, and Ranjay Krishna. Sugarcrepe: Fixing hackable\nbenchmarks for vision-language compositionality. _arXiv preprint arXiv:2306.14610_, 2023. 8\n\nJie Lei, Tamara Berg, and Mohit Bansal. Revealing single frame bias for video-and-language learning. In _Proceedings of the_\n_61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 487\u2013507, 2023. 2\n\nBo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei\nLiu, et al. Llava-onevision: Easy visual task transfer. _arXiv preprint arXiv:2408.03326_, 2024. 5\n\nYingwei Li, Yi Li, and Nuno Vasconcelos. Resound: Towards action recognition without representation bias. In _ECCV_, 2018.\n\n2\n\nDivyam Madaan, Taro Makino, Sumit Chopra, and Kyunghyun Cho. Jointly modeling inter-& intra-modality dependencies\nfor multi-modal learning. _Advances in Neural Information Processing Systems_, 37:116084\u2013116105, 2024. 8\n\nDivyam Madaan, Varshan Muhunthan, Kyunghyun Cho, and Sumit Chopra. Multi-modal data spectrum: Multi-modal\ndatasets are multi-dimensional. _arXiv preprint arXiv:2509.23499_, 2025. 8\n\nMarianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, and Jenia Jitsev. Alice in wonderland: Simple tasks showing\ncomplete reasoning breakdown in state-of-the-art large language models. _arXiv preprint arXiv:2406.02061_, 2024. 8\n\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda\nAskell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In\n_International Conference on Machine Learning (ICML)_, 2021. 3, 5\n\n10\n\nKrishna Kumar Singh, Kayvon Fatahalian, and Alexei A Efros. Krishnacam: Using a longitudinal, single-person, egocentric\ndataset for scene understanding tasks. In _2016 IEEE Winter Conference on Applications of Computer Vision (WACV)_,\npages 1\u20139. IEEE, 2016. 8\n\nEnxin Song, Wenhao Chai, Guanhong Wang, Yucheng Zhang, Haoyang Zhou, Feiyang Wu, Haozhe Chi, Xun Guo, Tian Ye,\nYanting Zhang, et al. Moviechat: From dense token to sparse memory for long video understanding. In _CVPR_, 2024. 5\n\nMatthias Tangemann, Matthias K\u00a8ummerer, Thomas SA Wallis, and Matthias Bethge. Measuring the importance of temporal\nfeatures in video saliency. In _European Conference on Computer Vision_, pages 667\u2013684. Springer, 2020. 2\n\nVishaal Udandarao, Mehdi Cherti, Shyamgopal Karthik, Jenia Jitsev, Samuel Albanie, and Matthias Bethge. A good\ncrepe needs more than just sugar: Investigating biases in compositional vision-language benchmarks. _arXiv preprint_\n_arXiv:2506.08227_, 2025. 8\n\nJihan Yang, Shusheng Yang, Anjali W Gupta, Rilyn Han, Li Fei-Fei, and Saining Xie. Thinking in space: How multimodal\nlarge language models see, remember, and recall spaces. In _Proceedings of the Computer Vision and Pattern Recognition_\n_Conference_, pages 10632\u201310643, 2025a. 6\n\nShusheng Yang, Jihan Yang, Pinzhi Huang, Ellis Brown, Zihao Yang, Yue Yu, Shengbang Tong, Zihan Zheng, Yifan Xu,\nMuhan Wang, et al. Cambrian-s: Towards spatial supersensing in video. _arXiv preprint arXiv:2511.04670_, 2025b. 2, 6, 8\n\nJian Yao, Ran Cheng, and Kay Chen Tan. Var-math: Probing true mathematical reasoning in llms via symbolic multi-instance\nbenchmarks. _arXiv preprint arXiv:2507.12885_, 2025. 8\n\nMert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, and James Zou. When and why vision-language\nmodels behave like bag-of-words models, and what to do about it? _arXiv preprint arXiv:2210.01936_, 2022. 5\n\nXiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer. Sigmoid loss for language image pre-training. In\n_Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 11975\u201311986, 2023. 3\n\nHaoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Jifeng Dai, and Xiaojie Jin. Flash-vstream: Memory-based\nreal-time understanding for long video streams. _arXiv preprint arXiv:2406.08085_, 2024. 5\n\nDaniil Zverev, Thadd\u00a8aus Wiedemer, Ameya Prabhu, Matthias Bethge, Wieland Brendel, and A Koepke. Vggsounder:\nAudio-visual evaluations for foundation models. In _Proceedings of the IEEE/CVF International Conference on Computer_\n_Vision_, pages 1027\u20131037, 2025. 8\n\n11\n\n**A** **Feedback from Cambrian-S Authors**\n\nWe aim to foster open discussion in the spirit of journals such as _Behavioral and Brain Sciences_ (BBS), which use\nan open peer commentary format for controversial work. Before releasing this work, we emailed the Cambrian-S\nauthors to share our findings. We present their response to give readers a more balanced perspective on this work:\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-11-0.png)\n\n12"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revealed is not true spatial reasoning, but 'benchmark-model co-adaptation' where models exploit dataset generative assumptions. This is analogous to a system learning specific 'if-then' rules or a lookup table based on observed patterns in the training data, rather than building a generalized, dynamic internal world representation. The 'NoSense' baseline showcases this by using simple contrastive retrieval from pre-trained embeddings.\n\n**Explanation:** The paper demonstrates that current 'spatial supersensing' benchmarks are fundamentally flawed because models don't actually learn to 'see' and track objects across long videos. Instead, the 'why' behind their success is simpler: they're exploiting predictable patterns inherent in how the benchmark data was created. Think of it like a `key-value store` or a set of `if-else` statements. If the model sees a certain setup ('key'), it's learned to output a specific answer ('value') because that's always been the correct answer in *that particular dataset*. It's not building a complex internal `graph` of spatial relationships or performing `long-horizon integration` \u2013 essentially, it's not maintaining a persistent `data structure` representing the world over time. A 'NoSense' baseline, built on readily available pre-trained vision-language encoders (which map images and text to a common `vector space`), simply performs a sophisticated form of `nearest-neighbor search` or `retrieval`. It matches queries to the closest stored patterns, achieving high scores without any deep spatial understanding. This means the perceived 'progress' is often a result of 'shortcut learning' within the benchmark's specific statistical regularities, not generalizable intelligence."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ \u2265 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_\ud835\udc4f\ud835\udc64_ \u2217 1 _._ 25 **then** /* BBR.BtlBw still growing? */\n\n**80** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc4f\ud835\udc64_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ ; /* record new baseline level */\n\n**81** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ = 0 ;"}, {"role": "assistant", "content": "**Mechanism:** This code implements a dynamic baseline update mechanism for observed bottleneck bandwidth. It prevents premature convergence to a 'full' bandwidth state by requiring a significant (25%) and sustained increase in current bottleneck bandwidth (BBR.BtlBw) over the previously established full bandwidth (BBR.full_bw) before updating the baseline.\n\n**Explanation:** Think of `BBR.full_bw` as a running maximum or 'high-water mark' for the network's perceived capacity, while `BBR.BtlBw` is the current measured capacity. The comparison `BBR.BtlBw >= BBR.full_bw * 1.25` acts as a threshold. It says, 'Don't just update the `BBR.full_bw` for tiny improvements; wait until we see a truly substantial, convincing increase (at least 25%) in the current bottleneck bandwidth.' If such an increase is observed, it indicates the previous `BBR.full_bw` was an underestimation, so `BBR.full_bw` is updated to the new, higher `BBR.BtlBw`, and an associated counter (`BBR.full_bw_count`) is reset. This allows the algorithm to continually adapt and discover higher available bandwidth if network conditions improve, rather than getting stuck at an outdated estimate. It's like finding a new maximum in a stream of data, but only if the new maximum is significantly greater than the current one."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc56\ud835\udc60_ _ _\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e_ **or** _\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ \u2264 _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ (1) ;\n\n54 D. Dimopoulos, et al.\n\n**ACK-arrival function definitions (cont. 2/4):**\n\n**71** BBR_Advance_Cycle_Phase():\n\n**72** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () ;\n\n**73** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65_ = ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65_ + 1) % _\ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52\ud835\udc3f\ud835\udc52\ud835\udc5b_ ;\n\n**74** _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ _ _\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ = [5/4 _,_ 3/4 _,_ 1 _,_ 1 _,_ 1 _,_ 1 _,_ 1 _,_ 1] ;\n\n**75** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ _ _\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ [ _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65_ ] ;\n\n**76** BBR_Check_Full_Pipe():"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a cyclical state machine that uses modulo arithmetic to index into a predefined array of pacing gain values. This creates a periodic adjustment to the data transmission rate, allowing for phases of bandwidth probing, queue draining, and steady-state maintenance.\n\n**Explanation:** This code implements a periodic control loop, essentially a cyclical state machine. The `BBR_Advance_Cycle_Phase` function increments a `cycle_index` which acts like a pointer into the `pacing_gain_cycle` array. The modulo operator ensures the index wraps around, making the sequence of gain factors repeat. Each factor, like `5/4`, `3/4`, or `1`, dictates how the data sending rate (pacing gain) is adjusted. A gain above 1 (e.g., `5/4`) temporarily increases the rate to 'probe' for more available network capacity. A gain below 1 (e.g., `3/4`) reduces the rate to 'drain' any built-up data in network queues. Gains of 1 maintain the current rate. This cyclical approach allows BBR to continuously explore and adapt to network conditions. The initial condition `prior_inflight <= BBR_Inflgitht` likely forms part of a check to determine if the network 'pipe' is full, informing BBR's state transitions and preventing overfilling."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**2.1** **Reconfigurable XDNA2\u2122Architecture**\n\nFig. 1 (left) shows the latest AMD XDNA2\u2122NPU architecture, integrated in Strix [3] and Kraken [2] Point laptops. It features an AIE\narray consisting of 32 compute cores, eight shim cores, and eight\nmemory cores. Those cores are reconfigurable blocks connected\nwith FPGA-like adaptable interconnects [1]. Each compute core\nintegrates a VLIW processor, 64 KB of local L1 memory, DMA engines, register files, and two input and two output stream channels.\nInter-core connections are reconfigurable through stream channels,\nenabling flexible communication patterns such as broadcasting\nfrom a single producer core to multiple consumer cores. Each memory core provides 512 KB of L2 memory along with six input and six\noutput stream channels. To access the flexible compute and memory\nhierarchy, toolkits such as IRON [14] provide explicit control over\ndata movement, allowing developers to configure stream interfaces\n\nChengyue Wang [1], Wesley Pang [2], Xinrui Wu [1], Gregory Jun [2], Luis Romero [3], Endri Taka [4], Diana Marculescu [4], Tony Nowatzki [1], Pranathi Vasireddy [5], Joseph Melber [5], Deming Chen [2],\nConference\u201917, July 2017, Washington, DC, USA Jason Cong [1]\n\nand data movement across cores in Python while linking C++ AIE\nkernels for programming the VLIW processor.\n\n**2.2** **Challenges of Data Movement and Tiling**\n\nArithmetic intensity measures the ratio of computation to data\nmovement and is critical for overcoming memory bottlenecks (Fig. 1,\nright) [13, 22]. For GEMM, arithmetic intensity increases with tile\nsize. Each AIE compute core provides only two input streams, typically used for operands _\ud835\udc34_ and _\ud835\udc35_, leaving no channel to bring partial\nsums back for further accumulation. Moreover, memory cores lack\naccumulator units, so partial sums cannot be stored in L2 or reloaded\nto the compute cores. As a result, each output tile of _\ud835\udc36_ must be\nfully accumulated in L1 before being written out, and the L2 output\ntile size exactly equals the aggregate of L1 tiles across the used\ncompute cores. For example, if each core computes a 64 \u00d7 64 BF16\ntile (8 KB), then 32 cores collectively produce 256 KB of output in\nL1, so the L2 output tile size is also 256 KB. The L1 output tile size\nis therefore critical: it directly determines the L2 output tile size,\nwhich directly governs the reuse of off-chip input data.\nGiven this, asymmetric tile buffering in L1 memory offers a\npromising way to increase arithmetic intensity and improve offchip data reuse. However, prior AIE studies [10, 16\u201318, 23, 24] have\nadopted only symmetric tile buffering at both L1 and L2, with the\ntiling space defined solely by the three parameters ( _\ud835\udc47\ud835\udc40_, _\ud835\udc47\ud835\udc3e_, _\ud835\udc47\ud835\udc41_ )\nat each memory level. Although simulation-based design space\nexploration studies [11, 15] have explored the idea of asymmetric\ntile buffering, they neither analyze its overheads on real hardware\nnor its impact on kernel performance. Moreover, to the best of our\nknowledge, CPU and GPU implementations also rarely adopt such\nstrategies, due to both hardware constraints and the complexity\nof managing data movement across multiple memory levels. For\nexample, widely used GEMM frameworks such as BLIS [20] and\nCUTLASS [19] also rely on symmetric tile buffering in L1 caches.\n\n**2.3** **Challenges of Kernel Design**\n\nAs shown in Fig. 1 (right), an efficient kernel design drives the bound\nof attainable performance. Inside a kernel, the fundamental unit\nof computation is the _microkernel_ : a fully unrolled inner loop that\nperforms fused multiply\u2013accumulate (MAC) operations on small\ntiles of data held in registers. Running on a 7-way VLIW processor,\nAIE microkernel performance depends on how efficiently the VMAC\ninstruction is scheduled at compile time.\nWhile most prior AIE studies [10, 16\u201318, 23, 24] focus primarily on data movement between L1, L2, and off-chip memory, they\ngenerally lack a systematic discussion of AIE microkernel optimization. Additionally, although microkernels can be optimized with\ncompiler pragmas such as chess::unroll_loop in the Chess compiler for AIE, analytical modeling of the underlying execution is\nessential to guide programmers in their effective use of pragmas.\nFurthermore, mixed precision complicates instruction pipelines\nand makes it difficult for the compiler to optimize without manual\ncode refactoring. This paper presents an analytical model to guide\nmanual kernel optimization.\nBetween kernels, additional performance challenges arise from\nexecution gaps introduced during kernel switching. These gaps\nresult from inherent overheads such as kernel initialization, pipeline\n\n![](papers/images/Can-Asymmetric-Tile-Buffering-Be-Beneficial.pdf-1-0.png)\n\n**Figure 2: Comparison of symmetric (left) and asymmetric**\n**(right) tile buffering. Asymmetric tiles (** _\ud835\udc47\ud835\udc40\ud835\udc34_ **,** _\ud835\udc47\ud835\udc40\ud835\udc36_ **,** _\ud835\udc47\ud835\udc3e_ **,** _\ud835\udc47\ud835\udc41_ **) in-**\n**crease arithmetic intensity but also switching overhead.**\n\nresets, and synchronization delays. They accumulate across the\nmany kernels invoked in a tiled GEMM, widening the difference\nbetween microkernel-level attainable performance and core-level\nattainable performance.\n\n**2.4** **BFP16 Data Type**\n\nXDNA2\u2122introduces native support for the Block Floating Point\n(BFP16) format [6], a quantized precision that balances efficiency\nand accuracy. Unlike BF16, where each value carries its own exponent, BFP16 shares one 8-bit exponent across a block of 8 values,\neach storing only an 8-bit mantissa. This packs 8 elements into\n9 bytes, represented in AIE as bfp16ebs8 [4]. Each compute core\nexecutes BFP16 on a dedicated 8 \u00d7 8 \u00d7 8 MAC unit, sustaining 512\nMACs per cycle. A VMAC instruction multiplies two 8 \u00d7 8 BFP16\nvector registers and accumulates into an 8 \u00d7 8 FP32 accumulator\nregister. At 1.8 GHz [5], this delivers 1.84 TFLOPS per core and 58.8\nTFLOPS across the whole 32-core array. However, the current best\nmixed-precision BF16-BFP16 GEMM result on an AMD Strix Point\nlaptop is only 4.8 TFLOPS [9]."}, {"role": "assistant", "content": "**Mechanism:** The XDNA2 NPU functions as a reconfigurable array of VLIW processing elements (compute cores) and dedicated memory blocks (memory cores), connected by explicit, programmable stream channels. The core challenge for operations like GEMM is a data movement bottleneck: compute cores have only two input streams, precluding feedback of partial sums for accumulation within the core, and memory cores lack accumulator units. This forces full accumulation of output tiles in L1 memory before writing to L2, leading to frequent L1-to-L2 transfers if L1 tile sizes are small. Arithmetic intensity, the ratio of computation to data movement, is paramount; larger tile sizes (especially for output) reduce traffic to slower memory levels and improve reuse.\n\n**Explanation:** Think of the NPU as a network of highly specialized mini-processors. Each compute core has a VLIW processor, like a very smart CPU that can do many different things at the exact same time (multiple instructions per clock cycle), and a small, super-fast scratchpad memory (L1). Data moves between these cores and larger memory banks (L2) using explicit channels, much like message passing between different programs. The fundamental problem is that when these mini-processors are doing a big calculation, like multiplying matrices, they get new numbers through two input pipes, but they don't have a pipe to send their 'half-finished answers' back to themselves to add more to them. Also, the bigger memory banks don't have built-in calculators. This means each mini-processor has to completely finish a small piece of the answer in its tiny scratchpad before it can send it off. If these pieces are small, they are constantly sending data to the slower, bigger memory, wasting valuable time. The paper proposes 'asymmetric tile buffering,' which is like strategically choosing different-sized memory segments for different parts of the calculation, rather than using one-size-fits-all segments. This allows the mini-processors to keep more of their work in their fast scratchpad for longer, doing more calculations per data fetch and reducing slow trips to the main memory. They also tackle how to perfectly arrange the smallest calculation steps (microkernels) for the VLIW processor and how a new compressed number format (BFP16) allows more numbers to be processed simultaneously, despite the added complexity."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThere are two lines of research aiming to tame high variance\nand improve stability in PG methods: ( _i_ ) _algorithm-centric_\nvariants that bake variance-reduction or trust-region ideas\ninto the core update, and ( _ii_ ) _wrapper-style_ frameworks that\nlayer on generic stability checks without re-engineering the\nunderlying optimizer.\n( _i_ ) **Algorithm-centric approaches.** Early variance reduction in REINFORCE introduced _baselines_, which are often a\nlearned value function, to center Monte-Carlo returns, yielding unbiased and lower-variance updates (Sutton et al. 1999).\nActor\u2013critic architectures extend this idea by bootstrapping\nvia temporal-difference learning, trading bias for further variance reduction (Konda and Tsitsiklis 1999; Sutton 1984);\nhowever, a misspecified critic step can introduce harmful\nbias (Chen, Sun, and Yin 2021; Olshevsky and Gharesifard\n2023). As an alternative approach, trust-region methods such\nas TRPO enforce a KL-constraint to guarantee monotonic policy improvement under certain regularity conditions (Schulman et al. 2015), but rely on second-order solvers, which\nare expensive. PPO replaces TRPO\u2019s conjugate-gradient and\nHessian computations with a clipped surrogate objective,\nretaining many of the stability benefits while using only firstorder updates (Schulman et al. 2017); nevertheless, it can\n\nstill exhibit overly conservative steps or exploration failures\nin complex, contact-rich tasks (Wang et al. 2019b). Beyond\non-policy methods, off-policy actor-critic algorithms like\nDDPG (Lillicrap et al. 2015) and TD3 (Fujimoto, van Hoof,\nand Meger 2018) aim for high sample efficiency via replay\nbuffers, but suffer from spiky Q-value estimates and divergent updates without careful regularization (Haarnoja et al.\n2018; Islam et al. 2017). Variants such as SAC inject entropy\nbonuses for exploration and stability (Haarnoja et al. 2018),\nyet their gains come at the cost of extra hyperparameters and\ntemperature tuning.\n( _ii_ ) **Framework-based approaches.** An orthogonal strand\nof work wraps a generic PG optimizer with lightweight\nchecks or corrections. SVRG-style control variates (e.g.,\nSVRPG) freeze a reference policy to reduce gradient variance, at the expense of extra memory and on-policy rollouts\n(Xu, Liu, and Peng 2018). Momentum injections, such as\nNesterov and heavy-ball variants, have been proposed to accelerate PG under smoothness assumptions (Xiao 2022; Chen\net al. 2024); although they sometimes amplify early spikes. In\nacceptance-based schemes, updates are only applied if a heldout performance estimate improves\u2014trace back to optimistic\nor hysteretic updates in multi-agent settings (Omidshafiei\net al. 2017; Palma et al. 2018); however, repeatedly validating a \u201dtrue\u201d return can be prohibitively costly.\nOur reward-profiling wrapper unifies and extends\nthese ideas with three simple, hyperparameter-minimal\nschemes: **Lookback** acts like a backtracking line search in\npolicy space, rejecting any update whose empirical returns\nare lower than the previous policy. **Mixup** is a convex combination of the old and new parameters to smooth the transition\nand escape rejection deadlocks. **Three-Points** evaluates an\nadditional \u201dmidpoint\u201d to choose the best of the old, new, and\nmixed policies. Requiring only _O_ ( _\u03f5_ _[\u2212]_ [2] ln( _T/\u03b4_ )) extra rollouts, it can be plugged into any PG method (DDPG, TRPO,\nPPO, etc.) without per-environment tuning. This design delivers theoretical improvement guarantees and consistent empirical gains in final performance, sample efficiency, and training\nstability. The framework can be related to line-search and\nmomentum (More, Garbow, and Hillstrom 1994; Sutskever\u00b4\net al. 2013; Muehlebach and Jordan 2021), but is designed as\na virtually zero-hyperparameter, plug-in wrapper."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around post-update validation and policy smoothing. Instead of solely relying on the gradient signal, this framework explicitly evaluates the empirical performance of proposed policy updates. 'Lookback' implements a direct performance check, akin to an 'if' statement: if a proposed new policy (\u03b8_new) yields a lower observed reward than the current policy (\u03b8_old), the update is rejected. 'Mixup' creates an intermediate policy (\u03b8_mixed) as a convex combination of \u03b8_old and \u03b8_new. This acts as a dampening mechanism, similar to a low-pass filter on policy changes, preventing abrupt shifts that might be destabilizing or lead to repeated rejections. 'Three-Points' extends this by evaluating three specific policy candidates (\u03b8_old, \u03b8_new, \u03b8_mixed) and selecting the one with the highest empirical reward. This is like performing a mini-grid search or a ternary search over a small set of relevant policy points, making the update more robust to noise and local instabilities. The mechanism ensures that each policy update, while still guided by an underlying policy gradient optimizer, is explicitly validated or smoothed based on actual observed returns, thereby taming variance by preventing or mitigating 'bad' steps.\n\n**Explanation:** Policy gradient methods often suffer from high variance in their gradient estimates, meaning the 'direction' to improve the policy can be very noisy and lead to unstable learning. Existing methods either modify the gradient calculation directly (like baselines subtracting an estimated value to reduce the spread of reward signals, or trust-region methods constraining the magnitude of policy change, acting like a maximum step-size) or use techniques like replay buffers to decorrelate samples. This new 'wrapper' approach doesn't change how the base policy gradient is calculated, but rather how its proposed update is *applied*. It's like adding a quality assurance layer after a function computes a result. 'Lookback' is essentially a `rollback` feature: if `execute_update(proposed_policy)` results in `empirical_reward < old_empirical_reward`, then `rollback_to(old_policy)`. 'Mixup' introduces a form of interpolation; it's `new_policy = (1-alpha) * old_policy + alpha * proposed_policy`, making the transition smoother and potentially helping escape plateaus where a full jump might be rejected. 'Three-Points' acts like a localized `argmax` operation after sampling: `best_policy = argmax(evaluate(old_policy), evaluate(proposed_policy), evaluate(mixed_policy))`. All these require additional 'rollouts' (simulations or data collection) to empirically evaluate the candidate policies, which are like extra calls to a `cost_function` to confirm the proposed changes. This ensures that even if the gradient is noisy, the actual policy parameters move in a demonstrably beneficial direction, improving stability and performance without deep re-engineering of the underlying learning algorithm itself."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nTo contextualize the behavioral presence observed above in Section 3.3.1, we examine how contemporary LLM\nresearch conceptualizes \"reasoning\" as a design choice. With growing interest in the development and analysis\nof models with \"diverse and strong reasoning\" abilities, we aimed to understand what cognitive elements are\ncurrently supported and which remain underexplored. For this analysis, we scraped arXiv [3] papers using\nkeyword-based queries applied to titles and abstracts. We searched using general reasoning-related keywords\n(e.g., \"large language model reasoning,\" \"LLM cognitive behaviors,\" \"LLM thinking\") and for each capability\nin our taxonomy we added an additional query of the form \"large language model _<capability>_ \", retrieving\nthe top ten papers for each general query (in order to maximize precision) and 100 papers for each behaviorspecific query.\n\nWe then annotated this set of papers using both two human annotators and GPT-4.1 (all three achieve\nmoderate agreement _ICC_ 3 _k_ = 0 _._ 593; we iteratively improve annotation prompts based on human feedback).\nFor each paper\u2013capability pair, we record whether a behavior is _explicitly targeted_ (via evaluation objectives\nor architecture), _implicitly encouraged_ (dataset structure, demonstration style), or _not incorporated_ .\n\nResults from this analysis displayed in Figure 2 reveal substantial imbalance in the types of reasoning\nbehaviors emphasized across LLM reasoning research. The dominant cognitive elements (context awareness:\n70% of papers, decomposition and integration: 60%, knowledge structure alignment: 56%) align with linear\nprocedural step-by-step reasoning that is straightforward to evaluate. Sequential organization (54%), pattern\nrecognition (51%), and abstraction (46%) similarly emphasize forward-moving compositional patterns. In\ncontrast, behaviors enabling flexible problem-solving receive far less attention: self-awareness appears in only\n16% of papers, spatial organization in 10%, and temporal organization in 22%.\n\nComparing paper-level design intentions to observed model behaviors reveals three key discrepancies. First,\n**design-behavior gaps** : Compositionality appears in 38% of papers yet shows inconsistent presence in reasoning traces. Context alignment and knowledge structure alignment are frequently targeted (47% and 56%)\nbut models struggle to maintain these consistently across problem types. Second, **emergent but under-**\n**theorized behaviors** : Profundity appears in only 16% of papers but manifests consistently in model outputs, suggesting models develop meta-cognitive patterns not explicitly designed for. Third, **systematically**\n**neglected capabilities** : Self-awareness (16%), temporal organization (22%), ordinal organization (27%),\nand spatial organization (10%) represent sophisticated cognitive structures essential for non-linear thinking,\nmental simulation, and metacognitive monitoring. These capabilities receive minimal research attention and\nfail to emerge spontaneously in model behavior.\n\nThis synthesis reveals a critical bottleneck. Current LLM reasoning research operates within a narrow\nconceptual vocabulary privileging linear, compositional behaviors amenable to straightforward evaluation.\n\n3https://arxiv.org/\n\n21\n\nExpanding theoretical foundations beyond step-by-step decomposition toward richer cognitive taxonomies\nmay be essential for developing more sophisticated reasoning capabilities."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism being analyzed is the discrepancy between designed-for cognitive capabilities in large language models (LLMs) and their actual, observed performance, revealing inherent biases in current AI development towards linear, sequential processing.\n\n**Explanation:** Think of an LLM as a complex software system designed with specific 'cognitive' functions. Researchers primarily build and evaluate functions that are like simple `for` loops or sequential processing pipelines (e.g., context handling, step-by-step decomposition). These are easy to implement and test because you can trace each input and output, much like debugging a function's return value. However, the system consistently struggles with or entirely lacks capabilities that require more complex state management, non-linear relationships, or self-referential logic. For instance, 'self-awareness' is like a program having a robust internal object representing its own state, or 'spatial organization' being a complex data structure like a graph or quadtree for understanding relationships between entities. When researchers *do* try to implement these complex features, the system's behavior is often unreliable, like a function that works for one set of inputs but fails for another, indicating a lack of robust generalization or brittle internal logic. Some advanced behaviors might 'emerge' unexpectedly, like a useful side-effect in a complex codebase, but without explicit design, they remain untamed. This implies that the fundamental 'API' or 'SDK' used for building current LLMs is inherently limited, preventing the creation of truly flexible, intelligent problem-solving systems."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Pure Integer Pretraining of an RNN Language Model**\n\nTo demonstrate the potential of EGGROLL as a general optimization method, we study whether EGGROLL\ncould be used for language model pretraining. Since EGGROLL does not rely on gradients, we can explicitly\ndesign a language model architecture to be efficient and hardware-friendly at inference time. In particular, we\nbuild a model under the following constraints to emphasize the flexibility of EGGROLL:\n\n1. **Pure Integer Training:** On H100 systems, int8 is the fastest datatype, with int8 matrix multiplication\nwith int32 accumulation being the fastest tensor core operation. Furthermore, integer datatypes are\nmuch simpler to implement in hardware, providing massive energy savings for high-throughput\nsystems (Horowitz, 2014). Therefore, we keep all weights in int8 and all activations in integer\nformats, _never_ casting to floating point at any point during training.\n\n2. **Nonlinear RNN:** Modern language models use sequence-parallel architectures like Transformers and\nSSMs, since they enable stable gradients without backpropagation through time. However, most of\nthese sequence-parallel architectures are unable to handle simple state tracking (Merrill et al., 2024),\nwhereas classic recurrent networks like LSTMs and GRUs can handle these problems with a single\nlayer. Since EGGROLL does not require backpropagation through time, we can train on unbounded\nsequence lengths (Li et al., 2023a) with nonlinear RNNs of broader complexity classes. Specifically,\nwe develop a variant of the minGRU model (Heck & Salem, 2017) that performs all operations in\ninteger formats.\n\n3. **Removal of all Activation Functions:** Inspired by Foerster (2017), we remove all activation\nfunctions, like the rectified linear unit and hyperbolic tangent, due to the nonlinearity present in the\nint8 datatype. Specifically, the saturated addition of int8 values provides sufficient nonlinearity due to\nthe implicit clipping of values to the int8 dynamic range, which evolution strategies can exploit.\n\nWe call the resulting language model EGG, the **E** volved **G** enerative **G** RU, an EGGROLL-friendly architecture.\nIts architecture is similar to standard pre-layernorm transformer decoder models, but we (1) use a variant of L1\nnormalization instead of L2 normalization for our layernorm to avoid square roots, (2) replace self-attention\nwith our custom GRU, and (3) perform all operations in integer datatypes. See Appendix C for more details on\nthe architecture.\n\nWe train an EGG model with 6 layers and hidden dimension 256 to do character-level prediction on the\nminipile dataset (Kaddour, 2023). We update parameters after 100 tokens for each population member,\napplying truncated ES by keeping the hidden state and only resetting at document boundaries. We plot the\ntest loss in Fig. 2b over training steps across a range of population sizes, where the best test loss is 3.41\nbits/byte. We find that training is stable and loss curves are relatively smooth, especially with large population\nsizes, avoiding loss spikes, nan values, and other instabilities associated with backprop-based training at low\nprecision datatypes.\n\nNote that our largest population size is 2 [18] = 262144, which is two orders of magnitude larger than the largest\nexperiment done by Salimans et al. (2017) while only requiring a single GPU to train. We see that multiplying\nthe population size by 8 results in the loss dropping by approximately 0.4 over the range of population values\nwe have tested, though this pattern will eventually break since the loss must be strictly positive. We conduct\nmore ablations in Appendix E, determining how data efficient training can be achieved with EGGROLL and\nvalidating the importance of large batch sizes.\n\n**6.2** **Reinforcement Learning Tasks**\n\nIn these experiments, we compare the performance of EGGROLL against standard OpenES as implemented in\nSalimans et al. (2017) on reinforcement learning tasks. Given the small network sizes, we can use Open ES at\nthis scale, but we note that as network sizes increase, the use of vanilla OpenES becomes impossible. We use\nthe standard formulation of simply optimizing for the final return in the environment. For both EGGROLL\nand OpenES, we perform hyperparameter optimization (HPO) separately for each environment. For each\nalgorithm\u2013environment pair, we define plausible ranges for all key hyperparameters based on prior work and\npreliminary experiments. We then perform 20 random search trials, where each trial corresponds to a single\n\n9\n\nPendulum-v1\n\n1.0\n\n0.5\n\n0.0\n\n1.0\n\n0.5\n\n0.0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-0.png)\n\n0 2 4\nSteps 1e8\n\nJumanji 2048\n\n0 2 4\nSteps 1e8\n\nCraftax Symbolic\n\n0 2 4\nSteps 1e8\n\nNavix DoorKey (8x8)\n\n0 2 4\nSteps 1e8\n\nBrax Inverted Double Pendulum\n\n1.0\n\n0.5\n\n0.0\n\n0 2 4\nSteps 1e8\n\nKinetix Thrust Control Left (m)\n\n1.5\n\n1.0\n\n0.5\n\n0.0\n\n0 2 4\nSteps 1e8\n\n1.0\n\n0.5\n\n0.0\n\n1.0\n\n0.5\n\n0.0\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-1.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-2.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-3.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-4.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-9-5.png)\n\nFigure 4: Comparison of reinforcement learning Mean returns normalized by PPO performance for 10 seeds. The returns\nare evaluated using the mean of the parameters. HPO was conducted for each algorithm/environment pair. The shaded\nregion is the standard error of the mean .\n\ntraining run with a randomly sampled hyperparameter configuration. Each configuration is evaluated based on\nthe final return achieved by the mean policy parameters at the end of training. After all trials, we select the\nconfiguration that yields the highest final return. Using this best configuration, we then run 10 independent\nseeds to evaluate performance and report the mean and standard error of the mean across these seeds.\n\nWe use policy networks with 3 layers of 256 neurons and a range of environments that demonstrate different\ncapabilities. We evaluate across the Navix (Pignatelli et al., 2024), Craftax (Matthews et al., 2024), Brax\n(Freeman et al., 2021), Kinetix (Matthews et al., 2025), and Jumanji (Bonnet et al., 2024) suites of environments.\nWe evaluate 16 environments in total. To pick environments, we choose environments that are not trivial or\nimpossible for PPO to solve, according to the original papers. We also choose environments that are part of\ndifferent categories when these are available (e.g. environment size in Kinetix or categories in Jumanji).\n\nWe show a subsample of the environments that were evaluated in Fig. 4. The remaining environment results\nare in Appendix G.1. Our findings show that EGGROLL is competitive with Open ES on 7/16 environments,\nunderperforms on 2/16, and outperforms on 7/16. This does not take into account the speed-ups when\ncompared to using OpenES (full-rank updates). We postulate that the reason for this performance increase is\nthat the large networks are difficult to optimize for Open ES and lend themselves well to low rank updates. All\nhyperparameter configuration details are available in Appendix G.1.\n\n**6.3** **LLM Fine-tuning for Reasoning Tasks**\n\nWe apply EGGROLL for LLM finetuning of RWKV-7 (Peng et al., 2025) models in two reasoning tasks:\ncountdown and GSM8K. The RWKV architecture is a recurrent model that, compared to transformers, is\nespecially suited to parallelization due to the fact that any memory otherwise spent on the KV cache can be\nused to evaluate population members. The training curves of EGGROLL and GRPO in countdown are shown\nin figure 5a. EGGROLL fine-tuning on an RWKV-7 1.5B model converges to a higher validation accuracy\nof 35% (v.s. 23%) under the same hardware and wall-clock time in the countdown task. Similarly, figure 5b\n\n10\n\nGSM8K \u2014 RWKV 7g7B\n\n0 2 4 6 8 10\n\nRelative wall-clock time (hours)\n\nGRPO (n=3) EGGROLL (n=3)\n\n(b)\n\n0.3\n\n0.2\n\n0.1\n\n0.0\n\nCountdown \u2014 RWKV 7g1.5B\n\n0 1 2 3 4 5 6 7 8\n\nRelative wall-clock time (hours)\n\nGRPO (n=3) EGGROLL (n=3)\n\n(a)\n\n0.80\n\n0.75\n\n0.70\n\n0.65\n\n0.60\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-10-0.png)\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-10-1.png)\n\nFigure 5: Comparison of the validation score of 3 seeds of EGGROLL v.s. 3 seeds of GRPO in: (a) Countdown task with\nan RWKV 7g1.5B model on a single GPU. EGGROLL allows 1024 parallel generations per GPU whereas GRPO only 32.\n(b) GSM8K task with an RWKV 7g7B model on 8 GPUs. EGGROLL allows 8096 parallel genrations (1024 per GPU)\nwhereas GRPO only 256 (32 per GPU).\n\nshows that EGGROLL outperforms GRPO on GSM8K fine-tuning. Our scoring function draws parallels to the\ngroup relative advantage of GRPO. In particular, to score a set of noise directions, _E \u2261{E_ 1 _, . . ., En}_, we first\ncompute their accuracies, _{s_ 1 _,qi, . . ., sn,qi}_, on _|q|_ = _m_ questions, creating a matrix of scores _S \u2208_ R _[m][\u00d7][n]_ .\nWe then compute the _z_ score per question, with the main difference that we use the global variance \u00af _\u03c3_, and\naverage over all the questions to compute the final score for the noise direction _Ei_ :\n\n_m_\n\n\u00af\n_si_ = [1]\n\n_m_\n\n_m_\n\ufffd\n\n\ufffd _zi,qj_ = _m_ [1]\n\n_j_ =1\n\n_m_\n\ufffd\n\n_j_ =1\n\n_si,j \u2212_ _\u00b5qj_\n\n_\u03c3_ \u00af _._\n\nThis scoring function has the purpose of weighting all questions within the same batch the same across\npopulation members."}, {"role": "assistant", "content": "**Mechanism:** EGGROLL uses an evolutionary strategy (ES), which means it optimizes by perturbing parameters, evaluating performance, and updating based on which perturbations yield better results, rather than relying on exact gradient calculations. This frees it from constraints typically imposed by backpropagation, such as the need for floating-point operations or stable gradients over long sequences.\n\n**Explanation:** The core mechanism revolves around three design choices. First, 'Pure Integer Training' isn't just a simplification; it exploits the fact that current hardware (like H100's Tensor Cores) performs int8 matrix multiplication with int32 accumulation *faster* and with *less energy* than floating-point operations. It's like writing code that uses `byte` or `int` types where possible instead of `float` for maximum CPU efficiency. Second, by not relying on backpropagation through time, EGGROLL can effectively train recurrent networks (like a custom GRU) on 'unbounded' sequence lengths, avoiding the instability and computational graph truncation issues that push gradient-based models towards sequence-parallel architectures. This allows it to maintain 'state' over much longer inputs. Third, 'Removal of all Activation Functions' is clever: the inherent saturation and clipping that occur when adding int8 values (e.g., 100 + 50 will clip at 127 for int8) provides *implicit nonlinearity*. Evolution strategies are robust enough to exploit this native hardware behavior, making explicit activation functions (like ReLU) redundant and saving computational cycles. For reinforcement learning and LLM fine-tuning, EGGROLL's strength lies in its scalability for larger networks, likely due to low-rank updates in its ES formulation, which makes it more efficient than full-rank ES methods like vanilla OpenES for high-dimensional parameter spaces. The LLM scoring function effectively normalizes question scores using a global variance, ensuring all questions contribute equally to the overall fitness evaluation for a given population member, similar to how one might normalize a dataset before training to prevent features with larger scales from dominating."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nVideo understanding benchmarks should test whether models build coherent, predictive world models from long video\nstreams. This requires accumulating visual evidence, maintaining state, and tracking entities over time\u2014abilities\nthat humans use naturally but current models largely lack. In practice, many benchmarks do not meet this goal.\nPrior work shows that models can often ignore most of the temporal structure in the video, rely on a single frame,\nor even use text-only inputs and still match or surpass state-of-the-art _video_ models (Yang et al., 2025b; Tangemann\net al., 2020; Buch et al., 2022; Lei et al., 2023; Li et al., 2018; Goyal et al., 2017; Brown et al., 2025). Much of what\nwe call _video understanding_ reduces to image captioning or language modeling with minimal temporal reasoning.\n\nThis is known as shortcut learning (Geirhos et al., 2020). Benchmark designers aim for tasks that are hard to solve\nvia shortcuts, so that the easiest way to improve performance is to develop the intended capability (Brown et al.,\n2025). When this fails, the design can unintentionally nudge practitioners into baking those same shortcuts into\ntheir models (Hammoud et al., 2023; Dehghani et al., 2021). Large models often similarly exploit spurious cues\ninstead (Geirhos et al., 2020). A recent work, Cambrian-S (Yang et al., 2025b) proposes to address these issues.\n\nCambrian-S argues that benchmarks should target specific capabilities: streaming event cognition, implicit 3D\nreasoning, and _spatial supersensing_ i.e., whether models form predictive world models from raw video. To resist\nbrute-force context expansion, Cambrian-S introduces the VSI-Super benchmarks which need true spatial reasoning\nabilities. The tasks use long, multi-environment videos and questions designed to require accumulating evidence,\ntracking objects, and maintaining state over time. The promise is clear: strong performance on these benchmarks\nshould require genuine spatial cognition and memory. This motivates our central questions about VSI-Super:\n\n1. Does success on _VSI-Super-Recall_ (VSR) truly require supersensing or even spatial cognition, or can a simple\nSigLIP model which discards almost all temporal structure still perfectly solve the benchmark?\n\n2. Does the Cambrian-S inference method perform the intended event-level reasoning and spatial supersensing, or\ndoes it rely on shortcuts specific to the benchmark like _VSI-Super-Counting_ (VSC)?\n\nTo investigate these questions, we conduct two complementary analyses:\n\n1. **VSR: A Simple Baseline.** We take SigLIP-2, select the four frames most relevant to the object mentioned\nin the question, and select the most correlated answer option. We call the resulting baseline _NoSense_, short\nfor _No Supersensing_ . NoSense uses no explicit 3D representation, does not track objects, and does not use\nlanguage models. Despite this simplicity, NoSense nearly perfectly solves VSR, even on 4-hour videos, while\ndiscarding almost all temporal structure in the video. This suggests that VSI-Super-Recall, like many prior video\nbenchmarks, primarily measures image-level semantic cues and object\u2013context associations rather than spatial\nsupersensing, and only needs a few informative frames rather than long-range temporal understanding.\n\n2. **VSC: A Sanity Check.** Does the inference method of Cambrian-S, designed for each benchmark, simply\nexploit shortcuts in the benchmark? We evaluate this by creating _VSC-Repeat_ : We take each video clip in\nthe VSC benchmark and concatenate it with itself 1-5 times, creating a sequence in which every room and\nobject is revisited repeatedly. A model performing genuine supersensing should recognize that these are repeated\nobservations of the same scene; therefore, the predicted object counts should remain unchanged. However,\nrepeating the video a few times reduces the mean relative accuracy of Cambrian-S from 42% to 0%. This indicates\nthe inference algorithm inadvertently exploits the benchmark shortcuts rather than improving supersensing.\n\nOur findings do not imply that there has been no progress in improving spatial supersensing. Gemini 2.5 Flash\nachieves around 41.5% accuracy on 60-minute VSR videos, illustrating that substantial VSR performance can arise\nfrom generic long-context video training. While VSI-Super is a comprehensive, thoughtful effort, it still fails to\n\n                                                       reliably enforce the long-horizon spatial supersensing it aims to elicit. Cambrian S\u2019 VSR inference pipeline and\n_NoSense_ share a similar high-level pattern \u2013 streaming frame encoding, a compact memory of salient frames, and\nquery-guided retrieval \u2013 suggesting that a much simpler instantiation of this pattern already goes a long way on\nVSR. Our simple sanity check, _VSC-Repeat_ shows the degree to which VSC-tailored inference algorithms rely on\nshortcuts. Our two-fold analysis underscores the need for caution when interpreting performance on VSI-Super:\nrather than reflecting genuine spatial cognition, high scores may simply mean exploiting heuristic shortcuts. We\nfurther include a response from the authors (in Appendix A) to provide a balanced perspective alongside our claims.\n\n2\n\nOverall, our tools \u2013 _NoSense_ for VSR and _VSC-Repeat_ for VSC \u2013 act as simple stress tests for benchmarks and\ntraining methods. We view this kind of meta-evaluation as analogous to ablation studies for models and believe\nit should be standard for benchmarks. For any proposed spatial supersensing task, we should ask: what is the\nsimplest streaming baseline that exploits obvious regularities? Which invariances should hold, and do methods\nrespect them? We hope our analysis fosters more rigorous testing and design of superspatial sensing in the future."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism being exploited by existing models is that many video understanding tasks don't *strictly require* maintaining a coherent, evolving internal representation (a \"world model\") of the video's content over long durations. Instead, they can often be solved by treating the video as a collection of independent still images or short clips, or even by extracting cues from associated text. The 'NoSense' baseline works by reducing a complex temporal integration problem to a few relevant static frames, effectively performing a nearest-neighbor search on visual features rather than continuous state tracking. The 'VSC-Repeat' test exposes shortcuts by verifying if models maintain unique entity identities or merely count repeated observations, akin to checking if a hash map correctly handles unique keys versus a simple loop incrementing a counter for every input.\n\n**Explanation:** Imagine a video as a long list of pictures, like an array of frames. True video understanding requires processing this array sequentially, building a 'state' that tracks objects and events as they change across frames, much like a program maintaining variables to represent the current state of a game. This involves accumulating evidence and updating an internal model. However, many benchmarks allow models to 'cheat'. The 'NoSense' baseline demonstrates this: instead of building a continuous internal state, it's like a function that takes a query and quickly scans the entire array of frames, picks out the four frames that are 'most similar' to what the query asks about (a kind of nearest-neighbor search or cosine similarity on visual features). Then, it makes a decision *only* based on these few selected frames, effectively ignoring the order or anything that happened in between. This is akin to solving a puzzle by only looking at a few key pieces, rather than assembling the whole picture. It reduces a sequential processing problem to a set-based retrieval problem. The 'VSC-Repeat' experiment tests whether the model genuinely *tracks unique entities* or simply *counts observations*. If you have a list of items and you want to count how many *unique* items there are, you'd put them in a `Set` or use a `HashMap` to store them and check for duplicates. If you just iterate through the list and increment a counter every time you see an item, you'll count duplicates. VSC-Repeat shows that the tested Cambrian-S model behaves like the simple counter: when a video segment is repeated (meaning the *same* entities and events reappear), the model counts them again as if they were new, rather than recognizing them as repetitions of previously observed entities. This reveals that the model isn't maintaining a persistent, unique identity for objects or recognizing repeated events within its internal state over time; it's simply reacting to local, immediate observations, much like a simple `for` loop incrementing a variable without a uniqueness check."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51,\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ ) ;\n\n**181** BBR_Restore_Cwnd():\n\n**182** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51, \ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ ) ;\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 57\n\n**Algorithm 13:** Coupled Multipath BBR (C-MPBBR) - [theoretical part in 2.3.7]\n\n**Fulfilling Goal 1 (MPTCP incentive):**\n\n**1** _\ud835\udefd_ = 40, _\ud835\udc47\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc37\ud835\udc52\ud835\udc59_ _ _\ud835\udc45\ud835\udc61_ = 0 ;\n\n**2** _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ = 999999999 ;\n\n**3** _\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ = 0 ;\n\n**4** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ = 0 ;"}, {"role": "assistant", "content": "**Mechanism:** The 'BBR_Restore_Cwnd()' function acts as a 'floor' or lower bound enforcer for the congestion window (`cwnd`). It leverages a `max` operation, ensuring that the current `cwnd` is never less than a previously recorded stable or high-water mark value (`BBR.prior_cwnd`). This mechanism is critical for BBR's state transitions, especially after a `PROBE_RTT` phase where `cwnd` might be temporarily reduced to measure Round Trip Time, allowing it to quickly revert to an effective sending rate. The algorithm initialization sets up standard counters and extremum finding variables. `lowest_bw_among_all_SFs` is initialized to a very high value and `highest_bw_among_all_SFs` to zero, which is a common programming pattern for finding true minimum and maximum values during subsequent iterations over a collection (subflows in this case). `Total_Del_Rt` and `total_number_of_SFs` are simple accumulators.\n\n**Explanation:** The `BBR_Restore_Cwnd()` line is essentially a `Math.max(current_value, historical_best_value)`. This prevents the congestion window from collapsing too much during transient phases, maintaining good throughput by ensuring it always operates at a known effective level or better. It's like having a 'memory' for the best recent throughput capacity. For the C-MPBBR algorithm, the initial variable setups are classic programming constructs: `beta` is a fixed constant parameter, `Total_Del_Rt` is an integer accumulator that will sum values from multiple sources, and `lowest_bw`/`highest_bw` are initialized to their respective 'identity' values (maximum possible for min, minimum possible for max) so that any actual bandwidth reading will correctly initialize these tracking variables. `total_number_of_SFs` is a simple counter for the number of active subflows, which will be incremented as subflows are detected or created."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nAI-enabled automotive perception systems (AIePS) are central to\nautomated driving, supporting object detection, tracking, and classification for enhanced safety and efficiency [1]. These systems\nunderpin advanced driver assistance systems (ADAS), which enhance driving safety, cost efficiency, and convenience [16, 20]. Core\nperception capabilities such as _pedestrian detection_, _traffic sign recog-_\n_nition_, and _obstacle avoidance_ serve as essential inputs to ADAS\nfunctions by interpreting sensor data from cameras, radar, LiDAR,\nand ultrasonics [6, 15, 33]. Within the AIePS development lifecycle, data annotation, the process of labelling raw sensor data and\nconverting it into structured datasets, remains one of the most expensive and error-prone tasks. Ultimately, the performance of these\nsystems depends on the quality of annotated data used for training\nand validation [15, 23].\n\n**Motivation.** While annotation quality is widely recognised as\ncritical for AIePS, the systematic impact of data annotation errors on system performance remains insufficiently understood. In\nsafety-critical domains such as autonomous driving, even minor\nannotation errors such as missed or inconsistently labelled objects\ncan cascade into unsafe behaviours and degraded model reliability [7, 12, 40, 41]. However, how such errors originate, propagate\nacross the AIePS development lifecycle, and ultimately impact system performance remains underexplored. [10, 22, 31]. This gap is\namplified in multi-organisational automotive supply chains, where\nheterogeneous tools, inconsistent annotation practices, and fragmented quality assurance processes increase error propagation.\nAddressing this issue is essential to shift from reactive correction\ntoward proactive, standardised, and trustworthy annotation processes [11].\n\n**Research Gap.** Prior work has focused on isolated error types\nor technical solutions such as weak supervision and automated\n\n1\n\n,, Saeeda et al.\n\nlabelling [25, 26, 32]. Crucially, there are no comprehensive, empirically grounded studies that systematically capture the full spectrum\nof annotation errors across multi-organisational automotive supply\nchain contexts. In this domain, different tiers produce annotated\ndatasets, develop AIePS, test them, and deliver integrated products\nto original equipment manufacturers (OEMs). The lack of an industry validated, comprehensive knowledge base (e.g a detailed\ntaxonomy) of annotation errors hinders alignment of processes,\nknowledge sharing, and quality assurance across organisational\nboundaries.\n\n**Study Aim.** Annotation quality is not merely a data issue but\nan AIePS developemnt lifecycle concern, as errors propagate from\nannotated data through the AI model to final system decisions.\nAccordingly, this study aims to provide insights and evaluations of\nthe data annotation errors to support proactive, lifecycle-oriented\nquality assurance. This study provides a taxonomy of data annotation errors and a classification of their root causes and impacts.\nThis study also provides insights into how companies can use this\ninformation to their advantage after validating the usefulness of\nthe proposed taxonomy with industrial practitioners.\n\n**Research Questions.** Guided by these objectives, this multiorganisational case study investigates:\n\n   - **RQ1:** What are the different types of data annotation errors,\ntheir causes, and how do they affect AIePS development\nand performance?\n\n   - **RQ2:** How do practitioners perceive the usefulness of the\nproposed taxonomy of data annotation errors?\n\n**Methodology Overview.** We conducted 19 semi-structured interviews with 20 participants from six international companies and\nfour research institutes. Using multi-level triangulation, integrating\ncase study data, thematic analysis, and expert validation, the study\nensures both empirical depth and practical relevance.\n\n**Novelty.** Our study is novel in (a) it presents the first systematic\nmulti-organisational empirical study in the automotive domain covering the full supply chain, (b) it introduces an industry validated\ntaxonomy of data annotation errors with practical relevance, and (c)\nit bridges data quality assurance (QA) with SE4AI practice by framing annotation errors as AIePS development lifecycle bottlenecks\nrather than isolated data issues."}, {"role": "assistant", "content": "**Mechanism:** At its core, an AI perception system learns by finding patterns and making connections between what it 'sees' (raw sensor data, like pixels from a camera) and what it's 'told' it's seeing (the human-made labels, or annotations). Imagine it like a massive \"if-then\" rule generator. If it sees this pattern of pixels, *then* it should identify a \"pedestrian\" in this specific area. Data annotation is the process of explicitly defining these \"if-then\" examples. Each annotation provides the 'answer key' for a specific piece of sensor data. An error in annotation means the answer key itself is wrong. If the system is given incorrect 'answers' during its training phase (like a student learning from a textbook with typos), its internal parameters (which are like millions of tiny dials and switches) get tuned to accept these incorrect answers as truth.\n\n**Explanation:** When an annotation error occurs\u2014for instance, a pedestrian is present but not labeled, or a car is incorrectly labeled as a truck\u2014it's like introducing bad data into a database. The AI model, functioning like a sophisticated pattern-matching algorithm, attempts to form a statistical model that fits all the input data and its corresponding labels. If the labels are inconsistent or wrong, the model's internal representation of the world becomes skewed. For example, if many pedestrians are consistently missed in annotations, the model will learn to *not* prioritize pedestrian detection, effectively setting its internal thresholds to ignore features that correspond to pedestrians. In a multi-organizational setting, different annotation teams might use slightly different \"schema\" or \"rules\" for labeling, leading to data that appears consistent to one team but is inconsistent when merged, much like trying to combine data from two separate applications that use different definitions for the same field. This study aims to build a systematic classification (like a nested dictionary or enumeration) of these data 'bugs' and their origins, allowing engineers to prevent these incorrect 'answer keys' from being generated in the first place, thus ensuring the AI system learns the correct 'if-then' rules and makes reliable decisions."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe task of _Dataset Distillation_ involves the synthesis of a small set of synthetic samples such that a\nmodel trained _from scratch_ on this synthetic set will achieve test-time performance comparable to\nthat of a model trained on the full real dataset. Since this problem\u2019s first introduction and proposed\nsolution in the self-titled paper [47], many new methods [6, 27, 51, 54\u201356] and extensions thereof [7,\n11, 16, 25, 28, 40, 46, 53] have made strides towards the lofty goal of learning a high-quality model\nfrom just a handful of synthetic images.\n\nMeanwhile, computer vision has increasingly adopted a paradigm of using the representations of large,\npre-trained self-supervised vision models for downstream tasks, either via fine-tuning or by using these\nmodels as feature extraction backbones. Given this trend, in this work, we explore dataset distillation\nin the regime of training models _on top of_ features extracted by pre-trained vision foundation models.\nSpecifically, we study **linear classification** on top of a **pre-trained feature representation** .\n\nIn our new method, _Linear Gradient Matching_, we distill synthetic datasets by optimizing such\nthat their representations extracted by pre-trained feature extractors induce _gradients_ in a linear\nclassifier similar to those obtained from real images. We find that a single synthetic image per class\nsuffices to train linear classifiers to competitive performance across a wide variety of large vision\n\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-0.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-1.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-2.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-3.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-4.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-5.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-6.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-17.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-18.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-19.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-20.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-21.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-22.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-23.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-24.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-33.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-34.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-35.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-36.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-37.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-38.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-39.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-40.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-51.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-52.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-53.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-54.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-55.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-56.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-57.png)\n\nFigure 1: **ImageNet-1k Distilled for Self-Supervised Models:** Using our method of _Linear Gradient Matching_,\nwe distill vision datasets to just one synthetic image per class using different pre-trained self-supervised backbone\nmodels. These learned images can then be used to train linear probes that achieve high accuracy on unseen test\ndata, outperforming all real-image baselines. Furthermore, each backbone model seems to yield its own \u201cstyle\u201d of\ndistilled image, giving insights into the aspects on which these models tend to focus (structure, texture, color, etc.).\n\nmodel backbones, outperforming all real-image baselines. Figure 1 shows samples distilled from\nImageNet-1k [12] with our method using various self-supervised feature extractors.\n\nMotivated by recent hypotheses that different large models converge to similar representations\neven when trained on different modalities [20], we investigate whether distilled datasets transfer\n_across architectures_ . We find that a gradient matching objective alone leads to images that are\noverfit to a particular model architecture and do not yield competitive performance across foundation models. However, we overcome this issue through differentiable augmentations and a simple\nre-parameterization of images via a multi-scale pyramid. Compared to those retrieved via na\u00efve\npixel optimization, the resulting distilled images not only look remarkably realistic but also readily\ntransfer across foundation models, such that a dataset distilled using, for example, a DINO backbone\nyields competitive performance when used to train a linear classifier on top of a different model\u2019s\nrepresentation, such as CLIP\u2019s.\n\nWe also observe that our distilled datasets offer several interesting interpretability results, including\npredicting alignment between different models, explaining susceptibility (or robustness) to spurious\ncorrelations in adversarial datasets, and highlighting out-of-distribution capabilities.\n\nExtensive experiments and ablations validate our _Linear Gradient Matching_ method\u2019s effectiveness\non this new dataset distillation task and highlight its potential as an interpretability tool."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is to synthesize a minimal set of data points such that a linear classifier, when trained on their pre-extracted features, generates parameter updates (gradients) that closely mimic those produced by the full, real dataset. This is achieved by directly optimizing the pixels (or a higher-level representation) of the synthetic images. When an image goes through a pre-trained feature extractor, it yields a high-dimensional vector. For a linear classifier, training involves adjusting weights based on the difference between predicted and actual labels, guided by these feature vectors. The 'Linear Gradient Matching' method iteratively adjusts the synthetic images until their corresponding feature vectors, when fed to a hypothetical linear classifier, would induce gradients that align with the aggregated gradients from the real dataset. This essentially distills the 'information for learning' contained in the real data's gradient landscape into the synthetic data. Transferability across different pre-trained models is enhanced by using differentiable augmentations and multi-scale image representations during optimization, making the synthetic images robust to variations in feature extraction.\n\n**Explanation:** Modern computer vision often starts with a 'feature extractor' - a large, pre-trained model that acts like a sophisticated `function` transforming raw pixel data into a structured `array` of numbers, capturing essential visual characteristics. Instead of training a model from scratch on raw pixels, we train a simple 'linear classifier' (think of it as a set of weighted `if-else` rules) on these extracted feature arrays. This paper's innovation lies in creating a tiny synthetic dataset (e.g., one image per class) that, when passed through the same feature extractor, produces features that would guide a linear classifier's `weight_update` routine (its gradient calculation) to similar `delta` values as if it had processed the entire real dataset. It's like finding a minimal set of `key-value` pairs that, when run through a `processing_pipeline`, produce an identical `log_file` of parameter changes as a much larger set. The 'gradients' here are the direction and magnitude of changes needed for the classifier's internal `variables` (weights). By matching these `update_vectors`, the synthetic data effectively teaches the classifier the same decision boundaries as the full dataset. The ability to transfer these synthetic images across different large feature extractors means they capture generalized patterns, rather than just specifics of one feature space, making them broadly useful. This generalization is achieved by representing the synthetic images in a way that allows for robust optimization across various transformations and scales, much like a `level-of-detail` system in graphics."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**34** _\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = 1 ;\n\n**35** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ = _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ ;\n\n**36** _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ = _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc61\u210e\ud835\udc56\ud835\udc60_ / _\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ ;"}, {"role": "assistant", "content": "**Mechanism:** This segment enforces a singular focus within a bottleneck context by conceptually isolating a 'final' service function and allocating its entire bandwidth. It uses a snapshot mechanism to preserve the state of active service functions.\n\n**Explanation:** Line 34 acts as a policy declaration, effectively stating that for any bandwidth distribution related to a 'final' state in a bottleneck (`btlneck`), we will consider only one Service Function (`SFs`). This is like setting a variable `final_active_count` to 1. Line 35, `cmpbbr -> last_number_of_SFs_in_btlneck = number_of_SFs_in_btlneck;`, is a state capture; it's functionally similar to `previous_sf_count = current_sf_count;` in programming. This allows the system to remember the number of SFs present *before* this specific 'final' state consideration. Finally, line 36, `bw_of_SFthis = bw_of_SFthis / final_number_of_SFs_in_btlneck;`, calculates the bandwidth for a specific `SFthis`. Since `final_number_of_SFs_in_btlneck` is set to 1, this division by one ensures that `SFthis` retains its full original bandwidth, conceptually assigning it the entire capacity as the single 'final' or prioritized entity within the bottleneck. It's not a mathematical reduction but an explicit affirmation that this SF gets full allocation because it's the designated 'winner' in this specific bottleneck context."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_\n\n**13** _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2217(1 \u2212 _\ud835\udefd_ )\n\nTimeout:\n\n**begin**\n\n**14** _\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc52\ud835\udc61_ ()\n\n**15** _\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc62\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ () :\n**begin**\n\n**16** _\ud835\udc4e\ud835\udc50\ud835\udc58_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 _\ud835\udc4e\ud835\udc50\ud835\udc58_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ + 1"}, {"role": "assistant", "content": "**Mechanism:** This mechanism is a reactive, adaptive control loop for network traffic. It fundamentally relies on implicit feedback (packet loss or successful acknowledgements) to adjust a 'congestion window' (cwnd), thereby controlling the sender's transmission rate. It employs both multiplicative decrease and a more drastic reset based on the severity of the congestion signal.\n\n**Explanation:** This code implements a core congestion control strategy from the CUBIC TCP algorithm. Line 13 describes a 'multiplicative decrease' response to mild congestion, where both the slow start threshold (`ssthresh`) and the congestion window (`cwnd`) are scaled down by a factor of `(1 - \u03b2)`. This is akin to resizing a buffer or a queue by a fixed percentage when it nears capacity. The `_Wlast_max` variable appears to snapshot the `cwnd` before this reduction, potentially for tracking peak capacity or for recovery algorithms. The `Timeout:` block indicates a more severe event, typically a packet loss without any acknowledgements. In this case, `cubic_reset()` (line 14) is called. This is conceptually similar to clearing all state variables and internal counters of the CUBIC algorithm, forcing it back to a very conservative initial state to re-probe the network. Finally, `cubic_update()` (line 15) is the routine that executes for each successfully acknowledged packet, indicated by `ack_cnt` incrementing (line 16). This `ack_cnt` acts like a loop counter, providing the necessary 'heartbeat' for the congestion control algorithm to know when to incrementally adjust the `cwnd` upwards, often non-linearly, during congestion avoidance."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**11**\n\n3.1 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n3.1.1 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n3.1.2 Fine-Grained Cognitive Element Annotation . . . . . . . . . . . . . . . . . . . . . . . 12\n\n3.1.3 Problem Type Classification & Response Evaluation . . . . . . . . . . . . . . . . . . . 13\n\n3.1.4 Cognitive Structure Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n3.2 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\n3.2.1 Dataset Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\n3.2.2 Analysis Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n3.3 Results & Analyses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n3.3.1 Distribution of Cognitive Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n3.3.2 Behavioral Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n3.4 Comparison with Humans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18"}, {"role": "assistant", "content": "**Mechanism:** This process involves breaking down complex thinking into individual 'steps' and then finding patterns in how those steps are put together. It's like disassembling a complex machine into its nuts and bolts, labeling each part, and then trying to reverse-engineer its operational diagrams.\n\n**Explanation:** First, they gather detailed records of thinking or problem-solving actions, much like collecting a long list of system logs where every tiny operation is timestamped (Data Collection). Each logged action is then given a specific, 'fine-grained' tag or category, turning raw events into structured data points (Fine-Grained Cognitive Element Annotation). Think of this as converting raw log strings into structured JSON objects with a 'cognitive_action' field. Problems themselves are then categorized, and the success of the solution is simply a pass/fail flag (Problem Type Classification & Response Evaluation). The core 'trick' is in 'Cognitive Structure Extraction': By analyzing these sequences of tagged actions, they're looking for recurring sub-sequences or common flowcharts of thought. This is akin to applying sequence mining algorithms or graph traversal to find common pathways in a state machine, identifying typical 'functions' or 'modules' of thinking that repeatedly appear. The experimental setup defines the scope and input data for these analyses, and the results then summarize frequencies (like collections.Counter on element tags) and observed patterns (Behavioral Structures, which are effectively frequently occurring sub-graphs or sequences). Finally, they compare these derived thinking patterns to actual human behavior, essentially using human data as a ground truth or a 'gold standard' reference implementation for their extracted cognitive models."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe now analyse how fast the Gaussian score approximation from Eq. (7) converges to the true Gaussian\nES matrix gradient in Eq. (4). We introduce the following formal regularity assumption for the fitness\nfunction:\n**Assumption 2.** _Assume that f_ ( _M_ ) _is bounded, that is_ sup _M |f_ ( _M_ ) _| < \u221e._\n\nDenote the true full-rank Gaussian ES gradient as _g_ True := _\u2207\u00b5J_ ( _\u00b5_ ). Our key theoretical result characterises\nthe error rate between the Gaussian score approximator in the low-rank update \u02c6 _g_ LR _[r]_ [from Eq. (][5][) and the true]\ngradient using the matrix Frobenius norm:\n**Theorem 2.** _Let Assumptions 1 and 2 hold and set \u03c3_ 0 = 1 _, then:_\n\n\u02c6 1\n_\u2225g_ LR _[r]_ _[\u2212]_ _[g]_ [True] _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n_._ (9)\n\ufffd\n\n_r_\n\nThe convergence rate in Eq. (9) is faster than the\ntypical _O_ ( [1] _/_ ~~_[\u221a]_~~ _r_ ) rate dictated by the general parametric central limit theorem. Our analysis shows that\nthis is due to the symmetry in our problem under\nAssumption 1. To obtain our results, we make an\nEdgeworth expansion (Bhattacharya & Ranga Rao,\n1976) of the density _p_ ( _Z_ _[r]_ ), which expands _p_ ( _Z_ _[r]_ )\nas the limiting Gaussian distribution plus a sum of\ndecaying terms that are controlled by the 3rd order\nand higher cumulants of _p_ ( _Z_ _[r]_ ). Each _i_ th order cumulant term is multiplied by a factor that decays at\nrate _O_ _r_ _[\u2212]_ _[i][\u2212]_ 2 [2] . For symmetric zero-mean distribu\ufffd \ufffd\n\n|r=1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|~~r=2~~<br>r=3<br>r=5<br>r=10||||||\n|r=50<br>r=100<br>r||||||\n|||||||\n|||||||\n|||||||\n\nFigure 3: Plot of Marginal Score Multiplied by Density for\nIncreasing _r_\n\nrate _O_ _r_ _[\u2212]_ _[i][\u2212]_ 2 [2] . For symmetric zero-mean distribu\ufffd \ufffd Figure 3: Plot of Marginal Score Multiplied by Density for\n\ntions, all odd cumulants are zero (for the same reason Increasing _r_\nthat all odd moments of a symmetric distribution are\nzero). Hence, the rate of convergence to the limiting distribution is controlled by the 4th order term, which has\nrate _O_ \ufffd _r_ _[\u2212]_ [1][\ufffd] .\n\nAlthough the full distribution _p_ ( _Z_ _[r]_ ) has no general closed-form solution, the distribution over marginals\n_p_ ( _zi,j_ ) is more amenable to analysis. We derive _p_ ( _zi,j_ ) for generalised Gaussian distributed _ai,j_ and _bi,j_ in\nSection B. To illustrate the fast converge rate, we plot the negative density _\u00d7_ score function _p_ ( _zi,j_ ) _zi,j_ for the\nmarginal distribution _p_ ( _zi,j_ ) in Fig. 3 using Gaussian distributed _ai,j_ and _bi,j_ with _\u03c3_ 0 [2] [= 1][ (see Theorem][ 4][ for]\n\n2\n\na derivation). The figure shows that _p_ ( _zi,j_ ) _zi,j_ quickly converges to the limiting function ~~_\u221a_~~ _[z][i]_ 2 _[,j]_ _\u03c0_ [exp] \ufffd _\u2212_ _[z][i]_ 2 _[,j]_ \ufffd,\n\nrecovering the Gaussian form from the true natural policy gradient update. Even at _r_ = 1, the function is not a\npoor approximation. After _r_ = 10, the function has nearly converged and after _r_ = 50, the function is visually\nindistinguishable from the limit, providing evidence for the hypothesis that the low-rank approximation is\naccurate even for very low rank regimes _r \u226a_ min( _m, n_ ).\n\n2\n\n_[,j]_ _\u2212_ _[z][i][,j]_\n\n2 _\u03c0_ [exp] \ufffd 2\n\na derivation). The figure shows that _p_ ( _zi,j_ ) _zi,j_ quickly converges to the limiting function ~~_\u221a_~~ _[z][i]_ 2 _[,j]_\n\n8"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is exploiting inherent symmetry within the problem's underlying distribution through an Edgeworth expansion. This expansion expresses the error between the approximation and the true value as a series of terms, each tied to a specific statistical cumulant (like skewness or kurtosis). For symmetric, zero-mean distributions, all odd-order cumulants are inherently zero. This effectively cancels out the lower-order error terms (e.g., 3rd order), causing the approximation's convergence rate to be dictated by the next non-zero cumulant (4th order or higher). Higher-order terms decay much faster with an increasing number of components 'r' in the approximation.\n\n**Explanation:** Think of it like this: when you approximate something, there's always a little bit of error. This method breaks down that error into different 'components' or 'wiggles'. The clever part is that because the system they are looking at is perfectly balanced (symmetric), all the 'lopsided' or 'uneven' wiggles in the error (odd cumulants) simply don't exist \u2013 they're zero. This means you don't even have to calculate or worry about those common error sources. Instead, you only have to deal with the smoother, more balanced error components, which shrink away incredibly quickly as you add just a few more pieces of information (increase 'r'). It's like having a very efficient computer program that knows, due to the structure of your input, it can skip entire sections of code that would normally check for certain types of errors, making it run much faster."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**5.1** **Experimental Settings**\n\n**Datasets.** We employ 10 real-world datasets including various type\nof graphs, primarily focusing on collaboration networks, social\nnetworks and road networks. All datasets can be downloaded from\n\n[15, 23, 42]. Since Kemeny constant is defined on connected graphs,\nwe focus on the largest connected component for each graph in\nthis study. The detailed statistics of each dataset are summarized\nin Table 2. Following previous studies [25, 51], we approximate\nKC using ApproxKemeny [52] with _\ud835\udf16_ = 0 _._ 15 as the ground truth\nfor small graphs ( _\ud835\udc5b_ _<_ 10 [6] ). For larger graphs, ApproxKemeny fails\nto provide results within an acceptable time, so we employ our\n\nproposed method TTF with a large sample size _\ud835\udc47_ ( _\ud835\udc47_ = 10 [5] ) to\nobtain a sufficiently accurate result as the ground truth.\n\n**Dynamic Updates.** To simulate dynamic graph updates, we consider both edge insertions and deletions. For the insertion scenario,\nwe first select 90% of the original graph as the base graph and sample 100 edges from the remaining 10% as candidate insertions. For\nthe deletion scenario, we sample 100 edges directly from the original graph as deletions. To better reflect realistic update behavior,\nwe further adopt a power-law update model, where most updates\noccur on a small fraction of edges. Specifically, an edge ( _\ud835\udc62, \ud835\udc63_ ) is\nchosen for insertion or deletion with probability proportional to\nthe product of the degrees of _\ud835\udc62_ and _\ud835\udc63_, ensuring that edges incident\nto high-degree nodes are more likely to be updated.\n\n**Different Algorithms.** For static graphs, we compare our proposed method TTF with several representative approaches, including the LERW-based method ForestMC [51], the UST-based\nmethod SpanTree [29], the truncated random walks-based methods DynamicMC [25] and RefinedMC [51], and the matrix-related\nmethod ApproxKemeny [52]. For dynamic graphs, we select the\nthree most competitive static methods, TTF, ForestMC, and SpanTree,\nand apply them by re-running after each update as baseline methods, comparing with our two proposed sample-maintenance approaches, BSM and ISM.\n\n**Experimental Environment.** All algorithms used in our experiment are implemented in C++ and compiled with g++ 11.2.0 using\nthe -O3 optimization flag, except for ApproxKemeny [52], which\nis implemented in Julia. We conduct all experiments on a Linux\nserver with a 64-core 2.9GHz AMD Threadripper 3990X CPU and\n128GB memory. Each experiment is repeated five times to avoid\naccidental anomalies.\n\n**5.2** **Experiment Results on Static Graphs**\n\n**Exp-I: Error vs. Time on Static Graphs.** In this experiment, we\nevaluate the performance of static algorithms across all datasets\nby comparing running time against relative error. As shown in\nFig. 9, ApproxKemeny can achieve very accurate results, but its\nruntime and memory usage are prohibitively high, making it infeasible for large graphs. Methods based on truncated random walks\nperform reasonably well on some datasets but struggle on road\nnetworks, where even extended runtimes fail to achieve high precision. ForestMC exhibits good accuracy on social networks, but\nits performance degrades on other types of graphs. In contrast,\nTTF consistently achieves lower error in less time across nearly all\ndatasets, demonstrating both high efficiency and accuracy.\n\n**Exp-II: Effect of Path Selection.** In Algorithm 1, we use BFS\nto construct a spanning tree that defines the set of paths used for\npath mapping. To investigate the impact of different path selection\nstrategies, we also experiment with DFS and Wilson\u2019s algorithm.\nThe results are presented in Fig. 10 and Fig. 11. We observe that\nwhile the choice of path selection method has a negligible impact on\nrunning time, it significantly affects the accuracy of the estimation.\nAs discussed in Theorem 3.9, the estimation value is bounded by\nthe maximum length of paths. When the spanning tree is generated\nvia BFS, the maximum path length is bounded by the diameter of\nthe graph, while it can be substantially longer when using DFS\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-13.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-14.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-12.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-11.png)\n\n|Re<br>101<br>102|lative Error|\n|---|---|\n|101<br>102<br>103<br><br>Running Time(Sec)<br>10<br>4<br>10<br>3<br>(e) Amazon|101<br>102<br>103<br><br>Running Time(Sec)<br>10<br>4<br>10<br>3<br>(e) Amazon|\n\n|10 10 Rel|01 102 103 1 Running Time(Sec) (e) Amazon lative Error|\n|---|---|\n|10<br>4<br>Re|lative Error|\n|10<br>4<br>Re||\n|101<br>102<br>103<br>104<br>Running Time(Sec)<br>(j) Orkut|101<br>102<br>103<br>104<br>Running Time(Sec)<br>(j) Orkut|\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-16.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-17.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-18.png)\n\n**Figure 9: Relative error vs running time for different algorithms**\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-15.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-19.png)\n\nor randomly sampled trees. Consequently, shorter paths tend to\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-13-20.png)\n\n**different path selection Methods**\n\n**different path selection Methods**\n\ndomly select root nodes with degrees close to _[\ud835\udc51]_ [max] 5 _[,]_ [ 2] _[\ud835\udc51]_ [max] 5 _, . . .,\ud835\udc51_ max,\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|ph<br>Email-enron<br>Amazon<br>DBLP<br>Youtube<br>roadNe<br>** ng time of** TTF** on each datas**<br>** ection Methods**|t-PA<br>roa<br>**  ets**|dNet<br>**  w**|-CA<br>Orkut<br>**  ith three**|\n|Wilson||||\n|||||\n|||||\n|||dNet<br>**  w**<br>  tic<br>  t n<br>    le<br>    fec<br>ax<br>|dNet<br>**  w**<br>  tic<br>  t n<br>    le<br>    fec<br>ax<br>|\n\nand measure the average running time. The results, illustrated in\nFig. 12, show that in most cases choosing the node with the maximum degree yields the fastest performance. Therefore, we adopt\nthe highest-degree node as the default root in our experiments.\n\n**Exp-IV: Scalability on Synthetically Generated Graphs.** In\nthis experiment, we evaluate the scalability of different methods\n\non randomly generated graphs. We employ two standard random\ngraph models: (i) Erd\u0151s\u2013R\u00e9nyi graphs [8], where each possible edge\nis independently included with probability _\ud835\udc5d_ = 5 \u00d7 10 [\u2212][4], and (ii)\nChung-Lu model [1], where the probability of creating an edge\nis proportional to the product of the endpoints\u2019 expected degrees,\nand the degree distribution follows a power law with exponent\n_\ud835\udefe_ = 3 _._ 5. The synthetic graphs are generated using the Networkit\ntoolkit [44], with their number of nodes in the largest connected\ncomponent varying from 10 [3] to 10 [6] . Fig. 13a and Fig. 13b show\nthat TTF and ForestMC scale better, as the running time of other\nmethods increases more rapidly.\n\n**Exp-V: Scalability on Huge Real-World Graphs.** In this experiment, we evaluate the scalability of different methods on two huge\nreal-world datasets: Friendster (65,608,366 nodes and 1,806,067,135\nedges) and Twitter (21,297,772 nodes and 265,025,809 edges). We run\nTTF with sufficient sample size _\ud835\udc47_ = 1000 to approximate the ground\ntruth. For all methods, we set the same and smaller sample size, and\ngradually increase it to compare their relative error and running\ntime, omitting results that exceed 24 hours. Fig. 14 show that TTF\nand ForestMC remain feasible even on such extremely large graphs,\nwhereas other methods either become prohibitively slow or fail to\nproduce accurate results. Overall, TTF achieves the best trade-off\nbetween accuracy and efficiency, demonstrating strong scalability.\n\n**Exp-VI: Parallelization.** We evaluate the parallel performance of\ndifferent algorithms using 64 threads against their single-threaded\nperformance. All methods except ApproxKemeny naturally parallelize across samples. To ensure fairness, we control the number of\nsamples to make the error levels of all algorithms comparable. As\nshown in Fig. 15, all algorithms benefit significantly from parallel\nexecution. Although TTF does not achieve the highest speedup, it\nremains among the most efficient methods.\n\n**5.3** **Experiment Results on Dynamic Graphs**\n\n**Exp-VII: Index Size.** This experiment evaluates the index size of\nboth BSM and ISM, compared to the size of graphs. The experimental results are shown in Fig. 16. We observe that the index sizes\nof both methods grow proportionally with the graph size, and the\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-4.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-5.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-6.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-7.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-8.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-14.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-15.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-16.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-17.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-18.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-28.png)\n\n**Figure 12: Impact of root node with different degrees on the running time of** TTF\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-24.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-25.png)\n\n**(a) Erd\u0151s\u2013R\u00e9nyi model** **(b) Chung-Lu model**\n\n**Figure 13: Scalability performance of different algorithms**\n**on random generated graphs**\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-26.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-27.png)\n\n**(a)** Twitter\n\n**(b)** Friendster\n\n**Figure 17: Running time of different algorithms for edges**\n**insertions on dynamic graphs**\n\n**Exp-VIII: Performance for Edge Insertion on Dynamic Graphs.**\nWe evaluate the performance of the basic and improved sample\nmaintenance methods, BSM and ISM, for edge insertions, comparing their accuracy and running time against three static methods\nthat recompute KC after each update. The results are shown in\nFig. 17 and Fig. 18. As expected, both BSM and ISM significantly\noutperform the static methods in terms of time efficiency. On social networks like Orkut, BSM and ISM are an order of magnitude\nfaster than TTF. However, on road networks such as roadNet-PA\nand roadNet-CA, the speed-up of BSM is limited, as the average\neffective resistance of edges is close to one, which means nearly\nall samples are required to be resampled. Additionally, sampling a\nUST that includes a specific edge might be slower regular Wilson\nalgorithm. In contrast, ISM still achieves notable speed-ups even\non road networks, since link-cut operations are significantly faster\nthan tree sampling, though it produces slightly higher error.\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-14-29.png)\n\n**Figure 15: Parallel speedup of different algorithms**\n\ngrowth rate remains stable across all datasets, which empirically\nvalidates the _\ud835\udc42_ ( _\ud835\udc5b_ ) space complexity discussed in Section 4. In all\ntested datasets, the maximum index size is 4.9GB, demonstrating\nthat our proposed dynamic algorithms are highly space-efficient\nwhile supporting real-time sample maintenance.\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-15-0.png)\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n**Figure 21: Normalized KC across real-world graphs**\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-15-1.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-15-6.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-15-7.png)\n\n![](papers/images/Scalable-and-Provable-Kemeny-Constant-Computation-on-Static-and-Dynamic-Graphs-A-2Forest-Sampling-Approach.pdf-15-12.png)\n\n|erG ri<br>P ow<br>re18:<br>sinse<br>LE<br>Sp<br>TT|d H ep - T<br>Acc<br>rtio<br>walk<br>anTree<br>F|h<br>u<br>n|ph<br>A Estr - o m a - il<br>racyperf<br>sondyn<br>BSM(De<br>ISM(Del|Aenron m azon D B LP<br>ormanceofd<br>amicgraphs<br>l)<br>)|Col6|utub roade<br>o Y<br>ifferen|Col8|N e - t<br>ta|roadPA<br>lgo|N e<br>ri|- t<br>t|C A<br>h|O r u k t<br>msfo|Col15|Col16|Col17|Col18|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||||||||||\n|PowerGri<br>**re 19:**<br>**ions**|Hep-T<br>** Ru**<br>** on d**|h<br>** n**<br>** y**|Astro-ph<br>Email-<br>** ning tim**<br>** namic g**<br>LEwal<br>~~SpanT~~|enron<br>Amazon<br>D<br>**  e of dife**<br>**  raphs**<br>k<br>~~ee~~<br>BSM(<br>~~ISM(~~|BLP<br><br>**   rent**<br>Del)<br>~~Del)~~|Youtube<br><br>**   alg**|road<br>**   or**|Net-<br>**   ith**|PA<br>road<br>**   m**|Ne<br>**   s f**|t-<br>**    o**|C<br>|**    r**|O<br>**    e**|rku<br>**    d**|t<br>**    ge**||\n||||TTF|||||||||||||||\n|||||||||||||||||||\n\n**Figure 20: Accuracy performance of different algorithms for**\n**edges deletions on dynamic graphs**\n\n**Exp-VIII: Performance for Edge Deletion on Dynamic Graphs.**\nWe also evaluate the performance of BSM and ISM for edge deletions. The results, shown in Fig. 19 and Fig. 20, are generally consistent with those from the insertion scenario. Notably, BSM shows\nbetter performance improvements on road networks during deletions than insertions, since it can employ the standard Wilson algorithm for tree sampling. Moreover, both BSM and ISM are slightly\nfaster for deletions than insertions. This is likely because edge insertions require computing effective resistance, which introduces\nadditional computational overhead, whereas deletions do not.\n\n**5.4** **Case Studies**\n\n**Case Study: Graph Classification.** We conducted a case study to\ninvestigate the relationship between the Kemeny constant and different types of graphs. For each dataset, we normalized the Kemeny\nconstant as _\ud835\udf05_ ( _\ud835\udc3a_ )/ _\ud835\udc5b_ and plotted the results. As shown in Fig .21,\ndifferent graph types exhibit distinct patterns in their normalized\nKemeny constants. Social networks and collaboration networks\ntypically have _\ud835\udf05_ ( _\ud835\udc3a_ )/ _\ud835\udc5b_ \u2248 1, whereas road networks generally show\nlarger values. Intuitively, a smaller Kemeny constant indicates that\nnodes are more tightly connected, which facilitates reaching other\nnodes from any starting point. This demonstrates that the Kemeny\nconstant is informative for understanding graph connectivity and\ncan be leveraged as a feature for graph classification.\n\n**Figure 22: Evolution of Kemeny constant over time**\n\n**Case Study: Kemeny Constant in Dynamic Graphs.** We further investigate the evolution of the Kemeny constant in dynamic\ngraphs using the HighSchool dataset [15], which captures contacts\namong students over a single day. Each student is represented as a\nnode, and an edge is created when two students are in close and\nface-to-face proximity during a 20-second time window. We divided\nthe data into 5-minute windows and computed the Kemeny constant for each window, updating every minute. Figure 22 shows\nthe number of edges and the corresponding Kemeny constant over\ntime. Although the number of edges fluctuates considerably, the\nKemeny constant remains largely stable, with notable changes only\nduring periods such as class breaks or lunch, when the network\nstructure undergoes significant alterations. This demonstrates that\nthe Kemeny constant can effectively capture structural changes in\ndynamic networks."}, {"role": "assistant", "content": "**Mechanism:** The core idea for efficiently calculating the Kemeny Constant (KC) for large static graphs is to approximate it by averaging results from many randomly sampled '2-forests' (pairs of spanning trees). Instead of exhaustively computing paths between all node pairs, which is computationally expensive, TTF samples these substructures. The accuracy of this approximation is strongly tied to the length of the paths within these sampled structures. By using Breadth-First Search (BFS) to construct the spanning tree component of the 2-forest, the maximum path length within the tree is minimized (bounded by the graph's diameter). This selection biases towards shorter paths, which mathematically leads to a tighter bound on the estimation error, thus improving accuracy. Choosing the highest-degree node as the root for BFS further optimizes performance, similar to how a well-chosen starting point for a search algorithm can reduce computation time. This approach is akin to using Monte Carlo sampling for integration, where many random samples provide a good estimate of the integral, and carefully chosen samples (like short paths from BFS) improve the convergence rate. For dynamic graphs (where edges are added or removed), instead of discarding all existing 'samples' (the 2-forests) and starting fresh (like re-running an entire program from scratch), BSM and ISM employ incremental updates. BSM attempts to 'resample' only the 2-forests that are directly affected by the edge change, similar to updating specific records in a database instead of reloading the entire dataset. ISM uses specialized data structures and operations, specifically 'link-cut trees' (a common data structure for maintaining dynamic trees), which allow for extremely fast (often logarithmic time) updates to the spanning trees. These link-cut operations act like pointers that can quickly 'cut' a branch from one part of the tree and 'link' it to another, effectively modifying the sampled 2-forests with minimal computational overhead.\n\n**Explanation:** To avoid the massive computations required for an exact Kemeny Constant, TTF takes many small, quick measurements of graph connectivity using 'random walks' on 'spanning trees'. Think of a spanning tree as a simplified map of just enough connections to reach everywhere. By generating many such maps, and particularly by using BFS to make sure the paths on these maps are as short as possible, it ensures that the 'average' measurement is very close to the true value without getting lost in overly complex long routes. When the graph changes (an edge is added or removed), instead of rebuilding all these simplified maps from scratch, BSM and ISM quickly tweak only the affected maps. BSM might rebuild a few maps if needed, like replacing a corrupted file. ISM is much more efficient, using 'link-cut' operations\u2014these are like advanced pointer manipulations that can surgically re-route paths in milliseconds without disturbing the rest of the map. This makes dynamic updates incredibly fast, preventing the entire calculation from grinding to a halt with every tiny change."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**66**\nC.1 Level-wise SBM statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\nC.2 Concentration inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nC.3 Voting lower bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n\n### **1 Introduction**\n\nThe stochastic block model (SBM), introduced by Holland et al. [HLL83], is a fundamental\nstatistical model for community detection in network analysis and has been extensively\nstudied over the years [MNS12, ABH15, KMM [+] 13, Abb18].\nIn this work, we focus on the symmetric balanced _\ud835\udc58_ -stochastic block model ( _\ud835\udc58_ -SBM).\nGiven _\ud835\udc58, \ud835\udc5b_ \u2208 \u2124 [+], let ( _\ud835\udc6e, \ud835\udc81_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) denote the _\ud835\udc58_ -SBM with expected degree _\ud835\udc51_ _>_ 0\nand bias _\ud835\udf00_ \u2208[0 _,_ 1]. The label _\ud835\udc81_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ is generated by partitioning the _\ud835\udc5b_ vertices of the\ngraph uniformly at random into _\ud835\udc58_ communities of size _\ud835\udc5b_ / _\ud835\udc58_ each; the _\ud835\udc56_ th row _\ud835\udc81_ ( _\ud835\udc56_ ) is the\nindicator vector of the community containing vertex _\ud835\udc56_ . Conditioned on the latent labels _\ud835\udc81_,\nthe edges between distinct vertices _\ud835\udc56, \ud835\udc57_ \u2208[ _\ud835\udc5b_ ] are sampled independently with probability\n\n###### \u2119\ufffd( \ud835\udc56, \ud835\udc57 ) \u2208 \ud835\udc38 ( \ud835\udc6e )\ufffd \ufffd\n\n###### \ud835\udc5d 1 = [\ufffd] 1 + [\ufffd] 1 \u2212 [1] \ud835\udc58 \ufffd \ud835\udc5d 2 = [\ufffd] 1 \u2212 [\ud835\udf00] \ud835\udc58 \ufffd \u00b7 \ud835\udc5b [\ud835\udc51]\n\n###### \ud835\udc5d 2 = [\ufffd] 1 \u2212 [\ud835\udf00] \ud835\udc58\n\n###### [\ud835\udf00] \ud835\udc58 \ufffd \u00b7 \ud835\udc5b [\ud835\udc51]\n\n###### [1] \ud835\udc58 \ufffd \ud835\udf00 [\ufffd] \u00b7 \ud835\udc5b [\ud835\udc51]\n\n_\ud835\udc5b_ _[,]_ if _\ud835\udc81_ ( _\ud835\udc56_ ) = _\ud835\udc81_ ( _\ud835\udc57_ ) _,_\n\n(1.1)\n\n_[\ud835\udc51]_ otherwise _._\n\n_\ud835\udc5b_ _[,]_\n\nGiven an observation of the graph _\ud835\udc6e_ \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ), a central statistical problem is to\nrecover its latent community structure _\ud835\udc81_ . This perspective naturally leads to the question\n\n_\ud835\udc81_ _\ud835\udf00_\nof how accurately the hidden labels can be recovered as a function of the parameters\nand _\ud835\udc51_ ; see the survey [Abb18] for a detailed overview.\nThe strongest statistical goal is to recover all labels without error, a task known as\n_exact recovery_ . This is not always achievable: for instance, when _\ud835\udc51_ = _\ud835\udc42_ (1), the graph _\ud835\udc6e_\ntypically contains isolated vertices whose labels cannot be inferred. More generally, Hajek\net al. [HWX14] and Abbe et al. [ABH15, AS15] showed that there exist efficient algorithms\n###### achieving exact recovery whenever \ud835\udc36\ud835\udc51,\ud835\udf00 \u2a7e \ud835\udc58 log \ud835\udc5b, the so-called Chernoff\u2013Hellinger threshold,\n\nand that exact recovery is information-theoretically impossible below this threshold.\nWhen exact recovery is out of reach, a natural weaker requirement is to output a labeling\nthat performs better than random guessing, or equivalently, has nontrivial correlation\nwith the ground truth. This guarantee is called _weak recovery_ and has been a central\nnotion in the study of the SBM. The key threshold governing weak recovery is the _Kesten\u2013_\n_Stigum (KS) threshold_, given by _\ud835\udf00_ [2] _\ud835\udc51_ _> \ud835\udc58_ [2] . In the symmetric, balanced _\ud835\udc58_ -SBM, a sequence\nof works [DKMZ11, Mas14, BLM15, AS16, MNS18] established that weak recovery can\nbe achieved in polynomial time whenever _\ud835\udf00_ [2] _\ud835\udc51_ _> \ud835\udc58_ [2] . Conversely, for _\ud835\udf00_ [2] _\ud835\udc51_ _< \ud835\udc58_ [2], a rich\nline of work [HS17, Hop18, BBK [+] 21, DHSS25, SW25] provides strong evidence that no\npolynomial-time algorithm can achieve weak recovery in this regime.\nThese results delineate the regimes where exact recovery is possible and those where\nonly weak recovery can be hoped for. Between these two extremes, it is natural to ask: for\n_\ud835\udf00_ and _\ud835\udc51_\nfixed, what is the best achievable recovery rate, either information-theoretically or\nby efficient algorithms? This question leads to the notion of the _minimax rate_ in the SBM.\n\n1\n\n**Minimax error rate.** For a family \u0398 of _\ud835\udc58_ -SBMs (specified by the degree _\ud835\udc51_, bias _\ud835\udf00_, and\nallowing imbalance), we define the misclassification error as\n\n1\nerror _\ud835\udc58_ ( _\ud835\udc4d,_ [\u02c6] _\ud835\udc81_ ) \ufffd min\n_\ud835\udf0b_ :[ _\ud835\udc58_ ]\u2192[ _\ud835\udc58_ ] 2 _\ud835\udc5b_\n\n_\ud835\udc58_\n\n\u02c6\n_\ud835\udc4d_ (\u00b7 _, \ud835\udc57_ ) \u2212 _\ud835\udc81_ (\u00b7 _, \ud835\udf0b_ ( _\ud835\udc57_ ))\n###### \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd1 [.]\n\n_\ud835\udc57_ =1\n\nThe minimax rate is then\n###### inf\u02c6 sup \ud835\udd3c \ud835\udf03 \ufffderror \ud835\udc58 ( \ud835\udc4d, [\u02c6] \ud835\udc81 )\ufffd,\n\n_\ud835\udc4d_ _\ud835\udf03_ \u2208 \u0398\n\nwhere the infimum is taken over all estimators _\ud835\udc4d_ [\u02c6], the supremum over parameters _\ud835\udf03_ \u2208 \u0398,\nand \ud835\udd3c _\ud835\udf03_ denotes expectation with respect to the _\ud835\udc58_ -SBM with parameter _\ud835\udf03_ .\n###### Zhang et al. [ZZ15] showed that whenever \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 log \ud835\udc58 ), the minimax error rate is\n\ngiven by exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ), where _\ud835\udc36\ud835\udc51,\ud835\udf00_ [1] is defined as\n\n2\n\n2\n###### \ud835\udc36\ud835\udc51,\ud835\udf00 \ufffd [\ufffd][\u221a] \ud835\udc5b\ud835\udc5d 1 \u2212 [\u221a] \ud835\udc5b\ud835\udc5d 2\ufffd = \ufffd\ufffd \ufffd\n\n1 + 1 \u2212 [1]\n\n_\ud835\udc58_\n###### \ufffd \ufffd \ufffd\n\n###### \ud835\udc51 [\ufffd] \ufffd ~~\ufffd~~ \ufffd\n\n\u2212\n_\ud835\udf00_ _\ud835\udc51_\n###### ~~\ufffd \ufffd~~\n\n1 \u2212 _[\ud835\udf00]_\n###### \ufffd\ufffd \ud835\udc58\n\n_._ (1.2)\n\nIn the same work, they constructed a statistically optimal but computationally inefficient\n###### estimator that attains this rate for the \ud835\udc58 -SBM under the condition \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 log \ud835\udc58 ).\n\nEfficient procedures are known in two regimes. For the case _\ud835\udc58_ = 2, Mossel et al. [MNS14]\ndeveloped a polynomial-time algorithm based on belief propagation that achieves the\noptimal rate when _\ud835\udc36\ud835\udc51,\ud835\udf00_ is sufficiently large. For general _\ud835\udc58_, Gao et al. [GMZZ17] proposed a\npolynomial-time algorithm based on spectral initialization followed by majority voting,\n###### showing that it attains the minimax rate under the stronger condition \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [3] ). Thus,\n\nthere remains a gap between the KS threshold _\ud835\udf00_ [2] _\ud835\udc51_ _> \ud835\udc58_ [2] and the best-known polynomial###### time algorithm \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [3] ), which motivates the following question on achieving the\n\nminimax rate in polynomial time for the _\ud835\udc58_ -SBM.\n\n**Question 1.1.** Can the minimax error rate exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ) be achieved by efficient algorithms\n###### under the condition \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] for some universal constant \ud835\udc3e ?\n\n**Node robustness.** The SBM is an idealized statistical model and may fail to capture\ncertain features of real-world networks. In social networks, for example, fake or automated\naccounts can distort connectivity patterns, while in biological networks, contaminated\nsamples may induce spurious interactions.\nA natural way to model such effects is via _node corruptions_, formally introduced by\nAcharya et al. [AJK [+] 22] in the context of edge density estimation in Erd\u0151s-R\u00e9nyi random\ngraphs. In the node corruption model, an adversary may arbitrarily modify all edges\nincident to up to _\ud835\udf02\ud835\udc5b_ vertices, where _\ud835\udf02_ \u2208[0 _,_ 1) is the corruption fraction. This allows up to\n_\ud835\udc42_ ( _\ud835\udf02\ud835\udc5b_ [2] ) adversarial edge changes and poses significant challenges for algorithm design. In\n\n1For interpretation, note that _\ud835\udc36\ud835\udc51,\ud835\udf00_ differs from _\ud835\udf00_ 2 _\ud835\udc51_ only by a constant factor.\n\n2\n\nparticular, both belief propagation [MNS14] and spectral algorithms [GMZZ17] rely on\ndistributional assumptions that are brittle under such perturbations.\nThe study of the node corruption model for community recovery in the stochastic block\nmodel dates back to [ABARS20, AR20], where the authors give a fast algorithm that is robust\nto a polylog( _\ud835\udc5b_ ) number of corrupted nodes. For the symmetric _\ud835\udc58_ -SBM, Liu et al. [LM22]\nrecently gave the first polynomial-time algorithm that achieves the minimax rate under\n###### node corruption when \ud835\udf02 \u2a7d exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 ). [2] However, their result requires \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [102] ),\n\nwhich is very far from the KS threshold. This leads to the following natural question in the\nnode-robustness setting.\n\n###### Question 1.2. Given an \ud835\udf02 -node-corrupted \ud835\udc58 -SBM and assuming \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2], can we achieve the minimax rate exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 ) in polynomial time when \ud835\udf02 \u2a7d exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 )?\n\n##### **1.1 Results**\n\nIn this work, we answer the above questions affirmatively, up to a multiplicative log _\ud835\udc58_ factor.\nMore specifically, we give the first polynomial-time algorithm that achieves the minimax\nrate in the presence of node corruption, even when the number of communities _\ud835\udc58_ diverges\nwith _\ud835\udc5b_ .\n\n**Theorem 1.3** (Informal main theorem, see Theorem 5.7 for the formal version) **.** _Let_\n###### \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [, and][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [. Suppose][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2][ log] [ \ud835\udc58] [for some sufficiently large]\n\n_universal constant \ud835\udc3e_\n_. Then there exists a polynomial-time algorithm that, given an \ud835\udf02-node corrupted_\n_graph \ud835\udc6e_ \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _, produces a labeling with expected error at most_\n\nexp \u2212 _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_ + _\ud835\udc42_ \u221a\n###### \ud835\udc58 \ufffd \ufffd\n\n_\ud835\udc51\ud835\udf00_ + poly( _\ud835\udc58_ ) _\ud835\udf02_ _._\n###### \ufffd [\ufffd]\n\n###### Under the conditions \ud835\udf02 \u2a7d exp [\ufffd] \u2212 [\ud835\udc36] \ud835\udc58 [\ud835\udc51][,][\ud835\udf00] [(][1][+] [\ud835\udc5c] [(][1][))][\ufffd] and \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58, this bound shows that our algorithm robustly attains the minimax error rate. The requirement \ud835\udf02 \u2a7d exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 ) is information-theoretically necessary, and the condition \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58 matches the KS\n\nthreshold up to a log _\ud835\udc58_ factor. Moreover, as an immediate corollary of Theorem 1.3, in the\nabsence of node corruptions (i.e., when _\ud835\udf02_ = 0), our algorithm achieves exact recovery under\n###### the information-theoretically optimal condition \ud835\udc36\ud835\udc51,\ud835\udf00 \u2a7e \ud835\udc58 log \ud835\udc5b .\n\nFor comparison, the best previously known node-robust algorithm [LM22] achieves an\nerror rate of\n\n###### \u2212 [\ud835\udc36][\ud835\udc51,][\ud835\udf00] + \ud835\udc42 [\ufffd] \ud835\udc58 [50][\u221a]\n\nexp\n\n_\ud835\udc58_\n###### \ufffd\n\n###### \ud835\udc51 \ud835\udf00 [\ufffd\ufffd] + \ud835\udc42 ( \ud835\udc58\ud835\udf02 ),\n\nwhich exhibits a much worse dependence on _\ud835\udc58_ . In addition, even to obtain weak recovery,\n###### their algorithm requires \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc58 [102], which is far above the KS threshold.\n\n2Their algorithm also tolerates semi-random corruption that can arbitrarily add intra-cluster edges and\ndelete inter-cluster edges.\n\n3\n\n**Open problem.** We leave as an open problem whether there exist polynomial-time\nalgorithms that achieve the minimax error rate exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ) under the weaker condition\n###### \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [2] ). This problem remains open even in the non-robust setting. Note that, since \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 \u2273 \ud835\udc58, when \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [2] ) the optimal error exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 ) is at most exp(\u2212 \ud835\udc58 ). Thus, a\n\npositive resolution would yield an error rate of exp(\u2212(1 \u00b1 _\ud835\udc5c_ (1)) _\ud835\udc58_ ) throughout the regime\nabove the KS threshold.\n\nMoreover, we suspect that our results extend to inhomogeneous stochastic block models\nin which the intra-cluster connection probabilities are at least _\ud835\udc4e_ / _\ud835\udc5b_ and the inter-cluster\nconnection probabilities are at most _\ud835\udc4f_ / _\ud835\udc5b_ .\n\n##### **1.2 Previous work**\n\n**Semidefinite programming for community detection.** Semidefinite programming (SDP)\nhas been extensively studied for community detection. The most natural SDP is based on\nan SDP relaxation of the _minimum bisection_ problem (which we refer to as the basic SDP),\nfirst studied by Feige and Kilian [FK01]. Hajek et al. initiated the study of the power of the\nbasic SDP for exact recovery in the 2-SBM [HWX14]. Gu\u00e9don and Vershynin developed\nthe first polynomial-time algorithm that achieves an error rate _\ud835\udc5c_ (1) for the balanced _\ud835\udc58_ -SBM\nwhen _\ud835\udf00_ [2] _\ud835\udc51_ \u226b _\ud835\udc58_ [2] [GV14]. More recently, Fei and Chen [FC19] applied a novel primal-dual\nanalysis to the basic SDP for the balanced 2-SBM, proving that it achieves the minimax\nerror rate near the KS threshold.\n\n**Majority voting based algorithms for minimax error rate.** Majority voting has been the\nde facto method to achieve the minimax rate. Gao et al. proposed a two-stage algorithm\nfor _\ud835\udc58_ -SBM that combines spectral methods for initial estimation with majority voting\n###### for accuracy boosting [GMZZ17]. However, their algorithm requires \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [3] ), which\n\nexceeds the KS threshold by a factor of _\ud835\udc58_ .\nLiu and Moitra later developed the first polynomial-time algorithm that achieves the\nminimax error rate under node corruption by robustly simulating majority voting via\n###### SDP [LM22]. However, their algorithm requires \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [102] ), which is substantially above\n\nthe KS threshold.\n\n**Sum-of-Squares algorithms for robust estimation.** The Sum-of-Squares (SoS) framework\nprovides a general _proof-to-algorithm_ paradigm: low-degree SoS certificates of identifiability\ncan be converted by semidefinite programming into efficient algorithms whose guarantees\nfollow mechanically from the SoS proofs [BS14, RSS18]. This framework is particularly\npowerful for robust estimation problems in random graphs, where pseudorandomness\ncan be certified by constant-degree spectral constraints. In such settings, one can encode\nexponentially many correlation inequalities using only a polynomial number of constraints [DdHS23, CDd [+] 24, CDHS24, CDHT25]. In the context of SBMs, [DdHS23] used\n\n4\n\nSoS to achieve weak recovery at the KS threshold, even when a constant fraction of nodes\nis adversarially corrupted.\n\n##### **1.3 Organization**\n\nThe rest of the paper is organized as follows. In Section 2, we give a high-level overview of\nour techniques with a focus on robust majority voting via Sum-of-Squares. In Section 3, we\ncover notations and basics of the Sum-of-Squares framework. In Section 4, we establish the\nstatistical properties of the _\ud835\udc58_ -SBM model with a focus on the majority voting concentration\nresult. In Section 5, we outline our algorithmic framework and present our formal main\nresults. The proofs of these results are subsequently detailed in Section 6 (initial rough\nclustering), Section 7 (identifying clusters with a 0 _._ 99-fraction of the vertices recovered),\nand Section 8 (robustly boosting the rough bisection accuracy to bisection minimax rate),\nrespectively. These ingredients are then combined in Section 9 to obtain our robust\nbisectioning algorithm. In Section 10, we show how to recursively apply the robust\nbisectioning algorithm to robustly find a _\ud835\udc58_ -clustering of the graph with error rate 1/poly( _\ud835\udc58_ )\nfor symmetry breaking. Finally, we conclude in Section 11 by boosting the error rate from\n1/poly( _\ud835\udc58_ ) to the minimax optimal rate using robust pairwise majority voting.\n\n### **2 Techniques**\n\n##### **2.1 Two communities**\n\nFor notational simplicity, we first illustrate some of the ideas underlying our algorithm for\nthe case of two communities. Let ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ ) denote the stochastic block model\nwith degree parameter _\ud835\udc51_ _>_ 0 and bias parameter _\ud835\udf00_ \u2208[0 _,_ 1]. Here, we choose _\ud835\udc99_ \u2208{\u00b11} _[\ud835\udc5b]_\n###### uniformly at random among all unbiased vectors so that [\ufffd] [\ud835\udc5b] \ud835\udc56 =1 [\ud835\udc99] [(] [\ud835\udc56] [)][ =][ 0][, where we take] \ud835\udc5b \u2a7e 2 to be even. We can view \ud835\udc99 as a balanced bipartition of the vertex set [ \ud835\udc5b ]. We refer\n\nto its parts _\ud835\udc99_ [\u2212][1] (1) and _\ud835\udc99_ [\u2212][1] (\u22121) as blocks or communities. Then, for every pair of distinct\nvertices _\ud835\udc56, \ud835\udc57_ \u2208[ _\ud835\udc5b_ ], we decide independently at random whether to join them by an edge\nwith probability,\n###### \u2119\ufffd \ud835\udc56\ud835\udc57 \u2208 \ud835\udc38 ( \ud835\udc6e ) | \ud835\udc99 \ufffd = [\ufffd] 1 + \ud835\udf00 \u00b7 \ud835\udc99 ( \ud835\udc56 ) \u00b7 \ud835\udc99 ( \ud835\udc57 ) [\ufffd] \u00b7 [\ud835\udc51] (2.1)\n\n_\ud835\udc5b_ _[.]_\n\n**Basic recovery approach.** In the stochastic block model without adversarial corruptions,\nthe most basic approach for approximately recovering the underlying blocks uses spectral\ntechniques [Bop87, GV16, CO10, Mas14, CRV15]. As a slight abuse of notation, let _\ud835\udc3a_ denote\nthe centered adjacency matrix of an _\ud835\udc5b_ -vertex graph with degree parameter _\ud835\udc51_,\n\n_\ud835\udc3a_ ( _\ud835\udc56, \ud835\udc57_ ) =\n\n1 \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n\n\u2212 _[\ud835\udc51]_\n###### \ufffd \ud835\udc5b\n\n\u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_ (2.2)\n\n_[\ud835\udc51]_ otherwise.\n\n_\ud835\udc5b_\n\n_\ud835\udc5b_ if _\ud835\udc56\ud835\udc57_ \u2208 _\ud835\udc38_ ( _\ud835\udc3a_ ),\n\n5\n\nThen, for the stochastic block model ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ ),\n\n\ud835\udd3c[ _\ud835\udc6e_ | _\ud835\udc99_ ] = _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_ [\u00b7] _[ \ud835\udc99\ud835\udc99]_ [T] _[ .]_ (2.3)\n\n_\ud835\udc5b_\nAt the same time, conditioned on _\ud835\udc99_, the matrix _\ud835\udc6c_ := _\ud835\udf00\ud835\udc51_ _[\ud835\udc6e]_ [\u2212] _[\ud835\udc99\ud835\udc99]_ [T][ has (up to symmetry)]\n###### independent mean-zero entries and enjoys a spectral norm bound \u2225 \ud835\udc6c \u2225 \u2272 \ud835\udc5b /( \ud835\udf00 \u221a \ud835\udc51 ) for\n\n###### independent mean-zero entries and enjoys a spectral norm bound \u2225 \ud835\udc6c \u2225 \u2272 \ud835\udc5b /( \ud835\udf00 \u221a \ud835\udc51 ) for\n\n_\ud835\udc51_ \u226b log _\ud835\udc5b_ . In this way, the best rank-one approximation of _\ud835\udc3a_ allows us to approximately\nrecover _\ud835\udc99_ up to sign as long as _\ud835\udf00_ - \u221a _\ud835\udc51_ \u226b 1 and _\ud835\udc51_ \u226b log _\ud835\udc5b_ . After carefully truncating\n\nrecover _\ud835\udc99_ _\ud835\udf00_ - _\ud835\udc51_ \u226b 1 and _\ud835\udc51_ \u226b _\ud835\udc5b_\nup to sign as long as log . After carefully truncating\n\nhigh-degree nodes, we can even drop the logarithmic-degree condition _\ud835\udc51_ \u226b log _\ud835\udc5b_ . It turns\nout that for approximately recovering the underlying blocks, the only remaining condition,\n_\ud835\udc51_ \u226b 1/ _\ud835\udf00_ [2], is also information-theoretically necessary.\n\n**Sum-of-squares lens on the basic approach.** It will be instructive to formulate this basic\napproach in terms of the sum-of-squares method. While this sum-of-squares formulation\nis certainly overkill for approximate recovery in the vanilla version of the model, it will\ngive us node-robustness essentially for free (whereas basic spectral techniques or even\nsemidefinite programming techniques cannot handle node corruption). The basic spectral\nalgorithms and majority voting algorithms are known to be brittle under node corruptions,\nwhile the basic semidefinite programming algorithms are only known to be robust against\n_\ud835\udc42_ ( _\ud835\udc5b\ud835\udc51\ud835\udf00_ ) number of corrupted edges.\nAs a starting point for our sum-of-squares formulation, we note that a spectral norm\n###### bound \u2225 \ud835\udc38 \u2225 \u2a7d \ud835\udf06 \u00b7 \ud835\udc5b certifies the following universally quantified inequality over the\n\nhypercube,\n###### \u2200 \ud835\udc62, \ud835\udc63 \u2208{\u00b11} [\ud835\udc5b] . \u27e8 \ud835\udc62, \ud835\udc38\ud835\udc63 \u27e9 \u2a7d \ud835\udf06 \u00b7 \ud835\udc5b [2] . (2.4)\n\nMoreover, this spectral norm bound constitutes a degree-2 sum-of-squares proof of the\nabove inequality.\nFor our purposes, it will be useful to introduce sum-of-squares proofs as mathematical\nobjects in their own right. For _\ud835\udc5b_ -variate polynomials _\ud835\udc5d, \ud835\udc5e_ 1 _, . . ., \ud835\udc5e\ud835\udc5a_ \u2208 \u211d[ _\ud835\udc65_ ], we say that a\n###### real-valued square matrix \ud835\udc45 is a degree-\u2113 sum-of-squares proof of the inequality \ud835\udc5d \u2a7e 0 subject to the constraints \ud835\udc5e 1 \u2a7e 0, . . ., \ud835\udc5e\ud835\udc5a \u2a7e 0 if\n\n_\ud835\udc5d_ = Tr _\ud835\udc45\ud835\udc45_ [T]              - Mom _\u2113_ ( _\ud835\udc5e_ 1 _, . . ., \ud835\udc5e\ud835\udc5a_ ) _,_ (2.5)\n\nwhere Mom _\u2113_ ( _\ud835\udc5e_ 1 _, . . ., \ud835\udc5e\ud835\udc5a_ ) is a block-diagonal matrix with entries in \u211d[ _\ud835\udc65_ ] and (possibly\nempty) blocks _\ud835\udc40\ud835\udc46_ indexed by multisubsets _\ud835\udc46_ \u2286[ _\ud835\udc5a_ ] such that for all pairs of monomials\n###### \ud835\udc65 [\ud835\udefc], \ud835\udc65 [\ud835\udefd] with deg \ud835\udc65 [\ud835\udefc], deg \ud835\udc65 [\ud835\udefd] \u2a7d 2 [1] [\u00b7 (] [\u2113] [\u2212] [\ufffd] \ud835\udc56 \u2208 \ud835\udc46 [deg] [ \ud835\udc5e][\ud835\udc56] [)][,]\n\n_\ud835\udc40\ud835\udc46_ ( _\ud835\udefc, \ud835\udefd_ ) :=\n###### \ufffd\ufffd\n\n      - _\ud835\udc65_ _[\ud835\udefc]_      - _\ud835\udc65_ _[\ud835\udefd]_ _._ (2.6)\n###### \ud835\udc56 \u2208 \ud835\udc46 [\ud835\udc5e][\ud835\udc56] \ufffd\n\nWe remark that sum-of-squares proofs are more commonly defined in terms of sumof-squares polynomial multipliers for (products of) the constraint polynomials _\ud835\udc5e_ 1 _, . . ., \ud835\udc5e\ud835\udc5a_ .\nHowever, it will be beneficial for our purposes to represent them as matrices (corresponding\n\n6\n\nto the monomial-coefficients of the polynomial multipliers). Crucially, our definition makes\nit apparent that sum-of-squares proofs are solutions to a system of quadratic equations of\n\n.\nEq. (2.6)\nNote that each block _\ud835\udc40\ud835\udc46_ has size _\ud835\udc42_ ( _\ud835\udc5b_ _[\u2113]_ [/][2] ) by _\ud835\udc42_ ( _\ud835\udc5b_ _[\u2113]_ [/][2] ) and the number of non-empty\nblocks is _\ud835\udc42_ ( _\ud835\udc5a_ _[\u2113]_ ) (as we may assume the polynomials _\ud835\udc5e_ 1 _, . . ., \ud835\udc5e\ud835\udc5a_ to have degree at least 1).\nTherefore, _\ud835\udc45_ has size _\ud835\udc42_ ( _\ud835\udc5b\ud835\udc5a_ ) _[\u2113]_ by _\ud835\udc42_ ( _\ud835\udc5b\ud835\udc5a_ ) _[\u2113]_ and the number of quadratic equations in Eq. (2.5)\nis polynomial in _\ud835\udc5b_ and _\ud835\udc5a_ for every constant _\u2113_ .\n###### We denote that \ud835\udc45 is a degree-\u2113 sum-of-squares proof of the inequality \ud835\udc5d \u2a7e 0 subject to the constraints \ud835\udc5e 1 \u2a7e 0, . . ., \ud835\udc5e\ud835\udc5a \u2a7e 0 by\n\n###### \ud835\udc45 : \ufffd \ud835\udc5e 1( \ud835\udc65 ) \u2a7e 0, . . ., \ud835\udc5e\ud835\udc5a ( \ud835\udc65 ) \u2a7e 0\ufffd\n\n_\ud835\udc65_\n_\u2113_ _\ud835\udc5d_ ( _\ud835\udc65_ ) \u2a7e 0 _._ (2.7)\n\nIf the variables _\ud835\udc65_ quantified by the proof or the degree bound _\u2113_ are clear from the context,\nwe may drop them in the above notation.\nA fundamental property of sum-of-squares proofs is that they are automatizable.\nIf a matrix _\ud835\udc45_ as above exists, we can find it in time polynomial in its bit complexity\n\n[BS14, BS16, RSS18]. A simple but very important consequence for estimation problems is\nthat given as input a system of polynomial constraints \ud835\udc9c( _\ud835\udc65_ ), we can compute in polynomialtime a vector \u02c6 _\ud835\udc65_ that satisfies all convex polynomial inequalities that can be derived from\n\ud835\udc9c( _\ud835\udc65_ ) by a sum-of-squares proof with polynomial bit complexity [BS14, BS16, RSS18]. In this\nway, referred to as the _proof-to-algorithm paradigm_, we obtain efficient estimation algorithms\nfrom the mere existence of small identifiability proofs.\nIn order to apply this terminology for approximate recovery of the stochastic block\nmodel, we consider the following polynomial constraints for the set of possible label\nassignments (for the case of two communities),\n\n_\ud835\udc5b_\n###### \ud835\udc9clabel( \ud835\udc65 ) := \ufffd \ud835\udc65 1 [2] [=] [ . . .] [ =] [ \ud835\udc65] \ud835\udc5b [2] [=][ 1] [,] \ufffd \ud835\udc56 =1 [\ud835\udc65][\ud835\udc56] [=][ 0] \ufffd . (2.8)\n\nNext, we consider a system of quadratic equations for matrices _\ud835\udc38_ that are certifiably\npseudo-random, in the sense that they are uncorrelated with all possible label assignments,\n\n###### \ud835\udc9crand( \ud835\udc38, \ud835\udc45 ; \ud835\udf06 ) := \ud835\udc45 : \ud835\udc9clabel( \ud835\udc62 ), \ud835\udc9clabel( \ud835\udc63 ) \ud835\udc65 2 \u27e8 \ud835\udc62, \ud835\udc38\ud835\udc63 \u27e9 \u2a7d \ud835\udf06 \u00b7 \ud835\udc5b 2 [\ufffd] . (2.9) \ufffd\n\nHere, the auxiliary variables _\ud835\udc45_ represent the sum-of-squares certificate for the correlation\nbound. When we combine systems of polynomial constraints, we usually take these\nauxiliary variables to be unrelated. In this case, we do not keep track of these variables\nexplicitly and suppress them in the above notation. We emphasize that the system Eq. (2.9)\nhas only _\ud835\udc38_ and _\ud835\udc45_ as variables but not _\ud835\udc62_ or _\ud835\udc63_ . Instead _\ud835\udc62, \ud835\udc63_ determine the quadratic equations\nwe impose for the variables _\ud835\udc38_ and _\ud835\udc45_ . We also remark that Eq. (2.9) is a proxy for requiring\nthat _\ud835\udc38_ satisfies the universally quantified inequality Eq. (2.4). In this sense, Eq. (2.9) allows\nus to encode 2 _[\ud835\udc5b]_ constraints as a polynomial number of constraints.\n\n7\n\nWith the above two polynomial systems at hand, we can mimic the basic recovery\napproach by the following combined system, [3]\n\n\ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06_ ) := \ud835\udc9clabel( _\ud835\udc65_ ) \u222a\ud835\udc9crand( _\ud835\udf00_ _[\ud835\udc5b]_ _\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][;] _[ \ud835\udf06]_ [)] _[,]_ (2.10)\n\n###### where we choose \ud835\udf06 \u2272 1/( \ud835\udf00 \u221a \ud835\udc51 ). These constraints are useful for recovery because for the\n\nsame graph _\ud835\udc3a_, essentially only one label assignment _\ud835\udc65_ can satisfy the constraints. Concretely,\nwe have\n\ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06_ ) _,_ \ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ [\u2032] ; _\ud835\udf06_ ) _\ud835\udc3a,\ud835\udc65,\ud835\udc65_ 16 [\u2032] _\ud835\udc5b_ 1 [2] [\u27e8] _[\ud835\udc65, \ud835\udc65]_ [\u2032][\u27e9][2][ \u2a7e] [1][ \u2212] [2] _[\ud835\udf06]_ _[.]_ (2.11)\n\nWe emphasize that the above fact is deterministic and thus independent of any statistical\nmodel. Ignoring some details, its proof boils down to the following direct calculation,\n\n###### \ud835\udc5b [2] \u2212\u27e8 \ud835\udc65, \ud835\udc65 [\u2032] \u27e9 [2] = \ufffd \ud835\udc65\ud835\udc65 [T] \u2212( \ud835\udc65 [\u2032] )( \ud835\udc65 [\u2032] ) [T], \ud835\udc65\ud835\udc65 [T][\ufffd] = \ufffd \ud835\udc38 [\u2032] \u2212 \ud835\udc38, \ud835\udc65\ud835\udc65 [T][\ufffd] (2.12)\n\n= \u27e8 _\ud835\udc65, \ud835\udc38_ [\u2032] _\ud835\udc65_ \u27e9+ \u27e8\u2212 _\ud835\udc65, \ud835\udc38\ud835\udc65_ \u27e9 _,_ (2.13)\n\nwhere _\ud835\udc38_ = _[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and] _[ \ud835\udc38]_ [\u2032][ =] _\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212(] _[\ud835\udc65]_ [\u2032][)(] _[\ud835\udc65]_ [\u2032][)][T][. At the same time, the pseudorandomness]\n\nconstraints Eq. (2.9) allow us to bound both terms on the right in the same way by _\ud835\udf06_ - _\ud835\udc5b_ [2],\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and] _[ \ud835\udc38]_ [\u2032][ =] _\ud835\udf00_\n\nwhere _\ud835\udc38_ = _[\ud835\udc5b]_\n\n_\ud835\udc38_ [\u2032] _,\ud835\udc45,\ud835\udc65_ \u2032 2 T\n\ud835\udc9crand( _\ud835\udc38_ [\u2032] _, \ud835\udc45_ ; _\ud835\udf06_ ) _,_ \ud835\udc9clabel( _\ud835\udc65_ ) _\ud835\udc3f_ \u27e8 _\ud835\udc65, \ud835\udc38_ _\ud835\udc65_ \u27e9 = _\ud835\udf06\ud835\udc5b_ \u2212 Tr _\ud835\udc45\ud835\udc45_ - Mom2(\ud835\udc9clabel( _\ud835\udc65_ )) (2.14)\n###### \u2a7d \ud835\udf06\ud835\udc5b [2] . (2.15)\n\nIn the second step, we use that \ud835\udc9crand( _\ud835\udc38_ [\u2032] _, \ud835\udc45_ ) contains the constraint _\ud835\udf06_ - _\ud835\udc5b_ [2] \u2212\u27e8 _\ud835\udc62, \ud835\udc38_ [\u2032] _\ud835\udc63_ \u27e9 [2] =\nTr _\ud835\udc45\ud835\udc45_ [T] - Mom2(\ud835\udc9clabel( _\ud835\udc62_ ) _,_ \ud835\udc9clabel( _\ud835\udc63_ )), where _\ud835\udc62, \ud835\udc63_ are formal variables, and that we can\nsubstitute _\ud835\udc65_ for both _\ud835\udc62_ and _\ud835\udc63_ . In the third step, we use that Tr _\ud835\udc45\ud835\udc45_ [T] - Mom2(\ud835\udc9clabel( _\ud835\udc65_ )) is\na sum-of-squares polynomial in variables _\ud835\udc65_ and _\ud835\udc45_ modulo the constraints we have on\n_\ud835\udc65_ [4] . Combining the previous two calculations, we derive a bound of 2 _\ud835\udf06_ on the distance\n1 \u2212\u27e8 _\ud835\udc65, \ud835\udc65_ [\u2032] \u27e9 [2] / _\ud835\udc5b_ [2] from the constraints \ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ) _,_ \ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ [\u2032] ).\nThe stochastic block model ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ ) satisfies the constraints \ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06_ )\n###### for \ud835\udf06 \u2272 ( \ud835\udf00 \u221a \ud835\udc51 ) [\u2212][1] with high probability if \ud835\udf00 \u221a \ud835\udc51 \u226b 1 (even for constant degree \ud835\udc51 [GV16]). Thus,\n\n_\ud835\udc51_ ) [\u2212][1] with high probability if _\ud835\udf00_ \u221a\n\n###### for \ud835\udf06 \u2272 ( \ud835\udf00 \ud835\udc51 ) [\u2212] with high probability if \ud835\udf00 \ud835\udc51 \u226b 1 (even for constant degree \ud835\udc51 [GV16]). Thus,\n\nthe now standard proof-to-algorithm paradigm for sum-of-squares [DdNS22, DdHS23,\nMRW24] yields a polynomial-time algorithm to recover the underlying blocks up to an\n###### error of \ud835\udc42 [\ufffd] \ud835\udf00 \u221a \ud835\udc51 [\ufffd] [\u2212][1] .\n\n###### \ud835\udc51 [\ufffd] [\u2212][1] .\n\n**Handling node corruptions using sum-of-squares.** We will now see that the sum-ofsquares formulation Eq. (2.11) of the basic recovery approach directly implies that we can\nhandle a constant fraction of node corruptions.\n\n3In the constraint system \ud835\udc9cbasic we choose to treat the graph _\ud835\udc3a_ as a variable. As a consequence, our\nsum-of-squares proof will be for statements universally quantified over _\ud835\udc3a_ . While this property would not be\nnecessary for recovery in the non-robust setting, it will turn out to be crucial in the robust setting.\n4See Theorem A.6 for details\n\n8\n\nTo this end, we formulate the node distance between graphs in terms of polynomial\nequations,\n\n###### \ud835\udc9cclose( \ud835\udc3a 1, \ud835\udc3a 2, \ud835\udc67 ; \ud835\udf02 ) := \ufffdD( \ud835\udc67 ) [2] = D( \ud835\udc67 ), \ud835\udc37 ( \ud835\udc67 ) \u00b7 ( \ud835\udc3a 1 \u2212 \ud835\udc3a 2) \u00b7 D( \ud835\udc67 ) = 0, Tr D( \ud835\udc67 ) = (1 \u2212 \ud835\udf02 ) \u00b7 \ud835\udc5b \ufffd,\n\n(2.16)\nwhere _\ud835\udc37_ ( _\ud835\udc67_ ) denotes the diagonal matrix with _\ud835\udc67_ on the diagonal. A pair of graphs _\ud835\udc3a_ 1 and\n_\ud835\udc3a_ 2 satisfy the above constraints for some _\ud835\udc67_ if and only if the two graphs differ in at most\n_\ud835\udf02_ - _\ud835\udc5b_ nodes. Here, the binary vector _\ud835\udc67_ indicates the set of nodes, where the two graphs\nagree. As before, we will omit the auxiliary variables _\ud835\udc67_ in the above notation whenever\nthere are no relations to other variables.\n\nTo handle node corruptions, we use that \ud835\udc9cbasic is Lipschitz with respect to this node\ndistance and restrictions,\n\n_\ud835\udc3a,\ud835\udc3a_ [\u2032] _,\ud835\udc65,\ud835\udc67_\n###### \ud835\udc9cclose( \ud835\udc3a, \ud835\udc3a [\u2032], \ud835\udc67 ; \ud835\udf02 ), \ud835\udc9cbasic( \ud835\udc3a, \ud835\udc65 ; \ud835\udf06 ) 16 \ud835\udc9cbasic \ufffd D( \ud835\udc67 ) \u00b7 \ud835\udc3a [\u2032] \u00b7 D( \ud835\udc67 ), \ud835\udc65 ; \ud835\udf06 + 2 \ud835\udf02 [\ufffd] . (2.17)\n\nThe above statement is not surprising: If we have a good label assignment _\ud835\udc65_ for _\ud835\udc3a_, then it\ncontinues to be one if we were to remove a small fraction of nodes (the complement of the\nset indicated by _\ud835\udc67_ ). After removing this set of nodes, the two graphs _\ud835\udc3a_ and _\ud835\udc3a_ [\u2032] agree. (Note\nthat, in general, we cannot hope _\ud835\udc3a_ [\u2032] to satisfy the pseudorandomness constraints \ud835\udc9crand with\nrespect to _\ud835\udc65_ and that the restriction to the vertex set indicated by _\ud835\udc67_ is necessary.) Letting\n_\ud835\udc38_ = _[\ud835\udc5b]_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and] _[ \ud835\udc38]_ [\u2032][ =] _[\ud835\udc5b]_ [D] _[\ud835\udc67]_ _[ \ud835\udc3a]_ [\u2032][ \u00b7][ D] _[\ud835\udc67]_ _[\ud835\udc65\ud835\udc65]_ [T]\n\n_\ud835\udc38_ = _[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and] _[ \ud835\udc38]_ [\u2032][ =] _\ud835\udf00\ud835\udc51_ [D][(] _[\ud835\udc67]_ [) \u00b7] _[ \ud835\udc3a]_ [\u2032][ \u00b7][ D][(] _[\ud835\udc67]_ [) \u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and omitting some technical details, the]\n\nabove Lipschitz property follows from the fact,\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ and] _[ \ud835\udc38]_ [\u2032][ =] _\ud835\udf00_\n\n###### \ud835\udc9cclose( \ud835\udc3a, \ud835\udc3a [\u2032], \ud835\udc67 ; \ud835\udf02 ), \ud835\udc9clabel( \ud835\udc62 ), \ud835\udc9clabel( \ud835\udc63 ) 16 \u27e8 \ud835\udc62, \ud835\udc38 [\u2032] \ud835\udc63 \u27e9 \u2a7d \u27e8 \ud835\udc62, D( \ud835\udc67 ) \u00b7 \ud835\udc38 \u00b7 D( \ud835\udc67 ) \ud835\udc63 \u27e9+ 2 \ud835\udf02\ud835\udc5b [2], (2.18)\n\nwhere 2 _\ud835\udf02\ud835\udc5b_ [2] accounts for the entries where _\ud835\udc38_ [\u2032] and D( _\ud835\udc67_ ) \u00b7 _\ud835\udc38_ - D( _\ud835\udc67_ ) differ. Each of these entries\nis either 1 or \u22121 and is located in the union of _\ud835\udf02\ud835\udc5b_ rows and _\ud835\udf02\ud835\udc5b_ columns. Hence, the sum of\nthe absolute values of these entries is at most 2 _\ud835\udc5b_ [2] .\n_\ud835\udf02_\nGiven a corrupted graph _\ud835\udc3a_ corrupted as input, we can recover the underlying blocks using\nthe following polynomial constraints in variables _\ud835\udc3a_ and _\ud835\udc65_,\n\n\ud835\udc9crobust( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06, \ud835\udf02_ ) := \ud835\udc9cclose( _\ud835\udc3a, \ud835\udc3a_ corrupted; _\ud835\udf02_ ) \u222a\ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06_ + 4 _\ud835\udf02_ ) _._ (2.19)\n\nThe previous Lipschitz property of \ud835\udc9cbasic together with the vanilla analysis of \ud835\udc9cbasic for\nrecovery implies that any two solutions to the above system for the same input graph\n_\ud835\udc3a_ corrupted are close (and this fact has low-degree sum-of-squares proofs),\n\n\ud835\udc9crobust( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udf06, \ud835\udf02_ ) _,_ \ud835\udc9crobust( _\ud835\udc3a_ [\u2032] _, \ud835\udc65_ [\u2032] ; _\ud835\udf06, \ud835\udf02_ ) 16 1 \u2212 _\ud835\udc5b_ [1][2] [\u27e8] _[\ud835\udc65, \ud835\udc65]_ [\u2032][\u27e9][2][ \u2a7d] [2] _[\ud835\udf06]_ [+][ 8] _[\ud835\udf02]_ _[.]_ (2.20)\n\n_\ud835\udc3a_ and _\ud835\udc3a_ [\u2032] to be -close to _\ud835\udc3a_ _\ud835\udc3a_ and _\ud835\udc3a_ [\u2032]\nIndeed, since we impose both _\ud835\udf02_ corrupted, the graphs\n\nhave to be 2 _\ud835\udf02_ -close and we can derive \ud835\udc9cclose( _\ud835\udc3a, \ud835\udc3a_ [\u2032] _, \ud835\udc67_ ; 2 _\ud835\udf02_ ) for an appropriately chosen _\ud835\udc67_\nby a low-degree sum-of-squares proof. By the Lipschitz property of \ud835\udc9cbasic, we get that _\ud835\udc65_\nand _\ud835\udc65_ [\u2032] satisfy \ud835\udc9cbasic for the same graph _\ud835\udc3b_ := D( _\ud835\udc67_ ) \u00b7 _\ud835\udc3a_ - D( _\ud835\udc67_ ). Concretely, we can derive\n\n9\n\n\ud835\udc9cbasic( _\ud835\udc3b, \ud835\udc65_ ; _\ud835\udf06_ + 2 \u00b7 2 _\ud835\udf02_ ) and \ud835\udc9cbasic( _\ud835\udc3b, \ud835\udc65_ [\u2032] ; _\ud835\udf06_ + 2 \u00b7 2 _\ud835\udf02_ ) by Eq. (2.17) and conclude that _\ud835\udc65_ and _\ud835\udc65_ [\u2032]\n\nare close by Eq. (2.11). As before, Eq. (2.20) means that the sum-of-squares meta algorithm\nrecovers the underlying blocks with error _\ud835\udc42_ ( _\ud835\udf00_ ~~\u221a~~ _\ud835\udc51_ ) [\u2212][1] + _\ud835\udc42_ ( _\ud835\udf02_ ) for the stochastic block model\n\n_\ud835\udc51_ and bias _\ud835\udf00_ fraction of adversarial node\nwith degree parameter in the presence of an _\ud835\udf02_\ncorruptions, recovering one of the results of [LM22].\nThe algorithm obtained in this way is essentially the same as in [LM22] with only\nsuperficial differences. However, we believe the analyses differ substantially. While the\nanalysis in [LM22] requires significant ingenuity tailored to the particular algorithm, our\nanalysis in contrast is purely mechanical.\n\n**Boosting accuracy robustly.** While the techniques discussed so far capture up to constant\nfactors the information-theoretically necessary parameters to achieve small error, say error\nat most 0 _._ 01, they do not capture the optimal error rate.\nIn the non-robust setting, we can boost the accuracy of a solution with small error by\nseveral rounds of majority voting, where we assign each node the most common label\namong its neighbours. However, this strategy fails dramatically in the presence of node\ncorruptions. Concretely, even without changing the degrees of nodes, an adversary can\nfool majority voting by corrupting only an _\ud835\udc42_ ( _\ud835\udf02_ ) fraction of nodes [LM22].\n_\ud835\udc99_ and an\nFor simplicity, suppose that we start with the ground-truth label assignment\nadversary can select random vertex subsets _\ud835\udc46_ and _\ud835\udc47_ with | _\ud835\udc46_ | = _\ud835\udc42_ ( _\ud835\udf02\ud835\udc5b_ ) and | _\ud835\udc47_ | = _\ud835\udc5b_ /2. Then,\nthe adversary can use _\ud835\udc46_ to poison the votes for _\ud835\udc47_ by setting all edges from _\ud835\udc46_ to random\nnodes in _\ud835\udc47_ with the opposite label. This corruption flips the majority vote outcome for\nmost of the nodes in _\ud835\udc47_ with high probability. Hence, majority voting applied to _\ud835\udc99_ results in\n\n_\ud835\udc99_\nan assignment that agrees with in a random subset of roughly half of the nodes and thus\nhas large error.\nIn this example, a tiny fraction of nodes is responsible for roughly half of the majority\nvote outcomes. However, in a random-like graph, the expander mixing lemma certifies\nthat small fractions of nodes cannot change many majority vote outcomes. Concretely, in\nthe previous example, the expander mixing lemma implies for the uncorrupted graph that\nthe number of edges between _\ud835\udc46_ and _\ud835\udc47_ is _\ud835\udc5b_ _[\ud835\udc51]_ [|] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [| \u00b1] _[ \ud835\udc42]_ [(] _[\ud835\udc51]_ [\u00b7 |] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [|)][1][/][2][ =] [1] 2 _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_ [\u00b7 (][1][ \u00b1] _[ \ud835\udc42]_ [(] _[\ud835\udf00][\ud835\udc51]_ [)][\u2212][1][/][2][)][.]\n\nthe number of edges between _\ud835\udc46_ and _\ud835\udc47_ is _\ud835\udc5b_ _[\ud835\udc51]_ [|] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [| \u00b1] _[ \ud835\udc42]_ [(] _[\ud835\udc51]_ [\u00b7 |] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [|)][1][/][2][ =] [1] 2 _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_ [\u00b7 (][1][ \u00b1] _[ \ud835\udc42]_ [(] _[\ud835\udf00][\ud835\udc51]_ [)][\u2212][1][/][2][)][.]\n\n_\ud835\udf00\ud835\udc51\ud835\udc5b_\nOn the other hand, in the corrupted graph we have about edges between these sets,\nwhich is about two times larger than before the corruption as _\ud835\udf00\ud835\udc51_ \u226b _\ud835\udf00_ [2] _\ud835\udc51_ \u226b 1 when the\nblocks are recoverable.\n\nMore formally, we can limit the effect of small sets on majority vote outcomes if we have\na label assignment _\ud835\udc65_ consistent with the majority votes for most of the nodes such that the\nmatrix _\ud835\udc38_ = _[\ud835\udc5b]_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T]\n\n_[\ud835\udc51]_ [1]\n\n_\ud835\udc5b_ [|] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [| \u00b1] _[ \ud835\udc42]_ [(] _[\ud835\udc51]_ [\u00b7 |] _[\ud835\udc46]_ [| \u00b7 |] _[\ud835\udc47]_ [|)][1][/][2][ =] 2\n\nmatrix _\ud835\udc38_ = _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ satisfies the following pseudorandomness constraints, strengthening]\n\ud835\udc9crand( _\ud835\udc38, \ud835\udc45_ ; _\ud835\udf06_ ),\n\n###### \ud835\udc9cmix( \ud835\udc38, \ud835\udc45 ; \ud835\udf06 ) := \ud835\udc45 : \ud835\udc62,\ud835\udc63 2 \u27e8 \ud835\udc62, \ud835\udc38\ud835\udc63 \u27e9 \u2a7d \ud835\udf06\ud835\udc5b \u00b7 12 [(\u2225] [\ud835\udc62] [\u2225][2][ + \u2225] [\ud835\udc63] [\u2225][2][)] . (2.21) \ufffd \ufffd\n\nSince the previous pseudorandomness constraints \ud835\udc9crand defined in Eq. (2.9) consider\nvectors _\ud835\udc62, \ud835\udc63_ with \u2225 _\ud835\udc62_ \u2225 = \u2225 _\ud835\udc63_ \u2225 = [\u221a] _\ud835\udc5b_, the above normalization for _\ud835\udf06_ is the same as in Eq. (2.9).\n\n10\n\nWe remark that due to the characterization of the above inequality in terms of matrix\n###### factorizations an equivalent formulation of the above system would be \ufffd \ud835\udc45\ud835\udc45 [T] = \ud835\udf06\ud835\udc5b \u00b7 \ud835\udc3c\ud835\udc5b \u2212 \ud835\udc38 \ufffd.\n\nWe use the following polynomial constraints to encode that _\ud835\udc65_ is consistent with the majority\nvotes for most of the nodes,\n\n_\ud835\udc67_\n###### \ud835\udc9cmaj( \ud835\udc3a, \ud835\udc65, \ud835\udc45 ; \ud835\udefd, \ud835\udefe ) := \ud835\udc45 : \ud835\udc9cset( \ud835\udc67 ) 2 \u27e8 \ud835\udc37 ( \ud835\udc67 ) \ud835\udc65, \ud835\udc3a\ud835\udc65 \u27e9 \u2a7e (1 \u2212 \ud835\udefe ) \ud835\udf00\ud835\udc51 [\ufffd] | \ud835\udc67 | \u2212 \ud835\udefd\ud835\udc5b [\ufffd\ufffd], (2.22) \ufffd\n\nwhere | _\ud835\udc67_ | = _\ud835\udc67_ 1 + \u00b7 \u00b7 \u00b7 + _\ud835\udc67\ud835\udc5b_ and \ud835\udc9cset( _\ud835\udc67_ ) := {\ud835\udc9f( _\ud835\udc67_ ) [2] = D( _\ud835\udc67_ )}. Note that for the stochastic block\nmodel ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ ), we expect that ( _\ud835\udc3a\ud835\udc65_ ) _\ud835\udc56_ \u2248 _\ud835\udf00\ud835\udc51_ - _\ud835\udc65\ud835\udc56_ for most nodes _\ud835\udc56_ \u2208[ _\ud835\udc5b_ ]. Since\nthe inequality in Eq. (2.22) is linear subject to simple constraints, sum-of-squares proofs\ncapture all valid inequalities of this type up to a small error. If the inequality in Eq. (2.22)\n###### is valid, then we can have at most \ud835\udefd\ud835\udc5b / \ud835\udefe nodes \ud835\udc56 with ( \ud835\udc3a\ud835\udc65 ) \ud835\udc56 \u00b7 \ud835\udc65\ud835\udc56 \u2a7d (1 \u2212 2 \ud835\udefe ) \ud835\udf00\ud835\udc51 . At the same time, if the entries ( \ud835\udc3a\ud835\udc65 ) \ud835\udc56 with ( \ud835\udc3a\ud835\udc65 ) \ud835\udc56 \u00b7 \ud835\udc65\ud835\udc56 \u2a7d (1 \u2212 \ud835\udefe ) \ud835\udf00\ud835\udc51 sum [5] in absolute value to at most \ud835\udefd\ud835\udc5b,\n\nthen the above inequality is valid.\nLiu and Moitra [LM22] show that the stochastic block model satisfies the above\n###### constraints for \ud835\udf06 \u2272 ( \ud835\udf00 \u221a \ud835\udc51 ) [\u2212][1] and ln 1/ \ud835\udefd \u2248 \ud835\udc5c (1) \ud835\udefe\ud835\udc36\ud835\udc51,\ud835\udf00 /2 with high probability (after removing\n\na negligible number of nodes). They also provide an iterative algorithm that boosts the\naccuracy of a solution to a rate that is asymptotically optimal.\nSimplifying their approach significantly, we show that the sum-of-squares metaalgorithm can boost to such a rate in one shot. To this end, we combine the previous\nconstraints as follows,\n\n\ud835\udc9cboost( _\ud835\udc3a, \ud835\udc65_ ) := \ud835\udc9cmix( _\ud835\udf00_ _[\ud835\udc5b]_ _\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][;] _[ \ud835\udf06]_ [) \u222a\ud835\udc9c][maj][(] _[\ud835\udc3a, \ud835\udc65]_ [;] _[ \ud835\udefd]_ [1] _[,][ \ud835\udefe]_ [1][) \u222a\ud835\udc9c][maj][(] _[\ud835\udc3a, \ud835\udc65]_ [;] _[ \ud835\udefd]_ [2] _[,][ \ud835\udefe]_ [2][)] _[,]_ (2.23)\n\n###### where we choose \ud835\udf06 \u2272 ( \ud835\udf00 \u221a\n\n###### where we choose \ud835\udf06 \u2272 ( \ud835\udf00 \u221a \ud835\udc51 ) [\u2212][1], \ud835\udefe 1 = 0 . 01, \ud835\udefd 1 = \ud835\udf06, \ud835\udefe 2 = 1 \u2212 10 \ud835\udf06, and \ud835\udefd 2 = exp(\u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 /2 +\n\n_\ud835\udf12_ \u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ) for some sufficiently large absolute constant _\ud835\udf12_ . The following property of these\n\n_\ud835\udf12_ \u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ) for some sufficiently large absolute constant _\ud835\udf12_ . The following property of these\n\nconstraints allows us to boost the accuracy of a solution,\n\n_\ud835\udc5b_ 1 [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [0] _[.]_ [01] _[,]_ [ \ud835\udc9c][boost][(] _[\ud835\udc3a, \ud835\udc65]_ [)] _[,]_ [ \ud835\udc9c][boost][(] _[\ud835\udc3a, \ud835\udc65]_ [\u2032][)] _\ud835\udc3a,\ud835\udc65,\ud835\udc65_ [\u2032] _\ud835\udc5b_ 1 [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [exp] \u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ) _._\n###### \ufffd \ufffd\n\n(2.24)\nFor similar reasons as before, we can use Lipschitz and restriction properties of these\nconstraints in order to obtain error bounds in the robust setting at the cost of an additional\n_\ud835\udc42_ ( _\ud835\udf02_ ) error for an _\ud835\udc42_ ( _\ud835\udf02_ ) fraction of node corruptions.\n###### Toward establishing Eq. (2.24), we consider the vector \ud835\udc67 with \ud835\udc67\ud835\udc56 = 14 \ufffd \ud835\udc65\ud835\udc56 \u2212 \ud835\udc65 [\u2032] \ud835\udc56 \ufffd 2.\n\nSince _\ud835\udc65_ and _\ud835\udc65_ [\u2032] have coordinates in {\u00b11}, the vector _\ud835\udc67_ has coordinates in {0 _,_ 1}. Indeed,\n\ud835\udc9clabel( _\ud835\udc65_ ) _,_ \ud835\udc9clabel( _\ud835\udc65_ [\u2032] ) \ud835\udc9cset( _\ud835\udc67_ ). Furthermore, the vector _\ud835\udc67_ also satisfies D( _\ud835\udc67_ ) _\ud835\udc65_ = \u2212 D( _\ud835\udc67_ ) _\ud835\udc65_ [\u2032]\n\n1\n_\ud835\udc5b_ [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [0] _[.]_ [01] _[,]_ [ \ud835\udc9c][boost][(] _[\ud835\udc3a, \ud835\udc65]_ [)] _[,]_ [ \ud835\udc9c][boost][(] _[\ud835\udc3a, \ud835\udc65]_ [\u2032][)]\n\n_\ud835\udc3a,\ud835\udc65,\ud835\udc65_ [\u2032] _\ud835\udc5b_ 1 [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [exp] \u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a\n###### \ufffd\n\nand _\ud835\udc65_ \u2212 _\ud835\udc65_ [\u2032] = D( _\ud835\udc67_ ) \u00b7 ( _\ud835\udc65_ \u2212 _\ud835\udc65_ [\u2032] ) because _\ud835\udc67_ indicates the set of coordinates, where _\ud835\udc65_ and _\ud835\udc65_ [\u2032] differ.\nNow since the labelings _\ud835\udc65_ and _\ud835\udc65_ [\u2032] agree in at least a 0 _._ 99 fraction of the nodes, the\nmajority voting based on _\ud835\udc65_ or _\ud835\udc65_ [\u2032] will agree in all but a _\ud835\udefd_ fraction of the nodes (when there is\n\n5Note that for random-like graphs, the expander mixing lemma implies a bound on the sum of these\nentries as soon as we have a bound on the number of entries with ( _\ud835\udc3a\ud835\udc65_ ) _\ud835\udc56_ with ( _\ud835\udc3a\ud835\udc65_ ) _\ud835\udc56_ - _\ud835\udc65\ud835\udc56_ \u2a7d (1 \u2212 _\ud835\udefe_ ) _\ud835\udf00\ud835\udc51_ .\n\n11\n\nno node corruption). This gives us the intuition that the constraints from expander mixing\nlemmas (namely \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udefd, \ud835\udefe_ ) and \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ [\u2032] ; _\ud835\udefd, \ud835\udefe_ )) ensure that _\ud835\udc65_ and _\ud835\udc65_ [\u2032] are close to\neach other in distance _\ud835\udefd_ .\nConcretely, using these relations between _\ud835\udc67_, _\ud835\udc65_, and _\ud835\udc65_ [\u2032] together with majority-voting\nconsistency constraints \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udefd, \ud835\udefe_ ) and \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ [\u2032] ; _\ud835\udefd, \ud835\udefe_ ), we get\n\n(1 \u2212 _\ud835\udefe_ ) _\ud835\udf00\ud835\udc51_ (| _\ud835\udc67_ | \u2212 _\ud835\udefd\ud835\udc5b_ )\n\n\ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udefd, \ud835\udefe_ ) _,_ \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ [\u2032] ; _\ud835\udefd, \ud835\udefe_ )\n\n_\ud835\udc3a,\ud835\udc65,\ud835\udc65_ [\u2032]\n\n###### \u2a7d [1] 2 \u27e8D( \ud835\udc67 ) \ud835\udc65, \ud835\udc3a\ud835\udc65 \u27e9+ \u27e8D( \ud835\udc67 ) \ud835\udc65 [\u2032], \ud835\udc3a\ud835\udc65 [\u2032] \u27e9 \ufffd \ufffd\n\n= [1]\n\n2 [\u27e8][D][(] _[\ud835\udc67]_ [)] _[\ud835\udc65, \ud835\udc3a]_ [(] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][)\u27e9]\n\n= \u27e8D( _\ud835\udc67_ ) _\ud835\udc65, \ud835\udc3a_ D( _\ud835\udc67_ ) _\ud835\udc65_ \u27e9 _._\n\nWe can upper bound the quantity on the right using the constraints \ud835\udc9cmix( _\ud835\udc38_ ; _\ud835\udf06_ ) for the\nmatrix _\ud835\udc38_ = _[\ud835\udc5b]_\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [\u2212] _[\ud835\udc65\ud835\udc65]_ [T][ as well as the label-assignment and set constraints for] _[ \ud835\udc65]_ [and] _[ \ud835\udc67]_ [,]\n\n\ud835\udc9cmix( _\ud835\udc38_ ; _\ud835\udf06_ ) _,_ \ud835\udc9cset( _\ud835\udc67_ ) _,_ \ud835\udc9clabel( _\ud835\udc65_ )\n\n_\ud835\udc38,\ud835\udc67,\ud835\udc65_\n\u27e8D( _\ud835\udc67_ ) _\ud835\udc65, \ud835\udc3a_ D( _\ud835\udc67_ ) _\ud835\udc65_ \u27e9\n\n###### = [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd\u27e8 \ud835\udc65, D( \ud835\udc67 ) \ud835\udc65 \u27e9 [2] + \u27e8D( \ud835\udc67 ) \ud835\udc65, \ud835\udc38 D( \ud835\udc67 ) \ud835\udc65 \u27e9 [\ufffd] \u2a7d [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd\u2225D( \ud835\udc67 ) \ud835\udc65 \u2225 [4] + \ud835\udf06\ud835\udc5b \u00b7 \u2225D( \ud835\udc67 ) \ud835\udc65 \u2225 [2][\ufffd] = [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd| \ud835\udc67 | [2] + \ud835\udf06\ud835\udc5b \u00b7 | \ud835\udc67 | [\ufffd]\n\nCombining the lower and upper bounds on \u27e8D( _\ud835\udc67_ ) _\ud835\udc65, \ud835\udc3a_ D( _\ud835\udc67_ ) _\ud835\udc65_ \u27e9, we get the following upper\nbound on | _\ud835\udc67_ |,\n\n\ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ ; _\ud835\udefd, \ud835\udefe_ ) _,_ \ud835\udc9cmaj( _\ud835\udc3a, \ud835\udc65_ [\u2032] ; _\ud835\udefd, \ud835\udefe_ ) _,_ \ud835\udc9cmix( _\ud835\udc38_ ; _\ud835\udf06_ ) _,_ \ud835\udc9cset( _\ud835\udc67_ ) _,_ \ud835\udc9clabel( _\ud835\udc65_ ) _,_ \ud835\udc9clabel( _\ud835\udc65_ [\u2032] ) (2.25)\n\n_\ud835\udc3a,\ud835\udc65,\ud835\udc65_ [\u2032] _,\ud835\udc38,\ud835\udc67,\ud835\udc65_ 1\n| _\ud835\udc67_ | \u2a7d _\ud835\udefd\ud835\udc5b_ + (1\u2212 _\ud835\udefe_ \u2212 _\ud835\udf06_ ) _\ud835\udc5b_ [|] _[\ud835\udc67]_ [|][2] _[ .]_ (2.26)\n\nWhile this bound alone is not enough to conclude an absolute bound on | _\ud835\udc67_ |, it does allow\n\n1 2\n###### us to boost assumed bounds on | \ud835\udc67 |. Suppose \ud835\udefe + \ud835\udf06 \u2a7d 1 and \ud835\udf06 \u2a7d [1] 2 [(][1][ \u2212] [\ud835\udefe] [)][. Then,] 1\u2212 \ud835\udefe \u2212 \ud835\udf06 [\u2a7d] 1\u2212 \ud835\udefe [.]\n\nMoreover, if we add the constraint | _\ud835\udc67_ | \u2a7d [1][\u2212] _[\ud835\udefe]_\n\nMoreover, if we add the constraint | _\ud835\udc67_ | \u2a7d 4 _[\ud835\udc5b]_ [to the previous constraints, we can derive]\n\n(1\u2212 _\ud835\udefe_ 1\u2212 _\ud835\udf06_ ) _\ud835\udc5b_ [|] _[\ud835\udc67]_ [|][2][ \u2a7d] 2 [1][|] _[\ud835\udc67]_ [|][ and thus, by subtracting] [1] 2 [|] _[\ud835\udc67]_ [|][ from both sides of the inequality][ Eq. (2.25)][,]\n\n[1] [1]\n\n2 [|] _[\ud835\udc67]_ [|][ and thus, by subtracting] 2\n\n2 [|] _[\ud835\udc67]_ [|][ from both sides of the inequality][ Eq. (2.25)][,]\n\n| _\ud835\udc67_ | \u2a7d [1][\u2212] 4 _[\ud835\udefe]_ _[\ud835\udc5b,]_ [ |] _[\ud835\udc67]_ [|][ \u2a7d] _[\ud835\udefd][\ud835\udc5b]_ [+] (1\u2212 _\ud835\udefe_ 1\u2212 _\ud835\udf06_ ) _\ud835\udc5b_ [|] _[\ud835\udc67]_ [|][2] _\ud835\udc67_ | _\ud835\udc67_ | \u2a7d 2 _\ud835\udefd\ud835\udc5b._ (2.27)\n\n###### Our target derivation Eq. (2.24) contains the inequality | \ud835\udc67 | = \u2225 \ud835\udc65 \u2212 \ud835\udc65 [\u2032] \u2225 [2] \u2a7d 0 . 01 \ud835\udc5b as an\n\ninitial assumption. Hence, we get to assume | _\ud835\udc67_ | \u2a7d [1][\u2212] 4 _[\ud835\udefe]_ [1] _[\ud835\udc5b]_ [from the get-go as] _[ \ud835\udefe]_ [1][ =][ 0] _[.]_ [01][. By]\n\ninitial assumption. Hence, we get to assume | _\ud835\udc67_ | \u2a7d 4 _[\ud835\udc5b]_ [from the get-go as] _[ \ud835\udefe]_ [1][ =][ 0] _[.]_ [01][. By]\n\nsubstituting _\ud835\udefe_ 1 and _\ud835\udefd_ 1 for _\ud835\udefe_ and _\ud835\udefd_ in Eq. (2.27), we derive | _\ud835\udc67_ | \u2a7d 2 _\ud835\udefd_ 1 _\ud835\udc5b_ . Since _\ud835\udefe_ 2 = 1 \u2212 2 _\ud835\udf06_ \u2212 8 _\ud835\udefd_ 1,\nwe can compose this derivation with Eq. (2.27) with _\ud835\udefe_ 2 and _\ud835\udefd_ 2 substituted for _\ud835\udefd_ and _\ud835\udefe_ .\nIn this way, we derive the desired bound | _\ud835\udc67_ | \u2a7d _\ud835\udefd_ 2 _\ud835\udc5b_ for ln _\ud835\udefd_ 2 = \u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ) on the\n\nIn this way, we derive the desired bound | _\ud835\udc67_ | \u2a7d _\ud835\udefd_ 2 _\ud835\udc5b_ for ln _\ud835\udefd_ 2 = \u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ) on the\n\ndistance between the label assignments _\ud835\udc65_ and _\ud835\udc65_ [\u2032] .\n\n12\n\n**Concluding the two-community case.** Using the polynomial constraints and sum-ofsquares proofs discussed so far, we obtain a polynomial-time algorithm based on the sumof-squares method for robust recovery in stochastic block models with two communities up\n###### to asymptotically optimal error. Concretely, supposing \ud835\udc51 \u2a7e \ud835\udc42 (1/ \ud835\udf00 [2] ), we use the constraints\n\n\ud835\udc9crobust described in Eq. (2.19) in order to obtain with high probability a label assignment\n_\ud835\udc65_ \u02dc \u2208{\u00b11} _[\ud835\udc5b]_ with error at most 0 _._ 005 _\ud835\udc5b_ . Then, we solve the sum-of-squares program for the\nfollowing combination of constraints discussed in this paragraph,\n\n###### \ud835\udc9crobust\u2212boost( \ud835\udc3a, \ud835\udc65 ; \ud835\udf02 ) := \ud835\udc9cclose( \ud835\udc3a, \ud835\udc3a corrupted; \ud835\udf02 ) \u222a \ufffd\u2225 \ud835\udc65 \u2212\u02dc \ud835\udc65 \u2225 [2] \u2a7d 0 . 005 \ud835\udc5b \ufffd\n\n\u222a\ud835\udc9cboost( _\ud835\udc3a, \ud835\udc65_ ) _._\n\n(2.28)\n\nHere, _\ud835\udc3a_ corrupted is the _\ud835\udf02_ -node-corrupted input graph and \u02dc _\ud835\udc65_ is the rough label assignment\nwith error at most 0 _._ 005 obtained in the preprocessing phase of the algorithm. As discussed\nbefore, the stochastic block model ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ ) satisfies the above constraints with\n_\ud835\udc6e_ when we substitute _\ud835\udc6e_ and _\ud835\udc99_ for _\ud835\udc3a_\nhigh-probability uniformly for all _\ud835\udf02_ -corruptions on\nand _\ud835\udc65_ (after pruning a tiny fraction of nodes with high degree). By Eq. (2.24), any two\nsolutions _\ud835\udc65_ and _\ud835\udc65_ [\u2032] for the same graph _\ud835\udc3a_ are exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ))-close. (While our\n\nsolutions _\ud835\udc65_ and _\ud835\udc65_ [\u2032] for the same graph _\ud835\udc3a_ are exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ /2 + _\ud835\udc42_ (\u221a _\ud835\udc36_ _\ud835\udc51,\ud835\udf00_ ))-close. (While our\n\nconstraints do not include the inequality _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [0] _[.]_ [01][, we can derive it directly from]\n\nconstraints do not include the inequality _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u2032][\u2225][2][ \u2a7d] [0] _[.]_ [01][, we can derive it directly from]\n\nthe two included inequalities _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2212\u02dc] _[\ud835\udc65]_ [\u2225][2][ \u2a7d] [0] _[.]_ [005][ and] _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2032][ \u2212\u02dc] _[\ud835\udc65]_ [\u2225][2][ \u2a7d] [0] _[.]_ [005][ by] _[ \u2113]_ 2 [2] [triangle]\n\n[1] [1]\n\n_\ud835\udc5b_ [\u2225] _[\ud835\udc65]_ [\u2212\u02dc] _[\ud835\udc65]_ [\u2225][2][ \u2a7d] [0] _[.]_ [005][ and] _\ud835\udc5b_\n\nthe two included inequalities _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2212\u02dc] _[\ud835\udc65]_ [\u2225][2][ \u2a7d] [0] _[.]_ [005][ and] _\ud835\udc5b_ [1] [\u2225] _[\ud835\udc65]_ [\u2032][ \u2212\u02dc] _[\ud835\udc65]_ [\u2225][2][ \u2a7d] [0] _[.]_ [005][ by] _[ \u2113]_ 2 [2] [triangle]\n\ninequality.) By restriction arguments analogous to Eq. (2.17), we can allow for _\ud835\udf02_ -close\ngraphs _\ud835\udc3a_ and _\ud835\udc3a_ [\u2032] at the cost of an additional _\ud835\udc42_ ( _\ud835\udf02_ ) error.\nWe emphasize that this algorithm relies on the same structural properties of the\nstochastic block model as the algorithm by Liu and Moitra [LM22]. Concretely, both\nalgorithms try to rule out a small fraction of nodes swaying a disproportionate number of\nmajority vote outcomes. However, the final algorithms end up being quite different. While\nour algorithm and its analysis exploit the structural properties directly and don\u2019t require\nadditional concepts besides the generic SOS framework, Liu and Moitra introduce several\nnon-trivial technical tools such as the notion of resolvable matrices. Furthermore, they\nneed to keep track of invariants satisfied throughout the iterations of their algorithm. Our\nalgorithm avoids this complication by boosting to \u201cfull accuracy\u201d in one shot.\n\n##### **2.2 More than two communities**\n\nIn order to obtain high-accuracy label assignments for more than two communities, we\ncan extend the basic recovery approach. For _\ud835\udc58_ communities, we consider the stochastic\nblock model ( _\ud835\udc6e, \ud835\udc99_ ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ). Here, _\ud835\udc99_ is a random balanced assignment of labels\nfrom [ _\ud835\udc58_ ] to nodes [ _\ud835\udc5b_ ]. In particular, the blocks / communities are random subsets of nodes\nwith | _\ud835\udc99_ [\u2212][1] (1)| = \u00b7 \u00b7 \u00b7 = | _\ud835\udc99_ [\u2212][1] ( _\ud835\udc58_ )| = _[\ud835\udc5b]_ _\ud835\udc58_ [. For every pair of distinct nodes] _[ \ud835\udc56, \ud835\udc57]_ [\u2208[] _[\ud835\udc5b]_ []][, we decide]\n\nindependently at random whether to join them by an edge with probability,\n\n###### \u2119\ufffd \ud835\udc56\ud835\udc57 \u2208 \ud835\udc38 ( \ud835\udc6e ) \ufffd\ufffd \ud835\udc99 \ufffd =\n\n1 + (1 \u2212 [1] _\ud835\udc58_\n###### \ufffd\ufffd\ufffd1 \u2212 [1] \ud835\udc58 [\u00b7] [ \ud835\udf00] [\ufffd]\n\n###### 1 + (1 \u2212 \ud835\udc58 [)] [\ud835\udf00] [\ufffd] \u00b7 \ud835\udc5b if \ud835\udc99 ( \ud835\udc56 ) = \ud835\udc99 ( \ud835\udc57 ), \ufffd1 \u2212 [1] \ud835\udc58 [\u00b7] [ \ud835\udf00] [\ufffd] \u00b7 \ud835\udc5b [\ud835\udc51] if \ud835\udc99 ( \ud835\udc56 ) \u2260 \ud835\udc99 ( \ud835\udc57 ).\n\n[1] - _[\ud835\udc51]_\n###### \ud835\udc58 [\u00b7] [ \ud835\udf00] [\ufffd] \ud835\udc5b\n\n[1] - _[\ud835\udc51]_\n###### \ud835\udc58 [)] [\ud835\udf00] [\ufffd] \ud835\udc5b\n\n_\ud835\udc5b_ (2.29)\n\n_\ud835\udc5b_ _[\ud835\udc51]_ if _\ud835\udc99_ ( _\ud835\udc56_ ) \u2260 _\ud835\udc99_ ( _\ud835\udc57_ ).\n\n13\n\nFor _\ud835\udc58_ = 2, the above model SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00,_ 2) corresponds to the previously introduced model\nSBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00_ /2). The Kesten-Stigum threshold for this model, conjectured to coincide with\nthe computational threshold for weak recovery, is _\ud835\udc51_ _> \ud835\udc58_ [2] / _\ud835\udf00_ [2] [AS15, Hop18, BBK [+] 21, SW25].\nIndeed, for _[\ud835\udf00]_ _\ud835\udc58_ [2][2] _[\ud835\udc51]_ [\u2192\u221e] [and sufficiently large] _[ \ud835\udc5b]_ [, we know of polynomial-time algorithms that]\n\nachieve error tending to 0 (but not necessarily at an optimal rate) [GV16].\n\n**Rough initialization.** First, we briefly describe a sum-of-squares formulation that achieves\nvanishing error under the above condition for more than two communities. We denote the\nconstraints for balanced label assignments as follows,\n\n_\ud835\udc65_ ( _\ud835\udc56, \ud835\udc4e_ ) = _[\ud835\udc5b]_ _\ud835\udc58_\n\n_\ud835\udc56_\n\n\ud835\udc9clabel( _\ud835\udc65_ ) :=\n\n###### \ufffd\n\n_\ud835\udc65_ ( _\ud835\udc56, \ud835\udc4e_ ) [2] = _\ud835\udc65_ ( _\ud835\udc56, \ud835\udc4e_ ) _,_\n###### \ufffd\n\n_\ud835\udc65_ ( _\ud835\udc56, \ud835\udc4e_ ) = 1 _,_\n###### \ufffd\n\n_\ud835\udc4e_ _\ud835\udc56_\n\n_\ud835\udc58_\n\n###### \ufffd\n\n_._ (2.30)\n\nHere _\ud835\udc65_ \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ and we denote by _\ud835\udc65\ud835\udc4e_ the vector with entries _\ud835\udc65_ (1 _, \ud835\udc4e_ ) _, . . ., \ud835\udc65_ ( _\ud835\udc5b, \ud835\udc4e_ ) indicating\nthe set of nodes assigned label _\ud835\udc4e_ .\nWe consider the following constraints as analogue for basic recovery,\n\n\ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ ) := \ud835\udc9clabel( _\ud835\udc65_ ) \u222a\ud835\udc9cmix( _\ud835\udc38_ ; _\ud835\udf06_ ) _,_ (2.31)\n\n_[\ud835\udc5b]_ [1]\n\n_\ud835\udf00\ud835\udc51_ _[\ud835\udc3a]_ [+] _\ud835\udc58_\n\nwhere _\ud835\udc38_ := _[\ud835\udc5b]_\n\n###### [1] \ud835\udc58 [1 1] [ T][ \u2212] [\ufffd] \ud835\udc4e [\ud835\udc58] =1 [(] [\ud835\udc65][\ud835\udc4e] [)(] [\ud835\udc65][\ud835\udc4e] [)][T][ and] [ \ud835\udf06] [\u2272] [(] [\ud835\udf00] \u221a\n\n_\ud835\udc51_ ) [\u2212][1] . Suppose we have two solutions\n\n###### \ud835\udc65 [(][1][)] and \ud835\udc65 [(][2][)] of the above constraints for the same graph \ud835\udc3a . Let \ud835\udc4b [(] [\ud835\udc61] [)] := [\ufffd] \ud835\udc4e [\ud835\udc58] =1 \ud835\udc65 [(] \ud835\udc4e [\ud835\udc61] [)] \ud835\udc65 [(] \ud835\udc4e [\ud835\udc61] [)] T for \ufffd \ufffd\ufffd \ufffd\n\n_\ud835\udc61_ \u2208{1 _,_ 2}. Then,\n\n\u2225 _\ud835\udc4b_ [(][1][)] \u2212 _\ud835\udc4b_ [(][2][)] \u2225 [2] F [=][ \u27e8] _[\ud835\udc38]_ [(][2][)][ \u2212] _[\ud835\udc38]_ [(][1][)] _[, \ud835\udc4b]_ [(][1][)][ \u2212] _[\ud835\udc4b]_ [(][2][)][\u27e9] (2.32)\n\n\u27e8 _\ud835\udc65_ [(] _\ud835\udc4e_ [1][)] _[,]_ [ (] _[\ud835\udc38]_ [(][2][)][ \u2212] _[\ud835\udc38]_ [(][1][)][)] _[\ud835\udc65]_ [(] _\ud835\udc4e_ [1][)][\u27e9+]\n###### \ufffd\n\n_\ud835\udc4e_ _\ud835\udc4e_\n\n###### \u2a7d \ufffd\n\n\u27e8\u2212 _\ud835\udc65_ [(] _\ud835\udc4e_ [2][)] _[,]_ [ (] _[\ud835\udc38]_ [(][2][)][ \u2212] _[\ud835\udc38]_ [(][1][)][)] _[\ud835\udc65]_ [(] _\ud835\udc4e_ [2][)][\u27e9] (2.33)\n\n_\ud835\udc4e_\n\n###### \u2a7d 2 \ud835\udf06\ud835\udc5b \u00b7\n\n_\ud835\udc58_\n\n\u2225 _\ud835\udc65\ud835\udc4e_ \u2225 [2] = 2 _\ud835\udf06\ud835\udc5b_ [2] _,_ (2.34)\n###### \ufffd\n\n_\ud835\udc4e_ =1\n\n_\ud835\udc5b_\n###### where \ud835\udc38 [(] [\ud835\udc61] [)] := \ud835\udf00\ud835\udc51 [\ud835\udc3a] [+] [1] \ud835\udc58 [1 1] [ T][ \u2212] [\ufffd] \ud835\udc4e [\ud835\udc58] =1 [(] [\ud835\udc65] [(] \ud835\udc4e [\ud835\udc61] [)][)(] [\ud835\udc65] [(] \ud835\udc4e [\ud835\udc61] [)][)][T][ for] [ \ud835\udc61] [\u2208{][1] [,] [ 2][}][. Since the derivation][ Eq. (2.32)]\n\nuses only steps captured by the sum-of-squares proof system, we obtain an SOS proof for\nthe following error bound,\n\n_\ud835\udc3a,\ud835\udc65_ [(][1][)] _,\ud835\udc65_ [(][2][)]\n\ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ [(][1][)] ) _,_ \ud835\udc9cbasic( _\ud835\udc3a, \ud835\udc65_ [(][2][)] ) 2\n\n###### \u2225 \ud835\udc4b [(][1][)] \u2212 \ud835\udc4b [(][2][)] \u2225 [2] F [\u2a7d] [2] [\ud835\udf06][\ud835\udc5b] [2] [ .] (2.35)\n\nSince \u2225 _\ud835\udc4b_ [(][1][)] \u2225 [2] F [=][ \u2225] _[\ud835\udc4b]_ [(][2][)][\u2225][2] F [=] _[ \ud835\udc5b]_ [2][/] _[\ud835\udc58]_ [, the above error bounds allow us to recover the] _[ \ud835\udc58]_ [communi-]\nties with small error whenever 1 \u226a( _\ud835\udc58\ud835\udf06_ ) [\u2212][2] = _\ud835\udf00_ [2] _\ud835\udc51_ / _\ud835\udc58_ [2] . Furthermore, there is also a robust\nversion of this sum-of-squares proof (see Theorem 6.2)\n\n_\ud835\udc3a_ 1 _,\ud835\udc3a_ 2 _,\ud835\udc65_ [(][1][)] _,\ud835\udc65_ [(][2][)]\n###### \ud835\udc9cclose( \ud835\udc3a 1, \ud835\udc3a 2; \ud835\udf02 ), \ud835\udc9cbasic( \ud835\udc3a 1, \ud835\udc65 [(][1][)] ), \ud835\udc9cbasic( \ud835\udc3a 2, \ud835\udc65 [(][2][)] ) 4 \u2225 \ud835\udc4b [(][1][)] \u2212 \ud835\udc4b [(][2][)] \u2225 [2] F [\u2a7d] [2] [\ud835\udf06][\ud835\udc5b] [2][+] [\ud835\udc42] [(] [\ud835\udf02] [/] [\ud835\udc58] [)\u00b7] [\ud835\udc5b] [2] [ .]\n\n(2.36)\nThe above sum-of-squares proof directly implies a polynomial-time algorithm to robustly\nrecover communities for stochastic block models with more than two communities (under\nnode corruptions).\n\n14\n\n**Boosting accuracy for more than two communities.** While the rough initialization allow\nus to recover a label assignment with error at most 0 _._ 001 when _\ud835\udc51_ \u226b _\ud835\udc58_ [2] / _\ud835\udf00_ [2], we aim to boost\nthe error close to the asymptotically optimal bound exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ). A natural extension\nof the previous majority voting strategy would assign to every node the most common\nlabel among its neighbours. For this strategy to succeed, even without node corruptions,\nwe must start with a label assignment that has small error for every block. However, a\nlabel assignment with error at most 0 _._ 001 could assign random labels to a 0 _._ 001 fraction\nof the blocks. In this case, simple voting schemes cannot improve the accuracy for these\nblocks and the total error would stay at least 0 _._ 001. On the other hand, if the initial label\nassignment had error \u226a 1/ _\ud835\udc58_, we can conclude that the assignment has small error for every\nblock and, in the non-robust setting, we can boost by the above voting scheme to an error\nof roughly exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ). However, previous algorithms, including the robust algorithm by\nLiu and Moitra [LM22], can guarantee this small an error only if _\ud835\udc51_ _> \ud835\udc58_ [2][+] _[\ud835\udc50]_ / _\ud835\udf00_ [2] for a constant\n_\ud835\udc50_ _>_ 0. (Indeed, the error bound Eq. (2.35) requires _\ud835\udc51_ \u226b _\ud835\udc58_ [4] / _\ud835\udf00_ [2] to guarantee error at most\n1/ _\ud835\udc58_ .)\nTo overcome this inherent technical barrier, we develop a recursive bisectioning algo###### rithm for obtaining error rate 1/poly( \ud835\udc58 ) when \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58 for some sufficiently large\n\nconstant _\ud835\udc3e_ .\n\n**Robust verification.** A crucial procedure in the robust bisectioning algorithm is to test\nwhether a cluster output by the initialization algorithm well approximates one of the\nground truth clusters. In other words, given a set of _\ud835\udc5b_ / _\ud835\udc58_ vertices, the algorithm needs to\ndecide whether at least 0 _._ 99 fraction of the nodes belong to the same cluster. For this, we\nconsider the following sum-of-squares program.\n\n###### \u2225 [\ufffd] \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc4e] [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4] \u2225 \u2a7d \ud835\udf12 \ufffd \ud835\udc51 / \ud835\udc58 \ufffd\ufffd \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0]\n\n###### \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0] [.] [97][(] [\ud835\udc58] \ud835\udc58 [\u2212][3][1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n###### \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67, \u27e8 \ud835\udc67, 1 \u27e9 \u2a7e [\ufffd] [0] [.] \ud835\udc58 [99] \u2212 \ud835\udf02 [\ufffd] \ud835\udc5b\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) :=\n\n###### \uf8f1\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f3\n\n###### \u2225 [\ufffd] \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc4e]\n\n_[\ud835\udc4e]_\n###### \ud835\udc5b [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4] \u2225 \u2a7d \ud835\udf12 \ufffd\n\n_\ud835\udc58_ [3]\n\n_,_ (2.37)\n\n###### \uf8fc\uf8f4\uf8f4\uf8f4\uf8fd \uf8f4\uf8f4\uf8f4\uf8fe\n\nwhere _\ud835\udc4e_ / _\ud835\udc5b_ is the intra-cluster connection probability, and _\ud835\udf12_ is a large constant. When a\n0 _._ 99-fraction of the nodes indeed belongs to the same cluster, it is easy to see that the\nprogram is satisfied by setting _\ud835\udc67_ as the indicator vector for the set of uncorrupted vertices\nfrom the ground truth cluster. On the other hand, we give a constant-degree sum-of-squares\nrefutation for the program when less than 0 _._ 98 fraction of the nodes belong to the same\ncluster. The observation is that, having a large number of nodes from the other community\n###### leads to a large spectral norm of the matrix [\ufffd] \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc4e] [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4] . Let \ud835\udf09 be the indicator vector\n\n###### leads to a large spectral norm of the matrix [\ufffd] \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc4e] [\ud835\udc3d] [\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4] . Let \ud835\udf09 be the indicator vector\n\nfor the set of vertices belonging to other clusters. As the inter-cluster edge connection\nprobability is given by _\ud835\udc4e_ / _\ud835\udc5b_ \u2212 _\ud835\udf00\ud835\udc51_ / _\ud835\udc5b_, we have\n\n_\ud835\udf00\ud835\udc51_\n\n\u2212 _[\ud835\udc4e]_\n###### \u27e8 \ud835\udf09 \u2299 \ud835\udc67, \ud835\udc3a \ud835\udc67 \u27e9 \u2a7e \ufffd\ufffd\ufffd \ufffd \ud835\udc5b [\ud835\udc3d] \ufffd \ufffd\ufffd\ufffd \ud835\udc58 [\u2225] [\ud835\udc67] [\u2225\u2225] [\ud835\udf09] [\u2299] [\ud835\udc67] [\u2225] [,]\n\n_[\ud835\udc4e]_ _\ud835\udf00\ud835\udc51_\n###### \ud835\udc67 \u27e9 \u2a7e \ud835\udc5b [\ud835\udc3d] \ufffd \ufffd\ufffd\ufffd \ud835\udc58\n\n_\ud835\udc58_ [\u2225] _[\ud835\udc67]_ [\u2225\u2225] _[\ud835\udf09]_ [\u2299] _[\ud835\udc67]_ [\u2225] _[,]_\n\nwhich violates the spectral norm constraint.\n\n15\n\n**Robust bisectioning algorithm.** Now, we show that, given the rough initialization with\nerror rate 0 _._ 001, how to find a bisection of the graph such that, for each community, at\n###### least 1 \u2212 exp [\ufffd] \u2212 \ud835\udf00 [2] \ud835\udc51 /2 \ud835\udc58 [2][\ufffd] + poly( \ud835\udc58 ) \ud835\udf02 fraction of the nodes is assigned to the same side of the\n\nbisection.\n\nTo do this, we use the robust verification algorithm on the recovered communities from\nthe rough initialization. Since the rough initialization has error 0 _._ 001, among the recovered\ncommunities, there can be at most _\ud835\udc58_ /2 communities that has error more than 0 _._ 01 _\ud835\udc5b_ / _\ud835\udc58_ .\nTherefore, we can obtain _\ud835\udc58_ /2 clusters that each has error at most 0 _._ 01 _\ud835\udc5b_ / _\ud835\udc58_ via the robust\nverification algorithm, and we can put them in the same side of the bisection and form a\nrough bisection with bisection error 0 _._ 01 _\ud835\udc5b_ . Now, we treat the bisection as a 2-SBM and use\nmajority voting to boost the bisection accuracy to exp(\u2212 _\ud835\udf00_ [2] _\ud835\udc51_ /2 _\ud835\udc58_ [2] ) + poly( _\ud835\udc58_ ) _\ud835\udf02_ . [6] This leads to\n###### an algorithm with error rate 1/poly( \ud835\udc58 ) + \ud835\udc42 ( \ud835\udf02 ) when \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58 . [7]\n\n**Robust** _\ud835\udc58_ **-clustering algorithm.** Given the robust bisectioning algorithm, we can now\nrecursively bisect the graph and get a better initialization with accuracy 1/poly( _\ud835\udc58_ )+poly( _\ud835\udc58_ )\u00b7 _\ud835\udf02_\n###### when \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58 . More precisely, the algorithm robustly partitions the given graph\n\ninto a bisection with error rate exp(\u2212 _\ud835\udf00_ [2] _\ud835\udc51_ /2 _\ud835\udc58_ [2] ) + poly( _\ud835\udc58_ ) _\ud835\udf02_, then recursively applies the\nsame procedure to each side of the bisection. Since the algorithm is robust against node\ncorruptions, it can handle the misclassified nodes from the previous rounds by treating them\nas corruptions. As a result, we can obtain a clustering with error rate 1/poly( _\ud835\udc58_ ) + poly( _\ud835\udc58_ ) _\ud835\udf02_ .\n\n**Achieving minimax rate.** The last step is to boost the rough _\ud835\udc58_ -clustering with misclassification error poly1 ( _\ud835\udc58_ ) [+][ poly][(] _[\ud835\udc58]_ [) \u00b7] _[ \ud835\udf02]_ [to the minimax-optimal error rate.]\n\nexp \u2212(1 \u00b1 _\ud835\udc5c_ (1)) _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_\n\n_\ud835\udc58_\n###### \ufffd\n\n+ poly( _\ud835\udc58_ ) \u00b7 _\ud835\udf02._\n###### \ufffd\n\nNotice that, when there is no node corruptions, simple majority voting can boost clustering\nerror to exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ). To deal with node corruptions, we use the robust majority voting\nalgorithm for 2-SBM (as described in previous section) for each pair of the communities.\nMore precisely, we simulate majority voting within the SoS framework by imposing majorityvote and robust mixing constraints for every pair of communities. These constraints mirror\nthe 2-community scenario and establish that any feasible solution in the SoS program must\ndiffer from the ground truth by no more than a exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ / _\ud835\udc58_ ) fraction of nodes. [8]\n\nTo round the SoS solution to a community labelling, we apply the standard nodedistance Lipschitzness arguments and obtain a final clustering with misclassification error\n\n6The error rate here is of order exp(\u2212 _\ud835\udf00_ 2 _\ud835\udc51_ /2 _\ud835\udc58_ 2) because the voting signal is diluted after putting the\ncommunities in partitions of 2 _[\ud835\udc58]_ [communities.]\n\n7This is the bottleneck for us to get to the KS threshold.\n8For technical reasons, two rounds of majority voting are needed to achieve the optimal error rate.\nCorrespondingly, in our sum-of-squares program, we need to add two sets of majority voting constraints for\nachieving the minimax error rate.\n\n16\n\nat most\n\nexp \u2212(1 \u2212 _\ud835\udc5c_ (1)) _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_\n\n_\ud835\udc58_\n###### \ufffd\n\n##### **2.3 Relation to previous works**\n\n+ poly( _\ud835\udc58_ ) \u00b7 _\ud835\udf02_ _._\n###### \ufffd\n\n###### Comparison with [LM22]. One of the main reasons why [LM22] requires \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [102] )\n\nis that their initialization algorithm is the vanilla SDP which can only achieve error\n1/poly( _\ud835\udc58_ ) when it is far from the KS threshold. One key algorithmic innovation of our\nwork is the bisection boosting procedure. Instead of attempting to get an initialization\nwith error 1/poly( _\ud835\udc58_ ) in one shot, we recursively find bisections of the graph that have\nthe optimal bisection error rate. More concretely, in each recursion, we first get a rough\ninitialization with error 0 _._ 001, then boost the bisection accuracy to its optimal rate using\nbisection majority voting on the rough initialization. This allows us to get a 1/poly( _\ud835\udc58_ ) initial\n###### estimation when \ud835\udf00 [2] \ud835\udc51 \u2a7e \u03a9( \ud835\udc58 [2] log \ud835\udc58 ).\n\n**Comparison with [DdHS23].** In [DdHS23], the authors gave an SoS-based algorithm\nthat achieves weak recovery at the KS threshold. Our algorithm can be viewed as a\nstrengthening of the SoS relaxation from [DdHS23] by adding _majority voting constraints_ .\nInformally, these constraints enforce that, for most vertices, the assigned label agrees with\nthe label suggested by the majority of their neighbours in an appropriate pairwise sense.\nSince all known approaches that achieve the minimax error rate ultimately rely on belief\npropagation or majority voting, encoding such voting constraints into the SoS program\nappears essential for attaining optimal accuracy.\n\n### **3 Preliminary**\n\n##### **3.1 Notation**\n\n**Random variables.** We use boldface to denote random variables, e.g., _\ud835\udc7f_ _, \ud835\udc80_ _, \ud835\udc81_ .\n\n###### Asymptotics. We write \ud835\udc53 \u2272 \ud835\udc54 to denote the inequality \ud835\udc53 \u2a7d \ud835\udc36 \u00b7 \ud835\udc54 for some absolute constant \ud835\udc36 > 0. We write \ud835\udc42 ( \ud835\udc53 ) and \u03a9( \ud835\udc53 ) to denote quantities \ud835\udc53 \u2212 and \ud835\udc53 + satisfying \ud835\udc53 \u2212 \u2272 \ud835\udc53 and \ud835\udc53 \u2272 \ud835\udc53 +,\n\nrespectively.\n\n**Vector.** For any vector, we use the notation \u2225\u00b7 \u22251 for the _\u2113_ 1-norm, \u2225\u00b7 \u22252 for the _\u2113_ 2-norm,\nand \u2225\u00b7 \u2225\u221e for the _\u2113_ \u221e-norm. Furthermore, for any two vectors _\ud835\udc65, \ud835\udc66_ \u2208 \u211d _[\ud835\udc5b]_, we use _\ud835\udc65_ \u2299 _\ud835\udc66_ for\nthe Hadamard (entrywise) product of the two vectors. We write **1** and **0** for the all-ones\nand all-zeros vectors (or matrices) of the appropriate dimension. For a subset _\ud835\udc46_ \u2286[ _\ud835\udc5b_ ], we\ndenote its indicator vector by **1** _\ud835\udc46_ \u2208{0 _,_ 1} _[\ud835\udc5b]_, where **1** _\ud835\udc46_ ( _\ud835\udc56_ ) = 1 if _\ud835\udc56_ \u2208 _\ud835\udc46_ and **1** _\ud835\udc46_ ( _\ud835\udc56_ ) = 0 otherwise.\n\n17\n\n**Matrix.** For a matrix _\ud835\udc40_ \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5a]_, we denote its ( _\ud835\udc56, \ud835\udc57_ )-th entry by _\ud835\udc40_ ( _\ud835\udc56, \ud835\udc57_ ), its _\ud835\udc56_ -th row\nby _\ud835\udc40_ ( _\ud835\udc56,_ - ), and its _\ud835\udc57_ -th column by _\ud835\udc40_ (\u00b7 _, \ud835\udc57_ ). For two matrices of the same dimension, we\nalso use _\ud835\udc40_ \u2299 _\ud835\udc41_ for their Hadamard (entrywise) product. We use \u2225 _\ud835\udc40_ \u2225 (and also \u2225 _\ud835\udc40_ \u2225op)\nfor the spectral norm of _\ud835\udc40_ and \u2225 _\ud835\udc40_ \u2225F for the Frobenius norm of _\ud835\udc40_ . We denote by\n\u2225 _\ud835\udc40_ \u2225sum and \u2225 _\ud835\udc40_ \u2225max the sum and the maximum of the absolute values of the entries\nin _\ud835\udc40_, respectively. For two matrices _\ud835\udc40, \ud835\udc41_ \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5a]_, we denote their inner product by\n###### \u27e8 \ud835\udc40, \ud835\udc41 \u27e9 = Tr \ud835\udc40\ud835\udc41 [T] = [\ufffd] \ud835\udc56,\ud835\udc57 [\ud835\udc40] [(] [\ud835\udc56, \ud835\udc57] [)] [\ud835\udc41] [(] [\ud835\udc56, \ud835\udc57] [)][. We write] [ \ud835\udc3c][\ud835\udc5b] [for the] [ \ud835\udc5b] [\u00d7] [ \ud835\udc5b] [identity matrix, and]\n\n_\ud835\udc3d_ = **11** [\u22a4] for the all-ones matrix.\n\n**Graph.** We write _\ud835\udc3a_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5b]_ for the adjacency matrix of a (possibly corrupted) graph\non vertex set [ _\ud835\udc5b_ ]. When an average degree parameter _\ud835\udc51_ is specified, we define the centered\nadjacency matrix\n\n\u00af\n###### \ud835\udc3a \ufffd \ud835\udc3a \u2212 [\ud835\udc51]\n\n_\ud835\udc5b_ _[\ud835\udc3d.]_\n\nWhen we need to distinguish the uncorrupted graph sampled from the stochastic block\nmodel from a corrupted observation, we write _\ud835\udc3a_ [\u25e6] for the uncorrupted adjacency matrix\n###### and \ud835\udc3a [\u00af] [\u25e6] \ufffd \ud835\udc3a [\u25e6] \u2212 [\ud835\udc51]\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [for its centered version.]\n\n##### **3.2 Sum-of-Squares hierarchy**\n\nIn this paper, we employ the sum-of-squares hierarchy [BS14, BS16, RSS18] for both\nalgorithm design and analysis. As a broad category of semidefinite programming algorithms, sum-of-squares algorithms provide many optimal or state-of-the-art results in\nalgorithmic statistics [HL18, KSS18, PS17, Hop20]. We provide here a brief introduction to\npseudo-distributions, sum-of-squares proofs, and sum-of-squares algorithms.\n\n**Pseudo-distribution.** We can represent a finitely supported probability distribution over\n###### \u211d [\ud835\udc5b] by its probability mass function \ud835\udf07 : \u211d [\ud835\udc5b] \u2192 \u211d such that \ud835\udf07 \u2a7e 0 and [\ufffd] \ud835\udc65 \u2208supp( \ud835\udf07 ) [\ud835\udf07] [(] [\ud835\udc65] [)][ =][ 1][.]\n\nWe define pseudo-distributions as generalizations of such probability mass distributions,\n###### by relaxing the constraint \ud835\udf07 \u2a7e 0 and only requiring that \ud835\udf07 passes certain low-degree\n\nnon-negativity tests.\n\n**Definition 3.1** (Pseudo-distribution) **.** A _level-\u2113_ _pseudo-distribution \ud835\udf07_ over \u211d _[\ud835\udc5b]_ is a finitely\n###### supported function \ud835\udf07 : \u211d [\ud835\udc5b] \u2192 \u211d such that [\ufffd] \ud835\udc65 \u2208supp( \ud835\udf07 ) [\ud835\udf07] [(] [\ud835\udc65] [)][ =][ 1][ and][ \ufffd] \ud835\udc65 \u2208supp( \ud835\udf07 ) [\ud835\udf07] [(] [\ud835\udc65] [)] [ \ud835\udc53] [(] [\ud835\udc65] [)][2][ \u2a7e] [0]\n\nfor every polynomial _\ud835\udc53_ of degree at most _\u2113_ /2.\n\nWe can define the formal expectation of a pseudo-distribution in the same way as the\nexpectation of a finitely supported probability distribution.\n\n**Definition 3.2** (Pseudo-expectation) **.** Given a pseudo-distribution _\ud835\udf07_ over \u211d _[\ud835\udc5b]_, we define the\n_pseudo-expectation_ of a function _\ud835\udc53_ : \u211d _[\ud835\udc5b]_ \u2192 \u211d by\n\n\u02dc\n###### \ud835\udd3c \ud835\udf07 \ud835\udc53 := \ufffd \ud835\udf07 ( \ud835\udc65 ) \ud835\udc53 ( \ud835\udc65 ) . (3.1)\n\n_\ud835\udc65_ \u2208supp( _\ud835\udf07_ )\n\n18\n\nIn later sections, when the underlying pseudo-distribution _\ud835\udf07_ is implicit, we write \ud835\udd3c [\u02dc] for\nits pseudo-expectation operator and use the shorthand \ud835\udd3c [\u02dc] [ _\ud835\udc5d_ ] for \ud835\udd3c [\u02dc] _\ud835\udf07\ud835\udc5d_ .\nThe following definition formalizes what it means for a pseudo-distribution to satisfy a\nsystem of polynomial constraints.\n\n**Definition 3.3** (Constrained pseudo-distributions) **.** Let _\ud835\udf07_ : \u211d _[\ud835\udc5b]_ \u2192 \u211d be a level- _\u2113_ pseudo###### distribution over \u211d [\ud835\udc5b] . Let \ud835\udc9c = { \ud835\udc53 1 \u2a7e 0, . . ., \ud835\udc53\ud835\udc5a \u2a7e 0} be a system of polynomial constraints.\n\nWe say that _\ud835\udf07_ _satisfies_ \ud835\udc9c at level _\ud835\udc5f_, denoted by _\ud835\udf07_ _\ud835\udc5f_ \ud835\udc9c, if for every multiset _\ud835\udc46_ \u2286[ _\ud835\udc5a_ ] and\n###### every sum-of-squares polynomial \u210e such that deg( \u210e ) + [\ufffd] \ud835\udc56 \u2208 \ud835\udc46 [max][{][deg][(] [ \ud835\udc53][\ud835\udc56] [)] [, \ud835\udc5f] [}][ \u2a7d] [\u2113] [,]\n\n\u02dc\n###### \ud835\udd3c \ud835\udf07 \u210e \u00b7 \ufffd \ud835\udc53\ud835\udc56 \u2a7e 0 . (3.2)\n\n_\ud835\udc56_ \u2208 _\ud835\udc46_\n\nWe say _\ud835\udf07_ satisfies \ud835\udc9c and write _\ud835\udf07_ \ud835\udc9c (without further specifying the degree) if _\ud835\udf07_ 0 \ud835\udc9c.\n\nWe remark that if _\ud835\udf07_ is an actual finitely supported probability distribution, then we\nhave _\ud835\udf07_ \ud835\udc9c if and only if _\ud835\udf07_ is supported on solutions to \ud835\udc9c.\n\n**Sum-of-squares algorithm.** The _sum-of-squares algorithm_ searches through the space of\npseudo-distributions that satisfy a given system of polynomial constraints, by solving\nsemidefinite programming.\n\n**Theorem 3.4** (Sum-of-squares algorithm) **.** _There exists an_ ( _\ud835\udc5b_ + _\ud835\udc5a_ ) _[\ud835\udc42]_ [(] _[\u2113]_ [)] _-time algorithm that,_\n_given any explicitly bounded_ [9] _and satisfiable system_ [10] \ud835\udc9c _of \ud835\udc5a_ _polynomial constraints in \ud835\udc5b_ _variables,_\n_outputs a level-\u2113_ _pseudo-distribution that satisfies_ \ud835\udc9c _approximately._\n\n**Sum-of-squares proof.** We introduce sum-of-squares proofs as the dual objects of pseudodistributions, which can be used to reason about properties of pseudo-distributions. We\nsay a polynomial _\ud835\udc5d_ is a sum-of-squares polynomial if there exist polynomials ( _\ud835\udc5e\ud835\udc56_ ) such that\n###### \ud835\udc5d = [\ufffd] \ud835\udc56 [\ud835\udc5e] [2] \ud835\udc56 [.]\n\n**.** A\n**Definition 3.5** (Sum-of-squares proof) _sum-of-squares_ proof that a system of polynomial\n###### constraints \ud835\udc9c = { \ud835\udc53 1 \u2a7e 0, . . ., \ud835\udc53\ud835\udc5a \u2a7e 0} implies \ud835\udc5e \u2a7e 0 consists of sum-of-squares polynomials\n\n( _\ud835\udc5d\ud835\udc46_ ) _\ud835\udc46_ \u2286[ _\ud835\udc5a_ ] such that [11]\n\n_\ud835\udc5d\ud835\udc46_      ###### \ufffd \ufffd\n\nmultiset _\ud835\udc46_ \u2286[ _\ud835\udc5a_ ] _\ud835\udc56_ \u2208 _\ud835\udc46_\n\n_\ud835\udc5e_ =\n###### \ufffd\n\n_\ud835\udc53\ud835\udc56_ _._\n\n_\ud835\udc56_ \u2208 _\ud835\udc46_\n\n###### If such a proof exists, we say that \ud835\udc9c (sos-)proves \ud835\udc5e \u2a7e 0 within degree \u2113, denoted by \ud835\udc9c \u2113 \ud835\udc5e \u2a7e 0.\n\n_\ud835\udc65_\n\nIn order to clarify the variables quantified by the proof, we often write \ud835\udc9c( _\ud835\udc65_ ) _\u2113_ _\ud835\udc5e_ ( _\ud835\udc65_ ) \u2a7e 0.\n\nWe say that the system \ud835\udc9c is _sos-refuted_ within degree _\u2113_ if \ud835\udc9c _\u2113_ \u22121 \u2a7e 0. Otherwise, we say\nthat the system is _sos-consistent_ up to degree _\u2113_, which also means that there exists a level- _\u2113_\npseudo-distribution satisfying the system.\n\n9 2\nA system of polynomial constraints is _explicitly bounded_ if it contains a constraint of the form \u2225 _\ud835\udc65_ \u2225 \u2a7d _\ud835\udc40_ .\n10Here we assume that the bit complexity of the constraints in \ud835\udc9c is ( _\ud835\udc5b_ + _\ud835\udc5a_ ) _\ud835\udc42_ (1).\n11Here we follow the convention that [\ufffd] _\ud835\udc56_ \u2208 _\ud835\udc46_ _[\ud835\udc53][\ud835\udc56]_ [=][ 1 for] _[ \ud835\udc46]_ [=][ \u2205][.]\n\n19\n\n##### **3.3 Stochastic block model**\n\n**Definition 3.6** (Symmetric balanced _\ud835\udc58_ -community stochastic block model) **.** Assume that _\ud835\udc58_\nis a power of 2 and _\ud835\udc5b_ is a multiple of _\ud835\udc58_ . Let ( _\ud835\udc6e, \ud835\udc81_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) denote the symmetric\nbalanced _\ud835\udc58_ -community stochastic block model with degree parameter _\ud835\udc51_ _>_ 0 and bias\nparameter _\ud835\udf00_ \u2208[0 _,_ 1]. The model is defined as follows:\n\n - **Communities.** The communities _\ud835\udc81_ [\u25e6] are selected uniformly at random from even\npartitions of the nodes, i.e. uniformly at random partition the graph into _\ud835\udc58_ sets of _[\ud835\udc5b]_ _\ud835\udc58_\n\nvertices each.\n\n - **Edges.** For every pair of distinct vertices _\ud835\udc56, \ud835\udc57_ \u2208[ _\ud835\udc5b_ ], they are connected by an edge\nindependently at random with probability\n\n_\ud835\udc5d_ 2 = 1 \u2212 _[\ud835\udf00]_\n###### \ufffd \ud835\udc58\n\n###### [1] \ud835\udf00 [\ufffd] [\ud835\udc51] \ud835\udc58 \ufffd\n\nif _\ud835\udc81_ [\u25e6] ( _\ud835\udc56_ ) = _\ud835\udc81_ [\u25e6] ( _\ud835\udc57_ ) _,_\n_\ud835\udc5b_ _[,]_\n\n\u2119\ufffd( _\ud835\udc56, \ud835\udc57_ ) \u2208 _\ud835\udc38_ ( _\ud835\udc6e_ )\ufffd =\n\n###### \uf8f1\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f3\n\n###### \ud835\udc5d 1 = [\ufffd] 1 + [\ufffd] 1 \u2212 [1] \ud835\udc58\n\n_\ud835\udc51_\n\notherwise _._\n###### \ufffd \ud835\udc5b [,]\n\n**.**\n**Definition 3.7** (Community membership matrix) For a given community membership\nmatrix _\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ we define the associated centered community membership matrix\n\n###### \ud835\udc4b \ufffd \ud835\udc4d\ud835\udc4d [\u22a4] \u2212 [1]\n\n_\ud835\udc58_ _[\ud835\udc3d.]_\n\nIn particular, the true centered block matrix is\n\n###### \ud835\udc4b [\u25e6] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] \u2212 [1]\n\n_\ud835\udc58_ _[\ud835\udc3d.]_\n\n###### Let \ud835\udc3a [\u25e6] be the uncorrupted adjacency matrix and \ud835\udc3a [\u00af] [\u25e6] \ufffd \ud835\udc3a [\u25e6] \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [be the centered adjacency]\n\nmatrix, it follows that\n\n\u00af                         -                         ###### \ud835\udd3c\ufffd \ud835\udc3a \ufffd\ufffd \ud835\udc4d \ufffd = [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [\u25e6] _[.]_\n\n**Definition 3.8** (Signal-to-noise ratio (SNR)) **.** The _signal-to-noise ratio (SNR)_ for the symmetric\nbalanced _\ud835\udc58_ -community stochastic block model (Theorem 3.6) is defined as\n\n###### \ud835\udc5b\ud835\udc3c, where \ud835\udc3c = \ud835\udc37 1/2 \ufffdBer( \ud835\udc5d 1) \ufffd\ufffd Ber( \ud835\udc5d 2)\ufffd\n\nis the R\u00e9nyi divergence of order 1/2 between two Bernoulli distributions with parameters\n_\ud835\udc5d_ 1 and _\ud835\udc5d_ 2, as specified in Theorem 3.6. In the sparse regime where _\ud835\udc51_ = _\ud835\udc5c_ ( _\ud835\udc5b_ ), this expression\nsimplifies to\n###### \ud835\udc5b\ud835\udc3c = [\ufffd] [\u221a] \ud835\udc5d 1 \ud835\udc5b \u2212 [\u221a] \ud835\udc5d 2 \ud835\udc5b [\ufffd] [2] \u00b7 (1 + \ud835\udc5c (1)) .\n\nThroughout this paper, we denote this simplified expression by _\ud835\udc36\ud835\udc51,\ud835\udf00_ .\n\n20\n\n### **4 Statistical properties of the SBM**\n\nIn this section, we focus on the statistical properties of majority voting in SBM. At a\nhigh level, majority voting for a single vertex _\ud835\udc62_ asks whether its centered signed degree\n( _\ud835\udc3a\ud835\udc66_ [\u00af] ) _\ud835\udc62_ - _\ud835\udc66\ud835\udc62_ is positive. Aggregating this test over a set of candidate vertices _\ud835\udc46_ amounts to\nlower bounding the linear form \u27e8 _\ud835\udc3a\ud835\udc66_ [\u00af] \u2299 _\ud835\udc66, \ud835\udc67_ \u27e9 for indicators _\ud835\udc67_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ supported on the\nlevel- _\ud835\udc56_ bisection (or on a pair of communities in the _\ud835\udc58_ -clustering step). The voting bounds\nin Theorems 4.3 and 4.5 show that, with high probability, this inner product is uniformly\nlarge whenever \u2225 _\ud835\udc67_ \u22251 is not too small and remains not too negative even for very small \u2225 _\ud835\udc67_ \u22251,\nwhile the masked variants in Theorems 4.4 and 4.6 guarantee the same after restricting to\na large trusted subset. We will use these properties to certify that a small set of possibly\nadversarial vertices cannot flip many majority votes at once and to enable robust boosting.\nThe proofs of the results in this section are deferred to Section C.\n\n**Concentration bound of single-vertex majority voting.** The following result provides\na concentration bound for a mixture of binomial distributions. The argument follows a\ngeneric Chernoff bound approach similar to lemma 5.6 in [LM22]. The main difference is\nthat we need to find the right bound (i.e. SNR) for induced bisections of _\ud835\udc58_ -SBM. This boils\ndown to bounding the moments of the following summation of binomial distributions.\n\n**Theorem 4.1.** _Fix parameters \ud835\udefd_ \u2208(0 _,_ 1] _and \ud835\udefc_ \u2208(0 _, \ud835\udefd_ ] _. Consider the distribution_\n\n###### \ud835\udc9f = Binom( \ud835\udefc\ud835\udc5b, \ud835\udc4e / \ud835\udc5b ) + Binom [\ufffd] ( \ud835\udefd \u2212 \ud835\udefc ) \ud835\udc5b, \ud835\udc4f / \ud835\udc5b [\ufffd] \u2212 Binom( \ud835\udefd\ud835\udc5b, \ud835\udc4f / \ud835\udc5b ), where the three binomials are independent. Let \ud835\udefe \ufffd \ud835\udefc / \ud835\udefd and define\n\n###### \ufffd\n\n\u2212\n###### \ud835\udc4e \ufffd\n\n_\ud835\udc5e_ (1 \u2212 _\ud835\udc5d_ ) _[.]_\n\n###### \ufffd \ufffd \ufffd \ud835\udc4e \ufffd \ud835\udc4e [\ud835\udefe] \ud835\udc4f [1][\u2212] [\ud835\udefe], \ud835\udc4f \ufffd \ud835\udc4f, \ud835\udc36 \ufffd [\ufffd][\u221a]\n\n###### \ufffd \ud835\udc4f [\ufffd] [2], \ud835\udc45 ( \ud835\udc5d, \ud835\udc5e ) \ufffd [\ud835\udc5d] [(][1][ \u2212] [\ud835\udc5e] [)]\n\n_Then for every \ud835\udf03_ \u2208 \u211d _,_\n\n###### \ud835\udc7f \u2119\u223c\ud835\udc9f [[] [ \ud835\udc7f] [\u2a7d] [\ud835\udf03] []][ \u2a7d] [exp] \ufffd\u2212 \ud835\udefd \ud835\udc36 [\ufffd] + [\ud835\udf03] 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [ \ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd .\n\nAs an immediate corollary, we get:\n\n###### Theorem 4.2. Fix a level \ud835\udc56 \u2208{1, 2, . . ., log2 \ud835\udc58 } and let \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56] (with \ud835\udefc\ud835\udc56 = 1/ \ud835\udc58). Let \ufffd \ud835\udc4e, [\ufffd] \ud835\udc4f, \ud835\udc36 [\ufffd] and\n\n_\ud835\udc45_ (\u00b7 _,_ - ) _be as in Theorem C.4, evaluated at this_ ( _\ud835\udefc, \ud835\udefd_ ) _. Then for every \ud835\udf03_ \u2208 \u211d _,_\n\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] \u2a7d exp \u2212 [(][lo][g][ 2][)][2]\n\n4\n###### \ufffd\n\n[ 2][)][2]\n\n     - _[\ud835\udc51]_ _[\ud835\udf00]_ [2]\n4 _\ud835\udc58_\n\n_[\ud835\udf03]_ _._\n###### 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd\n\n_[\ud835\udc51]_ _[\ud835\udf00]_ _[\ud835\udf03]_\n\n_\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2] [+] 2\n\n21\n\n**Majority voting for bisections.** We first give a theorem for the error of majority voting in\ninduced bisections of the graph.\n\n**Theorem 4.3.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _, \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udc58\ud835\udc56_ = _\ud835\udefd\ud835\udc56_ _\ud835\udc58. Let \ud835\udefe_ \u2208[0 _,_ 0 _._ 99] _._\n###### Choose \ud835\udf0c\ud835\udefe \ufffd exp(\u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\u02dc] \ud835\udc56 /2), and set \ud835\udc61 = 0 . 001(1 \u2212 \ud835\udefe ) \ud835\udc36 [\u02dc] \ud835\udc56. Then with probability at least\n\n1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [1][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, and for every valid bisections][ \ud835\udc66]_ [\u2208{][0] _[,]_ [ \u00b1][1][}] _[\ud835\udc5b]_ _[at level][ \ud835\udc56][.]_\n\n_we have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b\ud835\udc56_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\nFor establishing the feasibility of the program constraints in Section 8 and Section 11,\nwe need to bound the error of majority voting when a small fraction of the vertices in the\ngraph are removed, i.e. the following corollary.\n\n**Corollary 4.4.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _, \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udc58\ud835\udc56_ = _\ud835\udefd\ud835\udc56_ _\ud835\udc58. Let \ud835\udefe_ \u2208[0 _,_ 0 _._ 99] _._\n###### Choose \ud835\udf0c\ud835\udefe \ufffd exp(\u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\u02dc] \ud835\udc56 /2), and set \ud835\udc61 = 0 . 001(1 \u2212 \ud835\udefe ) \ud835\udc36 [\u02dc] \ud835\udc56. Then with probability at least\n\n1\u2212exp(\u2212100 _\ud835\udc58_ )\u2212 _\ud835\udc5b_ [2][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, for every][ \ud835\udc60]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b]_ _[such that]_ [ \u2225] _[\ud835\udc60]_ [\u2225][1][ \u2a7e] [(][1][\u2212][exp][(\u2212][2] _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_ [))] _[\ud835\udc5b][,]_\n\n_and for every valid bisections \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _at level \ud835\udc56, we have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc60\ud835\udc60 [\u22a4] ) \ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n16 _\ud835\udc58_\n\n640 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b\ud835\udc56_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n**Majority voting for pairwise communities.** We give a similar theorem for bounding the\nerror of majority voting for each pair of communities.\n\n_\ud835\udc4f_ ) [2] _. Let \ud835\udefe_ \u2208[0 _,_ 1 \u2212 [1000] _[\ud835\udf12][\ud835\udc58]_\n\n**Theorem 4.5.** _Let \ud835\udc36\ud835\udc51,\ud835\udf00_ = ( ~~[\u221a]~~ _\ud835\udc4e_ \u2212 \u221a\n\n_\ud835\udf00_ ~~\u221a~~\n\n###### \ud835\udc51 []] [. Choose][ \ud835\udf0c][\ud835\udefe] [\ufffd] [exp][(\u2212] [\ud835\udefe][\ud835\udc36][\ud835\udc51,][\ud835\udf00] [/] [\ud835\udc58] [)] [.]\n\n_Then with probability at least_ 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [1][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, and for every pair of]_\n\n_communities \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _. We have_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\nSimilarly, for establishing the feasibility of the program constraints in Section 11, We\nneed the following corollary, which bounds the error of majority voting when a small\nfraction of the vertices are removed from the graph.\n\n**Corollary 4.6.** _Let \ud835\udefe_ \u2208[0 _,_ 1 \u2212 [1000] _[\ud835\udf12][\ud835\udc58]_\n\n###### \ud835\udc51 []] [. Choose][ \ud835\udf0c][\ud835\udefe] [\ufffd] [exp][(\u2212] [\ud835\udefe][\ud835\udc36] [)] [. Then with probability at least]\n\n_\ud835\udf00_ ~~\u221a~~\n\n1\u2212exp(\u2212100 _\ud835\udc58_ )\u2212 _\ud835\udc5b_ [2][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, for every][ \ud835\udc60]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b]_ _[such that]_ [ \u2225] _[\ud835\udc60]_ [\u2225][1][ \u2a7e] [(][1][\u2212][exp][(\u2212][2] _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_ [))] _[\ud835\udc5b][,]_\n\n_and for every pair of communities \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _. We have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc60\ud835\udc60 [\u22a4] ) \ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n16 _\ud835\udc58_\n\n640 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n22\n\n### **5 Algorithmic framework and results**\n\nIn this section, we give a sketch of our robust optimal recovery algorithm (see Theorem 11.1)\nwith its key building blocks. Theorem 11.1 contains two main steps: _initialization_ and\n_boosting based on pairwise majority voting_ . The goal of initialization is to get a 1/poly( _\ud835\udc58_ )\napproximation such that, in each community, we have error rate at most 0 _._ 001. Given the\n1/poly( _\ud835\udc58_ )-initial estimation, we can apply pairwise majority voting to boost the accuracy\nto the minimax rate.\n\n##### **5.1 Robust bisection algorithm**\n\nThe key component of our initialization algorithm is the following robust bisectioning\n###### algorithm that finds bisections in the graph with bisection error exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] \ud835\udc58 [\ud835\udc51] [2] [,][\ud835\udf00] + \ufffd \ufffd\n\npoly( _\ud835\udc58_ ) _\ud835\udf02_ .\n\n**.**\n**Algorithm 5.1** (Robust bisection algorithm)\n**Input:** A graph _\ud835\udc3a_ sampled from the _\ud835\udc58_ -stochastic block model SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) with _\ud835\udf02\ud835\udc5b_\ncorrupted nodes.\n\n1. **Graph splitting:** We let _\ud835\udc3a_ 1 be the graph obtained by subsampling each edge in _\ud835\udc3a_\nindependently with probability 0 _._ 99 and let _\ud835\udc3a_ 2 \ufffd _\ud835\udc3a_ \\ _\ud835\udc3a_ 1.\n\n2. **Rough initialization:** Run a rough _\ud835\udc58_ -clustering algorithm on graph _\ud835\udc3a_ 1 to obtain\nrough initialization _\ud835\udc4d_ rough with error rate 0 _._ 001 + 10 [4] _\ud835\udf02_ .\n\n3. **Identifying well recovered blocks:** Use graph _\ud835\udc3a_ 2 and _\ud835\udc4d_ rough to identify _\ud835\udc58_ /2\nclusters in which 0 _._ 99-fraction of the nodes belongs to the same community.\nConstruct rough bisection _\ud835\udc65_ rough by putting the _\ud835\udc58_ /2 identified clusters on one\nside of the bisection.\n\n4. **Bisection boosting:** Use majority voting on bisections with _\ud835\udc65_ rough as the initial###### ization to obtain a bisection \u02c6 \ud835\udc65 with error rate exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] \ud835\udc58 [\ud835\udc51] [2] [,][\ud835\udf00] + poly( \ud835\udc58 ) \ud835\udf02 . \ufffd \ufffd\n\n**Output:** \u02c6 _\ud835\udc65_ .\n\nWe will now briefly explain and state the results for the subroutines _rough initialization_,\n_identifying well recovered blocks_ and _bisection boosting_, then state the initialization guarantee\nthat is achieved by recursively applying the bisection algorithm.\n\n**Rough initialization.** Previous work based on semidefinite programming and spectral\nalgorithms can get a rough initialization with error 0 _._ 001 + 10 [4] _\ud835\udc58_ _\ud835\udf02_ (Lemma 7.3 of [LM22]).\n\n23\n\nIn our work, we show that a rough initialization procedure based on Sum-of-Squares (SoS)\ncan get an improved guarantee (see Section 6 for details).\n\n**Theorem 5.2** (Robust rough initialization) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs an estimator_\n\u02c6 1\n_\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n_error\ud835\udc58_ ( _\ud835\udc4d, \ud835\udc4d_ [\u02c6] [\u25e6] ) \u2a7d 0 _._ 001 + 10 [4] _\ud835\udf02._\n\n**Identifying well recovered clusters.** Once we have a rough initialization with misclassification rate at most 0 _._ 001, at least _\ud835\udc58_ /2 clusters must be \u201cwell recovered\u201d, in the sense that at\nleast 0 _._ 99 of the nodes in these well recovered clusters belong to the same community. We\nshow that there exists an algorithm that can robustly identify these well recovered clusters\n(see Section 7 for details).\n\n**Theorem 5.3** (Robust identification of well recovered clusters) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ )\n_be generated from the \ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting_\n###### \ud835\udf02-fraction of the nodes in \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some]\n\n_sufficiently large constant \ud835\udc3e. For any set \ud835\udc46_ \u2282 _\ud835\udc49_ _of \ud835\udc5b_ / _\ud835\udc58_ _vertices, there exists a polynomial-time_\n1\n_algorithm that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[, outputs]_\n\n - _YES if at least_ 0 _._ 99 _of the vertices in \ud835\udc46_ _belong to the same community;_\n\n - _NO if no more than_ 0 _._ 98 _of the vertices in \ud835\udc46_ _belong to any single community._\n\n**Bisection boosting.** Given _\ud835\udc58_ /2 well recovered clusters, we can construct a rough bisection\n_\ud835\udc65_ rough by putting them on one side of the bisection. We show that, given this rough bisection\nwith error rate 0 _._ 001, we can use majority voting to boost the bisection accuracy to obtain a\nbisection with optimal bisection error (see Section 8 for details).\n\n**Theorem 5.4** (Robust bisection boosting) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes_\n###### in \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large]\n\n_constant \ud835\udc3e. Let \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 \u2282 _\ud835\udc49_ _be disjoint subsets of size \ud835\udc5b_ / _\ud835\udc58_ _such that in every \ud835\udc46\ud835\udc56_ _at least_\n0 _._ 99 _-fraction of the nodes belong to the same community. Let \ud835\udc65_ [\u25e6] \u2208{\u00b11} _[\ud835\udc5b]_ _be the ground-truth_\n_community bisection with the underlying communities of \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 _on the same side. There_\n_exists a polynomial-time algorithm that, given observation of \ud835\udc3a_ _and \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 _, outputs_\n\u02c6 1\n_\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n1\n###### \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] [\u02dc]\n_\ud835\udc5b_ [\u2225\u02c6] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u25e6][\u2225][2][ \u2a7d] [exp] 8\n###### \ufffd\n\n+ poly( _\ud835\udc58_ ) _\ud835\udf02_ _,_\n###### \ufffd\n\n_where_ _\ud835\udc36_ [\u02dc] =\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 ~~\u221a~~\n\n2\n_\ud835\udc4f_ _is the bisection SNR._\n###### \ufffd\n\n24\n\n**Robust bisection algorithm.** As a corollary, by combining Theorem 5.2, Theorem 5.3 and\nTheorem 5.4, we have a robust bisection algorithm for the _\ud835\udc58_ -stochastic block model with\noptimal bisection error rate (see Section 9 for details).\n\n**Theorem 5.5** (Robust bisection algorithm) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs_ \u02c6 _\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b]_ _such_\n1\n_that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n1\n###### \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] [\u02dc]\n_\ud835\udc5b_ [\u2225\u02c6] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u25e6][\u2225][2][ \u2a7d] [exp] 8\n###### \ufffd\n\n+ _\ud835\udc42_ ( _\ud835\udc58\ud835\udf02_ ) _._\n###### \ufffd\n\n2\n\n2\n\n_where_ _\ud835\udc36_ [\u02dc] = _\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 \u221a _\ud835\udc4f_ _is the bisection SNR and \ud835\udc65_ [\u25e6] \u2208{\u00b11} _[\ud835\udc5b]_ _is a true community bisection_\n###### \ufffd\ufffd \ufffd\n\n_of \ud835\udc3a_ [\u25e6] _._\n\n_where_ _\ud835\udc36_ [\u02dc] =\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_\n\n_\ud835\udc58_ \u2212 \u221a\n\n##### **5.2 Robust initialization for symmetry breaking**\n\nBy recursively applying Theorem 5.5, we can cluster the vertices into _\ud835\udc58_ communities\n###### with error rate exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] \ud835\udc58 [\ud835\udc51] [2] [,][\ud835\udf00] + poly( \ud835\udc58 ) \ud835\udf02 (see Section 10 for details). When \ud835\udc36\ud835\udc51,\ud835\udf00 \u2a7e \ufffd \ufffd\n\n\u03a9( _\ud835\udc58_ [2] log _\ud835\udc58_ ), we get an error rate of 1/poly( _\ud835\udc58_ ) + poly( _\ud835\udc58_ ) _\ud835\udf02_ .\n\n**Theorem 5.6** (Initialization for symmetry breaking) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated_\n_from the \ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the_\n###### nodes in \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large]\n\n_constant \ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs an_\n_estimator_ _\ud835\udc4d_ [\u02c6] \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly1( _\ud835\udc5b_ ) _[,]_\n\n###### error\ud835\udc58 ( \ud835\udc4d, \ud835\udc4d [\u02c6] [\u25e6] ) \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00]\n\n_\ud835\udc58_ [2]\n###### \ufffd\n\n##### **5.3 Boosting via pairwise majority voting**\n\n+ poly( _\ud835\udc58_ ) _\ud835\udf02._\n###### \ufffd\n\nGiven the initialization with error 1/poly( _\ud835\udc58_ ) + poly( _\ud835\udc58_ ) _\ud835\udf02_, we can apply pairwise majority\nvoting to boost the accuracy of the estimator to the minimax rate. The formal main theorem\nof our robust clustering algorithm for node-corrupted k-stochastic block model is as follows.\nThe algorithm and proofs of Theorem 5.7 are presented in Section 11.\n\n**Theorem 5.7** (Robust recovery in k-SBM with optimal rate) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ )\n_be generated from the \ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting_\n###### \ud835\udf02-fraction of the nodes in \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2][ log] [ \ud835\udc58] [for]\n\n_some sufficiently large constant \ud835\udc3e. There exists a polynomial-time algorithm (see Theorem 11.1)_\n\n25\n\n_that, given observation of \ud835\udc3a, outputs an estimator_ _\ud835\udc4d_ [\u02c6] \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_\n1\n1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n###### error\ud835\udc58 ( \ud835\udc4d, \ud835\udc4d [\u02c6] [\u25e6] ) \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ud835\udc58\n\n### **6 Robust rough initialization**\n\n+ poly( _\ud835\udc58_ ) \u00b7 _\ud835\udf02_ _._\n###### \ufffd\n\nIn this section, we prove Theorem 5.2 via a natural SoS-based initialization procedure. Our\nanalysis is of independent interest as it both simplifies and strictly improves upon the\ninitialization guarantees of [LM22]. In particular, we distinguish two regimes based on the\nadversarial corruption fraction _\ud835\udf02_ :\n\n###### \u2022 If \ud835\udf02 \u223c exp [\ufffd] \u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 [\ufffd] (the critical, minimax regime), our goal is to obtain an initial\n\nrecovery error bounded by a small constant (e.g. 0 _._ 001).\n\n###### \u2022 If \ud835\udf02 is significantly larger than exp [\ufffd] \u2212 \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 [\ufffd], the recovery error is dominated by the\n\ncorruption level, meaning that one can only hope to recover the community structure\nup to the inherent corruption threshold.\n\nIn the former case, both our method and that of [LM22] achieve the desired 0 _._ 001 recovery\nerror, which is sufficient to bootstrap our subsequent boosting step. In the latter regime,\nhowever, our SoS formulation offers a significant improvement by tolerating a constant\ncorruption fraction _\ud835\udf02_ independently of _\ud835\udc58_ . By contrast, the guarantee in [LM22] requires\n###### that \ud835\udf02 \u2272 1/ \ud835\udc58 in order to maintain the misclassification error (on the order of \ud835\udc58\ud835\udf02 ) bounded,\n\nrendering their bound vacuous as _\ud835\udc58_ diverges.\n\n**Theorem** (Restatement of Theorem 5.2) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs an estimator_\n\u02c6 1\n_\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n_error\ud835\udc58_ ( _\ud835\udc4d, \ud835\udc4d_ [\u02c6] [\u25e6] ) \u2a7d 0 _._ 001 + 10 [4] _\ud835\udf02._\n\nWe consider a constant-degree sum-of-squares relaxation for the following program:\n\n###### \ud835\udf09 \u2299 \ud835\udf09 = \ud835\udf09, \u27e8 \ud835\udf09, 1 \u27e9 \u2a7e 1 \u2212 \ud835\udf02 \u2212 exp \u2212 [2] [\ud835\udf00] [2] [\ud835\udc51] \ud835\udc5b, \ufffd \ufffd \ud835\udc58 \ufffd\ufffd\n\n_\ud835\udc3a_ \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] = _\ud835\udc3a_ input \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] _._\n\n26\n\n(6.1)\n\n_\ud835\udc4d_ \u2299 _\ud835\udc4d_ = _\ud835\udc4d,_\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = _[\ud835\udc5b]_\n###### \ufffd \ud835\udc58\n\n_\ud835\udc56_ \u2208[ _\ud835\udc5b_ ]\n\n_\ud835\udc58_ _[,]_\n\n###### \uf8fc\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8fd \uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8fe\n\n\ud835\udc9cinit( _\ud835\udf09, \ud835\udc3a, \ud835\udc4d_ ; _\ud835\udc3a_ input _, \ud835\udf02_ ) :=\n\n###### \uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = 1 _,_\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ ] _\ud835\udc56_ \u2208[ _\ud835\udc5b_\n\n_\ud835\udc51_\n\n\u2212\n_\ud835\udc3a_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc51_\n\n_\ud835\udc5b_ [11][\u22a4] [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n[1]\n###### \u2a7d \ud835\udf12 \u221a\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [)]\n###### \ufffd\ufffd\ufffd\ufffdop\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ [(] _[\ud835\udc4d\ud835\udc4d]_ [\u22a4] [\u2212] [1] _\ud835\udc58_\n\n_\ud835\udc51,_\n\nFor simplicity of notation, we let\n\n###### \ud835\udc9cbool( \ud835\udf09, \ud835\udc4d ) := \uf8f1\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f3\n\n_\ud835\udf09_ \u2299 _\ud835\udf09_ = _\ud835\udf09, \ud835\udc4d_ \u2299 _\ud835\udc4d_ = _\ud835\udc4d,_\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = 1 _,_\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ ] _\ud835\udc56_ \u2208[ _\ud835\udc5b_\n\n###### \ufffd \ud835\udc4d ( \ud835\udc56, \ud835\udc4e ) = \ud835\udc5b / \ud835\udc58 \uf8fc\uf8f4\uf8f4\uf8fd \ud835\udc56 \u2208[ \ud835\udc5b ] \uf8f4\uf8f4\uf8fe\n\n[1]\n###### \u2a7d \ud835\udf12 \u221a\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [)]\n###### \ufffd\ufffd\ufffd\ufffdop\n\n\ud835\udc9cspec( _\ud835\udc3a, \ud835\udc4d_ ) :=\n\n_\ud835\udc51_\n\n\u2212\n_\ud835\udc3a_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc51_\n\n_\ud835\udc5b_ [11][\u22a4] [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ [(] _[\ud835\udc4d\ud835\udc4d]_ [\u22a4] [\u2212] [1] _\ud835\udc58_\n\n_\ud835\udc51_\n\n###### \ufffd\n\n###### \ud835\udc9ccorr( \ud835\udf09, \ud835\udc3a ; \ud835\udc3a input, \ud835\udf02 ) := \ufffd \ud835\udc3a \u2299 \ud835\udf09\ud835\udf09 [\u22a4] = \ud835\udc3a input \u2299 \ud835\udf09\ud835\udf09 [\u22a4], \u27e8 \ud835\udf09, 1 \u27e9 \u2a7e [\ufffd] 1 \u2212 \ud835\udf02 \u2212 exp(\u22122 \ud835\udf00 [2] \ud835\udc51 / \ud835\udc58 ) [\ufffd] \ud835\udc5b \ufffd\n\nThen we have\n\n\ud835\udc9cinit( _\ud835\udf09, \ud835\udc3a, \ud835\udc4d_ ; _\ud835\udc3a_ input _, \ud835\udf02_ ) = \ud835\udc9cbool( _\ud835\udf09, \ud835\udc4d_ ) \u222a\ud835\udc9cspec( _\ud835\udc3a, \ud835\udc4d_ ) \u222a\ud835\udc9ccorr( _\ud835\udf09, \ud835\udc3a_ ; _\ud835\udc3a_ input _, \ud835\udf02_ ) _._\n\nWe first show that the program is feasible with high probability.\n\n**Lemma 6.1.** _Let \ud835\udc3a_ input _be an \ud835\udf02-corrupted stochastic block model (SBM) graph on \ud835\udc5b_ _nodes partitioned_\n_into \ud835\udc58_ _communities. Suppose that_\n###### \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2],\n\n_for a sufficiently large constant \ud835\udc3e_ _>_ 0 _. Then, with high probability, the feasibility conditions in_\n_Eq._ (6.1) _are satisfied by the choice \ud835\udf09_ = _\ud835\udf09_ 0 \u2299 **1** _\ud835\udc46_ _(where \ud835\udc46_ _is as in Cor. B.2), \ud835\udc4d_ = _\ud835\udc4d_ [\u25e6] _, and a suitable_\n_\ud835\udc3a_ _agreeing with \ud835\udc3a_ input _on the subgraph induced by the set of vertices indicated by \ud835\udf09._\n\n###### Proof. By Corollary B.2, there exists a subset \ud835\udc46 \u2286[ \ud835\udc5b ] with | \ud835\udc46 | \u2a7e [\ufffd] 1 \u2212 exp(\u22122 \ud835\udc36\ud835\udc51,\ud835\udf00 ) [\ufffd] \ud835\udc5b such\n\nthat\n###### \ufffd \ud835\udc3a [\u25e6] \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [\u2212] [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd \ud835\udc4d [\u25e6] \ud835\udc4d [\u25e6\u22a4] \u2212 [1] \ud835\udc58 [\ud835\udc3d] [\ufffd\ufffd] \u2299 1 \ud835\udc46 1 [\u22a4] \ud835\udc46 \u2a7d \ud835\udf12 \u221a \ud835\udc51, \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n###### [1] \ud835\udc58 [\ud835\udc3d] [\ufffd\ufffd] \u2299 1 \ud835\udc46 1 [\u22a4] \ud835\udc46\n\n###### \u2a7d \ud835\udf12 \u221a \ufffd\ufffd\ufffd\ufffdop\n\n###### \ufffd \ud835\udc4d [\u25e6] \ud835\udc4d [\u25e6\u22a4] \u2212 [1] \ud835\udc58\n\n_\ud835\udc5b_\n\n_\ud835\udc51,_\n\nwhere _\ud835\udf12_ is a universal constant. Let _\ud835\udf09_ be the indicator of the uncorrupted nodes intersected\nwith _\ud835\udc46_, i.e., _\ud835\udf09_ := _\ud835\udf09_ 0 \u2299 **1** _\ud835\udc46_, and take _\ud835\udc4d_ [\u25e6] \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ to be the ground-truth membership\nmatrix. Define _\ud835\udc3a_ to agree with _\ud835\udc3a_ input on the block indexed by supp( _\ud835\udf09_ ) and to equal\nthe model mean _[\ud835\udc51]_ [+] _[\ud835\udf00][\ud835\udc51]_ _\ud835\udc4d_ [\u25e6] ( _\ud835\udc4d_ [\u25e6] ) [\u22a4] \u2212 [1] [outside this block. Then the centered matrix]\n\n_[\ud835\udc51]_ _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [+] _\ud835\udc5b_\n\n###### \ud835\udc5b [\ud835\udc51] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] \u2212 [1] \ud835\udc58\n\n###### the model mean \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [+] [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] \u2212 [1] \ud835\udc58 [\ud835\udc3d] [\ufffd] [outside this block. Then the centered matrix]\n\n_\ud835\udc3a_ \u2212 _[\ud835\udc51]_ [\u2212] _[\ud835\udf00][\ud835\udc51]_ _\ud835\udc4d_ [\u25e6] _\ud835\udc4d_ [\u25e6] [\u22a4] \u2212 [1] [vanishes outside] _[\ud835\udf09]_ [ and, on] _[\ud835\udf09]_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n###### \ud835\udc5b [\ud835\udc51] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] \u2212 [1] \ud835\udc58\n\n###### \ud835\udc3a \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d] [\u2212] [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] \u2212 [1] \ud835\udc58 [\ud835\udc3d] [\ufffd] [vanishes outside][ supp][(] [\ud835\udf09] [)][ and, on][ supp][(] [\ud835\udf09] [)][, its operator norm]\n\nis bounded by _\ud835\udf12_ \u221a _\ud835\udc51_ by Corollary B.2. Hence the spectral constraint in Eq. (6.1) holds.\n\nis bounded by _\ud835\udf12_ _\ud835\udc51_ by Corollary B.2. Hence the spectral constraint in Eq. (6.1) holds.\n###### Moreover, \u27e8 \ud835\udf09, 1 \u27e9 \u2a7e [\ufffd] 1 \u2212 \ud835\udf02 \u2212 exp(\u22122 \ud835\udc36\ud835\udc51,\ud835\udf00 ) [\ufffd] \ud835\udc5b, which satisfies \ud835\udc9ccorr. Therefore, with these\n\nchoices of _\ud835\udf09_, _\ud835\udc4d_ = _\ud835\udc4d_ [\u25e6], and _\ud835\udc3a_, all feasibility conditions in Eq. (6.1) are satisfied with high\n###### probability. \u25a1\n\nNow, we give the SoS proof for the recovery guarantees.\n\n**Lemma 6.2.** _Let \ud835\udc3ainput be an \ud835\udf02-corrupted SBM graph with \ud835\udc5b_ _nodes and \ud835\udc58_ _communities, and assume_\n_that_\n###### \ud835\udf00 [2] \ud835\udc51 \u2a7e \ud835\udc3e\ud835\udc58 [2],\n\n27\n\n_for some sufficiently large constant \ud835\udc3e. Then, we have_\n\n\ud835\udc9c _init_ ( _\ud835\udf09_ [(][1][)] _, \ud835\udc3a_ [(][1][)] _, \ud835\udc4d_ [(][1][)] ; _\ud835\udc3ainput, \ud835\udf02_ ) _,_ \ud835\udc9c _init_ ( _\ud835\udf09_ [(][2][)] _, \ud835\udc3a_ [(][2][)] _, \ud835\udc4d_ [(][2][)] ; _\ud835\udc3ainput, \ud835\udf02_ )\n###### \ud835\udf09 [(][1][)], \ud835\udf09 [(][2][)], \ud835\udc3a [(][1][)], \ud835\udc3a 8 [(][2][)], \ud835\udc4d [(][1][)], \ud835\udc4d [(][2][)][ \ufffd] \ufffd \ud835\udc4d (1)( \ud835\udc4d (1))\u22a4 \u2212 \ud835\udc4d (2)( \ud835\udc4d (2))\u22a4 [\ufffd] \ufffd2F [\u2a7d] [(][0] [.] [001][ +][ 10] [\ud835\udf02] [)] [\ud835\udc5b] [2][/] [\ud835\udc58.]\n\n_Proof._ Since the constraints _\ud835\udc3a_ [(][1][)] \u2299 _\ud835\udf09_ [(][1][)] ( _\ud835\udf09_ [(][1][)] ) [\u22a4] = _\ud835\udc3a_ input \u2299 _\ud835\udf09_ [(][1][)] ( _\ud835\udf09_ [(][1][)] ) [\u22a4] and _\ud835\udc3a_ [(][2][)] \u2299 _\ud835\udf09_ [(][2][)] ( _\ud835\udf09_ [(][2][)] ) [\u22a4] =\n_\ud835\udc3a_ input \u2299 _\ud835\udf09_ [(][2][)] ( _\ud835\udf09_ [(][2][)] ) [\u22a4] hold, let _\ud835\udf09_ = _\ud835\udf09_ [(][1][)] \u2299 _\ud835\udf09_ [(][2][)] . We then have a degree-8 sum-of-squares proof\nthat\n_\ud835\udc3a_ [(][1][)] \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] = _\ud835\udc3a_ input \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] and _\ud835\udc3a_ [(][2][)] \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] = _\ud835\udc3a_ input \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] _._\n\nTherefore, we have _\ud835\udc3a_ [(][1][)] \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] = _\ud835\udc3a_ [(][2][)] \u2299 _\ud835\udf09\ud835\udf09_ [\u22a4] . By the min\u2013max characterization of the spectral\n\nnorm,\n\n_\ud835\udc3a_ [(][1][)] _,\ud835\udc4d_ [(][1][)][ \ufffd\ufffd]\n###### \ud835\udc9cbool( \ud835\udf09 [(][1][)], \ud835\udc4d [(][1][)] ) \u222a\ud835\udc9cspec( \ud835\udc3a [(][1][)], \ud835\udc4d [(][1][)] ) 8 \ufffd\ufffd\n\n_\ud835\udc3a_ [(][2][)] _,\ud835\udc4d_ [(][2][)][ \ufffd\ufffd]\n###### \ud835\udc9cbool( \ud835\udf09 [(][2][)], \ud835\udc4d [(][2][)] ) \u222a\ud835\udc9cspec( \ud835\udc3a [(][2][)], \ud835\udc4d [(][2][)] ) 8 \ufffd\ufffd\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a_ [(][1][)]\n\n_\ud835\udc5b_\n###### \ufffd\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a_ [(][2][)]\n\n_\ud835\udc5b_\n###### \ufffd\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ [(] _[\ud835\udc4d]_ [(][1][)][(] _[\ud835\udc4d]_ [(][1][)][)][\u22a4] [\u2212] [1] _\ud835\udc58_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n[1]\n###### \u2299 \ud835\udf09\ud835\udf09 [\u22a4] \u2a7d \ud835\udf12 \u221a\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [)]\n###### \ufffd \ufffd\ufffd\ufffd\ufffdop\n\n[1]\n###### \u2299 \ud835\udf09\ud835\udf09 [\u22a4] \u2a7d \ud835\udf12 \u221a\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [)]\n###### \ufffd \ufffd\ufffd\ufffd\ufffdop\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ [(] _[\ud835\udc4d]_ [(][2][)][(] _[\ud835\udc4d]_ [(][2][)][)][\u22a4] [\u2212] [1] _\ud835\udc58_\n\n_\ud835\udc51_\n\n_\ud835\udc51_\n\nBy the triangle inequality, this yields a degree-8 sum-of-squares certificate that\n\n_\ud835\udf00\ud835\udc51_\n###### \ud835\udc5b \ufffd \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4] \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc4d [(][2][)] ) [\u22a4][\ufffd] \u2299 \ud835\udf09\ud835\udf09 [\u22a4] \u2a7d 2 \ud835\udf12 \u221a \ud835\udc51. \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc51._\n\n_\ud835\udc5b_\n\n###### \ufffd \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4] \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc4d [(][2][)] ) [\u22a4][\ufffd] \u2299 \ud835\udf09\ud835\udf09 [\u22a4] \u2a7d 2 \ud835\udf12 \u221a \ufffd\ufffd\ufffd\ufffdop\n\nSince _\ud835\udc4d_ [(][1][)] and _\ud835\udc4d_ [(][2][)] are community membership matrices, each Gram matrix _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] ( _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] ) [\u22a4] has\n###### rank at most \ud835\udc58, so [\ufffd] \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4] \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc4d [(][2][)] ) [\u22a4][\ufffd] \u2299 \ud835\udf09\ud835\udf09 [\u22a4] has rank at most 2 \ud835\udc58 [12] . Thus, we obtain a\n\ndegree-8 sum-of-squares proof that\n\n2\n###### F [\u2a7d] [8] [\ud835\udf12] \ud835\udf00 [2][2] [\ud835\udc58\ud835\udc5b] \ud835\udc51 [2]\n\n2\n###### \ufffd\ufffd\ufffd\ufffd \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4] \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc4d [(][2][)] ) [\u22a4][\ufffd] \u2299 \ud835\udf09\ud835\udf09 [\u22a4][\ufffd\ufffd] \ufffdF\n\n_\ud835\udf00_ [2] _\ud835\udc51_ _._\n\nFinally, since \u2225 _\ud835\udf09_ \u22251 \u2a7e (1 \u2212 2 _\ud835\udf02_ \u2212 2 exp(\u22122 _\ud835\udf00_ [2] _\ud835\udc51_ / _\ud835\udc58_ )) _\ud835\udc5b_, we have\n\n\ud835\udc9cinit( _\ud835\udf09_ [(][1][)] _, \ud835\udc3a_ [(][1][)] _, \ud835\udc4d_ [(][1][)] ; _\ud835\udc3a_ input _, \ud835\udf02_ ) _,_ \ud835\udc9cinit( _\ud835\udf09_ [(][2][)] _, \ud835\udc3a_ [(][2][)] _, \ud835\udc4d_ [(][2][)] ; _\ud835\udc3a_ input _, \ud835\udf02_ )\n###### \ud835\udf09 [(][1][)],\ud835\udf09 [(][2][)],\ud835\udc3a [(][1][)],\ud835\udc3a 8 [(][2][)],\ud835\udc4d [(][1][)],\ud835\udc4d [(][2][)][ \ufffd] \ufffd \ud835\udc4d (1)( \ud835\udc4d (1))\u22a4 \u2212 \ud835\udc4d (2)( \ud835\udc4d (2))\u22a4 [\ufffd] \ufffd2F [\u2a7d] [8] [\ud835\udf12] \ud835\udf00 [2][2] [\ud835\udc58\ud835\udc5b] \ud835\udc51 [2] + 10 \ud835\udf02\ud835\udc5b [2] / \ud835\udc58.\n\nFinally, we conclude with the rounding step.\n\n###### \u25a1\n\n12Indeed, letting _\ud835\udc37_ = diag( _\ud835\udf09_ ) and \u0394 = _\ud835\udc4d_ (1)( _\ud835\udc4d_ (1))\u22a4 \u2212 _\ud835\udc4d_ (2)( _\ud835\udc4d_ (2))\u22a4, we have \u0394 \u2299 _\ud835\udf09\ud835\udf09_ \u22a4 = _\ud835\udc37_ \u0394 _\ud835\udc37_, hence rank(\u0394 \u2299\n_\ud835\udf09\ud835\udf09_ [\u22a4] ) \u2a7d rank(\u0394) \u2a7d 2 _\ud835\udc58_ .\n\n28\n\n###### Proof of Theorem 5.2. Let us write \ud835\udc40 [\u25e6] \ufffd \ud835\udc4d [\u25e6] ( \ud835\udc4d [\u25e6] ) [\u22a4] for the ground-truth matrix. By The\norem 6.1, the ground-truth community matrix _\ud835\udc4d_ [\u25e6] is feasible for Eq. (6.1). Hence, any\npseudo-distribution satisfying these constraints obeys\n\n###### \u2225 \ud835\udc4d\ud835\udc4d [\u22a4] \u2212 \ud835\udc40 [\u25e6] \u2225 [2] \ud835\udc39 [\u2a7d] [10] [\ud835\udf02] [\ud835\udc5b] [2][/] [\ud835\udc58] [+][ 8] [\ud835\udf12] [2] [\ud835\udc58\ud835\udc5b] [2] .\n\n_\ud835\udf00_ [2] _\ud835\udc51_\n\nStandard rounding then yields a community matrix _\ud835\udc40_ = \ud835\udd3c [\u02dc] _\ud835\udc4d\ud835\udc4d_ _[\ud835\udc47]_ \u2208[0 _,_ 1] _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5b]_ such that\n\n_[\ud835\udf02]_ + [8] _[\ud835\udf12]_ [2] _[ \ud835\udc58]_\n\n_\ud835\udc58_ _\ud835\udf00_ [2] _\ud835\udc51_\n\n_[\ud835\udf02]_\n\n\u2212\n###### \u2225 \ud835\udc40 \ud835\udc40 [\u25e6] \u2225 [2] \ud835\udc39 [\u2a7d] [\ufffd] [10]\n\n###### \ufffd \ud835\udc5b [2] . (6.2)\n\n_\ud835\udf00_ [2] _\ud835\udc51_\n\nHaving established the Frobenius-norm bound, the rest of the proof mirrors Lemma 7.3\nof [LM22]; we present it below for completeness. Since the rows of _\ud835\udc40_ lie in \u211d _[\ud835\udc5b]_, we can\napply a Euclidean _\ud835\udc58_ -means algorithm with a _\ud835\udefe_ = 7 approximation guarantee [GOR [+] 21].\nEvaluating the _\ud835\udc58_ -means objective at the ground-truth partition ( _\ud835\udc46_ 1 _, . . ., \ud835\udc46\ud835\udc58_ ) shows that\n\n_\ud835\udf02_ + [8] _[\ud835\udf12]_ [2] _[ \ud835\udc58]_\n\n_\ud835\udc58_ _\ud835\udf00_ [2] _\ud835\udc51_\n\n###### \ud835\udc58 -meansopt( \ud835\udc40 ) \u2a7d \u2225 \ud835\udc40 \u2212 \ud835\udc40 [\u25e6] \u2225 [2] \ud835\udc39 [\u2a7d] 10 \ud835\udf02 \ufffd \ud835\udc58\n\n_\ud835\udf00_ [2] _\ud835\udc51_\n\n_\ud835\udc5b_ [2] _,_\n###### \ufffd\n\n.\nwhere the last inequality is Eq. (6.2)\nNow fix any alternative clustering _\ud835\udc46_ 1 [\u2032] _[, . . ., \ud835\udc46]_ [\u2032] _\ud835\udc58_ [of the rows, and consider the same]\nclustering evaluated on _\ud835\udc40_ [\u25e6] . For one cluster, say _\ud835\udc46_ 1 [\u2032] [, let]\n\n_\ud835\udc60\ud835\udc4f_ = | _\ud835\udc46_ 1 [\u2032] [\u2229] _[\ud835\udc46][\ud835\udc4f]_ [|] for _\ud835\udc4f_ \u2208[ _\ud835\udc58_ ] _._\n\nAs in Lemma 7.3 of [LM22], the _\ud835\udc58_ -means objective contributed by _\ud835\udc46_ 1 [\u2032] [on the rows of] _[ \ud835\udc40]_ [\u25e6] [is]\nat least\n_\ud835\udc60_ 1 + \u00b7 \u00b7 \u00b7 + _\ud835\udc60\ud835\udc58_ \u2212 max{ _\ud835\udc60_ 1 _, . . ., \ud835\udc60\ud835\udc58_ }                - _[\ud835\udc5b]_ (6.3)\n###### \ufffd \ufffd 4 \ud835\udc58 [.]\n\nSumming (6.3) over all clusters _\ud835\udc46_ [\u2032] _\ud835\udc4e_ [lower-bounds the] _[ \ud835\udc58]_ [-means objective on] _[ \ud835\udc40]_ [\u25e6] [for the]\npartition _\ud835\udc46_ 1 [\u2032] _[, . . ., \ud835\udc46]_ [\u2032] _\ud835\udc58_ [. Let the computed clustering be] _[ \ud835\udc46]_ 1 [\u2032] _[, . . ., \ud835\udc46]_ [\u2032] _\ud835\udc58_ [. Define]\n\nmin\n_\ud835\udc5b_ _\ud835\udc53_ :[ _\ud835\udc58_ ]\u2192[ _\ud835\udc58_ ]\n\n_\ud835\udc58_\n###### \ufffd | \ud835\udc46 [\u2032] \ud835\udc4e [\\] [ \ud835\udc46] \ud835\udc53 ( \ud835\udc4e ) [|] [.]\n\n_\ud835\udc4e_ =1\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udeff_ = [1] min\n\n_\ud835\udc5b_ _\ud835\udf0b_ :[ _\ud835\udc58_ ]\u2192[ _\ud835\udc58_ ]\n_\ud835\udf0b_ invertible\n\n_\ud835\udc58_\n###### \ufffd\n\n###### \ufffd | \ud835\udc46 [\u2032] \ud835\udc4e [\\] [ \ud835\udc46] \ud835\udf0b ( \ud835\udc4e ) [|] [,] \ud835\udeff [\u2032] = \ud835\udc5b [1]\n\n_\ud835\udc4e_ =1\n\nHere _\ud835\udeff_ is exactly the misclassification error of _\ud835\udc46_ 1 [\u2032] _[, . . ., \ud835\udc46]_ [\u2032] _\ud835\udc58_ [relative to the ground truth. As]\n###### in [LM22], one has \ud835\udeff \u2a7d 2 \ud835\udeff [\u2032] . Moreover, using (6.3) and summing over clusters shows that\n\nthe _\ud835\udc58_ -means objective of _\ud835\udc46_ 1 [\u2032] _[, . . ., \ud835\udc46]_ [\u2032] _\ud835\udc58_ [on] _[ \ud835\udc40]_ [\u25e6] [is at least] 4 _[\ud835\udc5b]_ _\ud835\udc58_ [2] _[\ud835\udeff]_ [\u2032][. Combining this lower bound]\n\nwith the _\ud835\udefe_ -approximation guarantee on _\ud835\udc40_ and Eq. (6.2) (exactly as in Lemma 7.3 of [LM22])\nyields\n\n_\ud835\udf02_ _[\ud835\udf12]_ [2] _[ \ud835\udc58]_\n\n_\ud835\udc58_ [+] _\ud835\udf00_ [2] _\ud835\udc51_\n\n_\ud835\udf02_\n###### \ud835\udeff \u2a7d 10 [4] \ud835\udc58\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udf00_ [2] _\ud835\udc51_\n\n_,_\n###### \ufffd\n\n###### which is the desired bound. \u25a1\n\n29\n\n### **7 Robustly identifying well-recovered clusters**\n\nIn this section, we show that given a set of _\ud835\udc5b_ / _\ud835\udc58_ vertices in the graph sampled from\nSBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ), we can decide between\n\n  - Case I: at least 0.99 of the vertices in the set belong to the same community;\n\n  - Case II: no more than 0.98 of the vertices in the set belong to any single community.\n\n**Restriction to the given set.** Let _\ud835\udc46_ \u2286[ _\ud835\udc5b_ ] denote the given set of | _\ud835\udc46_ | = _\ud835\udc5b_ / _\ud835\udc58_ vertices, and let\n**1** = **1** _\ud835\udc46_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ be its indicator. We define the matrices restricted to _\ud835\udc46_ as\n\n###### \ud835\udc3a\ud835\udc60 \ufffd \ud835\udc3a \u2299( 1 \ud835\udc46 1 [\u22a4] \ud835\udc46 [)] and \ud835\udc3d\ud835\udc60 \ufffd 1 \ud835\udc46 1 [\u22a4] \ud835\udc46 [.]\n\nThroughout this section, every appearance of _\ud835\udc3a_ and _\ud835\udc3d_ inside operator norms or inner\nproducts is to be understood as _\ud835\udc3a\ud835\udc60_ and _\ud835\udc3d\ud835\udc60_ respectively. We also view all vectors (e.g., _\ud835\udc67, \ud835\udf0f, \ud835\udf01_ )\nas elements of \u211d _[\ud835\udc5b]_ supported on _\ud835\udc46_ .\n\n**Theorem** (Restatement of Theorem 5.3) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. For any set \ud835\udc46_ \u2282 _\ud835\udc49_ _of \ud835\udc5b_ / _\ud835\udc58_ _vertices, there exists a polynomial-time algorithm that, with probability_\n1\n1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[, outputs]_\n\n - _YES if at least_ 0 _._ 99 _of the vertices in \ud835\udc46_ _belong to the same community;_\n\n - _NO if no more than_ 0 _._ 98 _of the vertices in \ud835\udc46_ _belong to any single community._\n\nWe will show that the feasibility of the degree-2 SoS relaxation of the following program\nsatisfies Theorem 5.3.\n\n###### \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67, \u27e8 \ud835\udc67, 1 \u27e9 \u2a7e [\ufffd] [0] [.] \ud835\udc58 [99]\n\n_\ud835\udc58_ [3]\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) :=\n\n###### \uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n###### \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67, \u27e8 \ud835\udc67, 1 \u27e9 \u2a7e [\ufffd] [0] [.] \ud835\udc58 [99] \u2212 \ud835\udf02 \u2212 \ud835\udf0c [\ufffd] \ud835\udc5b \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] [\u2a7d] [\ud835\udf12] \ufffd \ud835\udefc / \ud835\udc58\n\n###### \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd \ud835\udefc / \ud835\udc58 \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0] [.] [97][(]\n\n_[\ud835\udefc]_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd\n\n_,_ (7.1)\n\n###### \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0] [.] [97][(] [\ud835\udc58] \ud835\udc58 [\u2212][3][1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n###### \uf8fc\uf8f4\uf8f4\uf8f4\uf8f4\uf8fd \uf8f4\uf8f4\uf8f4\uf8f4\uf8fe\n\nwhere _\ud835\udefc_ = _\ud835\udc51_ + (1 \u2212 [1] _\ud835\udc58_ [)] _[\ud835\udf00][\ud835\udc51]_ [,] _[ \ud835\udf02]_ [is the corruption rate,] _[ \ud835\udf12]_ [is the universal constant defined in the]\n###### spectral result in Theorem B.1, and \ud835\udf0c = exp [\ufffd] \u22122 \ud835\udc36\ud835\udc51,\ud835\udf00 \ufffd is the fraction of high-degree vertices\n\nthat need to be trimmed to obtain the spectral norm bound (see Theorem B.2).\n\n**Lemma 7.1.** _Given a set of \ud835\udc5b_ / _\ud835\udc58_ _vertices in the graph sampled from_ SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _where at least_\n###### 0.99 fraction of the vertices in the set belongs to the same community (Case I), when \ud835\udf02 \u2a7d \ud835\udc36\ud835\udf02 for some\n\n_constant \ud835\udc36\ud835\udf02_ _that is small enough, Program Eq._ (7.1) _is feasible with probability at least_ 1 \u2212 _\ud835\udc5b_ [\u2212][\u03a9][(][1][)] _._\n\n30\n\n_Proof._ Let _\ud835\udf0f_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ (supported on _\ud835\udc46_ ) be the indicator vector for the largest set of\nuncorrupted and degree-bounded nodes (according to Theorem B.1) that are in the same\ncommunity. We will show that, with probability 1 \u2212 _\ud835\udc5b_ [\u2212][\u03a9][(][1][)], _\ud835\udf0f_ is a feasible solution to the\n\n.\nprogram Eq. (7.1)\nBy assumption, \u2225 _\ud835\udf0f_ \u22251 \u2a7e ( [0] _[.]_ _\ud835\udc58_ [99] \u2212 _\ud835\udf02_ \u2212 _\ud835\udf0c_ ) _\ud835\udc5b_ . Therefore, _\ud835\udf0f_ satisfies the integrality and norm\n\nBy assumption, \u2225 _\ud835\udf0f_ \u22251 \u2a7e ( _[.]_ _\ud835\udc58_ \u2212 _\ud835\udf02_ \u2212 _\ud835\udf0c_ ) _\ud835\udc5b_ . Therefore, _\ud835\udf0f_ satisfies the integrality and norm\n\n.\nconstraints of program Eq. (7.1)\n###### By Theorem B.1, with probability at least 1 \u2212 \ud835\udc5b [\ud835\udc58] [2][2] [, we have] \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udf0f\ud835\udf0f [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd \ud835\udefc \ud835\udc58 [.]\n\nTherefore, _\ud835\udf0f_ satisfies the spectral constraint of program Eq. (7.1).\n###### Now, consider \ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] [,][ \ud835\udf0f\ud835\udf0f] [\u22a4][\ufffd] . Notice that \u27e8 \ud835\udc3a\ud835\udc60, \ud835\udf0f\ud835\udf0f [\u22a4] \u27e9 is equal to 2 times the number of\n\n_[\ud835\udefc]_ ~~_\ud835\udefc_~~\n\n\u2299 _\ud835\udf0f\ud835\udf0f_ [\u22a4][\ufffd\ufffd]\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd op [\u2a7d] [\ud835\udf12] \ufffd \ud835\udc58\n\n###### \ud835\udc5b [\ud835\udc58] [2] [, we have] \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b\n\n###### Now, consider \ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] [,][ \ud835\udf0f\ud835\udf0f] [\u22a4][\ufffd] . Notice that \u27e8 \ud835\udc3a\ud835\udc60, \ud835\udf0f\ud835\udf0f [\u22a4] \u27e9 is equal to 2 times the number of\n\nedges in the induced subgraph _\ud835\udc3a\ud835\udc60_ ( _\ud835\udf0f_ ) where each edge is sampled independently with\nprobability _[\ud835\udefc]_ _\ud835\udc5b_ [. Therefore, by Chernoff bound, it follows that, with probability at least]\n\nprobability _[\ud835\udefc]_ _\ud835\udc5b_ [. Therefore, by Chernoff bound, it follows that, with probability at least]\n\n1 \u2212 _\ud835\udc5b_ [\u2212][100],\n\n_\ud835\udefc_ log( _\ud835\udc5b_ )\n###### \ufffd \ud835\udc3a\ud835\udc60, \ud835\udf0f\ud835\udf0f [\u22a4][\ufffd] \u2a7e [\ud835\udefc] [\u2225] [\ud835\udf0f] [\u2225] 1 [2] [\u2212] [\ud835\udc42] \ufffd \u2225 \ud835\udf0f \u2225 [2] 1 .\n\n1 [\u2212] _[\ud835\udc42]_\n_\ud835\udc5b_ [\u2225] _[\ud835\udf0f]_ [\u2225][2]\n\n###### \ufffd \ufffd\n\n_\ud835\udefc_ log( _\ud835\udc5b_ )\n\n\u2225 _\ud835\udf0f_ \u2225 [2] 1\n_\ud835\udc5b_\n\n###### \ufffd\n\n_._\n\nHence,\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n###### \ufffd\n\n_[\ud835\udc51]_\n###### \u2a7e [\ud835\udefc] [\u2212] [\ud835\udc51]\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_ _[,][ \ud835\udf0f\ud835\udf0f]_ [\u22a4] _\ud835\udc5b_\n###### \ufffd\n\n###### \ufffd\n\n[\u2212]\n\n\u2225 _\ud835\udf0f_ \u2225 [2] 1 [\u2212] _[\ud835\udc42]_\n_\ud835\udc5b_\n\n###### \ufffd \ufffd\n\n_\ud835\udefc_ log( _\ud835\udc5b_ )\n\n\u2225 _\ud835\udf0f_ \u2225 [2] 1\n_\ud835\udc5b_\n\n_\ud835\udefc_ log( _\ud835\udc5b_ )\n\n_._\n\nSince _\ud835\udefc_ = _\ud835\udc51_ + (1 \u2212 [1]\n\n###### [)] [\ud835\udf00][\ud835\udc51] [,] [ \ud835\udefc] [\u2a7d] [2] [\ud835\udc51] [and][ \u2225] [\ud835\udf0f] [\u2225][1] [\u2a7e] [(] [.] \ud835\udc58 \u2212 \ud835\udf02 \u2212 \ud835\udf0c ) \ud835\udc5b, it follows that \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udc51] \u2a7e [0] [.] [98][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] \u2212 \ud835\udc42 \ud835\udc51 log( \ud835\udc5b ) \ufffd \ud835\udc5b [\ud835\udc3d][\ud835\udc60] [,][ \ud835\udf0f\ud835\udf0f] [\u22a4] \ufffd \ud835\udc58 [3] \ufffd\ufffd \ufffd\n\n###### [1] \ud835\udc58 [)] [\ud835\udf00][\ud835\udc51] [,] [ \ud835\udefc] [\u2a7d] [2] [\ud835\udc51] [and][ \u2225] [\ud835\udf0f] [\u2225][1] [\u2a7e] [(] [0] [.] \ud835\udc58 [99]\n\n_[\ud835\udc51]_\n###### \u2a7e [0] [.] [98][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] [,][ \ud835\udf0f\ud835\udf0f] [\u22a4] \ufffd \ud835\udc58 [3]\n\n[\u2212] _[\ud835\udf00]_ \u2212\n\n_\ud835\udc42_\n###### \ud835\udc58 [3] \ufffd\ufffd\n\n_\ud835\udc51_ log( _\ud835\udc5b_ )\n###### \ufffd\n\n###### \u2a7e [0] [.] [975][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] .\n\n_\ud835\udc58_ [3]\n\n###### Thus, \ud835\udf0f satisfies the sum constraint of program Eq. (7.1), which finishes the proof. \u25a1\n\n**Lemma 7.2.** _Given a set of \ud835\udc5b_ / _\ud835\udc58_ _vertices in the graph sampled from_ SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _where at most a_\n###### 0.98 fraction of the vertices in the set belongs to the same community (Case II), when \ud835\udf02 \u2a7d \ud835\udc36\ud835\udf02 for\n\n_some constant \ud835\udc36\ud835\udf02_ _that is small enough, Program Eq._ (7.1) _is not feasible with probability at least_\n1 \u2212 _\ud835\udc5b_ [\u2212][\u03a9][(][1][)] _._\n\n_Proof._ We will show that there is an SoS proof of\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \ufffd \u2a7d [0] [.] [963][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b],\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \ufffd \u2a7d [0] [.] [963][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n###### \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0] [.] [97][(] [\ud835\udc58] \ud835\udc58 [\u2212][3][1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n###### which is a refutation to constraint \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n_[.]_ [\u2212]\n###### which is a refutation to constraint \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e \ud835\udc58 [3] in \ud835\udc9cverify( \ud835\udc67 ; \ud835\udc3a, \ud835\udf02 ).\n\nLet us denote the set of uncorrupted and degree-bounded (according to Theorem B.2)\nnodes by _\ud835\udf01_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ (supported on _\ud835\udc46_ ). By Theorem B.2, it follows that \u2225 _\ud835\udf01_ \u22251 \u2a7e (1 \u2212 _\ud835\udf02_ \u2212 _\ud835\udf0c_ ) _[\ud835\udc5b]_ _\ud835\udc58_\n###### and \ufffd\ufffd\ufffd( \ud835\udc3a 0) \ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd\ufffd] [\u2a7d] [\ud835\udf12] \ufffd \ud835\udc51 / \ud835\udc58, where ( \ud835\udc3a 0) \ud835\udc60 \ufffd \ud835\udc3a 0 \u2299( 1 1 [\u22a4] ). Consider the largest set\n\n_[\ud835\udc51]_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd\n\n###### and \ufffd\ufffd\ufffd( \ud835\udc3a 0) \ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd \ud835\udc51 / \ud835\udc58, where ( \ud835\udc3a 0) \ud835\udc60 \ufffd \ud835\udc3a 0 \u2299( 1 1 [\u22a4] ). Consider the largest set\n\nof vertices in _\ud835\udf01_ that are from the same community, denoted by _\ud835\udf0f_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ (supported on _\ud835\udc46_ ).\nBy our assumption, it follows that \u2225 _\ud835\udf0f_ \u22251 \u2a7d 0 _._ 98 _[\ud835\udc5b]_ _\ud835\udc58_ [.]\n\n_\ud835\udc58_ [.]\n\n31\n\n###### We will decompose \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n###### We will decompose \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] into the following three terms and bound\n\nthem separately\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4]\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_ _\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4]\n###### \ufffd \ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd \ufffd \ufffd\ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4] _._\n###### \ufffd \ufffd\n\n(7.2)\n\n+ _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n+ _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ 2( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] + _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd \ufffd \ufffd\ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ 2( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] + _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd \ufffd \ufffd\ufffd\n\n###### Term 1. For the first term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n###### Term 1. For the first term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], \ud835\udf0f\ud835\udf0f [\u22a4] + ( \ud835\udf01 \u2212 \ud835\udf0f )( \ud835\udf01 \u2212 \ud835\udf0f ) [\u22a4][\ufffd], we can further de\ncompose it into the following two terms\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4]\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_ _\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4]\n###### \ufffd \ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd \ufffd \ufffd\ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n+ _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4] _._\n###### \ufffd \ufffd\n\nThe two terms can be bounded using the same method. Consider the first term\n\u2212 _[\ud835\udc51]_\n###### \ufffd\ufffd \ud835\udc3a\ud835\udc60 \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], \ud835\udf0f\ud835\udf0f [\u22a4][\ufffd], it follows that\n\n_[\ud835\udc51]_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], \ud835\udf0f\ud835\udf0f [\u22a4][\ufffd], it follows that\n\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] = _\ud835\udc3a_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udefc]_\n###### \ufffd\ufffd \ud835\udc5b \ufffd \ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2212\n\n_[\ud835\udefc]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4][\ufffd] + _\ud835\udefc_ _\ud835\udc51_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \ud835\udc5b \ufffd\n\n\u2212\n_\ud835\udc51_\n\n_\ud835\udc3d\ud835\udc60_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4]\n_\ud835\udc5b_\n###### \ufffd\n\n_[\ud835\udefc]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4][\ufffd] + _[\ud835\udefc]_ [\u2212] _[\ud835\udc51]_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \ud835\udc5b\n\n= _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udefc]_\n###### \ufffd\ufffd \ud835\udc5b\n\n\u27e8 _\ud835\udf0f, \ud835\udc67_ \u27e9 [2] _._\n_\ud835\udc5b_\n\n\u2212 _[\ud835\udefc]_\n###### Since \ud835\udc9cverify certifies \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd\n\n_\ud835\udefc_ / _\ud835\udc58_, it follows that\n\n###### \u2299 \ud835\udc67\ud835\udc67 [\u22a4], \ud835\udf0f\ud835\udf0f [\u22a4] \u2a7d \ud835\udf12 \ufffd \ufffd \ufffd\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\n_\ud835\udefc_ / _\ud835\udc58_ \u2225 _\ud835\udf0f_ \u2225 [2] + _[\ud835\udefc]_ [\u2212] _[\ud835\udc51]_ \u27e8 _\ud835\udf0f, \ud835\udc67_ \u27e9 [2] _._\n\n_\ud835\udc5b_\n\nUsing the same analysis by replacing _\ud835\udf0f_ by _\ud835\udf01_ \u2212 _\ud835\udf0f_, we can also obtain\n\n###### \u2299 \ud835\udc67\ud835\udc67 [\u22a4], ( \ud835\udf01 \u2212 \ud835\udf0f )( \ud835\udf01 \u2212 \ud835\udf0f ) [\u22a4] \u2a7d \ud835\udf12 \ufffd \ufffd \ufffd\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n_\ud835\udefc_ / _\ud835\udc58_ \u2225 _\ud835\udf01_ \u2212 _\ud835\udf0f_ \u2225 [2] + _[\ud835\udefc]_ [\u2212] _[\ud835\udc51]_ \u27e8 _\ud835\udf01_ \u2212 _\ud835\udf0f, \ud835\udc67_ \u27e9 [2] _._\n\n_\ud835\udc5b_\n\nCombining the two inequalities, we get\n\n(7.3)\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4]\n###### \ufffd \ufffd\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n###### \u2a7d [\ud835\udefc] [\u2212] [\ud835\udc51] \ufffd\u27e8 \ud835\udf0f, \ud835\udc67 \u27e9 [2] + \u27e8 \ud835\udf01 \u2212 \ud835\udf0f, \ud835\udc67 \u27e9 [2][\ufffd] + \ud835\udf12 \ufffd\n\n_\ud835\udc5b_\n\n###### \u2a7d [\ud835\udefc] [\u2212] [\ud835\udc51]\n\n###### \ud835\udefc / \ud835\udc58 \ufffd\u2225 \ud835\udf0f \u2225 [2] + \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u2225 [2][\ufffd] .\n\n_\ud835\udc67_\n###### Since \ud835\udc9cverify( \ud835\udc67 ; \ud835\udc3a, \ud835\udf02 ) 2 0 \u2a7d \ud835\udc67 \u2a7d 1, it follows that \u27e8 \ud835\udf0f, \ud835\udc67 \u27e9 \u2a7d \u2225 \ud835\udf0f \u22251 and \u27e8 \ud835\udf01 \u2212 \ud835\udf0f, \ud835\udc67 \u27e9 \u2a7d \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u22251. Moreover, since \u2225 \ud835\udf0f \u22251 \u2a7d 0 . 98 [\ud835\udc5b] \ud835\udc58 [and][ \u2225] [\ud835\udf01] [\u2225][1] [\u2a7d] [\ud835\udc5b] \ud835\udc58 [, the value of][ \u2225] [\ud835\udf0f] [\u2225] 1 [2] [+ \u2225] [\ud835\udf01] [\u2212] [\ud835\udf0f] [\u2225][2] 1 [is upper bounded]\n\n###### Moreover, since \u2225 \ud835\udf0f \u22251 \u2a7d 0 . 98 [\ud835\udc5b] \ud835\udc58 [and][ \u2225] [\ud835\udf01] [\u2225][1] [\u2a7d] [\ud835\udc5b] \ud835\udc58 [, the value of][ \u2225] [\ud835\udf0f] [\u2225] 1 [2] [+ \u2225] [\ud835\udf01] [\u2212] [\ud835\udf0f] [\u2225][2] 1 [is upper bounded]\n\nby (0 _._ 98 _[\ud835\udc5b]_ _\ud835\udc58_ [)][2][ + (][0] _[.]_ [02] _[\ud835\udc5b]_ _\ud835\udc58_ [)][2][ \u2a7d] [0] _[.]_ [961] _[\ud835\udc5b]_ [2][2] [. Therefore, we can obtain]\n\n###### [\ud835\udc5b] \ud835\udc58 [and][ \u2225] [\ud835\udf01] [\u2225][1] [\u2a7d] [\ud835\udc5b] \ud835\udc58\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_ [2]\n\n_\ud835\udc58_ [)][2][ \u2a7d] [0] _[.]_ [961] _\ud835\udc58_ [2]\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udc58_ [)][2][ + (][0] _[.]_ [02] _\ud835\udc58_\n\n_[\ud835\udc5b]_ _\ud835\udc58_ [2] [. Therefore, we can obtain]\n\n###### 2 \ud835\udc67 \u27e8 \ud835\udf0f, \ud835\udc67 \u27e92 + \u27e8 \ud835\udf01 \u2212 \ud835\udf0f, \ud835\udc67 \u27e92 \u2a7d \u2225 \ud835\udf0f \u222521 [+ \u2225] [\ud835\udf01] [\u2212] [\ud835\udf0f] [\u2225][2] 1 [\u2a7d] [0] [.] [961] [\ud835\udc5b] [2]\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n_\ud835\udc58_ [2] _[.]_ (7.4)\n\n32\n\nSince _\ud835\udf0f_ and _\ud835\udf01_ are Boolean vectors and _\ud835\udf0f_ \u2286 _\ud835\udf01_, it follows that\n\n###### \u2225 \ud835\udf0f \u2225 [2] + \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u2225 [2] = \u2225 \ud835\udf01 \u2225 [2] \u2a7d [\ud835\udc5b] (7.5)\n\n_\ud835\udc58_ _[.]_\n\nPlugging Eq. (7.4) and Eq. (7.5) into Eq. (7.3), we can obtain\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _, \ud835\udf0f\ud835\udf0f_ [\u22a4] + ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ )( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) [\u22a4]\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd \ufffd \ufffd\n\n[(] _[\ud835\udefc]_ [\u2212] _[\ud835\udc51]_ [)] _[\ud835\udc5b]_ + _[\ud835\udf12]_ [\u221a] _[\ud835\udefc][\ud835\udc5b]_\n\n_\ud835\udc58_ [2] ~~\u221a~~ _\ud835\udc58_ [3]\n\n###### \u2a7d [0] [.] [961][(] [\ud835\udefc] [\u2212] [\ud835\udc51] [)] [\ud835\udc5b]\n\n_._\n_\ud835\udc58_ [3]\n\n###### Plugging in \ud835\udefc = \ud835\udc51 + (1 \u2212 [1] \ud835\udc58 [)] [\ud835\udf00][\ud835\udc51] [and] [ \ud835\udefc] [\u2a7d] [2] [\ud835\udc51] [, we get]\n\n[\u2212] [1][)] _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_ \u221a\n\n+ [2] _[\ud835\udf12]_\n_\ud835\udc58_ [3]\n\n_\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n_._\n_\ud835\udc58_ [3]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\n###### [\ud835\udc51] \u2299 \ud835\udc67\ud835\udc67 [\u22a4], \ud835\udf0f\ud835\udf0f [\u22a4] + ( \ud835\udf01 \u2212 \ud835\udf0f )( \ud835\udf01 \u2212 \ud835\udf0f ) [\u22a4] \u2a7d [0] [.] [961][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \ufffd \ud835\udc58 [3]\n\n(7.6)\n\n###### Term 2. For the the second term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n###### Term 2. For the the second term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 2( \ud835\udf01 \u2212 \ud835\udf0f ) \ud835\udf0f [\u22a4][\ufffd], since we are summing\n\nover entries in the set of uncorrupted vertices _\ud835\udf01_, it follows that\n\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ 2( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] = 2 ( _\ud835\udc3a_ 0) _\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udf01\ud835\udf01_ [\u22a4] _,_ ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _._\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_ _\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ 2( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] = 2 ( _\ud835\udc3a_ 0) _\ud835\udc60_ \u2212 _[\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd \ufffd \ufffd\ufffd\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udf01\ud835\udf01_ [\u22a4] _,_ ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _._\n###### \ufffd \ufffd\n\n###### To simplify notation, let us denote \ud835\udc40\ud835\udc51 = [\ufffd] ( \ud835\udc3a 0) \ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udf01\ud835\udf01 [\u22a4] . It follows by SoS Cauchy\nSchwarz (Theorem A.3) that\n\n2\ufffd _\ud835\udc40\ud835\udc51,_ ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) _\ud835\udf0f_ [\u22a4] \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4][\ufffd] = 2\u27e8 _\ud835\udc40\ud835\udc51_      - ( _\ud835\udf0f_ \u2299 _\ud835\udc67_ ) _,_ ( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) \u2299 _\ud835\udc67_ \u27e9\n\n###### \u2a7d [\u2225] [\ud835\udc40][\ud835\udc51] [\u00b7 ][(] [\ud835\udf0f] [\u2299] [\ud835\udc67] [)\u2225][2]\n\n_\ud835\udc51_ / _\ud835\udc58_ \u2225( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) \u2299 _\ud835\udc67_ \u2225 [2] _._\n\n###### + \ud835\udf12 \ufffd\n\n_\ud835\udc51_ / _\ud835\udc58_\n\n###### \ud835\udf12 \ufffd\n\n###### Since we chose \ud835\udf01 such that \u2225 \ud835\udc40\ud835\udc51 \u2225op \u2a7d \ud835\udf12 \ufffd \ud835\udc51 / \ud835\udc58, it follows that\n\n###### 2\ufffd \ud835\udc40\ud835\udc51, ( \ud835\udf01 \u2212 \ud835\udf0f ) \ud835\udf0f [\u22a4] \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd] \u2a7d \ud835\udf12 \ufffd\n\n_\ud835\udc51_ / _\ud835\udc58_ \u2225( _\ud835\udf01_ \u2212 _\ud835\udf0f_ ) \u2299 _\ud835\udc67_ \u2225 [2] + \u2225 _\ud835\udf0f_ \u2299 _\ud835\udc67_ \u2225 [2][\ufffd] _._\n###### \ufffd\n\n###### Since \ud835\udc9cverify( \ud835\udc67 ; \ud835\udc3a, \ud835\udf02 ) 2 \ud835\udc67 0 \u2a7d \ud835\udc67 \u2a7d 1, it follows that \u2225( \ud835\udf01 \u2212 \ud835\udf0f ) \u2299 \ud835\udc67 \u22252 \u2a7d \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u22252 and \u2225 \ud835\udf0f \u2299 \ud835\udc67 \u22252 \u2a7d \u2225 \ud835\udf0f \u2225 [2] . Moreover, since \ud835\udf01 and \ud835\udf0f are Boolean, we have \u2225 \ud835\udf0f \u2225 [2] + \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u2225 [2] = \u2225 \ud835\udf01 \u2225 [2] \u2a7d [\ud835\udc5b] [. Hence, we]\n\nSince \ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n###### \u2225 \ud835\udf0f \u2225 . Moreover, since \ud835\udf01 and \ud835\udf0f are Boolean, we have \u2225 \ud835\udf0f \u2225 + \u2225 \ud835\udf01 \u2212 \ud835\udf0f \u2225 = \u2225 \ud835\udf01 \u2225 \u2a7d [\ud835\udc5b] \ud835\udc58 [. Hence, we]\n\ncan obtain\n\n_\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n(7.7)\n\n_[.]_\n_\ud835\udc58_ [3]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n###### \ufffd\n\n###### [\ud835\udc51] 2( \ud835\udf01 \u2212 \ud835\udf0f ) \ud835\udf0f [\u22a4][\ufffd] \u2299 \ud835\udc67\ud835\udc67 [\u22a4] \u2a7d [\ud835\udf12] \u221a \ud835\udc5b [\ud835\udc3d][\ud835\udc60] [,] [ \ufffd] \ufffd \u221a\n\n33\n\n###### Term 3. For the third term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n###### Term 3. For the third term \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd], we can further decompose it\n\ninto\n\n\u2212\n_\ud835\udefc_ _\ud835\udc51_\n\n_\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udc51]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udefc]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4][\ufffd] + _\ud835\udc3d\ud835\udc60_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd\ufffd \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \ud835\udc5b \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd\n\n(7.8)\n###### Since \ud835\udc9cverify certifies \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] [\u2a7d] [\ud835\udf12] \ufffd \ud835\udefc / \ud835\udc58 and \u2225 \ud835\udf01 \u22251 \u2a7e (1 \u2212 \ud835\udf02 \u2212 \ud835\udf0c ) [\ud835\udc5b] \ud835\udc58 [, we can apply]\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4] = _\ud835\udc3a\ud835\udc60_ \u2212 _[\ud835\udefc]_\n###### \ufffd\ufffd \ud835\udc5b \ufffd \ufffd\n\n\u2212\n\n_[\ud835\udefc]_ \u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4][\ufffd] + _\ud835\udefc_ _\ud835\udc51_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \ud835\udc5b \ufffd\ufffd\n\n_\ud835\udc3d\ud835\udc60_\n_\ud835\udc5b_\n\n\u2299 _\ud835\udc67\ud835\udc67_ [\u22a4] _,_ **1 1** [\u22a4] \u2212 _\ud835\udf01\ud835\udf01_ [\u22a4] _._\n###### \ufffd \ufffd\n\n_[\ud835\udefc]_\n###### \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ufffd\n\n_\ud835\udefc_ / _\ud835\udc58_ and \u2225 _\ud835\udf01_ \u22251 \u2a7e (1 \u2212 _\ud835\udf02_ \u2212 _\ud835\udf0c_ ) _[\ud835\udc5b]_ _\ud835\udc58_\n\n###### Since \ud835\udc9cverify certifies \ufffd\ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 [\ud835\udefc] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4][\ufffd\ufffd] op [\u2a7d] [\ud835\udf12] \ud835\udefc / \ud835\udc58 and \u2225 \ud835\udf01 \u22251 \u2a7e (1 \u2212 \ud835\udf02 \u2212 \ud835\udf0c ) [\ud835\udc5b] \ud835\udc58 [, we can apply]\n\nFrobenius Cauchy\u2013Schwarz and get\n\n###### \ud835\udc67 [\ufffd\ufffd]\n\n\u2212 _[\ud835\udefc]_\n\n2 _\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n\n~~\u221a~~\n\n_._\n_\ud835\udc58_ [3]\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n2 _\ud835\udf12_ [\u221a] ~~_\ud835\udf02_~~ ~~+~~ ~~_\ud835\udf0c_~~ [\u221a] _\ud835\udefc\ud835\udc5b_\n###### [\ud835\udefc] \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd] \u2a7d \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd\n\n[3]\n\n###### Since \ud835\udefc \u2a7d 2 \ud835\udc51, \ud835\udf0c \u226a 1 (due to Theorem B.2) and the assumption that \ud835\udf02 \u226a 1, it follows that\n\n###### \ud835\udc67 [\ufffd\ufffd]\n\n\u2212 _[\ud835\udefc]_\n\n2 _\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n\n_\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n(7.9)\n\n_[.]_\n_\ud835\udc58_ [3]\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u221a\n###### [\ud835\udefc] \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4][\ufffd] \u2a7d [\ud835\udf12] \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd\n\n_\ud835\udc67_ 1\n###### 0 \u2a7d \ud835\udc67 \u2a7d 1 and \ud835\udefc = \ud835\udc51 + (1 \u2212\n\nSince \ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n_\ud835\udc58_ [)] _[\ud835\udf00][\ud835\udc51]_ [, it follows that]\n\n_[\ud835\udf0c]_ [)] _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4] \ufffd \u2a7d [2][(] [\ud835\udc58] [\u2212] [1][)(] \ud835\udc58 [\ud835\udf02] [3][+] .\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212\n_\ud835\udefc_ _\ud835\udc51_\n\n_\ud835\udc3d\ud835\udc60_\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\nSince _\ud835\udf0c_ \u226a 1 (due to Theorem B.2) and the assumption that _\ud835\udf02_ \u226a 1, it follows that\n\n###### \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4] \u2a7d [0] [.] [001][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] . (7.10) \ufffd \ufffd \ud835\udc58 [3]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212\n_\ud835\udefc_ _\ud835\udc51_\n\n_\ud835\udc3d\ud835\udc60_\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\nPlugging Eq. (7.9) and Eq. (7.10) into Eq. (7.8), it follows that\n\n_\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \u2212 \ud835\udf01\ud835\udf01 [\u22a4] \ufffd \u2a7d [0] [.] [001][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n[\u2212] [1][)] _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_ \u221a\n\n+ _[\ud835\udf12]_\n_\ud835\udc58_ [3]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n(7.11)\n\n_[.]_\n_\ud835\udc58_ [3]\n\n**Conclusion.** Plugging Eq. (7.6), Eq. (7.7) and Eq. (7.11) into Eq. (7.2), we can obtain\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \ufffd \u2a7d [0] [.] [962][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n[\u2212] [1][)] _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_ \u221a\n\n+ [4] _[\ud835\udf12]_\n_\ud835\udc58_ [3]\n\n_\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n_._\n_\ud835\udc58_ [3]\n\nSince _\ud835\udc58_ [2] \u226a _\ud835\udf00_ [2] _\ud835\udc51_, we can obtain\n\n4 _\ud835\udf12_ \u221a\n\n_\ud835\udf12_ _\ud835\udc51\ud835\udc5b_\n\n~~\u221a~~ _\ud835\udc58_ [3]\n\n    - _[\ud835\udf00][\ud835\udc51\ud835\udc5b]_\n_\ud835\udc58_ _\ud835\udc58_ [2]\n\n_\ud835\udc51\ud835\udc5b_\n###### \u2a7d [0] [.] [00001]\n\n_\ud835\udc58_ [3] ~~\u221a~~ _\ud835\udc58_\n\n_[\ud835\udc51\ud835\udc5b]_\n###### [\u2a7d] [0] [.] [001][(] [\ud835\udc58] [\u2212] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n_\ud835\udc58_ [2] _\ud835\udc58_ [3]\n\n_\ud835\udc58_ [3] _._\n\nThus, it follows that\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \ufffd \u2a7d [0] [.] [963][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b] .\n\n###### \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4] \ufffd \u2a7d [0] [.] [963][(] [\ud835\udc58] \ud835\udc58 [\u2212][3] [1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n_\ud835\udc67_\n\n\ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ ) 2\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_ _[\ud835\udc3d][\ud835\udc60]_\n###### \ufffd\ufffd\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a\ud835\udc60_\n\n_\ud835\udc5b_\n###### \ufffd\ufffd\n\n###### \ud835\udc5b [\ud835\udc51] [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e [0] [.] [97][(] [\ud835\udc58] \ud835\udc58 [\u2212][3][1][)] [\ud835\udf00][\ud835\udc51\ud835\udc5b]\n\n###### This is a refutation to constraint \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc51]\n\n_[.]_ [\u2212]\n###### This is a refutation to constraint \ufffd\ufffd \ud835\udc3a\ud835\udc60 \u2212 \ud835\udc5b [\ud835\udc3d][\ud835\udc60] \ufffd \u2299 \ud835\udc67\ud835\udc67 [\u22a4], 1 1 [\u22a4][\ufffd] \u2a7e \ud835\udc58 [3] in \ud835\udc9cverify( \ud835\udc67 ; \ud835\udc3a, \ud835\udf02 ), which finishes the proof. \u25a1\n\n34\n\n_Proof of Theorem 5.3._ By Theorem 7.1 and Theorem 7.2, it follows that, given a set of _\ud835\udc5b_ / _\ud835\udc58_\nvertices in the graph sampled from SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ), we can check feasibility of \ud835\udc9cverify( _\ud835\udc67_ ; _\ud835\udc3a, \ud835\udf02_ )\n(interpreted with _\ud835\udc3a\ud835\udc60_ _, \ud835\udc3d\ud835\udc60_ as above) in time _\ud835\udc5b_ _[\ud835\udc42]_ [(][1][)] to decide whether the set of vertices is in\nCase I or Case II:\n\n  - Case I (at least 0 _._ 99 of the vertices in the set belong to the same community): feasibility\nfollows by Theorem 7.1. Since the SoS SDP has small bit complexity and there exists a\nBoolean solution, by arguments analogous to those in [RW17], the ellipsoid method\nwill be able to find a feasible solution in time _\ud835\udc5b_ _[\ud835\udc42]_ [(][1][)] .\n\n  - Case II (no more than 0 _._ 98 of the vertices in the set belong to any single community):\nBy Theorem 7.2, the SoS program is infeasible; hence no feasible solution exists (and,\nin particular, none can be found in time _\ud835\udc5b_ _[\ud835\udc42]_ [(][1][)] ).\n\n###### The success probability is 1 \u2212 \ud835\udc5b [\u2212][\u03a9][(][1][)] . \u25a1\n\n### **8 Robust boosting algorithm for bisection**\n\nIn this section, we prove Theorem 5.4 for the robust bisection algorithm in the _\ud835\udc58_ -stochastic\nblock model. The procedure essentially constitutes recovery in the 2-SBM model by\naggregating communities into two global groups, each comprising _\ud835\udc58_ /2 local communities.\n\n##### **8.1 Algorithm and constraint systems**\n\nWe first introduce the polynomial constraints that we use in the algorithm.\n\n**(i) Labeling constraints.** The feasible label variable _\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ satisfies\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = _[\ud835\udc5b]_ _\ud835\udc58_\n\n_\ud835\udc56_\n\n\ud835\udc9clabel( _\ud835\udc4d_ ) :=\n\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) [2] = _\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) _,_\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = 1 _,_\n###### \ufffd\n\n_\ud835\udc4e_ _\ud835\udc56_\n\n_\ud835\udc58_\n\n###### \ufffd\n\n_._ (8.1)\n\n**(ii) Initialization.** Let _\ud835\udc4d_ init \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ be an initializer 0 _._ 001-approximation error and recovers\n0 _._ 99 fraction of the vertices in communities _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2], we add constraints to enforce the SoS\nvariable _\ud835\udc4d_ is close to _\ud835\udc4d_ init,\n\n_._ (8.2)\n###### \ufffd\n\n\ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init) :=\n\n###### \u2225 \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4e )\u2225 [2] \u2a7d 0 . 001 \ud835\udc5b / \ud835\udc58 \u2200 \ud835\udc4e \u2208[ \ud835\udc58 /2]\n\n2\n###### \ufffd\ufffd\ufffd\ufffd \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(\u00b7] [, \ud835\udc4e] [) \u2212] [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [init][(\u00b7] [, \ud835\udc4e] [)] \ufffd\ufffd \u2a7d 0 . 001 \ud835\udc5b\n\n**(iii) Corruption mask / node distance.** We model node corruptions through a binary mask\n_\ud835\udf09_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ and require the program matrix to agree with the observed graph outside the\ncorrupted rows/columns:\n\n###### \ufffd\n\n\ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ) :=\n\n###### \ufffd\n\n###### ( \ud835\udc4c \u2212 \ud835\udc3a [\u00af] ) \u2299( 1 \u2212 \ud835\udf09 )( 1 \u2212 \ud835\udf09 ) [\u22a4] = 0, \ud835\udf09 \u2299 \ud835\udf09 = \ud835\udf09, \ufffd \ud835\udf09\ud835\udc56 \u2a7d \ud835\udeff\ud835\udf02\ud835\udc5b\n\n_\ud835\udc56_\n\n###### ( \ud835\udc4c \u2212 \ud835\udc3a [\u00af] ) \u2299( 1 \u2212 \ud835\udf09 )( 1 \u2212 \ud835\udf09 ) [\u22a4] = 0, \ud835\udf09 \u2299 \ud835\udf09 = \ud835\udf09, \ufffd\n\n_,_ (8.3)\n\n35\n\nwhere _\ud835\udeff\ud835\udf02_ = exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ ) + _\ud835\udf02_ .\n\n**(iv) Community structure and spectral condition.** We encode the decomposition of the\ncentered adjacency into pairwise components and bound the spectral norm of the noise\nblocks:\n\n###### \ud835\udc51 \u2a7d \ud835\udf12 + [1]\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ _\ud835\udc58_\n###### \ufffd\ufffd\ufffd\ufffdop \ufffd\n\n_\ud835\udc58_\n\n\ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) :=\n\n###### \ufffd\n\n_\ud835\udc4b_ = _\ud835\udc4d\ud835\udc4d_ [\u22a4] \u2212 [1]\n\n[1] _\ud835\udc4c_ \u2212 _\ud835\udf00\ud835\udc51_\n\n_\ud835\udc58_ _[\ud835\udc3d,]_ _\ud835\udc5b_\n###### \ufffd\ufffd\ufffd\ufffd\n\n###### \ufffd\n\n_._ (8.4)\n\n\u221a\n###### \ufffd\n\n_\ud835\udc51_\n\n**(v) Majority-vote consistency.** The final constraint system characterizes the constraints for\nthe consistency of bisection majority voting, i.e. enforcing that the induced bisection of\n_\ud835\udc4b_ (bisection of vertices in community [ 2 _[\ud835\udc58]_ []][ and][ (] 2 _[\ud835\udc58]_ _[, \ud835\udc58]_ []][) is consistent with the concentration]\n\n_[\ud835\udc58]_ _[\ud835\udc58]_\n\n2 []][ and][ (] 2\n\n_\ud835\udc4b_ (bisection of vertices in community [ 2 []][ and][ (] 2 _[, \ud835\udc58]_ []][) is consistent with the concentration]\n\nresult for majority voting:\n\n###### \ufffd\ufffd\n\n_\ud835\udc67\ud835\udc56_ \u2212 _\ud835\udefd\ud835\udefe,_ \u02dc _\ud835\udc36_ _\ud835\udc5b_\n###### \ufffd\ufffd \ud835\udc56\n\n\ud835\udc9cmaj( _\ud835\udc4c, \ud835\udc4d, \ud835\udc45_ ; _\ud835\udefe,_ _\ud835\udc36_ [\u02dc] ) :=\n\n###### \ufffd\n\n_\ud835\udc62_\n###### \ud835\udc45 : \ud835\udc9cset( \ud835\udc67 ) 2 \u27e8 \ud835\udc4c\ud835\udc65 ( \ud835\udc4d ), \ud835\udc65 ( \ud835\udc4d ) \u2299 \ud835\udc67 \u27e9 \u2a7e \ud835\udefc\ud835\udefe\n\n_,_ (8.5)\n\nwhere _\ud835\udefc_ = (1\u2212 _\ud835\udefe_ ) _\ud835\udf00\ud835\udc51_\n_\ud835\udefe_ 16 _\ud835\udc58_\n\n2 _\ud835\udc4d_ (\u00b7 _, \ud835\udc4e_ ) \u2212 **1** [13] .\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n_\ud835\udefe_ _\ud835\udf00_ = 640 _\ud835\udc58_\n\n16 _\ud835\udc58_, _\ud835\udefd\ud835\udefe,_ \u02dc _\ud835\udc36_ 1\u2212 _\ud835\udefe_\n\n640 _\ud835\udc58_\n\n1\u2212 _\ud835\udefe_ [exp][(\u2212] _[\ud835\udefe][\ud835\udc36]_ [\u02dc] [/][2][)][,][ \ud835\udc9c][set][(] _[\ud835\udc67]_ [)][ :][=][ {] _[\ud835\udc67]_ [\u2299] _[\ud835\udc67]_ [=] _[ \ud835\udc67]_ [}][, and] _[ \ud835\udc65]_ [(] _[\ud835\udc4d]_ [)][ \ufffd]\n\n2\n###### \ufffd\n\nFor our algorithm, we define polynomial system \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udefe,_ _\ud835\udc36_ [\u02dc] ) based\non the set of constraints defined above [14]\n\n\ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udefe,_ _\ud835\udc36_ [\u02dc] )\n\n:= \ud835\udc9clabel( _\ud835\udc4d_ ) \u222a\ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init) \u222a\ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ) \u222a\ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) \u222a\ud835\udc9cmaj( _\ud835\udc4c, \ud835\udc4d, \ud835\udc45_ ; _\ud835\udefe,_ _\ud835\udc36_ [\u02dc] ) _._\n(8.6)\n\n**Algorithm.** Now we describe our algorithm in Theorem 8.1.\n\n**.**\n**Algorithm 8.1** (Robust bisection boosting algorithm)\n**Input:** The graph _\ud835\udc3a_ sampled from the _\ud835\udc58_ -stochastic block model SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) with _\ud835\udf02\ud835\udc5b_\ncorrupted nodes, and initial clusters _\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 \u2286[ _\ud835\udc5b_ ] with its corresponding label\nmatrix _\ud835\udc4d_ init.\n\n1. Finding degree- _\ud835\udc42_ (1) pseudo-distribution satisfying the polynomial constraints\n\ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udefe,_ _\ud835\udc36_ [\u02dc] ) where _\ud835\udc3a_ [\u00af] = _\ud835\udc3a_ \u2212 _\ud835\udc5b_ _[\ud835\udc51]_ _[\ud835\udc3d]_ [is the centered adjacency matrix,]\n\n= [1]\n_\ud835\udefe_ 2 [and][ \u02dc] _[\ud835\udc36]_ [=]\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 \u221a\n\n2\n_\ud835\udc4f_ .\n###### \ufffd\n\n2. Rounding the pseudo-distribution by sign to obtain the bisection \u02c6 _\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b]_ from\n###### \ud835\udc65 ( \ud835\udc4d ) = 2 [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(\u00b7] [, \ud835\udc4e] [) \u2212] [1] [.]\n\n13We write _\ud835\udc65_ for simplicity when _\ud835\udc4d_ is clear from context\n14For simplicity, we use \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) to denote \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; \u00af _\ud835\udc3a, \ud835\udc4d_ init _, \ud835\udf02, \ud835\udefe,_ \u02dc _\ud835\udc36_ ) when the input is clear from\nthe context.\n\n36\n\n##### **8.2 Feasibility and time complexity**\n\nWe first show that the program is feasible with high probability and runs in polynomial\n\ntime.\n\n**Lemma 8.2.** _Let_ _\ud835\udc3a_ [\u00af] [\u25e6] _be the centered adjacency matrix of the uncorrupted graph and \ud835\udc46_ _be the_\n_set of nodes with degree larger than_ 20 _\ud835\udc51. Let \ud835\udc47_ _be the set of corrupted nodes. Let \ud835\udc4d_ [\u25e6] _be the_\n_ground truth label matrix. Under the setting of Theorem 8.1, program_ \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) _is satisfied by_\n( _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] _[, \ud835\udc4d]_ [\u25e6] _[,]_ **[ 1]** _[\ud835\udc46]_ [\u222a] _[\ud835\udc47]_ [)] _[ with probability at least]_ [ 1][ \u2212] _[\ud835\udc5b]_ [\u2212][\u03a9][(][1][)][ \u2212] [exp][(\u2212][\u03a9][(] _[\ud835\udc58]_ [))] _[.]_\n\n_Proof._ Note that \ud835\udc9clabel( _\ud835\udc4d_ [\u25e6] ) and \ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init) is satisfied by definition. Let _\ud835\udc4b_ [\u25e6] = _\ud835\udc4d_ [\u25e6] ( _\ud835\udc4d_ [\u25e6] ) [\u22a4] \u2212 [1] _\ud835\udc58_\n\n_Proof._ Note that \ud835\udc9clabel( _\ud835\udc4d_ [\u25e6] ) and \ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init) is satisfied by definition. Let _\ud835\udc4b_ [\u25e6] = _\ud835\udc4d_ [\u25e6] ( _\ud835\udc4d_ [\u25e6] ) \u2212 _\ud835\udc58_ _[\ud835\udc3d]_ [.]\n\nBy\u00af Theorem B.2, the size of set _\ud835\udc46_ is bounded by exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ ) _\ud835\udc5b_ and the spectral norm of\n_\ud835\udc3a_ [\u25e6] \u2212 _[\ud835\udf00][\ud835\udc51]_ _[\ud835\udc4b]_ [\u25e6] \u221a _\ud835\udc51_\n\n_[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_ _[\ud835\udc4b]_ [\u25e6] [is bounded by] _[ \ud835\udf12]_ \u221a\n\n_[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc4b]_ [\u25e6] [is bounded by] _[ \ud835\udf12]_ _\ud835\udc51_ with high probability. Notice that\n\n###### \ud835\udc3a \u00af \u25e6 \u2299( 1 \u00af \ud835\udc46 1 \u22a4 \ud835\udc46 \u00af [) \u2212] [\ud835\udf00] \ud835\udc5b [\ud835\udc51] [\ud835\udc4b] [\u25e6] \u2a7d \ud835\udc3a \u00af [\u25e6] \u2212 [\ud835\udf00] \ud835\udc5b [\ud835\udc51] [\ud835\udc4b] [\u25e6] \u2299( 1 \u00af \ud835\udc46 1 [\u22a4] \ud835\udc46 \u00af [)] + [\ud835\udf00] \ud835\udc5b [\ud835\udc51] \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\n\n_[\ud835\udc51]_\n###### \u2a7d\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [\u25e6]\n###### \ufffd\ufffd\ufffd\ufffdop \ufffd\ufffd\ufffd\ufffd\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] + _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n###### \ufffd \ufffd\ufffd\ufffd\ufffdop\n\n\u00af\n\u2212 _[\ud835\udf00][\ud835\udc51]_\n_\ud835\udc3a_ [\u25e6]\n\n_\ud835\udc5b_\n###### \ufffd\n\n_\ud835\udc5b_\n\n###### \ufffd\ufffd\ufffd \ud835\udc4b \u25e6 \u2299( \ud835\udc3d \u2212 1 \u00af \ud835\udc46 1 \u22a4 \ud835\udc46 \u00af [)] \ufffd\ufffd\ufffdop\n\n_\ud835\udc51_ + _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_\n\n###### \u2a7d \ud835\udf12 \u221a \u2a7d \ud835\udf12 \u221a \u2a7d \ud835\udf12 \u221a\n\n_[\ud835\udf00]_ _\ud835\udc51_\n\n~~\u221a~~ _\ud835\udc58_\n\n###### \ufffd\ufffd\ufffd \ud835\udc4b \u25e6 \u2299( \ud835\udc3d \u2212 1 \u00af \ud835\udc46 1 \u22a4 \ud835\udc46 \u00af [)] \ufffd\ufffd\ufffdF\n\nexp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ )\u221a\n_\ud835\udc58_\n\n_\ud835\udc51_ + [2] _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_\n\n\u221a\n_\ud835\udc51_ + [4] _[\ud835\udf00]_\n\n_\ud835\udc51_\n\n###### \ufffd\ufffd \ud835\udc4b \u25e6 \u2299( 11 \u22a4 \ud835\udc46 [)] \ufffd\ufffdF\n\n= _\ud835\udf12_ \u221a _\ud835\udc51_ + 4 _\ud835\udc36\ud835\udc51,\ud835\udf00_ exp(\u2212 _\ud835\udc36\ud835\udc51,\ud835\udf00_ )\u221a\n\n_\ud835\udc51_\n\n###### \u2a7d \ud835\udf12 + [1]\n\n_\ud835\udc58_\n###### \ufffd\n\n~~\u221a~~ _\ud835\udc51._\n###### \ufffd\n\nTherefore, \ud835\udc9cmix( _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] _[, \ud835\udc4d]_ [\u25e6][)][ is feasible with probability][ 1] [\u2212] _[\ud835\udc5b]_ [\u2212] _[\ud835\udc42]_ [(][1][)][. Moreover,][ \u2225] **[1]** _[\ud835\udc46]_ [\u222a] _[\ud835\udc47]_ [\u2225][1][ \u2a7d]\n\n| _\ud835\udc46_ | + | _\ud835\udc47_ | \u2a7d _\ud835\udeff\ud835\udf02\ud835\udc5b_ with probability 1 \u2212 _\ud835\udc5b_ [\u2212] _[\ud835\udc42]_ [(][1][)] . Hence, \ud835\udc9cclose( _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] _[,]_ **[ 1]** _[\ud835\udc46]_ [\u222a] _[\ud835\udc47]_ [;] _[ \ud835\udf02][,]_ [ \u00af] _[\ud835\udc3a]_ [)][ is feasible]\n\nwith probability 1 \u2212 _\ud835\udc5b_ [\u2212] _[\ud835\udc42]_ [(][1][)] .\nBy Theorem 4.4, the voting lower bound in \ud835\udc9cmaj( _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] _[, \ud835\udc4d]_ [\u25e6] _[, \ud835\udc45]_ [;] _[ \ud835\udefe][,]_ [ \u02dc] _[\ud835\udc36]_ [)][ is feasible for]\n\n2\n\n2\n\n_\ud835\udefe_ = [1] 2 [and][ \u02dc] _[\ud835\udc36]_ [=] _\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 \u221a _\ud835\udc4f_ with probability 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 _\ud835\udc5b_ [\u2212][\u03a9][(][1][)] . The existence\n###### \ufffd\ufffd \ufffd\n\nof the SoS proof of Theorem 4.3 follows by Theorem A.6 and Theorem A.7.\n###### The feasibility proof is completed by a union bound over all failure probabilities. \u25a1\n\n[1] 2 [and][ \u02dc] _[\ud835\udc36]_ [=]\n###### \ufffd\ufffd\n\n= [1]\n_\ud835\udefe_ 2\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_\n\n_\ud835\udc58_ \u2212 \u221a\n\n**Lemma 8.3.** _Theorem 8.1 runs in polynomial time._\n\n_Proof._ Since the sum-of-squares relaxation is at a constant degree, the resulting semidefinite\nprogram involves only polynomially many constraints and can be solved in polynomial\n\n###### time. \u25a1\n\n37\n\n##### **8.3 SoS guarantees for robust bisection boosting**\n\nNow, we show that \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) boosts the bisection error rate from 0 _._ 001 to 1/poly( _\ud835\udc58_ ). To do\nthis, we consider two feasible solutions ( _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)] ) and ( _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)] ) of \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ).\nWe will show that the constraints in \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) allow us to prove that any two good\nsolutions will be close to each other in the bisection sense. Since _\ud835\udc4d_ [\u25e6] will also be a good\nsolution, this implies that any feasible solution of \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) will be close to _\ud835\udc4d_ [\u25e6] in the\nbisection sense.\n\nThroughout this section, we define the following terms:\n\n###### \u2022 Let \ud835\udc65 [(][1][)] = 2 [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(][1][)][(\u00b7] [, \ud835\udc4e] [) \u2212] [1] [ and] [ \ud835\udc65] [(][2][)][ =][ 2][ \ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(][2][)][(\u00b7] [, \ud835\udc4e] [) \u2212] [1] [ be the induced]\n\nbisections of _\ud835\udc4d_ [(][1][)] and _\ud835\udc4d_ [(][2][)] .\n\n  - Let _\ud835\udc63_ = **[1]** [\u2212] _[\ud835\udc65]_ [(][1] 2 [)][\u2299] _[\ud835\udc65]_ [(][2][)] be the set of nodes where the bisections _\ud835\udc65_ [(][1][)] and _\ud835\udc65_ [(][2][)] differ.\n\n  - Let _\ud835\udc60_ = **1** \u2212( **1** \u2212 _\ud835\udf09_ [(][1][)] ) \u2299( **1** \u2212 _\ud835\udf09_ [(][2][)] ) be the set of nodes where _\ud835\udc4c_ [(][1][)] and _\ud835\udc4c_ [(][2][)] differ.\n\n  - Let _\ud835\udc64_ = _\ud835\udc63_ \u2299( **1** \u2212 _\ud835\udc60_ ) be the set of vertices in the shared part of _\ud835\udc4c_ [(][1][)] and _\ud835\udc4c_ [(][2][)] such that\nthe bisections _\ud835\udc65_ [(][1][)] and _\ud835\udc65_ [(][2][)] differ.\n\n  - Let _\ud835\udc54_ = **1** \u2212( **1** \u2212 _\ud835\udc63_ ) \u2299( **1** \u2212 _\ud835\udc60_ ) be union of _\ud835\udc63_ and _\ud835\udc60_, notice that, equivalently _\ud835\udc54_ = _\ud835\udc64_ + _\ud835\udc60_ .\n\nTo prove the algorithmic guarantee of \ud835\udc9c( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ), we need the following observations\non properties of the variables defined above.\n\n**Lemma 8.4.** _\ud835\udc65_ [(][1][)] _, \ud835\udc65_ [(][2][)] _and \ud835\udc63_ _satisfies_\n\n_\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc63_ = \u2212 _\ud835\udc65_ [(][2][)] \u2299 _\ud835\udc63_ _and_ _\ud835\udc65_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc63_ ) = _\ud835\udc65_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc63_ ) _,_\n\n_and,_\n\n_[\ud835\udc65]_ [(][1][)]\n\n= _\ud835\udc63_ \u2299 **[1]** [ +] _[ \ud835\udc65]_ [(][2][)]\n2 2\n\n_[\ud835\udc65]_ [(][2][)]\n\n= _\ud835\udc63_ \u2299 **[1]** [ +] _[ \ud835\udc65]_ [(][1][)]\n2 2\n\n2 _._\n\n_\ud835\udc63_ \u2299 **[1]** [ \u2212] _[\ud835\udc65]_ [(][1][)]\n\n_[ \ud835\udc65]_ [(][2][)]\n\n_and_ _\ud835\udc63_ \u2299 **[1]** [ \u2212] _[\ud835\udc65]_ [(][2][)]\n2 2\n\n_Proof._ By the definition of _\ud835\udc63_ = **[1]** [\u2212] _[\ud835\udc65]_ [(][1] 2 [)][\u2299] _[\ud835\udc65]_ [(][2][)], it follows that\n\n_\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc63_ = _[\ud835\udc65]_ [(][1][)][ \u2212] _[\ud835\udc65]_ [(][2][)] = \u2212 _\ud835\udc65_ [(][2][)] \u2299 _\ud835\udc63,_\n\n2\n\nand,\n\n_\ud835\udc65_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc63_ ) = _[\ud835\udc65]_ [(][1][)][ +] _[ \ud835\udc65]_ [(][2][)] = _\ud835\udc65_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc63_ ) _._\n\n2\n\nNow, we show _\ud835\udc63_ \u2299 **[1]** [\u2212] _[\ud835\udc65]_ [(][1][)]\n\n_[\ud835\udc65]_ [(][1][)]\n\n= _\ud835\udc63_ \u2299 **[1]** [+] _[\ud835\udc65]_ [(][2][)]\n2 2\n\n2 _[\ud835\udc65]_, and the other side follows by symmetry. By plugging\n\nin _\ud835\udc63_ = **[1]** [\u2212] _[\ud835\udc65]_ [(][1] 2 [)][\u2299] _[\ud835\udc65]_ [(][2][)], the left hand side is\n\n_\ud835\udc63_ \u2299 **[1]** [ \u2212] _[\ud835\udc65]_ [(][1][)]\n\n_[\ud835\udc65]_ [(][1][)]\n\n= **[1]** [ \u2212] _[\ud835\udc65]_ [(][1][)][ \u2212] _[\ud835\udc65]_ [(][1][)][ \u2299] _[\ud835\udc65]_ [(][2][)][ +] _[ \ud835\udc65]_ [(][2][)]\n2 4\n\n4 _,_\n\n38\n\nand the right hand side is\n\n_\ud835\udc63_ \u2299 **[1]** [ +] _[ \ud835\udc65]_ [(][2][)]\n\n_[ \ud835\udc65]_ [(][2][)]\n\n= **[1]** [ +] _[ \ud835\udc65]_ [(][2][)][ \u2212] _[\ud835\udc65]_ [(][1][)][ \u2299] _[\ud835\udc65]_ [(][2][)][ \u2212] _[\ud835\udc65]_ [(][1][)]\n2 4\n\n4 _._\n\nTherefore, we have _\ud835\udc63_ \u2299 **[1]** [\u2212] _[\ud835\udc65]_ [(][1][)]\n\n_[\ud835\udc65]_ [(][1][)]\n\n= _\ud835\udc63_ \u2299 **[1]** [+] _[\ud835\udc65]_ [(][2][)]\n2 2\n\n###### 2 . \u25a1\n\n**Lemma 8.5.**\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n_\ud835\udc4c_ [(][1][)] _,\ud835\udc4d_ [(][1][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udc4c_ [(][2][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][2][)]\n###### \ud835\udc42 (1) \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd = \u2212\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd .\n\n_Proof._ Plugging in the definition of _\ud835\udc54_ and _\ud835\udc64_, the left hand side can be written as\n\n###### \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd = \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc63 ) \u2299( 1 \u2212 \ud835\udc60 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc63 \u2299( 1 \u2212 \ud835\udc60 )\ufffd = \ufffd\ufffd \ud835\udc4c [(][1][)] \u2299( 1 \u2212 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4][\ufffd] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc63 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc63 \ufffd .\n\nBy \ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ), we have\n\n_\ud835\udc4c_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc3a_ [\u00af] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc4c_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] _,_\n\nand, by Theorem 8.4, we have\n\n_\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc63_ = \u2212 _\ud835\udc65_ [(][2][)] \u2299 _\ud835\udc63_ and _\ud835\udc65_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc63_ ) = _\ud835\udc65_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc63_ ) _,_\n\nThus,\n\n###### \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd = \u2212 \ud835\udc4c [(][2][)] \u2299( 1 \u2212 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4][\ufffd] ( \ud835\udc65 [(][2][)] \u2299( 1 \u2212 \ud835\udc63 )), \ud835\udc65 [(][2][)] \u2299 \ud835\udc63 \ufffd\ufffd \ufffd = \u2212\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd .\n\n**Lemma 8.6.** _The norm of \ud835\udc63, \ud835\udc60_ _and \ud835\udc54_ _satisfies the following SoS inequalities_\n\n###### \u25a1\n\n_and,_\n\n_and,_\n\n_\ud835\udc4d_ [(][1][)] _,\ud835\udc4d_ [(][2][)]\n###### \ud835\udc9c \ufffd \ud835\udc4c [(][1][)], \ud835\udc4d [(][1][)], \ud835\udf09 [(][1][)][\ufffd], \ud835\udc9c \ufffd \ud835\udc4c [(][2][)], \ud835\udc4d [(][2][)], \ud835\udf09 [(][2][)][\ufffd] \ud835\udc42 (1) \ud835\udc9c \ufffd \ud835\udc4c [(][1][)], \ud835\udc4d [(][1][)], \ud835\udf09 [(][1][)][\ufffd], \ud835\udc9c \ufffd \ud835\udc4c [(][2][)], \ud835\udc4d [(][2][)], \ud835\udf09 [(][2][)][\ufffd] \ud835\udf09 [(] \ud835\udc42 [1][)] (,\ud835\udf09 1) [(][2][)]\n\n###### \u2225 \ud835\udc63 \u2225 [2] \u2a7d 0 . 004 \ud835\udc5b, \u2225 \ud835\udc60 \u2225 [2] \u2a7d 2 \ud835\udeff\ud835\udf02\ud835\udc5b,\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n_\ud835\udc4d_ [(][1][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udf09_ [(][2][)]\n\n_\ud835\udc42_ (1)\n\n###### \u2225 \ud835\udc64 \u2225 [2] \u2a7d 0 . 004 \ud835\udc5b,\n\n_and, for any \ud835\udc4f_ \u2208[ 2 _[\ud835\udc58]_ []] _[ and][ \ud835\udc61]_ [\u2208{][1] _[,]_ [ 2][}] _[,]_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \ud835\udc4d [(][1][)],\ud835\udc4d\ud835\udc42 [(][2][)], 1 \ud835\udf09 [(][1][)],\ud835\udf09 [(][2][)] \ufffd \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4f ), \ud835\udc64 \ufffd \u2a7d [0] [.] [004] [\ud835\udc5b]\n\n_\ud835\udc42_ (1)\n\n_\ud835\udc58_ _._\n\n39\n\n_Proof._ For the bound on _\ud835\udc63_, by constraints in \ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init), it follows that\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\n\n**1** \u2212 _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc65_ [(][2][)]\n\u2225 _\ud835\udc63_ \u2225 [2] =\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\n\n###### \ufffd\ufffd\ufffd\ufffd\n\n2\n_\ud835\udc65_ [(][1][)] \u2212 _\ud835\udc65_ [(][2][)]\n\n=\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\n\n2\n\n2\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc4d_ [(][2][)] (\u00b7 _, \ud835\udc4e_ )\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n=\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc4d_ [(][1][)] (\u00b7 _, \ud835\udc4e_ ) \u2212\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2] _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /\n\n###### \ufffd\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n2\n\n2\n\n_\ud835\udc4d_ init(\u00b7 _, \ud835\udc4e_ )\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc4d_ init(\u00b7 _, \ud835\udc4e_ )\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n###### \u2a7d 2\n\n_\ud835\udc4d_ [(][1][)] (\u00b7 _, \ud835\udc4e_ ) \u2212\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2] _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /\n\n###### \ufffd\n\n+ 2\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc4d_ [(][2][)] (\u00b7 _, \ud835\udc4e_ ) \u2212\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2] _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /\n\n###### \ufffd\n\n###### \u2a7d 0 . 004 \ud835\udc5b.\n\nFor the bound on _\ud835\udc60_, by constraints in \ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ), it follows that\n\n_\ud835\udf09_ [(] _\ud835\udc56_ [2][)][(][1][ \u2212] _[\ud835\udf09]_ [(] _\ud835\udc56_ [1][)][)]\n\n_\ud835\udc56_\n\n###### \u2225 \ud835\udc60 \u2225 [2] = \ufffd\n\n_\ud835\udc60\ud835\udc56_ =\n###### \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### 1 \u2212(1 \u2212 \ud835\udf09 [(] \ud835\udc56 [1][)][) \u2299(][1][ \u2212] [\ud835\udf09] [(] \ud835\udc56 [2][)][)][ =] \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \ud835\udf09 [(] \ud835\udc56 [1][)] + \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \ud835\udf09 [(] \ud835\udc56 [1][)] + \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \u2a7d \ufffd\n\n###### \ud835\udf09 [(] \ud835\udc56 [2][)] \u2a7d 2 \ud835\udeff\ud835\udf02\ud835\udc5b.\n\n_\ud835\udc56_\n\nNow, consider _\ud835\udc64_ = _\ud835\udc63_ \u2299( **1** \u2212 _\ud835\udc60_ ). Therefore,\n\n###### \u2225 \ud835\udc64 \u2225 [2] = \u2225 \ud835\udc63 \u2299( 1 \u2212 \ud835\udc60 )\u2225 [2] \u2a7d \u2225 \ud835\udc63 \u2225 [2] \u2a7d 0 . 004 \ud835\udc5b.\n\nFor the last inequality, for _\ud835\udc4f_ \u2208[ 2 _[\ud835\udc58]_\n\n_\ud835\udc4f_ \u2208[ 2 []][, it follows that]\n\n###### \ufffd \ud835\udc4d [(][1][)] (\u00b7, \ud835\udc4f ), \ud835\udc64 \ufffd = \ufffd \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) \ud835\udc63\ud835\udc56 (\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ ) _\ud835\udc63\ud835\udc56_ _._\n\n_\ud835\udc56_\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ ) _\ud835\udc63\ud835\udc56_ (1 \u2212 _\ud835\udc60\ud835\udc56_ ) \u2a7d\n###### \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### Since \ud835\udc63 = \ud835\udc65 [(][1][)] \u2299 \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(][1][)][(\u00b7] [, \ud835\udc4e] [) \u2212] [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(][2][)][(\u00b7] [, \ud835\udc4e] [)] and \ud835\udc65 [(][1][)] \u2299 \ud835\udc4d [(][1][)] (\u00b7, \ud835\udc4f ) = \ud835\udc4d [(][1][)] (\u00b7, \ud835\udc4f ) for \ufffd\ufffd \ufffd\n\n_\ud835\udc4f_ \u2208[ _[\ud835\udc58]_\n\n2 []][, we have]\n\n###### \ufffd\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ ) _\ud835\udc65_ [(] _\ud835\udc56_ [1][)]\n###### \ufffd\ufffd\n\n_\ud835\udc56_ _\ud835\udc4e_ _\ud835\udc58_ 2\n\n_\ud835\udc4d_ [(][2][)] ( _\ud835\udc56, \ud835\udc4e_ )\n###### \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ ) _\ud835\udc63\ud835\udc56_ =\n###### \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4e_ ) \u2212\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2] _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /\n\n=\n###### \ufffd\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ ) \u2212\n###### \ufffd\n\n_\ud835\udc56_ _\ud835\udc4e_ _\ud835\udc58_\n\n_\ud835\udc4d_ [(][2][)] ( _\ud835\udc56, \ud835\udc4e_ ) _\ud835\udc4d_ [(][1][)] ( _\ud835\udc56, \ud835\udc4f_ )\n###### \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n###### \u2a7d \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc56, \ud835\udc4f ) \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) \ufffd\n\n_\ud835\udc56_\n\n###### = \ufffd \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) [\ufffd] 1 \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc56, \ud835\udc4f ) [\ufffd]\n\n_\ud835\udc56_\n\n###### \u2a7d \ufffd\n\n_\ud835\udc56_\n\n###### \ufffd \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) \u2212 \ud835\udc4d [(][2][)] ( \ud835\udc56, \ud835\udc4f ) [\ufffd] [2]\n\n2\n###### = \ufffd\ufffd \ud835\udc4d (1)(\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d (2)(\u00b7, \ud835\udc4f )\ufffd\ufffd\n\n40\n\n2 2\n(1) (2)\n###### \u2a7d 2\ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4f )\ufffd\ufffd + 2\ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4f )\ufffd\ufffd \u2a7d [0] [.] [004] [ \ud835\udc5b] .\n\n_\ud835\udc58_\n\nThus,\n###### \ufffd \ud835\udc4d [(][1][)] (\u00b7, \ud835\udc4f ), \ud835\udc64 \ufffd \u2a7d \ufffd\n\n_\ud835\udc58_ _._\n\n###### \ud835\udc4d [(][1][)] ( \ud835\udc56, \ud835\udc4f ) \ud835\udc63\ud835\udc56 \u2a7d [0] [.] [004] [ \ud835\udc5b]\n\n_\ud835\udc58_\n\n_\ud835\udc56_\n\n###### \u25a1\n\n**Lemma 8.7.** _For any \ud835\udc4e_ \u2208[ 2 _[\ud835\udc58]_ []] _[ and][ \ud835\udc61]_ [\u2208{][1] _[,]_ [ 2][}] _[,]_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \ud835\udc4c [(][1][)],\ud835\udc4d [(][1][)],\ud835\udf09 [(] \ud835\udc42 [1][)] (,\ud835\udc4c 1) [(][2][)],\ud835\udc4d [(][2][)],\ud835\udf09 [(][2][)][ \ufffd] \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd \u2a7d [0] [.] [008] \ud835\udc58 [\ud835\udc5b]\n\n_\ud835\udc42_ (1)\n\n###### \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd,\n\n_\ud835\udc58_\n\n_and,_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n_\ud835\udc4c_ [(][1][)] _,\ud835\udc4d_ [(][1][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udc4c_ [(][2][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][2][)][ \ufffd]\n###### \ud835\udc42 (1) \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd \u2a7e \u2212 [0] [.] [004] \ud835\udc58 [\ud835\udc5b]\n\n_\ud835\udc42_ (1)\n\n###### \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd .\n\n_\ud835\udc58_\n\n_Proof._ Recall that _\ud835\udc4b_ [(] _[\ud835\udc61]_ [)] = _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] ( _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] ) [\u22a4] \u2212 [1] _\ud835\udc58_\n\n[1] [1]\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [. We consider] _[ \ud835\udc4d]_ [(] _[\ud835\udc61]_ [)][(] _[\ud835\udc4d]_ [(] _[\ud835\udc61]_ [)][)][\u22a4] [and] _\ud835\udc58_\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [separately. For the]\n\n###### \ud835\udc4d [(] [\ud835\udc61] [)] ( \ud835\udc4d [(] [\ud835\udc61] [)] ) [\u22a4] part, notice that, since \ud835\udc65\ud835\udc56 = 2 [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(] [\ud835\udc56, \ud835\udc4e] [)\u2212] [1][, we have] [ \ud835\udc65] [(] \ud835\udc56 [\ud835\udc61] [)] [\u00b7] [\ud835\udc4d] [(] [\ud835\udc61] [)][(] [\ud835\udc56, \ud835\udc4e] [)][ =] [ \ud835\udc4d] [(] [\ud835\udc61] [)][(] [\ud835\udc56, \ud835\udc4e] [)]\n\nfor _\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]. Therefore, it follows that\n\n###### \ud835\udc4d [(] [\ud835\udc61] [)] ( \ud835\udc4d [(] [\ud835\udc61] [)] ) [\u22a4] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d (\u00b7, \ud835\udc4e ) = \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4f ) \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4f ) [\u22a4] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\n\n_\ud835\udc4f_ \u2208[ _\ud835\udc58_ ]\n###### = \ufffd \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4f ) [\u22a4] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4f ) [\u22a4] ( \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ))\n\n_\ud835\udc4f_ \u2208[ _\ud835\udc58_ ]\n\n= _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] (\u00b7 _, \ud835\udc4e_ ) [\u22a4] ( _\ud835\udc65_ [(] _[\ud835\udc61]_ [)] \u2299 _\ud835\udc64_ ) _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] (\u00b7 _, \ud835\udc4e_ ) [\u22a4] ( _\ud835\udc65_ [(] _[\ud835\udc61]_ [)] \u2299 _\ud835\udc64_ \u2299 _\ud835\udc4d_ [(] _[\ud835\udc61]_ [)] (\u00b7 _, \ud835\udc4e_ ))\n###### = \ufffd \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ), \ud835\udc64 \ufffd \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) [\u22a4] ( \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )) \u2a7d [0] [.] [004] [\ud835\udc5b] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd,\n\n_\ud835\udc58_\n\nwhere the last inequality is by Theorem 8.6. Moreover, from the last equality, we can also\nobtain\n###### \ud835\udc4d [(] [\ud835\udc61] [)] ( \ud835\udc4d [(] [\ud835\udc61] [)] ) [\u22a4] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2a7e 0 \ufffd \ufffd \ufffd\n\nFor the [1]\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [part, we have]\n\n1\n_\ud835\udc65_ [(] _[\ud835\udc61]_ [)] \u2299 _\ud835\udc64_ _, \ud835\udc65_ [(] _[\ud835\udc61]_ [)] \u2299 _\ud835\udc64_ \u2299 _\ud835\udc4d_ (\u00b7 _, \ud835\udc4e_ ) = [1]\n###### \ud835\udc58 [\ud835\udc3d] \ufffd \ufffd \ud835\udc58 \ufffd \ufffd\n\n###### \ufffd 1, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd\ufffd 1, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd\n\n_\ud835\udc58_\n\n###### \u2a7d [1] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd\n\n_\ud835\udc58_ [\u27e8] **[1]** _[, \ud835\udc64]_ [\u27e9]\n\n41\n\n###### \u2a7d [0] [.] [004] [\ud835\udc5b] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd .\n\n_\ud835\udc58_\n\nEquivalently, we can obtain\n\n1\n###### \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2a7e \u2212 [0] [.] [004] [\ud835\udc5b] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd . \ud835\udc58 [\ud835\udc3d] \ufffd \ufffd \ud835\udc58 \ufffd \ufffd\n\nTherefore, we have\n\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) = \ud835\udc4d [(] [\ud835\udc61] [)] ( \ud835\udc4d [(] [\ud835\udc61] [)] ) [\u22a4] \u2212 [1] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) \ufffd \ufffd \ufffd \ud835\udc58 [\ud835\udc3d] \ufffd \ufffd\ufffd \ufffd\ufffd \ufffd \u2a7d [0] [.] [008] [\ud835\udc5b] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd,\n\n_\ud835\udc58_\n\nand,\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) \u2a7e \u2212 [0] [.] [004] [\ud835\udc5b] \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd . \ufffd \ufffd \ufffd \ud835\udc58\n\n**Corollary 8.8.** _For any \ud835\udc61_ \u2208{1 _,_ 2} _,_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \u25a1\n\n###### \ud835\udc4c [(][1][)],\ud835\udc4d [(][1][)],\ud835\udf09 [(] \ud835\udc42 [1][)] (,\ud835\udc4c 1) [(][2][)],\ud835\udc4d [(][2][)],\ud835\udf09 [(][2][)][ \ufffd] \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 [\ud835\udc65] [(] [\ud835\udc61] [)] 2 [ +] [ 1]\n\n###### \u2a7d [0] [.] [008] [\ud835\udc5b] \u2225 \ud835\udc64 \u2225 [2],\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udc42_ (1)\n\n2\n\n_and,_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \ud835\udc4c [(][1][)],\ud835\udc4d [(][1][)],\ud835\udf09 [(] \ud835\udc42 [1][)] (,\ud835\udc4c 1) [(][2][)],\ud835\udc4d [(][2][)],\ud835\udf09 [(][2][)][ \ufffd] \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 [\ud835\udc65] [(] [\ud835\udc61] [)] 2 [ +] [ 1]\n\n###### \u2a7e \u2212 [0] [.] [004] [\ud835\udc5b] \u2225 \ud835\udc64 \u2225 [2] .\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udc42_ (1)\n\n2\n\n###### Proof. Recall that \ud835\udc65 [(] [\ud835\udc61] [)] = 2 [\ufffd] \ud835\udc4e \u2208[ \ud835\udc58 /2] [\ud835\udc4d] [(] [\ud835\udc61] [)][(\u00b7] [, \ud835\udc4e] [) \u2212] [1] [. Therefore,]\n\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 [(] [\ud835\udc65] [(] [\ud835\udc61] [)][ +] [ 1] [)] \ufffd 2 \ufffd\n\n=\n###### \ufffd\n\n###### \ufffd\n\n###### \ufffd\n\n###### = \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e ) . \ufffd \ufffd \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\nApplying Theorem 8.7, we can get\n\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 [(] [\ud835\udc65] [(] [\ud835\udc61] [)][ +] [ 1] [)] \ufffd 2 \ufffd\n\n42\n\n###### \u2a7d \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n0 _._ 008 _\ud835\udc5b_\n###### \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd\n\n_\ud835\udc58_\n\n###### \ufffd\n\n= [0] _[.]_ [008] _[\ud835\udc5b]_\n\n_\ud835\udc58_\n\n_\ud835\udc64,_ _[\ud835\udc65]_ [(] _[\ud835\udc61]_ [)][ +] **[ 1]**\n\n2\n###### \ufffd\n\n###### \u2a7d [0] [.] [008] [\ud835\udc5b] \u2225 \ud835\udc64 \u2225 [2],\n\n_\ud835\udc58_\n\nand,\n\n###### \ud835\udc4b [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2299 [(] [\ud835\udc65] [(] [\ud835\udc61] [)][ +] [ 1] [)] \ufffd 2 \ufffd\n\n\u2212\n###### \u2a7e \ufffd \ufffd\n\n_\ud835\udc4e_ \u2208[ _\ud835\udc58_ /2]\n\n0 _._ 004 _\ud835\udc5b_\n###### \ufffd \ud835\udc64, \ud835\udc4d [(] [\ud835\udc61] [)] (\u00b7, \ud835\udc4e )\ufffd\n\n_\ud835\udc58_\n\n_\ud835\udc64,_ _[\ud835\udc65]_ [(] _[\ud835\udc61]_ [)][ +] **[ 1]**\n\n2\n###### \ufffd\n\n###### \ufffd\n\n= \u2212 [0] _[.]_ [004] _[\ud835\udc5b]_\n\n_\ud835\udc58_\n\n= \u2212 [0] _[.]_ [004] _[\ud835\udc5b]_\n\n###### \u2a7e \u2212 [0] [.] [004] [\ud835\udc5b] \u2225 \ud835\udc64 \u2225 [2] .\n\n_\ud835\udc58_\n\n###### \u25a1 The following bound on \ufffd \ud835\udc4c [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc54 [\ufffd], \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd will be the key thing that we need in\n\nthe proof of the algorithmic guarantees.\n\n**Lemma 8.9.** _For \ud835\udc61_ \u2208{1 _,_ 2} _,_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \ud835\udc4c [(][1][)],\ud835\udc4d [(][1][)],\ud835\udf09 [(] \ud835\udc42 [1][)] (,\ud835\udc4c 1) [(][2][)],\ud835\udc4d [(][2][)],\ud835\udf09 [(][2][)][ \ufffd] \ud835\udc4c [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc54 \ufffd, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \ufffd \u2a7d [0] [.] [016] \ud835\udc58 [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc42_ (1)\n\n_\ud835\udc58_ \u2225 _\ud835\udc64_ \u2225 [2] + 4 _\ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b._\n\n_Proof._ Without loss of generality, we prove the statement for _\ud835\udc61_ = 1. Let _\ud835\udc4c\ud835\udc46_ [(][1][)] := _\ud835\udc4c_ [(][1][)] \u2299( **1** \u2212\n_\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4], we use decomposition\n\n###### \ud835\udc4c [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 = \ud835\udc4c [(][1][)] \u2212 \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 + \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 . \ufffd \ufffd \ufffd \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\n\n(8.7)\n###### For the term \ud835\udc4c [(][1][)] \u2212 \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54 [\ufffd], \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, since \ud835\udc4c [(][1][)] \u2212 \ud835\udc4c\ud835\udc46 [(][1][)] = \ud835\udc4c [(][1][)] \u2299( \ud835\udc3d \u2212( 1 \u2212 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4] ), \ufffd\ufffd \ufffd\ufffd \ufffd \ud835\udc54 = \ud835\udc64 + \ud835\udc60, and \ud835\udc64 = \ud835\udc63 \u2299( 1 \u2212 \ud835\udc60 ), we have \ud835\udc4c [(][1][)] \u2212 \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 [\ufffd], \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 = 0 and \ufffd\ufffd \ufffd\ufffd \ufffd ( \ud835\udc3d \u2212( 1 \u2212 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4] ) \u2299 [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 [\ufffd\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 [\ufffd] [\u22a4] = [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 [\ufffd\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 [\ufffd] [\u22a4] . Therefore,\n\n_\ud835\udc4c_ [(][1][)] \u2212 _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ = _\ud835\udc4c_ [(][1][)] \u2212 _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc60_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_\n###### \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd \u22a4 [\ufffd] = \ud835\udc4c [(][1][)] \u2299 [\ufffd] \ud835\udc3d \u2212( 1 \u2212 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4][\ufffd], \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd \ufffd\ufffd \ufffd \ufffd \u22a4 [\ufffd]\n\n= _\ud835\udc4c_ [(][1][)] _,_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc60_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ _._\n###### \ufffd \ufffd\ufffd \ufffd \ufffd\n\nlet _\ud835\udc4c_ [(][1][)] = _[\ud835\udf00][\ud835\udc51]_\n\n[1]\n\n_\ud835\udc58_ _[\ud835\udc3d]_ [and] _[ \ud835\udc38]_ [(][1][)][ =] _[ \ud835\udc4c]_ [(][1][)][ \u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [(][1][)][ +] _[ \ud835\udc38]_ [(][1][)][ where] _[ \ud835\udc4b]_ [(][1][)][ =] _[ \ud835\udc4d]_ [(][1][)][(] _[\ud835\udc4d]_ [(][1][)][)][\u22a4] [\u2212] [1] _\ud835\udc58_\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [(][1][)][, it follows that]\n\n_\ud835\udc4c_ [(][1][)] \u2212 _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ = _[\ud835\udf00][\ud835\udc51]_\n###### \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd \ud835\udc5b\n\n43\n\n###### \u22a4 [\ufffd]\n\n_\ud835\udc4d_ [(][1][)] ( _\ud835\udc4d_ [(][1][)] ) [\u22a4] _,_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc60_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_\n###### \ufffd \ufffd\ufffd \ufffd \ufffd\n\n\u2212 _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc58\ud835\udc5b_\n\n###### \u22a4 [\ufffd]\n\n_\ud835\udc3d,_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc60_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_\n###### \ufffd \ufffd\ufffd \ufffd \ufffd\n\n###### \u22a4 [\ufffd]\n\n+ _\ud835\udc38_ [(][1][)] _,_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc60_ _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ _._\n###### \ufffd \ufffd\ufffd \ufffd \ufffd For the first term, since 0 \u2a7d \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4] \u2a7d \ud835\udc3d and \ud835\udc65 [(][1][)] \u2a7d 1, it follows that\n\n###### \ufffd\n\n_\ud835\udf00\ud835\udc51_\n\n_\ud835\udc5b_\n\n###### \u22a4 [\ufffd] \ud835\udc4d [(][1][)] ( \ud835\udc4d [(][1][)] ) [\u22a4], \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d [\ud835\udf00][\ud835\udc51] \ufffd \ufffd\ufffd \ufffd \ud835\udc5b \ufffd\n\n_[\ud835\udc51]_\n###### \ufffd \ud835\udc3d, \ud835\udc60\ud835\udc64 [\u22a4][\ufffd] = [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n\n_\ud835\udc5b_\n\n_\ud835\udc64\ud835\udc56_\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n_\ud835\udc60\ud835\udc56_\n###### \ufffd\ufffd \ud835\udc56\n\n###### \u2a7d 2 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02 \u2225 \ud835\udc64 \u2225 [2] .\n\n###### For the second term, since \ud835\udc65 [(][1][)] \u2a7e \u2212 1, it follows that\n\n_\ud835\udc64\ud835\udc56_\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n###### \ufffd\n\n\u2212 _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc58\ud835\udc5b_\n\n###### \u22a4 [\ufffd] \ud835\udc3d, \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d [\ud835\udf00][\ud835\udc51] \ufffd \ufffd\ufffd \ufffd \ud835\udc58\ud835\udc5b \ufffd\n\n###### [\ud835\udf00][\ud835\udc51] \ufffd \ud835\udc3d, \ud835\udc60\ud835\udc64 [\u22a4][\ufffd] = [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc58\ud835\udc5b_ _\ud835\udc58\ud835\udc5b_\n\n_\ud835\udc58\ud835\udc5b_\n\n_\ud835\udc60\ud835\udc56_\n###### \ufffd\ufffd \ud835\udc56\n\n###### \ufffd\ufffd \ud835\udc56\n\n2 _\ud835\udf00\ud835\udc51\ud835\udeff_\n_\ud835\udf02_\n###### \u2a7d \u2225 \ud835\udc64 \u2225 [2] .\n\n_\ud835\udc58_\n\nFor the third term, \ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) and SoS Cauchy-Schwarz inequality, it follows that\n\n###### \u22a4 [\ufffd]\n\n2 1 2\n(1) (1) (1)\n###### \ufffd \ud835\udc38 [(][1][)], \ufffd \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 \ufffd\ufffd \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd \u2a7d \ufffd \ud835\udf12 + [1] \ud835\udc58 \ufffd \u221a \ud835\udc51 \ufffd\ufffd \ud835\udc65 \u2299 \ud835\udc60 \ufffd\ufffd + \ud835\udf12 + [1] \u221a \ud835\udc51 \ufffd\ufffd \ud835\udc38 \ufffd\ufffdop\ufffd\ufffd \ud835\udc65 \u2299\n\n~~\u221a~~\n###### \ufffd\n\n~~\u221a~~\n###### \ufffd\n\n_\ud835\udc58_\n\n2 1\n(1)\n_\ud835\udc51_ _\ud835\udc65_ \u2299 _\ud835\udc60_ +\n###### \ufffd\ufffd \ufffd\ufffd \ufffd \ud835\udf12 + [1] \ud835\udc58\n\n###### [1] \ud835\udc58 \ufffd\u221a\n\n_\ud835\udc51_\n\n2 2\n(1) (1)\n_\ud835\udc38_ _\ud835\udc65_ \u2299 _\ud835\udc64_\n###### \ufffd\ufffd \ufffd\ufffdop\ufffd\ufffd \ufffd\ufffd\n\n\u221a _\ud835\udc51_ \u2225 _\ud835\udc64_ \u2225 [2]\n###### \ufffd\n\n###### \u2a7d \ud835\udf12 + [1]\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b_ + _\ud835\udf12_ + [1] _\ud835\udc58_\n###### \ufffd\n\n###### [1] \ud835\udc58 \ufffd\u221a\n\n###### Since \ud835\udf00 [2] \ud835\udc51 \u226b \ud835\udc58 [2], we have [\ufffd] \ud835\udf12 + [1] \ud835\udc58\n\n_\ud835\udc51_ \u226a _[\ud835\udf00][\ud835\udc51]_\n\n######, we have [\ufffd] \ud835\udf12 + \ud835\udc58 \ufffd \ud835\udc51 \u226a [\ud835\udf00] \ud835\udc58 [, we can obtain] \u22a4 [\ufffd] 0 . 0001 \ud835\udf00\ud835\udc51\ud835\udeff\n\n_\ud835\udf02_\n###### \ud835\udc38 [(][1][)], \ud835\udc65 [(][1][)] \u2299 \ud835\udc60 \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d \ufffd \ufffd\ufffd \ufffd \ud835\udc58 \ufffd\n\n_\ud835\udf00_ _\ud835\udeff_\n_\ud835\udf02_\n\n_\ud835\udc5b_ + [0] _[.]_ [001] _[\ud835\udf00][\ud835\udc51]_\n_\ud835\udc58_ _\ud835\udc58_\n\n\u2225 _\ud835\udc64_ \u2225 [2] _._\n_\ud835\udc58_\n\nThus, it follows that\n\n###### \ud835\udc4c [(][1][)] \u2212 \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d [0] [.] [001] [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b. (8.8) \ufffd\ufffd \ufffd\ufffd \ufffd \ufffd \ud835\udc58 Now, we consider the term \ud835\udc4c\ud835\udc46 [(][1][)] \ufffd \ud835\udc65 [(][1][)] \u2299 \ud835\udc54 [\ufffd], \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 . By \ud835\udc9cclose( \ud835\udc4c, \ud835\udf09 ; \ud835\udf02, \ud835\udc3a [\u00af] ), we have \ufffd \ufffd\n\n_\ud835\udc4c_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc3a_ [\u00af] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc4c_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] _._\n\nBy Theorem 8.4 and _\ud835\udc64_ = _\ud835\udc63_ \u2299( **1** \u2212 _\ud835\udc60_ ),\n\n**1** \u2212 _\ud835\udc65_ [(][1][)]\n\n_\ud835\udc65_ [(][1][)]\n\n\u2299 _\ud835\udc64_ = **[1]** [ +] _[ \ud835\udc65]_ [(][2][)]\n2 2\n\n\u2299 _\ud835\udc64_ and _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ = \u2212 _\ud835\udc65_ [(][2][)] \u2299 _\ud835\udc64._\n2\n\nTherefore, we have\n\n_\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_\n###### \ufffd \ufffd \ufffd \ufffd\n\n44\n\n= _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ \u2299 [1][ +] _[ \ud835\udc65]_ [(][1][)]\n###### \ufffd \ufffd 2 \ufffd\n\n= _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ \u2299 [1][ +] _[ \ud835\udc65]_ [(][1][)]\n###### \ufffd \ufffd 2 \ufffd = \ud835\udc4c [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \ufffd 2 \ufffd\n\n+ _\ud835\udc4c\ud835\udc46_ [(][1][)] _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][1][)] \u2299 _\ud835\udc64_ \u2299 [1][ \u2212] _[\ud835\udc65]_ [(][1][)]\n###### \ufffd \ufffd 2 \ufffd \ufffd\n\n\u2212 _\ud835\udc4c\ud835\udc46_ [(][2][)] _\ud835\udc65_ [(][2][)] \u2299 _\ud835\udc54_ _, \ud835\udc65_ [(][2][)] \u2299 _\ud835\udc64_ \u2299 [1][ +] _[ \ud835\udc65]_ [(][2][)]\n###### \ufffd \ufffd 2 \ufffd \ufffd\n\n###### \ufffd \ufffd\n\n###### \u2212 \ud835\udc4c [(][2][)] [\ufffd] \ud835\udc65 [(][2][)] \u2299 \ud835\udc64, \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][2][)] \ufffd 2 \ufffd \ufffd\n\n_._\n###### \ufffd\n\nConsider the first term, it follows that\n\n###### \ud835\udc4c [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \ufffd 2 \ufffd\n\nBy Theorem 8.8, we have\n\n###### \ufffd\n\n= _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_\n###### \ufffd\n\n###### \ud835\udc4b [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \ufffd 2 \ufffd\n\n###### + \ud835\udc38 [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \ufffd 2 \ufffd\n\n_._\n###### \ufffd\n\n###### \u2a7d [0] [.] [008] [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] .\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udf00\ud835\udc51_\n\n_\ud835\udc5b_\n\n###### \ud835\udc4b [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \ufffd 2 \ufffd\n\nBy \ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) and SoS Cauchy-Schwarz inequality, we have\n\n###### \ud835\udc38 [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \u2a7d \ud835\udf12 + \ufffd 2 \ufffd \ufffd \ufffd\n\n\u221a\n###### \ufffd\n\n_\ud835\udc51_ \u2225 _\ud835\udc64_ \u2225 [2] _._\n\n2\n\n###### \u2a7d \ud835\udf12 + [1]\n\n_\ud835\udc58_\n###### \ufffd \ufffd\n\n_\ud835\udc58_\n\n###### [1] \ud835\udc58 \ufffd\u221a\n\n###### Since \ud835\udf00 [2] \ud835\udc51 \u226b \ud835\udc58 [2], we have [\ufffd] \ud835\udf12 + [1] \ud835\udc58\n\n_\ud835\udc51_ \u226a _[\ud835\udf00][\ud835\udc51]_\n\n###### [\ufffd] \ud835\udf12 + \ud835\udc58 \ufffd \ud835\udc51 \u226a [\ud835\udf00] \ud835\udc58 [, and, therefore,] \ud835\udc4c [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc64, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][1][)] \u2a7d \ufffd 2 \ufffd \ufffd\n\n2\n\n###### \u2a7d [0] [.] [01] [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc58_\n###### \ufffd\n\n\u2225 _\ud835\udc64_ \u2225 [2] _._\n_\ud835\udc58_\n\nUsing similar analysis on the lower bound side, we can obtain\n\n###### \ud835\udc4c [(][2][)] [\ufffd] \ud835\udc65 [(][2][)] \u2299 \ud835\udc64, \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \u2299 [1][ +] [ \ud835\udc65] [(][2][)] \u2a7e \u2212 [0] [.] [005] \ufffd 2 \ud835\udc58 \ufffd \ufffd\n\n2\n\n\u2212 [0] _[.]_ [005] _[\ud835\udf00][\ud835\udc51]_\n###### \u2a7e\n\n_\ud835\udc58_\n###### \ufffd\n\n\u2225 _\ud835\udc64_ \u2225 [2] _._\n_\ud835\udc58_\n\nThus,\n###### \ud835\udc4c\ud835\udc46 [(][1][)] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d [0] [.] [015] [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] . (8.9) \ufffd \ufffd \ufffd \ufffd \ud835\udc58\n\nPlugging Eq. (8.8) and Eq. (8.9) into Eq. (8.7), it follows that\n\n###### \ud835\udc4c [(][1][)] [\ufffd] \ud835\udc65 [(][1][)] \u2299 \ud835\udc54, \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \u2a7d [0] [.] [016] [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b. \ufffd \ufffd \ufffd \ud835\udc58\n\nTheorem 8.5 and Theorem 8.9 Theorem 8.10.\nNow combining, we can prove\n\n45\n\n###### \u25a1\n\n**Theorem 8.10.** _Consider the setting of Theorem 8.1. We have_\n\n\ud835\udc9c _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9c _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\nexp(\u2212 _[\ud835\udefe][\ud835\udc36]_ [\u02dc]\n\n2 [) +] _[ \ud835\udeff][\ud835\udf02]_\n###### \ufffd\n\n_\ud835\udc5b_ _._\n###### \ufffd \ufffd\n\n_\ud835\udc4c_ [(][1][)] _,\ud835\udc4d_ [(][1][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udc4c_ [(][2][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][2][)][ \ufffd\ufffd] **1** \u2212 _\ud835\udc65_ [(][1][)] \u2299 _\ud835\udc65_ [(][2][)]\n\n_\ud835\udc42_ (1) 2\n###### \ufffd\ufffd\n\n_\ud835\udc42_ (1)\n\n2\n\n2\n_\ud835\udc58_\n###### \u2a7d \ud835\udc42 \ufffd\ufffd\ufffd\ufffd \ufffd 0 . 96 \u2212 \ud835\udefe\n\n_Proof._ By Theorem 8.5, we can obtain\n\n###### \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd = \u2212\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] \u2299( 1 \u2212 \ud835\udc54 )), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd .\n\nTherefore, we have\n\n###### \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] ), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd+\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] ), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd = \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] \u2299 \ud835\udc54 ), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd+\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] \u2299 \ud835\udc54 ), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd .\n\nBy \ud835\udc9cmaj( _\ud835\udc4c, \ud835\udc4d, \ud835\udc45_ ; _\ud835\udefe,_ _\ud835\udc36_ [\u02dc] ), it follows that\n\n###### \ufffd \ud835\udc4c [(][1][)] ( \ud835\udc65 [(][1][)] ), \ud835\udc65 [(][1][)] \u2299 \ud835\udc64 \ufffd + \ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(][2][)] ), \ud835\udc65 [(][2][)] \u2299 \ud835\udc64 \ufffd \u2a7e 2 \ud835\udefc\ud835\udefe \ufffd\u2225 \ud835\udc64 \u2225 [2] \u2212 \ud835\udefd\ud835\udefe, \u02dc \ud835\udc36 \ud835\udc5b \ufffd .\n\nBy Theorem 8.9, we have for each _\ud835\udc61_ \u2208{1 _,_ 2},\n\n###### \ud835\udc4c [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc54, \ud835\udc65 [(] [\ud835\udc61] [)] \u2299 \ud835\udc64 \u2a7d [0] [.] [016] [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b. \ufffd \ufffd \ufffd \ud835\udc58\n\nTherefore, we have\n\n###### \ud835\udefc\ud835\udefe \ufffd\u2225 \ud835\udc64 \u2225 [2] \u2212 \ud835\udefd\ud835\udefe, \u02dc \ud835\udc36 \ud835\udc5b \ufffd \u2a7d [0] [.] [016] \ud835\udc58 [\ud835\udf00][\ud835\udc51] \u2225 \ud835\udc64 \u2225 [2] + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\ud835\udc5b.\n\n_\ud835\udefc_ = [(][1][\u2212] _[\ud835\udefe]_ [)] _[\ud835\udf00][\ud835\udc51]_\nBy rearranging terms and plugging in _\ud835\udefe_ 16 _\ud835\udc58_\n\n_[\ud835\udefe]_ _[\ud835\udf00]_\n\n16 _\ud835\udc58_ and _\ud835\udefd\ud835\udefe,_ \u02dc _\ud835\udc36_ = [640] 1\u2212 _\ud835\udefe_ _[\ud835\udc58]_\n\n[\u2212] _[\ud835\udefe]_ _[\ud835\udf00]_\nBy rearranging terms and plugging in _\ud835\udefc\ud835\udefe_ = 16 _\ud835\udc58_ and _\ud835\udefd\ud835\udefe,_ \u02dc _\ud835\udc36_ = [640] 1\u2212 _\ud835\udefe_ _[\ud835\udc58]_ [exp][(\u2212] _[\ud835\udefe][\ud835\udc36]_ [\u02dc] [/][2][)][, we can]\n\nobtain\n\nexp(\u2212 _[\ud835\udefe][\ud835\udc36]_ [\u02dc]\n\n2 [) +] _[ \ud835\udeff][\ud835\udf02]_\n###### \ufffd\n\nexp(\u2212 _[\ud835\udefe][\ud835\udc36]_ [\u02dc]\n\n2\n###### \ufffd\n\n_\ud835\udc5b_ _._\n###### \ufffd \ufffd\n\n_\ud835\udc58_\n###### \u2225 \ud835\udc64 \u2225 [2] \u2a7d \ud835\udc42 \ufffd 0 . 96 \u2212 \ud835\udefe\n\nSince _\ud835\udc64_ = _\ud835\udc63_ \u2299( **1** \u2212 _\ud835\udc60_ ), it follows that\n\n_\ud835\udc5b_ _._\n###### \ufffd \ufffd\n\n_\ud835\udc58_\n###### \u2225 \ud835\udc63 \u2225 [2] = \u2225 \ud835\udc64 + \ud835\udc63 \u2299 \ud835\udc60 \u2225 [2] \u2a7d 2\u2225 \ud835\udc64 \u2225 [2] + 2\u2225 \ud835\udc63 \u2299 \ud835\udc60 \u2225 [2] \u2a7d \ud835\udc42 \ufffd 0 . 96 \u2212 \ud835\udefe\n\nexp(\u2212 _[\ud835\udefe][\ud835\udc36]_ [\u02dc]\n\n2 [) +] _[ \ud835\udeff][\ud835\udf02]_\n###### \ufffd\n\n###### \u25a1\n\n##### **8.4 Algorithmic guarantees for robust bisection boosting**\n\nNow, we are ready to prove Theorem 5.4.\n\n46\n\n**Theorem** (Restatement of Theorem 5.4) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes_\n###### in \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large]\n\n_constant \ud835\udc3e. Let \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 \u2282 _\ud835\udc49_ _be disjoint subsets of size \ud835\udc5b_ / _\ud835\udc58_ _such that in every \ud835\udc46\ud835\udc56_ _at least_\n0 _._ 99 _-fraction of the nodes belong to the same community. Let \ud835\udc65_ [\u25e6] \u2208{\u00b11} _[\ud835\udc5b]_ _be the ground-truth_\n_community bisection with the underlying communities of \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 _on the same side. There_\n_exists a polynomial-time algorithm that, given observation of \ud835\udc3a_ _and \ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 _, outputs_\n\u02c6 1\n_\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n1\n###### \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] [\u02dc]\n_\ud835\udc5b_ [\u2225\u02c6] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u25e6][\u2225][2][ \u2a7d] [exp] 8\n###### \ufffd\n\n+ poly( _\ud835\udc58_ ) _\ud835\udf02_ _,_\n###### \ufffd\n\n_where_ _\ud835\udc36_ [\u02dc] =\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 ~~\u221a~~\n\n2\n_\ud835\udc4f_ _is the bisection SNR._\n###### \ufffd\n\n_Proof._ Since the program is feasible for the spectrally truncated graph _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)][ with]\nground-truth label _\ud835\udc4d_ [\u25e6] with the ground-truth bisection be _\ud835\udc65_ [\u25e6] \u2208{\u00b11} _[\ud835\udc5b]_, by Theorem 8.10, it\nfollows that\n###### 1 \ufffd\ufffd\ud835\udd3c\u02dc \ud835\udc65 \u2212 \ud835\udc65 \u25e6\ufffd\ufffd2 \u2a7d \ud835\udc42 \ud835\udc58 exp \u2212 [\ud835\udefe][\ud835\udc36] [\u02dc] + \ud835\udeff\ud835\udf02, \ud835\udc5b 0 . 96 \u2212 \ufffd 4 \ufffd \ufffd \ufffd \ufffd\ufffd\n\n\ud835\udd3c\u02dc _\ud835\udc65_ \u2212 _\ud835\udc65_  - 2 \u2a7d _\ud835\udc42_ _\ud835\udc58_\n###### \ufffd\ufffd \ufffd\ufffd \ufffd 0 . 96 \u2212 \ud835\udefe\n\n\u2212 _[\ud835\udefe][\ud835\udc36]_ [\u02dc]\nexp\n###### \ufffd 4 \ufffd\n\n_,_\n###### \ufffd\ufffd\n\n4\n\n+ _\ud835\udeff_\n_\ud835\udf02_\n###### \ufffd\n\nwhere _\ud835\udc36_ [\u02dc] =\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 \u221a\n\n2\n_\ud835\udc4f_ = [1]\n. Plug in _\ud835\udefe_ 2 [and] _[ \ud835\udeff][\ud835\udf02]_ [=][ exp][(\u2212][2] _[\ud835\udc36][\ud835\udc51,][\ud835\udf00]_ [) +] _[ \ud835\udf02]_ [, it follows that]\n###### \ufffd\n\n+ _._\n_\ud835\udf02_\n###### \ufffd \ufffd\ufffd\n\n1\n\n_\ud835\udc5b_\n\n\u02dc\n###### \ufffd\ufffd\ud835\udd3c\u02dc \ud835\udc65 \u2212 \ud835\udc65 \u25e6\ufffd\ufffd2 \u2a7d \ud835\udc42 \ud835\udc58 exp \u2212 \ud835\udc36 \ufffd 8 \ufffd \ufffd\n\nLet \u02c6 _\ud835\udc65_ = sign( \ud835\udd3c [\u02dc] _\ud835\udc65_ ). Since the entrywise error of sign rounding increases by at most a\nmultiplicative factor of _\ud835\udc42_ (1), it follows that\n\n1 _\ud835\udc36_ \u02dc\n_\ud835\udc58_ \u2212\nexp\n###### \ud835\udc5b [\u2225\u02c6] [\ud835\udc65] [\u2212] [\ud835\udc65] [\u25e6][\u2225][2][ \u2a7d] [\ud835\udc42] \ufffd 8 \ufffd \ufffd\n\n###### + \ud835\udf02 = exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] [\u02dc] + \ud835\udc42 ( \ud835\udc58\ud835\udf02 ) . \ufffd 8 \ufffd\ufffd \ufffd \ufffd\n\n###### \u25a1\n\n### **9 Robust bisection algorithm**\n\nIn this section, we combine results from Section 6, Section 7 and Section 8 to design an\nalgorithm for robust bisectioning and prove Theorem 5.5.\n\n47\n\n**.**\n**Algorithm 9.1** (Robust bisection algorithm)\n**Input:** A graph _\ud835\udc3a_ sampled from the _\ud835\udc58_ -stochastic block model SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) with _\ud835\udf02\ud835\udc5b_\ncorrupted nodes.\n\n1. **Graph splitting:** We let _\ud835\udc3a_ 1 be the graph obtained by subsampling each edge in _\ud835\udc3a_\nindependently with probability 0 _._ 99 and let _\ud835\udc3a_ 2 \ufffd _\ud835\udc3a_ \\ _\ud835\udc3a_ 1.\n\n2. **Rough initialization:** Apply the algorithm from Theorem 5.2 on graph _\ud835\udc3a_ 1 to\nobtain a rough _\ud835\udc58_ -clustering _\ud835\udc4d_ rough with error rate 0 _._ 001 + 10 [4] _\ud835\udf02_ .\n\n3. **Identifying well recovered blocks:** Apply the algorithm from Theorem 5.3 on\ngraph _\ud835\udc3a_ 2 and _\ud835\udc4d_ rough to identify _\ud835\udc58_ /2 clusters _\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 in which 0 _._ 99-fraction\nof the nodes belongs to the same community.\n\n4. **Bisection boosting:** Apply the algorithm from Theorem 5.4 on graph _\ud835\udc3a_ with\n_\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2 and _\ud835\udc4d_ rough as input, find a bisection \u02c6 _\ud835\udc65_ that separates the identified\n###### blocks from the remaining blocks with an error rate exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] \ud835\udc58 [\ud835\udc51] [2] [,][\ud835\udf00] + \ufffd \ufffd\n\npoly( _\ud835\udc58_ ) _\ud835\udf02_ .\n\n**Output:** \u02c6 _\ud835\udc65_ .\n\n**Theorem** (Restatement of Theorem 5.5) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs_ \u02c6 _\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b]_ _such_\n1\n_that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n1\n###### \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36] [\u02dc]\n_\ud835\udc5b_ [\u2225\u02c6] _[\ud835\udc65]_ [\u2212] _[\ud835\udc65]_ [\u25e6][\u2225][2][ \u2a7d] [exp] 8\n###### \ufffd\n\n+ _\ud835\udc42_ ( _\ud835\udc58\ud835\udf02_ ) _._\n###### \ufffd\n\n2\n\n2\n\n_where_ _\ud835\udc36_ [\u02dc] = _\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_ \u2212 \u221a _\ud835\udc4f_ _is the bisection SNR and \ud835\udc65_ [\u25e6] \u2208{\u00b11} _[\ud835\udc5b]_ _is a true community bisection_\n###### \ufffd\ufffd \ufffd\n\n_of \ud835\udc3a_ [\u25e6] _._\n\n_where_ _\ud835\udc36_ [\u02dc] =\n###### \ufffd\ufffd\n\n2\n_\ud835\udc4e_ _\ud835\udc58_ _\ud835\udc4f_ [1][\u2212] [2] _\ud835\udc58_\n\n_\ud835\udc58_ \u2212 \u221a\n\n_Proof._ For Theorem 5.4, it suffices to establish the guarantees required by the initialization\nphase. Specifically, we must obtain _\ud835\udc58_ /2 disjoint subsets _\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2, each of size exactly\n_\ud835\udc5b_ / _\ud835\udc58_, [15] such that, with high probability, at least a 0 _._ 99 fraction of the vertices within each\nsubset belong to the same community.\nBy Theorem 5.2, we obtain with high probability disjoint subsets _\ud835\udc49_ 1 _, \ud835\udc49_ 2 _, . . ., \ud835\udc49\ud835\udc58_ \u2286[ _\ud835\udc5b_ ],\nsuch that for at least 0 _._ 99 fraction of these subsets, each contains at least 0 _._ 999 fraction of its\n\n15We assume that _\ud835\udc58_ is a power of 2 and _\ud835\udc5b_ is divisible by _\ud835\udc58_, ensuring that _\ud835\udc5b_ / _\ud835\udc58_ is an integer and eliminating\nrounding issues in the partitioning process.\n\n48\n\nvertices from one ground-truth community, with fewer than 0 _._ 001 _\ud835\udc5b_ / _\ud835\udc58_ vertices from other\ncommunities. Without loss of generality, let these well-aligned subsets be _\ud835\udc49_ 1 _, \ud835\udc49_ 2 _, . . ., \ud835\udc49_ 0 _._ 99 _\ud835\udc58_ .\nTo guarantee that each subset has exactly _\ud835\udc5b_ / _\ud835\udc58_ vertices, we rebalance the subsets by\nredistributing vertices appropriately. Specifically, surplus vertices are transferred from\nsubsets exceeding size _\ud835\udc5b_ / _\ud835\udc58_ to subsets with fewer than _\ud835\udc5b_ / _\ud835\udc58_ vertices. Let the resulting\nbalanced subsets be denoted by _\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ .\nThe key observation here is that, initially, each of the subsets _\ud835\udc49_ 1 _, . . ., \ud835\udc49_ 0 _._ 99 _\ud835\udc58_ contains\nbetween 0 _._ 999 _\ud835\udc5b_ / _\ud835\udc58_ and 1 _._ 001 _\ud835\udc5b_ / _\ud835\udc58_ vertices. Consequently, the number of vertices added to or\nremoved from each of these subsets during rebalancing is at most 0 _._ 001 _\ud835\udc5b_ / _\ud835\udc58_ . Thus, each\nsubset retains at least 0 _._ 998 _\ud835\udc5b_ / _\ud835\udc58_ vertices from its dominant community. Therefore, for at\nleast 0 _._ 99 fraction of the subsets, a 0 _._ 998 fraction of their vertices still belongs to a single\nground-truth community.\nNow, we have _\ud835\udc58_ /2 disjoint subsets _\ud835\udc46_ 1 _, \ud835\udc46_ 2 _, . . ., \ud835\udc46\ud835\udc58_ /2, each of size _\ud835\udc5b_ / _\ud835\udc58_, satisfying the\ncondition that at least 0 _._ 998 fraction of vertices in each subset originate from the same\ncommunity. By Theorem 5.3, the algorithm will accept these subsets as valid clusters and\nreject subsets with recovery rates below 0 _._ 99. Combining this with Theorem 5.4 concludes\n###### the proof of the theorem. \u25a1\n\n### **10 Robust initialization for symmetry breaking**\n\nBuilding on the robust optimal bisection algorithm from Section 9, we present a robust\npolynomial-time algorithm for clustering vertices into _\ud835\udc58_ communities. Our approach attains\na misclassification error strictly below the critical 1/ _\ud835\udc58_ symmetry-breaking threshold.\n\n**Algorithm 10.1** (Robust _\ud835\udc58_ -clustering via recursive bisections) **.**\n**Input:** Graph _\ud835\udc3a_ drawn from the _\ud835\udc58_ -stochastic block model SBM _\ud835\udc5b\ud835\udc56_ ( _\ud835\udc51\ud835\udc56_ _, \ud835\udf00, \ud835\udc58\ud835\udc56_ ) with corruption fraction at most _\ud835\udf02\ud835\udc56_ .\n\n1. Apply the robust bisection algorithm (Theorem 9.1) on _\ud835\udc3a_ to obtain bisection\n_\ud835\udc65_ \u2208{\u00b11} _[\ud835\udc5b][\ud835\udc56]_ .\n\n2. Let _\ud835\udc65_ [+] := { _\ud835\udc56_ \u2208[ _\ud835\udc5b_ ] : _\ud835\udc65\ud835\udc56_ = 1} and _\ud835\udc65_ [\u2212] := { _\ud835\udc56_ \u2208[ _\ud835\udc5b_ ] : _\ud835\udc65\ud835\udc56_ = \u22121}. Partition _\ud835\udc3a_ into two\ninduced subgraphs _\ud835\udc3a_ 1 = _\ud835\udc3a_ [ _\ud835\udc65_ [+] ] and _\ud835\udc3a_ 2 = _\ud835\udc3a_ [ _\ud835\udc65_ [\u2212] ] such that each distrbutes as\nSBM _\ud835\udc5b\ud835\udc56_ +1( _\ud835\udc51\ud835\udc56_ +1 _, \ud835\udf00, \ud835\udc58\ud835\udc56_ +1).\n\n3. Recursively apply Algorithm 10.1 to _\ud835\udc3a_ 1 and _\ud835\udc3a_ 2 with parameters _\ud835\udc5b\ud835\udc56_ +1 _, \ud835\udc51\ud835\udc56_ +1 _, \ud835\udf00, \ud835\udc58\ud835\udc56_ +1.\n\n4. After \u230alog _\ud835\udc58_ \u230b levels of recursion, merge the resulting clusters into a final community\nassignment vector _\ud835\udc4d_ [\u02c6] \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ .\n\n_\ud835\udc4d_ [\u02c6] .\n**Output:**\n\n49\n\nNow, we restate and prove the algorithmic guarantees of Theorem 10.1.\n\n**Theorem** (Restatement of Theorem 5.6) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2] [ for some sufficiently large constant]\n\n_\ud835\udc3e. There exists a polynomial-time algorithm that, given observation of \ud835\udc3a, outputs an estimator_\n\u02c6 1\n_\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly( _\ud835\udc5b_ ) _[,]_\n\n###### error\ud835\udc58 ( \ud835\udc4d, \ud835\udc4d [\u02c6] [\u25e6] ) \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00]\n\n_\ud835\udc58_ [2]\n###### \ufffd\n\n+ poly( _\ud835\udc58_ ) _\ud835\udf02._\n###### \ufffd\n\n_Proof._ We follow the level-wise parametrization of Appendix C.1: for level _\ud835\udc56_ \u2208\n###### {1, . . ., \u230alog2 \ud835\udc58 \u230b} set \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56], \ud835\udc5b\ud835\udc56 \ufffd 2 \ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udc58\ud835\udc56 \ufffd \ud835\udefd\ud835\udc56 \ud835\udc58 . There are 2 [\ud835\udc56] subproblems at level \ud835\udc56, each on \ud835\udc5b\ud835\udc56 vertices and \ud835\udc58\ud835\udc56 communities. Let \ud835\udc36 [\ufffd] \ud835\udc56 be the level- \ud835\udc56 bisection SNR and err \ud835\udc56\n\nthe (per-vertex) bisection error of Theorem 5.1 on a level- _\ud835\udc56_ subproblem.\nThe original instance has at most _\ud835\udf02\ud835\udc5b_ corrupted vertices. Restricting to any level- _\ud835\udc56_ vertex\nset _\ud835\udc49\ud835\udc56_ of size _\ud835\udc5b\ud835\udc56_ gives at most _\ud835\udf02\ud835\udc5b_ corruptions inside _\ud835\udc49\ud835\udc56_, so the effective corruption fraction\nsatisfies\n###### \ud835\udf02\ud835\udc56 \u2a7d [\ud835\udf02][\ud835\udc5b] = [\ud835\udf02] [\u2a7d] [\ud835\udf02] [\u2a7d] [\ud835\udc58][\ud835\udf02][,]\n\n_[\ud835\udc5b]_\n\n= _[\ud835\udf02]_\n_\ud835\udc5b\ud835\udc56_ 2\n\n_[\ud835\udf02]_\n###### 2 \ud835\udefd\ud835\udc56 [\u2a7d] \ud835\udefd [\ud835\udf02]\n\n###### \ud835\udefd\ud835\udc56 [\u2a7d] [\ud835\udc58][\ud835\udf02][,]\n\n###### since \ud835\udefd\ud835\udc56 \u2a7e 1/ \ud835\udc58 for \ud835\udc56 \u2a7d log2 \ud835\udc58 . Applied at level \ud835\udc56, Theorem 5.5 (with \ud835\udc58\ud835\udc56 communities and\n\ncorruption _\ud835\udf02\ud835\udc56_ ) gives, for some absolute _\ud835\udc36_ 0 _>_ 0,\n\n###### err \ud835\udc56 \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd\ufffd] [\ud835\udc36][\ud835\udc56] \ufffd 8\n\n+ _\ud835\udc36_ 0 _\ud835\udc58\ud835\udc56\ud835\udf02\ud835\udc56._\n###### \ufffd\n\n###### By Theorem C.5, \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 is nondecreasing in \ud835\udc56 and \ud835\udefd 1 \ud835\udc36 [\ufffd] 1 = \u0398( \ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 [2] ), hence\n\n###### exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd\ufffd] [\ud835\udc36][\ud835\udc56] \ufffd 8 Moreover \ud835\udc58\ud835\udc56\ud835\udf02\ud835\udc56 \u2a7d ( \ud835\udefd\ud835\udc56 \ud835\udc58 )( \ud835\udf02 / \ud835\udefd\ud835\udc56 ) = \ud835\udc58\ud835\udf02, so\n\n###### \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ufffd \ud835\udc58 [2]\n\n_._\n###### \ufffd\n\n###### err \ud835\udc56 \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ud835\udc58 [2]\n\n+ _\ud835\udc36_ 0 _\ud835\udc58\ud835\udf02_ for all _\ud835\udc56._ (10.1)\n###### \ufffd\n\nAt level _\ud835\udc56_ there are 2 _[\ud835\udc56]_ disjoint subproblems, each with error at most err _\ud835\udc56_, so the number\nof newly misclustered vertices at that level is at most 2 _[\ud835\udc56]_ err _\ud835\udc56\ud835\udc5b\ud835\udc56_ . Since _\ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b_ = 2 [1][\u2212] _[\ud835\udc56]_ _\ud835\udc5b_, we\nhave 2 _[\ud835\udc56]_ _\ud835\udc5b\ud835\udc56_ = 2 _\ud835\udc5b_, and the contribution of level _\ud835\udc56_ to the global error is at most\n\n2 _[\ud835\udc56]_ err _\ud835\udc56\ud835\udc5b\ud835\udc56_\n###### \u2a7d 2err \ud835\udc56.\n\n_\ud835\udc5b_\n\nSumming over _\ud835\udc56_ = 1 _, . . .,_ \u230alog2 _\ud835\udc58_ \u230b and using (10.1),\n\n_\ud835\udc58_ [2]\n\nerror _\ud835\udc58_ ( _\ud835\udc4d, \ud835\udc4d_ [\u02c6] [\u25e6] ) \u2a7d\n\n\u230alog2 _\ud835\udc58_ \u230b\n###### \ufffd\n\n###### 2err \ud835\udc56 \u2a7d \ud835\udc42 (log \ud835\udc58 ) [\ufffd] exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ufffd \ud835\udc58 [2]\n\n_\ud835\udc56_ =1\n\n###### + \ud835\udc36 0 \ud835\udc58\ud835\udf02 [\ufffd] . \ufffd\n\n50\n\nAbsorbing the _\ud835\udc42_ (log _\ud835\udc58_ ) and _\ud835\udc36_ 0 factors into poly( _\ud835\udc58_ ), we obtain\n\n###### error \ud835\udc58 ( \ud835\udc4d, \ud835\udc4d [\u02c6] [\u25e6] ) \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ud835\udc58 [2]\n\n+ poly( _\ud835\udc58_ ) _\ud835\udf02,_\n###### \ufffd\n\n###### as claimed. \u25a1\n\nAs a direct consequence of Theorem 5.6, we obtain the following corollary, capturing\nthe symmetry-breaking improvement:\n\n###### Corollary 10.2. If \ud835\udc51\ud835\udf00 [2] \u2a7e \ud835\udc3e\ud835\udc58 [2] log \ud835\udc58 for some sufficiently large constant \ud835\udc3e, then Theorem 10.1\n\n1 1\n###### achieves, with probability at least 1 \u2212 exp(\u2212\u03a9( \ud835\udc58 )) \u2212 poly( \ud835\udc5b ) [, a labeling error at most][ \ud835\udc42] \ufffd poly( \ud835\udc58 ) \ufffd .\n\n### **11 Robust optimal recovery algorithm**\n\nIn this section, we build on the guarantees from Section 10 and give a robust polynomialtime algorithm that partitions the vertices into _\ud835\udc58_ communities at the minimax-optimal\nrate. The algorithm is a constant-degree sum-of-squares (SoS) relaxation of polynomial\nconstraints that encode pairwise majority voting. These constraints closely mirror those\nused for robust bisectioning. The key difference is the symmetry-breaking guarantee from\nTheorem 10.2, which ensures that across all feasible solutions the community labels are\naligned. This alignment allows us to analyze the majority voting guarantees for each pair\nof communities.\n\n##### **11.1 Algorithm and constraint systems**\n\nWe first introduce the polynomial constraints that are used in our robust optimal recovery\nalgorithm.\n\n**(i) Labeling constraints.** The feasible label variable _\ud835\udc4d_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ satisfies\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = _[\ud835\udc5b]_\n\n_\ud835\udc58_\n\n_\ud835\udc56_\n\n_\ud835\udc58_\n\n\ud835\udc9clabel( _\ud835\udc4d_ ) :=\n\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) [2] = _\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) _,_\n###### \ufffd\n\n_\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ ) = 1 _,_\n###### \ufffd\n\n_\ud835\udc4e_ _\ud835\udc56_\n\n###### \ufffd\n\n_._ (11.1)\n\n**(ii) Initialization (symmetry breaking).** Let _\ud835\udc4d_ init \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ be an initializer with _\ud835\udf07_ approximation error. We constrain the SoS variable _\ud835\udc4d_ to remain close to _\ud835\udc4d_ init:\n\n###### \ud835\udc9csym-break( \ud835\udc4d ; \ud835\udc4d init, \ud835\udf07 ) := \ufffd\u2225 \ud835\udc4d \u2212 \ud835\udc4d init\u2225 [2] F [\u2a7d] [\ud835\udf07] \ufffd . (11.2)\n\n**(iii) Corruption mask / node distance.** We model node corruptions through a binary mask\n_\ud835\udf09_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ and require the program matrix to agree with the observed graph outside the\ncorrupted rows/columns:\n\n###### \ufffd\n\n\ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udc3a,_ [\u00af] _\ud835\udf02_ ) :=\n\n###### \ufffd\n\n###### ( \ud835\udc4c \u2212 \ud835\udc3a [\u00af] ) \u2299( 1 \u2212 \ud835\udf09 )( 1 \u2212 \ud835\udf09 ) [\u22a4] = 0, \ud835\udf09 \u2299 \ud835\udf09 = \ud835\udf09, \ufffd \ud835\udf09\ud835\udc56 \u2a7d \ud835\udeff\ud835\udf02\ud835\udc5b\n\n_\ud835\udc56_\n\n###### ( \ud835\udc4c \u2212 \ud835\udc3a [\u00af] ) \u2299( 1 \u2212 \ud835\udf09 )( 1 \u2212 \ud835\udf09 ) [\u22a4] = 0, \ud835\udf09 \u2299 \ud835\udf09 = \ud835\udf09, \ufffd\n\n_,_ (11.3)\n\n51\n\nwhere _\ud835\udeff\ud835\udf02_ = exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ ) + _\ud835\udf02_ .\n\n**(iv) Community structure and spectral condition.** We encode the decomposition of the\ncentered adjacency into pairwise components and bound the spectral norm of the noise\nblocks:\n\n###### \ud835\udc51 \u2a7d \ud835\udf12 + [1]\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ _\ud835\udc58_\n###### \ufffd\ufffd\ufffd\ufffdop \ufffd\n\n_\ud835\udc58_\n\n\ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) :=\n\n###### \ufffd\n\n_\ud835\udc4b_ = _\ud835\udc4d\ud835\udc4d_ [\u22a4] \u2212 [1]\n\n[1] _\ud835\udc4c_ \u2212 _\ud835\udf00\ud835\udc51_\n\n_\ud835\udc58_ _[\ud835\udc3d,]_ _\ud835\udc5b_\n###### \ufffd\ufffd\ufffd\ufffd\n\n###### \ufffd\n\n_._ (11.4)\n\n\u221a\n###### \ufffd\n\n_\ud835\udc51_\n\n**(v) Majority-vote consistency.** For each pair _\ud835\udc4e, \ud835\udc4f_ \u2208[ _\ud835\udc58_ ] define _\ud835\udc65\ud835\udc4e\ud835\udc4f_ = _\ud835\udc4d_ (\u00b7 _, \ud835\udc4e_ ) \u2212 _\ud835\udc4d_ (\u00b7 _, \ud835\udc4f_ ). We\nrequire that, the pairwise labels are satisfy majority voting constraint.\n\n\u2225 _\ud835\udc67_ \u2299 _\ud835\udc65\ud835\udc4e\ud835\udc4f_ \u2225 [2] \u2212 640 _\ud835\udefd\ud835\udc5b_\n###### \ufffd \ufffd\n\n###### \ud835\udc9cmaj( \ud835\udc4c, \ud835\udc4d, \ud835\udc45 ; \ud835\udefe, \ud835\udefd ) := \uf8f1\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f3\n\n###### \ud835\udc62 \u27e8 \ud835\udc4c\ud835\udc65\ud835\udc4e\ud835\udc4f, \ud835\udc67 \u2299 \ud835\udc65\ud835\udc4e\ud835\udc4f \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n###### \uf8fc\uf8f4\uf8f4\uf8fd \uf8f4\uf8f4\uf8fe\n\n_,_\n\n_\ud835\udc45_ : \ud835\udc9cset( _\ud835\udc67_ ) 2\n\n16 _\ud835\udc58_\n\n_\ud835\udc65\ud835\udc4e\ud835\udc4f_ = _\ud835\udc4d_ (\u00b7 _, \ud835\udc4e_ ) \u2212 _\ud835\udc4d_ (\u00b7 _, \ud835\udc4f_ )\n\n(11.5)\nwhere \ud835\udc9cset( _\ud835\udc67_ ) := { _\ud835\udc67_ \u2299 _\ud835\udc67_ = _\ud835\udc67_ }. We will use two parameter settings, corresponding to a\ntwo-round majority vote that achieves the minimax rate [16]\n###### \u2022 \ud835\udf07 1 = poly \ud835\udc5b ( \ud835\udc58 ) [,] [ \ud835\udefe] [1][ =][ 0] [.] [99,] [ \ud835\udefd] [1][ =][ 1000] [\ud835\udc58] [exp] \ufffd\u22120 . 99 [\ud835\udc36] \ud835\udc58 [\ud835\udc51][,][\ud835\udf00] \ufffd.\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\n- _\ud835\udf07_ opt = exp \u22120 _._ 99(1 \u2212 _\ud835\udc5c_ (1)) _[\ud835\udc36]_ _\ud835\udc58_ _[\ud835\udc51][,][\ud835\udf00]_\n###### \ufffd\n\n_[\ud835\udc51]_ _[,][\ud835\udf00]_\n\n_\ud835\udc58_, _\ud835\udefe_ opt = 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n###### \ufffd \u221a \ud835\udc36\ud835\udc51,\n\n_[\ud835\udf12][\ud835\udc58]_ \u221a\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ [,] _[ \ud835\udefd]_ [opt][ =]\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ \u2212 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n###### 10 \ud835\udf12 [exp] \ufffd \ufffd \u221a \ud835\udc36\ud835\udc51,\ud835\udf00\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\n_\ud835\udc58_ .\n###### \ufffd \ufffd\n\nFor our algorithm, we define polynomial system \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udf07, \ud835\udefe, \ud835\udefd_ ) based\non the set of constraints defined above [17]\n\n\ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udf07, \ud835\udefe, \ud835\udefd_ )\n\n:= \ud835\udc9clabel( _\ud835\udc4d_ ) \u222a\ud835\udc9csym-break( _\ud835\udc4d_ ; _\ud835\udc4d_ init _, \ud835\udf07_ ) \u222a\ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udc3a,_ [\u00af] _\ud835\udf02_ ) \u222a\ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) \u222a\ud835\udc9cmaj( _\ud835\udc4c, \ud835\udc4d, \ud835\udc45_ ; _\ud835\udefe, \ud835\udefd_ ) _._\n(11.6)\n\n**Algorithm.** The complete robust optimal recovery algorithm for _\ud835\udc58_ -SBM is described in\nTheorem 11.1.\n\n16Two rounds are needed to sharpen the error from a constant-factor exponent to the optimal exponent.\n17For simplicity, we use \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) to denote \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; \u00af _\ud835\udc3a, \ud835\udc4d_ init _, \ud835\udf02, \ud835\udefe, \ud835\udefd_ ) when the input is clear\nfrom the context.\n\n52\n\n**.**\n**Algorithm 11.1** (Robust recovery algorithm)\n**Input:** The centered adjacency matrix _\ud835\udc3a_ [\u00af] drawn from SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) with at most _\ud835\udf02\ud835\udc5b_\ncorrupted nodes.\n\n1. Run Theorem 10.1 to obtain an initializer _\ud835\udc4d_ [\u02c6] init.\n\n2. Find degree- _\ud835\udc42_ (1) pseudo-expectation \ud835\udd3c [\u02dc] satisfying \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udefe, \ud835\udefd_ )\n###### with \ud835\udc4d [\u02c6] init, \ud835\udefe = 0 . 99, \ud835\udf07 = poly \ud835\udc5b ( \ud835\udc58 ) [,] [ \ud835\udefd] [=][ 1000] [\ud835\udc58] [exp] \ufffd\u22120 . 99 [\ud835\udc36] \ud835\udc58 [\ud835\udc51][,][\ud835\udf00] \ufffd.\n\n3. Round \ud835\udd3c [\u02dc] by labelling vertex _\ud835\udc56_ with label argmax _\ud835\udc4e_ \ud835\udd3c [\u02dc] [ _\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ )] to _\ud835\udc4d_ [\u02c6] .\n\n4. Find degree- _\ud835\udc42_ (1) pseudo-expectation \ud835\udd3c [\u02dc] opt satisfying \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09, \ud835\udc45_ ; _\ud835\udc3a, \ud835\udc4d_ [\u00af] init _, \ud835\udf02, \ud835\udefe, \ud835\udefd_ )\n\n###### \ufffd\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\nwith _\ud835\udc4d_ [\u02c6], _\ud835\udf07_ = exp \u22120 _._ 99(1 \u2212 _\ud835\udc5c_ (1)) _[\ud835\udc36]_ _\ud835\udc58_ _[\ud835\udc51][,][\ud835\udf00]_\n###### \ufffd\n\n_[\ud835\udc51]_ _[,][\ud835\udf00]_\n\n_\ud835\udc58_, _\ud835\udefe_ = 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n###### \ufffd \u221a \ud835\udc36\ud835\udc51,\n\n_[\ud835\udf12][\ud835\udc58]_ \u221a\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ [,] _[ \ud835\udefd]_ [=]\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ \u2212 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n###### 10 \ud835\udf12 [exp] \ufffd \ufffd \u221a \ud835\udc36\ud835\udc51,\ud835\udf00\n\n.\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\n_\ud835\udc58_\n###### \ufffd\n\n5. Round \ud835\udd3c [\u02dc] opt by labelling vertex _\ud835\udc56_ with label argmax _\ud835\udc4e_ \ud835\udd3c [\u02dc] opt[ _\ud835\udc4d_ ( _\ud835\udc56, \ud835\udc4e_ )] to _\ud835\udc4d_ opt.\n\n_\ud835\udc4d_ .\n**Output:** opt\n\n##### **11.2 Feasibility and time complexity**\n\nWe first establish feasibility of \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) and time complexity of Theorem 11.1.\n\n**Lemma 11.2.** _Let_ _\ud835\udc3a_ [\u00af] [\u25e6] _be the centered adjacency matrix of the uncorrupted graph and \ud835\udc46_ _be the set_\n_of nodes with degree larger than_ 20 _\ud835\udc51. Let \ud835\udc47_ _be the set of corrupted nodes. Let \ud835\udc4d_ [\u25e6] _be the ground_\n_truth label matrix. Under the conditions of Theorem 5.7, program_ \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) _is satisfied by_\n( _\ud835\udc3a_ [\u00af] [\u25e6] \u2299( **1** \u00af _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_ \u00af [)] _[, \ud835\udc4d]_ [\u25e6] _[,]_ **[ 1]** _[\ud835\udc46]_ [\u222a] _[\ud835\udc47]_ [)] _[ with probability at least]_ [ 1][ \u2212] [exp][(\u2212][100] _[\ud835\udc58]_ [) \u2212] [1][/] _[\ud835\udc5b]_ [3] _[.]_\n\n_Proof._ The proof parallels Theorem 8.2. For \ud835\udc9cmix, feasibility follows from Theorem 4.6.\n###### The mixing constraints \ufffd\ufffd \ud835\udc4c \u2212 \ud835\udf00\ud835\udc5b\ud835\udc51 [\ud835\udc4b] \ufffd\ufffd [\u2a7d] [\ufffd] \ud835\udf12 + [1] \ud835\udc58 \ufffd\u221a \ud835\udc51 follow from applying Theorem B.2 and\n\n###### [1] \ud835\udc58 \ufffd\u221a\n\n###### \ud835\udc5b\ud835\udc51 [\ud835\udc4b] \ufffd\ufffdop [\u2a7d] [\ufffd] \ud835\udf12 + [1] \ud835\udc58\n\n###### The mixing constraints \ufffd\ufffd \ud835\udc4c \u2212 \ud835\udf00\ud835\udc5b [\ud835\udc4b] \ufffd\ufffdop [\u2a7d] [\ufffd] \ud835\udf12 + \ud835\udc58 \ufffd \ud835\udc51 follow from applying Theorem B.2 and\n\nsimilar analysis as Theorem 8.2. The feasibility of initialization constraint follows from\n###### Theorem 5.6. The feasibility of corruption constraint follows from Theorem B.2. \u25a1\n\n**Lemma 11.3.** _Theorem 11.1 runs in polynomial time._\n\n_Proof._ The SoS relaxation has constant degree and therefore produces an SDP with\n###### polynomially many variables and constraints, which can be solved in polynomial time. \u25a1\n\n##### **11.3 SoS guarantees for robust optimal boosting**\n\nWe now prove \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) boosts the accuracy to the desired rate. To do this, we consider\ntwo feasible solutions ( _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)] ) and ( _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)] ) of \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ). We will show\nthat the constraints in \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) allow us to prove that any two good solutions will be\n\n53\n\nwithin minimax error rate to each other. Since _\ud835\udc4d_ [\u25e6] is also a good solution, this implies that\nany feasible solution of \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ) achieves the minimax error rate.\nThroughout this section, we define the following terms:\n\n  - Let _\ud835\udc59_ [(] _[\ud835\udc61]_ [)]\n_\ud835\udc4e\ud835\udc4f_ [=] _[ \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ _[\ud835\udc61]_ [)] [\u2299] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ _[\ud835\udc61]_ [)] [be the support of] _[ \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ _[\ud835\udc61]_ [)] [for] _[ \ud835\udc61]_ [\u2208{][1] _[,]_ [ 2][}][. Notice that, equivalently,]\n\n_\ud835\udc59_ [(] _[\ud835\udc61]_ [)]\n_\ud835\udc4e\ud835\udc4f_ [=] _[ \ud835\udc4d]_ [(] _[\ud835\udc61]_ [)][(\u00b7] _[, \ud835\udc4e]_ [) +] _[ \ud835\udc4d]_ [(] _[\ud835\udc61]_ [)][(\u00b7] _[, \ud835\udc4f]_ [)][.]\n\n  - Let _\ud835\udc59\ud835\udc4e\ud835\udc4f_ = _\ud835\udc59\ud835\udc4e\ud835\udc4f_ [(][1][)] [\u2299] _[\ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][2][)] [be the intersection of] _[ \ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][1][)] [and] _[ \ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][2][)][.]\n\n_\ud835\udc59_ [(][1][)]\n\n  - Let _\ud835\udc63\ud835\udc4e\ud835\udc4f_ = _\ud835\udc4e\ud835\udc4f_ [\u2299] _[\ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][2][)][\u2212] 2 _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)][\u2299] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] be the coordinates where two feasible pairwise labels _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [and]\n\n_\ud835\udc65_ [(][2][)]\n_\ud835\udc4e\ud835\udc4f_ [differ.]\n\n  - Let _\ud835\udc60_ = **1** \u2212( **1** \u2212 _\ud835\udf09_ [(][1][)] ) \u2299( **1** \u2212 _\ud835\udf09_ [(][2][)] ) be the set of nodes where _\ud835\udc4c_ [(][1][)] and _\ud835\udc4c_ [(][2][)] differ.\n\n  - Let _\ud835\udc64\ud835\udc4e\ud835\udc4f_ = _\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2299( **1** \u2212 _\ud835\udc60_ ) be the set of vertices in the shared part of _\ud835\udc4c_ [(][1][)] and _\ud835\udc4c_ [(][2][)] such\nthat the bisections _\ud835\udc65_ [(][1][)] and _\ud835\udc65_ [(][2][)] differ.\n\n  - Let _\ud835\udc54\ud835\udc4e\ud835\udc4f_ = **1** \u2212( **1** \u2212 _\ud835\udc63\ud835\udc4e\ud835\udc4f_ ) \u2299( **1** \u2212 _\ud835\udc60_ ) be union of _\ud835\udc63\ud835\udc4e\ud835\udc4f_ and _\ud835\udc60_, notice that, equivalently\n\n_\ud835\udc54\ud835\udc4e\ud835\udc4f_ = _\ud835\udc64\ud835\udc4e\ud835\udc4f_ + _\ud835\udc60_ .\n\nTo prove the algorithmic guarantee of \ud835\udc9copt( _\ud835\udc4c, \ud835\udc4d, \ud835\udf09_ ), we need the following observations\non properties of the variables defined above.\n\n**Lemma 11.4.** _For any \ud835\udc4e, \ud835\udc4f_ \u2208[ _\ud835\udc58_ ] _, \ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] _[,][ \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] _[and][ \ud835\udc63][\ud835\udc4e\ud835\udc4f]_ _[satisfies]_\n\n_\ud835\udc65_ [(][1][)] _and_ _\ud835\udc65_ [(][1][)]\n_\ud835\udc4e\ud835\udc4f_ [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [=][ \u2212] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ _\ud835\udc4e\ud835\udc4f_ [\u2299(] _[\ud835\udc59][\ud835\udc4e\ud835\udc4f]_ [\u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [)][ =] _[ \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299(] _[\ud835\udc59][\ud835\udc4e\ud835\udc4f]_ [\u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [)] _[,]_\n\n_and,_\n\n_\ud835\udc59\ud835\udc4e\ud835\udc4f_ \u2212 _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] _\ud835\udc59\ud835\udc4e\ud835\udc4f_ + _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] _\ud835\udc59\ud835\udc4e\ud835\udc4f_ \u2212 _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] _\ud835\udc59\ud835\udc4e\ud835\udc4f_ + _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)]\n_\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2299 = _\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2299 _and_ _\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2299 = _\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2299 _._\n2 2 2 2\n\n###### Proof. The proof follows by similar analysis as Theorem 8.4. \u25a1\n\n**Lemma 11.5.** _The norm of \ud835\udc63\ud835\udc4e\ud835\udc4f, \ud835\udc60_ _and \ud835\udc54\ud835\udc4e\ud835\udc4f_ _satisfies the following SoS inequalities_\n\n_\ud835\udf09_ [(][1][)] _,\ud835\udf09_ [(][2][)]\n\n_\ud835\udc42_ (1)\n\n_\ud835\udc4d_ [(][1][)] _,\ud835\udc4d_ [(][2][)]\n\n_\ud835\udc42_ (1)\n\n_and,_\n\n_and,_\n\n_and,_\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n###### \u2225 \ud835\udc60 \u2225 [2] \u2a7d 2 \ud835\udeff\ud835\udf02\ud835\udc5b, \u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d \ud835\udf07,\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n_\ud835\udc4d_ [(][1][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udf09_ [(][2][)]\n\n_\ud835\udc42_ (1)\n\n###### \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d \ud835\udf07,\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n54\n\n_\ud835\udc4d_ [(][1][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udf09_ [(][2][)][ \ufffd] 2\n###### \ud835\udc42 (1) \ufffd \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd \u2a7d \ud835\udf07 + 4 \ud835\udeff\ud835\udf02\ud835\udc5b.\n\n_Proof._ For the bound on _\ud835\udc60_, by constraints in \ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ), it follows that\n\n_\ud835\udf09_ [(] _\ud835\udc56_ [2][)][(][1][ \u2212] _[\ud835\udf09]_ [(] _\ud835\udc56_ [1][)][)]\n\n_\ud835\udc56_\n\n###### \u2225 \ud835\udc60 \u2225 [2] = \ufffd\n\n_\ud835\udc60\ud835\udc56_ =\n###### \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### 1 \u2212(1 \u2212 \ud835\udf09 [(] \ud835\udc56 [1][)][) \u2299(][1][ \u2212] [\ud835\udf09] [(] \ud835\udc56 [2][)][)][ =] \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \ud835\udf09 [(] \ud835\udc56 [1][)] + \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \ud835\udf09 [(] \ud835\udc56 [1][)] + \ufffd\n\n_\ud835\udc56_ _\ud835\udc56_\n\n###### \u2a7d \ufffd\n\n###### \ud835\udf09 [(] \ud835\udc56 [2][)] \u2a7d 2 \ud835\udeff\ud835\udf02\ud835\udc5b.\n\n_\ud835\udc56_\n\nFor the bound on _\ud835\udc63\ud835\udc4e\ud835\udc4f_, by constraints in \ud835\udc9cinit( _\ud835\udc4d_ ; _\ud835\udc4d_ init), it follows that\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n\u2225 _\ud835\udc63\ud835\udc4e\ud835\udc4f_ \u2225 [2] =\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc59_ [(][1][)]\n_\ud835\udc4e\ud835\udc4f_ [\u2299] _[\ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][2][)] [\u2212] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)]\n\n2\n\n_\ud835\udc65_ [(][1][)]\n_\ud835\udc4e\ud835\udc4f_ [\u2299] _[\ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][2][)] [\u2212] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc59]_ _\ud835\udc4e\ud835\udc4f_ [(][1][)]\n\n2\n\n=\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n2\n###### \ufffd\ufffd\ufffd\ufffd\ufffd\n\n###### \u2a7d [1]\n\n2\n\n2\n(1) (2)\n###### \ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2212 \ud835\udc4d (\u00b7, \ud835\udc4e )\ufffd\ufffd + 1\n\n2\n\n###### \u2a7d\n\n###### \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc65_ [(][1][)]\n_\ud835\udc4e\ud835\udc4f_ [\u2212] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)]\n\n2\n\n2\n(1) (2)\n###### \ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d (\u00b7, \ud835\udc4f )\ufffd\ufffd\n\n2 2\n(1) (2)\n###### \u2a7d\ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4e )\ufffd\ufffd + \ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4e ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4e )\ufffd\ufffd\n\n2 2\n(1) (2)\n###### + \ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4f )\ufffd\ufffd + \ufffd\ufffd \ud835\udc4d (\u00b7, \ud835\udc4f ) \u2212 \ud835\udc4d init(\u00b7, \ud835\udc4f )\ufffd\ufffd \u2a7d\u2225 \ud835\udc4d \u2212 \ud835\udc4d init\u2225 [2] F [\u2a7d] [\ud835\udf07] [.]\n\nThe bound on \u2225 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] follows by\n\n###### \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] = \u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2299( 1 \u2212 \ud835\udc60 )\u2225 [2] \u2a7d \u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d \ud835\udf07 .\n\n2\n###### For the bound on \ufffd\ufffd \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd, since \ud835\udc54\ud835\udc4e\ud835\udc4f = \ud835\udc64\ud835\udc4e\ud835\udc4f + \ud835\udc60,\n\n2 2 2 2\n###### \ufffd\ufffd \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd = \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f + \ud835\udc60 \u2225 \u2a7d 2\u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 + 2\u2225 \ud835\udc60 \u2225 \u2a7d \ud835\udf07 + 4 \ud835\udeff\ud835\udf02\ud835\udc5b.\n\n**Fact 11.6.** _Fix \ud835\udc4e, \ud835\udc4f_ \u2208[ _\ud835\udc58_ ] _, there is a constant-degree SoS proof of_\n\n_\ud835\udc4c_ [(][1][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ = \u2212 _\ud835\udc4c_ [(][2][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ _._\n###### \ufffd \ufffd \ufffd \ufffd\n\n_Proof._ Plugging in the definition of _\ud835\udc54\ud835\udc4e\ud835\udc4f_ and _\ud835\udc64\ud835\udc4e\ud835\udc4f_, the left hand side can be written as\n\n_\ud835\udc4c_ [(][1][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ = _\ud835\udc4c_ [(][1][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [) \u2299(] **[1]** [ \u2212] _[\ud835\udc60]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [\u2299(] **[1]** [ \u2212] _[\ud835\udc60]_ [)]\n###### \ufffd \ufffd \ufffd \ufffd\n\n###### \u25a1\n\n= _\ud835\udc4c_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4][\ufffd\ufffd] _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [)] _, \ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ _._\n###### \ufffd\ufffd \ufffd \ufffd\n\nBy \ud835\udc9cclose( _\ud835\udc4c, \ud835\udf09_ ; _\ud835\udf02,_ _\ud835\udc3a_ [\u00af] ), we have\n\n_\ud835\udc4c_ [(][1][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc3a_ [\u00af] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] = _\ud835\udc4c_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] _,_\n\nand, by Theorem 11.4, we have\n\n_\ud835\udc65_ [(][1][)] and _\ud835\udc65_ [(][1][)]\n_\ud835\udc4e\ud835\udc4f_ [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [=][ \u2212] _[\ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ _\ud835\udc4e\ud835\udc4f_ [\u2299(] _[\ud835\udc59][\ud835\udc4e\ud835\udc4f]_ [\u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [)][ =] _[ \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299(] _[\ud835\udc59][\ud835\udc4e\ud835\udc4f]_ [\u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [)] _[,]_\n\n55\n\nThus,\n\n_\ud835\udc4c_ [(][1][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ = \u2212 _\ud835\udc4c_ [(][2][)] \u2299( **1** \u2212 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4][\ufffd] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc63][\ud835\udc4e\ud835\udc4f]_\n###### \ufffd \ufffd \ufffd\ufffd \ufffd = \u2212\ufffd \ud835\udc4c [(][2][)] ( \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [2][)] [\u2299(] [1] [ \u2212] [\ud835\udc54][\ud835\udc4e\ud835\udc4f] [))] [, \ud835\udc65] [(] \ud835\udc4e\ud835\udc4f [2][)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] \ufffd . \u25a1\n\n.\nWe next upper bound the contribution of the signal on the set _\ud835\udc54_\n\n**Lemma 11.7.** _In the setting of Theorem 5.7, for any \ud835\udeff_ \u2208[0 _,_ 0 _._ 001] _and \ud835\udc61_ \u2208{1 _,_ 2} _,_\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n_\ud835\udc4c_ [(][1][)] _,\ud835\udc4d_ [(][1][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udc4c_ [(][2][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][2][)][ \ufffd] _\ud835\udf00\ud835\udc51_ _\ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02_\n###### 6 \ud835\udc4c [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [\ud835\udc61] [)] [\u2299] [\ud835\udc54][\ud835\udc4e\ud835\udc4f], \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [\ud835\udc61] [)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] \u2a7d \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] + \ud835\udc5b. \ufffd \ufffd \ufffd poly( \ud835\udc58 ) [+][ 4] [\ud835\udf00][\ud835\udc51][\ud835\udeff][\ud835\udf02] \ufffd \ud835\udc58\n\n_Proof._ For notational simplicity, we ignore the superscript ( _\ud835\udc61_ ) throughout the proof. We\ndecompose the left hand side in the following way\n\n_[\ud835\udc51]_\n###### \ufffd \ud835\udc4b [\ufffd] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \ufffd+ ( \ud835\udc4c \u2212 [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n###### \ufffd\n\n###### \ufffd \ud835\udc4c [\ufffd] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54 [\ufffd], \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \ufffd = [\ud835\udf00][\ud835\udc51]\n\n###### \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [)][\ufffd]\n\n_._\n###### \ufffd\n\n(11.7)\n###### For the first term, since \ud835\udc4b = \ud835\udc4d\ud835\udc4d [\u22a4] \u2212 [1] \ud835\udc58 [\ud835\udc3d] [, we have][ \u2212] [\ud835\udc3d] [\u2a7d] [\ud835\udc4b] [\u2a7d] [\ud835\udc3d] [such that]\n\n( _\ud835\udc64\ud835\udc4e\ud835\udc4f_ ) _\ud835\udc56_\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n###### \ufffd\n\n_\ud835\udf00\ud835\udc51_\n\n_\ud835\udf00\ud835\udc51_\n###### \ufffd \ud835\udc4b [\ufffd] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \ufffd \u2a7d [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n\n( _\ud835\udc54\ud835\udc4e\ud835\udc4f_ ) _\ud835\udc56_\n###### \ufffd\ufffd \ud835\udc56\n\n###### \ufffd\ufffd \ud835\udc56\n\n= _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_\n\n_\ud835\udc5b_\n\n2 2\n###### \ufffd\ufffd \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 .\n\n2\n###### Since \ufffd\ufffd \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd \u2a7d \ud835\udf07 + 4 \ud835\udeff\ud835\udf02\ud835\udc5b, it follows that\n\n_\ud835\udf00\ud835\udc51_ _\ud835\udf00\ud835\udc51\ud835\udf07_\n###### \ufffd \ud835\udc4b [\ufffd] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \ufffd \u2a7d\n\n_\ud835\udc5b_ _\ud835\udc5b_\n###### \ufffd\n\n\u2225 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] _._ (11.8)\n###### \ufffd\n\n_\ud835\udf00\ud835\udc51_\n\n+ 4 _\ud835\udf00\ud835\udc51\ud835\udeff_\n_\ud835\udf02_\n_\ud835\udc5b_\n\nFor the second term, by \ud835\udc9cmix( _\ud835\udc4c, \ud835\udc4d_ ) and SoS Cauchy-Schwarz, we also have\n\n2\n###### ( \ud835\udc4c \u2212 [\ud835\udf00][\ud835\udc51] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2a7d [1] \ud835\udf12 + [1] \u221a \ud835\udc51 \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd + \u2225 \ud835\udc65\ud835\udc4e\ud835\udc4f \ud835\udc5b [\ud835\udc4b] [)][\ufffd] 2 \ud835\udc58 \ufffd\ufffd\ufffd \ufffd \ufffd \ufffd \ufffd\n\n###### \u2a7d [1]\n\n2\n###### \ufffd\n\n###### \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f\n\n_\ud835\udc5b_ _[\ud835\udc4b]_ [)][\ufffd]\n\n###### 2 2 [\ufffd] \ud835\udc51 \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd\ufffd + \u2225 \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 \ufffd\ufffd\ufffd\n\n2\n\n_\ud835\udf12_ + [1]\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udf12_ + [1]\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udf12_ + [1]\n\n_\ud835\udc58_\n###### \ufffd\n\n_\ud835\udc58_\n\n\u221a\n###### \ufffd\n\n\u221a\n###### \ufffd\n\n\u221a\n###### \ufffd\n\n###### \u2a7d [1]\n\n2\n\n###### \u2a7d [1]\n\n2\n\n###### \ud835\udc51 \ufffd3\u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] + 2\u2225 \ud835\udc60 \u2225 [2][\ufffd]\n\n_\ud835\udc51_ 3\u2225 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] + 2 _\ud835\udeff\ud835\udf02\ud835\udc5b_ _._\n###### \ufffd \ufffd\n\nSince \u221a\n\n_[\ud835\udf00]_\n\n_\ud835\udc58_ [, it follows that]\n\n_\ud835\udc4c_ \u2212 _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc4b]_\n###### \ufffd\ufffd \ufffd\ufffd\n\n_\ud835\udc51_ \u226a _[\ud835\udf00][\ud835\udc51]_\n\n_[\ud835\udc51]_\n###### \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54\ud835\udc4e\ud835\udc4f \ufffd, \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f\n\n_\ud835\udc5b_ _[\ud835\udc4b]_\n###### \ufffd\ufffd\n\n###### \u2a7d [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc58_\n###### \ufffd\n\n_[\ud835\udc51]_ _\ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02_\n\n_\ud835\udc58_ [\u2225] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ [\u2225][2][ +] _\ud835\udc58_\n\n_\ud835\udc5b._ (11.9)\n_\ud835\udc58_\n\n56\n\nPlugging Eq. (11.8) and Eq. (11.9) into Eq. (11.7), it follows that\n\n_\ud835\udf00\ud835\udc51\ud835\udf07_\n###### \ufffd \ud835\udc4c [\ufffd] \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc54 [\ufffd], \ud835\udc65\ud835\udc4e\ud835\udc4f \u2299 \ud835\udc64\ud835\udc4e\ud835\udc4f \ufffd \u2a7d + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02\n\n_\ud835\udc5b_\n###### \ufffd\n\n_\ud835\udf00\ud835\udc51\ud835\udeff_\n_\ud835\udf02_\n\u2225 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] + _\ud835\udc5b._\n\n_\ud835\udc58_\n###### \ufffd\n\n###### \u25a1\n\nNow, we are ready to prove the algorithmic guarantee of \ud835\udc9copt.\n\n**Theorem 11.8.** _In the setting of Theorem 5.7,_\n\n\ud835\udc9copt _\ud835\udc4c_ [(][1][)] _, \ud835\udc4d_ [(][1][)] _, \ud835\udf09_ [(][1][)][\ufffd] _,_ \ud835\udc9copt _\ud835\udc4c_ [(][2][)] _, \ud835\udc4d_ [(][2][)] _, \ud835\udf09_ [(][2][)][\ufffd]\n###### \ufffd \ufffd\n\n2 2\n(1 \u2212 _\ud835\udefe_ ) _\ud835\udc58_ _\ud835\udefd\ud835\udc5b_ + _\ud835\udc58_ _\ud835\udf02\ud835\udc5b_\n###### \u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d \ud835\udc42 \ufffd 1 \u2212 \ud835\udefe \u2212 \ud835\udf07\ud835\udc58 / \ud835\udc5b \u2212 \ud835\udf02\ud835\udc58\n\n_\ud835\udc4e,\ud835\udc4f_\n\n_\ud835\udc4c_ [(][1][)] _,\ud835\udc4d_ [(][1][)] _,\ud835\udf09_ [(][1][)] _,\ud835\udc4c_ [(][2][)] _,\ud835\udc4d_ [(][2][)] _,\ud835\udf09_ [(][2][)][ \ufffd]\n\n6\n\n2 2\n1 \u2212 _\ud835\udefe_ ) _\ud835\udc58_ _\ud835\udefd\ud835\udc5b_ + _\ud835\udc58_ _\ud835\udf02\ud835\udc5b_\n\n_._\n###### 1 \u2212 \ud835\udefe \u2212 \ud835\udf07\ud835\udc58 / \ud835\udc5b \u2212 \ud835\udf02\ud835\udc58 [+] [ \ud835\udc58] [2] [\ud835\udf07][\ud835\udc5b] \ufffd\n\n_Proof._ For any pairs of communities _\ud835\udc4e, \ud835\udc4f_ \u2208[ _\ud835\udc58_ ], by Theorem 11.6,\n\n_\ud835\udc4c_ [(][1][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [1][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ = \u2212 _\ud835\udc4c_ [(][2][)] ( _\ud835\udc65_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299(] **[1]** [ \u2212] _[\ud835\udc54][\ud835\udc4e\ud835\udc4f]_ [))] _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ [2][)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_ _._\n###### \ufffd \ufffd \ufffd \ufffd\n\nTherefore,\n\n###### \ud835\udc4c [(][1][)] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [1][)] [, \ud835\udc65] [(] \ud835\udc4e\ud835\udc4f [1][)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] + \ud835\udc4c [(][2][)] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [2][)] [, \ud835\udc65] [(] \ud835\udc4e\ud835\udc4f [2][)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] = \ud835\udc4c [(][1][)][\ufffd] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [1][)] [\u2299] [\ud835\udc54] [\ufffd], \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [1][)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] + \ud835\udc4c [(][2][)][\ufffd] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [2][)] [\u2299] [\ud835\udc54] [\ufffd], \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [2][)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] . \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\n\n(11.10)\nBy \ud835\udc9cmaj( _\ud835\udc4c, \ud835\udc4d, \ud835\udc45_ ; _\ud835\udefe, \ud835\udefd_ ), it follows that\n\n###### \ud835\udc4c [(] [\ud835\udc61] [)] \ud835\udc65 [(] [\ud835\udc61] [)] \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n_\ud835\udc4e\ud835\udc4f_ _[, \ud835\udc65]_ [(] _\ud835\udc4e\ud835\udc4f_ _[\ud835\udc61]_ [)] [\u2299] _[\ud835\udc64][\ud835\udc4e\ud835\udc4f]_\n###### \ufffd \ufffd 16 \ud835\udc58\n\nfor _\ud835\udc61_ \u2208{1 _,_ 2}. By Theorem 11.7, we have\n\n\u2225\u2299 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] \u2212 640 _\ud835\udefd\ud835\udc5b_ _,_ (11.11)\n###### \ufffd \ufffd\n\n_\ud835\udf00\ud835\udc51\ud835\udf07_\n###### \ud835\udc4c [(] [\ud835\udc61] [)] [\ufffd] \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [\ud835\udc61] [)] [\u2299] [\ud835\udc54][\ud835\udc4e\ud835\udc4f], \ud835\udc65 [(] \ud835\udc4e\ud835\udc4f [\ud835\udc61] [)] [\u2299] [\ud835\udc64][\ud835\udc4e\ud835\udc4f] \u2a7d + 4 \ud835\udf00\ud835\udc51\ud835\udeff\ud835\udf02 \ufffd \ufffd \ufffd \ud835\udc5b \ufffd\n\n_\ud835\udf00\ud835\udc51\ud835\udeff_\n_\ud835\udf02_\n\u2225 _\ud835\udc64\ud835\udc4e\ud835\udc4f_ \u2225 [2] + _\ud835\udc5b._ (11.12)\n\n_\ud835\udc58_\n###### \ufffd\n\nfor _\ud835\udc61_ \u2208{1 _,_ 2}.\nTherefore, plugging Eq. (11.11) and Eq. (11.12) into Eq. (11.10) and rearranging terms,\nwe can obtain\n\n(1 \u2212 _\ud835\udefe_ ) _\ud835\udefd\ud835\udc5b_ + _\ud835\udf02\ud835\udc5b_\n###### \u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d 1 \u2212 \ud835\udefe \u2212 \ud835\udf07\ud835\udc58 / \ud835\udc5b \u2212 \ud835\udf02\ud835\udc58 [.] Since \u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d 2\u2225 \ud835\udc64\ud835\udc4e\ud835\udc4f \u2225 [2] + 2\u2225 \ud835\udc60 \u2225 [2], it follows that\n\n2 2\n(1 \u2212 _\ud835\udefe_ ) _\ud835\udc58_ _\ud835\udefd\ud835\udc5b_ + _\ud835\udc58_ _\ud835\udf02\ud835\udc5b_\n###### \ufffd\u2225 \ud835\udc63\ud835\udc4e\ud835\udc4f \u2225 [2] \u2a7d \ud835\udc42 \ufffd 1 \u2212 \ud835\udefe \u2212 \ud835\udf07\ud835\udc58 / \ud835\udc5b \u2212 \ud835\udf02\ud835\udc58\n\n_\ud835\udc4e,\ud835\udc4f_\n\n###### \ufffd\n\n2 2\n1 \u2212 _\ud835\udefe_ ) _\ud835\udc58_ _\ud835\udefd\ud835\udc5b_ + _\ud835\udc58_ _\ud835\udf02\ud835\udc5b_\n\n_._\n###### 1 \u2212 \ud835\udefe \u2212 \ud835\udf07\ud835\udc58 / \ud835\udc5b \u2212 \ud835\udf02\ud835\udc58 [+] [ \ud835\udc58] [2] [\ud835\udf07][\ud835\udc5b] \ufffd\n\n###### \u25a1\n\n57\n\n##### **11.4 Algorithmic guarantees for robust optimal recovery**\n\nIn this section, we prove our main theorem and establish the algorithmic guarantees of our\nrobust optimal recovery algorithm for _\ud835\udc58_ -SBM.\n\n**Theorem** (Restatement of Theorem 5.7) **.** _Let_ ( _\ud835\udc3a_ [\u25e6] _, \ud835\udc4d_ [\u25e6] ) \u223c SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _be generated from the_\n_\ud835\udc58-stochastic block model and \ud835\udc3a_ _be generated by adversarially corrupting \ud835\udf02-fraction of the nodes in_\n###### \ud835\udc3a [\u25e6] . Assume \ud835\udc58 \u2a7d \ud835\udc5b [0] [.] [001], \ud835\udf02 \u2a7d poly1 ( \ud835\udc58 ) [,][ \ud835\udc51] [=] [ \ud835\udc5c] [(] [\ud835\udc5b] [)] [, and][ \ud835\udf00] [2] [\ud835\udc51] [\u2a7e] [\ud835\udc3e\ud835\udc58] [2][ log] [ \ud835\udc58] [for some sufficiently large]\n\n_constant \ud835\udc3e. There exists a polynomial-time algorithm (see Theorem 11.1) that, given observation of_\n_\ud835\udc3a, outputs an estimator_ _\ud835\udc4d_ [\u02c6] \u2208{0 _,_ 1} _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc58]_ _such that, with probability_ 1 \u2212 exp(\u2212\u03a9( _\ud835\udc58_ )) \u2212 poly1( _\ud835\udc5b_ ) _[,]_\n\n###### error\ud835\udc58 ( \ud835\udc4d, \ud835\udc4d [\u02c6] [\u25e6] ) \u2a7d exp \u2212 [\ufffd] 1 \u2212 \ud835\udc5c (1) [\ufffd] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd \ud835\udc58\n\n+ poly( _\ud835\udc58_ ) \u00b7 _\ud835\udf02_ _._\n###### \ufffd\n\n_Proof._ Let _\ud835\udc65_ [\u25e6] _\ud835\udc4e\ud835\udc4f_ [be the the ground-truth pairwise labels. Notice that][ Theorem 10.1][ provides]\na polynomial-time computable initializer _\ud835\udc4d_ [\u02c6] input with error at most _\ud835\udc5b_ /poly( _\ud835\udc58_ ) that we\n\n_\ud835\udc5b_\ncan use in step 2 of Theorem 11.1. Plugging in _\ud835\udc4d_ input = _\ud835\udc4d_ [\u02c6] input, _\ud835\udf07_ = poly( _\ud835\udc58_ ) [,] _[ \ud835\udefe]_ [=][ 0] _[.]_ [99][ and]\n\n= 1000 _\ud835\udc58_ \u22120 _._ 99 _[\ud835\udc36][\ud835\udc51][,][\ud835\udf00]_ in Theorem 11.8 \ud835\udd3c [\u02dc] such\n_\ud835\udefd_ exp _\ud835\udc58_ and rearranging terms, we can obtain\n###### \ufffd \ufffd\n\nthat\n###### \ufffd\u2225\ud835\udd3c [\u02dc] \ud835\udc65 [\u25e6] \ud835\udc4e\ud835\udc4f [\u2212] [\ud835\udc65][\ud835\udc4e\ud835\udc4f] [\u2225] 2 [2] [\u2a7d] [exp] \u2212(1 \u2212 \ud835\udc5c (1)) [0] [.] [99] [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ud835\udc5b + poly( \ud835\udc58 ) \ud835\udf02\ud835\udc5b. \ufffd \ufffd\n\n_\ud835\udefd_ = 1000 _\ud835\udc58_ exp \u22120 _._ 99 _[\ud835\udc36]_ _\ud835\udc58_ _[\ud835\udc51][,][\ud835\udf00]_\n###### \ufffd\n\n###### \ufffd\u2225\ud835\udd3c [\u02dc] \ud835\udc65 [\u25e6] \ud835\udc4e\ud835\udc4f [\u2212] [\ud835\udc65][\ud835\udc4e\ud835\udc4f] [\u2225] 2 [2] [\u2a7d] [exp] \u2212(1 \u2212 \ud835\udc5c (1)) [0] [.] [99] \ud835\udc58 [\ud835\udc36][\ud835\udc51,][\ud835\udf00] \ufffd\n\n_\ud835\udc4e,\ud835\udc4f_\n\n_\ud835\udc5b_ + poly( _\ud835\udc58_ ) _\ud835\udf02\ud835\udc5b._\n###### \ufffd\n\n_\ud835\udc58_\n\nSince the rounding introduces a constant multiplicative error, we can use the rounded\n\nsolution _\ud835\udc4d_ [\u02c6] in step 3. Repeating Theorem 11.8 with _\ud835\udc4d_ input = _\ud835\udc4d_ [\u02c6], _\ud835\udf07_ = exp \u22120 _._ 99(1 \u2212 _\ud835\udc5c_ (1)) _[\ud835\udc36]_ _\ud835\udc58_ _[\ud835\udc51][,][\ud835\udf00]_,\n###### \ufffd \ufffd\n\n, we can obtain \ud835\udd3c [\u02dc] opt such that\n###### \ufffd\n\n_[\ud835\udf12][\ud835\udc58]_ \u221a\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ [,] _[ \ud835\udefd]_ [=]\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\n_\ud835\udefe_ = 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n~~\u221a~~ _\ud835\udc36\ud835\udc51,_\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_ \u2212 1 \u2212 [10] _[\ud835\udf12][\ud835\udc58]_\n###### 10 \ud835\udf12 [exp] \ufffd \ufffd \u221a \ud835\udc36\ud835\udc51,\ud835\udf00\n\n_\ud835\udc36\ud835\udc51,\ud835\udf00_\n\n_\ud835\udc58_\n###### \ufffd\n\n###### \ufffd\u2225\ud835\udd3c [\u02dc] opt \ud835\udc65 [\u25e6] \ud835\udc4e\ud835\udc4f [\u2212] [\ud835\udc65][\ud835\udc4e\ud835\udc4f] [\u2225] 2 [2] [\u2a7d] [exp] \u2212(1 \u2212 \ud835\udc5c (1)) [\ud835\udc36] \ud835\udc58 [\ud835\udc51,][\ud835\udf00] \ufffd\n\n_\ud835\udc4e,\ud835\udc4f_\n\n_\ud835\udc5b_ + poly( _\ud835\udc58_ ) _\ud835\udf02\ud835\udc5b._\n###### \ufffd\n\n###### \ufffd\n\n_\ud835\udc58_\n\n###### Combine this with the rounding guarantees, we obtain the desired bound. \u25a1\n\n### **References**\n\n[ABARS20] Emmanuel Abbe, Enric Boix-Adser\u00e0, Peter Ralli, and Colin Sandon, _Graph_\n_powering and spectral robustness_, SIAM Journal on Mathematics of Data Science\n**2** (2020), no. 1, 132\u2013157. 3\n\n[Abb18] Emmanuel Abbe, _Community detection and stochastic block models: Recent de-_\n_velopments_, Journal of Machine Learning Research **18** (2018), no. 177, 1\u201386.\n\n1\n\n58\n\n[ABH15] Emmanuel Abbe, Afonso S Bandeira, and Georgina Hall, _Exact recovery in the_\n_stochastic block model_, IEEE Transactions on information theory **62** (2015), no. 1,\n471\u2013487. 1\n\n[AJK [+] 22] Jayadev Acharya, Ayush Jain, Gautam Kamath, Ananda Theertha Suresh, and\nHuanyu Zhang, _Robust estimation for random graphs_, Conference on Learning\nTheory, PMLR, 2022, pp. 130\u2013166. 2\n\n[AR20] Emmanuel Abbe and Peter Ralli, _An alon-boppana theorem for powered graphs_\n_and generalized ramanujan graphs_, arXiv preprint arXiv:2006.11248 (2020). 3\n\n[AS15] Emmanuel Abbe and Colin Sandon, _Community detection in general stochastic_\n_block models: Fundamental limits and efficient algorithms for recovery_, 2015 IEEE\n56th Annual Symposium on Foundations of Computer Science, IEEE, 2015,\npp. 670\u2013688. 1, 14\n\n[AS16], _Achieving the ks threshold in the general stochastic block model with linearized_\n_acyclic belief propagation_, Advances in Neural Information Processing Systems\n(D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, eds.), vol. 29,\nCurran Associates, Inc., 2016. 1\n\n[BBH [+] 12] Boaz Barak, Fernando GSL Brandao, Aram W Harrow, Jonathan Kelner, David\nSteurer, and Yuan Zhou, _Hypercontractivity, sum-of-squares proofs, and their_\n_applications_, Proceedings of the forty-fourth annual ACM symposium on\nTheory of computing, 2012, pp. 307\u2013326. 63\n\n[BBK [+] 21] Afonso S Bandeira, Jess Banks, Dmitriy Kunisky, Christopher Moore, and\nAlex Wein, _Spectral planting and the hardness of refuting cuts, colorability, and_\n_communities in random graphs_, Conference on Learning Theory, PMLR, 2021,\npp. 410\u2013473. 1, 14\n\n[BLM15] Charles Bordenave, Marc Lelarge, and Laurent Massouli\u00e9, _Non-backtracking_\n_spectrum of random graphs: community detection and non-regular ramanujan graphs_,\n2015 IEEE 56th Annual Symposium on Foundations of Computer Science,\nIEEE, 2015, pp. 1347\u20131357. 1\n\n[Bop87] Ravi B Boppana, _Eigenvalues and graph bisection: An average-case analysis_, 28th\nAnnual Symposium on Foundations of Computer Science (sfcs 1987), IEEE,\n1987, pp. 280\u2013285. 5\n\n[BS14] Boaz Barak and David Steurer, _Sum-of-squares proofs and the quest toward optimal_\n_algorithms_, arXiv preprint arXiv:1404.5236 (2014). 4, 7, 18\n\n[BS16], _Proofs, beliefs, and algorithms through the lens of sum-of-squares_, Course\nnotes: http://www. sumofsquares. org/public/index. html **1** (2016), 3. 7, 18\n\n59\n\n[CDd [+] 24] Hongjie Chen, Jingqiu Ding, Tommaso d\u2019Orsi, Yiding Hua, Chih-Hung Liu,\nand David Steurer, _Private graphon estimation via sum-of-squares_, Proceedings of\nthe 56th Annual ACM Symposium on Theory of Computing, 2024, pp. 172\u2013182.\n\n4\n\n[CDHS24] Hongjie Chen, Jingqiu Ding, Yiding Hua, and David Steurer, _Private edge_\n_density estimation for random graphs: Optimal, efficient and robust_, Advances in\nNeural Information Processing Systems **37** (2024), 90771\u201390817. 4\n\n[CDHT25] Hongjie Chen, Jingqiu Ding, Yiding Hua, and Stefan Tiegel, _Improved robust_\n_estimation for erd_ \\ _h_ { _o_ } _sr_ \\ _\u2019enyi graphs: The sparse regime and optimal breakdown_\n_point_, arXiv preprint arXiv:2503.03923 (2025). 4\n\n[CO10] Amin Coja-Oghlan, _Graph partitioning via adaptive spectral techniques_, Combinatorics, Probability and Computing **19** (2010), no. 2, 227\u2013284. 5\n\n[CRV15] Peter Chin, Anup Rao, and Van Vu, _Stochastic block model and community detection_\n_in sparse graphs: A spectral algorithm with optimal rate of recovery_, Conference on\nLearning Theory, PMLR, 2015, pp. 391\u2013423. 5\n\n[DdHS23] Jingqiu Ding, Tommaso d\u2019Orsi, Yiding Hua, and David Steurer, _Reaching kesten-_\n_stigum threshold in the stochastic block model under node corruptions_, Proceedings\nof Thirty Sixth Conference on Learning Theory (Gergely Neu and Lorenzo\nRosasco, eds.), Proceedings of Machine Learning Research, vol. 195, PMLR,\n12\u201315 Jul 2023, pp. 4044\u20134071. 4, 8, 17\n\n[DdNS22] Jingqiu Ding, Tommaso d\u2019Orsi, Rajai Nasser, and David Steurer, _Robust recovery_\n_for stochastic block models_, 2021 IEEE 62nd Annual Symposium on Foundations\nof Computer Science (FOCS), IEEE, 2022, pp. 387\u2013394. 8\n\n[DHSS25] Jingqiu Ding, Yiding Hua, Lucas Slot, and David Steurer, _Low degree conjecture_\n_implies sharp computational thresholds in stochastic block model_, arXiv preprint\narXiv:2502.15024 (2025). 1\n\n[DKMZ11] Aurelien Decelle, Florent Krzakala, Cristopher Moore, and Lenka Zdeborov\u00e1,\n_Asymptotic analysis of the stochastic block model for modular networks and its_\n_algorithmic applications_, Physical Review E **84** (2011), no. 6. 1\n\n[FC19] Yingjie Fei and Yudong Chen, _Achieving the bayes error rate in stochastic block_\n_model by sdp, robustly_, Proceedings of the Thirty-Second Conference on Learning\nTheory (Alina Beygelzimer and Daniel Hsu, eds.), Proceedings of Machine\nLearning Research, vol. 99, PMLR, 25\u201328 Jun 2019, pp. 1235\u20131269. 4\n\n[FK01] Uriel Feige and Joe Kilian, _Heuristics for semirandom graph problems_, J. Comput.\nSyst. Sci. **63** (2001), no. 4, 639\u2013671. 4\n\n60\n\n[FO05] Uriel Feige and Eran Ofek, _Spectral techniques applied to sparse random graphs_,\nRandom Structures & Algorithms **27** (2005), no. 2, 251\u2013275 (English). 65\n\n[GMZZ17] Chao Gao, Zongming Ma, Anderson Y. Zhang, and Harrison H. Zhou, _Achieving_\n_optimal misclassification proportion in stochastic block models_, Journal of Machine\nLearning Research **18** (2017), no. 60, 1\u201345. 1, 2, 3, 4\n\n[GOR [+] 21] Fabrizio Grandoni, Rafail Ostrovsky, Yuval Rabani, Leonard J. Schulman, and\nRakesh Venkat, _A refined approximation for euclidean k-means_, 2021. 29\n\n[GV14] Olivier Gu\u00e9don and Roman Vershynin, _Community detection in sparse networks_\n_via grothendieck\u2019s inequality_, Probability Theory and Related Fields **165** (2014),\n1025 \u2013 1049. 4\n\n[GV16] Olivier Gu\u00e9don and Roman Vershynin, _Community detection in sparse networks_\n_via grothendieck\u2019s inequality_, Probability Theory and Related Fields **165** (2016),\nno. 3, 1025\u20131049. 5, 8, 14\n\n[HL18] Samuel B. Hopkins and Jerry Li, _Mixture models, robustness, and sum of squares_\n_proofs_, Proceedings of the 50th Annual ACM SIGACT Symposium on Theory\nof Computing (New York, NY, USA), STOC 2018, Association for Computing\nMachinery, 2018, p. 1021\u20131034. 18\n\n[HLL83] Paul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt, _Stochastic_\n_blockmodels: First steps_, Social networks **5** (1983), no. 2, 109\u2013137. 1\n\n[Hop18] Samuel.B Hopkins, _Statistical inference and the sum of squares method_, Cornell\nUniversity, 2018. 1, 14\n\n[Hop20] Samuel B Hopkins, _Mean estimation with sub-gaussian rates in polynomial time_,\nThe Annals of Statistics **48** (2020), no. 2, 1193\u20131213. 18\n\n[HS17] Samuel B. Hopkins and David Steurer, _Efficient bayesian estimation from few_\n_samples: Community detection and related problems_, 2017 IEEE 58th Annual\nSymposium on Foundations of Computer Science (FOCS), 2017, pp. 379\u2013390. 1\n\n[HWX14] Bruce E. Hajek, Yihong Wu, and Jiaming Xu, _Achieving exact cluster recovery_\n_threshold via semidefinite programming_, IEEE Transactions on Information Theory\n**62** (2014), 2788\u20132797. 1, 4\n\n[KMM [+] 13] Florent Krzakala, Cristopher Moore, Elchanan Mossel, Joe Neeman, Allan\nSly, Lenka Zdeborov\u00e1, and Pan Zhang, _Spectral redemption in clustering sparse_\n_networks_, Proceedings of the National Academy of Sciences **110** (2013), no. 52,\n20935\u201320940. 1\n\n61\n\n[KSS18] Pravesh K. Kothari, Jacob Steinhardt, and David Steurer, _Robust moment_\n_estimation and improved clustering via sum of squares_, Proceedings of the 50th\nAnnual ACM SIGACT Symposium on Theory of Computing, Association for\nComputing Machinery, 2018. 18\n\n[LM22] Allen Liu and Ankur Moitra, _Minimax rates for robust community detection_, 2022\nIEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS),\n2022, pp. 823\u2013831. 1, 3, 4, 10, 11, 13, 15, 17, 21, 23, 26, 29, 65, 66, 71, 74\n\n[Mas14] Laurent Massouli\u00e9, _Community detection thresholds and the weak ramanujan_\n_property_, Proceedings of the forty-sixth annual ACM symposium on Theory of\ncomputing, 2014, pp. 694\u2013703. 1, 5\n\n[MNS12] Elchanan Mossel, Joe Neeman, and Allan Sly, _Stochastic block models and_\n_reconstruction_, arXiv preprint arXiv:1202.1499 (2012). 1\n\n[MNS14], _Belief propagation, robust reconstruction and optimal recovery of block_\n_models_, Proceedings of The 27th Conference on Learning Theory (Barcelona,\nSpain) (Maria Florina Balcan, Vitaly Feldman, and Csaba Szepesv\u00e1ri, eds.),\nProceedings of Machine Learning Research, vol. 35, PMLR, 13\u201315 Jun 2014,\npp. 356\u2013370. 2, 3\n\n[MNS18], _A proof of the block model threshold conjecture_, Combinatorica **38** (2018),\nno. 3, 665\u2013708. 1\n\n[MRW24] Sidhanth Mohanty, Prasad Raghavendra, and David X Wu, _Robust recovery for_\n_stochastic block models, simplified and generalized_, Proceedings of the 56th Annual\nACM Symposium on Theory of Computing, 2024, pp. 367\u2013374. 8\n\n[PS17] Aaron Potechin and David Steurer, _Exact tensor completion with sum-of-squares_,\nProceedings of the 2017 Conference on Learning Theory, 2017. 18\n\n[RSS18] Prasad Raghavendra, Tselil Schramm, and David Steurer, _High dimensional_\n_estimation via sum-of-squares proofs_, Proceedings of the International Congress\nof Mathematicians: Rio de Janeiro 2018, World Scientific, 2018, pp. 3389\u20133423.\n4, 7, 18\n\n[RW17] Prasad Raghavendra and Benjamin Weitz, _On the bit complexity of sum-of-squares_\n_proofs_, arXiv preprint arXiv:1702.05139 (2017). 35\n\n[SW25] Youngtak Sohn and Alexander S Wein, _Sharp phase transitions in estimation with_\n_low-degree polynomials_, Proceedings of the 57th Annual ACM Symposium on\nTheory of Computing, 2025, pp. 891\u2013902. 1, 14\n\n[ZZ15] Anderson Y. Zhang and Harrison H. Zhou, _Minimax rates of community detection_\n_in stochastic block models_, 2015. 1, 2\n\n62\n\n### **A Sum-of-Squares proofs**\n\nIn this section, we introduce some Sum-of-Squares (SoS) results that are used in our proofs.\n\n##### **A.1 Basic Sum-of-Squares inequalities**\n\nWe start with a Cauchy-Schwarz inequality for pseudo-distributions.\n\n**Fact A.1** (Cauchy-Schwarz for pseudo-distributions [BBH [+] 12]) **.** _Let \ud835\udc53, \ud835\udc54_ _be vector polynomials_\n_of degree at most \ud835\udc51_ _in indeterminate \ud835\udc65_ \u2208 \u211d _[\ud835\udc5b]_ _. Then, for any level_ 2 _\ud835\udc51_ _pseudo-distribution \ud835\udc37,_\n\n###### \ud835\udd3c\u02dc \ud835\udc37 \ufffd\u27e8 \ud835\udc53, \ud835\udc54 \u27e9\ufffd \u2a7d \ufffd\n\n\ud835\udd3c\u02dc _\ud835\udc37_ [\u2225 _\ud835\udc53_ \u22252] \u00b7 \ud835\udd3c\u02dc _\ud835\udc37_ [\u2225 _\ud835\udc54_ \u22252] _._\n###### \ufffd\n\nWe will also repeatedly use the following two SoS versions of Cauchy-Schwarz inequality:\n\n**Fact A.2** (Sum-of-Squares Cauchy-Schwarz I) **.** _Let \ud835\udc65, \ud835\udc66_ \u2208 \u211d _[\ud835\udc51]_ _be indeterminates. Then,_\n\n###### \ufffd\n\n_\ud835\udc66\ud835\udc56_ [2]\n###### \ufffd\ufffd\ufffd \ud835\udc56\n\n_\ud835\udc65,\ud835\udc66_ 2\n###### 4 \ufffd \ud835\udc65, \ud835\udc66 \ufffd \u2a7d\n\n_\ud835\udc65_ [2]\n_\ud835\udc56_\n###### \ufffd\ufffd \ud835\udc56\n\n_._\n\n**Fact A.3** (Sum-of-Squares Cauchy-Schwarz II) **.** _Let \ud835\udc65, \ud835\udc66_ \u2208 \u211d _[\ud835\udc51]_ _be indeterminates. Then, for any_\n_\ud835\udc36_ _>_ 0 _,_\n\n_\ud835\udc65,\ud835\udc66_\n###### 4 \ufffd \ud835\udc65, \ud835\udc66 \ufffd \u2a7d [\ud835\udc36]\n\n2 _\ud835\udc36_\n\n4\n\n_[\ud835\udc36]_ [1]\n\n2 [\u2225] _[\ud835\udc65]_ [\u2225][2][ +] 2\n\n2\n###### \ufffd\ufffd \ud835\udc66 \ufffd\ufffd,\n\n_and,_\n\n_\ud835\udc65,\ud835\udc66_\n\u2212 _[\ud835\udc36]_\n###### 4 \ufffd \ud835\udc65, \ud835\udc66 \ufffd \u2a7e\n\n2 _\ud835\udc36_\n\n2\n###### \ufffd\ufffd \ud835\udc66 \ufffd\ufffd,\n\n4\n\n_[\ud835\udc36]_\n\n2 [\u2225] _[\ud835\udc65]_ [\u2225][2][ \u2212] 2 [1]\n\nWe will use the following fact that shows how spectral certificates are captured within\nthe SoS proof system.\n\n**Fact A.4** (Spectral Certificates) **.** _For any \ud835\udc5a_ \u00d7 _\ud835\udc5a_ _matrix \ud835\udc34,_\n\n_\ud835\udc62_ 2\n###### 2 \u27e8 \ud835\udc62, \ud835\udc34\ud835\udc62 \u27e9 \u2a7d \u2225 \ud835\udc34 \u2225\u2225 \ud835\udc62 \u22252 [.]\n\nCombining these facts, we have the following lemma as a corollary:\n\n###### Lemma A.5. For any constant \ud835\udc3f \u2a7e 0, for variables \ud835\udc38 \u2208 \u211d [\ud835\udc5b] [\u00d7] [\ud835\udc5b], \ud835\udc63 \u2208 \u211d [\ud835\udc5b], \ud835\udc64 \u2208 \u211d [\ud835\udc5b], we have constant\n\n_degree SoS proof that_\n\n_\ud835\udc3f_ Id \u2212 _\ud835\udc38\ud835\udc38_ [\u22a4] = _\ud835\udc36\ud835\udc36_ [\u22a4]\n\n_\ud835\udc38,\ud835\udc36,\ud835\udc63,\ud835\udc64_ 4 \u27e8 _\ud835\udc38\ud835\udc63, \ud835\udc64_ \u27e92 \u2a7d _\ud835\udc3f_ \u2225 _\ud835\udc63_ \u22252\u2225 _\ud835\udc64_ \u22252 _._\n\n63\n\n_Proof._ We have\n\n_\ud835\udc38,\ud835\udc36,\ud835\udc63,\ud835\udc64_ 4 \u27e8 _\ud835\udc38\ud835\udc63, \ud835\udc64_ \u27e92 \u2a7d \u2225 _\ud835\udc63_ \u22252\u2225 _\ud835\udc38_ \u22a4 _\ud835\udc64_ \u22252\n\n= \u27e8 _\ud835\udc64, \ud835\udc38\ud835\udc38_ [\u22a4] _\ud835\udc64_ \u27e9\u00b7 \u2225 _\ud835\udc63_ \u2225 [2] _._\n\n###### Since \ud835\udc3f Id \u2212 \ud835\udc38\ud835\udc38 [\u22a4] = \ud835\udc36\ud835\udc36 [\u22a4], we have \u27e8 \ud835\udc64, \ud835\udc38\ud835\udc38 [\u22a4] \ud835\udc64 \u27e9 \u2a7d \ud835\udc3f \u2225 \ud835\udc64 \u2225 [2] . As a result,\n\n_\ud835\udc3f_ Id \u2212 _\ud835\udc38\ud835\udc38_ [\u22a4] = _\ud835\udc36\ud835\udc36_ [\u22a4]\n\n_\ud835\udc38,\ud835\udc36,\ud835\udc63,\ud835\udc64_ 4 \u27e8 _\ud835\udc38\ud835\udc63, \ud835\udc64_ \u27e92 \u2a7d _\ud835\udc3f_ \u2225 _\ud835\udc63_ \u22252\u2225 _\ud835\udc64_ \u22252 _._\n\n###### \u25a1\n\n##### **A.2 Sum-of-Squares certificate**\n\n**Theorem A.6.** _Let \ud835\udc65, \ud835\udc66_ \u2208 \u211d _[\ud835\udc51]_ _and \ud835\udc5d_ 1( _\ud835\udc65_ ) _, \ud835\udc5d_ 2( _\ud835\udc65_ ) _, . . ., \ud835\udc5d\ud835\udc5a_ ( _\ud835\udc65_ ) _be a set of polynomials_ \u211d _[\ud835\udc51]_ \u2192 \u211d _. If there_\n\n_exists \ud835\udc66_ [\u25e6] _such that \ud835\udc5d_ 1( _\ud835\udc65_ ) \u2a7e 0 _, \ud835\udc5d_ 2( _\ud835\udc65_ ) \u2a7e 0 _, . . ., \ud835\udc5d\ud835\udc5a_ ( _\ud835\udc65_ ) \u2a7e 0 _\u2113\ud835\udc65_ _\ud835\udc5e_ ( _\ud835\udc65_ ; _\ud835\udc66_ - ) \u2a7e 0 _, then the degree-_ ( _\u2113_ + 2)\n\n_SoS relaxation of the following program is feasible_\n\n###### \ud835\udc9c := \ud835\udc5d 1( \ud835\udc65 ) \u2a7e 0, \ud835\udc5d 2( \ud835\udc65 ) \u2a7e 0, . . ., \ud835\udc5d\ud835\udc5a ( \ud835\udc65 ) \u2a7e 0, \ud835\udc5e ( \ud835\udc65, \ud835\udc66 ) = Tr [\ufffd] \ud835\udc45\ud835\udc45 [\u22a4] Mom \ud835\udc51 ( \ud835\udc5d 1, \ud835\udc5d 2, . . ., \ud835\udc5d\ud835\udc5a ) [\ufffd\ufffd], \ufffd\n\n_where_ Mom _\ud835\udc51_ ( _\ud835\udc5d_ 1 _, . . ., \ud835\udc5d\ud835\udc5a_ ) _is a block-diagonal matrix with entries in_ \u211d[ _\ud835\udc65_ ] _and (possibly empty) blocks_\n###### \ud835\udc40\ud835\udc46 indexed by subsets \ud835\udc46 \u2286[ \ud835\udc5a ] such that for all pairs of monomials \ud835\udc65 [\ud835\udefc], \ud835\udc65 [\ud835\udefd] with deg \ud835\udc65 [\ud835\udefc], deg \ud835\udc65 [\ud835\udefd] \u2a7d\n\n1\n###### 2 [\u00b7 (] [\u2113] [\u2212] [\ufffd] \ud835\udc56 \u2208 \ud835\udc46 [deg] [ \ud835\udc5d][\ud835\udc56] [)] [,]\n\n_\ud835\udc40\ud835\udc46_ ( _\ud835\udefc, \ud835\udefd_ ) :=\n###### \ufffd\ufffd\n\n_We also have the following SoS proof_\n\n      - _\ud835\udc65_ _[\ud835\udefc]_      - _\ud835\udc65_ _[\ud835\udefd]_ _._\n###### \ud835\udc56 \u2208 \ud835\udc46 [\ud835\udc5d][\ud835\udc56] \ufffd\n\n_\ud835\udc65,\ud835\udc66,\ud835\udc45_\n\n\ud835\udc9c\n_\u2113_ +2\n\n_\ud835\udc5e_ ( _\ud835\udc65, \ud835\udc66_ ) \u2a7e 0 _._\n\n_Proof._ Let _\ud835\udc45_ [\u25e6] \u2208 \u211d _[\ud835\udc51][\u2113]_ [\u00d7] _[\ud835\udc51][\u2113]_ be the matrix corresponding to a degree- _\u2113_ SoS proof of _\ud835\udc5d_ 1( _\ud835\udc65_ ) \u2a7e\n0 _, \ud835\udc5d_ 2( _\ud835\udc65_ ) \u2a7e 0 _, . . ., \ud835\udc5d\ud835\udc5a_ ( _\ud835\udc65_ ) \u2a7e 0 _\u2113\ud835\udc65_ _\ud835\udc5e_ ( _\ud835\udc65_ ; _\ud835\udc66_ - ) \u2a7e 0, i.e.\n\n###### \ud835\udc5e ( \ud835\udc65 ; \ud835\udc66 [\u25e6] ) = Tr [\ufffd] \ud835\udc45 [\u25e6] ( \ud835\udc45 [\u25e6] ) [\u22a4] Mom \ud835\udc51 ( \ud835\udc5d 1, \ud835\udc5d 2, . . ., \ud835\udc5d\ud835\udc5a ) [\ufffd],\n\nNow, the degree-( _\u2113_ + 2) SoS relaxation of \ud835\udc9c is feasible with _\ud835\udc45_ = _\ud835\udc45_ [\u25e6] and _\ud835\udc66_ = _\ud835\udc66_ [\u25e6] . The SoS\nproof follows by\n\n_\ud835\udc65,\ud835\udc66,\ud835\udc45_\n###### \ud835\udc9c \u2113 +2 \ud835\udc5e ( \ud835\udc65, \ud835\udc66 ) = Tr\ufffd \ud835\udc45\ud835\udc45 [\u22a4] Mom \ud835\udc51 ( \ud835\udc5d 1, \ud835\udc5d 2, . . ., \ud835\udc5d\ud835\udc5a ) [\ufffd] \u2a7e 0 .\n\n64\n\n###### \u25a1\n\n##### **A.3 Sum-of-Squares subset sum**\n\nNext we give an SoS proof for a formulation related to the minimum subset sum.\n\n###### Lemma A.7. For any vector \ud835\udc63 \u2208 \u211d [\ud835\udc5b] such that for any subset \ud835\udc46 \u2286[ \ud835\udc5b ] we have [\ufffd] \ud835\udc56 \u2208 \ud835\udc46 [\ud835\udc63][\ud835\udc56] [\u2a7e] [\ud835\udefe] [(|] [\ud835\udc46] [| \u2212] [\ud835\udefd] [)] [,]\n\n_there is a SoS proof that_\n\n_\ud835\udc67_\n###### { \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67 } 2 \u27e8 \ud835\udc67, \ud835\udc63 \u27e9 \u2a7e \ud835\udefe (\u2225 \ud835\udc67 \u22251 \u2212 \ud835\udefd ) .\n\n_Proof._ We note that lemma is equivalent of showing\n\n_\ud835\udc67_\n###### { \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67 } 2 \u27e8 \ud835\udc67, \ud835\udc63 \u2212 \ud835\udefe 1 \u27e9 \u2a7e \u2212 \ud835\udefe \u00b7 \ud835\udefd . If \ud835\udc63\ud835\udc56 \u2a7d \ud835\udefe for all \ud835\udc56, then\n\n_\ud835\udc67_\n###### { \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67 } 2 \u27e8 \ud835\udc67, \ud835\udc63 \u2212 \ud835\udefe 1 \u27e9 \u2a7e \u27e8 1, \ud835\udc63 \u2212 \ud835\udefe 1 \u27e9 \u2a7e \u2212 \ud835\udefe \u00b7 \ud835\udefd .\n\nElse, w.l.o.g assume that _\ud835\udc63_ is in non-decreasing order and _\ud835\udc63\ud835\udc58_ is the last element that is at\n###### most \ud835\udefe, i.e. \ud835\udc63 1 \u2a7d \ud835\udc63 2 \u2a7d \u00b7 \u00b7 \u00b7 \u2a7d \ud835\udc63\ud835\udc58 \u2a7d \ud835\udefe< \ud835\udc63\ud835\udc58 +1 \u2a7d \ud835\udc63\ud835\udc5b . Now, we have\n\n_\ud835\udc67_\n\n{ _\ud835\udc67_ \u2299 _\ud835\udc67_ = _\ud835\udc67_ } 2 \u27e8 _\ud835\udc67, \ud835\udc63_ \u2212 _\ud835\udefe_ **1** \u27e9 =\n\n###### \u2a7e\n\n_\ud835\udc58_\n\n( _\ud835\udc63\ud835\udc56_ \u2212 _\ud835\udefe_ ) _\ud835\udc67\ud835\udc56_ +\n###### \ufffd\n\n_\ud835\udc56_ =1\n\n_\ud835\udc58_\n\n( _\ud835\udc63\ud835\udc56_ \u2212 _\ud835\udefe_ )\n###### \ufffd\n\n_\ud835\udc56_ =1\n\n_\ud835\udc5b_\n\n( _\ud835\udc63\ud835\udc56_ \u2212 _\ud835\udefe_ ) _\ud835\udc67\ud835\udc56_\n###### \ufffd\n\n_\ud835\udc56_ = _\ud835\udc58_ +1\n\n###### \u2a7e \u2212 \ud835\udefe \u00b7 \ud835\udefd .\n\n_\ud835\udc67_\n###### where the second last inequality is because { \ud835\udc67 \u2299 \ud835\udc67 = \ud835\udc67 } 2 0 \u2a7d \ud835\udc67 \u2a7d 1 . \u25a1\n\n### **B Spectral bounds**\n\nA well-known challenge in analyzing sparse SBMs is that high-degree nodes can inflate\nspectral bounds by an additional log _\ud835\udc5b_ factor. To establish identifiability in Section 8, we\nleverage a classical result from random matrix theory, which demonstrates that pruning\nnodes with degrees above a certain threshold suffices to achieve the desired spectral\nbounds.\n\n**Theorem B.1** (Originally proved in [FO05], restatement of theorem 6.7 in [LM22]) **.** _Suppose_\n_\ud835\udc40_ _is a random symmetric matrix with zero on the diagonal whose entries above the diagonal are_\n_independent with the following distribution_\n\n_\ud835\udc40_ =\n_\ud835\udc56\ud835\udc57_\n\n1 \u2212 _\ud835\udc5d\ud835\udc56\ud835\udc57_ _w.p. \ud835\udc5d\ud835\udc56\ud835\udc57_\n###### \ufffd\u2212 \ud835\udc5d\ud835\udc56\ud835\udc57 w.p. 1 \u2212 \ud835\udc5d\ud835\udc56\ud835\udc57\n\n###### Let \ud835\udf0e be a quantity such that \ud835\udc5d\ud835\udc56\ud835\udc57 \u2a7d \ud835\udf0e [2] and \ud835\udc40 1 be the matrix obtained from M by zeroing out all the\n\n_rows and columns having more than_ 20 _\ud835\udf0e_ [2] _\ud835\udc5b_ _positive entries. Then with probability_ 1 \u2212 1/ _\ud835\udc5b_ [2] _, we_\n###### have \u2225 \ud835\udc40 1\u2225 \u2a7d \ud835\udf12\ud835\udf0e [\u221a] \ud835\udc5b for some universal constant \ud835\udf12.\n\n65\n\nAs a consequence of the above, we admit the following spectral bound for the adjacency\nmatrix of a pruned SBM.\n\n**Corollary B.2** (Corollary 6.8 in [LM22]) **.** _Let \ud835\udc3a_ [\u25e6] _be a graph sampled from the \ud835\udc58-stochastic block_\n_model_ SBM _\ud835\udc5b_ ( _\ud835\udc51, \ud835\udf00, \ud835\udc58_ ) _and \ud835\udc4d_ [\u25e6] _be the true community membership matrix. Then, with probability at_\n_least_ 1 \u2212 [2] _[, there exists a subset][ \ud835\udc46]_ _[\ud835\udc5b]_ 1 \u2212 \u22122 _\ud835\udc36_ _\ud835\udc5b_ _such that_\n\n###### \ud835\udc5b [2][2] [, there exists a subset][ \ud835\udc46] [\u2286[] [\ud835\udc5b] []] [ of size at least] [ \ufffd] 1 \u2212 exp [\ufffd] \u22122 \ud835\udc36\ud835\udc51,\ud835\udf00 \ufffd\ufffd \ud835\udc5b such that \ud835\udc3a [\u25e6] \u2212 [\ud835\udc51] \u2299 1 \ud835\udc46 1 [\u22a4] \ud835\udc46 \u2a7d \ud835\udf12 \u221a \ud835\udc51,\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_ _[\ud835\udc4b]_ [\u25e6]\n###### \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\n\n\u2212 _[\ud835\udc51]_\n_\ud835\udc3a_ [\u25e6]\n\n_\ud835\udc5b_\n###### \ufffd\n\n_[\ud835\udc51]_\n\n\u2299 **1** _\ud835\udc46_ **1** [\u22a4] _\ud835\udc46_\n_\ud835\udc5b_ _[\ud835\udc4b]_ [\u25e6]\n###### \ufffd\n\n###### \u2a7d \ud835\udf12 \u221a \ufffd\ufffd\ufffd\ufffd\n\nop\n\n_[\ud835\udc51]_\n\n_\ud835\udc5b_ _[\ud835\udc3d]_ [\u2212] _[\ud835\udf00]_ _\ud835\udc5b_ _[\ud835\udc51]_\n\n_\ud835\udc51,_\n\n_where \ud835\udf12_ _is a universal constant and \ud835\udc4b_ [\u25e6] = _\ud835\udc4d_ [\u25e6] ( _\ud835\udc4d_ [\u25e6] ) [\u22a4] \u2212 [1] _\ud835\udc58_ _[\ud835\udc3d]_ _[is the signal part of][ \ud835\udc3a]_ [\u25e6] _[.]_\n\n### **C Statistical properties of stochastic block model**\n\n##### **C.1 Level-wise SBM statistics.**\n\nLet us consider a level _\ud835\udc56_ \u2208{1 _,_ 2 _, . . .,_ \u230alog2 _\ud835\udc58_ \u230b} in the recursive bisection as described in\nSection 10. We define the parameters\n\n###### \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56], \ud835\udc5b\ud835\udc56 \ufffd 2 \ud835\udefd\ud835\udc56\ud835\udc5b, \ud835\udc58\ud835\udc56 \ufffd \ud835\udefd\ud835\udc56 \ud835\udc58,\n\nso that one side of the level- _\ud835\udc56_ bisection has _\ud835\udc5b\ud835\udc56_ /2 vertices and contains _\ud835\udc58\ud835\udc56_ communities. We\n###### let \ud835\udefc\ud835\udc56 \ufffd 1/ \ud835\udc58 denote the mass of a single ground-truth community and define the mixing\n\nparameter\n###### \ud835\udefe\ud835\udc56 \ufffd \ud835\udefc\ud835\udc56 / \ud835\udefd\ud835\udc56 \u2208[0, 1],\n\nas the fraction of the side occupied by the community of a fixed vertex. Using _\ud835\udefe\ud835\udc56_, we\nintroduce the _geometrically weighted_ connection probabilities at level _\ud835\udc56_, so that\n\n###### \ufffd \ufffd \ud835\udc4e\ud835\udc56 \ufffd \ud835\udc4e [\ud835\udefe][\ud835\udc56] \ud835\udc4f [1][\u2212] [\ud835\udefe][\ud835\udc56], \ud835\udc4f\ud835\udc56 \ufffd \ud835\udc4f.\n\nThis geometric weighting reflects that a random neighbor on the same side belongs to the\nrelevant community with mass _\ud835\udefe\ud835\udc56_ and to an irrelevant community with mass 1 \u2212 _\ud835\udefe\ud835\udc56_ . A\nsimple uniform bound on the mixed probabilities will be used repeatedly through the\n\nsection.\n\n###### Lemma C.1. Fix \ud835\udc58 \u2a7e 2 and 0 < \ud835\udf00< 1 . Then, for every level \ud835\udc56, \ufffd \ufffd \ud835\udc4e\ud835\udc56 + [\ufffd] \ud835\udc4f\ud835\udc56 \u2a7d \u221a \ud835\udc4e + \ud835\udc4f = \ufffd \ud835\udc51 [\ufffd] 2 + \ud835\udf00 (1 \u2212 [2]\n\n###### \ufffd \ud835\udc4e\ud835\udc56 + [\ufffd] \ud835\udc4f\ud835\udc56 \u2a7d \u221a\n\n_\ud835\udc4e_ + _\ud835\udc4f_ =\n\n###### ~~\ufffd~~\n\n###### \ud835\udc51 [\ufffd] 2 + \ud835\udf00 (1 \u2212 [2]\n\n\u221a\n###### \ud835\udc58 [)][\ufffd] [\u2a7d]\n\n3 _\ud835\udc51._ (C.1)\n\n###### Proof. Since \ud835\udc4e \u2a7e \ud835\udc4f and \ud835\udefe\ud835\udc56 \u2208[0, 1], we have \ud835\udc4f [1][\u2212] [\ud835\udefe][\ud835\udc56] \u2a7d \ud835\udc4e [1][\u2212] [\ud835\udefe][\ud835\udc56] and hence \ufffd \ud835\udc4e\ud835\udc56 = \ud835\udc4e [\ud835\udefe][\ud835\udc56] \ud835\udc4f [1][\u2212] [\ud835\udefe][\ud835\udc56] \u2a7d \ud835\udc4e [\ud835\udefe][\ud835\udc56] \ud835\udc4e [1][\u2212] [\ud835\udefe][\ud835\udc56] = \ud835\udc4e ; also [\ufffd] \ud835\udc4f\ud835\udc56 = \ud835\udc4f . Therefore \ufffd \ud835\udc4e\ud835\udc56 + [\ufffd] \ud835\udc4f\ud835\udc56 \u2a7d \ud835\udc4e + \ud835\udc4f, which implies the first inequality in\n\n(C.1). A direct computation gives\n\n###### \ud835\udc4e + \ud835\udc4f = 1 + [\ufffd] 1 \u2212 [1] \ufffd \ud835\udc58\n\n_\ud835\udc58_\n\n_\ud835\udf00_ + 1 \u2212 _[\ud835\udf00]_\n###### \ufffd\n_\ud835\udc58_ _\ud835\udc58_\n\n###### \ud835\udc51 = [\ufffd] 2 + \ud835\udf00 (1 \u2212 [2] \ud835\udc51 \u2a7d (2 + \ud835\udf00 ) \ud835\udc51 \u2a7d 3 \ud835\udc51. \ufffd \ud835\udc58 [)][\ufffd]\n\n66\n\n###### \u25a1\n\nTo encode the same-side vs. opposite-side separation in a form amenable to multiplicative\nbounds used throughout the section we consider the per-edge log-odds ratio. For _\ud835\udc5d, \ud835\udc5e_ \u2208(0 _,_ 1)\n\nset\n\n###### \ufffd \ufffd \ud835\udc45 ( \ud835\udc5d, \ud835\udc5e ) \ufffd [\ud835\udc5d] [(][1][ \u2212] [\ud835\udc5e] [)] \ud835\udc45\ud835\udc56 \ufffd \ud835\udc45 \ud835\udc4e\ud835\udc56 / \ud835\udc5b, \ud835\udc4f [\ufffd] \ud835\udc56 / \ud835\udc5b . \ud835\udc5e (1 \u2212 \ud835\udc5d ) [,] \ufffd \ufffd The following lemma provides a useful lower bound on log \ud835\udc45 [\ufffd] \ud835\udc56 . Lemma C.2. Fix \ud835\udc58 \u2a7e 2 and \ud835\udf00 \u2208(0, 1), and let \ud835\udc51 = \ud835\udc5c ( \ud835\udc5b ) . Then, for every level \ud835\udc56, \ud835\udefe\ud835\udc56 \ud835\udf00 \u2a7d log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7d \ud835\udefe\ud835\udc56 \ud835\udf00 log 3 + \ud835\udc5c (1), (C.2)\n\n2\n\n_where \ud835\udc5c_ (1) = _\ud835\udc5c\ud835\udc5b_ (1) _is uniform in \ud835\udc56._\n\n_Proof._ By definition,\n\n###### [\ufffd] \ufffd [\ud835\udc4e][\ud835\udc56] + log [1][ \u2212] \ufffd [\ufffd] [\ud835\udc4f][\ud835\udc56] [/] [\ud835\udc5b]\n\n_\ud835\udc4f\ud835\udc56_ 1 \u2212 _\ud835\udc4e\ud835\udc56_ / _\ud835\udc5b_\n\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 = log [\ufffd] \ufffd [\ud835\udc4e][\ud835\udc56]\n\n###### \ufffd\n\n1 \u2212 _\ud835\udc4e\ud835\udc56_ / _\ud835\udc5b_ _[.]_\n\n###### Lower bound. Since \ufffd \ud835\udc4e\ud835\udc56 / [\ufffd] \ud835\udc4f\ud835\udc56 = ( \ud835\udc4e / \ud835\udc4f ) [\ud835\udefe][\ud835\udc56] and \ufffd \ud835\udc4e\ud835\udc56 \u2a7e [\ufffd] \ud835\udc4f\ud835\udc56, log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7e \ud835\udefe\ud835\udc56 log [\ud835\udc4e]\n\n_\ud835\udc4f_ _[.]_\n\nWith _\ud835\udc4e_ = (1 + (1 \u2212 [1]\n\n_[\ud835\udf00]_\n\n_\ud835\udc58_ [)] _[\ud835\udc51]_ [,]\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_ [)] _[\ud835\udc51]_ [,] _[ \ud835\udc4f]_ [=][ (][1][ \u2212] _[\ud835\udf00]_ _\ud835\udc58_\n\n_[\ud835\udc4e]_\nlog\n\n###### [1] \ud835\udc58 [)] [\ud835\udf00] [\ufffd] \u2212 log [\ufffd] 1 \u2212 [\ud835\udf00] \ud835\udc58\n\n###### [\ud835\udf00] \ud835\udc58 \ufffd \u2a7e (1 \u2212 1 \ud835\udc58\n\n_\ud835\udc4f_ [=][ log][\ufffd] 1 + (1 \u2212 [1] _\ud835\udc58_\n\n[1] _[\ud835\udf00]_\n\n_\ud835\udc58_ [)][2] _[\ud835\udf00]_ [2][ +] _\ud835\udc58_\n\n_[\ud835\udf00]_\n###### \ud835\udc58 [\u2a7e] [\ud835\udf00] [\u2212] [\ud835\udf00] 2 [2]\n\n###### 2 [\u2a7e] 2 [\ud835\udf00]\n\n2 _[,]_\n\n[1]\n\n2 [(][1][ \u2212] [1] _\ud835\udc58_\n\n1\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_ [\u2212] 2 [1]\n\n###### hence log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7e \ud835\udefe\ud835\udc56 \ud835\udf00 /2. Upper bound. Using 1 \u2212 [\ufffd] \ud835\udc4f\ud835\udc56 / \ud835\udc5b \u2a7d 1 and \u2212 log(1 \u2212 \ud835\udc65 ) \u2a7d \ud835\udc65 /(1 \u2212 \ud835\udc65 ) for \ud835\udc65 \u2208(0, 1),\n\n###### log [1][ \u2212] \ufffd [\ufffd] [\ud835\udc4f][\ud835\udc56] [/] [\ud835\udc5b]\n\n_\ud835\udc5b_\n\n###### [1][ \u2212] \ufffd [\ud835\udc4f][\ud835\udc56] [/] [\ud835\udc5b] 1 \u2212 [\ufffd] [\ud835\udc4e][\ud835\udc56] 1 \u2212 \ud835\udc4e\ud835\udc56 / \ud835\udc5b [\u2a7d] [\u2212] [log] \ufffd \ud835\udc5b\n\n###### \ufffd\n\n_\ud835\udc4e\ud835\udc56_ _\ud835\udc4e_\n###### \u2a7d \ufffd \u2a7d \ufffd \ud835\udc5b \u2212 \ud835\udc4e\ud835\udc56 \ud835\udc5b \u2212 \ud835\udc4e [,]\n\nso\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7d \ud835\udefe\ud835\udc56 log \ud835\udc4f [\ud835\udc4e] [+] \ud835\udc5b \u2212 \ud835\udc4e \ud835\udc4e [.]\n\n###### Moreover, for \ud835\udc58 \u2a7e 2,\n\nWe, thus, get\n\n_[\ud835\udc4e]_ 1 + (1 \u2212 [1] _\ud835\udc58_\n\n_\ud835\udc4f_ [=][ log] 1 \u2212 _[\ud835\udf00]_\n\n###### 1 \u2212 \ud835\udf00 /2 [\u2a7d] [\ud835\udf00] [log 3] [ .]\n\n_[\ud835\udc4e]_\nlog\n\n1 \u2212 _[\ud835\udf00]_\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_\n###### \u2a7d log [1][ +] [ \ud835\udf00] [/][2]\n\n_[\ud835\udf00]_ _\ud835\udc58_ 1 \u2212 _\ud835\udf00_ /2\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_\n\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7d \ud835\udefe\ud835\udc56 \ud835\udf00 log 3 + \ud835\udc5b \u2212 \ud835\udc4e \ud835\udc4e [.]\n\nSince _\ud835\udc4e_ = \u0398( _\ud835\udc51_ ) and _\ud835\udc51_ = _\ud835\udc5c_ ( _\ud835\udc5b_ ), we have _\ud835\udc4e_ /( _\ud835\udc5b_ \u2212 _\ud835\udc4e_ ) = _\ud835\udc5c_ (1) uniformly in _\ud835\udc56_, yielding the desired\n###### upper bound. \u25a1\n\n67\n\n##### **C.2 Concentration inequalities**\n\nWe now prove Theorem C.5, a bound on the success probability of majority voting for the\nheld-out vertex. Let us start with a short convexity lemma.\n\n###### Lemma C.3. Let \ud835\udc4e, \ud835\udc4f, \ud835\udc5b > 0 and \ud835\udefe \u2208(0, 1] . Assume \ud835\udc4e \u2a7d \ud835\udc5b and \ud835\udc4f \u2a7d \ud835\udc5b. Define \ud835\udc53 : [0, 1] \u2192 \u211d by\n\n###### \ud835\udc53 ( \ud835\udc65 ) = \ud835\udc65 \u2212 [\ufffd] \ud835\udc65 + [\ud835\udc5b]\n\n_[\ud835\udc5b]_\n\n_\ud835\udc4f_ [\u2212] [1][\ufffd] [1][\u2212] _[\ud835\udefe]_ [+][ \ufffd] _[\ud835\udc5b]_ _\ud835\udc4e_\n\n_[\ud835\udc5b]_ _\ud835\udc65_ + _[\ud835\udc5b]_\n###### \ud835\udc4e [\u2212] [1][\ufffd] [\ud835\udefe] [\ufffd] \ud835\udc4f\n\n###### [\ud835\udc5b] \ufffd \ud835\udefe \ufffd \ud835\udc5b\n\n_\ud835\udc4e_ _\ud835\udc4f_\n\n1\u2212 _\ud835\udefe_ \u2212 1 _._\n###### \ufffd\n_\ud835\udc4f_\n\n_Then \ud835\udc53_ ( _\ud835\udc65_ ) \u2a7e 0 _for all \ud835\udc65_ \u2208[0 _,_ 1] _._\n\n_Proof of Lemma C.3._ If _\ud835\udefe_ = 1 then _\ud835\udc53_ ( _\ud835\udc65_ ) \u2261 0, thus we restrict attention to 0 _< \ud835\udefe<_ 1. We\ncertify nonnegativity by showing that _\ud835\udc53_ is convex on [0 _,_ 1] and minimized at _\ud835\udc65_ = 1.\n\nLet _\ud835\udc62_ ( _\ud835\udc65_ ) = _\ud835\udc65_ + _[\ud835\udc5b]_\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udc4e_ [\u2212] [1 and] _[ \ud835\udc63]_ [(] _[\ud835\udc65]_ [)][ =] _[ \ud835\udc65]_ [+] _\ud835\udc4f_\n\n_[\ud835\udc5b]_\n\n_\ud835\udc4f_ [\u2212] [1. A direct differentiation gives]\n\n_\ud835\udc53_ [\u2032] ( _\ud835\udc65_ ) = 1 \u2212 _\ud835\udefe_ _\ud835\udc62_ ( _\ud835\udc65_ ) _[\ud835\udefe]_ [\u2212][1] _\ud835\udc63_ ( _\ud835\udc65_ ) [1][\u2212] _[\ud835\udefe]_ \u2212(1 \u2212 _\ud835\udefe_ ) _\ud835\udc62_ ( _\ud835\udc65_ ) _[\ud835\udefe]_ _\ud835\udc63_ ( _\ud835\udc65_ ) [\u2212] _[\ud835\udefe]_ _._ (C.3)\n\nEvaluating (C.3) at _\ud835\udc65_ = 1 (so _\ud835\udc62_ (1) = _[\ud835\udc5b]_ _\ud835\udc4e_\n\n_[\ud835\udc5b]_ _[\ud835\udc5b]_\n\n_\ud835\udc4e_ [,] _[ \ud835\udc63]_ [(][1][)][ =] _\ud835\udc4f_\n\n_[\ud835\udc5b]_\n\n_\ud835\udc4f_ [) yields]\n\n1\u2212 _\ud835\udefe_ _\ud835\udc4f_\n\u2212(1 \u2212 _\ud835\udefe_ )\n###### \ufffd \ud835\udc4e \ufffd\n\n_\ud835\udefe_\n###### \u2a7d 0, \ufffd\n\n_\ud835\udc4e_\n_\ud835\udc53_ [\u2032] (1) = 1 \u2212 _\ud835\udefe_\n###### \ufffd \ud835\udc4f\n\n_\ud835\udc4e_\n_\ud835\udc53_ [\u2032] (1) = 1 \u2212 _\ud835\udefe_\n###### \ufffd \ud835\udc4f\n\nwhere we used the weighted AM-GM inequality\n\n_\ud835\udc4e_\n###### \ud835\udefe\ud835\udc4e + (1 \u2212 \ud835\udefe ) \ud835\udc4f \u2a7e \ud835\udc4e [\ud835\udefe] \ud835\udc4f [1][\u2212] [\ud835\udefe] \u21d0\u21d2 \ud835\udefe \ufffd \ud835\udc4f\n\nDifferentiating (C.3) once more and factoring,\n\n1\u2212 _\ud835\udefe_ _\ud835\udc4f_\n+ (1 \u2212 _\ud835\udefe_ )\n###### \ufffd \ud835\udc4e \ufffd\n\n_\ud835\udefe_\n###### \u2a7e 1 . \ufffd\n\n_\ud835\udc53_ [\u2032\u2032] ( _\ud835\udc65_ ) = _\ud835\udefe_ (1 \u2212 _\ud835\udefe_ ) _\ud835\udc62_ ( _\ud835\udc65_ ) _[\ud835\udefe]_ [\u2212][2] _\ud835\udc63_ ( _\ud835\udc65_ ) [1][\u2212] _[\ud835\udefe]_ \u2212 2 _\ud835\udefe_ (1 \u2212 _\ud835\udefe_ ) _\ud835\udc62_ ( _\ud835\udc65_ ) _[\ud835\udefe]_ [\u2212][1] _\ud835\udc63_ ( _\ud835\udc65_ ) [\u2212] _[\ud835\udefe]_ + _\ud835\udefe_ (1 \u2212 _\ud835\udefe_ ) _\ud835\udc62_ ( _\ud835\udc65_ ) _[\ud835\udefe]_ _\ud835\udc63_ ( _\ud835\udc65_ ) [\u2212] _[\ud835\udefe]_ [\u2212][1]\n###### = \ud835\udefe (1 \u2212 \ud835\udefe ) \ud835\udc62 ( \ud835\udc65 ) [\ud835\udefe] [\u2212][2] \ud835\udc63 ( \ud835\udc65 ) [\u2212] [\ud835\udefe] [\u2212][1][ \ufffd] \ud835\udc63 ( \ud835\udc65 ) \u2212 \ud835\udc62 ( \ud835\udc65 ) [\ufffd] [2] \u2a7e 0 .\n\nHence _\ud835\udc53_ is convex on [0 _,_ 1]. In particular, _\ud835\udc53_ [\u2032] is nondecreasing on the interval. Since _\ud835\udc53_ [\u2032] (1) \u2a7d 0,\nwe have _\ud835\udc53_ [\u2032] ( _\ud835\udc65_ ) \u2a7d 0 for all _\ud835\udc65_ \u2208[0 _,_ 1], i.e., _\ud835\udc53_ is decreasing on [0 _,_ 1]. Finally,\n\n###### \ufffd \ud835\udefe \ufffd \ud835\udc5b\ud835\udc4f\n\n1\u2212 _\ud835\udefe_\n\u2212 1 = 0 _,_\n###### \ufffd\n\n_\ud835\udc5b_\n_\ud835\udc53_ (1) = 1 \u2212\n###### \ufffd \ud835\udc4e\n\n###### \ufffd \ud835\udefe \ufffd \ud835\udc5b\ud835\udc4f\n\n###### \ufffd \ud835\udefe \ufffd \ud835\udc5b\ud835\udc4f\n\n1\u2212 _\ud835\udefe_ _\ud835\udc5b_\n+\n###### \ufffd \ufffd \ud835\udc4e\n\n###### so \ud835\udc53 ( \ud835\udc65 ) \u2a7e \ud835\udc53 (1) = 0 for every \ud835\udc65 \u2208[0, 1], as claimed. \u25a1 Theorem C.4. Assume \ud835\udc4e \u2a7d \ud835\udc5b and \ud835\udc4f \u2a7d \ud835\udc5b. Fix parameters \ud835\udefd \u2208(0, 1] and \ud835\udefc \u2208(0, \ud835\udefd ] . Consider the\n\n_distribution_\n\n###### \ud835\udc9f = Binom( \ud835\udefc\ud835\udc5b, \ud835\udc4e / \ud835\udc5b ) + Binom [\ufffd] ( \ud835\udefd \u2212 \ud835\udefc ) \ud835\udc5b, \ud835\udc4f / \ud835\udc5b [\ufffd] \u2212 Binom( \ud835\udefd\ud835\udc5b, \ud835\udc4f / \ud835\udc5b ),\n\n68\n\n###### where the three binomials are independent. Let \ud835\udefe \ufffd \ud835\udefc / \ud835\udefd and define\n\n###### \ufffd\n\n\u2212\n###### \ud835\udc4e \ufffd\n\n_\ud835\udc5e_ (1 \u2212 _\ud835\udc5d_ ) _[.]_\n\n###### \ufffd \ufffd \ufffd \ud835\udc4e \ufffd \ud835\udc4e [\ud835\udefe] \ud835\udc4f [1][\u2212] [\ud835\udefe], \ud835\udc4f \ufffd \ud835\udc4f, \ud835\udc36 \ufffd [\ufffd][\u221a]\n\n###### \ufffd \ud835\udc4f [\ufffd] [2], \ud835\udc45 ( \ud835\udc5d, \ud835\udc5e ) \ufffd [\ud835\udc5d] [(][1][ \u2212] [\ud835\udc5e] [)]\n\n_Then for every \ud835\udf03_ \u2208 \u211d _,_\n###### \ud835\udc7f \u2119\u223c\ud835\udc9f [[] [ \ud835\udc7f] [\u2a7d] [\ud835\udf03] []][ \u2a7d] [exp] \ufffd\u2212 \ud835\udefd \ud835\udc36 [\ufffd] + [\ud835\udf03] 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [ \ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd .\n\n_Proof of Theorem C.4._ Let _\ud835\udc61_ _>_ 0 to be fixed later. By Markov\u2019s inequality,\n\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] = \u2119 [\ufffd] \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udc7f] \u2a7e \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udf03] [\ufffd] \u2a7d \ud835\udd3c[ \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udc7f] ] \ud835\udc52 [\ud835\udc61][\ud835\udf03] .\n\nSince the three binomials are independent and \ud835\udd3c[ _\ud835\udc52_ _[\ud835\udc60]_ [Binom][(] _[\ud835\udc5a,\ud835\udc5d]_ [)] ] = ( _\ud835\udc5d\ud835\udc52_ _[\ud835\udc60]_ + 1 \u2212 _\ud835\udc5d_ ) _[\ud835\udc5a]_, we have\n\n###### \ud835\udd3c[ \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udc7f] ] = [\ufffd] \ud835\udc4e / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4e / \ud835\udc5b [\ufffd] [\ud835\udefc][\ud835\udc5b] [\ufffd] \ud835\udc4f / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4f / \ud835\udc5b [\ufffd] [(] [\ud835\udefd] [\u2212] [\ud835\udefc] [)] [\ud835\udc5b] \u00b7 [\ufffd] \ud835\udc4f / \ud835\udc5b\ud835\udc52 [\ud835\udc61] + 1 \u2212 \ud835\udc4f / \ud835\udc5b [\ufffd] [\ud835\udefd][\ud835\udc5b]\n\n###### = \ud835\udc4e / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4e / \ud835\udc5b [\ufffd] [\ud835\udefe] [\ufffd] \ud835\udc4f / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4f / \ud835\udc5b [\ufffd] [1][\u2212] [\ud835\udefe] \ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\n\napply Lemma C.3\n\n###### \u00b7 [\ufffd] \ud835\udc4f / \ud835\udc5b\ud835\udc52 [\ud835\udc61] + 1 \u2212 \ud835\udc4f / \ud835\udc5b [\ufffd\ufffd] [\ud835\udefd][\ud835\udc5b],\n\nwhere _\ud835\udefe_ = _\ud835\udefc_ / _\ud835\udefd_ \u2208[0 _,_ 1]. Applying Lemma C.3 with _\ud835\udc65_ = _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ \u2208(0 _,_ 1] gives\n\n###### \ufffd \ufffd \ufffd \ud835\udc4e / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4e / \ud835\udc5b [\ufffd] [\ud835\udefe] [\ufffd] \ud835\udc4f / \ud835\udc5b\ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4f / \ud835\udc5b [\ufffd] [1][\u2212] [\ud835\udefe] \u2a7d ( \ud835\udc4e / \ud835\udc5b ) \ud835\udc52 [\u2212] [\ud835\udc61] + 1 \u2212 \ud835\udc4e / \ud835\udc5b, with \ufffd \ud835\udc4e = \ud835\udc4e [\ud835\udefe] \ud835\udc4f [1][\u2212] [\ud835\udefe] and [\ufffd] \ud835\udc4f = \ud835\udc4f . Hence\n\n_\ud835\udc4e_\n\ud835\udd3c[ _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udc7f]_ ] \u2a7d\n###### \ufffd\ufffd\ufffd \ud835\udc5b\n\n###### [\ufffd] [\ud835\udc4e] \ud835\udc4f \ufffd\ufffd [\ufffd]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n\n_\ud835\udc4e_\n###### \ud835\udc5b [\ud835\udc52] [\u2212] [\ud835\udc61] [+][ 1][ \u2212] [\ufffd] \ud835\udc5b [\ud835\udc4e]\n\n###### \ufffd\n\n_\ud835\udc4f_ _\ud835\udc4f_\n\n_._\n###### [\ufffd] \ufffd [\ufffd] [\ud835\udefd][\ud835\udc5b]\n_\ud835\udc5b_ _[\ud835\udc52]_ _[\ud835\udc61]_ [+][ 1][ \u2212] _\ud835\udc5b_\n\nWe choose\n\nIt then follows that\n\n###### \ud835\udc45 (\ufffd \ud835\udc4e / \ud835\udc5b, [\ufffd] \ud835\udc4f / \ud835\udc5b ) .\n\n_\ud835\udc52_ _[\ud835\udc61]_ =\n\n###### \ufffd\n\n###### \ufffd ( \ud835\udc4e / \ud835\udc5b )(1 \u2212 [\ufffd] \ud835\udc4f / \ud835\udc5b )\n\n=\n###### \ufffd \ufffd ( [\ufffd] \ud835\udc4f / \ud835\udc5b )(1 \u2212 \ud835\udc4e / \ud835\udc5b )\n\n###### \ufffd ( \ud835\udc4e / \ud835\udc5b )(1 \u2212 [\ufffd] \ud835\udc4f / \ud835\udc5b )\n\n_\ud835\udc4e_\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] \u2a7d \ufffd\ufffd\ufffd \ud835\udc5b\n\n_\ud835\udc4e_\n###### \ud835\udc5b [\ud835\udc52] [\u2212] [\ud835\udc61] [+][ 1][ \u2212] [\ufffd] \ud835\udc5b [\ud835\udc4e]\n\n###### [\ufffd] [\ud835\udc4e] \ud835\udc4f \ufffd\ufffd [\ufffd]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n\n###### \ufffd\n\n_\ud835\udc4f_ _\ud835\udc4f_\n\n_\ud835\udc52_ _[\ud835\udc61][\ud835\udf03]_\n###### [\ufffd] \ufffd [\ufffd] [\ud835\udefd][\ud835\udc5b]\n_\ud835\udc5b_ _[\ud835\udc52]_ _[\ud835\udc61]_ [+][ 1][ \u2212] _\ud835\udc5b_\n\n=\n###### \ufffd \ufffd\n\n###### \ufffd \ud835\udc4e [\ufffd] \ud835\udc4f\n\n[+]\n_\ud835\udc5b_ [2]\n\n###### \ufffd\n\n###### \ufffd\n\n_\ud835\udc4f_\n###### \ufffd1 \u2212 [\ufffd] [\ud835\udc4e] \ufffd\ufffd1 \u2212 \ufffd [\ufffd] [2] [\ud835\udefd][\ud835\udc5b] \ud835\udc52 [\ud835\udc61][\ud835\udf03]\n\n_\ud835\udc5b_ _\ud835\udc5b_\n\n2 _\ud835\udefd\ud835\udc5b_ _\ud835\udf03_\nexp\n###### \ufffd \ufffd 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd\n\n2 _\ud835\udefd\ud835\udc5b_ _\ud835\udf03_\nexp\n###### \ufffd \ufffd 2\n\n###### \ufffd \ud835\udc4f [\ufffd] [2]\n\n###### \u2a7d 1 \u2212 \ufffd\n\n###### \ufffd [\u221a]\n\n###### \ufffd \ud835\udc4e \u2212 \ufffd\n\n2 _\ud835\udc5b_\n\n###### \u2a7d exp\ufffd\u2212 \ud835\udefd \ud835\udc36 [\ufffd] + [\ud835\udf03] 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd .\n\n69\n\n###### \u25a1\n\n###### Theorem C.5. Fix a level \ud835\udc56 \u2208{1, 2, . . ., \u230alog2 \ud835\udc58 \u230b} and let \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56] (with \ud835\udefc\ud835\udc56 = 1/ \ud835\udc58). Let \ufffd \ud835\udc4e, [\ufffd] \ud835\udc4f, \ud835\udc36 [\ufffd]\n\n_and \ud835\udc45_ (\u00b7 _,_ - ) _be as in Theorem C.4, evaluated at this_ ( _\ud835\udefc, \ud835\udefd_ ) _. Then for every \ud835\udf03_ \u2208 \u211d _,_\n\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] \u2a7d exp \u2212 [(][lo][g][ 2][)][2]\n\n4\n###### \ufffd\n\n[g][ 2][)][2]\n\n     - _[\ud835\udc51]_ _[\ud835\udf00]_ [2]\n4 _\ud835\udc58_ [2]\n\n_[\ud835\udf03]_ _._\n###### 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd\n\n_[\ud835\udc51]_ _[\ud835\udf00]_ _[\ud835\udf03]_\n\n_\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2] [+] 2\n\n_Proof of Theorem C.5._ By Theorem C.4 (applied with ( _\ud835\udefd, \ud835\udefc_ ) = ( _\ud835\udefd\ud835\udc56_ _, \ud835\udefc\ud835\udc56_ )),\n\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] \u2a7d exp \u2212 \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 + [\ud835\udf03] 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] . \ufffd \ufffd It remains to lower bound \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 . Starting from the definition,\n\n###### \ufffd\n\n\u2212\n###### \ud835\udc4e \ufffd\n\n###### \ufffd \ud835\udc36\ud835\udc56 = [\ufffd][\u221a]\n\n###### \ufffd \ud835\udc4f [\ufffd] [2]\n\n2\n\n_\ud835\udc4e_ _\ud835\udefe\ud835\udc56_ /2\n= _\ud835\udc4f_ \u2212 1 _,_\n###### \ud835\udc4f \ufffd \ufffd\ufffd \ufffd\n\n###### where \ud835\udefe\ud835\udc56 = \ud835\udefc\ud835\udc56 / \ud835\udefd\ud835\udc56 . Writing \ud835\udc5f \ufffd \ud835\udc4e / \ud835\udc4f > 1, we have\n\n_\ud835\udc5f_ _[\ud835\udc62]_ \u2212 1 = _\ud835\udc52_ _[\ud835\udc62]_ [log] _[ \ud835\udc5f]_ \u2212 1 \u2a7e _\ud835\udc62_ log _\ud835\udc5f_ for all _\ud835\udc62_ _>_ 0 _,_\n\nso with _\ud835\udc62_ = _\ud835\udefe\ud835\udc56_ /2,\n###### \ufffd \ud835\udc4f\ud835\udc4e\n\nHence\n\n_\ud835\udefe\ud835\udc56_ /2\n###### \ufffd \u2212 1 \u2a7e [\ud835\udefe] 2 [\ud835\udc56]\n\n_\ud835\udc4f_ _[.]_\n\n_[\ud835\udc56]_ _[\ud835\udc4e]_\n\n2 [log] _\ud835\udc4f_\n\n###### \ufffd \ud835\udefe\ud835\udc56 \ud835\udc36\ud835\udc56 \u2a7e \ud835\udc4f \ufffd 2\n\n_\ud835\udc4f_\n\n###### \ufffd 2\n\n_\ud835\udefe\ud835\udc56_ _[\ud835\udc4e]_\n\n2 [log] _\ud835\udc4f_\n\n_\ud835\udefe\ud835\udc56_ [2] _[\ud835\udc4e]_\n= _\ud835\udc4f_ 4 [log][2] _\ud835\udc4f_ _[.]_\n\n_[\ud835\udefc][\ud835\udc56]_ [1]\n\n_\ud835\udefd\ud835\udc56_ [and] _[ \ud835\udefc][\ud835\udc56]_ [=] _\ud835\udc58_\n\nMultiplying by _\ud835\udefd\ud835\udc56_ and using _\ud835\udefe\ud835\udc56_ = _[\ud835\udefc][\ud835\udc56]_\n\n_\ud835\udc58_ [, we get]\n\n_\ud835\udc4f_\n_\ud835\udefe\ud835\udc56_ [2] _[\ud835\udc4e]_\n###### \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 \u2a7e \ud835\udefd\ud835\udc56 log [2]\n\n4 _\ud835\udc4f_\n\n_\ud835\udefc_ [2]\n_\ud835\udc56_ _[\ud835\udc4e]_\n\n_[\ud835\udc4f]_\n\nlog [2]\n4 [\u00b7] _\ud835\udefd\ud835\udc56_ _\ud835\udc4f_\n\n= _[\ud835\udc4f]_\n\n_\ud835\udc4f_\n\n= _[\ud835\udc4f]_\n\n_\ud835\udc4f_ _[.]_\n\n_[\ud835\udc4f]_ 1 _[\ud835\udc4e]_\n\n4 [\u00b7] _\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2] [log][2] _\ud835\udc4f_\n\nRecall _\ud835\udc4e_ = (1 + (1 \u2212 [1]\n\n_[\ud835\udf00]_\n\n_\ud835\udc58_ [)] _[\ud835\udc51]_ [, so]\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_ [)] _[\ud835\udc51]_ [and] _[ \ud835\udc4f]_ [=][ (][1][ \u2212] _[\ud835\udf00]_ _\ud835\udc58_\n\n_\ud835\udc4e_ 1 + (1 \u2212 [1] _\ud835\udc58_\n_\ud835\udc4f_ [=] 1 \u2212 _[\ud835\udf00]_\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_ _\ud835\udc4f_\n\n_[\ud835\udf00]_ _,_ _\ud835\udc51_ [=][ 1][ \u2212] _[\ud835\udf00]_ _\ud835\udc58_\n\n_\ud835\udc58_\n\n1 \u2212 _[\ud835\udf00]_\n\n_\ud835\udc58_ _[,]_\n\n70\n\nand therefore\n\nDefine\n\n1 \u2212 _[\ud835\udf00]_\n\n_\ud835\udc58_\n\n_\ud835\udc3b_ ( _\ud835\udf00, \ud835\udc58_ ) \ufffd\n\n\u2212 _[\ud835\udf00]_\n\n_\ud835\udc58_ _\ud835\udc58_\nlog [2][ 1][ + (][1][ \u2212] [1]\n_\ud835\udf00_ [2] 1 \u2212 _[\ud835\udf00]_\n\n_\ud835\udc51_\n###### \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 \u2a7e\n\n4 _\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2]\n\n1 \u2212 _[\ud835\udf00]_\n###### \ufffd \ud835\udc58\n\n[1][ + (][1][ \u2212] [1] _\ud835\udc58_\nlog [2]\n###### \ufffd 1 \u2212 [\ud835\udf00]\n\n_[\ud835\udf00]_ _._\n\n_\ud835\udc58_\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_\n\n1 \u2212 _[\ud835\udf00]_\n\n1 \u2212 _[\ud835\udf00]_\n\n######, \ud835\udf00 \u2208(0, 1], \ud835\udc58 \u2a7e 2 .\n\n_[\ud835\udf00]_\n\n_\ud835\udc58_\n\n_\ud835\udc58_ [)] _[\ud835\udf00]_\n\nA direct computation shows that _\ud835\udc3b_ ( _\ud835\udf00, \ud835\udc58_ ) is decreasing in _\ud835\udc58_, so\n\ninf _._\n_\ud835\udc58_ \u2a7e2 _[\ud835\udc3b]_ [(] _[\ud835\udf00][, \ud835\udc58]_ [)][ =][ lim] _\ud835\udc58_ \u2192\u221e _[\ud835\udc3b]_ [(] _[\ud835\udf00][, \ud835\udc58]_ [)][ =][ lo][g][2][(] _\ud835\udf00_ [1][2][ +] _[ \ud835\udf00]_ [)]\n\nMoreover, log(1 + _\ud835\udf00_ )/ _\ud835\udf00_ is decreasing on (0 _,_ 1], hence\n\nlog [2] (1 + _\ud835\udf00_ )\n###### \u2a7e log [2] 2 for all \ud835\udf00 \u2208(0, 1] .\n\n_\ud835\udf00_ [2]\n\n###### Thus \ud835\udc3b ( \ud835\udf00, \ud835\udc58 ) \u2a7e log [2] 2 for all \ud835\udf00 \u2208(0, 1], \ud835\udc58 \u2a7e 2, and we obtain\n\n###### \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 \u2a7e [(][lo][g][ 2][)][2]\n\n_\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2] _[.]_\n\n[ 2][)][2] _\ud835\udc51_ _\ud835\udf00_ [2]\n\n4 _\ud835\udc58_\n\nSubstituting this into the Theorem C.4 inequality yields\n\n###### \u2119[ \ud835\udc7f \u2a7d \ud835\udf03 ] \u2a7d exp \u2212 [(][lo][g][ 2][)][2]\n\n4\n###### \ufffd\n\n[g][ 2][)][2] _\ud835\udc51_ _\ud835\udf00_ [2]\n\n4 _\ud835\udc58_\n\n_[\ud835\udf03]_ _,_\n###### 2 [log] [ \ud835\udc45] [(][\ufffd] [\ud835\udc4e] [/] [\ud835\udc5b,] [\ufffd] [\ud835\udc4f] [/] [\ud835\udc5b] [)] \ufffd\n\n_\ud835\udc51_ _\ud835\udf00_ _[\ud835\udf03]_\n\n_\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2] [+] 2\n\n###### as claimed. \u25a1\n\n##### **C.3 Voting lower bound**\n\nIn this section, we will leverage the results of Section C.2 to prove the global voting\nconcentration theorems Theorem 4.3 and Theorem 4.5.\n\n**Theorem C.6** (Claim 6.2 in [LM22]) **.** _Let \ud835\udc5b, \ud835\udc5b_ 1 _, \ud835\udc5b_ 2 _be parameters with \ud835\udc5b_ 1 _, \ud835\udc5b_ 2 \u2a7d 10 [\u2212][6] _\ud835\udc5b. Let_\n_\ud835\udc40_ \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5b]_ _be a random matrix whose entries are independent, have mean_ 0 _, variance at most \ud835\udf0e_ [2] _for_\n###### some \ud835\udf0e \u2a7e 20/ [\u221a] \ud835\udc5b, and are almost surely bounded in [\u22121, 1] . Then, with probability at least\n\n###### 1 \u2212 exp\ufffd\u22128 ( \ud835\udc5b 1 + \ud835\udc5b 2) log [\ufffd] \ud835\udc5b [\ud835\udc5b]\n\n_\ud835\udc5b_ 2\n\n###### \ufffd [\ufffd],\n\n+ _[\ud835\udc5b]_\n\n_[\ud835\udc5b]_\n\n_\ud835\udc5b_ 1 _\ud835\udc5b_ 2\n\n_the magnitude of the sum of the entries over any \ud835\udc5b_ 1 \u00d7 _\ud835\udc5b_ 2 _combinatorial subrectangle of \ud835\udc40_ _is at most_\n( _\ud835\udc5b_ 1 + _\ud835\udc5b_ 2) _\ud835\udf0e_ [\u221a] _\ud835\udc5b._\n\nAs a corollary, we get the following theorem which applies for rectangles which are\nlong and thin.\n\n71\n\n**Theorem C.7.** _Let \ud835\udc5b, \ud835\udc5b_ 1 _, \ud835\udc5b_ 2 _be parameters with \ud835\udc5b_ 1 \u2a7d 10 [\u2212][6] _\ud835\udc5b_ _and \ud835\udc5b_ 2 \u2a7e 10 [\u2212][6] _\ud835\udc5b. Let \ud835\udc40_ \u2208 \u211d _[\ud835\udc5b]_ [\u00d7] _[\ud835\udc5b]_\n\n_be a random matrix whose entries are independent, have mean_ 0 _, variance at most \ud835\udf0e_ [2] _for some_\n###### \ud835\udf0e \u2a7e 20/ [\u221a] \ud835\udc5b, and are almost surely bounded in [\u22121, 1] . Then, with probability at least 1 \u2212 exp\ufffd\u22128 ( \ud835\udc5b 1 + 10 [\u2212][6] \ud835\udc5b ) log [\ufffd] \ud835\udc5b [\ud835\udc5b] 1 [+][ 10][6][\ufffd\ufffd],\n\n_the magnitude of the sum of the entries over any \ud835\udc5b_ 1 \u00d7 _\ud835\udc5b_ 2 _combinatorial subrectangle of \ud835\udc40_ _is at most_\n2 ( _\ud835\udc5b_ 1 + _\ud835\udc5b_ 2) _\ud835\udf0e_ [\u221a] _\ud835\udc5b._\n\n_Proof._ Let us fix a set _\ud835\udc46_ \u2286[ _\ud835\udc5b_ ] of rows with | _\ud835\udc46_ | = _\ud835\udc5b_ 1 and define\n\n###### \ud835\udc63 \ud835\udc57 := \ufffd \ud835\udc40\ud835\udc56\ud835\udc57, \ud835\udc57 \u2208[ \ud835\udc5b ] .\n\n_\ud835\udc56_ \u2208 _\ud835\udc46_\n\nSet _\ud835\udeff_ := 10 [\u2212][6] . By Theorem C.6 with parameters ( _\ud835\udc5b_ 1 _, \ud835\udeff\ud835\udc5b_ ), with the stated probability we\nhave for all _\ud835\udc48_ \u2286[ _\ud835\udc5b_ ] with | _\ud835\udc48_ | = _\ud835\udeff\ud835\udc5b_ that\n###### \ufffd\ufffd\ufffd\ufffd \ud835\udc63 \ud835\udc57 \ufffd\ufffd\ufffd = \ufffd\ufffd\ufffd \ufffd \ud835\udc40\ud835\udc56\ud835\udc57 \ufffd\ufffd\ufffd \u2a7d ( \ud835\udc5b 1 + \ud835\udeff\ud835\udc5b ) \ud835\udf0e \u221a \ud835\udc5b.\n\n###### \ufffd \ud835\udc63 \ud835\udc57 \ufffd\ufffd\ufffd = \ufffd\ufffd\ufffd \ufffd\n\n_\ud835\udc57_ \u2208 _\ud835\udc48_ ( _\ud835\udc56,\ud835\udc57_ )\u2208 _\ud835\udc46_\n\n###### \ufffd \ud835\udc40\ud835\udc56\ud835\udc57 \ufffd\ufffd\ufffd \u2a7d ( \ud835\udc5b 1 + \ud835\udeff\ud835\udc5b ) \ud835\udf0e \u221a\n\n( _\ud835\udc56,\ud835\udc57_ )\u2208 _\ud835\udc46_ \u00d7 _\ud835\udc48_\n\n_\ud835\udc5b._\n\n###### We now use a simple averaging inequality: for any integers \ud835\udc3e \u2a7e \ud835\udc3f and any vector \ud835\udc64,\n\n###### \ufffd\ufffd\ufffd\ufffd \ud835\udc64 \ud835\udc57 \ufffd\ufffd\ufffd .\n\n_\ud835\udc57_ \u2208 _\ud835\udc48_\n\n_\ud835\udc3f_ | [sup] _\ud835\udc48_ |= _\ud835\udc3f_\n\n###### \ufffd\ufffd\ufffd\ufffd\n\nsup\n| _\ud835\udc47_ |= _\ud835\udc3e_\n\n###### \ufffd\ufffd\ufffd\ufffd\n\n_\ud835\udc3e_\n###### \ufffd \ud835\udc64 \ud835\udc57 \ufffd\ufffd\ufffd \u2a7d \ud835\udc3f\n\n_\ud835\udc57_ \u2208 _\ud835\udc47_\n\n###### Indeed, for any fixed \ud835\udc47 with | \ud835\udc47 | = \ud835\udc3e, each \ud835\udc57 \u2208 \ud835\udc47 lies in exactly [\ufffd] [\ud835\udc3e] \ud835\udc3f \u2212 [\u2212] 1 [1] \ufffd subsets \ud835\udc48 \u2286 \ud835\udc47 of size \ud835\udc3f,\n\nso\n\n\u22121\n\n_\ud835\udc3e_ \u2212 1\n###### \ufffd \ud835\udc64 \ud835\udc57 = \u2212 \ufffd \ufffd \ud835\udc64 \ud835\udc57, \ufffd \ufffd\n\n_\ud835\udc3e_ \u2212 1\n###### \ufffd \ud835\udc64 \ud835\udc57 = \ud835\udc3f \u2212 1 \ud835\udc57 \u2208 \ud835\udc47 \ufffd\n\n\u22121\n###### \ufffd \ufffd\n\n_\ud835\udc48_ \u2286 _\ud835\udc47_\n| _\ud835\udc48_ |= _\ud835\udc3f_\n\n###### \ufffd\n\n_\ud835\udc64_ _\ud835\udc57_ _,_\n_\ud835\udc57_ \u2208 _\ud835\udc48_\n\n###### and taking absolute values yields the desired result since [\ufffd] [\ud835\udc3e] \ud835\udc3f \ufffd/ [\ufffd] [\ud835\udc3e] \ud835\udc3f \u2212 [\u2212] 1 [1] \ufffd = \ud835\udc3e / \ud835\udc3f .\n\nApplying this with _\ud835\udc64_ = _\ud835\udc63_, _\ud835\udc3e_ = _\ud835\udc5b_ 2, and _\ud835\udc3f_ = _\ud835\udeff\ud835\udc5b_ yields, uniformly for all _\ud835\udc47_ with | _\ud835\udc47_ | = _\ud835\udc5b_ 2,\n\n_\ud835\udc40_ = _\ud835\udc63_\n###### \ufffd\ufffd\ufffd \ufffd \ud835\udc56\ud835\udc57 \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ud835\udc57 \ufffd\ufffd\ufffd\n\n_\ud835\udc40_ =\n###### \ufffd \ud835\udc56\ud835\udc57 \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\n( _\ud835\udc56,\ud835\udc57_ )\u2208 _\ud835\udc46_ \u00d7 _\ud835\udc47_ _\ud835\udc57_ \u2208 _\ud835\udc47_\n\n###### \ufffd \ud835\udc63 \ud835\udc57 \ufffd\ufffd\ufffd\n\n_\ud835\udc57_ \u2208 _\ud835\udc47_\n\n###### \u2a7d [\ud835\udc5b] [2] sup\n\n_\ud835\udeff\ud835\udc5b_ | _\ud835\udc48_ |= _\ud835\udeff\ud835\udc5b_\n\n###### \u2a7d [\ud835\udc5b] [2]\n\n###### \ufffd\ufffd\ufffd\ufffd \ud835\udc63 \ud835\udc57 \ufffd\ufffd\ufffd\n\n_\ud835\udc57_ \u2208 _\ud835\udc48_\n\n###### \ufffd \ud835\udc63 \ud835\udc57 \ufffd\ufffd\ufffd\n\n_\ud835\udc57_ \u2208 _\ud835\udc48_\n\n###### \u2a7d [\ud835\udc5b] [2] \u221a\n\n_\ud835\udeff\ud835\udc5b_ [(] _[\ud835\udc5b]_ [1][ +] _[ \ud835\udeff][\ud835\udc5b]_ [)] _[ \ud835\udf0e]_\n\n###### \u2a7d [\ud835\udc5b] [2]\n\n_\ud835\udc5b_\n\n###### \u2a7d 2 \ud835\udc5b 2 \ud835\udf0e \u221a\n\n_\ud835\udc5b_\n\n###### \u2a7d 2 ( \ud835\udc5b 1 + \ud835\udc5b 2) \ud835\udf0e \u221a\n\n_\ud835\udc5b._\n\nSince Theorem C.6 is uniform over all choices of _\ud835\udc46_ and _\ud835\udc48_ of the specified sizes, the bound\n###### holds simultaneously for all \ud835\udc5b 1 \u00d7 \ud835\udc5b 2 combinatorial subrectangles, as claimed. \u25a1\n\n72\n\n###### Theorem C.8. Fix a level \ud835\udc56 \u2208{1, 2, . . ., \u230alog2 \ud835\udc58 \u230b} and set \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56], \ud835\udc5b\ud835\udc56 \ufffd 2 \ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udefe\ud835\udc56 \ufffd \ud835\udefc\ud835\udc56 / \ud835\udefd\ud835\udc56 = 2 [\ud835\udc56] / \ud835\udc58 with \ud835\udefc\ud835\udc56 = 1/ \ud835\udc58. Let \ud835\udc66 \u2208{0, \u00b11} [\ud835\udc5b] be a valid level-\ud835\udc56 bisection labeling. Fix parameters \ud835\udc61 \u2a7e 1 and 0 < \ud835\udf0c< 10 [\u2212][6], and set \ufffd \ud835\udc44\ud835\udc56 = \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 \u2212 log(1/ \ud835\udf0c ) \u2212 3 \ud835\udc61. Assume \ud835\udc4e \u2a7e \ud835\udc4f, \ud835\udc4e, \ud835\udc4f \u2a7d \ud835\udc5b, and \ud835\udc4e \u2a7e 400 . Then, with probability at least 1 \u2212 \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56] \u2212 1/ \ud835\udc5b\ud835\udc56 [3] [, for any][ \ud835\udc67]\n\n_supported on_ { _\ud835\udc57_ : _\ud835\udc66\ud835\udc57_ \u2260 0} _with_ \u2225 _\ud835\udc67_ \u22251 = _\ud835\udf0c_ _\ud835\udc5b\ud835\udc56, we have_\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e 2 \ud835\udf0c\ud835\udc5b\ud835\udc56\n\n###### \ufffd\n\n_\ud835\udc44\ud835\udc56_ \u2212\n\u221a\n###### \ufffd log \ud835\udc45 [\ufffd] \ud835\udc56\n\n_\ud835\udc4e_ + _\ud835\udc4f_ _._\n###### \ufffd\n\n_Proof._ Imagine sampling the matrix _\ud835\udc3a_ by independently drawing the entries _\ud835\udc3a\ud835\udc56\ud835\udc57_ for _\ud835\udc56_ _< \ud835\udc57_\nand then filling in the remainder symmetrically, with _\ud835\udc3a\ud835\udc57\ud835\udc56_ = _\ud835\udc3a\ud835\udc56\ud835\udc57_ and _\ud835\udc3a\ud835\udc56\ud835\udc56_ = 0. If _\ud835\udc56_ and _\ud835\udc57_ are\nin the same community then _\ud835\udc3a\ud835\udc56\ud835\udc57_ \u223c Bernoulli( _\ud835\udc4e_ / _\ud835\udc5b_ ); otherwise _\ud835\udc3a\ud835\udc56\ud835\udc57_ \u223c Bernoulli( _\ud835\udc4f_ / _\ud835\udc5b_ ). Fix a\nlevel- _\ud835\udc56_ bisection with sides _\ud835\udc46_ [+]\n_\ud835\udc56_ [and] _[ \ud835\udc46]_ [\u2212] _\ud835\udc56_ [of size] _[ \ud835\udc5b][\ud835\udc56]_ [/][2][ each, and write] _[ \ud835\udefc]_ [=][ 1][/] _[\ud835\udc58]_ [. For a vertex]\n_\ud835\udc62_ \u2208 _\ud835\udc46_ [+]\n_\ud835\udc56_ [consider the signed difference]\n\n_\ud835\udc7f\ud835\udc96_ =\n###### \ufffd\n\n\u2212\n_\ud835\udc3a\ud835\udc62\ud835\udc63_\n###### \ufffd \ufffd\n\n_\ud835\udc63_ \u2208 _\ud835\udc46_ [+] _\ud835\udc56_ [\\{] _[\ud835\udc62]_ [}] _\ud835\udc63_ \u2208 _\ud835\udc46_ [\u2212] _\ud835\udc56_\n\n_\ud835\udc3a\ud835\udc62\ud835\udc63_ _._\n\n_\ud835\udc63_ \u2208 _\ud835\udc46_ [\u2212]\n_\ud835\udc56_\n\nWe observe that the neighbors of _\ud835\udc62_ split into three disjoint sets: its own community\n_\ud835\udc36_ ( _\ud835\udc62_ ) \\ { _\ud835\udc62_ } of size _\ud835\udefc\ud835\udc5b_ \u2212 1 where edges have bias _\ud835\udc4e_ / _\ud835\udc5b_ ; the remaining ( _\ud835\udefd\ud835\udc56_ \u2212 _\ud835\udefc_ ) _\ud835\udc5b_ vertices on\nthe same side where edges have bias _\ud835\udc4f_ / _\ud835\udc5b_ ; and the _\ud835\udefd\ud835\udc56\ud835\udc5b_ vertices on the opposite side where\nedges have bias _\ud835\udc4f_ / _\ud835\udc5b_ . Independence across disjoint unordered pairs implies that these three\ncontributions are independent binomials, hence\n\n_\ud835\udc51_\n###### \ud835\udc7f\ud835\udc96 = Binom( \ud835\udefc\ud835\udc5b \u2212 1, \ud835\udc4e / \ud835\udc5b ) + Binom [\ufffd] ( \ud835\udefd\ud835\udc56 \u2212 \ud835\udefc ) \ud835\udc5b, \ud835\udc4f / \ud835\udc5b [\ufffd] \u2212 Binom( \ud835\udefd\ud835\udc56\ud835\udc5b, \ud835\udc4f / \ud835\udc5b ) .\n\nWe note that since \u27e8 _\ud835\udc3a\ud835\udc66_ \u2299 _\ud835\udc66, \ud835\udc67_ \u27e9 is linear in _\ud835\udc67_ and only coordinates with _\ud835\udc66\ud835\udc57_ \u2260 0 contribute, it\nsuffices to take _\ud835\udc67_ = **1** _\ud835\udc46_ for some _\ud835\udc46_ \u2286{ _\ud835\udc57_ : _\ud835\udc66\ud835\udc57_ \u2260 0} with | _\ud835\udc46_ | = _\ud835\udf0c_ _\ud835\udc5b\ud835\udc56_ (if _\ud835\udf0c\ud835\udc5b\ud835\udc56_ \u2209\u2115, take \u230a _\ud835\udf0c\ud835\udc5b\ud835\udc56_ \u230b and\n\u2308 _\ud835\udf0c\ud835\udc5b\ud835\udc56_ \u2309; any other _\ud835\udc67_ \u2208[0 _,_ 1] _[\ud835\udc5b]_ with the same _\u2113_ 1-norm is a convex combination).\nLet us first construct an auxiliary matrix _\ud835\udc3a_ [ind] in which, for each fixed row _\ud835\udc62_, the\nvariables **{** _\ud835\udc3a\ud835\udc62\ud835\udc63_ [ind][}] _[\ud835\udc63]_ [are independent Bernoullis with the same means as above (and different]\n_\ud835\udc7f_ **[ind]**\nrows are also independent); define _\ud835\udc96_ analogously. Then\n\n\u27e8 _\ud835\udc3a_ [ind] _\ud835\udc66_ \u2299 _\ud835\udc66,_ **1** _\ud835\udc46_ \u27e9 = _\ud835\udc7f\ud835\udc96_ **[ind]** _._\n###### \ufffd\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_\n\nWe now apply Theorem C.4 to the sum _\ud835\udc7f\ud835\udc96_ **[ind]** by independence across rows with the\n###### \ufffd\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_\n\nparameter\n\n###### \ufffd \ufffd \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 \u2212 log(1/ \ud835\udf0c ) \u2212 3 \ud835\udc61 \ud835\udc44\ud835\udc56\n\n_\ud835\udf03\ud835\udc56_ = 2 _\ud835\udf0c\ud835\udc5b\ud835\udc56_ = 2 _\ud835\udf0c\ud835\udc5b\ud835\udc56_ _._\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 log \ud835\udc45 [\ufffd] \ud835\udc56\n\n73\n\nThis yields\n\n\u2119\n###### \ufffd\ufffd\n\n2 _\ud835\udc56_ [log][ \ufffd] _[\ud835\udc45][\ud835\udc56]_ = exp \u2212| _\ud835\udc46_ |(log(1/ _\ud835\udf0c_ ) + 3 _\ud835\udc61_ ) _._\n###### \ufffd \ufffd \ufffd\n\n###### \ud835\udc7f\ud835\udc96 [ind] \u2a7d \ud835\udf03 [\ufffd] \ud835\udc56 \u2a7d exp \u2212| \ud835\udc46 | \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 + \ud835\udf03 \ufffd2 \ud835\udc56 \ufffd \ufffd\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_\n\nA union bound over all _\ud835\udc46_ \u2286{ _\ud835\udc66_ \u2260 0} with | _\ud835\udc46_ | = _\ud835\udf0c\ud835\udc5b\ud835\udc56_ gives\n\n_\ud835\udc5b\ud835\udc56_\n###### \u2119 \u2203 \ud835\udc46 : \ud835\udc7f\ud835\udc96 [ind] \u2a7d \ud835\udf03 [\ufffd] \ud835\udc56 \u2a7d \ufffd \ufffd \ud835\udc62 \u2208 \ud835\udc46 \ufffd \ufffd \ud835\udf0c\ud835\udc5b\ud835\udc56\n\n###### \ud835\udc52 [\u2212|] [\ud835\udc46] [|(][log][(][1][/] [\ud835\udf0c] [)+][3] [\ud835\udc61] [)] \u2a7d \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56], \ufffd\n\n###### using [\ufffd] \ud835\udf0c [\ud835\udc5b] \ud835\udc5b [\ud835\udc56] \ud835\udc56 \ufffd \u2a7d exp( \ud835\udf0c\ud835\udc5b\ud835\udc56 (log(1/ \ud835\udf0c )+ 1)) and \ud835\udc61 \u2a7e 1. Therefore, with probability at least 1 \u2212 \ud835\udc52 \u2212 \ud835\udc61\ud835\udf0c\ud835\udc5b\ud835\udc56,\n\nsimultaneously for all such _\ud835\udc46_,\n\n###### \ufffd\n\n_\ud835\udc44\ud835\udc56_\n###### \ud835\udc7f\ud835\udc96 [ind] \u2a7e \ud835\udf03 [\ufffd] \ud835\udc56 = 2| \ud835\udc46 | . (C.4) \ufffd \ud835\udc62 \u2208 \ud835\udc46 log \ud835\udc45 [\ufffd] \ud835\udc56\n\nIt remains to pass from the independent sampling used above to the actual symmetric\nSBM with zero diagonal. We, first, note that zeroing the diagonal affects the sum by\nat most | _\ud835\udc46_ | = _\ud835\udf0c\ud835\udc5b\ud835\udc56_ . We, further, note that only the block _\ud835\udc46_ \u00d7 _\ud835\udc46_ differs between the two\nsampling procedures. Let \u0394( _\ud835\udc46_ ) be the difference between the contributions of _\ud835\udc46_ \u00d7 _\ud835\udc46_ to\n###### \ufffd \ud835\udc62 \u2208 \ud835\udc46 [\ud835\udc7f] \ud835\udc96 [ind] and to [\ufffd] \ud835\udc62 \u2208 \ud835\udc46 [\ud835\udc7f][\ud835\udc96] [. As in [][LM22][],][ \u0394][(] [\ud835\udc46] [)][ is a sum/difference of independent, mean-][0][,]\n\nbounded variables, each supported in [\u22121 _,_ 1] and nonzero with probability at most _\ud835\udc4e_ / _\ud835\udc5b_\n###### (so \ud835\udf0e [2] \u2a7d ( \ud835\udc4e + \ud835\udc4f )/ \ud835\udc5b ). Apply Theorem C.6 with \ud835\udc5b 1 = \ud835\udc5b 2 = | \ud835\udc46 | and \ud835\udf0e [2] = ( \ud835\udc4e + \ud835\udc4f )/ \ud835\udc5b (hence \ud835\udf0e \u2a7e 20/ [\u221a] \ud835\udc5b because \ud835\udc4e \u2a7e 400). Since \ud835\udc56 \u2a7e 1, we have \ud835\udc5b\ud835\udc56 \u2a7d \ud835\udc5b and hence | \ud835\udc46 | = \ud835\udf0c\ud835\udc5b\ud835\udc56 \u2a7d \ud835\udf0c\ud835\udc5b \u2a7d 10 [\u2212][6] \ud835\udc5b,\n\nso the conditions hold. We obtain\n\n\u2119 |\u0394( _\ud835\udc46_ )| _>_ 2| _\ud835\udc46_ |\u221a\n###### \ufffd\n\n###### \ud835\udc4e + \ud835\udc4f \ufffd \u2a7d exp \ufffd \u2212 16| \ud835\udc46 | log [\ufffd] | [\ud835\udc5b] \ud835\udc46 | \ufffd [\ufffd] .\n\n###### A union bound over all [\ufffd] \ud835\udf0c [\ud835\udc5b] \ud835\udc5b [\ud835\udc56] \ud835\udc56 \ufffd choices of \ud835\udc46 shows that, with additional failure probability at\n\nmost 1/ _\ud835\udc5b\ud835\udc56_ [3] [(for all large] _[ \ud835\udc5b]_ [), we have][ |][\u0394][(] _[\ud835\udc46]_ [)|][ \u2a7d] [2][|] _[\ud835\udc46]_ [|] ~~\u221a~~ _\ud835\udc4e_ + _\ud835\udc4f_ simultaneously for all such _\ud835\udc46_ .\n\nFinally, intersecting the two high-probability events and noting that the level- _\ud835\udc56_ bisection\nis balanced so we get\n\n_\ud835\udc66\ud835\udc62_\n###### \ufffd \ufffd\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_ _\ud835\udc63_\n\n###### \ud835\udc7f\ud835\udc96 \u2a7e \ud835\udf03 [\ufffd] \ud835\udc56 \u2212 2| \ud835\udc46 |\u221a \ufffd\n\n_\ud835\udc62_ \u2208 _\ud835\udc46_\n\n\u27e8 _\ud835\udc3a\ud835\udc66_ [\u00af] \u2299 _\ud835\udc66,_ **1** _\ud835\udc46_ \u27e9 =\n###### \ufffd\n\n_\ud835\udc66\ud835\udc63_ ( _\ud835\udc3a\ud835\udc62\ud835\udc63_ \u2212 _\ud835\udc51\ud835\udc56_ ) =\n###### \ufffd\n\n_\ud835\udc63_ _\ud835\udc62_ \u2208 _\ud835\udc46_\n\n_\ud835\udc4e_ + _\ud835\udc4f._\n\n###### Substituting | \ud835\udc46 | = \ud835\udf0c\ud835\udc5b\ud835\udc56 and the definition of \ud835\udf03 [\ufffd] \ud835\udc56 yields the desired conclusion. \u25a1 Theorem C.9. Fix a level \ud835\udc56 \u2208{1, 2, . . ., \u230alog2 \ud835\udc58 \u230b} and set \ud835\udefd\ud835\udc56 \ufffd 2 [\u2212] [\ud835\udc56], \ud835\udc5b\ud835\udc56 \ufffd 2 \ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udefe\ud835\udc56 \ufffd \ud835\udefc\ud835\udc56 / \ud835\udefd\ud835\udc56 = 2 [\ud835\udc56] / \ud835\udc58 with \ud835\udefc\ud835\udc56 = 1/ \ud835\udc58. Assume 0 < \ud835\udf00< 1 and \ud835\udc58 \u2a7e 2, and take other parameters as in Theorem C.4.\n\n_Define_\n\n1\n\n\u2212 _[\ud835\udf00]_ [2] _[\ud835\udc51]_\n_\ud835\udc52_ _[,]_ [ exp][\ufffd] 8 _\ud835\udc58_\n\n1\n###### \ud835\udf0c\ud835\udefe \ufffd min \ufffd \ud835\udc52\n\n_._\n###### \ufffd [\ufffd]\n8 _\ud835\udc58_\n\n74\n\n###### If, in addition, \ud835\udf00 [2] \ud835\udc51 \u2a7e 9 \ud835\udc58 [2], then for any 0 < \ud835\udf0c \u2a7d min{ \ud835\udf0c\ud835\udefe, 10 [\u2212][6] } and \ud835\udc61 = \ud835\udf00 [2] \ud835\udc51 / \ud835\udc58, with probability at\n\n_least_ 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ \u2212 [1]\n\n_\ud835\udc5b_ [3]\n_\ud835\udc56_ _[we have]_\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e \u221212 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51 for every \ud835\udc67 with \u2225 \ud835\udc67 \u22251 = \ud835\udf0c\ud835\udc5b\ud835\udc56,\n\n_where \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _is any valid bisection labeling at level \ud835\udc56._\n\n###### Proof. Let \ud835\udc61 = \ud835\udf00 [2] \ud835\udc51 / \ud835\udc58 and fix any 0 < \ud835\udf0c \u2a7d min{ \ud835\udf0c\ud835\udefe, 10 [\u2212][6] }. By Theorem C.8, with probability\n\nat least 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ \u2212 [1]\n\n_\ud835\udc5b_ [3]\n_\ud835\udc56_ [, we have for all] _[ \ud835\udc67]_ [with][ \u2225] _[\ud835\udc67]_ [\u2225][1][ =] _[ \ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [,]\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e 2 \ud835\udf0c\ud835\udc5b\ud835\udc56\n\n###### \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 \u2212 log(1/ \ud835\udf0c ) \u2212 3 \ud835\udc61 \u2212\n\n\u221a\n###### \ufffd log \ud835\udc45 [\ufffd] \ud835\udc56\n\n_\ud835\udc4e_ + _\ud835\udc4f_\n\n###### \ufffd\n\n_._ (C.5)\n\nWe now bound the three potentially negative contributions on the right-hand side of (C.5).\nFor the \u2212 log(1/ _\ud835\udf0c_ ) term, Theorem C.2 yields\n\n_\ud835\udf0c_ _[.]_\n\n\u2212 [2] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_\n\n[1]\n###### \ud835\udf0c [\u2a7e] [\u2212] [4] \ud835\udefe [\ud835\udf0c] \ud835\udc56 [\ud835\udc5b] \ud835\udf00 [\ud835\udc56]\n\n_[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [1]\n\n_\ud835\udefe\ud835\udc56_ _\ud835\udf00_ [log] _\ud835\udf0c_\n\n[2] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [1]\n\nlog\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 \ud835\udf0c\n\n###### By the monotonicity of \ud835\udc65 log(1/ \ud835\udc65 ) on (0, \ud835\udc52 [\u2212][1] ] and \ud835\udf0c \u2a7d \ud835\udf0c\ud835\udefe \u2a7d \ud835\udc52 [\u2212][1], we have\n\n[1]\n_\ud835\udf0c_ log\n\n_,_\n_\ud835\udf0c\ud835\udefe_\n\n[1] [1]\n###### \ud835\udf0c [\u2a7d] [\ud835\udf0c][\ud835\udefe] [log] \ud835\udf0c\n\nand therefore\n\n###### \ud835\udefe\ud835\udc56 \ud835\udc58 [\u2a7e] [\u2212][4] [\ud835\udf0c][\ud835\udefe][\ud835\udc5b][\ud835\udc56] [\ud835\udf00][\ud835\udc51.]\n\n4 _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_\n\n[1]\n###### \ud835\udf0c\ud835\udefe [\u2a7e] [\u2212] \ud835\udefe\ud835\udc56 \ud835\udf00\n\n\u2212 [2] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_\n\n4 _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_\n\n[1]\n###### \ud835\udf0c [\u2a7e] [\u2212] \ud835\udefe\ud835\udc56 \ud835\udf00\n\n[2] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [1]\n\nlog\n###### log \ud835\udc45 [\ufffd] \ud835\udc56 \ud835\udf0c\n\n_\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_\n\n[1]\nlog\n_\ud835\udefe\ud835\udc56_ _\ud835\udf00_ _\ud835\udf0c_\n\n_\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_\n\n     - _[\ud835\udf00]_ [2] _[\ud835\udc51]_\n_\ud835\udefe\ud835\udc56_ _\ud835\udf00_ _\ud835\udc58_\n\n_[\ud835\udc51]_\n\n_\ud835\udc58_ = \u22124 _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_ _\ud835\udf00\ud835\udc51_ - [1]\n\nFor the \u22123 _\ud835\udc61_ term, using _\ud835\udc61_ = _\ud835\udf00_ [2] _\ud835\udc51_ / _\ud835\udc58_ and Theorem C.2 we obtain\n\n_[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [\u00b7][ 3] _[\ud835\udc61]_\n\n\u2212 [12] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ _[\ud835\udc61]_\n###### \u2a7e log \ud835\udc45 [\ufffd] \ud835\udc56 \ud835\udefe\ud835\udc56 \ud835\udf00\n\n_[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ _[\ud835\udf00]_ [2] _[\ud835\udc51]_\n\n_\ud835\udefe\ud835\udc56_ _\ud835\udf00_ [\u00b7] _\ud835\udc58_\n\n\u2212 [2] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ [\u00b7][ 3] _[\ud835\udc61]_\n\n_[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ _[\ud835\udc61]_\n\n= \u2212 [12] _[\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_\n_\ud835\udefe\ud835\udc56_ _\ud835\udf00_ _\ud835\udefe\ud835\udc56_ _\ud835\udf00_\n\n###### \ud835\udc58 = \u221212 \ud835\udf0c\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51 \u00b7 \ud835\udefd\ud835\udc56 \u2a7e \u22126 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51.\n\nFinally, by Theorem C.1, we have that\n\n\u22122 _\ud835\udf0c\ud835\udc5b\ud835\udc56_ \u221a\n\n###### \ud835\udc4e + \ud835\udc4f \u2a7e \u22122 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \u221a3 \ud835\udc51 \u2a7e \u22122 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51.\n\nCombining these three bounds in (C.5) yields\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e \u2212 4 + 6 + 2 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51 = \u221212 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51 \u2a7e \u221212 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51, \ufffd \ufffd\n\nwhich is the desired inequality. The probability statement is exactly that of Theorem C.8\n###### with \ud835\udc61 = \ud835\udf00 [2] \ud835\udc51 / \ud835\udc58, completing the proof. \u25a1\n\n75\n\n**Lemma C.10.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _and \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b. Let \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _be a valid bisection_\n###### labeling at level \ud835\udc56. Choose 0 < \ud835\udf0c\ud835\udefe \u2a7d 10 [\u2212][6] and set \ud835\udc61 = \ud835\udf00 [2] \ud835\udc51 / \ud835\udc58. Then, with probability at least\n\n1 \u2212 2 _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ \u2212 _\ud835\udc5b_ [\u2212][2]\n_\ud835\udc56_ _[, the inequality]_\n###### \u27e8 \ud835\udc3a\ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e \u221212 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51\n\n_holds simultaneously for every vector \ud835\udc67_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _with_ \u2225 _\ud835\udc67_ \u22251 \u2a7d _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56._\n\n_Proof._ We discretize over the admissible _\u2113_ 1 sizes: since _\ud835\udc67_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_, the quantity \u2225 _\ud835\udc67_ \u22251 is an\n###### integer, hence \ud835\udf0c = \u2225 \ud835\udc67 \u22251/ \ud835\udc5b\ud835\udc56 ranges over the set { \ud835\udc57 / \ud835\udc5b\ud835\udc56 : 1 \u2a7d \ud835\udc57 \u2a7d \u230a \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \u230b}. For a fixed value \ud835\udf0c\n\nwe invoke the level- _\ud835\udc56_ voting lower bound (Theorem C.9) with this _\ud835\udf0c_ . It states that, with\nprobability at least 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ \u2212 _\ud835\udc5b\ud835\udc56_ [\u2212][3][, the estimate]\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e \u221212 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \ud835\udf00\ud835\udc51\n\nholds simultaneously for all _\ud835\udc67_ with \u2225 _\ud835\udc67_ \u22251 = _\ud835\udf0c\ud835\udc5b\ud835\udc56_ . Taking a union bound over the at most\n\u230a _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_ \u230b distinct values, the failure probability is at most\n\n\u230a _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_ \u230b\n###### \ufffd\n\n_\ud835\udc57_ =1\n\n_\ud835\udc52_ [\u2212] _[\ud835\udc61]_ \u230a _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56_ \u230b\n\n1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ [+] [3]\n\n_\ud835\udc52_ [\u2212] [1]\n\n1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ [+]\n\n###### [1] \u2a7d 2 \ud835\udc52 [\u2212] [\ud835\udc61] + [1]\n\n_\ud835\udc5b_ [2] _\ud835\udc5b_\n_\ud835\udc56_\n\n_\ud835\udc52_ [\u2212] _[\ud835\udc61]_\n###### \ud835\udc52 [\u2212] [\ud835\udc61\ud835\udc57] + \ud835\udc5b [\u2212][3] \u2a7d\n\n_\ud835\udc56_\n###### \ufffd \ufffd 1 \u2212 \ud835\udc52\n\n_\ud835\udefe\ud835\udc5b\ud835\udc56_ \u230b _\ud835\udc52_ [\u2212] _[\ud835\udc61]_\n###### \u2a7d\n\n_\ud835\udc5b_ [3] 1 \u2212 _\ud835\udc52_\n_\ud835\udc56_\n\n_._\n_\ud835\udc5b_ [2]\n_\ud835\udc56_\n\nOn the complementary event, the desired bound holds for every value in the set, and hence\n###### for every \ud835\udc67 \u2208{0, \u00b11} [\ud835\udc5b] with \u2225 \ud835\udc67 \u22251 \u2a7d \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56, as claimed. \u25a1\n\nNext we give a lemma for lower bounding the inner product when the size of the set is\nlarge.\n\n**Lemma C.11.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _, \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udc58\ud835\udc56_ = _\ud835\udefd\ud835\udc56_ _\ud835\udc58. Let \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _be a valid_\n###### bisection labeling at level \ud835\udc56. Let \ud835\udefe \u2208 \ufffd0, 1 \u2212 [1000] [\ud835\udf12] [\ud835\udc58][\ud835\udc56] \ufffd . Define\n\n###### \ud835\udc51 [\ud835\udf12] \ud835\udc56 [\ud835\udc56] \ufffd . Define\n\n_\ud835\udf00_ ~~\u221a~~\n\n###### \ud835\udf0c\ud835\udefe \ufffd exp \u2212 [\ud835\udefe\ud835\udefd][\ud835\udc56] [\ud835\udc36] [\ufffd] [\ud835\udc56] \ufffd 2\n\n######, \ud835\udc61 \ufffd 0 . 001 (1 \u2212 \ud835\udefe ) \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56. \ufffd\n\n###### Then for every \ud835\udf0c \u2a7e \ud835\udf0c\ud835\udefe, with probability at least 1 \u2212 exp(\u2212 \ud835\udc61\ud835\udf0c\ud835\udc5b\ud835\udc56 ) \u2212 \ud835\udc5b [1][3]\n\n_\ud835\udc56_ _[, the inequality]_\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [\ud835\udf00][\ud835\udc51]\n\n5 _\ud835\udc58_ [(][1][ \u2212] _[\ud835\udefe]_ [)] _[ \ud835\udf0c][\ud835\udefe]_ _[\ud835\udc5b][\ud835\udc56]_\n\n_holds for all \ud835\udc67_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ _with_ \u2225 _\ud835\udc67_ \u22251 = _\ud835\udf0c\ud835\udc5b\ud835\udc56, where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n_Proof._ Let us fix _\ud835\udf0c_ \u2208[ _\ud835\udf0c\ud835\udefe,_ 1] and _\ud835\udc67_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ with \u2225 _\ud835\udc67_ \u22251 = _\ud835\udf0c\ud835\udc5b\ud835\udc56_ . By Theorem C.8 applied to _\ud835\udc3a_ [\u00af],\nwith probability at least 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ \u2212 _\ud835\udc5b\ud835\udc56_ [\u2212][3] we have\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e 2 \ud835\udf0c\ud835\udc5b\ud835\udc56\n\n###### \ufffd\n\n_\ud835\udc44\ud835\udc56_ \u2212 \u221a _\ud835\udc4e_ + _\ud835\udc4f_\n###### \ufffd log \ud835\udc45 [\ufffd] \ud835\udc56\n\n76\n\n###### \ufffd\n\n###### \ufffd, \ud835\udc44\ud835\udc56 \ufffd \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 \u2212 log [1] (C.6)\n\n_\ud835\udf0c_ [\u2212] [3] _[\ud835\udc61.]_\n\n###### Since \ud835\udf0c \u2a7e \ud835\udf0c\ud835\udefe = exp(\u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 /2), we have \u2212 log(1/ \ud835\udf0c ) \u2a7e \u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 /2,\n\nand hence\n\n###### \ufffd \ud835\udc44\ud835\udc56 \u2a7e 1 \u2212 [\ud835\udefe] \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56 \ufffd 2 [\u2212] [0] [.] [003][(][1][ \u2212] [\ud835\udefe] [)] \ufffd \u2a7e 0 . 997 [\ufffd] 1 \u2212 \ud835\udefe [\ufffd] \ud835\udefd\ud835\udc56\ud835\udc36 [\ufffd] \ud835\udc56. (C.7) By Lemma C.2, log \ud835\udc45 [\ufffd] \ud835\udc56 \u2a7d \ud835\udefe\ud835\udc56 \ud835\udf00 log 3 + \ud835\udc5c (1). Therefore \ufffd \ud835\udc44\ud835\udc56 (1 \u2212 \ud835\udefe ) \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 \u2a7e 0 . 997 log \ud835\udc45 [\ufffd] \ud835\udc56 \ud835\udefe\ud835\udc56 \ud835\udf00 log 3 + \ud835\udc5c (1)\n\n###### \u2a7e 0 . 997 \u00b7 [(][lo][g][ 2][)][2]\n\n(C.8)\n_\ud835\udc58_ _[,]_\n\n[lo][g][ 2][)]\n\n_[\ud835\udf00][\ud835\udc51]_\n4 log 3 [(][1][ \u2212] _[\ud835\udefe]_ [)] _\ud835\udc58_\n\nusing\n\n###### \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56 \u2a7e [(][lo][g][ 2][)][2]\n\n_\ud835\udefd\ud835\udc56_ _\ud835\udc58_ [2]\n\n[ 2][)][2] _\ud835\udc51_ _\ud835\udf00_ [2]\n\n4 _\ud835\udc58_ [2]\n\nby the monotonicity shown in Theorem C.5.\nFor the last term, Lemma C.1 gives \u221a _\ud835\udc4e_ + _\ud835\udc4f_\n\n###### \ud835\udc4e + \ud835\udc4f \u2a7d \u221a\n\n###### gives \ud835\udc4e + \ud835\udc4f \u2a7d 3 \ud835\udc51 . We thus have \u221a \ud835\udc4e + \ud835\udc4f \u2a7d \u221a3 \ud835\udc51 \u2a7d 0 . 001 (1 \u2212 ) [\ud835\udf00][\ud835\udc51]\n\n_[.]_\n\n###### \ud835\udc4e + \ud835\udc4f \u2a7d \u221a\n\n###### 3 \ud835\udc51 \u2a7d 0 . 001 (1 \u2212 \ud835\udefe ) [\ud835\udf00][\ud835\udc51]\n\n(C.9)\n_\ud835\udc58_ _[.]_\n\nCombining (C.6), (C.8), and (C.9), we obtain\n\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e 2 \ud835\udf0c\ud835\udc5b\ud835\udc56\n\n0 _._ 109 (1 \u2212 _\ud835\udefe_ ) _[\ud835\udf00][\ud835\udc51]_\n\n_\ud835\udc58_\n###### \ufffd\n\n_[\ud835\udc51]_\n\n_[\ud835\udf00][\ud835\udc51]_\n_\ud835\udc58_ [\u2212] [0] _[.]_ [001][ (][1][ \u2212] _[\ud835\udefe]_ [)] _\ud835\udc58_\n\n_\ud835\udc58_\n\n###### \u2a7e [\ud835\udf00][\ud835\udc51]\n\n5 _\ud835\udc58_ [(][1][ \u2212] _[\ud835\udefe]_ [)] _[ \ud835\udf0c][\ud835\udc5b][\ud835\udc56]_\n###### \u2a7e [\ud835\udf00][\ud835\udc51]\n\n5 _\ud835\udc58_ [(][1][ \u2212] _[\ud835\udefe]_ [)] _[ \ud835\udf0c][\ud835\udefe][\ud835\udc5b][\ud835\udc56]_ _[,]_\n\n###### as claimed. \u25a1\n\n**Corollary C.12.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _and \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b. Let \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _be a valid bisection_\n###### labeling at level \ud835\udc56. Let \ud835\udefe \u2208 \ufffd0, 1 \u2212 [1000] [\ud835\udf12] [\ud835\udc58][\ud835\udc56] \ufffd, and define\n\n###### \ud835\udc51 [\ud835\udf12] \ud835\udc56 [\ud835\udc56] \ufffd, and define\n\n_\ud835\udf00_ ~~\u221a~~\n\n###### \ud835\udf0c\ud835\udefe \ufffd exp \u2212 [\ud835\udefe\ud835\udefd] 2 [\ud835\udc56] [\ud835\udc36] [\ufffd] [\ud835\udc56], \ud835\udc61 \ufffd 0 . 001 (1 \u2212 \ud835\udefe ) \ud835\udefd\ud835\udc56 \ud835\udc36 [\ufffd] \ud835\udc56. \ufffd \ufffd\n\n_Then, with probability at least_ 1 \u2212 2 _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ _[\ud835\udf0c][\ud835\udefe][\ud835\udc5b][\ud835\udc56]_ \u2212 _\ud835\udc5b\ud835\udc56_ [\u2212][2] _[, the inequality]_\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [\ud835\udf00][\ud835\udc51]\n\n5 _\ud835\udc58_ [(][1][ \u2212] _[\ud835\udefe]_ [)] _[ \ud835\udf0c][\ud835\udefe]_ _[\ud835\udc5b][\ud835\udc56]_\n\n_holds simultaneously for every vector \ud835\udc67_ \u2208{0 _,_ 1} _[\ud835\udc5b]_ _with_ \u2225 _\ud835\udc67_ \u22251 \u2a7e _\ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56, where_ _\ud835\udc3a_ [\u00af] _is the centered_\n_adjacency matrix._\n\n77\n\n_Proof._ We discretize over the admissible _\u2113_ 1 sizes. Since _\ud835\udc67_ \u2208{0 _,_ 1} _[\ud835\udc5b]_, the quantity \u2225 _\ud835\udc67_ \u22251 is\n###### an integer, so \ud835\udf0c = \u2225 \ud835\udc67 \u22251/ \ud835\udc5b\ud835\udc56 ranges over { \ud835\udc57 / \ud835\udc5b\ud835\udc56 : \ud835\udc5a 0 \u2a7d \ud835\udc57 \u2a7d \ud835\udc5b\ud835\udc56 }, where \ud835\udc5a 0 \ufffd \u2308 \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56 \u2309. Fix \ud835\udc57 \u2208{ \ud835\udc5a 0, . . ., \ud835\udc5b } and set \ud835\udf0c = \ud835\udc57 / \ud835\udc5b\ud835\udc56 \u2a7e \ud835\udf0c\ud835\udefe . By Lemma C.11 (applied with our choice of \ud835\udf0c ), with\n\nprobability at least 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61][\ud835\udf0c][\ud835\udc5b][\ud835\udc56]_ \u2212 _\ud835\udc5b\ud835\udc56_ [\u2212][3] = 1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61\ud835\udc57]_ \u2212 _\ud835\udc5b\ud835\udc56_ [\u2212][3][, we have]\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [\ud835\udf00][\ud835\udc51] for all \ud835\udc67 \u2208{0, 1} [\ud835\udc5b] with \u2225 \ud835\udc67 \u22251 = \ud835\udc57.\n\n5 _\ud835\udc58_ [(][1][ \u2212] _[\ud835\udefe]_ [)] _[ \ud835\udf0c][\ud835\udefe]_ _[\ud835\udc5b][\ud835\udc56]_\n\nTaking a union bound over all _\ud835\udc57_ \u2208{ _\ud835\udc5a_ 0 _, . . ., \ud835\udc5b\ud835\udc56_ }, the total failure probability is at most\n\n_\ud835\udc5b\ud835\udc56_\n###### \ufffd\n\n_\ud835\udc57_ = _\ud835\udc5a_ 0\n\n_\ud835\udc52_ [\u2212] _[\ud835\udc61\ud835\udc5a]_ [0]\n###### \ufffd \ud835\udc52 [\u2212] [\ud835\udc61\ud835\udc57] + \ud835\udc5b\ud835\udc56 [\u2212][3] \ufffd \u2a7d\n\n###### [\ud835\udc5a] [0][ +][ 1] \u2a7d 2 \ud835\udc52 [\u2212] [\ud835\udc61][\ud835\udf0c][\ud835\udefe][\ud835\udc5b][\ud835\udc56] + [1]\n\n_\ud835\udc5b_ [3] _\ud835\udc5b_\n_\ud835\udc56_\n\n_\ud835\udc52_ [\u2212] [0] _[\ud835\udc5b][\ud835\udc56]_ [\u2212] _[\ud835\udc5a]_ [0][ +][ 1]\n\n1 \u2212 _\ud835\udc52_ [\u2212] _[\ud835\udc61]_ [+] [3]\n\n_._\n_\ud835\udc5b_ [2]\n_\ud835\udc56_\n\nOn the complementary event, the claimed lower bound holds simultaneously for all sizes\n###### \ud835\udc57 \u2a7e \ud835\udc5a 0, and hence for every \ud835\udc67 \u2208{0, 1} [\ud835\udc5b] with \u2225 \ud835\udc67 \u22251 \u2a7e \ud835\udf0c\ud835\udefe\ud835\udc5b\ud835\udc56, as desired. \u25a1\n\nNow we conclude the proof of the majority voting lower bound of bisections.\n\n**Theorem** (Restatement of Theorem 4.3) **.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _, \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b, and \ud835\udc58\ud835\udc56_ = _\ud835\udefd\ud835\udc56_ _\ud835\udc58._\n###### Let \ud835\udefe \u2208[0, 0 . 99] . Choose \ud835\udf0c\ud835\udefe \ufffd exp(\u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\u02dc] \ud835\udc56 /2), and set \ud835\udc61 = 0 . 001(1 \u2212 \ud835\udefe ) \ud835\udc36 [\u02dc] \ud835\udc56. Then with probability\n\n_at least_ 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [1][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, and for every valid bisections][ \ud835\udc66]_ [\u2208{][0] _[,]_ [ \u00b1][1][}] _[\ud835\udc5b]_ _[at]_\n\n_level \ud835\udc56. we have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b\ud835\udc56_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n_Proof._ We first prove the claim for fixed bisection _\ud835\udc66_ . When the size of the set is at least _\ud835\udf0c\ud835\udefe\ud835\udc5b_,\nthe lower bound easily follows from Theorem C.12. When the size of the set is at most _\ud835\udf0c\ud835\udefe\ud835\udc5b_,\nthe lower bound follows from Theorem C.10 with probability 1 \u2212 exp(\u2212 _\ud835\udf00_ [2] _\ud835\udc51_ / _\ud835\udc58_ ), as \u2225 _\ud835\udc67_ \u22251 \u2a7e 0.\n###### From the proof of Theorem C.5, we know that \ud835\udefd\ud835\udc56\ud835\udc36 [\u02dc] \ud835\udc56 \u2a7e \u03a9( \ud835\udf00 [2] \ud835\udc51\ud835\udc56 / \ud835\udc58\ud835\udc56 [2][)][ \u2a7e] [\u03a9][(][2] [\ud835\udc56] [log][(] [\ud835\udc58] [))][. It follows] that \ud835\udc36 [\u02dc] \ud835\udc56\ud835\udf0c\ud835\udefe\ud835\udc5b \u2a7e 100 \ud835\udc58 log( \ud835\udc58 ). Since there are at most 2 [2] [\ud835\udc58] possible choices for community bisections \ud835\udc66, we can take union bound and the claim follows. \u25a1\n\nFinally we give the bound for larger values of _\ud835\udefe_ which will be helpful for obtaining the\noptimal recovery rate in the final _\ud835\udc58_ -clustering.\n\n**Theorem** (Restatement of Theorem 4.5) **.** _Let \ud835\udc36\ud835\udc51,\ud835\udf00_ = ( [\u221a] _\ud835\udc4e_ \u2212 ~~\u221a~~\n\n_\ud835\udc4f_ ) [2] _. Let \ud835\udefe_ \u2208[0 _,_ 1 \u2212 [1000] _[\ud835\udf12][\ud835\udc58]_\n\n_\ud835\udf00_ ~~\u221a~~\n\n_\ud835\udc51_ []] _[. Choose]_\n\n###### \ud835\udf0c\ud835\udefe \ufffd exp(\u2212 \ud835\udefe\ud835\udc36\ud835\udc51,\ud835\udf00 / \ud835\udc58 ) . Then with probability at least 1 \u2212 exp(\u2212100 \ud835\udc58 ) \u2212 \ud835\udc5b [1][3] [, for every][ \ud835\udc67] [\u2208{][0] [,] [ 1][}] [\ud835\udc5b][,]\n\n_and for every pair of communities \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _. We have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a\ud835\udc66 [\u00af] \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n78\n\n_Proof._ The proof is very similar to Theorem 4.3. However, now for the probability bound,\n###### we only need to use \ud835\udf0c\ud835\udefe\ud835\udc5b \u2a7e 1 and \ud835\udc36 \u2a7e 100 \ud835\udc58, and we only need to take union bound over \ud835\udc58 [2] pairs of communities. \u25a1\n\n**Corollary** (Restatement of Theorem 4.4) **.** _Fix a level \ud835\udc56_ _and set \ud835\udefd\ud835\udc56_ = 2 [\u2212] _[\ud835\udc56]_ _, \ud835\udc5b\ud835\udc56_ = 2 _\ud835\udefd\ud835\udc56\ud835\udc5b, and_\n###### \ud835\udc58\ud835\udc56 = \ud835\udefd\ud835\udc56 \ud835\udc58. Let \ud835\udefe \u2208[0, 0 . 99] . Choose \ud835\udf0c\ud835\udefe \ufffd exp(\u2212 \ud835\udefe\ud835\udefd\ud835\udc56\ud835\udc36 [\u02dc] \ud835\udc56 /2), and set \ud835\udc61 = 0 . 001(1 \u2212 \ud835\udefe ) \ud835\udc36 [\u02dc] \ud835\udc56. Then with\n\n_probability at least_ 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [2][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, for every][ \ud835\udc60]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b]_ _[such that]_\n\n\u2225 _\ud835\udc60_ \u22251 \u2a7e (1 \u2212 exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ )) _\ud835\udc5b, and for every valid bisections \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _at level \ud835\udc56, we have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc60\ud835\udc60 [\u22a4] ) \ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n16 _\ud835\udc58_\n\n640 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b\ud835\udc56_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n_Proof._ Notice that\n\n\u27e8 _\ud835\udc3a_ [\u00af] \u2299( _\ud835\udc60\ud835\udc60_ [\u22a4] ) _\ud835\udc66_ \u2299 _\ud835\udc66, \ud835\udc67_ \u27e9 = \u27e8 _\ud835\udc3a_ [\u00af] \u2299( _\ud835\udc66\ud835\udc66_ [\u22a4] ) _,_ ( _\ud835\udc67_ \u2299 _\ud835\udc60_ ) _\ud835\udc60_ [\u22a4] \u27e9\n\n= \u27e8 _\ud835\udc3a_ [\u00af] \u2299( _\ud835\udc66\ud835\udc66_ [\u22a4] ) _,_ ( _\ud835\udc67_ \u2299 _\ud835\udc60_ ) **1** [\u22a4] \u27e9\u2212\u27e8 _\ud835\udc3a_ [\u00af] \u2299( _\ud835\udc66\ud835\udc66_ [\u22a4] ) _,_ ( _\ud835\udc67_ \u2299 _\ud835\udc60_ )( **1** \u2212 _\ud835\udc60_ ) [\u22a4] \u27e9 _._\n\nBy Theorem 4.3, it follows that, with probability 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [1][3] [,]\n\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc66\ud835\udc66 [\u22a4] ), ( \ud835\udc67 \u2299 \ud835\udc60 ) 1 [\u22a4] \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u2299 _\ud835\udc60_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n###### \ufffd\n\n###### \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\u2225 **1** \u2212 _\ud835\udc60_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n###### \ufffd\n\n###### \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n\u2225 _\ud835\udc67_ \u22251 \u2212 exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ ) _\ud835\udc5b_ \u2212 96 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_._\n###### \ufffd\n\n###### \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n200 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\nBy Theorem C.7, it follows that, with probability 1 \u2212 _\ud835\udc5b_ [1][3]\n\n_._\n###### \ufffd \u25a1\n\n100 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 +\n###### \ufffd 1 \u2212 \ud835\udefe\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc66\ud835\udc66 [\u22a4] ), ( \ud835\udc67 \u2299 \ud835\udc60 )( 1 \u2212 \ud835\udc60 ) [\u22a4] \u27e9 \u2a7d \u221a\n\n2 _\ud835\udc51_ (\u2225 _\ud835\udc67_ \u22251 + exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ ) _\ud835\udc5b_ ) \u2a7d [(][1][ \u2212] _[\ud835\udefe]_ [)] _[\ud835\udf00][\ud835\udc51]_\n\n16 _\ud835\udc58_\n\nTherefore, with probability 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [2][3] [,]\n\n###### \ufffd\n\n100 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 +\n###### \ufffd 1 \u2212 \ud835\udefe\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc60\ud835\udc60 [\u22a4] ) \ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n8 _\ud835\udc58_\n\n###### \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n16 _\ud835\udc58_\n\n200 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n640 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n79\n\n\u2212 [(][1][ \u2212] _[\ud835\udefe]_ [)] _[\ud835\udf00][\ud835\udc51]_\n\n16 _\ud835\udc58_\n###### \ufffd\n\n_._\n###### \ufffd\n\n**Corollary** (Restatement of Theorem 4.6) **.** _Let \ud835\udefe_ \u2208[0 _,_ 1 \u2212 [1000] _[\ud835\udf12][\ud835\udc58]_\n\n_\ud835\udf00_ ~~\u221a~~\n\n###### \ud835\udc51 []] [. Choose][ \ud835\udf0c][\ud835\udefe] [\ufffd] [exp][(\u2212] [\ud835\udefe][\ud835\udc36] [)] [.]\n\n_Then with probability at least_ 1 \u2212 exp(\u2212100 _\ud835\udc58_ ) \u2212 _\ud835\udc5b_ [2][3] _[, for every][ \ud835\udc67]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b][, for every][ \ud835\udc60]_ [\u2208{][0] _[,]_ [ 1][}] _[\ud835\udc5b]_\n\n_such that_ \u2225 _\ud835\udc60_ \u22251 \u2a7e (1 \u2212 exp(\u22122 _\ud835\udc36\ud835\udc51,\ud835\udf00_ )) _\ud835\udc5b, and for every pair of communities \ud835\udc66_ \u2208{0 _,_ \u00b11} _[\ud835\udc5b]_ _. We have_\n\n_,_\n###### \ufffd\n\n###### \u27e8 \ud835\udc3a [\u00af] \u2299( \ud835\udc60\ud835\udc60 [\u22a4] ) \ud835\udc66 \u2299 \ud835\udc66, \ud835\udc67 \u27e9 \u2a7e [(][1][ \u2212] [\ud835\udefe] [)] [\ud835\udf00][\ud835\udc51]\n\n16 _\ud835\udc58_\n\n640 _\ud835\udf0c\ud835\udefe_ _\ud835\udc58\ud835\udc5b_\n\u2225 _\ud835\udc67_ \u22251 \u2212\n###### \ufffd 1 \u2212 \ud835\udefe\n\n_where_ _\ud835\udc3a_ [\u00af] _is the centered adjacency matrix._\n\n_Proof._ The proof is very similar to Theorem 4.4. The only difference is that the voting lower\n###### bound is via Theorem 4.5. \u25a1\n\n80"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an iterative, multi-stage refinement of community assignments. It first establishes a 'rough' clustering, then recursively bisects the graph, and finally boosts accuracy using pairwise 'majority voting' \u2014 all within a 'Sum-of-Squares' (SoS) optimization framework that intrinsically encodes robustness to noisy and corrupted data.\n\n**Explanation:** We're tasked with identifying hidden community structures (like 'k' groups) in a network graph, where nodes within a community connect more frequently. The major challenge is that the observed graph might be corrupted by an 'adversary' who arbitrarily alters connections for a fraction of nodes, breaking assumptions of standard algorithms. The solution employs a Sum-of-Squares (SoS) approach. SoS is a powerful mathematical proof system that, when a property (like 'this node belongs to community A') can be 'proven' with low-degree polynomials, can automatically generate an efficient (polynomial-time) algorithm to find solutions satisfying that property. Here's how it works intuitively: 1.  **Modeling Truth and Corruption:** The algorithm sets up polynomial constraints that represent valid community structures (`Alabel`) and also a 'mask' (`xi`) for potentially corrupted nodes. It requires the *uncorrupted* part of the observed graph to behave according to the expected statistical model. This is like filtering out known bad data rows in a database query before analysis. 2.  **Rough Initialization:** It first finds an initial, 'good enough' clustering (analogous to a simple greedy loop or a hash map setup for initial assignment) that's resilient to some noise, thanks to the SoS constraints. 3.  **Recursive Bisection (Divide and Conquer):** Instead of directly finding 'k' communities, it recursively splits the graph in half, determining which of two large super-communities each node belongs to. This is a binary decision (like `if (node_feature > threshold) then assign_left else assign_right`). Each bisection step refines the assignments. 4.  **Robust Majority Voting (Refinement):** The key to high accuracy is 'majority voting.' For any pair of communities, or during a bisection, a node's assignment is considered 'consistent' if it matches the majority label of its neighbors. The SoS framework includes 'majority-vote consistency' constraints (`Amaj`). These constraints mathematically enforce that the observed connections support the chosen labels, making it hard for local noise or corruption to significantly flip outcomes. It's not just a simple count; it ensures that expected 'signal' (connections within a community) strongly outweighs 'noise.' The mechanism reveals that adversarial alterations can be 'contained' by the robust spectral properties enforced by SoS, preventing them from propagating widely. By iteratively applying this robust bisection and voting, the algorithm effectively 'boosts' its accuracy, reaching the theoretically best possible (minimax) error rate. This works because SoS constraints, through polynomial inequalities, effectively 'refute' (prove impossible) any solution that deviates too much from the true underlying structure or that is too affected by corruption."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_rpsi,j_ ( _si_ ( _j_ ) _, sj_ ( _i_ )) = _i for all j \u2208_ _`UndecidedNeighbors`_ **then**\n\n**19** Output 1 (join MIS);\n\n```\n   /* Round 3: Observe Undecided Neighbors\u2019 Outputs */\n```"}, {"role": "assistant", "content": "**Mechanism:** This describes a distributed local consensus loop where a node 'i' conditionally decides to join a Maximal Independent Set (MIS). Node 'i' iterates through its set of 'UndecidedNeighbors' (like a 'for-each' loop over a list of peer IDs). For each neighbor 'j', it evaluates a function, `_rpsi,j_`, which likely processes exchanged local states or 'signals' (`_si_(j)` and `_sj_(i)`). The critical mechanism is that *all* such evaluations must resolve to 'i' (meaning 'i' is the designated winner or preferred node in that pairwise context) for 'i' to proceed. It's a unanimous local 'vote' based on a deterministic outcome of state comparisons.\n\n**Explanation:** Essentially, a node `i` is trying to figure out if it's 'safe' to join the MIS. It checks with all its direct neighbors who haven't yet made up their minds. Think of it like a series of small, local computations. For every undecided neighbor `j`, node `i` performs a calculation using some information `j` has about `i` and `i` has about `j`. If *every single one* of these calculations points back to `i` being the designated node (e.g., `i` has the highest ID or some other agreed-upon priority), then `i` gives itself the green light to join the MIS. If even one undecided neighbor's calculation doesn't 'approve' `i` in this specific way, `i` cannot join in this round."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nZebra-CoT (Li et al., 2025a) 18,000 GPT 4.1 and Gemini 2.5 pro (Only used for 2 18,000\n**Image**\nrefinement)\n\n**Total (Image Data)** **18,000** **Total (Image Models)**"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves large-scale, automated data generation and targeted curation using sophisticated pre-trained language models. Think of it as a primary 'data population' routine executed by GPT 4.1 that iterates 18,000 times, creating a base set of image-related data entries. Subsequently, a highly specialized, minimal 'data quality assurance' subroutine, or a 'patch function', is invoked using Gemini 2.5 pro. This secondary model is not for bulk generation but rather for specific, fine-grained adjustments or enhancements, indicated by '2 refinement,' implying a very limited number of targeted corrections or specific improvement tasks on a subset of the data.\n\n**Explanation:** This setup is like running a massive data pipeline where the heavy lifting of generating 18,000 individual data records (each representing 'image data') is handled by a primary, powerful model, GPT 4.1. This model acts as a highly capable 'data generator' that understands complex patterns. Then, a second, equally advanced model, Gemini 2.5 pro, is employed for extremely selective 'refinement'. This isn't about generating more data; it's akin to a dedicated 'error correction' or 'semantic tuning' function that's called only for a very specific, limited number of items or tasks (implied by '2 refinement'), perhaps to fix obscure inconsistencies or align with niche criteria. The combined output is a dataset of 18,000 refined image data points."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThere are different directions in literature around the performance assessment of MPTCP and its underlying packet\n\nscheduling and congestion control algorithms. Some works maintain the default MPTCP algorithm configuration (e.g.,\n\nminRTT packet scheduler and (O)LIA congestion control) and examine the impact of the various (MP)TCP protocol\n\nparameters (e.g., send/receive buffer size, SACK, TCP auto-tuning, etc.) on the overall MPTCP performance. Another\n\ndirection is focusing on a specific research area (e.g., on packet scheduling) and assessing how the various algorithms of\n\nthis particular domain perform, while keeping the default configuration in other protocol areas (e.g., default congestion\n\ncontrol and/or default (MP)TCP parameters). Finally, there is a limited number of works assessing how the various\n\nalgorithm combinations affect MPTCP protocol operation. Our work is positioned to this latter case, coupling the\n\ntheoretical aspects with an extensive performance assessment of the state-of-art packet scheduling and congestion\n\ncontrol algorithms. Our manuscript\u2019s motivation and distinctive aspects are described hereinafter.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 39\n\nThe performance evaluation conducted within [1] has been one of the first attempts to quantify the impact that\n\nvarious factors may impose on MPTCP performance (i.e., the buffer size, packet loss, the MSS-size). Besides evaluating\n\nthe impact of a single parameter (i.e., BW, RTT delay, or packet loss) on MPTCP performance, our work considers also\n\na mixture of these parameters and examines how these affect factors other than merely goodput, such as the SRTT,\n\nthe OFO-queue size, and the number of retransmissions. Moreover, our experiments go beyond the default MPTCP\n\npacket scheduling (minRTT), and Reno / Coupled (LIA) congestion control schemes, assessing a variety of schedulers\n\nand congestion control algorithm combinations. [71] implements the first framework which enables loading packet\n\nscheduling and congestion control algorithms as modules, allowing algorithm alternations at runtime. Experimental\n\nevaluation there, is conducted using minRTT scheduler, both for bulk transfer and application-limited traffic. On\n\nthe contrary, our work examines a bunch of modern packet scheduling and congestion control schemes. [43] is a\n\ncomprehensive work trying to measure the extent to which MPTCP is beneficial compared to single-path TCP under\n\ndifferent scenarios. The authors consider minRTT scheduler combined with Coupled (LIA) CCA for MPTCP, and Cubic\n\nCCA for SP-TCP, while our work examines multiple packet scheduling and congestion control algorithm combinations.\n\nAnother difference is the fact that the experiments conducted throughout [43] consider variable traffic size and higher\n\n5G bandwidths close to 1Gbps; our work seeks to provide foundational details behind the operation of schedulers and\n\nCCA combinations, thus selected to keep a static length-based traffic approach (iperf traffic tries to fill in resources for\n\n30 sec. test duration) and cap bandwidth to 100Mbps per subflow in order to be able to identify basic discrepancies and\n\ninefficiencies within the algorithms, which might be invisible in high data rates. [46] focuses on the development of a\n\nnew scheduler (STTF) while assessing it against other packet scheduling algorithms (i.e., minRTT, BLEST, ECF, DAPS\n\n[61], OTIAS [91]) under various traffic conditions. However, packet schedulers are compared to one another using\n\nonly the default MPTCP congestion control algorithm, which was Coupled (LIA). [76] provides a high level overview\n\non the advancements of transport layer protocols, a classification of the various congestion control schemes and a\n\nshort description of them, as well as details around the various multipath protocols. In a different direction, our work is\n\nfocused on a limited number of packet scheduling and congestion control schemes, providing an in-depth analysis of\n\ntheir internal operation as well as the detailed algorithmic steps. Furthermore [76] is a theoretical survey, while our\n\nwork is an experimental manuscript, combining theory with experimental evaluation of the algorithms under review. As\n\nmentioned earlier, part of our work has been inspired by the work conducted in [13], especially regarding the visibility\n\nof the results in a combined figure including goodput, SRTT, OFO queue size, and the number of retransmissions. [13]\n\nalso provides a short description as well as the algorithmic steps of some packet scheduling algorithms (i.e., minRTT, RR,\n\nMuSher [80], BLEST, ECF, STTF [46]), and examines their performance in conjunction with some congestion control\n\nschemes (i.e., LIA, OLIA, BALIA, wVegas). However, it modifies the send and receive buffers to identify their impact on\n\nperformance, while we selected to maintain the default values in order to focus mainly on the underlying algorithms\u2019\n\nperformance, and to avoid blending many factors which could further affect performance results. In addition, our work\n\nincludes the latest BBR and C-MPBBR congestion control schemes and tries to further analyze the results by introducing\n\nnovel metrics, in an attempt to directly assess all possible combinations and extract the best-performing ones. Another\n\nextensive experimental survey has been provided through the work conducted in [60]. The authors of this work provide\n\na comprehensive analysis of packet scheduling schemes along with a classification based on their use cases and the\n\nnumber of scheduling criteria considered by each algorithm. Their work has also influenced the design of our own\n\nexperimentation strategy, and considers a nearly-exhaustive list of packet schedulers and CCAs. However, the authors\n\nof that work examine different packet scheduling and a subset of the congestion control algorithms we use in our own\n\nexperiments (i.e., _\ud835\udc43\ud835\udc46\ud835\udc34\ud835\udc60_ = { _\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc45\ud835\udc47\ud835\udc47, \ud835\udc45\ud835\udc45, \ud835\udc3f\ud835\udc4a\ud835\udc46, \ud835\udc3f\ud835\udc47\ud835\udc46, \ud835\udc3b\ud835\udc46\ud835\udc45_ } and _\ud835\udc36\ud835\udc36\ud835\udc34\ud835\udc60_ = { _\ud835\udc3f\ud835\udc3c\ud835\udc34, \ud835\udc35\ud835\udc34\ud835\udc3f\ud835\udc3c\ud835\udc34,\ud835\udc42\ud835\udc3f\ud835\udc3c\ud835\udc34,\ud835\udc64\ud835\udc49\ud835\udc52\ud835\udc54\ud835\udc4e\ud835\udc60_ }, respectively).\n\n40 D. Dimopoulos, et al."}, {"role": "assistant", "content": "**Mechanism:** MPTCP allows a single data stream to use multiple independent network paths (subflows) concurrently. The core mechanisms at play are 'packet scheduling' and 'congestion control'. Packet scheduling is analogous to a load balancer, deciding which packet is transmitted over which subflow, akin to how a priority queue or round-robin logic might dispatch tasks. Congestion control, on each subflow, acts as a feedback loop, adjusting the sending rate based on network conditions (loss, RTT) using algorithms that resemble dynamic rate limiters or adaptive windowing functions. This paper systematically evaluates the cross-product of various modern scheduling and congestion control algorithms, effectively performing an n-dimensional search across their behavioral space.\n\n**Explanation:** The novelty lies in analyzing the *interaction* of these fundamental algorithmic components rather than just tweaking environmental parameters (like buffer sizes). By using static traffic patterns and capped bandwidths, the researchers isolate the intrinsic behaviors of these algorithmic combinations. For instance, a poor packet scheduler might consistently direct too many packets to a slower subflow, leading to high 'out-of-order' queue sizes (like a hash map filling up with items waiting for their predecessors) and increased retransmissions, even if the individual congestion control algorithms are working as expected. The chosen metrics (SRTT, OFO-queue size, retransmissions beyond mere goodput) provide a granular view into the efficiency and robustness of these coupled mechanisms. For example, a high OFO queue directly implies that the scheduler or CC is leading to non-sequential packet arrivals, forcing the receiver to hold packets (buffer) and increasing processing latency, similar to how a database transaction might stall waiting for an out-of-order write to complete."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**3.1** **Evolutionary Algorithms**\n\nEvolutionary algorithms have long been a compelling alternative to backpropagation-based training methods.\nDespite encompassing a broad range of algorithms (e.g., genetic algorithms (Such et al., 2018) or symbolic\nevolution (Koza, 1994)), most contemporary research on evolution has shifted towards algorithms that scale\nbetter to large numbers of neural network parameters (Jaderberg et al., 2017; Hansen & Ostermeier, 2001;\nSalimans et al., 2017).\n\nOur work focuses on evolving the weights of predetermined architectures, building up from the NES (Wierstra\net al., 2011) family of methods. Such an approach has recently grown in prominence, following the application\nof NES to policy learning in conventional RL environments (Salimans et al., 2017) to alleviate some of the\nchallenges that policy-gradient methods struggle with, like long-horizon environments. Since then, evolution\nhas been widely applied in other domains, such as meta-learning (e.g., (Lu et al., 2022; Metz et al., 2022; Lange\net al., 2023; Goldie et al., 2024; 2025)), hyperparameter tuning (e.g., (Parker-Holder et al., 2021; Tani et al.,\n2021; Vincent & Jidesh, 2023)) and drug discovery (Towers et al., 2025). Here, we consider the limitations\nand solutions to applying ES at significant scale, beyond the small networks and population sizes of these prior\nworks, with a broad focus on policy-learning. In particular, Salimans et al. (2017) uses a maximum population\nsize of 1440, whereas our maximum population size is on the order of hundreds of thousands.\n\nES is limited by its requirement for full, potentially expensive evaluations of the fitness function due to\nsimulating policies in long-horizon environments and potentially high memory usage. Persistent Evolution\nStrategies (Vicol et al., 2021) demonstrate a significant speedup by updating networks _online_ (i.e., during the\nunroll), with followups offering further variance reduction (Li et al., 2023b; Vicol et al., 2023). We note that\nthese works are orthogonal to our focus on scaling up the population size of ES; we leave the application of\nthese techniques on top of EGGROLL to future work.\n\n**3.2** **Evolution Strategies for LLMs**\n\nAlthough gradient backpropagation is typically used for LLM training and fine-tuning, prior work has explored\nES variants for fine-tuning. In particular, zeroth order optimization (Zhang et al., 2024), which is analogous to\nES with a population size of 1, is used by Malladi et al. (2023) for memory-efficient LLM fine-tuning. Yu et al.\n(2025) extend this approach by projecting perturbations to a low-rank subspace, improving the convergence\nof zeroth order optimization. Jin et al. (2024) performs ES directly on LoRA matrices. These works focus\non the supervised fine-tuning setting, finding comparable performance to full fine-tuning, but they do not\ndetermine whether pretraining is possible with zeroth order methods; we find that large population sizes are\nnecessary for pretraining performance, indicating that zeroth order optimization methods would be unsuitable\nfor pretraining.\n\nRecent work has also explored ES in the context of LLM reasoning. Korotyshova et al. (2025) first train\nLoRA adapters using supervised fine-tuning (SFT) before decomposing them into fixed SVD bases alongside\nsingular values that are trained using CMA-ES. They achieve comparable performance to GRPO (Shao et al.,\n2024) in significantly less wall-clock time on math reasoning benchmarks. Qiu et al. (2025) directly use ES\nto optimize all LLM parameters for reasoning, with stronger performance than GRPO on the countdown\nreasoning task. However, both of these approaches use relatively small population sizes, on the order of a\nhundred unique perturbations per update, and instead collect hundreds of rollouts per perturbation to efficiently\nuse GPUs. By contrast, our approach allows all generations to use different perturbations, such that our\nmaximum population size per update is orders of magnitude larger (equal to the maximum inference batch\nsize), without compromising token generation throughput."}, {"role": "assistant", "content": "**Mechanism:** Evolutionary Strategies (ES) function as a gradient-free optimization method. Instead of computing the exact gradient of a loss function, ES samples a population of 'perturbations' around a candidate solution. Each perturbed solution's 'fitness' (performance) is evaluated, and these fitness scores are used to estimate a 'gradient' (or update direction) for the original candidate solution. This process is iteratively refined: the candidate solution is updated, and a new population of perturbations is sampled around the improved candidate. This mechanism is essentially a parallel search and refinement loop, where the 'direction' of improvement is inferred from the relative performance of many diverse attempts. This paper scales this mechanism by dramatically increasing the population size in each iteration, allowing for a much broader exploration of the parameter space simultaneously.\n\n**Explanation:** The core idea here is to enable a brute-force-like exploration of complex solution spaces that are difficult for traditional gradient-based methods to navigate. For problems with extremely high dimensionality (many parameters) or non-smooth objective functions, a small, localized gradient estimate might lead to suboptimal solutions. By increasing the population size from hundreds to hundreds of thousands, the algorithm can 'sample' a much larger and more diverse set of parameter variations. This wider sampling provides a more robust estimate of the true direction towards better performance, effectively allowing the algorithm to 'jump' over local minima and find better global solutions. For tasks like pretraining large language models, where the search space is vast and highly non-convex, this massive parallel exploration becomes a viable alternative to the more delicate, sequential steps of backpropagation, especially if the objective function is computationally expensive to differentiate but cheap to evaluate."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe followed the qualitative case study guidelines established by\nRuneson and H\u00f6st et al. [30], and aligned our study design and\nreporting with the empirical standards proposed by Ralph et al. [28]\nto ensure transparency, triangulation, and validity (see Figure 1).\n\n**Figure 1: Research method followed.**\n\n2\n\n![](papers/images/Data-Annotation-Quality-Problems-in-AIEnabled-Perception-System-Development.pdf-1-0.png)\nData Annotation Quality Problems in AI-Enabled Perception System Development,,\n\n**Research Context** This study is part of Project X, which aims\nto enhance academia-industry collaboration by developing concepts, models, and techniques for effective and safe AIePS productions. We conducted 19 semi-structured interviews [30] with 20\nparticipants from industry and academia. These interviews were\nperformed online between October 2024 and April 2025, each lasting \u2265 120 minutes. ID16 participated in two separate interviews\n(labelled 16A and 16B), each lasting approximately four hours. In\ncontrast, participants ID18 and ID19 took part in a single focus\ngroup session, counted as one interview (see Table 1). In total, this\namounts to over _**50 hours of rich transcripts**_ . Using purposeful\nsampling [28], we selected participants based on their roles, organisational context, and experience with data annotation or AI model\ndevelopment in autonomous driving. Interviews were recorded,\ntranscribed, manually corrected, and concluded with participant\nfeedback. This approach ensured diverse and in-depth insights into\nannotation quality, associated errors, and their impact on the AIePS\ndevelopment life cycle.\n**Companies Context** To capture diverse perspectives, we conducted fourteen interviews with representatives from six companies engaged in AIePS development. We included the entire supply\nchain: one OEM, three Tier-1 suppliers, two Tier-2 suppliers, a\nperception training company, and a code analysis firm, all based in\ntwo European countries and the UK.\nAdditionally, five interviewees from four research institutes,\nincluding a state-owned European institute and leading universities from Europe and the UK, helped bridge theory and practice\nacross AI, data annotation, quality, and regulation. Thematic Saturation was reached with Interview 15, with no new information or\ncandidate themes emerging in Interviews 16, 17, 18, and 19.\n**Participants** As shown in Table 1, targeted experts included\nleading contributors to AIePS, such as safety standard developers,\nfounders of relevant companies, and the chief investigator of toptier research labs, ensuring deep domain expertise. This is a niche\ndomain where only a few globally recognised organisations and\nexperts are active. We deliberately reached out to these leading\nactors and succeeded in including the most relevant and established\nexperts in this emerging field.\n**Interview Preparation:** A semi-structured interview guide [28]\nwas developed iteratively by four researchers in collaboration with\nthree industrial experts experienced in data annotation and AIePS,\nthereby establishing content validity. The guide featured openended, neutral, and clear questions aligned with the research questions and relevant literature presented in the background and related work section 2. To enhance clarity, structure, and duration, the\nguide was piloted with two independent industry partners (not part\nof the final study), representing annotation requirements (Tier 1)\nand production (Tier 2), whose feedback informed refinements. (For\ndetails, see: \u2192 [Interview Guide)](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n**Data Analysis:** We applied a six-phase thematic analysis process following Braun and Clarke _et al._ [5]. The analysis was guided\nby a combined deductive\u2013inductive codebook, and the units of\nanalysis were 19 interview transcripts, each coded in text chunks\nof approximately three sentences. Across all transcripts, about 1050\ntext segments (coded units) were analysed.\n**(1) Familiarisation:** Two researchers transcribed, anonymised,\nand validated all interviews to ensure ethical integrity and data\n\n**Table 1: Categorisation of interviewees based on company**\n**type and specialisation, including their roles and years of**\n**experience**\n\n**Company ID: Type** **Focus Area** **Expert (Years of Experience)**\n\nA: Tier 2 Data Annotation ID1: Annotation Expert (6)\nID2: Perception Expert (10)\nID3: Quality Expert (9)\n\nB: Tier 1 Safety Software ID4: Machine Learning Expert (7)\nID5: Data Scientist (11)\n\nC: University Research ID6: Senior Researcher (9)\n\nD: University Research ID7: Researcher (8)\n\nE: University Research ID8: Researcher (5)\n\nF: Research Institute Research ID9: Researcher (10)\nID10: Researcher (20)\n\nG: OEM Automotive ID11: Machine Learning Expert (5)\nID12: V&V Expert (5)\nID13: Data Engineer (4)\nID14: Researcher (3)\n\nH: Tier 1 Safety Software ID15: Researcher (10)\n\nI: Tier 2 Quality Assurance ID16 A: Quality Expert (18)\nI: Tier 2 Quality Assurance ID16 B: Quality Expert (18)\n\nJ: Tier 1 Digital Solution ID17: Head of Research (17)\nID18,19: Research Engineer (1,2)\n\naccuracy. Through multiple readings, they familiarised themselves\nwith the data, developing an initial understanding of emerging\npatterns and potential themes.\n**(2) Initial Coding:** A deductive codebook was first developed\nbased on the research questions and interview guide (see:\u2192 [Code-](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n[book and \u2192](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8) [Codebook-Aligned Initial Codes). During open coding,](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\ninductive codes were added as new insights emerged. Each transcript (ID1\u2013ID19) was coded systematically, resulting in a compre[hensive set of detailed codes extracted from all interviews (see: \u2192](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n[Complete List of Emerging Codes from Transcripts).](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n**(3) Code Validation:** Two researchers independently coded all\ntranscripts and cross-verified results, achieving a strong inter-coder\nreliability (Cohen\u2019s _\ud835\udf05_ = 0 _._ 8) corresponding to 80% agreement. The\nremaining minor differences (about 20%) were resolved through\ndiscussion and consensus, ensuring the consistency and credibility\nof the coding process.\n**(4) Theme Development:** All codes were clustered into potential themes, related to the three key data quality dimensions\n_Completeness, Consistency, and Accuracy_ and aligned with the predefined research questions (see: \u2192 [Detailed Themes Development).](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\nA consolidated analysis produced an initial _Master List of Data_\n_Annotation Errors_, capturing all identified errors across the AIePS\ndevelopment lifecycle. The master list compiles identified errors organised by their nature, frequency, and impact, with representative\nexamples forming the basis for the final taxonomy of annotation\n\nerrors.\n\n**(5) Theme Refinement:** The five researchers collaboratively\nreviewed, merged, and refined overlapping codes through a threestage iterative process to ensure analytical robustness. In the first\nround, all codes within each theme were compiled, and their frequencies ( _i.e.,_ the number of mentions across interviews were\nrecorded. Across the three quality dimensions, we identified 23\ncodes under _Completeness_, 23 under _Consistency_, and 18 under _Ac-_\n_curacy_ . In the second round, codes mentioned three times or fewer\n\n3\n\n,, Saeeda et al.\n\nwere classified as low-frequency. In the final round, these were\nremoved, retaining only the most recurrent data annotation errors\nconsistently mentioned by multiple experts. This resulted in six\nhigh-frequency codes for _Completeness_, seven for _Consistency_, and\nfive for _Accuracy_ (see: \u2192 [Final Refine Data Annotation Errors List).](https://dataverse.harvard.edu/previewurl.xhtml?token=da9478c0-7653-48cb-bc5f-b8ae1d0810e8)\n**(6) Reporting:** The final themes and associated codes were\nverified, documented, and linked with representative quotes to\nmaintain transparency and traceability. Five researchers collaboratively reviewed the complete analysis using Excel, OneDrive, and\nMiro, ensuring structured documentation and analytic rigour.\n**Replication Package:** We make the interview guide, codebook,\nthematic analysis themes, and validation survey available to support\nfuture researchers in replicating the study. The replication package\nis available on HARVARD Dataverse [1] ."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a systematic, iterative process for extracting structured insights from unstructured qualitative data (interview transcripts) using thematic analysis, ensuring reliability through inter-coder agreement and refining themes by frequency.\n\n**Explanation:** Imagine you have a massive log file (transcripts) from various distributed systems (interviewees), each describing system failures. The goal isn't just to read them, but to identify recurring patterns and root causes. \"Initial Coding\" is like applying regular expressions or simple parsers to tag specific log lines (text chunks) with problem categories. This starts with a pre-defined set of tags (deductive codebook, like known error codes) and expands with new tags as novel issues appear (inductive coding, adding new error codes on the fly). \"Code Validation\" with Cohen's Kappa is analogous to a distributed consensus algorithm: two independent agents (researchers) label the same data, and Kappa measures the agreement. A Kappa of 0.8 signifies strong agreement, indicating that the 'parsing logic' is robust and consistent across agents, minimizing subjective bias in categorizing errors. \"Theme Development\" clusters these fine-grained tags into broader problem domains (like grouping all 'memory leaks' under a 'resource management' theme). Finally, \"Theme Refinement\" acts as a frequency-based filter, analogous to GROUP BY and COUNT queries in a database, followed by a HAVING COUNT > N clause. Low-frequency codes (tags mentioned only a few times) are pruned, ensuring that only statistically prevalent and impactful qualitative observations are elevated to final themes, thereby focusing on widespread issues rather than isolated incidents."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5f\ud835\udc60.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ \u2265 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ **or not** _\ud835\udc5f\ud835\udc60.\ud835\udc56\ud835\udc60_\ud835\udc4e\ud835\udc5d\ud835\udc5d_\ud835\udc59\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc51_ **then**\n\n**51** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ = _\ud835\udc62\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc64\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc51_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _ _\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f_ ( _\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64\ud835\udc39\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f, \ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52_ = _\ud835\udc5f\ud835\udc60.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52,_\n_\ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61,\ud835\udc64\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc5c\ud835\udc64_ _ _\ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e_ = _\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64\ud835\udc39\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc3f\ud835\udc52\ud835\udc5b_ ) ;\n\n**52** BBR_Update_Round():\n\n**53** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ + = _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61.\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52_ ;"}, {"role": "assistant", "content": "**Mechanism:** This code snippet dynamically updates the estimated network bottleneck bandwidth (BtlBw) by continuously observing the current data delivery rate. It employs a 'windowed maximum' filter to capture the highest sustained capacity over a recent time period, rather than being swayed by momentary dips.\n\n**Explanation:** The `if` statement acts as a gatekeeper: it allows an update to the bandwidth estimate only if the current `delivery_rate` is at least as good as our current `BtlBw` estimate, OR if the application isn't limited (meaning the observed rate truly reflects network capability, not a lack of data to send). If either is true, `BBR.BtlBw` is updated. This update isn't just a direct assignment; it's fed into a `windowed_max_filter`. This filter operates much like a sliding window (e.g., a circular buffer or a fixed-size array) that stores the `delivery_rate` values from the last `BtlBwFilterLen` rounds. It then consistently reports the *maximum* value observed within that window. This 'max' behavior ensures that temporary slowdowns (like minor congestion) don't immediately reduce the `BtlBw` estimate, maintaining an optimistic but evidence-based view of the network's potential. Separately, `BBR.delivered` functions as a simple cumulative counter, incrementing by `packet.size` to track total bytes transferred, independent of the rate estimation logic."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**2.1** **Reasoning and Reinforcement Learning**\n\n**Reasoning LLMs** . Large Language Models (LLMs) have\nrecently shown remarkable performance in complex reasoning domains such as mathematics, logic, and programming.\n\n20K\n\n15K\n\n10K\n\n2\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-2.png)\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|\n|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|Target Model<br><br><br>|\n|Target Model<br><br><br>|||\u2460|\u2460|\u2460|\u2460|\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-1.png)\n\n|Open<br>s1|AI-o1|\n|---|---|\n|||\n|||\n|||\n\n**Figure 3. Test-time scaling of reasoning models** . (a) Performance of OpenAI-o1 [40] and Stanford s1-32B [38] on the\nAIME Competition-level Math Benchmark [34]. (b) Example\nof self-reflection correcting an error within the reasoning.\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||Vanil<br>Spec|la Dec.<br>. Dec.|\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|le training step i<br>   s: (1)**_ Rollout St_**|\n|ndidate response|ndidate response|ndidate response|ndidate response|\n\n|Col1|Pha Dse c1 o: dR ino gllout<br>e<br>ReM spo od ne sl<br>es<br>R1<br>\ud83d\udd25<br>Model R2<br>\u2026<br>Rn|P Rh ea ss pe n2 s: I n Pf re er fe iln linc ge<br>o e<br>\u2744<br>Ref Model<br>\ud83d\udd25<br>Model<br>R Pe ow lia cr yd|Col4|Col5|Ph Mas oe e3 : T pr da ain teing<br>d l U<br>KL<br>Diverge nce Update<br>\ud83d\udd25<br>FL uo nss Model<br>c|\n|---|---|---|---|---|---|\n||R1<br>R2<br>\u2026<br>Rn<br>Model<br>Responses<br>Model<br>\ud83d\udd25<br>**Phase 1: Rollout**<br>_Decoding_|||||\n|Prompt<br>(Question)|Prompt<br>(Question)|||||\n|Prompt<br>(Question)|Prompt<br>(Question)||Reward<br>Policy|Reward<br>Policy|Reward<br>Policy|\n|Prompt<br>(Question)|Prompt<br>(Question)|||||\n\n**Figure 4.** Overview of the GRPO [51] RL training process.\n\nPowerful models such as OpenAI-o1 [40] and DeepSeekR1 [9] achieve impressive accuracy on challenging reasoning\nbenchmarks, including competition-level math and coding\nchallenges. A key factor in their success is _test-time scaling_\n\n[32, 62], an inference paradigm that enhances accuracy by\naffording models more generation time to explore complex\nreasoning paths. These reasoning LLMs typically feature:\n(1) _Long Chain-of-Thought_, generating extended intermediate reasoning steps before reaching a final answer; (2) _Self-_\n_Reflection_, the capacity to evaluate, refine, and correct their\nown reasoning during inference to improve accuracy. As\nillustrated in Figure 3 (a), allowing extended generation time\nenables these models to explore deeper and wider thinking\ntraces [6], thereby enhancing accuracy without additional\ntraining costs. More importantly, unlike traditional LLMs,\nthese reasoning models can automatically revisit their generated responses and exhibit self-reflection capabilities (e.g.,\n\" _wait_ \" in Figure 3 (b) reasoning trace), which are typically\nacquired during their RL training stage [9] and are key to\nperformance enhancements.\n**Reinforcement Learning for Reasoning** . Recently, RL algorithm variants such as Group Relative Policy Optimization\n(GRPO) [51] have proven their success in training reasoning LLMs. Unlike standard Policy Optimization (PPO) [50],\nwhich relies on an extensive critic model, GRPO employs a\ngroup-based baseline estimation to streamline the optimization process, significantly reducing training overhead while\npreserving the robustness of policy updates [58].\n\n**Figure 5. Overview of Speculative Decoding.** (a & b)\nComparison between Vanilla and Speculative Decoding. (c)\nSpeculative decoding achieves peak compute throughput\n(TFLOPS) at significantly smaller batch sizes (gray arrow).\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-2-3.png)\n\nFigure 4 illustrates a single training step in GRPO, which\ncomprises three main stages: (1) _**Rollout Stage**_, the target\nmodel generates multiple candidate responses for each input\nprompt; (2) _**Inference Stage**_, the generated responses are\nprocessed by both the _target model_ (the model undergoing\nRL training) and a fixed _reference model_ (the initial target\nmodel, i.e., RL step=0). This processing yields logits used\nto compute a KL divergence penalty [49], which serves to\nconstrain model updates, ensuring stability and preventing\nexcessive deviation from the reference model. Concurrently\nwithin this stage, a reward is calculated with a _rule-based_\npolicy regarding response characteristics (e.g., correctness),\nrather than relying on a separate value model; (3) _**Training**_\n_**Stage**_, a loss function is constructed using the reward value\nand KL divergence. The target model\u2019s weights are then\nupdated according to this loss.\n\n**2.2** **Speculative Decoding for Efficient Reasoning RL**\n\nAs mentioned in \u00a71, the long-tail rollout stage in reasoning\nRL frequently becomes a performance bottleneck. Consequently, tailored system optimizations for decoding acceleration are essential to improve throughput and resource efficiency. To this end, we identify speculative decoding [5, 22]\nas a key approach well-suited to tackle these challenges.\n**Why Speculative Decoding** . Among numerous methods accelerating LLM decoding, speculative decoding (SD) appears\nparticularly advantageous for the reasoning RL scenario. Its\nprimary benefit lies in its _lossless_ nature, mathematically ensuring the output distribution remains identical to that of\nthe original target model. This fidelity is paramount in reasoning tasks where the correctness and logical coherence of\ngenerated steps are critical for effective reinforcement learning. It directly tackles the throughput bottleneck identified\nin the long-tail rollout stage by speeding up generation, enhancing sample efficiency without compromising the crucial\naccuracy needed for reliable reasoning RL training.\n\n3\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-3-0.png)\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|||\n||Spot<br>Drafter<br>Training|\n|||\n|||\n|||\n\n**Figure 6.** Overview of TLT architecture and workflow.\n\n**Mechanism of Speculative Decoding** . In speculative decoding (Figure 5 (b)), a lightweight draft model rapidly generates a sequence of candidate tokens. These candidates are\nthen efficiently verified in parallel by the much larger target model in a single forward pass. The system accepts the\ndrafted sequence up to the first token that mismatches the\ntarget model\u2019s prediction, also keeping the single correct\ntoken that the target model generated at that position. As\nshown in the roofline analysis in Figure 5 (c), this process improves throughput by shifting the typically memory-bound\nautoregressive generation towards a more compute-bound\noperation, more effectively saturating the GPU resources.\n**Challenges in Reasoning RL** . Despite its effectiveness in\nalleviating the memory-bound issue and enhancing decoding\nthroughput, adapting existing speculative decoding methods\nto the context of RL training is fundamentally non-trivial.\nWe identify three key challenges:\n**C1. Evolving Target Model** . Unlike standard inference\nscenarios where models are fixed, RL training involves continuous target model updates. This constant evolution renders the draft model used in SD progressively \"stale\", diminishing the acceptance rate of speculated tokens and significantly undermining SD\u2019s effectiveness.\n**C2. Draft Model Training Costs** . Achieving high SD\nefficiency often requires dedicated draft models (e.g., singledecoder-layer models like Eagle [26], HASS [67]), rather than\narbitrary smaller models. Training a specialized drafter for\nthe target model introduces substantial additional cost.\n**C3. Fluctuating Batch Sizes** . As shown in Figure 5 (c),\nSD is typically optimized for small batch sizes. In contrast,\nRL rollouts often involve dynamically varying generation\nbatch sizes. Applying SD efficiently in this scenario is challenging, as performance can degrade with larger batches if\nnot managed properly, impacting overall throughput.\n\nTo address these challenges, TLT leverages the unique\ncharacteristics of the reasoning RL training process. Specifically, we introduce the Adaptive Drafter (\u00a74) to mitigate\nperformance degradation from dynamic model weights ( **C1** ),\nutilizing spare GPU resources for efficient draft model updates and thereby removing training overhead ( **C2** ). Furthermore, we design a specialized scheduling strategy (\u00a75)\nwithin the reasoning RL system to effectively manage the\nchallenges posed by varying batch sizes ( **C3** )."}, {"role": "assistant", "content": "**Mechanism:** Reasoning LLMs achieve high accuracy by employing 'Chain-of-Thought' (generating explicit intermediate steps) and 'Self-Reflection' (evaluating and correcting their own reasoning during inference). This 'test-time scaling' allows models to explore deeper and wider solution paths. Reinforcement Learning (RL), specifically GRPO, refines these models. GRPO operates in three stages: (1) Rollout: The target model generates multiple candidate responses for a given prompt, akin to exploring a search tree. (2) Inference: Each candidate response is evaluated by both the current target model and a fixed reference model (an immutable snapshot of the target model at the start of training). A KL divergence penalty is computed between their logits, serving as a regularization term to prevent the target model from diverging too rapidly or becoming unstable. Concurrently, a rule-based reward (e.g., based on answer correctness) is calculated for each response, bypassing the need for a separate, expensive critic model. (3) Training: A combined loss function, incorporating both the reward and the KL divergence penalty, is used to update the target model's parameters via gradient descent. This feedback loop strengthens desirable reasoning patterns. Speculative Decoding accelerates the Rollout stage. A small, fast 'draft model' quickly generates a sequence of speculative tokens (like a prefetcher). The larger 'target model' then simultaneously validates this entire sequence in a single forward pass. Tokens are accepted sequentially up to the first one where the target model's prediction disagrees with the draft model's. The correct token predicted by the target model at that mismatch point is then used to continue the generation process. This transforms many sequential, memory-bound inference steps into fewer, more compute-bound parallel verification steps.\n\n**Explanation:** The core idea behind powerful reasoning LLMs is not just guessing the answer, but showing their work. By generating a 'Chain-of-Thought,' they break down complex problems into manageable steps, much like a programmer writing a function for each sub-problem. 'Self-reflection' is like a built-in debugger, allowing the model to re-evaluate and correct its own intermediate outputs, improving the final accuracy. Reinforcement Learning, using algorithms like GRPO, is how these self-correction abilities are instilled. GRPO simplifies traditional RL by using a 'group-based baseline' and a rule-based reward instead of a full critic network, making it more efficient. The KL divergence penalty during inference acts as a 'soft constraint,' ensuring that as the model learns from rewards, it doesn't forget its previous, generally good knowledge\u2014it's like a dampener on learning rate, preventing drastic swings. This prevents model updates from making the policy too different from the previous stable policy, ensuring stability. Speculative Decoding tackles the slow generation (rollout) problem. Instead of the main model generating one token at a time in a loop (which is memory-bound as it constantly loads model weights), a smaller 'draft model' quickly guesses many tokens. The main model then processes these guessed tokens in parallel. This is similar to a CPU fetching multiple instructions at once and verifying them, rather than fetching, executing, and then fetching the next. If the draft model guesses correctly, you get many tokens for the cost of one main model forward pass. If it guesses wrong, you still get a partial win up to the error. This effectively trades sequential memory access for parallel computation, saturating GPU compute units more effectively. The 'lossless' guarantee means this speedup doesn't compromise the mathematical correctness of the output distribution, which is crucial for sensitive reasoning tasks."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-2-0.png)\n\nFigure 2: _**NoSense**_ **does no spatial supersensing.** Frames are encoded independently with SigLIP. We keep\ntop-4 frames by cosine similarity to the object query and aggregate similarities to auxiliary objects from the MCQ\noptions to select the answer. The pipeline is streaming, memory-efficient and uses only the relative order of the four\nmost object-relevant frames; it never reasons about motion, continuity, or long-range temporal patterns.\n\nIn this section, we introduce _NoSense_, a streaming, atemporal baseline for the VSR benchmark. We first state the\ntask and method, then report our results compared to the previous SoTA, and finally present ablation studies.\n\n**Task.** VSR tests whether a system can recover the appearance order of an object of interest. Each video _V_ contains\nfour inserted frames in which the same object of interest (e.g., a teddy bear) is co-located with 4 auxiliary objects\nor environments (e.g., bed, bathtub, sink, floor). The goal is to predict the correct temporal ordering of these four\nenvironments from videos lasting 10 minutes to 4 hours.\n\n**NoSense baseline.** _NoSense_ is a simple streaming method that uses only a CLIP/SigLIP model (Radford et al.,\n2021; Zhai et al., 2023), illustrated in Figure 2. It assumes a video of _N_ frames sampled at 1 FPS, an object of interest\n_o_, four auxiliaries _{ai}_ [4] _i_ =1 [, and four answer options] _[ {][\u03c0]_ [(] _[k]_ [)] _[}]_ [4] _k_ =1 [(each a permutation of the auxiliaries). NoSense]\nperforms the following steps: (i) it processes frames independently (discards nearly all temporal information), (ii)\nit keeps only the top four frames most similar to the query object in a buffer (no long-term memory), and (iii)\nit scores answer options by aggregating cosine similarities to auxiliary object prompts (no LLM). It requires no\n\n**Input:** Frames _{xt}_ _[N]_ _t_ =1 [at 1 FPS; object] _[ o]_ [; auxiliaries] _[ {][a][i][}]_ [4] _i_ =1 [; answer options] _[ {][\u03c0]_ [(] _[k]_ [)] _[}]_ [4] _k_ =1\n**Output:** _k_ [\u02c6]\nEncode _o_ with a prompt ensemble to get normalized _O \u2208_ R _[d]_\n\nEncode each frame: _Ft_ = norm( _f_ img( _xt_ ))\n_st_ = _\u27e8Ft, O\u27e9_ for _t_ = 1 _, . . ., N_ ; keep top-4 indices ( _t_ 1 _< \u00b7 \u00b7 \u00b7 < t_ 4) in buffer while streaming\nEncode joint text for ( _o, ai_ ) to get normalized _Ai_ .\n_ru,i_ = _\u27e8Ftu_ _, Ai\u27e9_ for _u, i \u2208{_ 1 _, . . .,_ 4 _}_\n**for** _k \u2208{_ 1 _, . . .,_ 4 _}_ **do**\n\nscore( _k_ ) = [\ufffd][4] _u_ =1 _[r]_ _u,\u03c0u_ [(] _[k]_ [)]\n**end**\n_k_ \u02c6 = arg max _k_ score( _k_ )\n**return** _k_ [\u02c6]\n\n**Algorithm 1:** _NoSense_ for VSR: streaming CLIP/SigLIP with no temporal reasoning.\n\n3\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-3-2.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-3-0.png)\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-3-1.png)\n\nFigure 3: _**NoSense**_ **solves VSR with no supersensing.** _NoSense_ uses only a SigLIP image encoder with\nindependent frame-level processing\u2014no video model, LLM, memory, or temporal reasoning. Yet, NoSense nearly\nperfectly solves VSR _(left)_, while using a fraction of the GPU memory of previous methods _(right)_ . This clearly\nshows that VSR can be solved without explicit 3D state, object tracking, or long-horizon temporal reasoning.\n\nspatial supersensing, spatial cognition, or world modeling. It uses the same information and procedural constraints:\nquery-aware, frame-level retrieval paradigm employed in Cambrian-S\u2019 own VSR inference pipeline. Thus, NoSense\nshould be interpreted as a valid solution, not as a misuse of the benchmark. The full algorithm is in Algorithm 1.\n\n**Experimental details.** The primary and only main design choice for _NoSense_ is the contrastive VLM used for\ntext and image embeddings. We evaluate four models: (i) OpenAI-CLIP-L/14, (ii) SigLIP2-B/16, (iii) SigLIP2So400m-384, and (iv) SigLIP2-So400m-512. Our best results are obtained with SigLIP2-So400m-512.\n\n**NoSense (almost) perfectly solves the VSR benchmark.** As shown in Figure 1, _NoSense_ nearly solves all\nfive test splits, from 10-minute to 4-hour videos. It achieves 98 _._ 3% on the 10-minute split and maintains _\u2248_ 95%\non the 2- and 4-hour splits, outperforming Cambrian-S by 55% in absolute performance. These results show that\nVSR does not require explicit world modeling or long-horizon reasoning; a simple contrastive-VLM baseline which\nexploits shortcuts in the benchmark by adopting a design similar to the VSR-specific inference algorithm suffices.\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-3-3.png)\n\n**Why does NoSense work so well?** _NoSense_ succeeds without extra supervision or training because the benchmark\nconstruction tightly aligns with contrastive retrieval pipeline used by the inference algorithm of Cambrian-S. We show\nthat (i) _NoSense_ uses no more inductive bias than Cambrian-S for this task, and (ii) relaxing our text-embedding\ndesign still yields strong performance.\n\n_(i) Cambrian-S and NoSense share the same functional components._ Both methods use: (a) a vision encoder for the\nstream, (b) a memory with consolidation (top- _k_ frames for _NoSense_ ), and (c) query-guided retrieval mechanism.\n_NoSense_ implements these aspects with a contrastive VLM rather than a multimodal LLM, and removes components\nsuch as long-term memory that are necessary for spatial supersensing but not for this benchmark. The fact that a\nsimpler instantiation near-perfectly solves VSR suggests that it can be solved without additional inductive biases.\n\n                                  -                                  Given this similarity, it is plausible that Cambrian S\u2019 VSR gains also rely heavily on the same basic retrieval style\nshortcut \u2013 identifying a few discriminative frames for the target object \u2013 rather than by better spatial supersensing.\n\n4\n\nTable 1: **Ablation Results** . Across all variants, NoSense remains far ahead of Cambrian-S on VSR. ( _left_ ) Even\nwhen we (1) use the raw question without extracting the target object, or (2) drop prompt ensembling and use a\nsingle basic template. ( _right_ ) Likewise, swapping the SigLIP-2 encoder for weaker CLIP/SigLIP variants still leaves\nus well above Cambrian-S on every split. This robustness suggests that near-perfect performance on VSR is not a\nfragile artifact of prompt engineering or a particular encoder.\n\n**Method** **10 mins** **30 mins** **60 mins**\n\nCambrian-S (baseline) 45.0% 41.7% 40.0%\n_NoSense_ (Ours, Best) 98.3% 98.3% 96.7%\n\n**Ablation 1: Use Raw Questions**\nNoSense (Raw) 90.0% 81.7% 75.0%\n\n**Ablation 2: Use Basic Prompt**\nNoSense (Basic Prompt) 98.3% 98.3% 93.3%\n\n|100|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||||\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||||\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||||\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||||\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||||\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||Cambria<br>~~NoSense~~|n~~-~~S (w/ Mem.)<br>~~ (CLIP-L/14)~~|\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||<br>NoSense<br>NoSense|<br> (Siglip2~~-~~B/16)<br> (Siglip2~~-~~So400m~~-~~384|\n|10 30<br>60<br>120<br>2<br>Video Duration (in Mins)<br>40<br>50<br>60<br>70<br>80<br>90<br>Accuracy (%)<br>Cambrian~~-~~S (w/ Mem.)<br>~~NoSense (CLIP-L/14)~~<br>NoSense (Siglip2~~-~~B/16)<br>NoSense (Siglip2~~-~~So400m~~-~~384<br>NoSense (Siglip2~~-~~So400m~~-~~512|||NoSense|(Siglip2~~-~~So400m~~-~~512|\n\n![](papers/images/Solving-Spatial-Supersensing-Without-Spatial-Supersensing.pdf-4-1.png)\n\n**Why was this missed?** Cambrian-S makes a careful effort to test shortcuts and strong baselines. However:\n\n- Cambrian-S uncovers flaws with existing benchmarks, these were done by measuring the performance of languageonly, single-frame and caption-only baselines. Single-frame baselines cannot directly work on VSR, because\nit requires at least four frames. Caption-based pipelines _could_ work, but the implementation in Cambrian-S\nsummarizes only 32 frames (as in short-video setups like LLaVA-OneVision (Li et al., 2024)), which dramatically\nundersamples long videos. Captioning at _\u223c_ 1 FPS might suffice.\n\n- Cambrian-S evaluates long-video methods such as MovieChat (Song et al., 2024) and Flash-VStream (Zhang\net al., 2024) specifically for these tasks. However, they use generic memory mechanisms that are not designed to\nexploit VSR\u2019s construction as directly as the inference pipeline of Cambrian-S.\n\n_(ii) Relaxing our text-embedding design still yields strong performance._ Until now, for extracting our text embeddings,\nwe leveraged a prompt ensemble in our experiments as this has been shown to reliably improve embedding\nquality (Radford et al., 2021). We now study two simplified variants: (1) using the raw question text and skipping\nexplicit extraction of the object from the question, and (2) removing prompt ensembling and using a single basic\ntemplate for all text encodings. Additionally, we study robustness across 4 different CLIP/SigLIP models.\n\n**Ablation results.** Table 1 summarizes our ablations. We show results of using the raw question (ablation 1) in\nTable 1 (left, middle). We observe that performance drops significantly (8-20%) compared to our best NoSense but\nremains far above Cambrian-S by 35-40%. The target objects in VSR are distinctive enough that a CLIP-style text\nencoder produces discriminative signal directly from the raw query due to its bag-of-words nature (Yuksekgonul\net al., 2022), making explicit extraction optional. We next show results of removing prompt ensembling (ablation 2)\nin Table 1 (left, bottom). We observe that accuracy decreases slightly but performance is still extremely competitive\n(more than 50% gain over Cambrian-S), indicating that prompt ensembling helps slightly but our results are largely\nindependent of this aspect. Lastly, we test robustness across CLIP/SigLIP variants in Table 1 (right). Even when\nvarying contrastive VLMs both in model family and size, _NoSense_ remains far ahead of Cambrian-S. This robustness\nsuggests that relatively small contrastive VLMs already provide features sufficient to almost perfectly solve VSR.\n\n**Conclusion.** Our results indicate that, despite careful design, VSR can be solved primarily through semantic cues\nfrom a handful of informative frames, with little need for explicit 3D reasoning, state maintenance, or long-term\nmemory. This gap between the intended and actual difficulty of VSR is closely related to shortcuts introduced in\nthe benchmark construction. Our NoSense baseline effectively isolates this shortcut. Cambrian-S\u2019 VSR inference\npipeline implements the same functional pattern \u2013 vision encoding, a compact memory of salient frames, and\nquery-guided retrieval \u2013 but with a multimodal LLM. The fact that our simple baseline almost perfectly solves\nVSR suggests that a substantial portion of Cambrian-S\u2019 VSR performance may come from a similar retrieval-style\n\n5\n\nshortcut, rather than uniquely from the additional machinery intended to support spatial supersensing or world\nmodeling. In the next section, we rigorously test this hypothesis on the VSC benchmark."}, {"role": "assistant", "content": "**Mechanism:** The VSR task, despite appearing to require complex temporal or spatial reasoning, can be solved effectively by combining a high-quality visual-language embedding model with a straightforward 'top-k retrieval and re-ordering' mechanism. It leverages the inherent 'snapshot' quality of the benchmark's object insertions, where key events are distinct co-occurrences rather than continuous motion.\n\n**Explanation:** NoSense works by treating each video frame like an independent image. First, a 'vision encoder' (like a function converting an image into a unique list of numbers) processes every single frame. Simultaneously, the 'object of interest' (e.g., 'teddy bear') is converted into its own list of numbers using a 'text encoder' \u2013 this is our search query. For each frame, NoSense calculates how 'similar' its numerical representation is to the teddy bear's numerical representation using cosine similarity (a measure of how aligned two lists of numbers are). As it streams through the video, it maintains a small buffer (like a fixed-size `ArrayList` or `priority queue`) that always holds the indices of the four frames with the highest similarity to the teddy bear. Crucially, these indices inherently preserve the original relative temporal order of these four most relevant frames. Then, each of the four 'auxiliary objects' (e.g., 'bed') is combined with the main object ('teddy bear on bed') and also encoded into lists of numbers. For each of the four buffered 'best' frames, NoSense checks its similarity against all four of these combined auxiliary object descriptions. Finally, given multiple possible orderings of the auxiliary objects, NoSense sums up the relevant similarities for each proposed ordering. For example, if an option is 'bed, bathtub, sink, floor', it sums: similarity(first best frame, 'teddy bear on bed') + similarity(second best frame, 'teddy bear in bathtub'), and so on. The ordering with the highest sum is chosen. This works because the benchmark effectively just asks for the sequence of these distinct co-occurrence events, and the visual-language model is excellent at identifying these salient snapshots, with their relative order implicitly providing the temporal information needed."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**144** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc52\ud835\udc5b\ud835\udc51_ _ _\ud835\udc5e\ud835\udc62\ud835\udc4e\ud835\udc5b\ud835\udc61\ud835\udc62\ud835\udc5a_ = _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ \u2217 1 _\ud835\udc5a\ud835\udc60,_ 64 _\ud835\udc3e\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ ) ;\n\n56 D. Dimopoulos, et al.\n\n**ACK-arrival function definitions (cont. 4/4):**\n\n**145** BBR_Set_Cwnd():\n\n**146** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc47\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ () ;\n\n**147** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc40\ud835\udc5c\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc39\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_ () ;"}, {"role": "assistant", "content": "**Mechanism:** The 'send_quantum' variable controls the maximum size of individual data bursts, calculated as the minimum of a rate-based volume (pacing_rate * 1ms) and a fixed upper limit (64 KBytes). The 'BBR_Set_Cwnd' function, triggered by acknowledgements, manages the total amount of outstanding data. It first calculates an ideal congestion window ('BBR_Update_Target_Cwnd') based on estimated network capacity and then dynamically adjusts it downwards ('BBR_Modulate_Cwnd_For_Recovery') if network congestion or packet loss is detected.\n\n**Explanation:** The `send_quantum` effectively sets the granularity of data transmission, using a `min` operation, which behaves like choosing the smaller result from two `if` conditions. One condition calculates how much data can be sent in a tiny time slice (1ms) based on the estimated `pacing_rate`, akin to filling a small temporary buffer for an upcoming send. The other condition provides a hard maximum (64 KBytes), preventing excessively large bursts. This balances sending enough data to be efficient without overwhelming network buffers. The `BBR_Set_Cwnd` function is essentially an event handler that runs when an acknowledgement arrives. It first calls a subroutine to compute the 'target' congestion window, which is like setting a maximum capacity for a queue based on a formula that anticipates throughput (often bandwidth-delay product). Subsequently, it calls another subroutine that acts as a conditional check, similar to an `if-else` block. If specific 'recovery' flags are set, indicating network trouble, it will reduce the congestion window, analogous to shrinking a dynamic array's allowed size to reduce load on a system that's struggling."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_\ud835\udc4e\ud835\udc59\ud835\udc59_\ud835\udc46\ud835\udc39\ud835\udc60_ _> \ud835\udc4f\ud835\udc64_\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc56_ **then**\n\n**11** _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_ _ _\ud835\udc4e\ud835\udc59\ud835\udc59_ _ _\ud835\udc46\ud835\udc39\ud835\udc60_ = _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc46\ud835\udc39\ud835\udc56_ ;"}, {"role": "assistant", "content": "**Mechanism:** This is a conditional assignment that updates a running minimum value. It's akin to an iterative 'find min' loop where a temporary minimum is continuously challenged by new values.\n\n**Explanation:** The expression describes a common algorithm pattern for finding the minimum value within a set. A variable, `lowest_bw_among_all_SFs`, holds the smallest bandwidth encountered so far. When a new bandwidth, `bw_of_SFi`, is presented, it's compared to this current minimum. If `lowest_bw_among_all_SFs` is currently greater than `bw_of_SFi` (meaning `bw_of_SFi` is smaller), then `lowest_bw_among_all_SFs` is updated to `bw_of_SFi`. This `if-then` construct within an iterating process ensures that `lowest_bw_among_all_SFs` always stores the true minimum value encountered up to that point, analogous to how you would find the minimum element in an array using a simple loop and a temporary variable in most programming languages."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section is dedicated in describing the fundamental aspects of MPTCP, such as the protocol structure, the architectural\n\ndetails, as well as foundational knowledge behind the most salient modules comprising and dictating the operation of\n\nMPTCP; the Path Manager, the Packet Scheduler, and the Congestion Controller. Afterwards, the main logic, as well as\n\nthe algorithmic steps of the state-of-art packet scheduling and congestion control algorithms are presented.\n\n**2.1** **MPTCP Theory**\n\n_2.1.1_ _General principles._ MPTCP has been designed on top of TCP, and as such, shares and extends much of its\n\nprinciples and structural details. The intention behind its development was the design of a protocol which provides the\n\ntraditional single-path TCP transport layer services, such as connection-oriented, reliable, and in-order data delivery,\n\nwhile being able to simultaneously use multiple paths for the transmission of data segments. MPTCP is thus extending\n\ntraditional TCP, and its operation is determined by specific attributes present within TCP header options; for instance,\n\nthe TCP option-kind number _30_ has been reserved by IANA to indicate whether the TCP header options carry additional\n\nMPTCP related fields. While advancing the legacy TCP functionality, it was also fundamental for MPTCP to be able to\n\nfall back to TCP, if required. Thus, the new protocol should not incur any modifications to the overlay application which,\n\nas with traditional TCP, can establish a MPTCP connection through a single socket. Despite the use of multiple paths in\n\nlower layers, each socket supports a single connection between the application and the transport layer. Applications\n\nmay continue using the existing TCP socket API for MPTCP connections; in that case MPTCP specific parameters are\n\nconfigured in the operating system. However, a new MPTCP socket is also available allowing applications to control\n\nMPTCP behavior via socket parameters.\n\n_2.1.2_ _Subflows._ The MPTCP\u2019s foundational principle is the ability to route application traffic over multiple paths, and\n\nyet enable seamless communication between two end-systems, as if it were for a single-path TCP connection. The\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 3\n\nunderlying paths carrying data packets, can be either distinct end-to-end physical links (i.e., \"disjoint\" paths), or paths\n\nwhich at some point share a common bottleneck link (e.g., \"partially disjoint\"). As with standard TCP, different paths\n\nare uniquely identified by a 4-tuple (source & destination address/port pair). Each data flow carried on an individual\n\npath which belongs to the same MPTCP connection, is called _subflow_ . Each subflow resembles a standard single-path\n\nTCP connection; subflow connection establishment and termination follows the typical single-path TCP procedures.\n\nConsequently, a MPTCP connection can comprise one or more subflows, ultimately enabling application communication\n\nbetween two end-hosts over multiple paths. From application\u2019s perspective, there is only a single socket bind and accept\n\ncall to the MPTCP connection. Each of the communicating multipath-capable hosts generates a token, based on the\n\nkeys exchanged during the initial MPTCP connection initiation procedure, which uniquely identifies each MPTCP\n\nconnection. Then, each time a new subflow needs to be created and be associated to an existing MPTCP connection,\n\neach host binds the 5-tuple of the TCP subflow to the local token of the connection. This allows any port pairs to be\n\nused for a connection, eliminating in essence the identification of a subflow based on the 4-tuple, and relying merely on\n\nthe token, instead [36].\n\n_2.1.3_ _Multipath-capable hosts._ The establishment of a multipath TCP connection requires that both communicating\n\nhosts have multipath capability. MPTCP is already supported by operating systems which base their function on recent\n\nversions of the linux kernel [38]. End-hosts negotiate their multipath capabilities ( _MP_CAPABLE_ ) over a typical 3-way\n\nhandshake, before being able to establish a MPTCP connection. If one of the hosts is not multipath-capable, or in case\n\nmiddleboxes intervene altering either the TCP header options and removing the MP_CAPABLE field or the payload\n\nitself, or in case of MPTCP version mismatch, the connection falls back to regular TCP. This allows the establishment of\n\na standard TCP connection, absent any manual intervention.\n\n_2.1.4_ _Meta- vs. Subflow-level._ In case of MPTCP, transport layer is logically segregated into two parts; the MPTCP \"Meta\n\nlevel\" (or \"Connection-level\"), and the MPTCP \"subflow-level\". The MPTCP meta-level is responsible for maintaining\n\na single connection point to the application layer, thus MPTCP is still perceived as a single-path TCP connection\n\nfrom application\u2019s point of view. The meta-level has all those mechanisms required to allow the presence of a single\n\nconnection to the upper layer, yet able to distribute (or reassemble) application bytestream across (or from) multiple\n\nsubflows. At subflow-level, each subflow is essentially handled as an individual single-path TCP connection between\n\nend-hosts.\n\n_2.1.5_ _Protocol Structure._ Building upon and extending traditional TCP, MPTCP protocol operations are defined within\n\nTCP header \"Options\" field. There are different MPTCP fields set within TCP header \"Options\" field depending on\n\nthe various MPTCP operations; i.e., _MP_CAPABLE_ option is used during MPTCP connection initiation, the _MP_JOIN_\n\noption is used to associate additional subflows with an existing MPTCP connection, the _ADD_ADDR_ option denotes the\n\naddress advertisement operation which announces the availability of new interfaces at end-hosts, the Data Sequence\n\nSignal ( _DSS_ ) option carries the Data Sequence Mapping, etc. A general overview of the MPTCP protocol stack as well as\n\nthe respective protocol structure, is depicted in Figures 1 and 2, respectively.\n\n_2.1.6_ _Path Manager._ As mentioned earlier, each MPTCP subflow is uniquely identified by a 4-tuple (source & destination\n\naddress/port pair). The MPTCP _Path Manager_ module is responsible for advertising the availability or elimination of an\n\nIP addresses/ port pair of a multipath-capable host, for establishing and removing subflows between two end-systems,\n\nas well as for maintaining the MPTCP connection state. The MPTCP connection state includes details of the active and\n\nstandby subflows constituting each MPTCP connection, and maps each subflow\u2019s 4-tuple to an _Address ID_ ; the latter is\n\n4 D. Dimopoulos, et al.\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-3-0.png)\n\nFig. 1. MPTCP protocol stack (Source:\nIETF RFCs 8684 [36], 6897 [83])\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-3-1.png)\n\nFig. 2. MPTCP protocol header structure - MPTCP header is included into TCP header \"Options\" field\n\ngenerated and announced by a source host during MP_JOIN or ADD_ADDR operation to allow the receiver to refer to\n\na source IP address/port pair implicitly, in case NAT protocol or other middleboxes conceal the actual source details.\n\n_2.1.7_ _Packet Scheduler._ The _Packet Scheduling_ functionality [51] at the transmitting end is responsible for receiving\n\nthe application bytestream, dividing application data into transport layer segments with appropriate connection-level\n\nsequence numbers, and transmitting the segments onto the available subflows according to the scheduler\u2019s own policy.\n\nThe availability of the subflows is exposed to the scheduler by the path manager. At the receiving side, a corresponding\n\nfunctionality is in charge of appropriately ordering the received segments based on the connection-level sequence\n\nnumbers, and delivering them in a bytestream fashion to the receiving application.\n\n_2.1.8_ _Flow control._ MPTCP inherits and extends standard TCP mechanisms. _Flow control_ guarantees that the transmitted\n\napplication data will reach the receiving end in-order and flawlessly, while it also allows the receiver to regulate the\n\nsender\u2019s transmitting rate based on the receiving application processing capabilities; the transmitting rate is essentially\n\ncontrolled via the _receive window (rwnd)_ which is announced by the receiver to the sending host at regular intervals\n\n(i.e., with each cumulative ACK in TCP). The typical TCP flow control is maintained at subflow-level, where each\n\nindividual subflow maintains its own _sequence_ and _acknowledgment_ numbers. However, the existing TCP flow control\n\nmechanism is not sufficient since although received packets may end up reassembled in correct order at subflow-level,\n\nthey may not necessarily be appropriately ordered at MPTCP connection-level due to heterogeneous path conditions or\n\nretransmissions. For this reason, besides the subflow-specific sequence and acknowledgment numbers, flow control\n\nmechanism is extended at connection-level. _Data Sequence Number (DSN)_ and _Data ACK_ enable the appropriate _Data_\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 5\n\n_Sequence Mapping_ from the subflow sequence space to the data sequence space [36]. This extended functionality allows\n\nfor a cumulative data tracking at connection-level and ensures in-order delivery to the application.\n\n_2.1.9_ _Congestion Control - the Reno approach._ The _Congestion control_ mechanism has been developed in the context\n\nof TCP [2, 31] to regulate the transmission rate of each sender in an attempt to protect networks, and subsequently\n\nthe Internet, from _congestion collapse_ . Since then, various congestion control algorithms have emerged, with CUBIC\n\nbeing the one most broadly utilized by Internet hosts, at the time of this publication. The remainder of this subsection\n\nprovides the foundational aspects of congestion control as defined by the legacy TCP-Reno [2]; CUBIC [89] is analyzed\n\nin a dedicated subsection below 2.3.1. TCP\u2019s congestion control mechanism comprises the following algorithms (or\n\n\"phases\"): _slow start_, _congestion avoidance_, _fast retransmit_, and _fast recovery_ ; the first two are responsible for regulating\n\nthe amount of data each TCP sender can inject into the network at any given moment, while the last two determine\n\nthe way congestion control reacts to potential loss. Three important state variables influence the function of these\n\nalgorithms: i) the congestion window (cwnd), which is essentially a sender-side limit on the amount of data that can be\n\ntransmitted and, consequently be in-flight, at any moment, ii) the receive window (rwnd), which is part of flow control\n\nmechanism and constitutes a receiver-side limit on the amount of data the receiver can accept at any given time, and\n\niii) the slow start threshold (ssthresh) which dictates whether congestion control operates according to slow start or\n\ncongestion avoidance algorithm. At any given moment, TCP must send no more than _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51,\ud835\udc5f\ud835\udc64\ud835\udc5b\ud835\udc51_ ) data beyond\n\nthe highest acknowledged sequence number; this formula guarantees that the amount of data transmitted at any instant\n\nneither incurs network congestion nor overloads the receive buffer. At any given time,the amount of bytes the sender is\n\nallowed to send next, is defined according to below formula:\n\n#_ _\ud835\udc5c\ud835\udc53_ _ _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ _ _\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_ = _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51,\ud835\udc5f\ud835\udc64\ud835\udc5b\ud835\udc51_ ) \u2212 _\ud835\udc39\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc52_ (1)\n\nwhere _FlightSize_ is the amount of data in-flight, or in other words, the amount of outstanding data in the network.\n\nIt is also recommended that the initial value of ssthresh be set arbitrarily high to allow network conditions, rather\n\nthan host limitations, dictate the sending rate. Nevertheless, sshthresh is adjusted to lower values in case congestion is\n\ndetected. The selection of the algorithm to be employed by the congestion control mechanism, is based on the relation\n\nbetween the slow start threshold and the congestion window:\n\n   - if _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _< \ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_, then _slow start_ algorithm is employed\n\n   - if _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _> \ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_, then _congestion avoidance_ algorithm is employed\n\n   - if _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ == _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_, then either _slow start_ or _congestion avoidance_ algorithm is selected\n\n_Slow start._ Slow start algorithm [2] is executed at the beginning of a data transfer after a TCP connection has been\n\nsuccessfully established, or when _retransmission timeout (RTO)_ timer elapses, indicating a loss. Slow start algorithm\n\nessentially allows sending-host\u2019s TCP to slowly probe the network to estimate network capacity, while avoiding network\n\ncongestion induced by large data bursts. In slow start, the initial value of the congestion window immediately after the\n\ncompletion of the 3-way handshake is:\n\n   - if _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ _>_ 2190 _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ :\n\n_\ud835\udc3c\ud835\udc4a_ = 2 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ and NOT more than 2 segments\n\n   - if ( _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ _>_ 1095 _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ ) && ( _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ _<_ = 2190 _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ ):\n\n_\ud835\udc3c\ud835\udc4a_ = 3 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ and NOT more than 3 segments\n\n   - if _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ _<_ = 1095 _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ :\n\n6 D. Dimopoulos, et al.\n\n_\ud835\udc3c\ud835\udc4a_ = 4 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ and NOT more than 4 segments\n\nwhere _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ is the _Sender Maximum Segment Size_, and _\ud835\udc3c\ud835\udc4a_ denotes the _Initial Congestion Window_ . During slow start,\n\nTCP increments the congestion window by at most _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ bytes for each ACK received that cumulatively acknowledges\n\nnew data:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + = _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ (2)\n\nA more conservative, yet secure against \"ACK Division\" approach [82], recommends that TCP increment congestion\n\nwindow according to the actual amount of bytes corresponding to new data, that are successfully acknowledged by the\n\nreceiver; this transforms 2 to a more precise formula:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + = _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc41,\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ ) (3)\n\nwhere _N_ is the number of previously unacknowledged bytes acknowledged in the incoming ACK. Incrementing the\n\ncongestion window by at most one SMSS for every received ACK acknowledging new data, leads to an exponential\n\ngrowth of the congestion window, until the point it reaches slow-start threshold ( _ssthresh_ ); from that point onward,\n\n_congestion avoidance_ algorithm controls data transmission, provided that no loss is encountered.\n\n_Congestion avoidance._ [2] When _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2265 _\ud835\udc60\ud835\udc60\u210e\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_, congestion control enters the congestion avoidance phase. During\n\ncongestion avoidance, it is recommended that congestion window be incremented proportionally to the number of\n\nbytes acknowledged for new data, but no more than _SMSS_ bytes per RTT, as defined in equation 4:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + = _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ / _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ (4)\n\nEquation 4 provides a byte-unit calculation of the congestion window during CA phase. An alternative to this, is the\n\nfull-size segment equivalent provided through 3. However, of vital importance here is the fact that the increment takes\n\nplace per RTT, and not per ACK as is the case in slow start mode.\n\n_Loss detection due to RTO expiration._ [2] When a TCP sender presumes that a segment is lost, by means of RTO\n\nexpiration, and the segment has not yet been resent for the same reason (i.e., RTO expiration), _ssthresh_ is adjusted based\n\non the below equation:\n\n_\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ = _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _\ud835\udc39\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc52_ _,_ 2 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ (5)\n\ufffd 2 \ufffd\n\nIf the lost segment has previously been sent as part of retransmission timer expiration, _ssthresh_ value remains unmodified.\n\nIn addition, upon _RTO_ expiration, congestion window should be set as follows:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = 1 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ (6)\n\nAt this point, the TCP sender is expected to retransmit the dropped segment and then, using the slow start algorithm,\n\nto increase the congestion window from one segment to the new value of _ssthresh_ 5. Once _sshthresh_ is reached, the\n\nalgorithm switches to _congestion avoidance_ phase [73].\n\n_Fast Retransmit & Fast Recovery._ [2] Fast retransmit algorithm exploits ACKs to detect and repair loss. The receiver\n\nshould respond with a duplicate-ACK when an out-of-order segment arrives, and should continue responding with\n\nduplicate ACKs for every new segment arriving, other than the one still missing. Duplicate-ACKs can in principle be\n\nimplying a couple of conditions:\n\ni. the segment has been dropped in transit to the destination\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 7\n\nii. the network might have re-ordered the segments\n\niii. the network replicates ACKs or data segments (i.e., triggered by intermediate devices in the network path\n\nbetween two end nodes)\n\nUpon reception of the missing segment, the receiver is expected to immediately respond with an ACK, indicating\n\nthat the received segment fills in the gap in the sequence space. Upon reception of the first and second duplicate ACKs,\n\nthe sender (unless SACK mechanism is enabled [1] ) is expected to send a segment of new data, provided that: i) _rwnd_\n\nallows, ii) _\ud835\udc39\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc52_ + _\ud835\udc5a\ud835\udc56\ud835\udc5b_ ( _\ud835\udc41,\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ ) \u2264 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + 2 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_, and iii) new data is available for transmission. However,\n\n_cwnd_ does not yet change, avoiding to reflect the new segments [33].\n\nThe reception of three duplicate ACKs denotes that a particular segment has potentially been lost. In that case, the\n\nsender sets _ssthresh_ according to equation 5, retransmits immediately the missing segment without waiting for the RTO\n\nto expire, and sets _cwnd_ according to the below formula:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ + 3 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ (7)\n\nThis immediate response to the detected loss is termed _fast retransmit_ . Equation 7 indicates that the congestion window\n\nis artificially inflated by the number of segments (i.e., three) that have left the network and which the receiver has\n\nbuffered. Notable here is the fact that congestion control does not switch to the slow start phase; this is reasonable,\n\nsince the reception of duplicate ACKs, if not excessive for different segments, indicates that the network can still\n\ndeliver segments despite the perceived congestion. As a result, the reception of duplicate ACKs is considered a _transient_\n\ncongestion, contrary to the expiration of RTO which indicates severe congestion and requests for more drastic measures,\n\nenforced by entering the slow start phase.\n\nFollowing the _fast retransmit_, congestion control enters the _fast recovery_ phase, until a normal (i.e., non-duplicate)\n\nACK arrives, indicating the recovery of the segment which was supposed to be missing. In _fast recovery_ phase, for\n\neach additional duplicate ACK received after the third, congestion window is incremented by one SMSS, that is\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ + = _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_, per dup-ACK receipt. This increase artificially inflates the congestion window in order to reflect the\n\nsegment that has left the network. Based on this increase, the sender can send 1 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ bytes of previously unsent\n\ndata, given that the normal requisites hold true (e.g., new value of _rwnd_ and _cwnd_ allow, and new data is available\n\nfor transmission). Upon reception of an ACK that acknowledges new data, beyond the sequence range of the missing\n\nsegment, loss is deemed repaired and TCP sets _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ ; beyond that point, _congestion avoidance_ algorithm\n\ntakes over to regulate _cwnd_ increase.\n\n_Final remarks._ The aforementioned congestion control operation is also known as Additive Increase - Multiplicative\n\nDecrease (AIMD). The additive increase describes the behavior of the congestion control algorithm within the congestion\n\navoidance phase, where the congestion window increases linearly by at most 1 \u2217 _\ud835\udc46\ud835\udc40\ud835\udc46\ud835\udc46_ bytes per RTT. The multiplicative\n\ndecrease is referred to loss detection by means of three duplicate ACKs\u2019 receipt, where the congestion window is halved,\n\nand then continues again to increase until the next congestion event is detected. The initial implementation of TCP (i.e.,\n\n_TCP Tahoe_ [84, 86]), included the first three phases of congestion control, that is, the _slow-start_, _congestion avoidance_,\n\nand _fast recovery_ . Whenever a loss was detected by way of receipt of three duplicate ACKs, congestion control was\n\nretransmitting the packet which was supposed to be lost, and then entered slow start phase. A subsequent update of\n\nthe congestion control mechanism, known as _TCP Reno_ [2], introduced the _fast recovery_ phase, where the detection of\n\nloss via three duplicate ACKs does not require entering the slow start phase after _fast retransmit_, thus optimizing the\n\n1A sender using SACK [35] must not send new data unless the incoming duplicate acknowledgment contains new SACK information.\n\n8 D. Dimopoulos, et al.\n\nperformance by remaining in the _congestion avoidance_ phase. The entire congestion control mechanism described earlier,\n\nis based on the _TCP Reno_ IETF standard; however, several optimizations took place since then (e.g., _TCP NewReno_ [40]\n\nwhich optimized the _fast recovery_ phase, and the successor of them, _CUBIC_ [89]). The following subsections describe\n\nin more detail how the legacy congestion control mechanism is operating in the context of MPTCP, as well as new\n\nalgorithms and variations of the existing ones.\n\n_2.1.10_ _MPTCP Implementation._ As mentioned earlier, in case of MPTCP, the application maintains a single socket\n\nfor each individual MPTCP connection, regardless of the number of subflows associated with this connection. The\n\nlife cycle of each individual subflow adheres to the legacy single-path TCP principles; consequently each subflow\n\nmaintains the same mechanisms and operates similarly to a standard TCP connection. On the sending node, each\n\nsubflow maintains its own subflow-level send window, as well as its own congestion and flow control mechanisms,\n\nwhich enable TCP-like communication with the receiving host at subflow-level. Thus, each subflow is individually\n\nresponsible for the reliable and in-order delivery of the segments it carries. When a loss is detected, the subflow-level\n\ncongestion control mechanism of the sending node undertakes the task of retransmitting the missing segment, while\n\nthe receiving node ensures that the segments will be rearranged in the appropriate order at subflow-level. For this\n\npurpose, each individual subflow makes use of a dedicated out-of-order queue and a corresponding receive buffer.\n\nHowever, as explained earlier as part of MPTCP flow control, even if it is ensured that each individual subflow\n\ndelivers the segments carried over it reliably and in-order, it is not guaranteed that, when combining the ordered\n\nsegments from multiple subflows, the result will be the original application bytestream. The MPTCP packet scheduler\n\nat the sending node could, for instance, split a data flow into segments traversing multiple subflows with heterogeneous\n\npath characteristics; then, at the receiving node, the in-order re-arrangement of the segments at subflow-level does\n\nnot provide any guarantee for in-order arrangement _across_ subflows. This task is assigned to the MPTCP connection\n\nlevel out-of-order queue which ensures the reassembly of segments arriving from different subflows, reconstructing\n\nessentially the original bytestream in the MPTCP receive buffer, and delivering it to the receiving application. This\n\nis why MPTCP makes use of a new sequence space; the _Data Sequence Number (DSN)_ and _Data Acknowledgment_\n\n_(Data-ACK)_ at connection-level complement the subflow-level standard TCP\u2019s _sequence (SN)_ and _acknowledgment_\n\n_numbers (ACK)_ . It is a prerequisite that each segment be acknowledged both at subflow- and connection-level before\n\nbeing passed to the receiving application\u2019s socket; only then is the sending node\u2019s connection-level send window able\n\nto slide further to the right, allowing the transmission of more data.\n\nIf a segment is never acknowledged on a specific subflow, a subflow-level timeout occurs indicating severe congestion\n\nor complete failure of that specific subflow. In that case, the segment is copied into the retransmission queue which is\n\nread on priority by the scheduler, who injects the missing segment to another subflow as soon as an opening in the\n\ncongestion window permits. All segments residing within the shared retransmission queue have higher priority over\n\nthe segments within the MPTCP send buffer; only when all segments from the retransmission queue are scheduled,\n\nthus the retransmission queue becomes empty, does the scheduler pull segments from the shared send buffer.\n\nA concise view of MPTCP protocol\u2019s end-to-end service delivery model, is depicted in Figure 3.\n\n**2.2** **Packet Scheduling Algorithms**\n\nResearch efforts have yielded a multitude of packet scheduling algorithms, with each one being tailored to specific\n\napplication demands. Besides the target application, packet schedulers can also be classified according to the inner\n\ntechniques they employ to achieve their goals; be it heuristics or machine learning (ML) algorithms. This work seeks\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 9\n\nFig. 3. Indicative MPTCP service delivery model\n\nto present and assess the state-of-art _heuristics-based_ MPTCP packet scheduling algorithms available in literature, up\n\nto the time of this publication. A more exhaustive list of multipath-compatible packet schedulers, along with some\n\nclassification options, can be studied through other works available in literature, references to which are provided\n\nthroughout the current manuscript. A brief overview of the MPTCP packet schedulers investigated through this work,\n\nis provided in Table 1.\n\n_2.2.1_ _MPTCP Default (minRTT)._ minRTT is the default MPTCP packet scheduler. It selects the subflow with the lowest\n\nRTT which has space in its congestion window ( _cwnd_ ), to transmit the next segment(s). If the subflow experiencing the\n\nlowest RTT among the available subflows (i.e., among all subflows established and not marked as \u2019backup\u2019) does not\n\nhave space in its cwnd, minRTT selects the subflow with the second lowest RTT that has sufficient cwnd. minRTT\n\nscheduler may optionally use some additional mechanisms to optimize its operation when the MPTCP connection is\n\nreceive-window limited; that is, the receive window is blocked by one or more segments not yet acknowledged (e.g.,\n\nmissing segments or segments traversing a slow subflow), which are in turn causing HoL blocking at the receiving\n\nend. In such cases, _opportunistic retransmission and penalization_ [79] technique showcases some additional benefit.\n\n_Opportunistic retransmission_ mechanism is responsible for retransmitting a not-yet-acknowledged segment over a faster\n\nsubflow, in anticipation for expedited delivery and unblocking of the receive window. In addition, the slow subflow is\n\n_penalized_ by halving its congestion window and setting _ssthresh_ to the new cwnd value. While those mechanisms provide\n\nsome short-term advantage, their benefit is questionable in the long run; the reactive approach those mechanisms follow,\n\n![](papers/images/Evaluating-the-Impact-of-Packet-Scheduling-and-Congestion-Control-Algorithms-on-MPTCP-Performance-over-Heterogeneous-Networks.pdf-8-0.png)\n10 D. Dimopoulos, et al.\n\nTable 1. MPTCP packet schedulers\n\nScheduler Full Name Reference Approach Main concept\n\nminRTT default v0.96\n\n[6, 17, 18,\n71, 79]\n\nminRTT default v0.96 reactive This is the default MPTCP packet scheduler. Assigns segments\n\n[6, 17, 18, to the subflow experiencing the lowest RTT, as long as CWND\n71, 79] permits.\n\nBLEST Blocking v0.96 [6, proactive BLEST tries to estimate and eliminate HoL blocking, by assessing\nEstimation 18, 29, 30] whether it is beneficial to schedule segments on a currently available subflow, or skip it, waiting for a more advantageous one.\nECF Earliest v0.96 [6, proactive ECF prioritizes scheduling over the faster subflows, anticipating\nCompletion 18, 63, 64] to achieve lowest flow completion time. ECF may elect not to use\n\nFirst\n\nECF Earliest v0.96 [6, proactive ECF prioritizes scheduling over the faster subflows, anticipating\nCompletion 18, 63, 64] to achieve lowest flow completion time. ECF may elect not to use\nFirst a slower path, in an attempt to increase utilization of the faster\n\nones.\n\nRR roundrobin v0.96 [6, blind (ack- Experimental scheduler. RR transmits traffic in a round-robin fash18, 69, 71] clocked) ion. Tunable configuration following either real round-robin scheduling or ACK-clocked behavior.\nLLHD Low v0.96 [66, reactive LLHD bases its decisions on the combined measurement of realLatency 67] time throughput, delay, and packet loss rate, rather than relying on\nand High a single parameter. LLHD adjusts scheduling reactively according\nData Rate to the erceived network conditions.\n\nLLHD Low v0.96 [66, reactive LLHD bases its decisions on the combined measurement of realLatency 67] time throughput, delay, and packet loss rate, rather than relying on\nand High a single parameter. LLHD adjusts scheduling reactively according\nData Rate to the perceived network conditions.\n\nReMP TCP redundant v0.96 blind Sends each data segment on all available subflows. It guarantees\n\n[6, 18, 39] lowest per-packet latency and increased reliability, at the expense\nof limited goodput and higher flow completion time.\n\nlimits artificially the congestion window of the slow path, causing it to increase slowly until the next HoL blocking\n\noccurrence. This continuous penalization approach has a detrimental effect on the slow subflows, the bandwidth of\n\nwhich is significantly underutilized.\n\nThe algorithmic steps of _minRTT_ packet scheduling algorithm are presented in detail in 1.\n\n_2.2.2_ _BLocking ESTimation-based (BLEST)._ BLEST adapts proactively its scheduling decisions by estimating whether\n\ninjecting segments on a slow subflow would incur HoL blocking when the fast subflow becomes available again. It\n\ntries to limit, in essence, the amount of time a fast subflow remains underutilized due to receive window (and the\n\nmirror-effect of MPTCP send window) blocking. To achieve this, BLEST estimates the amount of data that would be\n\nsent on a fast subflow during the duration of a slow subflow ( _RTTs_ ). If this calculated amount of data is larger than\n\nthe usable MPTCP send window [28], then potential scheduling on the slow subflow would block the entire MPTCP\n\nsend window. Instead, BLEST selects to skip the currently available slow subflow, waiting for the faster one to become\n\navailable again (i.e., by delivering some segments and opening some space in its congestion window). Using this core\n\nidea, BLEST tackles the HoL blocking issue which is present during scheduling across heterogeneous networks or paths,\n\nat the expense of underutilizing the slower paths in case their use is deemed detrimental in the long run. BLEST uses\n\nminRTT algorithm 2.2.1 to identify the subflow experiencing the lowest RTT at any given moment before applying\n\nits sophisticated scheduling logic. A correction factor lambda ( _\ud835\udf06_ ) adjusts the scale of X (see algorithmic steps in 2),\n\ncontrolling essentially how strict or relaxed will the decision on selecting the slower path be; an increase in the value of\n\n_\ud835\udf06_ induced by a HoL blocking observation, incurs more stringent requirements on the selection of the slow subflow _\ud835\udc65\ud835\udc60_ .\n\nThe algorithmic steps of _BLEST_ packet scheduling algorithm are presented in detail in 2.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 11\n\n_2.2.3_ _Earliest Completion First (ECF)._ ECF aims to reduce the completion time of a data flow traversing heterogeneous\n\npaths. It achieves this by ensuring that the completion of a flow is not delayed by transmission over a slower path.\n\nInstead, ECF prioritizes scheduling on the fastest (in terms of RTT) path as long as it is available for sending; that is,\n\nhaving available space in its congestion window. Unlike minRTT, ECF may elect not to send on a slower path and\n\nrather wait for a faster one to become available, if this is estimated to be beneficial for the total flow completion time.\n\nThus, a slower path can only be used as long as it does not delay the completion of the entire flow. The estimation\n\nof completion times is calculated using not only path RTTs, but also an estimation of paths\u2019 bandwidth incorporated\n\nwithin the congestion window, and the size of the connection-level send buffer. ECF uses a margin _\ud835\udeff_ which incorporates\n\nthe standard deviation of each path\u2019s RTT (denoted by _\ud835\udf0e_ ) to compensate for RTT and CWND variabilities, a hysteresis\n\nconstant _\ud835\udefd_ which limits frequent switchover between subflows, as well as parameter _k_ which holds the number of bytes\n\nremaining to be sent in order to complete the transfer of the data flow.\n\nThe algorithmic steps of _ECF_ packet scheduling algorithm are presented in detail in 3.\n\n_2.2.4_ _Round-Robin (RR)._ The round-robin scheduler selects the subflows to schedule segments on, in a round-robin\n\nfashion [71]. While this technique might offer load-balancing and equal use of the available subflow resources in case\n\nof homogeneous paths, it is detrimental in case of highly heterogeneous paths. Segments scheduled in a round-robin\n\nfashion over paths with different network characteristics will end up out-of-order at the receiving node, causing\n\nHoL blocking, limiting the receive window, and delaying the whole data flow completion. Such conditions have a\n\ndomino effect, increasing retransmissions, and stalling the entire connection. RR scheduler\u2019s default operation is\n\n_congestion-window limited_, that is, trying to fill in the entire congestion window of each subflow; as a result, RR becomes\n\n_ack-clocked_ [53] in case of bulk data transfers, waiting, in essence, for ACKs to open up some space in the subflow\u2019s\n\ncongestion window before the scheduler is able to inject new segments on that subflow again. However, the MPTCP\n\ndevelopment community has provided the option to tune RR\u2019s behavior through configurable parameters which control\n\nboth the number of consecutive segments to be transmitted in each subflow before switching to another, as well as\n\nwhether RR will leave some open space in the congestion window to retain its real round-robin scheduling scheme,\n\navoiding the ack-clocked behavior [6].\n\nThe algorithmic steps of _RR_ packet scheduling algorithm are presented in detail in 4.\n\n_2.2.5_ _Low Latency and High Data Rate (LLHD)._ Instead of relying on a single parameter to devise the next scheduling\n\naction, LLHD seeks to combine all the available network parameters (i.e., delay, path loss, and available bandwidth)\n\nand adapt quickly to the constantly changing network conditions. For this purpose, LLHD tries to optimize a utility\n\nfunction _\ud835\udefe_, which embodies the various network parameters as follows:\n\n1\n_\ud835\udefe_ = _\ud835\udc3a\ud835\udc43\ud835\udc41_ + _\ud835\udefd_ \u00d7 (8)\n_\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc41_\n\nwhere _\ud835\udefd_ is a balancing factor, and _\ud835\udc3a\ud835\udc43\ud835\udc41_ [2] and _\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc41_ are the normalized goodput and RTT, respectively, which are\n\ndefined as follows:\n\n_\ud835\udc3a\ud835\udc43\ud835\udc41_ = _\ud835\udc3a\ud835\udc43\ud835\udc3a\ud835\udc43\ud835\udc5a\ud835\udc4e\ud835\udc65_ [,] _[ \ud835\udc45\ud835\udc47\ud835\udc47][\ud835\udc41]_ [=] _\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc5a\ud835\udc4e\ud835\udc65_\nwhere _\ud835\udc3a\ud835\udc43_ and _\ud835\udc45\ud835\udc47\ud835\udc47_ are the goodput and RTT of _\ud835\udc60\ud835\udc53\ud835\udc56_, respectively; similarly, _\ud835\udc3a\ud835\udc43\ud835\udc5a\ud835\udc4e\ud835\udc65_ and _\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc5a\ud835\udc4e\ud835\udc65_ are the maximum\n\ngoodput and RTT values among all subflows, respectively. The algorithm considers available all those subflows with\n\nsufficient congestion window (cwnd). The subflow that maximizes the utility function _\ud835\udefe_ is the one to be selected for\n\n2 _\ud835\udc3a\ud835\udc5c\ud835\udc5c\ud835\udc51\ud835\udc5d\ud835\udc62\ud835\udc61_ = _\ud835\udc47\u210e\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc54\u210e\ud835\udc5d\ud835\udc62\ud835\udc61_ \u2212 _\ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60\ud835\udc52\ud835\udc60_\n\n12 D. Dimopoulos, et al.\n\nscheduling at any given time. Subflows that have been marked as \"backup\" are used only when no normal subflows are\n\navailable. In addition, the algorithm examines whether a subflow is _unavailable_ (e.g., no longer usable), or _temporarily_\n\n_unavailable_ (e.g., no available space in its cwnd) for data transfer. The LLHD algorithm presented in 5, is based on\n\nthe respective paper [67]. However, the set of steps is simplified; multiple conditions are examined within the actual\n\ncode published in GitHub [66], controlling how the temporarily unavailable subflows, as well as any backup ones, are\n\nactually used upon each call of the algorithm.\n\nThe algorithmic steps of _LLHD_ packet scheduling algorithm are presented in detail in 5.\n\n_2.2.6_ _ReMP TCP (Redundant)._ In multipath scheduling, redundancy is realized by sending duplicate segments on\n\nall available subflows. This technique is profoundly inefficient in terms of bandwidth utilization; it might however\n\nbe applied to reduce per-packet latency and any induced retransmissions in case of interactive bandwidth-tolerant\n\napplications, which are though limited by stringent latency and jitter requirements. Using redundant packet scheduling,\n\nthe fastest path is the one determining the effective end-to-end latency. In addition, redundancy contributes to reduced\n\nRTT, minimizing delays induced by excessive retransmissions; this can be achieved since segments arriving at the\n\nreceiving node via the faster path will be acknowledged faster compared to how their duplicates (carried over a\n\nslower and even lossy path) would. According to its authors, _ReMP TCP_ can efficiently handle queuing delays, latency\n\nvariations (jitter), and heterogeneous path performance, exchanging, in essence, bandwidth for reduced latency in\n\nexisting best-effort networks. If a subflow is not available at the time of redundant scheduling (i.e., in case cwnd does\n\nnot permit, or in case of link unavailability or failure), a segment is injected only on the available subflow.\n\nThe algorithmic steps of _ReMP TCP_ packet scheduling algorithm are presented in detail in 6.\n\n**2.3** **Congestion Control Algorithms**\n\n_Uncoupled Congestion Control._ As with standard TCP, MPTCP also makes use of the congestion control mechanism\n\nto regulate the amount of outstanding data, in an attempt to detect and recover from network congestion. The standard\n\nTCP congestion control mechanism is applied individually to each MPTCP subflow, managing the rate at which each\n\nsubflow can inject segments into the network. Thus, each MPTCP subflow maintains its own congestion window,\n\noperating essentially as an individual single-path TCP connection. While such an approach is functional, it leads to\n\nan unfair share of a bottleneck link\u2019s bandwidth. For instance, when two subflows belonging to the same MPTCP\n\nconnection coexist alongside a standard single-path TCP connection in a bottleneck link, the MPTCP connection would\n\noccupy 2/3 of the bottleneck link\u2019s bandwidth. Applying such a congestion control mechanism for broader utilization,\n\nwould provide an unfair advantage to MPTCP connections over standard TCP ones, allowing the latter to be allocated\n\nonly a small fraction of the available bandwidth, and eventually leading them to resource starvation. A multipath\n\ncongestion control mechanism with the aforementioned characteristics is called _uncoupled_, since the congestion window\n\nof each subflow scales individually, absent any MPTCP connection-level limit.\n\n_Coupled Congestion control._ On the contrary, one of the main principles to be considered during the design of TCP\n\ncongestion control algorithms, is to ensure _fairness_ among the TCP connections which are competing for bandwidth\n\n[31]. The same principle is carried over to the MPTCP congestion control design [32, 36, 51, 78], ensuring that each\n\nMPTCP connection will be allocated the same amount of bandwidth as if it were a standard TCP connection; in the\n\nabove example, the MPTCP connection would be allocated 1/2 of the bottleneck bandwidth, however many subflows\n\ncomprising it. Such a congestion control algorithm, which imposes an upper bound on the aggregate amount of\n\noutstanding data at MPTCP connection-level, is called _coupled_ .\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 13\n\nTable 2 provides a concise description of the state-of-art congestion control algorithms used in MPTCP, inherited\n\neither directly from TCP (uncoupled), or adapted and new ones focusing on fairness (coupled).\n\n_2.3.1_ _CUBIC._ The initial AIMD approach, as specified and applied in legacy _TCP Reno_ and _NewReno_ algorithms, was\n\nfollowing a linear increase of the congestion window (cwnd) during the congestion avoidance phase, that is, an increase\n\nof the cwnd by one segment per RTT. While this approach is suitable for low BDP (bandwidth-delay product) links, there\n\nis a noticeable drawback when used in long-fat networks (i.e., with links experiencing high bandwidth and round-trip\n\ntime delays). In such cases, the available bandwidth is underutilized since the linear increase of the congestion window\n\ntakes too long to reach the link\u2019s saturation point, that is, the link\u2019s full capacity. As a result, the amount of time needed\n\nto reach the link\u2019s full capacity may be much higher than the one a flow may take to complete. For instance, using a\n\n10Gbps/100ms round-trip delay link, the congestion window would reach the link\u2019s full capacity in \u223c 1 _._ 4h.\n\nThe above computation is based on S. Floyd\u2019s et al. calculation of the round-trip times required until full congestion\n\nwindow is reached following a loss [34], that is:\n\n_\ud835\udefd_\nround-trip times (9)\n_\ud835\udc4e_ _[\ud835\udc4a]_ [+][ 1]\n\nwhere _W_ is the congestion window value just before the loss event occurs, and _a_ and _\ud835\udefd_ are AIMD\u2019s additive-increase\n\nand multiplicative-decrease factors, respectively. In the above example, using traditional TCP Reno and NewReno where\n\n_\ud835\udc34\ud835\udc3c\ud835\udc40\ud835\udc37_ ( _\ud835\udc4e, \ud835\udefd_ ) = _\ud835\udc34\ud835\udc3c\ud835\udc40\ud835\udc37_ (1 _,_ 1/2), it would take approximately (given that: 1 _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52_ \u2248 10 _\ud835\udc4f\ud835\udc56\ud835\udc61\ud835\udc60_, _\ud835\udc40\ud835\udc46\ud835\udc46_ \u2248 1000 _\ud835\udc35\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ ):\n\n_\ud835\udc45\ud835\udc47\ud835\udc47_ \u2217 _[\ud835\udefd]_\n\n[1]\n\n2 [10][5][ =][ 5000 sec. for the congestion window to reach its full capacity. To cope with such]\n\n_\ud835\udc4e_ _[\ud835\udc4a]_ [=][ 0] _[.]_ [1][ \u2217] 2 [1]\n\nlong-distance and high-latency links, CUBIC replaces AIMD\u2019s additive increase alorithm with a cubic function, the\n\nwindow growth of which, is provided in equation 10:\n\n_\ud835\udc4a_ ( _\ud835\udc61_ ) = _\ud835\udc36_ ( _\ud835\udc61_ \u2212 _\ud835\udc3e_ ) [3] + _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_ (10)\n\nwhere _C_ is a CUBIC parameter determining the aggressiveness of the protocol against competing flows which may\n\nbe using other congestion control schemes, _t_ is the elapsed time from the last window reduction, _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_ is the congestion\n\nwindow value when the loss occurred, and _K_ is the time period that the above function takes to increase _\ud835\udc4a_ to _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_\n\nwhen there is no further loss event, and is calculated by the following equation:\n\n3\n_\ud835\udc3e_ =\n~~\u221a~~\n\n_\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_ _\ud835\udefd_\n\n(11)\n_\ud835\udc36_\n\nCUBIC heuristically sets constant _\ud835\udc36_ = 0 _._ 4, and the AIMD decrease factor _\ud835\udefd_ = 0 _._ 2, to adapt for fairness with other TCP\n\nflows, and attain a balance between protocol stability and convergence speed. CUBIC algorithm essentially computes\n\nthe target value of the congestion window growth during the next RTT: _\ud835\udc4a_ ( _\ud835\udc61_ + _\ud835\udc45\ud835\udc47\ud835\udc47_ ), and then compares this target\n\nvalue with the growth of the congestion window that standard TCP would achieve within the same time interval. If the\n\ncurrent congestion window is less than the estimated standard TCP\u2019s congestion window (calculated in terms of time\n\n_t_, where t is the elapsed time after the loss event), then CUBIC operates in _TCP mode_ where the current congestion\n\nwindow is updated according to standard TCP\u2019s AIMD; this allows CUBIC to perform equally to TCP Reno in low BDP\n\nnetworks. If the current congestion window is greater than the one TCP would reach within the same time interval, then\n\nthe protocol operates either in the _concave_ or the _convex_ region, depending on whether the current congestion window\n\nvalue is less or greater than _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_, respectively. Within both the concave and convex regions, CUBIC increments the\n\ncongestion window (cwnd) by _[\ud835\udc4a]_ [(] _[\ud835\udc61]_ [+] _[\ud835\udc45\ud835\udc47\ud835\udc47]_ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [)] [\u2212] _[\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51]_ . The _concave_ profile allows the algorithm to approach quickly the area\n\n14 D. Dimopoulos, et al.\n\nTable 2. MPTCP Congestion Control Algorithms (CCA)\n\nCCA Full Name Reference Approach Main concept\n\nCUBIC - v0.96 [18, uncoupled CUBIC replaces the linear additive increase phase of Reno-based\n41, 42, 89] (loss-based) AIMD CCAs, with a cubic function. This allows fast convergence\ntoward the actual link bandwidth in high-BDP networks.\nCoupled Linked v0.96 [18, coupled LIA is the default MPTCP congestion control algorithm. It has been\n(LIA) Increases 70, 78, 88] (loss-based) the first coupled congestion control scheme to ensure MPTCP\u2019s\nAlgorithm incentive and fairness to single-path TCP flows. It modifies the\n\nCoupled Linked v0.96 [18, coupled LIA is the default MPTCP congestion control algorithm. It has been\n(LIA) Increases 70, 78, 88] (loss-based) the first coupled congestion control scheme to ensure MPTCP\u2019s\nAlgorithm incentive and fairness to single-path TCP flows. It modifies the\n\nadditive increase part of Reno-based AIMD algorithm.\nOLIA Opportunistic v0.96 [18, coupled OLIA has been proposed as an optimization alternative to LIA,\nLinked- 57\u201359] (loss-based) managing to eliminate the trade-off between responsiveness and\nIncreases optimal congestion balancing; thus, providing a pareto-optimal\nAlgorithm solution that combines both simultaneously. As with LIA, the\n\nOLIA Opportunistic v0.96 [18, coupled OLIA has been proposed as an optimization alternative to LIA,\nLinked- 57\u201359] (loss-based) managing to eliminate the trade-off between responsiveness and\nIncreases optimal congestion balancing; thus, providing a pareto-optimal\nAlgorithm solution that combines both simultaneously. As with LIA, the\n\nproposed optimization is applied to the additive increase part of\nthe AIMD algorithm.\nBALIA Balanced v0.96 [18, coupled BALIA reveals an inevitable tradeoff between friendliness, responLinked 48, 74, 85] (loss-based) siveness, and window oscillation of congestion control schemes.\nAdaptation Basing its design on an analytical framework, BALIA proves to\n\nBALIA Balanced v0.96 [18, coupled BALIA reveals an inevitable tradeoff between friendliness, responLinked 48, 74, 85] (loss-based) siveness, and window oscillation of congestion control schemes.\nAdaptation Basing its design on an analytical framework, BALIA proves to\n\nreach a unique equilibrium point, managing to mitigate the tradeoff and provide balanced performance. BALIA adjusts the entire\nAIMD algorithm controlling the Congestion Avoidance (CA) phase.\nwVegas weighted v0.96 [8, 9, coupled wVegas is a coupled delay-based alternative of standard TCP-Vegas\nVegas 18, 90] (delay- for MPTCP. Contrary to loss-based CCAs that associate packet loss\nbased) with congestion, wVegas interprets queuing delay as congestion\n\nwVegas weighted v0.96 [8, 9, coupled wVegas is a coupled delay-based alternative of standard TCP-Vegas\nVegas 18, 90] (delay- for MPTCP. Contrary to loss-based CCAs that associate packet loss\nbased) with congestion, wVegas interprets queuing delay as congestion\n\nsignal. Using weights to equally distribute the congestion cost\namong subflows, wVegas ensures that each sublow allocates a\nfair share of the bottleneck bandwidth. Maintaining a moderate\nbuffer occupancy in link queues, wVegas accounts for congestion\nproactively, thus preventing excessive packet loss.\nBBR Bottleneck v0.96 [10\u2013 uncoupled BBR-v1 [11] is neither a loss- nor a purely delay-based scheme.\nBand- 12, 16, 18, (congestion- Although inspired by the delay-based approach of TCP-Vegas, BBR\nwidth and 54] based) follows a unique method to identify the optimal operating point,\nRound-trip by accurately estimating the bottleneck bandwidth and base RTT.\npropaga- Based on these estimations and appropriate traffic pacing adjusttion time ments, BBR achieves maximum bandwidth utilization at the lowest\n\nBBR Bottleneck v0.96 [10\u2013 uncoupled BBR-v1 [11] is neither a loss- nor a purely delay-based scheme.\nBand- 12, 16, 18, (congestion- Although inspired by the delay-based approach of TCP-Vegas, BBR\nwidth and 54] based) follows a unique method to identify the optimal operating point,\nRound-trip by accurately estimating the bottleneck bandwidth and base RTT.\npropaga- Based on these estimations and appropriate traffic pacing adjusttion time ments, BBR achieves maximum bandwidth utilization at the lowest\n\npossible round-trip delay, eliminating intermediate queue formation. To derive these estimations, BBR implements a state transition\nmodel, cycling over four states (Startup, Drain, Probe_BW, and\nProbe_RTT). BBR\u2019s congestion-proactive approach leads to sustained high bandwidth utilization, low RTT, and infrequent loss.\nC-MPBBR Coupled v0.96 [55, coupled C-MPBBR is a coupled alternative of BBR for MPTCP. It exploits\nMultipath 68] (congestion- BBR\u2019s existing BtlBw and DelRt parameters to ensure multipath\n\nBBR\n\nv0.96 [10\u2013\n\n12, 16, 18,\n54]\n\nuncoupled\n(congestionbased)\n\nv0.96 [55, coupled\n68] (congestionbased)\n\nC-MPBBR is a coupled alternative of BBR for MPTCP. It exploits\nBBR\u2019s existing BtlBw and DelRt parameters to ensure multipath\nbenefit, as well as fairness among single- and multi-path flows\ntraversing a common bottleneck. C-MPBBR achieves the first goal\nby closing any subflows not contributing sufficiently to the multipath connection. Fairness is established by leveraging BtlBw\nestimations to identify subflows on the same bottleneck, and dividing the measured bandwidth equally among them.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 15\n\nclose to link\u2019s saturation point, but then slow down to remain long-enough in this area which is expected to provide\n\nthe highest bandwidth utilization. In case network conditions have improved since the last congestion event (i.e., the\n\nreception of a duplicate ACK), the protocol is switching to the _convex_ region (also known as _maximum probing phase_ )\n\nwhere it seeks to identify the new bandwidth saturation point; it does this following the convex function\u2019s exponential\n\nnature, in which the algorithm prompts for the new _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_ initially slowly, and then more aggressively.\n\nThe advantage of CUBIC compared to standard TCP is that, while maintaining the standard TCP principles, it\n\nmanages to converge faster in case of high BDP links. It is also unique in the way it approaches the saturation point,\n\nby combining the concave and convex profiles encompassed within a single cubic function. This way, it approaches\n\nquickly the last epoch\u2019s _\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_, then prompts slowly for the new saturation point close to the plateau created around\n\n_\ud835\udc4a\ud835\udc5a\ud835\udc4e\ud835\udc65_, and in case the available bandwidth has increased since the previous epoch, it increases the congestion window\u2019s\n\ngrowth rate more aggressively to find the new maximum value. Another key property of CUBIC is the fact that the\n\ncongestion window increase rate is independent of RTTs outside the TCP-mode; this characteristic allows flows with\n\ndifferent RTTs to maintain similar congestion window sizes, thus further contributing to the protocol\u2019s fairness.\n\nSince CUBIC is based on the AIMD congestion control scheme, where the congestion window decreases [3] rapidly\n\nupon an identified loss and then grows linearly, it is considered a _loss-based_ congestion control algorithm. From MPTCP\n\nperspective, since CUBIC does not incorporate any multipath-specific logic to account for fairness between MPTCP and\n\nstandard TCP connections, it is considered _uncoupled_ . A condensed version of CUBIC pseudo-code is presented in the\n\nAppendix, based on the original source [42]. Some more recent updates can be found within RFC 9438 [89].\n\nThe algorithmic steps of _CUBIC_ congestion control algorithm are presented in detail in 7.\n\n_2.3.2_ _Coupled._ Coupled (also called _Linked Increases Algorithm (LIA)_ ) [78, 88], has been the first coupled congestion\n\ncontrol algorithm for Multipath TCP that efficiently tackles the fairness issues arising when single- and multi-path\n\nflows concurrently share the same bottleneck link resources. Coupled congestion control has been therefore introduced\n\nto satisfy the fairness principles that the respective standard TCP congestion control schemes lack.\n\nThe bottleneck fairness properties that any multipath congestion control scheme should employ, are succinctly\n\nsummarized in the following three goals [78]:\n\n   - Goal #1 (Improve Throughput): A multipath flow should at least achieve the performance of a single path flow\n\non the best of the paths available to it.\n\n   - Goal #2 (Do no harm): A multipath flow should not allocate more capacity from the resources shared when\n\ntraversing multiple paths, than if it were a single flow using only one of these paths. This guarantees fairness\n\nagainst other competing flows.\n\n   - Goal #3 (Balance congestion): A multipath flow is expected to remove traffic from its most congested paths,\n\nsubject to meeting the first two goals.\n\nOn the basis of these goals, three main approaches have been studied in literature in an attempt to identify the\n\nmost appropriate multipath congestion control coupling scheme [44]. The first approach suggests the use of a common\n\ncongestion window, shared between the subflows of a multipath connection. While this approach sounds reasonable, it\n\nmay lead to suboptimal performance of the multipath connection, since individual subflows traversing distinct paths\n\nusually experience different RTT characteristics, which in turn lead to varying ACK receipts and, consequently, to\n\n3To avoid any confusion between the multiplicative decrease factor as defined within [42] ( _\ud835\udefd_ = 0 _._ 2) and the one specified within [89] ( _\ud835\udefd_ = 0 _._ 7), we have\nto clarify that both are using the same decrease factor. The RFC updates _ssthresh_ by exploiting the decrease factor directly, i.e. by: _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ = _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ \u2217 _\ud835\udefd_,\nwhile the paper calculates it using: _\ud835\udc60\ud835\udc60\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e_ = (1 \u2212 _\ud835\udefd_ ) \u2217 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ .\n\n16 D. Dimopoulos, et al.\n\ndiffering congestion window increase and decrease intervals. As a result, there is no perfect synchronization among\n\nsubflows regarding the congestion window increase and decrease events. Furthermore, a packet loss event on a particular\n\nsubflow would decrease the shared congestion window, degrading the performance of the entire multipath connection.\n\nThe second approach includes the detection of shared bottleneck links, and ensuring that no more than one subflow will\n\ntraverse such a link. While that approach was not that convincing a couple of years ago [44, 92], recent works provide\n\nthe means for accurate detection of shared bottlenecks [10], enabling also efficient coupling approaches [68]. The third\n\napproach considers individual congestion windows for each subflow of a multipath connection, where each subflow\n\nadjusts its own congestion window according to a weight, such that the entire multipath flow (comprising multiple\n\nsubflows) has the same aggressiveness as a standard TCP flow [44]. Building upon this approach, the work pursued in\n\n[44, 88] suggests to modify the legacy additive increase algorithm of the congestion avoidance phase, as follows:\n\n   - upon receipt of an ACK, increase congestion window by: _\ud835\udc64\ud835\udefc\ud835\udc5f_\n\n   - upon loss detection, decrease the congestion window by: _[\ud835\udc64]_ 2 _[\ud835\udc5f]_\n\nwhere _\ud835\udc64\ud835\udc5f_ is the congestion window of subflow _\ud835\udc5f_ . According to [44], the relation between the increase parameter _\ud835\udefc_\n\nand each subflow\u2019s individual weight factor _\ud835\udc37_ is denoted by _\ud835\udefc_ = _\ud835\udc37_ [2] (a). A weight factor of _\ud835\udc37_ = _\ud835\udc5b_ [1] [(b), where] _[ \ud835\udc5b]_ [is the]\n\nnumber of subflows belonging to a multipath connection, would couple the throughput of a multipath connection to the\n\nequivalent of a standard TCP connection within an RTT interval. Consequently, according to (a) and (b), the increase\n\nparameter should be: _\ud835\udefc_ = ~~\u221a~~ 1 ~~_\ud835\udc5b_~~ . While this approach ensures fairness among single- and multi-path flows traversing a\n\nshared bottleneck link where flows experience the same RTTs, it may lead to suboptimal resource utilization when the\n\nflows traverse multi-hop bottleneck paths encompassing varying RTTs and packet loss rates [88].\n\nThis is where _Coupled_ congestion control algorithm kicks in, managing to equalize the multipath flow\u2019s aggregate\n\nbandwidth with the one a regular TCP flow would get on the best path available to the multipath flow. Coupled\n\nalgorithm enables the multipath flow to first estimate the target rate of a regular TCP flow based on currently measured\n\npath conditions (i.e., RTT, packet loss rate). Then, it calculates the increase parameter _\ud835\udefc_ which controls the overall\n\naggressiveness of the protocol and assists in reaching the desirable target rate. Similarly to EWTCP [88], Coupled\n\nmodifies the additive increase algorithm of the congestion avoidance phase, while maintaining the legacy TCP\u2019s\n\nmultiplicative decrease, fast retransmit, and fast recovery schemes [2, 78].\n\nMore specifically [4],\n\n   - upon ACK receipt on _\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc5f_, increase the congestion window _\ud835\udc64\ud835\udc5f_ by: min( _\ud835\udc64\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udefc_ _[,]_ _\ud835\udc64_ 1 _\ud835\udc5f_ [)]\n\n   - upon loss detection on _\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc5f_, decrease the congestion window _\ud835\udc64\ud835\udc5f_ by: _[\ud835\udc64]_ 2 _[\ud835\udc5f]_\n\nNoteworthy here, is the fact that Coupled algorithm\u2019s design encompasses an adaptive behavior based on the level of\n\nstatistical multiplexing. In cases of high statistical multiplexing, where the multipath flow coexists alongside single-path\n\nflows, the multipath flow does not influence the link loss rates; in such scenarios, MPTCP will achieve the same\n\nthroughput as standard TCP on the best path. However, when low statistical multiplexing is present, in which case\n\nthe multipath flow influences the loss rate of the path, MPTCP\u2019s throughput is guaranteed to be higher than that of a\n\nsingle-path TCP flow on the best path; in that case, the achieved multipath throughput is expected to be equal to the\n\nsum of the idle paths\u2019 individual throughput, thus, fully aggregating the available bandwidth.\n\nContrary to EWTCP [88] where the increase parameter _\ud835\udefc_ was inversely proportional to the square root of the number\n\nof subflows, Coupled bases its decisions on how TCP would perform on the best path available at each RTT interval;\n\n4Details on the specific equations which determine the congestion window increase and decrease steps, are provided within the algorithm in 8.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 17\n\nsince path conditions in real networks are subject to constant and dynamic changes, Coupled needs to compute _\ud835\udefc_ [5] once\n\nper RTT or upon packet loss detection [6] [78].\n\nSince Coupled CCA couples only the congestion window increases, it satisfies Goals #1 & #2. To achieve Goal #3,\n\nwhich essentially implies perfect resource pooling [87], would require to couple also the multiplicative decrease phase,\n\nwhile ensuring that no traffic would be scheduled on links with higher loss rates. According to LIA\u2019s authors, given\n\nthe Internet\u2019s dynamic path conditions, such a restriction would lead the algorithm to _flappiness_ between paths and\n\ninsufficient probing of lossy paths, thus failing to utilize them quickly once they recover. The notion behind LIA\u2019s\n\noperation is to allocate congestion windows to the subflows, such that _\ud835\udc5d\ud835\udc56_ \u2217 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ is constant, for all _\ud835\udc56_ ( _\ud835\udc5d\ud835\udc56_ denotes the\n\npacket loss rate experienced by _\ud835\udc60\ud835\udc53\ud835\udc56_ ). This ensures that equal congestion windows will be allocated among subflows\n\nin case they experience equal loss rates, while higher congestion window values will be progressively allocated to\n\nless-lossy subflows when their packet loss rates differ.\n\nThe algorithmic steps of _LIA_ congestion control algorithm are presented in detail in 8.\n\n_2.3.3_ _Opportunistic Linked-Increases Algorithm (OLIA)._ LIA\u2019s shortcoming in fulfilling the third principle of multipath\n\ncongestion control, has gathered attention. Some more complex scenarios examining MPTCP connections\u2019 fairness to\n\nregular TCP flows under LIA congestion control, identified a couple of issues: i) the fact that upgrading TCP users to\n\nMPTCP has a negative impact to the remaining regular TCP flows without any added benefit to the MPTCP ones, and ii)\n\nthat MPTCP is over-aggressive to regular TCP flows [59]. Scientific research on this field, revealed that it is feasible to\n\nattain all three multipath congestion control goals simultaneously. As a result, _OLIA_ congestion control algorithm has\n\nbeen proposed as an alternative to LIA. Contrary to LIA, OLIA\u2019s design eliminates the trade-off between responsiveness\n\nand optimal congestion balancing, managing to provide a pareto-optimal solution which achieves both simultaneously.\n\nSimilarly to LIA, OLIA couples only the additive increase algorithm of the congestion avoidance phase; in case of loss,\n\nthe multiplicative decrease, as well as the fast retransmit and fast recovery, retain the legacy TCP NewReno approach.\n\nOLIA maintains a couple of variables, such as the set of paths over which subflows of the MPTCP connection\n\nhave been established ( _all_paths_ ), a subset of \"all_paths\" containing all presumably best paths ( _best_paths_ ), a subset of\n\n\"all_paths\" including paths with the largest congestion windows ( _max_w_paths_ ), and a subset of \"all_paths\" which also\n\nbelong to \"best_paths\" but are not among those exhibiting largest congestion windows ( _collected_paths_ ). Exploiting\n\nthese variables, the increase part of OLIA is defined as follows:\n\n   - for each ACK received on path r, increase the congestion window ( _\ud835\udc64\ud835\udc5f_ ) by:\n\n_\ud835\udc64\ud835\udc5f_ / _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_ [2]\n\n\ufffd\ufffd\n\ufffd\n\n\u2211\ufe01 _\ud835\udc64\ud835\udc5d_ / _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5d_ \ufffd [\ufffd]\n\n_\ud835\udc5d_ \u2208 _\ud835\udc45\ud835\udc62_ \ufffd\n\n2 [+] _\ud835\udc64_ _[\ud835\udc4e][\ud835\udc5f]_ _\ud835\udc5f_ (12)\n\n\u2211\ufe01\n\nwhere _\ud835\udc5d_ denotes a path on the set of \"all_paths\" _\ud835\udc45\ud835\udc62_, and _\ud835\udc64\ud835\udc5d_ and _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5d_ denote the congestion window and the\n\nround-trip time of path _\ud835\udc5f_, respectively. Equation 12 comprises two terms: the first term ensures Pareto optimality\n\nin resource pooling (satisfying MPTCP Goal #3: \"Balance congestion\"), while the second one, encompassing _\ud835\udefc\ud835\udc5f_,\n\nguarantees responsiveness and non-flappiness (satisfying MPTCP Goal #1: \"Improve throughput\", and Goal #2:\n\n\"Do no harm\") [59]\n\n5 _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ calculation formula: The calculation of _\ud835\udefc_ within algorithm\u2019s step #2 in 8, is derived by equalizing the rate of the multipath flow with the rate of a\nTCP running on the best path, and solving for _\ud835\udefc_ .\n6The pseudo-code steps showcase the congestion window increment and _\ud835\udefc_ computation per ACK; in actual implementations, however, such computations\nare performed once per RTT or upon packet loss detection.\n\n18 D. Dimopoulos, et al.\n\n_\ud835\udc4e\ud835\udc5f_ is calculated as follows:\n\n**\u2013** if _\ud835\udc5f_ is within the _collected_paths_, then: _\ud835\udc4e\ud835\udc5f_ = | [1] _\ud835\udc50\ud835\udc5c\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc52\ud835\udc51_ [/] _[\ud835\udc5b\ud835\udc62\ud835\udc5a]_ [_] _[\ud835\udc5c]_ _[\ud835\udc53]_ _ [_] _\ud835\udc5d\ud835\udc4e\ud835\udc61\u210e\ud835\udc60_ _[\ud835\udc5d][\ud835\udc4e\ud835\udc61\u210e\ud835\udc60]_ |\n\n**\u2013** if _\ud835\udc5f_ is within the _max_w_paths_ and if _collected_paths_ is not empty, then: _\ud835\udc4e\ud835\udc5f_ = \u2212 [1] | [/] _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _[\ud835\udc5b\ud835\udc62\ud835\udc5a]_ _ [_] _\ud835\udc64_ _[\ud835\udc5c]_ _ _[\ud835\udc53]_ _\ud835\udc5d\ud835\udc4e\ud835\udc61\u210e\ud835\udc60_ [_] _[\ud835\udc5d][\ud835\udc4e\ud835\udc61\u210e\ud835\udc60]_ |\n\n**\u2013** otherwise, _\ud835\udc4e\ud835\udc5f_ = 0.\n\n- for each loss on path r, decrease the congestion window ( _\ud835\udc64\ud835\udc5f_ ) by: _[\ud835\udc64]_ 2 _[\ud835\udc5f]_ [.]\n\nOLIA adapts the congestion window increases as a function of the underlying paths\u2019 RTTs, thus efficiently compen\n\nsates for different RTTs. Analytical results and testbed experiments prove that OLIA provides fairness among coexisting\n\nTCP and MPTCP flows, as well as optimal congestion balancing, while remaining as responsive and non-flappy as LIA.\n\nThe algorithmic steps of _OLIA_ congestion control algorithm are presented in detail in 9.\n\n_2.3.4_ _Balanced Linked Adaptation (BALIA)._ A subsequent work has identified that OLIA also suffers a shortcoming,\n\nthat is, its limited responsiveness to dynamic network conditions when the used paths experience similar round-trip\n\ntimes (RTTs). To confront OLIA\u2019s weakness, meticulous research conducted in the context of [74] devised BALIA\n\nwhich, similarly to its predecessors LIA and OLIA, is a window-based coupled congestion control algorithm designed\n\nfor MPTCP. This work identified an inevitable tradeoff between friendliness, responsiveness, and window oscillation\n\nof congestion control schemes, and proposed an analytical framework that enables the aforementioned properties\u2019\n\nassessment for any congestion control algorithm, already from the design phase.\n\nLeveraging the designed analytical framework to prove BALIA\u2019s unique equilibrium point and asymptotical stability,\n\nand confirming it through experimental evaluation, BALIA\u2019s authors managed to successfully mitigate the tradeoff\n\nand provide balanced performance. As with LIA and OLIA, BALIA modifies the additive increase (AI) algorithm of the\n\ncongestion avoidance phase, while maintaining the TCP NewReno fast retransmit & recovery algorithms. In case of\n\nloss, BALIA adjusts the TCP NewReno multiplicative decrease (MD) algorithm, multiplying it by a factor in the range of\n\n[1, 1.5]. In case of single path use, BALIA reduces to the standard TCP NewReno increment and decrement algorithms.\n\nThe algorithmic steps of _BALIA_ congestion control algorithm are presented in detail in 10.\n\n_2.3.5_ _Weighted Vegas (wVegas)._ An alternative approach to the aforementioned loss-based congestion control schemes\n\n(i.e., LIA, OLIA, BALIA), is _wVegas_ which bases its decisions on queuing delay measurements. wVegas builds upon the\n\nrespective standard TCP congestion control algorithm TCP-Vegas, and is adapted to serve the fairness requirements\n\nof multipath environments. Contrary to other coupled multipath congestion control schemes (e.g., LIA, OLIA, and\n\nBALIA) that estimate network congestion through packet losses, wVegas interprets queuing delay as congestion signal,\n\nthus being more sensitive to network condition changes in an attempt to achieve fine-grained load balancing. wVegas\n\nfocuses on satisfying the \"Congestion Equality Principle\" [9], where all flows attempt to allocate a fair share of the\n\navailable bottleneck bandwidth via an equal share of the congestion cost. For this purpose, wVegas assigns a weight to\n\neach subflow belonging to a multipath flow, and adaptively adjusts this weight according to the Congestion Equality\n\nPrinciple. The weight quantifies, in essence, the aggressiveness of each subflow on acquiring part of the available\n\nbandwidth. Subflows established on less congested paths are expected to be assigned a larger weight value, allowing\n\nthem to compete for bandwidth more aggressively; this competition is expected to increase the underlying path\u2019s\n\ncongestion, which will in turn lead to decrease of the subflow\u2019s weight value on that path. This cycle is executed for all\n\nsubflows traversing the various paths until congestion equilibrium is reached; at that point network resources will be\n\nfairly shared by all flows.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 19\n\nDiving deeper into the design principles of the algorithm, wVegas is essentially assigning a fixed parameter _\ud835\udefc_ = 10\n\nto each one of the multipath flows. This parameter determines the total number of bytes backlogged in the network\n\nfor all subflows belonging to a MPTCP flow [9, 90]. Each subflow (e.g., assuming a subflow on path _\ud835\udc5f_ ) belonging to a\n\nbroader multipath flow, is then assigned a portion of this value (e.g., _\ud835\udefc\ud835\udc5f_ ) according to the weight corresponding to this\n\nsubflow _\ud835\udc64\ud835\udc5f_ . The weight is calculated as the portion of a subflow\u2019s rate to the overall rate of the entire multipath flow, as\n\ndepicted in 14.\n\nThe _rate_ and _weight_ of a subflow _\ud835\udc5f_ is respectively provided by the below equations:\n\n_\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc5f_ = _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc5f_ / _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_ (13)\n\n_\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc5f_ = _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc5f_ / [\ufffd] _\ud835\udc56_ [(] _[\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52]_ _\ud835\udc56_ [)] (14)\n\nwhere [\ufffd] _\ud835\udc56_ [(] _[\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52]_ [_] _[\ud835\udc56]_ [)][ denotes the aggregate rate achieved by all subflows of the multipath flow.]\n\nThe portion of _\ud835\udefc_ [7], which then corresponds to a subflow on path _\ud835\udc5f_, _\ud835\udefc\ud835\udc5f_, is calculated as follows:\n\n_\ud835\udefc\ud835\udc5f_ = _\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc5f_ \u2217 _\ud835\udefc_ (15)\n\nWithin wVegas, _\ud835\udefc\ud835\udc5f_ serves as a threshold which controls whether the equilibrium rate should be updated, and whether\n\nthe congestion window of the respective subflow established on path _\ud835\udc5f_ will increase or decrease at the end of each RTT\n\ninterval. If the currently measured rate deviates from the expected equilibrium rate beyond _\ud835\udefc\ud835\udc5f_, then the congestion\n\nwindow is decreased at the end of the RTT; otherwise it is increased. The aforementioned rate difference is calculated\n\nwithin the wVegas\u2019 weight adjustment algorithm as follows:\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_\n_\ud835\udc51\ud835\udc56\ud835\udc53\ud835\udc53_ =\n\ufffd _\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ [\u2212] _[\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51]_ _\ud835\udc5f\ud835\udc61\ud835\udc61_\n\n  - _\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ (16)\n\ufffd\n\nConsequently, wVegas adjusts parameter _\ud835\udefc_ dynamically, thereby influencing the transmission rate of the correspond\ning subflow and managing to equalize congestion on the path. Normalized _\ud835\udefc_, that is _[\ud835\udefc]_ _\ud835\udefc_ _[\ud835\udc5f]_ [, is essentially the weight factor]\n\n_\ud835\udc64\ud835\udc5f_ applied on the subflow established on path _\ud835\udc5f_ . The packet queuing delay measurement employed by wVegas is meant\n\nto provide a more accurate estimation of the underlying path\u2019s congestion compared to loss-based techniques. Since\n\nwVegas maintains a moderate buffer occupancy in link queues, it accounts for congestion proactively and rarely leads\n\nto packet losses. On the contrary, loss-based congestion control schemes try to fill in intermediate queues before a loss\n\nis detected and backoff procedure begins. However, wVegas experiences some shortcomings, such as its reliance on\n\naccurate RTT measurements, its less aggressive behavior when competing with loss-based algorithms, as well as its\n\nlimited efficiency on high BDP paths.\n\nThe algorithmic steps of _wVegas_ congestion control algorithm are presented in detail in 11.\n\n_2.3.6_ _Bottleneck Bandwidth and Round-trip propagation time (BBR)._ Traditional loss-based congestion control algo\n\nrithms cycle through the process of filling in the bottleneck link and any intermediate queues, and then responding\n\nto the detected bufferbloat-induced loss. Deviating from such loss-based schemes, _BBR_ follows a different approach,\n\ninspired by the delay-based control logic proposed within TCP-Vegas [5]. Contrary to the operation of loss-based\n\nschemes, BBR attempts to identify a bottleneck link\u2019s optimal operating point. Such a point entails maximum utilization\n\nof the underlying link\u2019s capacity at the lowest round-trip delay. At each moment, a sender operating at this optimal\n\n7Parameter _\ud835\udefc_ is associated with a MPTCP flow, while _\ud835\udc4e\ud835\udc5f_ is associated with a specific subflow _\ud835\udc5f_ of that MPTCP connection. Parameter _\ud835\udefc_ is referred to\nas _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ within the algorithmic steps in 11. Similarly, the aggregate rate of all MPTCP subflows, denoted as [\ufffd] _\ud835\udc56_ [(] _[\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52]_ _\ud835\udc56_ [)][ in 14, is referred to as]\n_\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ into the algorithmic steps.\n\n20 D. Dimopoulos, et al.\n\npoint, transmits at the bottleneck link rate, while simultaneously ensuring that no intermediate queues are formed.\n\nThis prevents round-trip delay increases and minimizes the packet loss probability.\n\nFor this purpose, BBR makes use of two parameters: _BtlBw_ (bottleneck bandwidth) and _RTprop_ (round-trip propagation\n\ntime); the first tracking bottleneck link\u2019s capacity, and the latter the round-trip delay. Rtprop reflects the base RTT and\n\nis used to measure any subsequent round-trip delay updates. Given a fixed data path, RTprop remains constant up to\n\nthe point where intermediate queues begin to be formed; from that point onward, an increase in RTT indicates that the\n\npipe is already full and the sending rate exceeds bottleneck bandwidth. An increase in RTprop while BtlBw remains\n\nconstant, allows BBR to infer that intermediate queues have started to be filled in. Bottleneck bandwidth (BtlBw) is used\n\nto probe for any updates in the underlying bottleneck capacity by comparing it with the actual delivery rate (DelRt).\n\nBBR attempts to estimate the bottleneck link\u2019s optimal operating point by trying to estimate these two parameters. The\n\nconstraints reflected through these parameters are intrinsically contradicting, meaning that the operating point where\n\none can be measured, hinders the measurement of the other. Measuring RTprop, for instance, requires that inflight\n\npackets remain below BDP, so that the link is underutilized. On the other hand, bottleneck bandwidth estimations\n\nrequest for probing above the known BDP, which could lie in the region where queues start to be formed, in case\n\nbottleneck capacity has not changed.\n\nIn order for a link to be fully utilized at each moment, BDP amount of data should be inflight, where _\ud835\udc35\ud835\udc37\ud835\udc43_ =\n\n_\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ \u2217 _\ud835\udc45\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ . BtlBw controls the sending rate and ensures full bandwidth utilization, while Rtprop guarantees an\n\nalways full pipe by managing the volume of inflight data; an amount of data less than the optimal would cause link\n\nstarvation, while an excess would overfill the pipe and lead to developing queues. To accurately measure BtlBw and\n\nRTprop, BBR implements a state transition model, cycling over different states, such as the _Startup_, _Drain_, _Probe_BW_, and\n\n_Probe_RTT_ . During Startup phase, a flow\u2019s congestion window increases exponentially, similarly to that of loss-based\n\ncongestion control schemes; however the congestion window increase with BBR is smoother and the algorithm does not\n\nback off in case of packet loss or delay increase, maintaining its robustness toward discovering the available bandwidth.\n\nThe Startup phase is over once the bottleneck bandwidth is considered to be successfully detected. Then, BBR enters\n\nthe Drain phase, the purpose of which is to drain any queues formed during Startup. The Drain phase lasts one RTT\n\ninterval, managing to clean up any filled queues rapidly. Once BBR estimates that the queue is empty and the link is\n\nsufficiently filled with BDP data inflight, it leaves Drain and enters Probe_BW phase. BBR consumes the majority of\n\nits time in this phase, keeping a BDP of data inflight, paced at a rate equal to the BtlBw estimate. The _pacing_gain_\n\nparameter used in this phase controls the way the algorithm probes for updates in BtlBw estimation. More specifically,\n\nProbe_Bw phase consists of eight-cycle rounds, each lasting an RTprop interval. A full Probe_BW round involves\n\ncycling through pacing_gain values in the following order: {5/4 _,_ 3/4 _,_ 1 _,_ 1 _,_ 1 _,_ 1 _,_ 1 _,_ 1} [10]. According to this pacing_gain\n\nsequence, BBR spends one round exploring whether bottleneck bandwidth has increased, thus probing at a rate equal\n\nto 5/4 of the current estimate. Then, pacing_gain decreases equally to the initial increase portion (3/4), draining any\n\nqueues formed during the previous round. BBR spends the next six rounds \"cruising\" at BtlBw rate, thus achieving the\n\nhighest link utilization with minimum delay.\n\nIf probing for higher bandwidth leads to higher delivery rate, BBR updates its bottleneck bandwidth estimation\n\nand adapts traffic transmission rate at the new delivery rate. If probing for higher bandwidth is not accompanied by\n\ndelivery rate increase, it means that the current transmission rate already matches the bottleneck link\u2019s capacity, and the\n\nexcess data transmitted during BtlBw probing leads to queue formation, which is also perceptible through a subsequent\n\nincrease in RTprop.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 21\n\nIn case RTprop estimate has not been updated by a lower RTT measurement within 10 seconds of operation into the\n\nProbe_BW phase, BBR enters Probe_RTT phase. The intention of this phase is to obtain an accurate measurement of\n\nthe base RTT by reducing the congestion window (cwnd) to a very small value (i.e., four packets). After remaining in\n\nProbe_RTT phase for at least 200ms and one RTT [10], BBR enters either Startup or Probe_BW phase, depending of the\n\nBtlBw estimate; if BtlBw indicates a full pipe, BBR transitions to Probe_BW phase; otherwise to Startup.\n\nAnother important parameter used in BBR [8] is the _cwnd_gain_ which bounds the amount of data inflight in each state;\n\ncwnd_gain is different from the pacing_gain, in that the first allows for an upper bound of inflight data, while the latter\n\ncontrols the sending rate and consequently influences the amount of outstanding data occupying the link.\n\nWhat distinguishes BBR from AIMD algorithms, is the fact that it is proactive to loss, operating at the point where\n\nintermediate queues start to be formed, whereas AIMD schemes operate at the saturation point where queues are\n\nalready full, merely reacting to detected loss. BBR\u2019s subtle traffic pacing at a rate equal to bottleneck link\u2019s bandwidth,\n\ndiffers from traditional AIMD algorithms whose sending scheme follows a bursty pattern within each RTT interval [47].\n\nIn the context of multipath communications, BBR is deemed an uncoupled congestion control scheme. In the following\n\nsubsection, a coupled alternative, based on BBR, is presented (C-MPBBR).\n\nThe algorithmic steps [9] of _BBR_ congestion control algorithm are presented in detail in 12.\n\n_2.3.7_ _Coupled Multipath BBR (C-MPBBR)._ C-MPBBR arose from an attempt to create a coupled congestion control\n\nalgorithm for MPTCP, on the basis of BBR. The main goals C-MPBBR aims at fulfilling, are the following:\n\ni. Goal #1: to incentivize the use of MPTCP over standrard single-path TCP connections, which implies that\n\nMPTCP performs at least as well as a single-path TCP (SPTCP) flow on the best path, and\n\nii. Goal #2: to reinforce fairness among flows consuming the resources of a shared bottleneck.\n\nTo achieve Goal #1, C-MPBBR continuously measures the bottleneck bandwidth (BtlBw) and the actual delivery rate\n\n(DelRt) using BBR\u2019s existing parameters. If the algorithm identifies that, during five consecutive ProbeBw rounds, the\n\naggregate throughput of the MPTCP subflows is below that of a single-path flow on the best path, it closes the subflow\n\nexperiencing the lowest performance. The algorithm performs the same operation for as long as the same condition\n\nholds true, up until the point where only a single subflow remains available; at that point, an MPTCP connection\n\ncomprising one subflow is equivallent to a SPTCP flow, acquiring and utilizing the same amount of resources.\n\nC-MPBBR adheres to Goal #2 by ensuring that the aggregate amount of bandwidth allocated to the subflows of a\n\nMPTCP connection equals that of a SPTCP flow, when sharing the same bottleneck link. C-MPBBR satisfies fairness\n\namong single- and multi-path flows, by exploiting the BtlBw parameter value. The BtlBw estimations, which are\n\nmeasured individually by each subflow, allow the algorithm to infer whether the subflows of a MPTCP connection\n\ntraverse the same bottleneck link. In that case, the BtlBw value measured by an individual subflow is divided by the\n\nnumber of subflows sharing the same bottleneck link, so that multipath flows are allocated their fair share when\n\ncompeting against single-path flows for bottleneck resources.\n\nC-MPBBR is a worth-researching coupled congestion control scheme, as it manages to combine the state-of-art\n\ntechnology inherited from BBR, along with MPTCP\u2019s _aggregation benefit_ [56] and _fairness_ concepts [27, 31]; initial\n\ntests [68] showcased that it fulfills both goals when compared to coupled loss-based congestion control schemes (i.e.,\n\nLIA, OLIA, BALIA), or other BBR-based variants. For this reason, we selected to include C-MPBBR within our own\n\n8It is important to mention here that throughout our work, any reference to BBR is referred to _BBR v1_ [10, 11], which is also available in the older\nMPTCPv0 linux kernels. However, BBR is still under development at the time of this publication. IETF details in regard to BBR are referred to BBR v2 [12].\n9An abstract version of BBR algorithm\u2019s pseudo-code is provided in 12, as originally published for BBR_v1 within [11]. BBR actually spans more than a\nthousand lines of C code, details of which can be found within [11, 12, 14, 54].\n\n22 D. Dimopoulos, et al.\n\nexperimentation campaign, and verify its behavior both compared to other congestion control schemes, as well as in\n\ncombination with various MPTCP packet scheduling algorithms.\n\nThe pseudo-code determining _C-MPBBR\u2019s_ operation toward fulfilling its incentive and fairness goals, is presented in\n\n13."}, {"role": "assistant", "content": "**Mechanism:** MPTCP fundamentally operates by abstracting multiple underlying TCP connections (called 'subflows') into a single logical application-level connection. This is achieved by introducing a 'meta-level' atop the standard TCP 'subflow-level'. The core mechanism relies on unique sequence spaces: standard TCP sequence numbers (SN) and acknowledgments (ACK) at the subflow level for individual path reliability, and a 'Data Sequence Number (DSN)' and 'Data ACK' at the connection level for end-to-end in-order delivery to the application. This dual sequencing allows independent management of subflows while guaranteeing correct reassembly. The 'Path Manager' is essentially a state machine that monitors network interface availability and lifecycle of subflows (analogous to a connection pool manager). The 'Packet Scheduler' is a dispatch algorithm (like a prioritized queue or a load balancer) that determines which available subflow receives the next data segment based on a policy (e.g., lowest RTT, avoiding Head-of-Line blocking, or even redundant transmission). Congestion Control algorithms manage the 'congestion window (cwnd)' on each subflow. Traditional TCP (Reno, CUBIC) uses an AIMD (Additive Increase, Multiplicative Decrease) feedback loop where cwnd grows linearly (or cubically for CUBIC) during 'congestion avoidance' and halves on packet loss. 'Coupled' algorithms modify this increase to ensure fairness across multiple subflows competing for shared bottlenecks, often by dynamically adjusting a multiplicative factor for `cwnd` increments. 'Delay-based' algorithms like wVegas and BBR diverge by using real-time RTT measurements and bandwidth estimations, respectively, to proactively infer congestion (e.g., queuing delay) and adjust sending rates. BBR, for instance, uses a state machine to actively probe and estimate the 'Bottleneck Bandwidth (BtlBw)' and 'Round-Trip Propagation Time (RTprop)', then uses these estimates to pace traffic and maintain an 'in-flight' amount close to the 'Bandwidth-Delay Product (BDP)' to maximize throughput with minimal queueing.\n\n**Explanation:** At its heart, MPTCP extends TCP to use multiple network paths for a single data stream. Think of it as managing several regular TCP 'sockets' (subflows) under one 'master socket' (the MPTCP connection). Each subflow acts like a normal TCP connection, handling its own reliability and ordering for its segment of data. However, because data can arrive out of order from different subflows (due to varying path speeds), MPTCP adds an extra layer of sequencing (DSN) to reassemble the full data stream correctly for the application. The 'Path Manager' is like a dynamic hash map, keeping track of available network interfaces and their associated subflows, and managing their creation and deletion based on network events. The 'Packet Scheduler' is a complex 'if-else' logic or a scoring function that decides which subflow to write the next data chunk to, based on criteria like Round Trip Time (RTT), congestion window space, or even predicted future delays. For example, `minRTT` is a simple greedy choice, always picking the 'fastest' available subflow. `BLEST` adds a predictive 'look-ahead' step, checking if using a slow path now would cause problems later for a faster path, effectively trying to avoid a 'head-of-line' blocking condition by skipping a slower subflow. Congestion control algorithms, like `TCP Reno` or `CUBIC`, are feedback loops. They adjust how much data can be 'in flight' (`cwnd`) based on acknowledgments or packet loss. `cwnd += SMSS * SMSS / cwnd` means that the window grows faster when it's smaller, and slower as it gets larger, aiming for a linear growth over a full RTT. `CUBIC` replaces this linear growth with a cubic function, `W(t) = C(t - K)^3 + Wmax`, allowing for much faster window increases in high-bandwidth, high-delay networks, quickly recovering to previous peaks and then probing for new capacity with increased aggressiveness. 'Coupled' algorithms, like LIA, ensure that the *total* `cwnd` across all subflows doesn't unfairly consume more network resources than a single TCP flow would, by adjusting individual subflow `cwnd` increments with a scaling factor (`alpha`) based on the number of active subflows and their RTTs. `wVegas` uses the difference between the actual RTT and the 'base RTT' (minimum observed RTT) as a proxy for queueing delay, `diff = cwnd/baseRTT - cwnd/rtt`. If this difference is too large, it means too much data is queuing, and it reduces `cwnd` proactively. `BBR` goes even further, acting as a system identification controller. It actively measures 'Bottleneck Bandwidth' (how fast the pipe is) and 'Round-Trip Propagation Time' (how long the pipe is), then calculates the optimal 'in-flight' data (BDP) and sets the sending rate to match the bottleneck bandwidth, aiming to keep queues empty. Its state machine ('Startup', 'Drain', 'Probe_BW', 'Probe_RTT') is a carefully designed sequence of actions to discover and maintain these optimal parameters."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section introduces the Adaptive Drafter component of\nTLT, focusing on how it creates, trains, and utilizes draft\nmodels to accelerate the reasoning RL process without interference with the primary RL workload.\n\n**4.1** **Draft Model**\n\nTLT utilizes a compact, specialized model trained to mimic\nthe target LLM\u2019s token generation behavior, enabling efficient and accurate speculative execution.\n**Model Architecture** . To maximize efficiency, TLT adopts a\nhighly lightweight, _single-layer_ model design for the drafter\n\n[26, 27, 67]. In this context, a \"layer\" refers to one complete\ntransformer decoder block, including attention and feedforward components. This approach differs from vanilla speculative decoding [5, 22], which often uses a separate, smaller\nmulti-layer LLM from the same family (e.g., Qwen2.5-0.5B\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-4-0.png)\n\n\u2465Training\nStrategies \u2463HiddenStates \u2464LossFunc\nTime Test\n\nEagle [26] Last layer L1 + CE loss N.A.\nHASS [67] Last layer L1 + CE loss 3 steps\n\nTop, mid and\nEagle-3 [27] CE loss only 7 steps\nbottom layers\n\n**Figure 7. Draft Model Training** . _Upper_ : Unified training\nworkflow using target model hidden states. _Lower_ : Specific\nconfigurations of different training strategies.\n\nfor a Qwen2.5-32B target). The vanilla approach has drawbacks: suitable and accurate small drafters may not exist for\nevery target LLM, not to mention that these smaller models can still incur substantial drafting latency. For instance,\nwhile Qwen2.5-32B has 64 layers, Qwen2.5-0.5B still contains\n24 layers. Although the parameter count is reduced significantly (64\u00d7 in this case), latency remains dominated by the\nsequential computation across multiple layers. Experiments\ndemonstrate that TLT\u2019s single-layer draft model, sharing approximately the same parameter count as the Qwen2.5-0.5B\ndrafter, is significantly faster (2.4\u00d7).\nAs illustrated in Figure 7 (blue block), the TLT drafter\nmirrors the target model\u2019s architecture but incorporates\nonly a single, trainable decoder layer. It reuses the target\nmodel\u2019s original Embedding and LM Head layers, keeping\ntheir weights frozen during training. Consequently, only the\nsingle decoder layer\u2019s parameters are updated, representing\na small fraction (approximately 1/layer_num) of the target\nmodel\u2019s total parameters. This architectural design significantly reduces both training and inference overhead. The\neffectiveness of such single-layer drafters is corroborated by\nprior work [2, 14, 25\u201327, 67], which has shown their capability to closely align with the target model\u2019s auto-regressive\ndistribution and achieve high acceptance rates for speculative tokens. During operation, the trained drafter takes\nhidden states from the target model and auto-regressively\ndrafts subsequent tokens for verification.\n**Training Process** . TLT builds a unified training framework\nthat supports diverse draft model training strategies and integrates seamlessly with the RL workflow. As depicted in\nFigure 7, the training process leverages data generated during\n\n5\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-5-0.png)\n\nTrainer is designed to counteract this drift without hindering the primary RL workflow. To achieve this goal, TLT\nincorporates the following novel designs:\n**Worker Coordinator** . It aims to bridge the gap between the\nRollout Engine and the Spot Trainer, coordinating resource\nallocation, particularly repurposing GPU resources that become idle during the long-tail phase of rollout. In TLT, a\n_worker_ is the basic unit of resource management, defined\nas one rollout instance. For example, when rollout uses a\nfull DGX-H100 node with TP=8, a single worker represents\n8 GPUs. The coordinator follows a centralized model im\nplemented with ZeroMQ [17], where a single coordinator\nprocess (rank 0) maintains the global state and workers communicate through asynchronous request-reply patterns. By\nmonitoring active request counts and worker states, the coordinator determines when workers can be migrated from\nrollout to opportunistic drafter training. Each worker cycles\nbetween three states\u2014 _BUSY_ (serving rollout), _IDLE_ (inference finished and memory released), and _TRAINING_ (engaged in drafter updates)\u2014and notifies the coordinator on\nevery transition. Once the number of idle workers exceeds\na configurable threshold, the coordinator promotes them to\ntraining mode and initiates drafter training.\nTraining initiation follows a leader-election pattern, where\nthe first eligible worker sets up the training session and later\nworkers can join if they belong to the same data-parallel\ngroup. When rollout completes, the coordinator immediately\nhalts any ongoing drafter training and performs a graceful\nshutdown to ensure proper cleanup. This design ensures\nthat idle GPU cycles during long-tail rollouts are effectively\nexploited without interfering with the primary RL workflow.\n**Spot Training with DataBuffer** . Figure 8 contrasts our\nSpot Trainer approach with standard RL workflows. Vanilla\nRL (a) involves a sequential process: rollout, target & reference model inference for KL divergence calculation, and\ntarget model training (reward calculation is fast and omitted\nfor brevity). A naive integration of drafter training (b) typically adds it as another sequential step, although reusing\nsome prefilling computations but still incurs extra overhead.\nIn contrast, the Spot Trainer (c) operates on the principle\nthat draft model training can proceed effectively without\nwaiting for all generated responses to complete, allowing\ntraining to execute in a non-blocking manner. Due to the\nlong-tail distribution in reasoning RL tasks, a majority of\nresponses are generated significantly faster than the longest\nones. The Spot Trainer leverages this observation by using\npartial of responses to train the draft model. However, relying only on early finishes means the drafter rarely sees very\nlong sequences, which can introduce distribution mismatch.\nTo address this, TLT introduces the DataBuffer, which decouples drafter training from rollout completion. The DataBuffer\ncaches hidden states and tokens produced during the inference stage and loads them with minimal overhead. Crucially,\nit supports _one-step offset_ sampling: we persist the buffer\n\n|Rollout with Adaptive SD|Reference|Target|Target Training|\n|---|---|---|---|\n|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|(c) SecRL with Sot Trai<br>Tar Drafter Training<br>DataBufer<br>\u2460Partial Responses<br>\u2461One-Step Of|\n\n**Figure 8. Spot Trainer Workflow** . Block lengths are illustrative and not strictly proportional to execution time.\nNote that target model prefilling during drafter training is\noptional since hidden states from the rollout engine can be\nused directly.\n\nthe RL workflow. Specifically, input prompts are first processed by the target model to generate rollout responses (\u2460,\n\u2461). During the subsequent prefilling (i.e., inference) phase,\nhidden states are collected from specific layers of the target model (\u2462). These collected hidden states, concatenated\nwith input token embeddings, are then passed through a\nlightweight linear layer for dimension reduction. Then the\noutput features serve as input to the drafter\u2019s single decoder\nlayer for training (\u2463). Given the target model\u2019s significantly\nlarger size (over 20\u00d7 than the draft model), its prefilling cost\ncan be far more expensive than one drafter training iteration.\nIn TLT, we cache the hidden states generated during the\ninherent RL inference phase to host memory and reuse them,\nthereby eliminating this overhead.\nTLT also accommodates multiple training objectives. The\nframework can apply an L1 loss between the hidden states\nof the target and draft models to align their representations,\na cross-entropy (CE) loss on the output logits to match token\npredictions, or a combination of both (\u2464). The computed loss\nis then backpropagated to update only the drafter\u2019s decoder\nlayer, while embeddings and the LM head remain tied to the\ntarget model (\u2465).\nAdditionally, several training strategies are supported\nwithin this unified pipeline in TLT. For instance, EAGLE\n\n[26] uses only the last layer\u2019s hidden states; HASS [67] further enhance the training by feeding the output feature of\ndraft model back into itself for multiple time (i.e., trainingtime test); EAGLE-3 [27] further fuses multi-layer hidden\nstates from the target model, aiming for better acceptance\nrates. Despite these differences, all these variants can be\nnaturally expressed within our training framework. In this\nwork, we use the EAGLE model as the default, as it offers\nhigh accepted lengths and faster convergence with much\nlower training cost.\n\n**4.2** **Spot Trainer**\n\nThe key challenge in applying speculative decoding within\nRL training is the _evolving target model_ ( **C1** ), causing a fixed\ndraft model to quickly become stale and ineffective. Spot\n\n6\n\nDepth = 1 Depth = 2 Depth = 3 Depth = 4\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-6-0.png)\n\n|8|4|16|6|32|8|48|8|\n|---|---|---|---|---|---|---|---|\n|S1:{V=8, D=4}|S1:{V=8, D=4}|S2:{V=16, D=6}|S2:{V=16, D=6}|S3:{V=32, D=8}|S3:{V=32, D=8}|S4:{V=48, D=8}|S4:{V=48, D=8}|\n\n|Prompt<br>Climate|change<br>(04)<br>.<br>control<br>(025)<br>.<br>DraftingStage|will<br>(012)<br>.<br>is<br>(025)<br>.<br>can<br>(006)<br>.<br>systems<br>(013)<br>.|a<br>(015)<br>.<br>very<br>(005)<br>.<br>are<br>(004)<br>.<br>often<br>(002)<br>.|global<br>(007)<br>.<br>serious<br>(003)<br>.<br>urgent<br>(001)<br>.<br>important<br>(002)<br>.|Col6|\n|---|---|---|---|---|---|\n|Climate<br>**Prompt**|control<br>(0.25)<br>change<br>(0.4)<br>**Drafting Stage**|will<br>(0.12)<br>is<br>(0.25)<br>can<br>(0.06)<br>systems<br>(0.13)|a<br>(0.15)<br>very<br>(0.05)<br>are<br>(0.04)<br>often<br>(0.02)|Drafted Token<br>(Prob.)<br>Token to Verify<br>(Prob.)|Drafted Token<br>(Prob.)<br>Token to Verify<br>(Prob.)|\n\n**Figure 9. Example of Tree Decoding** . We set topK=2,\nDraft_Depth=4, and Tokens_to_Verify=8 in this example.\nProb. denotes token probability given by the draft model.\n\nacross RL steps and prioritize long sequences from the previous step to compensate for the scarcity of long-tail data in the\ncurrent partial set. Although these samples are slightly stale,\nthey remain effective for drafter training. Our experiments\nshow that combining partial current-step data with buffered\nlong sequences attains performance comparable to training\non the full response set. Drafter updates are scheduled as\nlow-priority \u201cspot tasks\u201d on idle GPUs, effectively harvesting\ncompute freed by the long tail while keeping the main RL\nworkflow non-blocking.\n**Selective Asynchronous Checkpointing** . A key design\nfeature of the Spot Trainer is its preemptibility, allowing\nit to utilize idle resources without blocking the main RL\nworkload. However, preemptions may lead to substantial\nloss of the draft model\u2019s training progress. To address this,\nthe Spot Trainer utilizes asynchronous checkpointing: when\ntriggered, the process of saving the draft model\u2019s state is offloaded to a background thread. Moreover, we optimize this\nprocess by filtering out frozen layers (e.g., embeddings and\nthe LM head) and dumping only the trainable parameters, significantly reducing checkpointing latency. This mechanism\nminimizes work lost due to preemption through frequent\nand efficient checkpointing.\n**Sequence Packing** . The training data inherently consists\nof sequences with variable lengths. Standard batching techniques often require padding sequences to a uniform length,\nleading to inefficiency of computation, communication, and\nmemory. To maximize GPU utilization during opportunistic\ndrafter training, the Spot Trainer employs sequence packing\n\n[20]. This technique concatenates multiple variable-length\nsequences into a single packed sequence, removing padding\nwhile using attention masks to preserve sequence integrity\nduring parallel processing. This enables efficient processing of the unbalanced training data within the limited, preemptible time slots available for spot training."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around a single-layer transformer decoder acting as a highly efficient 'prediction proxy' for a larger, evolving target LLM. It learns to predict the subsequent token's logit distribution or hidden state representation by directly observing and matching the target model's internal states, thus enabling rapid speculative execution. This proxy model is kept continuously fresh through opportunistic, non-blocking training on dynamically allocated idle GPU resources, utilizing a buffered data sampling strategy to overcome data distribution mismatches inherent in partial and long-tail sequences.\n\n**Explanation:** Think of an LLM generating text as a complex, sequential calculation where each step depends on the previous one. This paper introduces a highly specialized 'shortcut' model, the 'draft model', which is essentially a single transformer decoder block. Instead of predicting the next token from scratch like the big LLM, it learns to predict the *next internal state transformation* or *next token probabilities* by directly tapping into the hidden states of the big LLM. It's like finding a small function `f(hidden_state_t) -> hidden_state_t+1` or `f(hidden_state_t) -> logits_t+1` that mirrors just one layer of the larger LLM. Because it's only one layer and reuses the big LLM's initial embedding and final output layers, it's incredibly lightweight and fast. The genius part is keeping this small model up-to-date. During RL training, the main LLM is constantly changing. A 'Worker Coordinator' acts like a task scheduler, identifying GPUs that have finished their primary RL 'rollout' tasks and would otherwise be idle. It then 'spots' these idle GPUs and assigns them to train the draft model. To ensure the draft model learns effectively, a 'DataBuffer' stores historical hidden states and tokens, allowing the trainer to combine current, rapidly available short sequences with older, longer sequences. This prevents the draft model from only seeing short examples. If the main RL task needs the GPU back, the draft model training uses 'asynchronous checkpointing' to quickly save only its few updated parameters, minimizing lost work. Finally, 'sequence packing' is used to efficiently batch variable-length training data, maximizing GPU throughput during these opportunistic training windows, much like fitting multiple small programs into a single larger memory block to process them without wasted space."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**125** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc38\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc62\ud835\udc5d_ () ;\n\n**126** BBR_Enter_Probe_BW():\n\n**127** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc35\ud835\udc4a_ ;\n\n**128** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = 1 ;\n\n**129** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = 2 ;\n\n**130** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65_ = _\ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52\ud835\udc3f\ud835\udc52\ud835\udc5b_ \u2212 1 \u2212 _\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc5c\ud835\udc5a_ _ _\ud835\udc56\ud835\udc5b\ud835\udc61_ _ _\ud835\udc56\ud835\udc5b_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc54\ud835\udc52_ (0 _.._ 6) ;\n\n**131** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc34\ud835\udc51\ud835\udc63\ud835\udc4e\ud835\udc5b\ud835\udc50\ud835\udc52_ _ _\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc43\u210e\ud835\udc4e\ud835\udc60\ud835\udc52_ () ;\n\n**132** BBR_Set_Pacing_Rate():\n\n**133** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc52\ud835\udc61_ _ _\ud835\udc43\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc45\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc4a\ud835\udc56\ud835\udc61\u210e_ _ _\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b_ ( _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ ) ;\n\n**134** BBR_Set_Pacing_Rate_With_Gain(pacing_gain):\n\n**135** _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ \u2217 _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ ;"}, {"role": "assistant", "content": "**Mechanism:** This section outlines the initialization and entry into the 'ProbeBW' state of the BBR congestion control algorithm. The core mechanism is to establish an initial set of parameters for pacing and congestion window (cwnd) and then to actively set a pacing rate based on these parameters and the estimated Bottleneck Bandwidth (BtlBw). The 'gain' values act as multipliers for the baseline BtlBw and cwnd capacity, allowing BBR to systematically explore network capacity. The random cycle index introduces variability to avoid synchronization with other network flows or repetitive patterns.\n\n**Explanation:** Think of this as a network connection's 'discovery phase'. When a BBR connection starts, it explicitly sets its state to `ProbeBW`, signaling its mission to find the maximum sustainable bandwidth. It assigns 'gain' values: `pacing_gain = 1` means it aims to send data at roughly the *estimated* bottleneck bandwidth, while `cwnd_gain = 2` means it allows twice that amount of data to be 'in flight' (unacknowledged) at any given moment, providing a buffer to keep the network pipeline full even with latency. The `cycle_index` acts like an offset into a pre-defined sequence of probing behaviors. The `random_int_in_range` component is crucial; it ensures that multiple BBR flows don't start their probing cycles at exactly the same time, preventing potential synchronized congestion and helping them discover capacity more independently. Finally, `rate = pacing_gain * BBR.BtlBw` is the direct application: if BBR believes the network's max speed (`BtlBw`) is X, and its pacing gain is 1, it will attempt to send data at X. This `rate` dynamically adjusts the outgoing data stream, preventing sudden bursts and smoothing traffic, functioning as a continuous feedback loop."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe now introduce and motivate our method EGGROLL, which is presented in Algorithm 1. In Section 4.1\nwe derive a low-rank ES update that approximates a full-rank ES gradient. One practical issue with using\na low-rank matrix approximation is that its distribution and score function have no analytic solution except\nfor degenerate cases, so in Section 4.2 we derive an alternative score function from the limiting high-rank\nGaussian which we propose as an approximation.\n\n5\n\n**4.1** **Low Rank Evolution Strategies** **Algorithm 1** EGGROLL( _r, \u03b1, \u03c3, T_ max _, N_ workers)\n\nRecall the Gaussian matrix ES update from Eq. (4).\nOur goal is to introduce a tractable approximation to\ngenerating full-rank matrices, using low-rank matrices\n_AB_ _[\u22a4]_ as our search matrices instead. We denote the\ndistribution of _A_ as _p_ ( _A_ ) and _B_ as _p_ ( _B_ ) assume that the\nelements of _A_ and _B_ are drawn independently:\n**Assumption 1.** _Assume all elements ai,j \u2208_ _A and_\n_bi,j \u2208_ _B are continuous identically and independently_\n_distributed random variables according to some zero-_\n_mean, symmetric, absolutely continuous (i.e., it has a_\n_density) distribution p_ 0( _\u00b7_ ) _with finite 4th order moments_\n_and variance_ 0 _< \u03c3_ 0 [2] _[.]_\n\n**initialise** _\u00b5_ and workers with known random seeds _\u03c2_\n**for** _T_ max timesteps **do**\n\n**for** Each worker _i \u2208{_ 1 _, . . . N_ workers _}_ in parallel **do**\n\n_Ai \u223c_ _p_ ( _Ai_ ) _, Bi \u223c_ _p_ ( _Bi_ )\n_Ei \u2190_ ~~_\u221a_~~ 1 _r_ _AiBi_ _[\u22a4]_\n_fi \u2190_ _f_ ( _\u00b5_ + _\u03c3Ei_ )\n**end for**\n\nWorkers share scalar fitness _fi_ with other workers\n**for** Each worker _i \u2208{_ 1 _, . . . N_ workers _}_ in parallel **do**\n\nReconstruct _Ej_ for _j \u2208{_ 1 _, . . . N_ workers _}_ from _\u03c2_\n\n_\u00b5 \u2190_ _\u00b5_ + _\u03b1_ _N_ Workers1 \ufffd _Nj_ =1Workers _Ej_ _fj_\n**end for**\n\n**end for**\n\nThe low-rank approximation _AB_ _[\u22a4]_ must be carefully integrated into the Gaussian matrix ES objective in\nEq. (3) to ensure that the variance of the updates remains bounded with increasing number of columns _r_ as the\nelements of _AB_ _[\u22a4]_ are a sum of _r_ random variables. To counter this, we scale the outer product by ~~_\u221a_~~ 1 _r_ which\nkeeps the variance of _E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ as _O_ (1).\n\nObserve that _E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ maps to the manifold M _[r]_ _\u2282_ R _[m][\u00d7][n]_ of rank _r_ matrices, which is a subset of R _[m][\u00d7][n]_ .\nThis means that the density _p_ ( _E_ ) is defined with respect to a unit volume over the manifold and cannot be\ndefined with respect to the standard unit volume in Euclidean space as the volume of the manifold is zero\nusing this measure. For the corresponding score function, gradients with respect to log _p_ ( _E_ ) are defined\nover the tangent space to M _[r]_ instead of in the usual Euclidean space. An intuitive reason for this is that\nthere is dependence between elements of _E_ and so it is not possible to take partial derivatives with respect\nto each element whilst keeping all other elements free. In principle it is possible to define all distributions\nand gradients with respect to the manifold M _[r]_, however this makes an analysis of low-rank updates difficult.\nInstead, we study the variable _Z_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ + _\u03f5_ where _\u03f5_ is an _m \u00d7 n_ matrix with independent decaying\n1\nGaussian elements _\u03f5i,j \u223cN_ (0 _,_ _[\u03c3]_ _\u03f5_ [2] _/r_ ). The variable _Z_ = ~~_\u221a_~~ _r_ _AB_ _[\u22a4]_ + _\u03f5_ has a well-defined density _p_ ( _Z_ ) for all\n_\u03c3\u03f5 >_ 0. This conceptual tool greatly simplifies analysis and as _\u03c3\u03f5_ can be made arbitrarily small and hence _p_ ( _E_ )\ncan be arbitrarily close to _p_ ( _Z_ ), the difference between the update used in practice and the update analysed is\nnegligible. Substituting for _p_ ( _E_ ) = _p_ ( _Z_ ) in Eq. (3), we derive the low-rank ES objective:\n\n_J_ LR( _\u00b5_ ) = E _Z\u223cp_ ( _Z_ ) [ _f_ ( _M_ = _\u00b5_ + _\u03c3Z_ )] _._\n\nWe now verify that _p_ ( _z_ ) is well-defined and show how _J_ LR( _\u00b5_ ) can be optimised using the score function of\n_p_ ( _Z_ ):\n**Theorem 1.** _**Low-rank ES Gradient.**_ _Let Assumption 1 hold. Then for finite r:_\n\n_gLR_ := _\u2207\u00b5JLR_ ( _\u00b5_ ) = _\u2212_ [1]\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)][ [] _[\u2207][Z]_ [ log] _[ p]_ [ (] _[Z]_ [)] _[ f]_ [(] _[M]_ [ =] _[ \u00b5]_ [ +] _[ \u03c3Z]_ [)]] _[ .]_\n\n_where Z is generated by sampling A \u223c_ _p_ ( _A_ ) _, B \u223c_ _p_ ( _B_ ) _, \u03f5 \u223c_ _p_ ( _\u03f5_ ) _and making the transformation Z_ =\n1 _AB_ _[\u22a4]_ + _\u03f5._\n~~_\u221a_~~ _r_\n\n**4.2** **Score Function Approximation**\n\nAs the mapping ( _A, B, \u03f5_ ) : _\u2192_ _Z_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ + _\u03f5_ is non-invertible, there does not exist a simple closed form\nsolution for the density _p_ ( _Z_ ) and score function except in degenerate cases such as _m_ = _n_ = 1. Instead, we\nuse an approximation for the score function _S_ [\u02c6] ( _Z_ ) _\u2248\u2207Z_ log _p_ ( _Z_ ):\n\n\u02c6 \u02c6\n_g_ LR = _\u2212_ [1] _S_ ( _Z_ ) _f_ ( _M_ = _\u00b5_ + _\u03c3Z_ ) _._ (5)\n\n_\u03c3_ [E] _[Z][\u223c][p]_ [(] _[Z]_ [)] \ufffd \ufffd\n\nTo optimise the ES objective using the EGGROLL update, we adapt the parallelised evolutionary strategies\nalgorithm from Salimans et al. (2017). In our experiments and Algorithm 1, we use a Gaussian approximate\n\n6\n\nscore function, which is obtained from taking the limit _r \u2192\u221e_ . As _\u03f5_ is a random matrix formed of independent\nGaussian elements, it can be decomposed into an equivalent sum of _r_ independent Gaussian matrices:\n\n1\n\n_\u03f5_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd _\u03f5i,_\n\n_i_ =1\n\nwhere each random matrix _\u03f5i \u223c_ _p_ ( _\u03f5i_ ) has the same distribution as _\u03f5_ . Likewise, the matrix _AB_ _[\u22a4]_ can be\ndecomposed as a sum of independent, zero-mean vector outer products:\n\n_AB_ _[\u22a4]_ =\n\n_r_\n\ufffd _aib_ _[\u22a4]_ _i_ _[,]_\n\n_i_ =1\n\nwhere _ai_ and _bi_ are the _i_ th column vectors of _A_ and _B_ . This allows us to write _Z_ as a standardised sum of _r_\nindependent random matrices:\n\n1\n_Z_ =\n~~_\u221ar_~~\n\n_r_\n\ufffd \ufffd _aib_ _[\u22a4]_ _i_ [+] _[ \u03f5][i]_ \ufffd _._ (6)\n\n_i_ =1\n\nUnder Assumption 1, the central limit theorem proves that _p_ ( _Z_ ) converges in distribution to a Gaussian\n_N_ (0 _, Im\u03c3_ 0 [4] _[, I][n][\u03c3]_ 0 [4][)][. Using this limiting distribution in place of the true distribution] _[ p]_ [(] _[Z]_ [)][, we obtain the]\nGaussian approximate score function:\n\n_S_ \u02c6( _Z_ ) = _\u2212_ [1] _Z._ (7)\n\n_\u03c3_ 0 [4]\n\nWe remark that EGGROLL is not wedded to any particular score function approximator and we derive and\nexplore a set of mean-field approximators in Appendix B as alternatives, however our experiments show that\nthe Gaussian approximator has the best overall performance on the set of tasks we evaluated on. We make\na Monte Carlo estimate of expectation in Eq. (5) with _N_ workers samples to optimise the parameters _\u00b5_ using\n(approximate) stochastic gradient ascent. This yields the Gaussian EGGROLL update:\n\n![](papers/images/Evolution-Strategies-at-the-Hyperscale.pdf-6-0.png)\n\nHere we have absorbed the constants _\u03c3_ [1] [and] _\u03c3_ 10 [4] [into the tunable learning rate] _[ \u03b1][t]_ [. As each random matrix]\n\n_Ei,t_ in Eq. (8) has rank _r_ almost surely and the matrix is updated using a sum of _N_ worker such matrices,\nthe overall EGGROLL matrix parameter update has rank min( _Nr, m, n_ ) almost surely, meaning that the\noverall parameter update is not restricted to be low-rank. For all experiments in Section 6, _Nr >_ min( _, m, n_ ),\nmeaning EGGROLL parameter updates are full-rank.\n\n**4.3** **Hardware-Efficient EGGROLL Implementation**\n\nA key reason to use EGGROLL over standard ES is that large populations can be simulated in parallel on a\nGPU thanks to the low-rank perturbations. For the sake of exposition, we write equations from the perspective\nof a single worker, _i_, and explain in text how this corresponds to batched GPU operations.\n\nConsider the task of computing a batched forward pass over inputs _xi \u2208_ R _[d][in]_ for a linear layer with mean\nparameter _\u00b5 \u2208_ R _[d][out][\u00d7][d][in]_ . The standard forward pass is just a regular matrix multiplication, _x\u00b5_ _[T]_, since _\u00b5_ is\nconstant across all threads. However, naively applying ES by trying to compute _xi_ ( _\u00b5_ + _\u03c3Ei_ ) _[T]_ becomes a\nbatched matrix multiplication, which is inefficient on GPUs since every element of _\u00b5_ + _\u03c3Ei_ is only used in a\nsingle multiplication, yielding poor arithmetic intensity.\n\n7\n\nHowever, with EGGROLL we know that _xi_ ( _\u00b5_ + _\u03c3Ei_ ) = _xi\u00b5_ + ~~_\u221a_~~ _\u03c3r_ ( _xiBi_ ) _A_ _[T]_ _i_ [. In this context, the bulk of]\ncompute is spent on the efficient calculation of _xi\u00b5_ using regular matrix multiplication. Meanwhile, when\n_r_ = 1, _xiBi_ simply becomes an inexpensive batched vector-vector dot product to get a batch of scalars, which\nis then processed by a batched scalar-vector multiplication when multiplying by _A_ _[T]_ _i_ [. This decomposition]\nis key to efficient batched LoRA inference, such as those used by vLLM (Kwon et al., 2023), which why\nEGGROLL achieves the same speeds as batched LoRA inference systems.\n\nWe additionally optimize the update process by not explicitly materializing the individual _Ei_ in the computation\nof [\ufffd] _[N]_ _i_ =1 _[E][i][f][i]_ [, the key term in the Gaussian approximate score function. In particular, when the rank is 1, we]\nreconstruct _A \u2208_ R _[N]_ _[\u00d7][d][out]_ and _B \u2208_ R _[N]_ _[\u00d7][d][in]_ and calculate the expression as ( _A \u2299_ _f_ ) _B_ _[T]_, which is a simple\nmatrix multiplication."}, {"role": "assistant", "content": "**Mechanism:** The core problem is that updating a high-dimensional model (like a neural network's weights) with full-rank random noise in Evolution Strategies (ES) is computationally very expensive. This method uses *low-rank* matrices, formed by multiplying two smaller matrices (like `A` and `B` to get `AB^T`), as the noise. This drastically reduces the number of values needed. However, these low-rank matrices don't live in a simple 'flat' mathematical space, making their probability and update rules complex. To fix this, they introduce a conceptual trick: adding a tiny amount of full-rank 'fuzz' (Gaussian noise `\u03f5`) to the low-rank matrix. This makes the matrix effectively 'full-rank' for mathematical analysis, simplifying its probability distribution and allowing standard calculus to apply. Moreover, by relying on the Central Limit Theorem, when you average many of these slightly 'fuzzed' low-rank matrices, their combined effect looks exactly like a simple bell-shaped curve (a Gaussian distribution). This allows for a very simple and efficient formula for calculating the update direction. Crucially for computers, the actual calculations are broken down. Instead of a slow general matrix multiplication `x(\u00b5 + \u03c3E)^T`, it's split into a super-fast standard matrix multiplication `x\u00b5^T` and then smaller, faster batched vector operations for the low-rank part `(\u03c3/\u221ar)(xB_i)A_i^T`, which is like using specialized, optimized code paths for different parts of a complex task.\n\n**Explanation:** Imagine you're trying to adjust a complex machine (your model parameters `\u00b5`) by pushing it in slightly different ways. Traditional ES is like pushing every single bolt on the machine separately, which is precise but super slow if the machine has millions of bolts. EGGROLL says, 'What if we just push a few *combinations* of bolts instead?' So, instead of a giant push matrix `E`, we create it from two much smaller pieces, `A` and `B`, by multiplying them (`AB^T`). This `AB^T` is a low-rank matrix, meaning it represents a 'push' that's simpler and more coordinated, using fewer independent motions. The problem arises because `AB^T` lives on a specific, curved surface (the 'manifold') within the space of all possible pushes. Trying to measure how much `AB^T` moves the machine on this curved surface is really hard. To fix this, we pretend to 'smear' this curved surface with a tiny, tiny bit of universal 'fog' (`\u03f5`), turning `AB^T` into `Z = (1/\u221ar)AB^T + \u03f5`. Now, `Z` exists in the normal, flat space, and we can use regular calculus to figure out its 'score' \u2013 how good of a push it was. Even better, when we average many of these `Z` pushes, because each `Z` is made from summing up small, independent random bits (like adding `r` small random vectors), the total push `Z` starts to look like a perfectly smooth, bell-shaped curve (a Gaussian distribution). This 'Central Limit Theorem' effect is super powerful: it means we don't need a complex formula for our 'score function'; we can just use a simple, elegant one: `S\u0302(Z) = - (1/\u03c3_0^4) Z`. It essentially says, 'The best way to push is proportional to the push itself!' This simplifies the update rule to something very easy to calculate: `\u00b5` gets updated by summing up `E_j * f_j` for all workers. For computers (especially GPUs), this `x\u00b5^T + (\u03c3/\u221ar)(xB_i)A_i^T` decomposition is like having a really fast 'express lane' for the main calculation (`x\u00b5^T`) and then several smaller, dedicated 'side roads' for the `(\u03c3/\u221ar)(xB_i)A_i^T` part. Instead of each worker calculating a massive `\u00b5+\u03c3E_i` matrix, they calculate the main `x\u00b5^T` part (common for all), and then for the `E_i` part, they only need `A_i` and `B_i`. This avoids the inefficiency of needing to store and use a unique, full-size `E_i` for every single parallel computation, allowing massive parallelism."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWith the growing complexity of integrated circuits, hardware engineers are required to invest increasing effort in HDL design [1].\nTraditional hardware design flows typically begin with engineers interpreting algorithm specifications and then manually coding them\ninto corresponding HDL designs. As shown in Fig. 1(a), this process\nis highly labor-intensive: developers should write HDL designs by\nhand, perform simulation, and debug errors to ensure functional\ncorrectness, resulting in a time-consuming and costly process [2].\nRecently, large language models (LLMs) have demonstrated significant potential in enhancing the efficiency of HDL design [7\u201321].\nBy learning expert design patterns, LLMs can generate HDL designs directly from specifications with significantly reduced manual\neffort [22\u201330]. Chip-Chat [7] presents the first systematic study\nof conversational LLMs for interactively co-designing an 8-bit accumulator microprocessor under real-world constraints. Rome [8]\nintroduces hierarchical prompting and an automated generation\npipeline that enables LLMs to reliably produce multi-level HDL designs. GPT4AIGChip [9] leverages LLMs for AI accelerator design by\ndecoupling circuit modules with in-context learning. RTLFixer [10]\nintroduces a RAG-based debugging flow that repairs syntax errors in\nHDL designs. AssertLLM [31] generates functional assertions from\nspecifications, while _CorrectBench_ [32, 33] employs LLMs to build a\nhybrid evaluation platform with a self-correction mechanism. The\nfrontier of LLM-assisted hardware design is further advanced in\n\nHigh-Level Synthesis (HLS) [34\u201340], C2HLSC [34\u201336], HLS-Repair\n\n[37], and HLSPilot [38] use LLMs to iteratively refactor C/C++ programs into HLS-compatible versions with tool-guided feedback.\nDespite the advances of HDL design with LLMs, the inherent\nhallucinations of LLMs frequently introduce syntactic and, more critically, functional errors into the generated HDL designs [7]. While\nsyntax issues can often be detected by compilers and fixed by iterative repair loops [10], functional debugging remains fundamentally\nchallenging. Current LLM-based flows lack a bit-accurate reference\nat the same abstraction level as the generated HDL, forcing engineers to manually interpret algorithm specifications, analyze simulation waveforms, and infer intended behaviors to locate functional\nbugs. Consequently, the effort required to validate and correct LLMgenerated designs can partially offset the benefits of automated\ncode generation, thereby limiting the practical adoption of LLMs for\nproducing functionally correct HDL in industry [25, 26].\nTo address the challenge above, we introduce a novel agentic\ndesign framework, _CorrectHDL_, for LLM-assisted HDL design and\ndebugging using the results of high-level synthesis (HLS) as a bitaccurate reference to overcome functional errors. To the best of our\n\nknowledge, this is the first work leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven synthesis\nflows to support LLM-assisted HDL design and debugging. The key\ncontributions of this paper are summarized as follows:\n\n  - An agentic HDL design framework, _CorrectHDL_, is proposed\nand released as open source. By leveraging HLS-generated\nHDL as a functional reference, _CorrectHDL_ implements an\nend-to-end design flow that covers HDL generation, runtime\nprofiling, differential verification, iterative repair, and PPA\nevaluation, enabling accurate and efficient hardware design.\n\n  - To mitigate attention dilution in LLMs, complex C/C++ algorithms are decomposed into LLM-friendly submodules through\na structured C/C++ decomposition strategy, which also provides a basis for subsequent differential debugging.\n\n  - By leveraging the adaptive learning capability of LLMs, a\nRetrieval-Augmented Generation mechanism is introduced\nto correct syntax errors in the LLM-generated HDL designs,\nincreasing the compilation pass rate by an average of 15.49%.\n\n  - To address functional errors caused by LLM hallucinations, a\ndifferential verification and repair loop is established using\nHLS-generated HDL as the functional reference, improving\nthe functional pass rate of LLM-generated HDL by 28.05%.\n\n  - To efficiently debug the LLM-generated top-level HDL design, submodule boundary instrumentation is combined with\na backward slicing technique to locate errors from the system level down to individual modules, thereby bringing the\noverall functional pass rate improvement to 38.54%. Experimental results also demonstrate that the proposed _CorrectHDL_\nachieves an average area reduction of 24.83% and power reduction of 26.98% compared with conventional HLS designs\nand approaches the quality of human-engineered circuits.\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-1.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-2.png)\n\n**Figure 1: Traditional manual HDL design flow.**\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-5.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-6.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-8.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-1-9.png)\n\n**Figure 2: (a) LLM-aided HDL design flow; (b) High-Level Syn-**\n**thesis (HLS) flow; (c) Our proposed concept.**\n\nThe paper is organized as follows. Section 2 provides the background and motivation. Section 3 details the framework. Section 4\nshows the experimental results, and Section 5 concludes the paper."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is using a functionally correct High-Level Synthesis (HLS) output as a bit-accurate 'oracle' or reference model to differentially verify and iteratively debug LLM-generated Hardware Description Language (HDL). This establishes a concrete ground truth for functional correctness that was previously absent.\n\n**Explanation:** Think of it like this: you have a high-level instruction set (C/C++ code) for a complex task. An LLM (like a smart junior engineer) quickly writes the low-level instructions (HDL). But the LLM often 'hallucinates' or makes functional errors. Historically, finding these errors was hard because you had no perfect low-level reference. This framework introduces a 'master engineer' (HLS tool) who, given the *exact same* high-level instructions, generates a *guaranteed functionally correct* set of low-level instructions, even if they aren't the most compact. The framework then breaks the high-level instructions into smaller functions (submodules). For each submodule, it compares the outputs of the LLM's HDL and the master engineer's HLS-generated HDL for the same inputs, just like unit testing. If they differ, it uses 'backward slicing' (similar to tracing data dependencies in a program to find the source of a bug) to pinpoint the exact section of the LLM's faulty HDL. The LLM is then prompted to correct *only that specific section* until its output matches the HLS reference. This iterative, targeted debugging, along with a RAG-based 'syntax fixer' (like an intelligent linter with code examples), ensures the LLM's final HDL is both syntactically and functionally correct."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e\ud835\udc5c\ud835\udc59\ud835\udc51_\ud835\udc4f\ud835\udc64_\ud835\udc53\ud835\udc5c\ud835\udc5f_ __\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc5d\ud835\udc56\ud835\udc5b\ud835\udc54_\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc46\ud835\udc39_ _> \ud835\udc47\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_\ud835\udc37\ud835\udc52\ud835\udc59_\ud835\udc45\ud835\udc61_ **and**\n_\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc4f\ud835\udc61\ud835\udc59\ud835\udc5b\ud835\udc52\ud835\udc50\ud835\udc58_ _<_ 2 **and** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_\ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f_ __\ud835\udc5c\ud835\udc53_ __\ud835\udc46\ud835\udc39\ud835\udc60_ _>_ 1 **and**\n_\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_\ud835\udc4e\ud835\udc59\ud835\udc59_\ud835\udc46\ud835\udc39\ud835\udc60_ \u2260 _\u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc60\ud835\udc61_\ud835\udc4f\ud835\udc64_\ud835\udc4e\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc54_\ud835\udc4e\ud835\udc59\ud835\udc59_\ud835\udc46\ud835\udc39\ud835\udc60_ **then**\n\n**16** _\ud835\udc50\ud835\udc5a\ud835\udc5d\ud835\udc4f\ud835\udc4f\ud835\udc5f_ \u2192 _\ud835\udc60\ud835\udc61\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc46\ud835\udc39_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ + + ;"}, {"role": "assistant", "content": "**Mechanism:** This logic implements a conditional increment of a counter, which serves as a metric or trigger for a resource management action. It detects specific network congestion patterns and tallies instances where a singular, lowest-bandwidth flow contributes disproportionately to a bottleneck.\n\n**Explanation:** The system identifies a condition where intervening with the lowest-bandwidth service flow (SF) might be beneficial. This happens if the potential bandwidth freed by stopping the lowest SF exceeds the current total delivery rate, suggesting significant stress. Crucially, it only considers this if there's *at most one* SF currently identified as the 'last' in the bottleneck, focusing the intervention on a precise choke point. Furthermore, it only acts if there are multiple SFs in total and if there's an actual disparity between the lowest and highest bandwidth SFs (meaning, not all SFs are performing identically). If all these conditions are met, a counter (like an integer variable) associated with stopping the lowest bandwidth SF for a particular comparison context (`cmpbbr`) is incremented. This count likely informs a subsequent decision-making process to actually pause or throttle that specific low-bandwidth SF."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Dataset Distillation.** As dataset and model sizes continue to grow, so has the interest in more\nefficient forms of learning. To this end, researchers have worked towards methods of _learning_\noptimal training data such that one could train an effective model from scratch using as few\nsamples as possible. One such solution to this problem was the initial proposal of _Dataset_\n_Distillation_ [47] in which the model\u2019s final performance was expressed as a function of the _synthetic_\n_training data_ that was optimized end-to-end by back-propagating through many inner training\niterations. Follow-up works introduced proxy losses and learned synthetic images that matched\ngradients [55], feature distributions [54], training trajectories [6] and more [27, 51, 56]. Some\nworks extend dataset distillation to large models [50, 51], but these methods do not excel in the\nultra-small data regime, i.e., one image per class. For such settings, Trajectory Matching [6] and\n\n2\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-2-1.png)\n\nReal Images\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-2-0.png)\n\nFigure 2: **Linear Gradient Matching for Pre-Trained Vision Models:** Given a pre-trained self-supervised\nvision model ( _\u03d5_ ), we perform a distillation step by first passing a batch of real and synthetic data through _\u03d5_\nand a randomly-initialized linear classifier ( _W_ ) to get the real and synthetic classification losses ( _\u2113_ real and _\u2113_ syn).\nOur meta loss ( _L_ meta) is then defined as the cosine distance between the _gradients_ of these classification losses\n( _\u2113_ real and _\u2113_ syn) with respect to the random linear probe ( _W_ ). This meta loss is then back-propagated through the initial synthetic gradient calculation and used to update our synthetic images. This technique allows us to distill large\ndatasets to just a single image per class while still achieving high performance when training new linear probes.\n\nits modifications [7, 11, 16, 32, 40] still reign supreme. However, this method fails to scale up to\nlarge models due to memory constraints and instability in the bi-level optimization.\n\nThis work introduces a new problem in the space of dataset distillation: learning synthetic images\nfor the purpose of training _linear probes_ on top of _pre-trained self-supervised feature extractors_\ninstead of training randomly initialized models from scratch. Our proposed solution, _Linear Gradient_\n_Matching_, takes inspiration from prior work on gradient matching [55] and trajectory matching [6]\nbut only considers gradients of the linear classifier as opposed to the entire model.\n\n**Self-Supervised Learning.** Given that the overwhelming majority of available visual data lacks\nany useful labels, _Self-Supervised Learning_ has become the defacto method of pre-training neural\nnetworks to be later used for down-stream tasks. In recent years, several different paradigms of\nself-supervised training have emerged, including contrastive learners [5, 8\u201310, 18, 31], masked\nauto-encoders [17, 37], vision-language models [34, 41, 44, 52], and hybrid approaches [13, 14].\nDespite the various training methods, researchers have noticed that these different models tend\nto learn similar representations, even across different modalities, and dubbed this observation the\n\u201cPlatonic Representation Hypothesis\u201d [20].\n\nIn this work, we focus on distilling datasets using four pre-trained self-supervised models in\nparticular: CLIP [34], DINO-v2 [31], EVA-02 [13], and MoCo-v3 [10]. Since our feature extractors\nwere pre-trained in a purely self-supervised manner, our linear probes still only see a single _labeled_\nsample per class while achieving competitive performance."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism here is an optimized form of 'gradient matching'. Imagine our pre-trained model as a fixed, powerful feature extractor. When we want to classify new data, we attach a simple 'linear probe' (a small, adaptable component) to its output. This linear probe is like a simple lookup table or a small decision-making function that uses the rich information provided by the main model. We're trying to find a few 'synthetic images' that, when fed through this system, cause the linear probe to adjust itself in the same way it would if it were seeing a batch of many real images. We achieve this by calculating the 'gradients' \u2013 which are essentially directions indicating how to best tweak the linear probe's internal settings to reduce errors \u2013 for both real and synthetic data. Our 'meta loss' then measures the 'cosine distance' between these two sets of gradient vectors. A small cosine distance means the gradients point in similar directions. We then 'back-propagate' this meta loss not to update the linear probe, but to adjust the synthetic images themselves, making them more effective at mimicking the 'teaching signal' of real data for the linear probe. This avoids the memory and stability issues of previous methods because we only track gradients for the small linear probe, not the massive pre-trained model.\n\n**Explanation:** Training large models usually involves a 'feature extractor' that turns raw data (like an image) into a numerical representation, and then a 'classifier' that uses that representation to make a decision. This paper tackles the problem of creating tiny, artificial datasets that can train this final 'classifier' part efficiently, especially when the feature extractor is already very good (pre-trained). Instead of trying to make synthetic images that would teach the *entire* model from scratch, which is computationally expensive and complex, they focus on matching the 'learning directions' (gradients) *only for the small, final classifier*. Think of it like this: the pre-trained model is a complex lookup function that transforms an image into a list of numbers. The linear classifier is a simple calculation on those numbers to decide the image's category. We want our synthetic images to push the weights of this simple calculation in the same way real images would. By comparing how the synthetic images would 'correct' the classifier to how real images would, and then adjusting the synthetic images themselves based on that comparison, we create highly effective teaching examples without the massive computational overhead of trying to imitate the entire complex learning process."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nEvolution Strategies (ES) (Rechenberg, 1978; Beyer, 1995; Beyer & Schwefel, 2002) are an attractive\nalternative to first-order methods based on gradient backpropagation, for several reasons. First, ES does not\nrequire differentiability, so it can optimise a broader class of models, like models with discrete parametrisation\nspaces (cellular automata), and can optimize objectives where gradients are unavailable or noisy, like outcomeonly rewards in LLM fine-tuning (Qiu et al., 2025). Second, ES is more robust to noisy and ill-conditioned\noptimisation landscapes (Wierstra et al., 2011; Xue et al., 2021). Unlike gradients, population-based exploration\nsmooths irregularities (Salimans et al., 2017), tolerates discontinuities, and mitigates issues like ill-conditioned\ncurvature or vanishing and exploding gradients in long-range or recurrent settings (Hansen, 2023). Third,\nES is highly amenable to scaling through parallelisation, since fitness evaluations are independent across\npopulation members and require only the communication of scalar fitnesses, which maps cleanly onto modern\ninference infrastructure and yields near-linear speedups on large clusters (Salimans et al., 2017). By contrast,\nbackpropagation requires communicating and aggregating gradients across devices, yielding updates with high\nmemory and computation costs. Additionally, backpropagation requires special care when training models\nwith low-precision datatypes, whereas ES can directly optimize any model with the same datatypes used\nat inference time. Together, these properties position ES as a potentially powerful foundation for training\nlarge, discrete, or hybrid architectures, and end-to-end systems with non-differentiable components, including\nlarge language models (LLMs) (Brown et al., 2020; Chowdhery et al., 2023; Du et al., 2022; Fedus et al.,\n2022).\n\nDespite this potential, there are practical obstacles to employing ES at scale. In deep learning architectures\n(Goodfellow et al., 2016), the majority of trainable parameters form linear mappings represented by matrices\n(Rosenblatt, 1962; Hochreiter & Schmidhuber, 1996; Bengio et al., 2000; Krizhevsky et al., 2012; Goodfellow\net al., 2014; Kingma & Welling, 2014; Vaswani et al., 2017); na\u00efvely adapting ES therefore requires generating\nfull-rank matrix perturbations that replicate the entire parameter set for every population member. This inflates\nmemory costs and forces frequent movement of large weight tensors. Evaluating these perturbations then\nrequires a separate sequence of matrix multiplications per member, so the total compute and wall-clock\ntime scale roughly with the population size and sequence length. In billion-parameter regimes, these two\ncosts dominate, making it difficult to scale ES beyond small models or small populations (Qiu et al., 2025;\nKorotyshova et al., 2025).\n\nTo mitigate both memory and computational bottlenecks, we introduce Evolution Guided General Optimization\nvia Low-rank Learning (EGGROLL), an ES algorithm that allows for the efficient training of neural network\narchitectures with billions of parameters. Analogous to LoRA\u2019s low-rank adapters in gradient-based training\n(Hu et al., 2022), EGGROLL generates _low-rank_ parameter-space perturbations for ES: instead of sampling\na full-rank matrix _E \u2208_ R _[m][\u00d7][n]_, we sample _A \u2208_ R _[m][\u00d7][r]_ and _B \u2208_ R _[n][\u00d7][r]_ with _r \u226a_ min( _m, n_ ) and form\n_E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ . This reduces auxiliary perturbation matrix storage from _mn_ to ( _m_ + _n_ ) _r_ per layer, and\nproportionally reduces tensor movement. Moreover, we use a counter-based deterministic random number\ngenerator (RNG) (Salmon et al., 2011; Bradbury et al., 2018) to reconstruct noise on demand, so matrix\n\n2\n\nperturbations need not persist in memory. When evaluating the fitness of members of multiple perturbations\nin parallel, EGGROLL batches a population of low-rank adapters and shares the base activations, enabling\na single forward pass that applies all _AB_ _[\u22a4]_ updates via specialized batched matrix multiplications. The\ncompute required beyond standard batched inference scales with _O_ ( _r_ ( _n_ + _m_ ) _N_ ), where _N_ is the population\nsize, instead of _O_ ( _nmN_ ) for standard ES, yielding substantial memory and inference savings and making\nEGGROLL efficient for extremely large models. We emphasise that our method does not restrict the updates\nto be low-rank: the overall EGGROLL update is an average of rank _r_ matrices across the population, making\nthe matrix parameter update rank min( _Nr, m, n_ ) .\n\nEGGROLL is described in detail in Section 4. We provide a rigorous theoretical analysis of the low-rank\napproximation accuracy in Section 5, proving that EGGROLL updates converge to the full rank Gaussian\nES updates at an _O_ ( [1] _/r_ ) rate. This fast convergence rate suggests that low-rank updates are sufficient to\ntrain large-scale architectures, even with _r \u226a_ min( _m, n_ ). In our extensive empirical evaluation, we test this\nhypothesis across a wide range of domains in Section 6. In tabula rasa and multi-agent RL (MARL) settings,\nwe show that EGGROLL does not compromise performance compared to na\u00efve ES despite being faster.\nTo demonstrate the scalability of our method for LLM fine-tuning, we conduct experiments on pretrained\nRWKV7 (Peng et al., 2025) models, modern recurrent language models that enable large batch inference\ndue to their constant state size. Finally, we develop a nonlinear RNN language model that operates purely in\ninteger datatypes, and demonstrate that EGGROLL can stably pretrain this language model, a feat which is\nonly feasible due to the large population sizes enabled by EGGROLL."}, {"role": "assistant", "content": "**Mechanism:** EGGROLL addresses the prohibitive memory and compute costs of applying Evolution Strategies (ES) to large deep learning models by replacing full-rank parameter perturbations with low-rank approximations. Instead of generating and storing an `m x n` matrix `E` for each model variant (population member), it uses two much smaller matrices, `A` (`m x r`) and `B` (`n x r`), where `r` is a tiny fraction of `m` or `n`. These are combined as `AB\u1d40` to form the effective perturbation. This drastically cuts down the storage from `mn` to `(m+n)r`. Further memory savings come from regenerating these `A` and `B` matrices on demand using a deterministic random number generator (like a seeded pseudo-random number generator), meaning they don't need to be kept in active memory. Computationally, instead of performing `N` full forward passes, EGGROLL batches the low-rank adapters and shares base activations, allowing a single base forward pass with specialized batched matrix multiplications for the `N` perturbations. This converts the `O(nmN)` scaling of standard ES to `O(r(n+m)N)`, a massive reduction when `r` is small.\n\n**Explanation:** Traditional Evolution Strategies (ES) works by making many slightly different copies of a model, evaluating each copy, and then using the feedback to create a new set of copies. For deep learning models with billions of parameters (which are often represented as huge matrices), making a 'slightly different copy' means adding a unique 'jiggle' matrix to the original parameters. If this jiggle matrix is full-sized (e.g., `m` rows by `n` columns), it requires `m*n` numbers to store per model variant, and each variant needs a full `m x n` matrix multiplication pass. This quickly exhausts memory and compute. EGGROLL's trick is to realize that a 'good enough' jiggle doesn't need to be `m x n` complex. Instead, it generates a much simpler change by multiplying two small matrices, `A` and `B`. This `A * B-transpose` operation still results in an `m x n` matrix, but it only required `(m+n)*r` numbers to define, where `r` is very small. It's like only needing to specify a few core 'patterns' for the change instead of every single element. To save even more memory, these small `A` and `B` matrices aren't stored; they're regenerated using a fixed recipe (like a unique ID or 'seed') for each model variant, similar to how you can regenerate a specific 'random' sequence in a program if you know its seed. For computation, instead of running `N` separate, full calculations, EGGROLL shares the main work for the base model and then applies all `N` small `A * B-transpose` adjustments simultaneously in a highly optimized, batched operation. This is akin to performing one big calculation, and then quickly applying `N` small, parallel tweaks, making it vastly more efficient for large model populations."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nReinforcement learning (RL) optimizes an agent\u2019s performance in a stochastic, sequential decision-making task.\nPolicy-gradient (PG) methods, which directly optimize parameterized policies from sampled trajectories rather than\nrelying on value-function bootstrapping, form one of the core\nparadigms in RL (Sutton, Barto et al. 1998; Schulman et al.\n2015). Its direct formulation hence enables PG\u2019s effective\nimplementations in high-dimensional and continuous-control\nsettings, including robotic manipulation (Peters and Schaal\n2006), locomotion (Todorov, Erez, and Tassa 2012), and autonomous driving (Schulman et al. 2017), where value-based\napproaches are inefficient.\nHowever, PG methods generally suffer from _high variance_\nin gradient estimations. Small stochastic fluctuations in earlyepisode rewards of the trajectories can propagate through the\nMonte Carlo estimator (e.g. REINFORCE (Williams 1992)),\nleading to erratic updates, slow convergence, and occasional\ncollapse of performance (Ilyas et al. 2018; Lehmann 2024).\nClassic variance-reduction techniques, including baseline/advantage normalization and trust-region constraints, can improve the stability but also bring drawbacks: problem-specific\ntuning (Chung et al. 2021), second-order solvers (Schulman\net al. 2015), or extra computational overhead (Wu et al. 2017).\n\n*Code available at: https://github.com/SHlHAB/reward-profiling\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-0-0.png)\n\nFigure 1: Training performance of REINFORCE. The agent converges with stable behavior with our reward profiling. **\u2014** REINFORCE **\u2014** REINFORCE+Lookback.\n\nA unified framework combining sample efficiency, stability,\nand simplicity that does not rely on problem-specific baselines can be useful. Therefore, a natural question arises:\n\n_Is it possible to reduce PG variance and stabilize learning_\n_across arbitrary policy-gradient methods, without relying on_\n_specialized tuning or heavy second-order machinery?_\n\nIn this paper, we provide an affirmative answer to this question by proposing our reward profiling framework. Our framework is based on a straightforward, natural idea: we only\nupdate the policy if the updated one implies a better performance. Under ideal circumstances, when our justifications\nare exact, our reward profiling will imply a monotonically\nincreasing performance, addressing the issue of unstable performance in vanilla PG methods. We perform a simple experiment to entertain this idea. We apply our reward profiling to a simple REINFORCE algorithm, and implement\ntwo algorithms under the CartPole environment (Brockman\net al. 2016). Figure 1 shows vanilla REINFORCE can suffer\nfrom unstable learning and severe performance fluctuations,\nwhereas the reward profiling provides a much more stable,\nnearly monotonic improvement. This observation shows that\nthe profiling framework can address the fundamental challenge in PG without acquiring any complicated techniques.\nIn this paper, we further investigate this idea and develop\nour reward profiling framework to overcome the common\ninstability issues of PG methods. Our contributions are summarized as follows.\n\n**Design of a universal reward-profiling framework (\u00a74).**\nWe first develop our universal reward-profiling framework in\n\nAlgorithm 1, where we selectively accept, reject, or blend the\npolicy updates based on the high-confidence value estimations of their value functions. The framework requires a small\nnumber of additional rollouts per iteration, without incurring\nsignificant additional computation. First, we introduce our\nLookback technique, which updates the policy only when\nthe estimated cumulative reward of the new policy surpasses\nthat of the current policy. We further develop two variants of\nour profiling technique (Mix-up and Three-Points) to\naddress the potential issue of being stuck at a local optimum.\nThey are designed to accelerate convergence while maintaining stability. This can be applied to any PG methods, and is\nexpected to stabilize the learning process and improve their\nperformance.\n**Theoretical guarantees (\u00a75).** We establish theoretical guarantees on the convergence and global optimality of the presented framework. We showed that, in the justification phase,\nwith additional samples of order _O_ ( _\u03f5_ _[\u2212]_ [2] ln( _T/\u03b4_ )), we can\ncompare the performances of the current and updated policies\nwith high probability, thus ensuring monotonic improvements.\nWe also show that the profiling framework will not slow\ndown convergence theoretically, and enjoys an _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] )\nsub-optimality gap on the last iterate, providing a solid foundation for our proposed framework.\n**Extensive empirical evaluation (\u00a76).** We adapt our framework with three representative algorithms: DDPG (Lillicrap\net al. 2015), TRPO (Schulman et al. 2015), and PPO (Schulman et al. 2017), and design corresponding profiling algorithms. We then evaluate their performance on continuouscontrol benchmarks. Results show consistent gains in final\nperformance, sample efficiency, and training stability, providing validation for the algorithmic framework. We also port\nthe algorithm to a Unity-ML \u201dReacher\u201d DDPG agent with\na separate simulation backend to verify that our framework\nis broadly applicable while yielding faster convergence and\nlower variance."}, {"role": "assistant", "content": "**Mechanism:** Policy gradient algorithms update a 'policy' (a program's action rules) by estimating how much each action contributes to future rewards, using sampled 'trajectories' (sequences of actions). The core mechanism of 'reward profiling' is a conditional update gate: before committing to a new policy, it performs a statistical validation.\n\n**Explanation:** Policy gradient methods suffer from 'high variance' because small, random fluctuations in early rewards within a sampled trajectory can mislead the learning process, causing erratic and unstable policy updates. This is like a program frequently changing its core logic based on noisy, short-term feedback. Reward profiling addresses this by introducing a 'pre-commit' check, similar to a database transaction that can be rolled back. Before a proposed new policy (think of it as a modified set of program rules) is fully adopted, the system performs a small number of additional 'rollouts' (like executing a temporary function in a sandbox) to obtain a more reliable estimate of its performance compared to the current policy. The 'Lookback' technique specifically checks if the new policy's estimated cumulative reward (its total expected score) is *confidently* better. If not, the proposed update is rejected, and the previous policy is maintained (a 'rollback'). This filtering mechanism ensures that only robust, actual improvements are integrated, preventing the amplification of noise and stabilizing the learning process by reducing unwanted policy state changes."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe performance results derived by this extended experimentation campaign indicate that the there is no single\n\ncongestion control and packet scheduling algorithm combination that fits well all underlying network conditions. As a\n\nresult, it would be recommended to select an algorithmic scheme combination according to the level of heterogeneity\n\nexperienced in the network, as illustrated through the aforementioned results. On the other hand, adjusting the protocol\n\nconfiguration for fine-tuning can be a cumbersome procedure since network changes can be of dynamic, and in most\n\ncases stochastic, nature. It is then reasonable to seek for a stable configuration, able to cope with all potential network\n\ncharacteristics. Toward this objective, the initial factor which determines the overall performance outcome, is the\n\nappropriate selection of the congestion control algorithm. In this direction, our analysis indicated that _BBR_, _C-MPBBR_,\n\nand _OLIA_ could be potentially applied as generic-use congestion control schemes. With any one of these three CCA\u2019s,\n\nour performance results indicate that _ECF_ and the _MPTCP default (minRTT)_ packet scheduling algorithms exhibit\n\nthe highest goodput and lowest per-packet delay performance, across almost all scenarios. _RR_ turns out to be useful\n\nonly for experimentation purposes, and should rather be avoided in production environments, since it experiences\n\nthe worst results among the examined schedulers; RR\u2019s performance outcome across the diverse scenarios confirm\n\nthe recommendation included within [6]. _LLHD_ is also considered a stable, in terms of goodput and per-packet delay,\n\npacket scheduling algorithm whose results are very close to these of the first two. _BLEST_ is also a highly-sophisticated\n\nalgorithm which performs quite well in case of homogeneous and mild heterogeneity; however, when the underlying\n\nnetwork\u2019s path heterogeneity becomes severe, BLEST decides to skip the non-beneficial paths, underutilizing the\n\navailable network resources. Doing so, diminishes its performance results compared to the other best-performing\n\nschedulers (except RR which performs the worst). Nevertheless, even with this kind of resource underuse, BLEST does\n\nnot experience any significant performance inefficiency, and can thus be included within the group of top-four. An\n\nimportant observation here is the fact that if the optimization goal is application-level smoothness instead of raw\n\nthroughput maximization, BLEST could be considered superior since it actively avoids the impaired path to prevent\n\nHoL blocking. This attribute also stresses the fact that the \"best\" scheduler is ultimately application-dependent.\n\nOne limitation of the current experimentation test-set is the fact that our traffic resembled bulk-traffic conditions;\n\nthus, schedulers that might lag behind in this specific use case, might reach better results under other types of traffic,\n\nsuch as short web-page loads, or traffic generated by video streaming applications."}, {"role": "assistant", "content": "**Mechanism:** The core challenge is orchestrating data flow (congestion control) and path selection (packet scheduling) over multiple, varying network routes. Congestion control algorithms like BBR actively estimate network capacity (bottleneck bandwidth and round-trip time) rather than just reacting to packet loss, much like an intelligent traffic light system predicting traffic flow before jams occur. Packet schedulers then decide which specific path to use for the next packet. ECF and MPTCP default (minRTT) use a simple greedy heuristic, akin to always picking the shortest queue in a supermarket, based on the observed latency (minRTT). BLEST, however, implements a more sophisticated heuristic: if a path is consistently problematic (high heterogeneity), it will actively deprioritize or 'skip' that path. This is a resource allocation decision, trading off potential aggregate throughput from all available paths for more stable, predictable performance on reliable paths, similar to how a load balancer might remove an unstable server from its pool even if it's technically still online, prioritizing system stability over maximum concurrent utilization.\n\n**Explanation:** Think of sending many trucks (data packets) across a network of roads (paths). 'Congestion control' is like managing the overall flow of trucks into the road system so you don't cause a traffic jam. Algorithms like BBR are smart because they try to figure out the maximum safe speed and the time it takes to travel before traffic builds up, rather than just slowing down when you see brake lights. 'Packet scheduling' is like deciding which specific road each truck takes if there are multiple options. ECF and MPTCP's minRTT are like a GPS always picking the path that currently has the shortest travel time, a simple but effective strategy often found in priority queue implementations. BLEST is interesting because it's like a really cautious truck dispatcher: if one road is always getting into accidents or has huge delays, it will tell its trucks to avoid that road completely, even if it means other roads get a bit busier. This isn't about maximizing the total number of trucks that pass, but ensuring that the trucks that do pass have a smooth and predictable journey. This design choice is critical for applications where consistent delivery (like video streaming) is more important than sheer volume, similar to how a database might prefer eventual consistency for higher availability over strict immediate consistency across all replicas."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe evaluate our method on various datasets, including ImageNet-1k [12] and ImageNet-100 [42] for\nour primary results, Spawrious [26] and Waterbirds [38] for a study on adversarial datasets, Stanford\nDogs [21] and CUB-200-2011 [45] for fine-grained visual classification, and ArtBench [24] to test\nthe method\u2019s out-of-distribution capabilities. The majority of our experiments use four pre-trained\nself-supervised feature extractors as backbones: CLIP [34], DINO-v2 [31], EVA-02 [14], and MoCov3 [10]. In all our experiments, we distill the given dataset for 5000 iterations before training linear\nprobes to convergence on the resulting synthetic images. All experiments are conducted at 224 _\u00d7_ 224\nresolution and use the \u201cViT-B\u201d version of the given model. All distilled datasets by default use 10\nsets of augmentations per batch except for ImageNet-1k, for which only 3 sets of augmentations are\nused due to compute constraints. For further implementation details, please see the Appendix.\n\n**Evaluation and Baselines.** To measure our method\u2019s performance on a given feature extractor,\nwe randomly initialize a linear classifier and optimize it to convergence using the distilled images\nbefore evaluating on the test set. The same procedure is used to evaluate real-image baselines. In\nprior works on self-supervised learning [31], the evaluation consists of a grid search across a number\nof hyper-parameters, including from which layer(s) the features used to train the linear probe should\nbe taken from. For simplicity, we instead use only the features from the backbone\u2019s _last layer_ and\nkeep the training hyper-parameters consistent across the training of all linear probes.\n\nWe compare our method against three real-image baselines. For the **Neighbors** baseline, we choose\nthe real image for each class whose _distill-model_ embedding is closest to that of the corresponding\nsynthetic image produced by our method. Similarly, for **Centroids**, we take the real training image\nwith embedding closest to the _mean_ embedding for each class. Lastly, for **Random**, we simply select\na random image for each class and average the performance over 10 different seeds.\n\n5\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-4-0.png)\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-5-1.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-5-0.png)\n\nFigure 3: Performing more rounds of differentiable\naugmentation on the synthetic data during each distillation step improves both the single-model and crossmodel performance of the distilled images.\n\n|Distil<br>Centr|Col2|Col3|Distil<br>Centr|\n|---|---|---|---|\n|30<br>20<br>10|0|10<br>20|10<br>20|\n\nFigure 4: We distill ImageNet-Fruits and observe the\nPCA of the training image embeddings. Each color\nrepresents a class. Note that the distilled images typically lie on the edge or outside of their class\u2019s cluster.\n\n**4.1** **Linear Gradient Matching Out-Performs Real-Image Baselines**\n\nFirst, we evaluate our method on the original dataset distillation task: using a backbone model\nto distill a dataset and then training a model _of the same architecture_ on the resulting synthetic\nimages. Note that this setting differs from previous dataset distillation works in that we use a\n_pre-trained backbone_ distillation and reuse that backbone during evaluation by training a new\nrandomly-initialized linear classifier on top of it.\n\nIn Table 1, we see results for the single-model setting when distilling ImageNet-100 and ImageNet-1k.\nAcross both datasets and all four models, **our method convincingly out-performs all real-image**\n**baselines** . In particular, our method enables a linear probe trained on top of DINO-v2 [31] to reach\n**75% test accuracy** on ImageNet-1k while only ever having seen a **single labeled image per class** .\nIn comparison, training on the full dataset of 1.3 million real images reaches just 7 points higher at\n83%. Similar results are seen for the other models and datasets as well.\n\nIn Figure 4 we visualize the _embeddings_ of the distilled images relative to the real training data\nby plotting the 2D principal component analysis (PCA). For the sake of visual clarity, we use\nImageNet-Fruits [6, 7], a toy dataset of 10 fruit classes from ImageNet-1k. The embeddings in this\nfigure are from the same model used to distill the dataset (DINO-v2). We observe that the embeddings\nof the distilled images tend to lie far away from their respective class\u2019s centroid, often falling on\nthe outside edge of the class\u2019s distribution. We hypothesize that this is due in-part to the distillation\nembedding _highly-discriminative_ features within the synthetic images.\n\n**4.2** **Distilled Images Generalize Across Models**\n\nNext, we investigate the cross-model generalization capabilities of our distilled datasets. That is, we\nfirst distill a dataset using one backbone model (e.g., CLIP) and then evaluate the synthetic images\u2019 performance on the _other_ models (DINO-v2, EVA-02, MoCo-v3) that were not seen during distillation.\n\nWe visualize these results in Table 2. The diagonal elements are equivalent to the first row of Table 1\nand represent single-model performance while the off-diagonals show cross-model capabilities. We\nsee that the distilled datasets tend to generalize well to unseen models save for an outlier between\nCLIP and Moco, possibly due to poor model _alignment_ (Section 4.6). We also observe that the highestaccuracy model on the full dataset (DINO) also has the distilled dataset with the best cross-model performance, suggesting that a model\u2019s quality affects the generalization capabilities of its distilled data.\n\n**4.3** **Regularization and Augmentation Enable High Performance**\n\nIn this section, we quantitatively (Figure 3) and qualitatively (Table 5) analyze the effects of the\nvarious regularization and augmentation techniques included in our distillation process. Table 3 shows\nthe effects of ablating various components when evaluating using the same model used to distill ( **top** )\n\n6\n\nTrain Set ImageNet-100\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nFull (Ours) **84.9** _\u00b1_ **0.1 91.5** _\u00b1_ **0.1 89.0** _\u00b1_ **0.0 83.4** _\u00b1_ **0.1 87.2** _\u00b1_ **0.1**\n-Decorrelate 82.6 _\u00b1_ 0.1 **91.3** _\u00b1_ **0.2 89.0** _\u00b1_ **0.1** 83.2 _\u00b1_ 0.1 86.5 _\u00b1_ 0.1\n\n-Pyramid 83.5 _\u00b1_ 0.2 91.0 _\u00b1_ 0.3 87.9 _\u00b1_ 0.1 80.5 _\u00b1_ 0.1 85.7 _\u00b1_ 0.1\n-Augment 58.4 _\u00b1_ 0.2 82.6 _\u00b1_ 0.4 74.0 _\u00b1_ 0.3 59.6 _\u00b1_ 0.5 68.6 _\u00b1_ 0.4\n\nFull (Ours) **75.4** _\u00b1_ **0.3 80.9** _\u00b1_ **0.1** 76.6 _\u00b1_ 0.1 78.2 _\u00b1_ 0.1 **77.8** _\u00b1_ **0.2**\n-Decorrelate 69.4 _\u00b1_ 0.4 79.5 _\u00b1_ 0.1 **76.8** _\u00b1_ **0.1 79.9** _\u00b1_ **0.2** 76.4 _\u00b1_ 0.2\n\n-Pyramid 57.3 _\u00b1_ 0.2 74.5 _\u00b1_ 0.2 68.5 _\u00b1_ 0.2 68.1 _\u00b1_ 0.2 67.1 _\u00b1_ 0.2\n-Augment 35.3 _\u00b1_ 0.4 31.6 _\u00b1_ 0.2 34.3 _\u00b1_ 0.5 32.2 _\u00b1_ 0.5 33.3 _\u00b1_ 0.4\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1\n\nTable 3: **Evaluating Ablations:** While all three components\nprovide improvements, the Augmentation has the most dramatic effect, especially in the cross-model setting. Likewise,\nthe Pyramid optimization seems to matter more in the crossmodel setting than the same-model setting by mitigating overfitting to the model used during distillation.\n\nFigure 5: **Visualizing Ablations:** Removing\nvarious components of our pipeline causes\nvisual degradation in the distilled images.\n\nand averaging performances across the other three models ( **bottom** ). Figure 5 visualizes the distilled\nPineapple class from ImageNet-100 under the same ablations.\n\n**Color Decorrelation** Inspired by prior work in feature visualization [30] and motivated by a desire\nto spare our synthetic images from any color-related biases imposed by the model used to distill\nthem, we apply a color decorrelation technique to our distillation process. In Figure 5, we see that the\nimages distilled without the color decorrelation (column 2) look less realistic than those using our\nfull method (column 1); they are over saturated and contain high levels of incorrect colors (blue in\nthis example). Quantitatively, however, this component has the lowest effect of the three analyzed in\nthis section. While generally slightly helpful, it only offers a large improvement in the cross-model\nsetting when distilling using CLIP.\n\n**Pyramid Representation** It has been shown in prior work [7] that pixel-based optimization for\ndataset distillation does not scale well to higher resolutions; the synthetic images tend to become\nriddled with high-frequency patterns that inhibit their usefulness as training data. As discussed in\nSection 3.2, we instead adopt a pyramid representation for the distillation process. In Figure 5, we\nsee samples distilled from ImageNet-100 optimized using either the pyramid (column 1) or na\u00efve\npixel representation (column 3). We encourage the reader to zoom in and observe the high-frequency\npatterns and overall lack of coherence in the pixel-based images. In Table 3, we see that the images\ndistilled without the pyramid representation do indeed make far worse training data in the cross-model\nsetting, causing the model to overfit to the high-frequency patterns.\n\n**Differentiable Augmentations** Since its first proposal [53], the incorporation of differentiable\naugmentations during the distillation process has proven critical to the efficacy of the synthesized\nimages as training data. As such, we also perform differentiable augmentations in this work, as\ndescribed in Section 3.3. In Figure 5, we see samples from ImageNet-100 distilled both with (column 1) and without (column 4) augmentations. Visually, we observe that the images distilled _without_\naugmentations lack much meaningful structure and appear to simply be blobs of color with just a hint\nof geometry. In Table 3, we see that the lack of augmentations _severely_ limits the synthetic images\u2019\nusefulness as training data, even when evaluation on the same model used to distill.\n\nAs earlier discussed, we also apply _multiple rounds_ of augmentations at each distillation step and\nconcatenate the multiple augmented versions together to form the synthetic batch. Figure 3 illustrates\nhow the number of _augmentations per batch_ affects both the single-model and cross-model performance of the distilled data. Specifically, we see that when distilling ImageNet-100 with DINO-v2,\nraising the number of augmentations per batch from 1 to 5 and eventually 10 steadily increases the\ndistilled images\u2019 effectiveness as training data both on the backbone model used to distill (DINO-v2)\nand the other unseen models (CLIP, EVA-02, MoCo-v3).\n\n7\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-3.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-4.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-5.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-6.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-7.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-8.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-9.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-10.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-14.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-15.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-16.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-17.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-18.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-19.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-20.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-7-21.png)\n\nFigure 6: **Distilling Datasets with Spurious Correlations:** The 4-class \u201cSpawrious\u201d dataset contains spurious\nbackground correlations in the training set that are then subverted in the test set ( **left** ). A DINO linear\nprobe trained on the full training set performs well, reaching 78% test accuracy, while a MoCo probe fails\ncatastrophically, only reaching 36%. The distilled images ( **right** ) hint as to why: those distilled with DINO-v2\nstill contain mostly decipherable dog breeds while the MoCo-v3 counterparts focus almost entirely on the\nbackground environments. These images likely reflect the same biases held by the models used to distill them.\n\nTrain Set Spawrious WaterBirds\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **43.1** _\u00b1_ **6.4 80.8** _\u00b1_ **3.1 36.5** _\u00b1_ **3.1 32.7** _\u00b1_ **2.3 48.3** _\u00b1_ **3.7 77.9** _\u00b1_ **0.2 82.1** _\u00b1_ **2.9 78.0** _\u00b1_ **0.8 77.8** _\u00b1_ **0.0 79.0** _\u00b1_ **1.0**\nNeighbors **41.7** _\u00b1_ **4.6 76.9** _\u00b1_ **1.2 40.7** _\u00b1_ **2.7 33.0** _\u00b1_ **3.4 48.1** _\u00b1_ **3.0 74.6** _\u00b1_ **6.5** 67.3 _\u00b1_ 5.8 **74.3** _\u00b1_ **3.3** 45.2 _\u00b1_ 11.4 65.3 _\u00b1_ 6.8\nCentroids **44.8** _\u00b1_ **5.0 80.2** _\u00b1_ **2.7 38.1** _\u00b1_ **3.3 30.5** _\u00b1_ **1.6 48.4** _\u00b1_ **3.2 69.8** _\u00b1_ **8.6** 65.7 _\u00b1_ 3.4 64.6 _\u00b1_ 7.9 62.0 _\u00b1_ 5.2 65.5 _\u00b1_ 6.3\n\nRandom **46.2** _\u00b1_ **4.4** 68.1 _\u00b1_ 8.1 **33.3** _\u00b1_ **5.3 31.8** _\u00b1_ **2.5 44.9** _\u00b1_ **5.1** 71.9 _\u00b1_ 4.5 57.1 _\u00b1_ 8.6 59.8 _\u00b1_ 13.3 67.4 _\u00b1_ 5.7 64.0 _\u00b1_ 8.0\n\nFull Dataset 50.4 _\u00b1_ 0.3 78.1 _\u00b1_ 0.1 50.1 _\u00b1_ 0.4 35.8 _\u00b1_ 0.0 53.6 _\u00b1_ 0.2 86.0 _\u00b1_ 0.1 95.5 _\u00b1_ 0.1 90.4 _\u00b1_ 0.2 74.3 _\u00b1_ 0.1 86.5 _\u00b1_ 0.1\n\nTable 4: **Performance on Datasets with Spurious Background Correlations:** The Spawrious ( **left** ) and Waterbirds ( **right** ) training sets contain intentionally adversarial background correlations that are then subverted in the\ntest sets. On Spawrious, our method no longer out-performs the real-image baselines as with the standard datasets\n(Table 1). This is perhaps due to the synthetic data adopting the models\u2019 biases and overfitting to the backgrounds\non the training sets. We also see interesting interpretability results in the images themselves (Figure 6).\n\n**4.4** **Distilling Adversarial Datasets Reveals Interpretable Model Weaknesses**\n\nThe \u201cSpawrious\u201d dataset [26] consists of four classes of dog breeds and is designed to evaluate a\nmodel\u2019s ability to focus on the relevant content of an image rather than spurious correlations. In the\ntraining data, each breed is paired with its own unique environment: (Bulldog, Forest), (Corgi, Desert),\n(Dachshund, Mountain), and (Labrador, Snow). However, in the test set, the environments are intentionally different: (Bulldog, Mountain), (Corgi, Forest), (Dachshund, Snow), and (Labrador, Desert).\nWe also experiment with a similarly constructed data, \u201cWaterbirds\u201d [38] consisting of just two classes\n(land birds and water birds) with similarly spurious background correlations.\n\nQuantitative results on these datasets are shown in Table 4. Our method generally outperforms the\nreal-image baselines, but to a significantly smaller extent than on the standard datasets (Table 1). We\nalso observe that when training on the full Spawrious dataset, DINO-v2 [31] _far_ out-performs the\nrest of the models (81% test accuracy) with MoCo-v3 [10] doing dramatically worse (37%), both to\ndegrees far greater than seen when training on standard datasets (as in Table 1).\n\nBy _distilling_ Spawrious with our method, we gain potential insights as to why we might see such\ndramatic results. As seen in Figure 6, the images distilled with DINO-v2 contain clear (albeit\nabstract) depictions of the correct dog breeds. On the other hand, those yielded by MoCo-v3 are\nalmost entirely indecipherable, with the only clear portions being the spurious backgrounds from the\ntraining set. This interpretability result gives a clue towards explaining MoCo-v3\u2019s poor performance\non this dataset; the model clearly seems to focus on the spurious background correlations present\nin the training set rather than the relevant subjects, causing catastrophic overfitting.\n\n**4.5** **Distillation Excels in Fine-Grained Visual Classification**\n\nWhile computer vision methods are typically benchmarked against datasets containing broad categories of objects, such as ImageNet [12], much research also focuses on the task of Fine-Grained\nVisual Classification (FGVC) wherein datasets consist of many closely related classes that can be\n\n8\n\nFigure 7: **Distilling Fine-Grained Datasets:** Our distillation method captures the details necessary to teach a\nclassifier to distinguish between highly similar classes. Pictured above are just 10 of the 120 classes distilled\nfrom the Stanford Dogs [21] dataset ( **top** ) and 10 of the 200 classes distilled from Caltech-UCSD Birds [45]\n[using DINO-v2. For the full distilled datasets, please see the Appendix or our project page.](http://georgecazenavette.github.io/linear-gm)\n\nTrain Set Stanford Dogs CUB-2011\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **52.1** _\u00b1_ **0.2 83.0** _\u00b1_ **0.1 74.8** _\u00b1_ **0.1 69.6** _\u00b1_ **0.2 69.9** _\u00b1_ **0.2 62.2** _\u00b1_ **0.2 86.0** _\u00b1_ **0.1 74.1** _\u00b1_ **0.2 42.5** _\u00b1_ **0.2 66.2** _\u00b1_ **0.2**\nNeighbors 33.4 _\u00b1_ 0.1 71.3 _\u00b1_ 0.2 58.5 _\u00b1_ 0.2 56.3 _\u00b1_ 0.1 54.9 _\u00b1_ 0.2 39.4 _\u00b1_ 0.1 76.9 _\u00b1_ 0.0 52.6 _\u00b1_ 0.3 28.1 _\u00b1_ 0.0 49.2 _\u00b1_ 0.1\nCentroids 43.3 _\u00b1_ 0.1 73.0 _\u00b1_ 0.2 60.9 _\u00b1_ 0.2 55.2 _\u00b1_ 0.2 58.1 _\u00b1_ 0.2 54.3 _\u00b1_ 0.2 78.5 _\u00b1_ 0.2 59.9 _\u00b1_ 0.3 30.2 _\u00b1_ 0.1 55.7 _\u00b1_ 0.2\n\nRandom 23.3 _\u00b1_ 1.5 51.9 _\u00b1_ 1.8 38.3 _\u00b1_ 1.8 36.6 _\u00b1_ 1.4 37.5 _\u00b1_ 1.6 37.5 _\u00b1_ 1.6 64.4 _\u00b1_ 1.5 44.3 _\u00b1_ 1.5 19.1 _\u00b1_ 0.5 41.3 _\u00b1_ 1.3\n\nFull Dataset 76.9 _\u00b1_ 0.1 88.6 _\u00b1_ 0.1 82.6 _\u00b1_ 0.1 72.3 _\u00b1_ 0.5 80.1 _\u00b1_ 0.2 77.5 _\u00b1_ 0.7 90.2 _\u00b1_ 0.2 84.0 _\u00b1_ 0.3 43.7 _\u00b1_ 0.8 73.8 _\u00b1_ 0.5\n\nTable 5: **Performance on Fine-Grained Datasets:** Our distillation method captures the most discriminative\naspects of each class, thereby enabling a down-stream classifier to correctly identify samples from datasets\nwhere all classes are closely related. In particular, the performance gap between our method and the real-image\nbaselines is even higher on these fine-grained datasets (Stanford Dogs [21] and CUB-200-2011 [45]) than on the\nstandard ImageNet benchmarks.\n\nchallenging for even human experts to distinguish. Such datasets require models to learn fine-grained\nfeatures in order to identify the subtle differences between each class.\n\nWe apply our linear method to two common FGVC datasets: Stanford Dogs [21] and Caltech-UCSD\nBirds-200-2011 [45]. Samples of these datasets distilled using DINO-v2 can be seen in Figure 7. As\nseen in Table 5, in this more challenging fine-grained setting, our method outperforms the real-image\nbaselines to a _significantly higher_ degree than on the standard ImageNet benchmarks (Table 1). It\nseems as though the distillation process\u2019s ability to store didactic information in a single image\nper class is even more relevant in this setting since any one real image is less likely to contain the\ninformation necessary to distinguish its entire respective class from the other highly similar classes.\n\n**4.6** **Cross-Model Performance Predicts Model Alignment**\n\nRecent research has suggested an \u201calignment\u201d of various self-supervised models despite large\ndifferences in their training methods or even data modalities. The notion that all these models are\nindeed converging to a unified embedding space has been dubbed the \u201cPlatonic Representation\nHypothesis\u201d [20]. While the representations of today\u2019s models are not yet perfectly synchronized, it\nis still of interest to measure the degree to which they are aligned.\n\nIn the hypothesis\u2019s titular work, the authors introduce a method of measuring the alignment of two\nmodels called \u201cmutual _k_ nearest neighbors.\u201d In short, this method finds each sample\u2019s _k_ nearest\nneighbors in the embedding spaces of each model and then computes the fraction of neighbors that\nare shared between the two.\n\nWhen we distill images with a given model A and measure the 1 nearest neighbor performance\n(since there is just one image per class) on a different model B, we find that the normalized test\naccuracy is strongly correlated with the mutual _k_ -nn alignment between models A and B, as seen\nin Table 6. This is an interesting interpretability result showing that the cross-model performance of\na distilled dataset highly depends on the alignment between the two models. Given this dependency,\nour distillation method then acts as a method of _visualizing_ how well these models align by backing\nthe discrepancies in the embedding space out to image space. For example, given the two least\naligned models (CLIP and MoCo), we can see in Figure 1 that even for different sets of classes, the\ntwo models clearly distill very different _styles_ of images, alluding towards their misalignment.\n\n9\n\nDistill Normalized _k_ -NN Accuracy\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3\n\nSource Model Alignment\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-9-0.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-9-1.png)\n\nTable 6: **Distilled datasets predict model alignment.** We distill ImageNet-1k and find the synthetic data\u2019s\n_cross-model_ performance ( **left** ) by evaluating on a model other than the one used during distillation. We find that\nthis cross-model performance correlates well with the _alignment_ between models\u2019 embedding spaces ( **right** ).\nNote the similarity of the per-row trends between the two tables. Rows are colored from highest to lowest.\n\nFigure 8: **Distilling Out-of-Distribution Datasets:** Despite only ever being trained on the real-world images\nin ImageNet-1k [12], our method can still use DINO-v1 [5] to distill out-of-distribution datasets such as\nArtBench [24] that have no overlapping content. We see that the distillation is not simply \u201ccopying\u201d samples\nfrom the dataset by comparing to the nearest real neighbor in the model\u2019s embedding space and observing the\nstark differences. This interpretability insight granted by our method highlights DINO\u2019s remarkable ability to\ngeneralize beyond its training distribution.\n\n**4.7** **Self-Supervised Backbones can Distill Out-of-Distribution Datasets**\n\nNote that while we have thus far been discussing DINO-v2, this section in particular will reference\nDINO-v1 since this version\u2019s training set is open-sourced. Since DINO-v1 [5] was only trained on\nImageNet [12], a dataset of nearly all \u201creal-world\u201d images, we can easily test its ability to distill an\n**out-of-distribution** dataset such as ArtBench [24] that consists of 10 classes of art styles. In Figure 8,\nwe visualize the distilled images ( **top** ) as well as the nearest neighbor in DINO-v1\u2019s embedding\nspace. Surprisingly, despite having previously only ever seen \u201creal-world\u201d images from ImageNet,\nDINO-v1 is still able to effectively distill ArtBench into a single image per class. Furthermore, we\nconfirm that the distilling is not simply \u201ccopying\u201d real images from the training set by observing\nthe stark differences between the synthetic images and their nearest neighbors. This is especially\napparent in the cases of Realism, Renaissance, and Romanticism where the nearest neighbors are\nblack and white while the distilled images are colorful."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is gradient-based optimization in image space to create synthetic data points that effectively summarize the discriminative features of a class, as perceived by a pre-trained feature extractor. Instead of trying to reconstruct the data distribution, it aims to create didactic examples. This is achieved by iteratively updating pixel values (or a multi-resolution representation, like a pyramid) of a small set of synthetic images (one per class) such that the gradients of a loss function are maximized. The pre-trained backbone acts as a fixed oracle providing a \"target signal\" in its embedding space, akin to backpropagating through the input pixels themselves.\n\n**Explanation:** Think of it like this: You have a large collection of photos, and a very smart but rigid art critic (the pre-trained feature extractor). We want to create just one \"perfect\" abstract painting for each category (e.g., \"dog\", \"cat\") that this critic would immediately recognize as the quintessential example. We start with a blank canvas for each category. We then repeatedly show this canvas to the critic, get its \"opinion\" (the feature embedding), and also check how well a small, simple classifier built on top of the critic's opinion would perform if it learned from this single abstract painting. Using the critic's detailed feedback (gradients) and the classifier's performance feedback, we subtly adjust the pixels of our abstract painting. This is like a feedback loop: \"Does this pixel change make the critic think it's more dog-like and easier for the classifier to learn 'dog'?\" We repeat this thousands of times. The \"pyramid representation\" is like working on a painting by first sketching big shapes, then adding medium details, then fine ones, rather than trying to draw every tiny pixel perfectly from the start, which often leads to messy, noisy paintings. \"Differentiable augmentations\" are like showing the critic our abstract painting from different angles, lighting conditions, or with parts zoomed in. This forces our abstract painting to capture robust features that define the object itself, rather than just superficial details. The magic isn't in copying real images, but in distilling the essence or most discriminative features that the pre-trained feature extractor has learned, concentrating the \"teaching signal\" of many images into one, allowing a simple classifier (like a basic if-else statement) to learn effectively."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this paper, we introduce EGGROLL, a powerful method for blackbox optimisation that scales evolutionary\nstrategies to billion-parameter models and beyond using low-rank search matrices. Our experiments demonstrate that EGGROLL is effective with rank as small as _r_ = 1, which represents substantial computational and\nmemory savings for negligible decrease in performance when compared to the full-rank ES update. Empirically,\nEGGROLL delivers large speedups over na\u00efve ES in tabula rasa and multi-agent RL, and can power end-to-end\ntraining pipelines for large language models. Our theoretical analysis reveals that the low-rank EGGROLL\nupdate quickly converges with rank _r_, however further theoretical analysis is needed to explain the success of\nour method when _r_ = 1.\n\nLooking forward, we are working on applying EGGROLL for other problems beyond the reach of modern\ngradient-based techniques. In particular, EGGROLL can enable the training of large scale end-to-end neurosymbolic systems (Sarker et al., 2021) which have nondifferentiable components. For instance, we can\ntrain neural networks that directly interface with symbolic modules for specialized functions, like memory\nor calculations. We can also optimize end-to-end systems of language models, training them to be aware of\ninference-time harnesses and interactions with other agents in complex systems.\n\n**Acknowledgements**\n\nCompute for this project is graciously provided by the Isambard-AI National AI Research Resource, under\nthe projects \u201cFLAIR 2025 Moonshot Projects\u201d and \u201cRobustness via Self-Play RL.\u201d Some experiments also\n[used compute generously given by JASMIN, the UK\u2019s collaborative data analysis environment (https:](https://www.jasmin.ac.uk)\n[//www.jasmin.ac.uk).](https://www.jasmin.ac.uk)\n\n11\n\nBidipta Sarkar is supported by the Clarendon Fund Scholarship in partnership with a Department of Engineering\nScience Studentship for his Oxford DPhil. Mattie Fellows is funded by a generous grant from the UKRI\nEngineering and Physical Sciences Research Council EP/Y028481/1. Jakob Nicolaus Foerster is partially\nfunded by the UKRI grant EP/Y028481/1 (originally selected for funding by the ERC). Jakob Nicolaus Foerster\nis also supported by the JPMC Research Award and the Amazon Research Award. Juan Agustin Duque is\nsupported by the St-Pierre-Larochelle Scholarship at the University of Montreal and by Aaron Courville\u2019s\nCIFAR AI Chair in Representations that Generalize Systematically. Lukas Seier is supported by the Intelligent\nEarth CDT with funding from the UKRI grant number EP/Y030907/1.\n\n**References**\n\nShun-ichi Amari. Natural gradient works efficiently in learning. _Neural Computation_, 10(2):251\u2013276, 1998.\ndoi: 10.1162/089976698300017746.\n\nA. B. Basset. _A Treatise on Hydrodynamics: with numerous examples_, volume 2. Deighton, Bell, and Co.,\nCambridge, UK, 1892.\n\nYoshua Bengio, R\u00e9jean Ducharme, and Pascal Vincent. A neural probabilistic language model. In T. Leen,\nT. Dietterich, and V. Tresp (eds.), _Advances in Neural Information Processing Systems_, volume 13.\n[MIT Press, 2000. URL https://proceedings.neurips.cc/paper_files/paper/2000/](https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf)\n[file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf)\n\nHans-Georg Beyer. Toward a theory of evolution strategies: Self-adaptation. _Evolutionary Computation_, 3:\n[311\u2013347, 1995. URL https://api.semanticscholar.org/CorpusID:17416734.](https://api.semanticscholar.org/CorpusID:17416734)\n\nHans-Georg Beyer and Hans-Paul Schwefel. Evolution strategies \u2013a comprehensive introduction. _Natural_\n_Computing_, 1(1):3\u201352, 2002.\n\nR. N. Bhattacharya and R. Ranga Rao. _Normal approximation and asymptotic expansions_ . Wiley series in\nprobability and mathematical statistics. Wiley, New York, 1976. ISBN 047107201X.\n\nCl\u00e9ment Bonnet, Daniel Luo, Donal Byrne, Shikha Surana, Sasha Abramowitz, Paul Duckworth, Vincent\nCoyette, Laurence I. Midgley, Elshadai Tegegn, Tristan Kalloniatis, Omayma Mahjoub, Matthew Macfarlane,\nAndries P. Smit, Nathan Grinsztajn, Raphael Boige, Cemlyn N. Waters, Mohamed A. Mimouni, Ulrich\nA. Mbou Sob, Ruan de Kock, Siddarth Singh, Daniel Furelos-Blanco, Victor Le, Arnu Pretorius, and\nAlexandre Laterre. Jumanji: a diverse suite of scalable reinforcement learning environments in jax, 2024.\n[URL https://arxiv.org/abs/2306.09884.](https://arxiv.org/abs/2306.09884)\n\nJames Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George\nNecula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable\n[transformations of Python+NumPy programs, 2018. URL http://github.com/jax-ml/jax.](http://github.com/jax-ml/jax)\n\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,\nChristopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models\n[are few-shot learners, 2020. URL https://arxiv.org/abs/2005.14165.](https://arxiv.org/abs/2005.14165)\n\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, ..., Barret Zoph, Liam Fedus, and ...\n(full list). Palm: Scaling language modeling with pathways. _J. Mach. Learn. Res._, 24(1144), 2023. URL\n[https://jmlr.org/papers/volume24/22-1144/22-1144.pdf.](https://jmlr.org/papers/volume24/22-1144/22-1144.pdf)\n\nA. P. Dawid. Some matrix-variate distribution theory: Notational considerations and a bayesian application.\n_Biometrika_, 68(1):265\u2013274, 1981. ISSN 0006-3444.\n\n12\n\nNan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun,\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P. Bosma, Zongwei Zhou,\nTao Wang, Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathleen Meier-Hellstern, Toju\nDuke, Lucas Dixon, Kun Zhang, Quoc Le, Yonghui Wu, Zhifeng Chen, and Claire Cui. Glam: Efficient\nscaling of language models with mixture-of-experts. In _Proceedings of the 39th International Conference_\n_on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pp. 5547\u20135569, Jul 2022.\n[URL https://proceedings.mlr.press/v162/du22c.html.](https://proceedings.mlr.press/v162/du22c.html)\n\nRichard Durrett. _Probability: Theory and Examples_ . Cambridge University Press, Cambridge, UK, 4th edition,\n2010.\n\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: scaling to trillion parameter models\nwith simple and efficient sparsity. _J. Mach. Learn. Res._, 23(1):1\u201339, January 2022. ISSN 1532-4435. URL\n[https://jmlr.org/papers/volume23/21-0998/21-0998.pdf.](https://jmlr.org/papers/volume23/21-0998/21-0998.pdf)\n\n[Jakob Nicolaus Foerster. Nonlinear computation in deep linear networks, sep 2017. URL https://blog.](https://blog.openai.com/nonlinear-computation-in-linear-networks/)\n[openai.com/nonlinear-computation-in-linear-networks/. Accessed: 2025-11-20.](https://blog.openai.com/nonlinear-computation-in-linear-networks/)\n\nGerald B. Folland. _Real Analysis: Modern Techniques and Their Applications_ . John Wiley & Sons, New York,\n2nd edition, 1999. See Theorem 8.22 (Riemann\u2013Lebesgue Lemma).\n\nC. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem. Brax \u2013 a\n[differentiable physics engine for large scale rigid body simulation, 2021. URL https://arxiv.org/](https://arxiv.org/abs/2106.13281)\n[abs/2106.13281.](https://arxiv.org/abs/2106.13281)\n\nAlexander D. Goldie, Chris Lu, Matthew T. Jackson, Shimon Whiteson, and Jakob N. Foerster. Can Learned\nOptimization Make Reinforcement Learning Less Difficult? In _Advances in Neural Information Processing_\n_Systems_, volume 37, pp. 5454\u20135497, 2024.\n\nAlexander David Goldie, Zilin Wang, Jaron Cohen, Jakob Nicolaus Foerster, and Shimon Whiteson. How\n[Should We Meta-Learn Reinforcement Learning Algorithms? May 2025. URL https://openreview.](https://openreview.net/forum?id=jKzQ6af2DU)\n[net/forum?id=jKzQ6af2DU.](https://openreview.net/forum?id=jKzQ6af2DU)\n\nIan Goodfellow, Yoshua Bengio, and Aaron Courville. _Deep Learning_ [. MIT Press, 2016. http://www.](http://www.deeplearningbook.org)\n[deeplearningbook.org.](http://www.deeplearningbook.org)\n\nIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes,\nN. Lawrence, and K.Q. Weinberger (eds.), _Advances in Neural Information Processing Systems_, volume 27. Curran Associates, Inc., 2014. [URL https://proceedings.neurips.cc/paper_](https://proceedings.neurips.cc/paper_files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf)\n[files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2014/file/f033ed80deb0234979a61f95710dbe25-Paper.pdf)\n\nI. S. (Izrail Solomonovich) Gradshte\u02d8\u0131n, I. M. (Iosif Moiseevich) Ryzhik, Daniel Zwillinger, Victor Moll, and\nInc Scripta Technica. _Table of integrals, series, and products_ . Academic Press, San Diego ; Tokyo, 8 edition,\n2015. ISBN 0123849330.\n\nG R Grimmett and D R Stirzaker. Probability and random processes. _Journal of the Royal Statistical Society._\n_Series A, Statistics in society_, 156(3):503\u2013503, 1993. ISSN 0964-1998.\n\nPeter Hall. _The bootstrap and Edgeworth expansion_ . Springer series in statistics. Springer-Verlag, New York,\n1992. ISBN 9780387945088.\n\n[Nikolaus Hansen. The cma evolution strategy: A tutorial, 2023. URL https://arxiv.org/abs/1604.](https://arxiv.org/abs/1604.00772)\n\n[00772.](https://arxiv.org/abs/1604.00772)\n\nNikolaus Hansen and Andreas Ostermeier. Completely Derandomized Self-Adaptation in Evolution Strategies.\n_Evolutionary Computation_, 9(2):159\u2013195, June 2001. ISSN 1063-6560. doi: 10.1162/106365601750190398.\n[URL https://ieeexplore.ieee.org/document/6790628.](https://ieeexplore.ieee.org/document/6790628)\n\n13\n\nJoel Heck and Fathi M. Salem. Simplified minimal gated unit variations for recurrent neural networks, 2017.\n[URL https://arxiv.org/abs/1701.03452.](https://arxiv.org/abs/1701.03452)\n\nSepp Hochreiter and J\u00fcrgen Schmidhuber. Lstm can solve hard long time lag problems. In M.C. Mozer,\nM. Jordan, and T. Petsche (eds.), _Advances in Neural Information Processing Systems_, volume 9.\n[MIT Press, 1996. URL https://proceedings.neurips.cc/paper_files/paper/1996/](https://proceedings.neurips.cc/paper_files/paper/1996/file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf)\n[file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/1996/file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf)\n\nMark Horowitz. 1.1 computing\u2019s energy problem (and what we can do about it). In _2014 IEEE International_\n_Solid-State Circuits Conference Digest of Technical Papers (ISSCC)_, pp. 10\u201314, 2014. doi: 10.1109/ISSCC.\n2014.6757323.\n\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. Lora: Low-rank adaptation of large language models. In _ICLR_ . OpenReview.net, 2022.\n\nMax Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi,\nOriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, Chrisantha Fernando, and Koray Kavukcuoglu.\n[Population Based Training of Neural Networks, November 2017. URL http://arxiv.org/abs/](http://arxiv.org/abs/1711.09846)\n[1711.09846. arXiv:1711.09846 [cs].](http://arxiv.org/abs/1711.09846)\n\nFeihu Jin, Yifan Liu, and Ying Tan. Derivative-free optimization for low-rank adaptation in large language\nmodels. _IEEE/ACM Trans. Audio, Speech and Lang. Proc._, 32:4607\u20134616, October 2024. ISSN 2329-9290.\n[doi: 10.1109/TASLP.2024.3477330. URL https://doi.org/10.1109/TASLP.2024.3477330.](https://doi.org/10.1109/TASLP.2024.3477330)\n\nJean Kaddour. The minipile challenge for data-efficient language models. _arXiv preprint arXiv:2304.08442_,\n2023.\n\nSham M Kakade. A natural policy gradient. In T. Dietterich, S. Becker, and Z. Ghahramani (eds.), _Advances in Neural Information Processing Systems_, volume 14. MIT Press,\n2001. [URL https://proceedings.neurips.cc/paper_files/paper/2001/file/](https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)\n[4b86abe48d358ecf194c56c69108433e-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)\n\nDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and Yann LeCun\n(eds.), _2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April_\n_14-16, 2014, Conference Track Proceedings_ [, 2014. URL http://arxiv.org/abs/1312.6114.](http://arxiv.org/abs/1312.6114)\n\nDaria Korotyshova, Boris Shaposhnikov, Alexey Malakhov, Alexey Khokhulin, Nikita Surnachev, Kirill\nOvcharenko, George Bredis, Alexey Gorbatovski, Viacheslav Sinii, and Daniil Gavrilov. Essa: Evolutionary\n[strategies for scalable alignment, 2025. URL https://arxiv.org/abs/2507.04453.](https://arxiv.org/abs/2507.04453)\n\nJohn R. Koza. Genetic programming as a means for programming computers by natural selection. _Statistics_\n_and Computing_ [, 4(2):87\u2013112, June 1994. ISSN 1573-1375. doi: 10.1007/BF00175355. URL https:](https://doi.org/10.1007/BF00175355)\n[//doi.org/10.1007/BF00175355.](https://doi.org/10.1007/BF00175355)\n\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep\nconvolutional neural networks. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger\n(eds.), _Advances in Neural Information Processing Systems_, volume 25. Curran Associates,\n[Inc., 2012. URL https://proceedings.neurips.cc/paper_files/paper/2012/file/](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n[c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with\npagedattention. In _Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles_,\n2023.\n\nRobert Tjarko Lange, Tom Schaul, Yutian Chen, Tom Zahavy, Valentin Dallibard, Chris Lu, Satinder Singh,\nand Sebastian Flennerhag. Discovering Evolution Strategies via Meta-Black-Box Optimization, March\n[2023. URL http://arxiv.org/abs/2211.11260. arXiv:2211.11260 [cs].](http://arxiv.org/abs/2211.11260)\n\n14\n\nPierre-Simon Laplace. M\u00e9moire sur les int\u00e9grales d\u00e9finies et leur application aux probabilit\u00e9s, et sp\u00e9cialement\n\u00e0 la recherche du milieu qu\u2019il faut choisir entre les r\u00e9sultats des observations. _M\u00e9moires de la Classe des_\n_Sciences Math\u00e9matiques et Physiques de l\u2019Institut Imp\u00e9rial de France,_ 1 [re] s\u00e9rie, 11(1 [re] partie):297\u2013347,\n1811.\n\nV. P. Leonov and A. N. Shiryaev. On a method of calculation of semi-invariants. _Theory of Probability and Its_\n_Applications_ [, 4(3):342\u2013355, 1959. URL https://www.mathnet.ru/eng/tvp4894.](https://www.mathnet.ru/eng/tvp4894)\n\nOscar Li, James Harrison, Jascha Sohl-Dickstein, Virginia Smith, and Luke Metz. Variance-reduced gradient\nestimation via noise-reuse in online evolution strategies. In _Thirty-seventh Conference on Neural Information_\n_Processing Systems_, 2023a.\n\nOscar Li, James Harrison, Jascha Sohl-Dickstein, Virginia Smith, and Luke Metz. Noise-Reuse in Online\n[Evolution Strategies, April 2023b. URL http://arxiv.org/abs/2304.12180. arXiv:2304.12180](http://arxiv.org/abs/2304.12180)\n\n[cs].\n\n[Jarek Liesen, Chris Lu, and Robert Lange. rejax, 2024. URL https://github.com/keraJLi/rejax.](https://github.com/keraJLi/rejax)\n\nRyan Lowe, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor Mordatch. Multi-agent actor-critic for\nmixed cooperative-competitive environments. _Advances in neural information processing systems_, 30, 2017.\n\nChris Lu, Jakub Kuba, Alistair Letcher, Luke Metz, Christian Schroeder de Witt, and Jakob Foerster. Discovered policy optimisation. _Advances in Neural Information Processing Systems_, 35:16455\u201316468, 2022.\n\nH. M. Macdonald. Zeroes of the bessel functions. _Proceedings of the London Mathematical Society_, 30:\n165\u2013179, 1899. doi: 10.1112/plms/s1-30.1.165.\n\nSadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen, and Sanjeev Arora.\nFine-tuning language models with just forward passes. In _Proceedings of the 37th International Conference_\n_on Neural Information Processing Systems_, NIPS \u201923, Red Hook, NY, USA, 2023. Curran Associates Inc.\n\nMichael Matthews, Michael Beukman, Benjamin Ellis, Mikayel Samvelyan, Matthew Jackson, Samuel\nCoward, and Jakob Foerster. Craftax: A lightning-fast benchmark for open-ended reinforcement learning.\n_arXiv preprint arXiv:2402.16801_, 2024.\n\nMichael T. Matthews, Michael Beukman, Chris Lu, and Jakob Nicolaus Foerster. Kinetix: Investigating\nthe training of general agents through open-ended physics-based control tasks. In _ICLR_, 2025. URL\n[https://openreview.net/forum?id=zCxGCdzreM.](https://openreview.net/forum?id=zCxGCdzreM)\n\n[P. McCullagh. Cumulants (lecture notes). Lecture notes, University of Chicago (pdf), 2013. URL https:](https://www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf)\n[//www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf.](https://www.stat.uchicago.edu/~pmcc/courses/stat306/2013/cumulants.pdf)\n\nPeter McCullagh. _Tensor Methods in Statistics_ . Monographs on Statistics and Applied Probability. Chapman\n[& Hall / CRC, London, 1987. URL https://www.stat.uchicago.edu/~pmcc/tensorbook/](https://www.stat.uchicago.edu/~pmcc/tensorbook/DoverEdition.pdf)\n[DoverEdition.pdf. Discusses multivariate moments and cumulants (cumulant tensors).](https://www.stat.uchicago.edu/~pmcc/tensorbook/DoverEdition.pdf)\n\nWilliam Merrill, Jackson Petty, and Ashish Sabharwal. The illusion of state in state-space models. In\nRuslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and\nFelix Berkenkamp (eds.), _Proceedings of the 41st International Conference on Machine Learning_, volume\n235 of _Proceedings of Machine Learning Research_, pp. 35492\u201335506. PMLR, 21\u201327 Jul 2024. URL\n[https://proceedings.mlr.press/v235/merrill24a.html.](https://proceedings.mlr.press/v235/merrill24a.html)\n\nLuke Metz, James Harrison, C. Daniel Freeman, Amil Merchant, Lucas Beyer, James Bradbury, Naman\nAgrawal, Ben Poole, Igor Mordatch, Adam Roberts, and Jascha Sohl-Dickstein. VeLO: Training Versatile\n[Learned Optimizers by Scaling Up, November 2022. URL http://arxiv.org/abs/2211.09760.](http://arxiv.org/abs/2211.09760)\narXiv:2211.09760 [cs, math, stat].\n\nJack Parker-Holder, Vu Nguyen, and Stephen Roberts. Provably Efficient Online Hyperparameter Opti[mization with Population-Based Bandits, June 2021. URL http://arxiv.org/abs/2002.02518.](http://arxiv.org/abs/2002.02518)\narXiv:2002.02518 [cs].\n\n15\n\nBo Peng, Ruichong Zhang, Daniel Goldstein, Eric Alcaide, Xingjian Du, Haowen Hou, Jiaju Lin, Jiaxing\nLiu, Janna Lu, William Merrill, Guangyu Song, Kaifeng Tan, Saiteja Utpala, Nathan Wilce, Johan S. Wind,\nTianyi Wu, Daniel Wuttke, and Christian Zhou-Zheng. Rwkv-7 \"goose\" with expressive dynamic state\n[evolution, 2025. URL https://arxiv.org/abs/2503.14456.](https://arxiv.org/abs/2503.14456)\n\n[K. B. Petersen and M. S. Pedersen. The matrix cookbook, October 2008. URL http://www2.imm.dtu.](http://www2.imm.dtu.dk/pubdb/p.php?3274)\n[dk/pubdb/p.php?3274. Version 20081110.](http://www2.imm.dtu.dk/pubdb/p.php?3274)\n\nEduardo Pignatelli, Jarek Liesen, Robert Tjarko Lange, Chris Lu, Pablo Samuel Castro, and Laura Toni. Navix:\n[Scaling minigrid environments with jax, 2024. URL https://arxiv.org/abs/2407.19396.](https://arxiv.org/abs/2407.19396)\n\nXin Qiu, Yulu Gan, Conor F. Hayes, Qiyao Liang, Elliot Meyerson, Babak Hodjat, and Risto Miikkulainen.\n[Evolution strategies at scale: Llm fine-tuning beyond reinforcement learning, 2025. URL https://](https://arxiv.org/abs/2509.24372)\n[arxiv.org/abs/2509.24372.](https://arxiv.org/abs/2509.24372)\n\nI. Rechenberg. Evolutionsstrategien. In Berthold Schneider and Ulrich Ranft (eds.), _Simulationsmethoden_\n_in der Medizin und Biologie_, pp. 83\u2013114, Berlin, Heidelberg, 1978. Springer Berlin Heidelberg. ISBN\n978-3-642-81283-5.\n\nV. K. Rohatgi. _An introduction to probability theory and mathematical statistics_ . Wiley series in probability\nand mathematical statistics. Wiley, New York, 1976. ISBN 0471731358.\n\nFrank. Rosenblatt. _Principles of neurodynamics : perceptrons and the theory of brain mechanisms._ Spartan\nBooks, Washington, 1962.\n\nAlexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson,\nTimon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, et al. Jaxmarl: Multi-agent rl\nenvironments in jax. _arXiv preprint arXiv:2311.10090_, 2023.\n\nTim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable\n[alternative to reinforcement learning, 2017. URL https://arxiv.org/abs/1703.03864.](https://arxiv.org/abs/1703.03864)\n\nJohn K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw. Parallel random numbers: As easy as 1, 2,\n3. In _SC \u201911: Proceedings of 2011 International Conference for High Performance Computing, Networking,_\n_Storage and Analysis_, pp. 1\u201312, 2011. doi: 10.1145/2063384.2063405.\n\nMd Kamruzzaman Sarker, Lu Zhou, Aaron Eberhart, and Pascal Hitzler. Neuro-symbolic artificial intelligence:\n[Current trends, 2021. URL https://arxiv.org/abs/2105.05330.](https://arxiv.org/abs/2105.05330)\n\nZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang,\nY. K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open\n[language models, 2024. URL https://arxiv.org/abs/2402.03300.](https://arxiv.org/abs/2402.03300)\n\nJasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine learning\n[algorithms, 2012. URL https://arxiv.org/abs/1206.2944.](https://arxiv.org/abs/1206.2944)\n\nFelipe Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman, Kenneth O. Stanley, and Jeff\nClune. Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural\n[Networks for Reinforcement Learning, April 2018. URL http://arxiv.org/abs/1712.06567.](http://arxiv.org/abs/1712.06567)\narXiv:1712.06567 [cs].\n\nLaurits Tani, Diana Rand, Christian Veelken, and Mario Kadastik. Evolutionary algorithms for hyperparameter\noptimization in machine learning for application in high energy physics. _The European Physical Journal C_,\n81(2):170, February 2021. ISSN 1434-6044, 1434-6052. doi: 10.1140/epjc/s10052-021-08950-y. URL\n[http://arxiv.org/abs/2011.04434. arXiv:2011.04434 [hep-ex].](http://arxiv.org/abs/2011.04434)\n\nNico M Temme. _Bessel Functions_, chapter 9, pp. 219\u2013255. John Wiley and Sons, Ltd, 1996. ISBN\n[9781118032572. doi: https://doi.org/10.1002/9781118032572.ch9. URL https://onlinelibrary.](https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118032572.ch9)\n[wiley.com/doi/abs/10.1002/9781118032572.ch9.](https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118032572.ch9)\n\n16\n\nSebastian Towers, Aleksandra Kalisz, Philippe A. Robert, Alicia Higueruelo, Francesca Vianello, MingHan Chloe Tsai, Harrison Steel, and Jakob N. Foerster. ADIOS: Antibody Development via Opponent\n[Shaping, June 2025. URL http://arxiv.org/abs/2409.10588. arXiv:2409.10588 [q-bio].](http://arxiv.org/abs/2409.10588)\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett (eds.), _Advances in Neural Information Processing Systems_,\n[volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n[files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n\nPaul Vicol, Luke Metz, and Jascha Sohl-Dickstein. Unbiased gradient estimation in unrolled computation\ngraphs with persistent evolution strategies. In Marina Meila and Tong Zhang (eds.), _Proceedings of the_\n_38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning_\n_Research_ [, pp. 10553\u201310563. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/](https://proceedings.mlr.press/v139/vicol21a.html)\n[v139/vicol21a.html.](https://proceedings.mlr.press/v139/vicol21a.html)\n\nPaul Vicol, Zico Kolter, and Kevin Swersky. Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single, April 2023. [URL http://arxiv.org/abs/2304.11153.](http://arxiv.org/abs/2304.11153)\narXiv:2304.11153 [cs, stat].\n\nAmala Mary Vincent and P. Jidesh. An improved hyperparameter optimization framework for AutoML\nsystems using evolutionary algorithms. _Scientific Reports_, 13(1):4737, March 2023. ISSN 2045-2322. doi:\n[10.1038/s41598-023-32027-3. URL https://doi.org/10.1038/s41598-023-32027-3.](https://doi.org/10.1038/s41598-023-32027-3)\n\nG. N. Watson. _A Treatise on the Theory of Bessel Functions_ . Cambridge University Press, Cambridge, 2\nedition, 1944. Reprinted with corrections, various later printings.\n\nG. B. Whitham. _Linear and nonlinear waves_ . Pure and applied mathematics. Wiley-Interscience, New York,\n1999. ISBN 9786613306241.\n\nDaan Wierstra, Tom Schaul, Jan Peters, and J\u00fcrgen Schmidhuber. Natural evolution strategies. pp. 3381\u20133387,\n06 2008. doi: 10.1109/CEC.2008.4631255.\n\nDaan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, and J\u00fcrgen Schmidhuber. Natural evolution\n[strategies, 2011. URL https://arxiv.org/abs/1106.4487.](https://arxiv.org/abs/1106.4487)\n\nC.S. Withers. A simple expression for the multivariate hermite polynomials. _Statistics and Probability Letters_,\n47(2):165\u2013169, 2000. ISSN 0167-7152. doi: https://doi.org/10.1016/S0167-7152(99)00153-4. URL\n[https://www.sciencedirect.com/science/article/pii/S0167715299001534.](https://www.sciencedirect.com/science/article/pii/S0167715299001534)\n\nKe Xue, Chao Qian, Ling Xu, and Xudong Fei. Evolutionary gradient descent for non-convex optimization.\nIn Zhi-Hua Zhou (ed.), _Proceedings of the Thirtieth International Joint Conference on Artificial Intelli-_\n_gence, IJCAI-21_, pp. 3221\u20133227. International Joint Conferences on Artificial Intelligence Organization,\n[8 2021. doi: 10.24963/ijcai.2021/443. URL https://doi.org/10.24963/ijcai.2021/443.](https://doi.org/10.24963/ijcai.2021/443)\nMain Track.\n\nZiming Yu, Pan Zhou, Sike Wang, Jia Li, Mi Tian, and Hua Huang. Zeroth-order fine-tuning of llms in random\nsubspaces. In _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)_, pp.\n4475\u20134485, October 2025.\n\nYihua Zhang, Pingzhi Li, Junyuan Hong, Jiaxiang Li, Yimeng Zhang, Wenqing Zheng, Pin-Yu Chen, Jason D.\nLee, Wotao Yin, Mingyi Hong, Zhangyang Wang, Sijia Liu, and Tianlong Chen. Revisiting zeroth-order\noptimization for memory-efficient llm fine-tuning: A benchmark, 2024.\n\n17\n\n**Appendix**\n\n**A Proofs** **19**\n\nA.1 ES Matrix Gradient Deviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n\nA.2 Error Rate Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n\n**B** **Mean Field Score Function Approximator** **27**\n\nB.1 Bessel Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n\nB.2 Derivation of Mean-field Approximators . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n**C EGG Architecture** **33**\n\nC.1 Notation and Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n\nC.2 Parameter Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n\nC.3 Matrix Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.4 Embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.5 Layer Normalization (LN) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nC.6 MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\nC.7 GRU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\nC.8 Fitness Calculation in Integer Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n**D EGG Pretraining with Integer EGGROLL** **35**\n\nD.1 Adding EGGROLL Perturbations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nD.2 Fitness Shaping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nD.3 Parameter Update . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n**E** **EGG Ablations** **36**\n\nE.1 Data Efficient Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\nE.2 Controlling For Data Across Population Sizes . . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n**F** **EGGROLL Speed**"}, {"role": "assistant", "content": "**Mechanism:** Evolutionary Strategies (ES) typically optimize by sampling perturbations across all model parameters and then aggregating these samples to estimate an update direction. For models with billions of parameters, this involves constructing and manipulating a full-rank covariance matrix for perturbations, which incurs quadratic computational and memory costs relative to the number of parameters. EGGROLL introduces a low-rank decomposition of this search matrix (often to a rank 'r' as small as 1).\n\n**Explanation:** Instead of generating fully independent random changes for every single parameter (which is what a full-rank ES update implicitly does, similar to making a totally new random list of changes for every item in a huge array), EGGROLL restricts the changes to a low-dimensional subspace. Think of it this way: if you have a million-item array to update, a full-rank update means you compute a million new values. With a low-rank update (say, rank `r=1`), you only compute two much smaller vectors, and their outer product defines all million changes. This is like saying, 'Instead of calculating every new item's value, I'll calculate two short 'basis' lists, and combine them to quickly find all the new values.' This drastically reduces the computations (from `N^2` to `N*r` for an `N`-dimensional problem) and memory, because you only need to store and manipulate these 'basis' vectors, not the full `N x N` matrix. Empirically, even a single 'direction' (`r=1`) is often sufficient, implying that the effective search space for large models might be inherently very low-dimensional."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n`UndecidedNeighbors` _is empty_ **then**\n\n**13** Output 1 (join MIS and terminate);\n\nWe now proceed to prove the remaining claims of Theorem 3.2 on this deviation-free execution: namely, correctness (that the output forms a valid MIS), termination (with high probability), and positive inclusion probability (every node has a nonzero chance of joining the MIS).\n\n**Theorem 3.6** (Termination) **.** _Algorithm 2 terminates in O_ (3 [4\u2206] log _n_ ) _rounds with high proba-_\n_bility on graphs with maximum degree_ \u2206 _._\n\n_Proof._ Let _Y_ denote the number of edges removed in a given iteration, and for each edge\n_{i, j} \u2208_ _E_, define _Xij_ to be an indicator variable for the event that _i_ wins with all its neighbors\nand _j_ wins with all its neighbors except for _i_ . Let _di_ and _dj_ be the number of undecided neighbors\nof _i_ and _j_ respectively. As _i_ needs to win a total of _di_ games and _j_ needs to win a total of _dj \u2212_ 1\ngames, we have, Pr[ _Xij_ = 1] = 1 _/_ (3 _[d][i]_ [+] _[d][j]_ _[\u2212]_ [1] )\nWe now relate this to the total number of edges that have been removed. Let _Y_ be the total\nnumber of removed edges, and let both _Yij_ and _Yji_ denote the removal of edge _{i, j}_ . For all\nvertices _i \u2208_ _N_ ( _j_ ) there can only be one node _k_ with _Xkj_ = 1, and if there is such a node _k_, then\n_Yij_ = 1 for all _i \u2208_ _N_ ( _j_ ) (as _k_ will join the MIS and cause _j_ to be delete and hence all edges\n\n13\n\nincident on _j_ will be deleted). Therefore, [\ufffd] _i\u2208N_ ( _j_ ) _[d][j][X][ij][ \u2264]_ [\ufffd] _i\u2208N_ ( _j_ ) _[Y][ij]_ [. Now summing over all]\nthe vertices gives\n\n\ufffd \ufffd _djXij \u2264_ \ufffd \ufffd _Yij_ = _\u21d2_ \ufffd ( _djXij_ + _diXji_ ) _\u2264_ \ufffd 2 _Yij_\n\n\ufffd\n\n\ufffd\n\n\ufffd ( _djXij_ + _diXji_ ) _\u2264_ \ufffd\n\n_ij\u2208E_ _ij\u2208E_\n\n2 _Y_\n\n\ufffd _ij_\n\n_ij\u2208E_\n\n_j\u2208V_\n\n\ufffd _djXij \u2264_ \ufffd\n\n_i\u2208N_ ( _j_ ) _j\u2208V_\n\n_j\u2208V_\n\n\ufffd _Yij_ = _\u21d2_ \ufffd\n\n_i\u2208N_ ( _j_ ) _ij\u2208E_\n\nTaking the expectation on both sides,\n\n=\n\ufffd\n\ufffd _ij\u2208E_\n\n2E[ _Y_ ] _\u2265_ \ufffd\n\n\ufffd ( _dj \u00b7_ E[ _Xij_ ] + _di \u00b7_ E[ _Xji_ ]) _\u2265_ \ufffd\n\n_ij\u2208E_ _ij\u2208E_\n\n_ij\u2208E_\n\n3 _dj_ 3 _di_\n\ufffd 3 _[d][i]_ [+] _[d][j]_ [+] 3 _[d][j]_ [+] _[d][i]_\n\n3( _di_ + _dj_ )\n\n3 _[d][i]_ [+] _[d][j]_\n\nLet \u2206be the maximum degree in the graph. Since _di, dj \u2264_ \u2206and _di_ + _dj \u2265_ 2, we get\n\n3\n\n\ufffd ( _di_ + _dj_ ) _\u2265_ 2 _\u00b7_ 3 [2\u2206] _[\u00b7]_ \ufffd\n\n_ij\u2208E_ _ij\u2208E_\n\nE[ _Y_ ] _\u2265_ [3]\n\n2\n\n\ufffd\n\n_ij\u2208E_\n\n2 = [3] _[|][E][|]_\n\n\ufffd 3 [2\u2206]\n\n_ij\u2208E_\n\n3 [2\u2206]\n\n_di_ + _dj_\n\n+ _dj_ = 3\n\n3 [2\u2206] 2 _\u00b7_ 3 [2\u2206] \ufffd\n\nLet _\u03b1_ = 3 _/_ (2 _\u00b7_ 3 [2\u2206] ). Therefore E[ _Y_ ] _\u2265_ 2 _c|E|_ . Using Lemma A.1, with _d_ = _\u03b1|E|_ and _a_ = _|E|_ :\n\n[]] _[ \u2212]_ _[\u03b1][|][E][|]_ _\u03b1_\nPr ( _Y \u2265_ _\u03b1|E|_ ) _\u2265_ [E][[] _[Y]_\n\n_|E| \u2212_ _\u03b1|E|_ _[\u2265]_ 1 _\u2212_ _\u03b1_ _[\u2265]_ _[\u03b1]_\n\nThus, with probability at least _\u03b1_ = 3 _/_ (2 _\u00b7_ 3 [2\u2206] ), at least an _\u03b1_ -fraction of the edges are\nremoved in a single iteration. Let _E_ _[\u2032]_ be the set of edges remaining after the iteration, we have\n_|E_ _[\u2032]_ _| \u2264_ (1 _\u2212_ _\u03b1_ ) _|E|_ with probability at least _\u03b1_ .\nTo reduce the number of edges from _|E| \u2264_ _n_ [2] to 0, it suffices to have _r_ successful iterations\nof edges reducing by factor of (1 _\u2212_ _\u03b1_ ) such that _n_ [2] _\u00b7_ (1 _\u2212_ _\u03b1_ ) _[r]_ _\u2264_ _n_ [2] _\u00b7 e_ _[\u2212][\u03b1r]_ _<_ 1 which implies\n_r >_ (2 _/\u03b1_ ) ln _n_ . Now we will calculate the number of trials _T_ required to get _r_ successful\niterations with high probability.\nFor each iteration 1 _\u2264_ _t \u2264_ _T_, let _Zt_ be an indicator variable denoting the event that at least\na (1 _\u2212_ _\u03b1_ )-fraction of edges were removed in iteration _t_ . Let _Z_ = [\ufffd] _[T]_ _t_ =1 _[Z][t]_ [ be the total number of]\nsuccessful rounds out of _T_ total rounds. By linearity of expectations, we have E[ _Z_ ] _\u2265_ _\u03b1T_ . Now\nconsider _T_ = (4 _c/\u03b1_ [2] ) log _n_ for some constant _c >_ 0. We have E[ _Z_ ] _\u2265_ (4 _c/\u03b1_ ) log _n_ . Applying the\nChernoff bound A.2 with _\u03b4_ = 1 _/_ 2, we obtain\n\nPr ( _Z \u2264_ (2 _c/\u03b1_ ) log _n_ ) _\u2264_ exp _\u2212_ [4] _[c]_ [ lo][g] _[ n]_\n\ufffd 8 _\u03b1_\n\n_\u226a_ _n_ _[\u2212][c]_\n\ufffd\n\nSo, if we have _T_ trials, we get that whp, more than (2 _c/\u03b1_ ) log _n_ successful iterations, which\nimplies that all edges are removed and the algorithm terminates. Therefore, the algorithm\nterminates in _O_ (3 [4\u2206] log _n_ ) rounds with high probability, which proves the lemma.\n\n**Theorem 3.7** (Correctness) **.** _When all nodes follow Algorithm 2, after termination, the set of_\n_nodes that output_ 1 _forms a valid Maximal Independent Set (MIS) of the network graph, and all_\n_remaining nodes output_ 0 _._\n\n_Proof._ We now prove that the output of Algorithm 2 satisfies both the independence and maximality conditions of a Maximal Independent Set (MIS).\n\n  - _Independence:_ A node _i_ outputs 1 (i.e., joins the MIS) only if it wins the Rock-PaperScissors (RPS) game against all its currently undecided neighbors, given that all its decided\nneighbors have output only 0. In no case, two neighboring nodes _i_ and _j_ both win against\neach other in the same iteration. Therefore, no two adjacent nodes can simultaneously\noutput 1, and once a node outputs 1, its neighbors are required to output 0 in the next\nround, thereby ensuring independence.\n\n14\n\n  - _Maximality:_ A node _i_ outputs 0 only in Round 3 and only if at least one of its neighbors\nhas output 1. Moreover, each node continues participating until it outputs either 0, 1, or\n_\u22a5_ . However, under the assumption that all nodes follow Algorithm 2 honestly, no node\never outputs _\u22a5_ (as no node deviates). Thus, since termination is guaranteed with high\nprobability by Theorem 3.6, every node eventually outputs 1 or 0, and every node that\noutputs 0 must be adjacent to a node in the MIS. Hence, the resulting set is maximal.\n\n**Theorem 3.8** (Positive Probability of MIS Inclusion) **.** _Under Algorithm 2, each node has a_\n_non-zero probability of eventually outputting_ 1 _, i.e., joining the MIS, in every round where none_\n_of its neighbors has output_ 1\n\n_Proof._ In any iteration where a node _i_ is still undecided and none of its neighbors has output 1, it\nplays the RPS game with all of its undecided neighbors. Since the outcome of RPS is uniformly\nrandom, the probability that _i_ wins against any particular neighbor is [1] 3 [. Consequently, the]\n\nprobability that _i_ wins against all of its undecided neighbors and joins the MIS in that iteration\nis \ufffd 13 \ufffd _di_, where _di_ denotes the number of undecided neighbors of _i_ . Thus, as long as none of its\n\nneighbors has output 1, node _i_ always has a strictly positive probability of joining the MIS.\n\n### **4 A Faster Strategy Algorithm using Cryptography**\n\nThe RPS-based algorithm described in the previous section is not very efficient on graphs with\nhigh-degree nodes. The exponential dependence on degree arises because each node plays independent RPS games with its neighbors and can only join the MIS if it wins _all_ of them. To\nimprove the round complexity, we require an algorithm where each node plays a single game\nwith all of its neighbors, under the condition that if a node wins, none of its neighbors can win.\nThe algorithm by M\u00b4etivier et al. [15], can be viewed as such a game: each node generates a\nrandom rank, and a node \u201cwins\u201d if its rank is lower than that of all its neighbors, in which case\nit joins the MIS. However, as discussed in Section 1, this algorithm by itself fails in rational\nsettings because nodes can bias their rank selection to gain an advantage.\nA natural attempt to get around this obstacle is to have each node\u2019s rank also depend on\ninputs from its neighbors. For instance, if rank of node _i_ is computed using randomness from\nboth _i_ and an arbitrarily chosen neighbor _j_, then neither _i_ nor _j_ can fully influence the outcome:\n_i_ prefers a low rank in order to join the MIS, while _j_ prefers _i_ to have a high rank in order to block\nit from joining the MIS. This idea of _two-party shared randomness_ ensures that the ranks will be\n_truly random_ and cannot be changed unilaterally by any single party. To make this verifiable,\nnodes must prove the correctness of their computed rank to others. This requires sharing the\nopponent\u2019s input, which must be authenticated by some means. We perform authentication\nusing digital signatures, which requires standard cryptographic assumptions.\n\n**Additional Assumptions** As mentioned, our approach relies on cryptographic tools; we\nassume that each node _i_ is equipped with a public\u2013private key pair and can sign messages. In\norder to verify the digital signatures, all nodes are assumed to know the identifiers and public\nkeys of every other node in the network. Further, nodes can only broadcast to their neighbors. [3]\n\n3The algorithm can, in principle, be extended to support unicast communication. However, doing so introduces\nseveral corner cases that would require substantially more discussion. One such case arises when a node can avoid\ndetection by selecting multiple opponents simultaneously. Although this strategy does not yield a higher expected\npayoff than choosing a single opponent, we must still account for it, since the algorithm is required to prescribe\nthe best continuation strategy for every possible history.\n\n15\n\n**4.1** **Rationality Resilient Rank-based Strategy Algorithm**\n\nThe algorithm proceeds in _iterations_, where each iteration consists of _five rounds_ . Initially, all\nnodes are in the `undecided` state. Once a node outputs a value in _{_ 0 _,_ 1 _, \u22a5}_, it becomes `decided`,\nmeaning that its output is visible to all neighbors and it takes no further action in subsequent\nrounds. Each node maintains a `BeenCheated` flag, initialized to `false`, and in every iteration,\nthe algorithm proceeds through the following rounds:\n\n  - **Round 1: Opponent Selection.** Each node _i_ selects an arbitrary undecided neighbor\nas its _opponent_, denoted by opp(i), and broadcasts this choice to all neighbors.\n\n  - **Round 2 (Randomness Generation and Exchange).** Each node _i_ generates a _c_ log _n_\nlength bit string _ri\u2192i \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly at random and broadcasts it to all neighbors,\nwhere _c >_ 0 is a fixed constant. For each neighbor _j_ who selected _i_ as an opponent in\nRound 1, node _i_ generates a separate _c_ log _n_ length bit string _ri\u2192j \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly\nat random, signs it along with the current iteration counter, and broadcasts each signed\n\nmessage.\n\n  - **Round 3: Share Randomness of Opponent** Each node _i_ that broadcast opp( _i_ ) in\nRound 1 and received _r_ opp( _i_ ) _\u2192i_ computes its rank as _Ri_ = _ri\u2192i \u2295_ _r_ opp( _i_ ) _\u2192i_, and then\nbroadcasts the signed message it received from opp( _i_ ) to all its neighbors.\n\n  - **Round 4: Calculate Ranks of Neighbors.** Each node _i_, for each of its neighbors\n_j_, after receiving a valid signed _r_ opp( _j_ ) _\u2192j_ in the previous round, computes the rank\n_Rj_ = _rj\u2192j \u2295_ _r_ opp( _j_ ) _\u2192j_ . If any undecided neighbor _j_ did not broadcast some message\nin the previous 3 rounds as expected, then _i_ assumes _j_ \u2019s rank to be _{_ 1 _}_ _[c]_ [ log] _[ n]_ and sets\nits `BeenCheated` flag to `true`, since such nodes are considered to have deviated from the\nalgorithm. Similarly, if _i_ deviated in a manner that can be detected by some of its neighbors(this includes the case where _i_ fails to broadcast _r_ opp( _i_ ) _\u2192i_ because it did not receive\nit from opp( _i_ )), then it sets its own rank to _{_ 1 _}_ _[c]_ [ log] _[ n]_ in order to stay consistent with\nneighbors that detect _i_ \u2019s deviation, and avoid a potential _\u2212\u221e_ payoff.\n\nNext, node _i_ checks whether any neighbor has already output 1 or _\u22a5_ in the current\niteration; if so, it outputs _\u22a5_ in every subsequent round in which it remains `Undecided` . .\nOtherwise, it compares its rank with all its undecided neighbors. If _Ri < Rj_ for all such\nneighbors _j_, then node _i_ outputs 1, joining the MIS and terminates.\n\n  - **Round 5: Reacting to Neighbor Decisions.** Each node _i_ checks whether any undecided neighbor _j_ has output _\u22a5_ . If such a node exists, _i_ outputs _\u22a5_ in every subsequent\nround in which it remains `Undecided` .\n\nElse, if any neighbor _j_ has output 1 in previous round, then:\n\n**\u2013** If, for all such _j_ with output 1, it holds that _Rj < Ri_, then node _i_ outputs 0 in every\nsubsequent round while it remains undecided, unless `BeenCheated` is `true`, in which\ncase it outputs _\u22a5_ in every subsequent round while it remains undecided..\n\n**\u2013** Otherwise, if there exists a node _j_ with _Rj > Ri_ that still outputs 1, then _i_ outputs\n_\u22a5_ in every subsequent round while it remains undecided.\n\nIf there are no `Undecided` neighbors, _i_ outputs 1. otherwise, _i_ proceeds to next iteration.\n\nThe distributed strategy algorithm described above is formalized in Algorithm 3. Since the\ndescription is quite lengthy, we have modularized it into several algorithms, each describing\none round of the iteration, presented in Algorithms 4 \u2013 8. We then proceed to prove the main\ntheorem, Theorem 4.1, which demonstrates that the proposed algorithm is rationality resilient.\n\n**Theorem 4.1.** _Algorithm 3 is a Rationality Resilient Algorithm as defined in Definition 2.10._\n\n16\n\n**Algorithm 3:** Rank based MIS algorithm for Node _i_\n\n**1 Initialization**\n\n**2** `UndecidedNeighbors` _\u2190_ _N_ ( _i_ ); `BeenCheated` _\u2190_ false; `iteration` `number` _\u2190_ 0\n\n**3 if** _N_ ( _i_ ) = _\u2205_ **then**\n\n**4** In every round where node _i_ is still Undecided, Output 1\n\n**5 while** _i is_ Undecided **do**\n\n**6** `iteration` ~~`n`~~ `umber` _\u2190_ `iteration` `number` +1;\n```\n   // --- Round 1 --```\n\n**7** Run Algorithm Opponent Selection (Algorithm 4) ;\n```\n   // --- Round 2 --```\n\n**8** Run Algorithm Generate Randomness (Algorithm 5);\n```\n   // --- Round 3 --```\n\n**9** Run Algorithm Forward Opponent\u2019s random input (Algorithm 6);\n```\n   // --- Round 4 --```\n\n**10** Run Algorithm Calculate Ranks of Neighbors (Algorithm 7);\n```\n   // --- Round 5 --```\n\n**11** Run Algorithm Reacting to Neighbor Decisions (Algorithm 8);\n\n**Algorithm 4:** Opponent Selection\n\n**1** Choose any _k \u2208_ `UndecidedNeighbors` as the opponent opp( _i_ ), and broadcast this\nchoice to all neighbors.\n\n**Algorithm 5:** Generate Randomness\n\n**1 if** _i did not broadcast a valid ID in Round 1_ **then**\n\n**2** _Ri \u2190{_ 1 _}_ _[c]_ [ log] _[ n]_ ;\n`// Node` _i_ `deviated; as neighbors assume its rank is` _{_ 1 _}_ _[c]_ [ log] _[ n]_ `,` _i_ `also`\n`adopts this to stay consistent and avoid` _\u2212\u221e_ `payoff.`\n\n**3** Draw _c_ log _n_ bits _ri\u2192i \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly at random and broadcast to all the\nneighbors;"}, {"role": "assistant", "content": "**Mechanism:** The first algorithm's termination relies on an expected exponential reduction in active 'edges' (connections) per iteration. When a node successfully joins the MIS, it and its immediate neighbors are removed from the undecided pool, effectively 'deleting' all incident edges from further consideration. The second algorithm achieves rationality-resilience and faster performance through cryptographically-secured shared randomness for rank generation. Ranks are computed as `Ri = ri->i XOR ropp(i)->i`, where both `ri->i` and `ropp(i)->i` are random strings contributed by node `i` and its chosen opponent `opp(i)`, respectively, with `ropp(i)->i` being cryptographically signed to prevent manipulation. This 'two-party shared secret' makes the rank unpredictable by either party alone, enforcing fairness in the 'lowest rank wins' mechanism.\n\n**Explanation:** The first algorithm guarantees completion because it's like a `while` loop that keeps running as long as there are 'undecided' connections (edges) in the network. Each time the loop iterates, there's a high probability that a significant *fraction* of these undecided connections will be eliminated. This isn't just a fixed number of connections, but a percentage, which means the total number of connections shrinks exponentially fast, similar to repeatedly halving a value until it reaches zero. The math shows that this fractional reduction is consistent enough, with high probability, to ensure the algorithm eventually halts. The second algorithm tackles the speed bottleneck by moving from many small, independent contests to a single 'lowest rank wins' competition per iteration. To prevent nodes from simply picking the lowest rank and cheating, it uses a clever trick. Each node combines its own secret random number with a secret random number received and cryptographically 'signed' (like a tamper-proof digital stamp) from a chosen neighbor using an XOR operation. The XOR operation is key: since it mixes two independent random inputs, neither node can unilaterally force the final rank to be low. This ensures the generated ranks are truly random and unbiased, even if nodes are trying to cheat. Digital signatures act like immutable records, allowing other neighbors to verify that the rank computation was performed honestly. If a node fails to provide a signed random number or deviates, its rank is automatically set to a very high value (effectively 'losing' the round), creating a strong disincentive for dishonesty."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5e_ \u2265 2 \u00d7 _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] **then** /* cwnd backoff once queuing delay exceeds threshold */\n\n**23** _\ud835\udc4f\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc5c\ud835\udc53\ud835\udc53_ _ _\ud835\udc53\ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc5c\ud835\udc5f_ \u2190 0 _._ 5 \u00d7 _\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ [ _\ud835\udc5f_ ]/ _\ud835\udc5f\ud835\udc61\ud835\udc61_\n\n**24** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u00d7 _\ud835\udc4f\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc5c\ud835\udc53\ud835\udc53_ _ _\ud835\udc53\ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc5c\ud835\udc5f_\n\n**25** _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 0\n\n**26** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u2190 max{2 _,\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ]} // lower bound\n\n**Adjust_Weights():**\n\n**27** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ \u2190 [\ufffd] _\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ ;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism is a reactive feedback loop for network congestion control. It monitors a 'queue_delay' metric. If this delay for a given data stream (denoted 'r') exceeds a threshold (twice its historical baseline), it signals congestion. The system then reduces the transmission rate by shrinking the 'congestion window' ('cwnd') for that stream. The degree of reduction is proportional to how much the current 'round-trip time' ('rtt') has increased relative to a 'baseRTT', ensuring a stronger reduction for more severe congestion.\n\n**Explanation:** At its core, this code acts like a dynamic traffic controller for data packets. Each data stream 'r' has a 'congestion window' (`cwnd[r]`) which dictates how many packets it can send without waiting for acknowledgements. Think of `cwnd` as the number of cars allowed on the road at once for a specific driver. The system constantly checks `queue_delays[r]`, which is analogous to how long cars are waiting at a bottleneck. If this wait time `q` gets too high (specifically, more than double a baseline `queue_delays[r]`), it assumes the network is congested for that stream. It then calculates a `backoff_factor` using `baseRTT` (the 'normal' travel time) and `rtt` (the 'current' travel time). If `rtt` is much larger than `baseRTT`, it means data is taking much longer, indicating severe congestion, leading to a small `backoff_factor` and a significant reduction in `cwnd[r]`. This is like telling that driver to send fewer cars. The `queue_delays[r]` is then reset, clearing the slate for future measurements. A minimum `cwnd` of 2 is enforced, like ensuring at least two cars can always try to move, preventing total stoppage."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5f_ \u2208 _\ud835\udc45\ud835\udc60_ **do**\n\n**5** _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ [ _\ud835\udc5f_ ] \u2190 2 ;\n\n**6** _\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 0 ;\n\n**7** _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 0 ;\n\n**On the end of round for subflow** _\ud835\udc5f_ **:**\n\n/* average RTT estimated in the last round - used instead of smoothed RTT for faster\n\nreaction to congestion */\n\n**8** _\ud835\udc5f\ud835\udc61\ud835\udc61_ \u2190 _\ud835\udc60\ud835\udc4e\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc51_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc60_ [ _\ud835\udc5f_ ]/ _\ud835\udc60\ud835\udc4e\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc51_ _ _\ud835\udc5b\ud835\udc62\ud835\udc5a_ [ _\ud835\udc5f_ ] ;\n\n**9** _\ud835\udc51\ud835\udc56\ud835\udc53\ud835\udc53_ \u2190 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [ _\ud835\udc5f_ ] \u00d7 ( _\ud835\udc5f\ud835\udc61\ud835\udc61_ \u2212 _\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ [ _\ud835\udc5f_ ])/ _\ud835\udc5f\ud835\udc61\ud835\udc61_ ;\n\n/* tweak weights and alphas */"}, {"role": "assistant", "content": "**Mechanism:** This code segment initializes per-subflow state variables and then, at the end of each round, calculates a real-time average Round Trip Time (RTT) and a congestion indicator. The mechanism explicitly avoids RTT smoothing for faster reaction. The congestion indicator ('diff') is derived by measuring the relative RTT increase over a baseline and scaling it by the current congestion window.\n\n**Explanation:** Think of this as a network managing multiple independent data streams, or 'subflows', each like a separate logical channel. Lines 5-7 are analogous to initializing registers or variables for each channel in a hash map, setting initial control parameters. At the end of a transmission round for a specific channel, line 8 rapidly calculates the average RTT for that round. It uses a direct average (sum of sampled RTTs divided by number of samples) rather than a smoothed average (like an Exponentially Weighted Moving Average) to ensure immediate feedback on current network conditions. This is like sampling sensor data frequently to react instantly. Line 9 then calculates 'diff', which is a crucial feedback signal. It essentially quantifies the extra delay caused by network queuing ('rtt - baseRTT') and scales this delay by the current data volume in transit ('cwnd'). This multiplication amplifies the signal when a large amount of data is experiencing increased delay, giving a clear, proportional measure of congestion that directly informs subsequent adjustments to flow control parameters."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this work, we study the problem of approximating Kemeny constant problem for both static and dynamic graphs. We propose two\nnovel formulas of Kemeny constant and design an biased estimator\nbased on spanning trees and 2-forests. For static graphs, we develop\na sampling-based algorithm with stronger theoretical guarantees.\nThe proposed method outperforms SOTA approaches in both efficiency and accuracy on real-world datasets. For dynamic graphs,\nwe introduce two sample maintenance strategies that efficiently\npreserve the correctness of samples instead of recomputing from\nscratch for each update. Both two methods are faster than static\nalgorithms, with only a slight loss in precision. Extensive experiments on real-world graphs demonstrate the effectiveness and\nefficiency of our solutions.\n\n**REFERENCES**\n\n[1] William Aiello, Fan Chung, and Linyuan Lu. 2001. A random graph model for\npower law graphs. _Experimental mathematics_ 10, 1 (2001), 53\u201366.\n\n[2] Diego Altafini, Dario A Bini, Valerio Cutini, Beatrice Meini, and Federico Poloni.\n2023. An edge centrality measure based on the Kemeny constant. _SIAM J. Matrix_\n_Anal. Appl._ 44, 2 (2023), 648\u2013669.\n\n[3] Reid Andersen, Fan Chung, and Kevin Lang. 2006. Local graph partitioning using\npagerank vectors. In _FOCS_ . IEEE, 475\u2013486.\n\n[4] Eugenio Angriman, Maria Predari, Alexander van der Grinten, and Henning\nMeyerhenke. 2020. Approximation of the Diagonal of a Laplacian\u2019s Pseudoinverse\nfor Complex Network Analysis. _ESA_ 173 (2020), 6:1\u20136:24.\n\n[5] Luca Avena, Fabienne Castell, Alexandre Gaudilli\u00e8re, and Clothilde M\u00e9lot. 2018.\nRandom forests and networks analysis. _Journal of Statistical Physics_ 173 (2018),\n985\u20131027.\n\n[6] Bahman Bahmani, Abdur Chowdhury, and Ashish Goel. 2010. Fast Incremental\nand Personalized PageRank. _VLDB_ 4, 3 (2010), 173\u2013184.\n\n[7] B\u00e9la Bollob\u00e1s. 2013. _Modern graph theory_ . Vol. 184. Springer Science & Business\nMedia.\n\n[8] B\u00e9la Bollob\u00e1s and B\u00e9la Bollob\u00e1s. 1998. _Random graphs_ . Springer.\n\n[9] Mo Chen, Jianzhuang Liu, and Xiaoou Tang. 2008. Clustering via Random Walk\nHitting Time on Directed Graphs. In _AAAI_, Vol. 8. 616\u2013621.\n\n[10] Fan Chung and Ji Zeng. 2023. Forest formulas of discrete Green\u2019s functions. _J._\n_Graph Theory_ 102, 3 (2023), 556\u2013577.\n\n[11] S Condamin, O B\u00e9nichou, V Tejedor, R Voituriez, and Joseph Klafter. 2007. Firstpassage times in complex scale-invariant media. _Nature_ 450, 7166 (2007), 77\u201380.\n\n[12] Emanuele Crisostomi, Stephen Kirkland, and Robert Shorten. 2011. A Google-like\nmodel of road network dynamics and its application to regulation and control.\n_Internat. J. Control_ 84, 3 (2011), 633\u2013651.\n\n[13] Peter G Doyle. 2009. The Kemeny constant of a Markov chain. _arXiv preprint_\n_arXiv:0909.2636_ (2009).\n\n[14] Peter M. Fenwick. 1994. A New Data Structure for Cumulative Frequency Tables.\n_Softw. Pract. Exp._ 24, 3 (1994), 327\u2013336.\n\n[15] Julie Fournet and Alain Barrat. 2014. Contact Patterns among High School\nStudents. _PLoS ONE_ [9, 9 (09 2014), e107878. https://doi.org/10.1371/journal.pone.](https://doi.org/10.1371/journal.pone.0107878)\n[0107878](https://doi.org/10.1371/journal.pone.0107878)\n\n[16] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for\nnetworks. In _KDD_ . 855\u2013864.\n\n[17] Takanori Hayashi, Takuya Akiba, and Yuichi Yoshida. 2016. Efficient Algorithms\nfor Spanning Tree Centrality. In _IJCAI_, Vol. 16. 3733\u20133739.\n\n[18] Wassily Hoeffding. 1994. Probability inequalities for sums of bounded random\nvariables. _The collected works of Wassily Hoeffding_ (1994), 409\u2013426.\n\n[19] Guanhao Hou, Qintian Guo, Fangyuan Zhang, Sibo Wang, and Zhewei Wei. 2023.\nPersonalized PageRank on evolving graphs with an incremental index-update\nscheme. _SIGMOD_ 1, 1 (2023), 1\u201326.\n\n[20] Jeffrey J Hunter. 2014. The role of Kemeny\u2019s constant in properties of Markov\nchains. _Communications in Statistics-Theory and Methods_ 43, 7 (2014), 1309\u20131321.\n\n[21] Michael F Hutchinson. 1989. A stochastic estimator of the trace of the influence\nmatrix for Laplacian smoothing splines. _Communications in Statistics-Simulation_\n_and Computation_ 18, 3 (1989), 1059\u20131076.\n\n[22] John G Kemeny, J Laurie Snell, et al. 1969. _Finite markov chains_ . Vol. 26. van\nNostrand Princeton, NJ.\n\n[23] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network\n[Dataset Collection. http://snap.stanford.edu/data.](http://snap.stanford.edu/data)\n\n[24] Mark Levene and George Loizou. 2002. Kemeny\u2019s constant and the random\nsurfer. _The American mathematical monthly_ 109, 8 (2002), 741\u2013745.\n\n[25] Shiju Li, Xin Huang, and Chul-Ho Lee. 2021. An efficient and scalable algorithm\nfor estimating Kemeny\u2019s constant of a Markov chain on large graphs. In _KDD_ .\n964\u2013974.\n\n[26] Zihao Li, Dongqi Fu, and Jingrui He. 2023. Everything evolves in personalized\npagerank. In _WWW_ . 3342\u20133352.\n\n[27] Meihao Liao, Rong-Hua Li, Qiangqiang Dai, Hongyang Chen, Hongchao Qin,\nand Guoren Wang. 2023. Efficient personalized pagerank computation: The\npower of variance-reduced monte carlo approaches. _SIGMOD_ 1, 2 (2023), 1\u201326.\n\n[28] Meihao Liao, Rong-Hua Li, Qiangqiang Dai, Hongyang Chen, Hongchao Qin,\nand Guoren Wang. 2023. Efficient resistance distance computation: The power\nof landmark-based approaches. _SIGMOD_ 1, 1 (2023), 1\u201327.\n\n[29] Meihao Liao, Rong-Hua Li, Qiangqiang Dai, Hongyang Chen, and Guoren Wang.\n2023. Scalable Algorithms for Laplacian Pseudo-inverse Computation. _arXiv_\n_preprint arXiv:2311.10290_ (2023).\n\n[30] Meihao Liao, Rong-Hua Li, Qiangqiang Dai, and Guoren Wang. 2022. Efficient\npersonalized pagerank computation: A spanning forests sampling based approach. In _SIGMOD_ . 2048\u20132061.\n\n[31] Meihao Liao, Junjie Zhou, Rong-Hua Li, Qiangqiang Dai, Hongyang Chen, and\nGuoren Wang. 2024. Efficient and Provable Effective Resistance Computation on\nLarge Graphs: An Index-based Approach. _SIGMOD_ 2, 3 (2024), 1\u201327.\n\n[32] Haoyu Liu and Siqiang Luo. 2024. BIRD: Efficient Approximation of Bidirectional\nHidden Personalized PageRank. _VLDB_ 17, 9 (2024), 2255\u20132268.\n\n[33] L\u00e1szl\u00f3 Lov\u00e1sz. 1993. Random walks on graphs. _Combinatorics, Paul erdos is_\n_eighty_ 2, 1-46 (1993), 4.\n\n[34] Sam Alexander Martino, Jo\u00e3o Morado, Chenghao Li, Zhenghao Lu, and Edina\nRosta. 2024. Kemeny Constant-Based Optimization of Network Clustering Using\nGraph Neural Networks. _The Journal of Physical Chemistry B_ 128, 34 (2024),\n8103\u20138115.\n\n[35] Dingheng Mo and Siqiang Luo. 2021. Agenda: Robust personalized pageranks in\nevolving graphs. In _CIKM_ . 1315\u20131324.\n\n[36] Naoto Ohsaka, Takanori Maehara, and Ken-ichi Kawarabayashi. 2015. Efficient\npagerank tracking in evolving networks. In _KDD_ . 875\u2013884.\n\n[37] Rushabh Patel, Pushkarini Agharkar, and Francesco Bullo. 2015. Robotic surveillance and Markov chains with minimal weighted Kemeny constant. _IEEE Trans._\n_Automat. Control_ 60, 12 (2015), 3156\u20133167.\n\n[38] Bibek Paudel and Abraham Bernstein. 2021. Random walks with erasure: Diversifying personalized recommendations on social and information networks. In\n_WWW_ . 2046\u20132057.\n\n[39] Pan Peng, Daniel Lopatta, Yuichi Yoshida, and Gramoz Goranci. 2021. Local\nalgorithms for estimating effective resistance. In _KDD_ . 1329\u20131338.\n\n[40] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning\nof social representations. In _KDD_ . 701\u2013710.\n\n[41] Maria Predari, Lukas Berner, Robert Kooij, and Henning Meyerhenke. 2023.\nGreedy optimization of resistance-based graph robustness with global and local\nedge insertions. _Soc. Netw. Anal. Min._ 13, 1 (2023), 130.\n\n[42] Ryan A. Rossi and Nesreen K. Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization. In _AAAI_ . [https:](https://networkrepository.com)\n[//networkrepository.com](https://networkrepository.com)\n\n[43] Purnamrita Sarkar and Andrew W Moore. 2011. Random walks in social networks\nand their applications: a survey. _Social Network Data Analytics_ (2011), 43\u201377.\n\n[44] Christian L. Staudt, Aleksejs Sazonovs, and Henning Meyerhenke. 2015.\nNetworKit: A Tool Suite for Large-scale Complex Network Analysis.\n[arXiv:1403.3005 [cs.SI] https://arxiv.org/abs/1403.3005](https://arxiv.org/abs/1403.3005)\n\n[45] Prasad Tetali. 1991. Random walks and the effective resistance of networks.\n_Journal of Theoretical Probability_ 4, 1 (1991), 101\u2013109.\n\n[46] Hanzhi Wang, Zhewei Wei, Junhao Gan, Ye Yuan, Xiaoyong Du, and Ji-Rong\nWen. 2022. Edge-based local push for personalized PageRank. _VLDB_ 15, 7 (2022),\n1376\u20131389.\n\n[47] Scott White and Padhraic Smyth. 2003. Algorithms for estimating relative\nimportance in networks. In _KDD_ . 266\u2013275.\n\n[48] David Bruce Wilson. 1996. Generating random spanning trees more quickly\nthan the cover time. In _STOC_ . 296\u2013303.\n\n[49] Feng Xia, Haifeng Liu, Ivan Lee, and Longbing Cao. 2016. Scientific article\nrecommendation: Exploiting common author relations and historical preferences.\n_IEEE Trans. Big Data_ 2, 2 (2016), 101\u2013112.\n\n[50] Feng Xia, Jiaying Liu, Hansong Nie, Yonghao Fu, Liangtian Wan, and Xiangjie\nKong. 2019. Random walks: A review of algorithms and applications. _IEEE_\n_Transactions on Emerging Topics in Computational Intelligence_ 4, 2 (2019), 95\u2013\n107.\n\n[51] Haisong Xia and Zhongzhi Zhang. 2024. Efficient Approximation of Kemeny\u2019s\nConstant for Large Graphs. _SIGMOD_ 2, 3 (2024), 1\u201326.\n\n[52] Wanyue Xu, Yibin Sheng, Zuobai Zhang, Haibin Kan, and Zhongzhi Zhang. 2020.\nPower-law graphs have minimal scaling of Kemeny constant for random walks.\nIn _WWW_ . 46\u201356.\n\n[53] Mingji Yang, Hanzhi Wang, Zhewei Wei, Sibo Wang, and Ji-Rong Wen. 2024.\nEfficient algorithms for personalized pagerank computation: A survey. _IEEE_\n_TKDE_ (2024).\n\n[54] Renchi Yang, Jieming Shi, Xiaokui Xiao, Yin Yang, and Sourav S Bhowmick.\n2020. Homogeneous Network Embedding for Massive Graphs via Reweighted\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\nPersonalized PageRank. _VLDB_ 13, 5 (2020), 670\u2013683.\n\n[55] Renchi Yang and Jing Tang. 2023. Efficient estimation of pairwise effective\nresistance. _Proceedings of the ACM on Management of Data_ 1, 1 (2023), 1\u201327.\n\n[56] Serife Yilmaz, Ekaterina Dudkina, Michelangelo Bin, Emanuele Crisostomi,\nPietro Ferraro, Roderick Murray-Smith, Thomas Parisini, Lewi Stone, and Robert\nShorten. 2020. Kemeny-based testing for COVID-19. _PLOS ONE_ 15, 11 (2020),\n1\u201319.\n\n[57] Hongzhi Yin, Bin Cui, Jing Li, Junjie Yao, and Chen Chen. 2012. Challenging the\nLong Tail Recommendation. _VLDB_ 5, 9 (2012).\n\n[58] Minji Yoon, Woojeong Jin, and U Kang. 2018. Fast and accurate random walk\nwith restart on dynamic graphs with guarantees. In _WWW_ . 409\u2013418.\n\n[59] Hongyang Zhang, Peter Lofgren, and Ashish Goel. 2016. Approximate personalized pagerank on dynamic graphs. In _KDD_ . 1315\u20131324.\n\n[60] Xiaohan Zhao, Adelbert Chang, Atish Das Sarma, Haitao Zheng, and Ben Y\nZhao. 2013. On the embeddability of random walk distances. _VLDB_ 6, 14 (2013),\n1690\u20131701.\n\n[61] Yanping Zheng, Hanzhi Wang, Zhewei Wei, Jiajun Liu, and Sibo Wang. 2022.\nInstant graph neural networks for dynamic graphs. In _KDD_ . 2605\u20132615."}, {"role": "assistant", "content": "**Mechanism:** The Kemeny constant measures the average number of steps for a random walk to reach any node from any other node, fundamentally reflecting a graph's connectivity and mixing time. The 'novel formulas' likely exploit structural properties of the graph (e.g., spectral properties or decomposition into simpler components) to express the Kemeny constant in a form more amenable to approximation. The 'biased estimator' utilizes spanning trees and 2-forests, which are foundational graph structures related to connectivity and path enumeration. By sampling these structures, the approach approximates the complex sum involved in the Kemeny constant calculation, trading exactness for computational tractability. This works by leveraging the fact that these sampled structures, despite being 'biased', still capture enough of the graph's global connectivity to provide a good estimate. For dynamic graphs, the 'sample maintenance strategies' are essentially incremental update mechanisms. Instead of re-running the entire sampling or estimation process (analogous to rebuilding a hash table from scratch), they identify how local graph changes (edge additions/deletions) affect the existing samples or computed quantities, and then efficiently update only those affected parts, much like updating a linked list pointer instead of re-copying the whole list.\n\n**Explanation:** At its core, the problem is computing an expectation over many random walks, which is computationally expensive for large graphs. The proposed solution tackles this by finding new mathematical representations (the 'novel formulas') that might simplify the structure of the computation. Then, it uses a sampling technique where instead of looking at all possible paths, it strategically samples specific graph substructures (spanning trees and 2-forests) that are known to encapsulate critical connectivity information. This reduces the problem from enumerating exponentially many paths to working with a manageable set of sampled structures. The 'biased' nature implies that while each sample might not be a perfect representation, the aggregation of samples still provides a statistically robust approximation. For graphs that evolve, recomputing everything is like re-downloading an entire dataset for a single byte change. The maintenance strategies function as an intelligent cache invalidation and update system, leveraging the fact that most of the graph remains unchanged, allowing for very fast updates by only recalculating what's absolutely necessary."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nOur proposed cognitive foundations taxonomy enables systematic characterization of reasoning processes,\nallowing us to answer questions like _which cognitive elements appear in models?_, _how behaviors unfold during_\n_reasoning?_ and _which behavioral patterns correlate with success?_ Overall, our analyses expose fundamental\ngaps: we cannot know which training produces which cognitive capabilities a priori, cannot ensure behaviors\ntransfer beyond training distributions, and cannot validate whether observed patterns reflect genuine cognitive mechanisms or spurious reasoning shortcuts. The cognitively inspired test-time reasoning guidance\ndemonstrates that this understanding is actionable, in which successful behavioral patterns can be elicited\nto improve performance on ill-structured problems (Table 4). However, even in this case, it remains unclear whether our guidance enables genuine deployment of latent capabilities or simply helps models retrieve\ncached reasoning patterns from training data.\n\n**Cognitive science research provides principled frameworks for diagnosing gaps in current sys-**\n**tems and designing interventions to address them.** We posit that decades of research on problemsolving, mental representation, and meta-cognition offer concrete guidance for technical development of\nLLMs. The following challenges illustrate how cognitive theories illuminate current limitations and suggest\nspecific research directions.\n\n**Predicting cognitive capabilities from training procedure.** Current training paradigms lack predictive theories connecting procedures to emergent reasoning capabilities. Meta-cognitive monitoring correlates\nstrongly with success on ill-structured problems (Figure 4), yet appears in only 8% of reasoning traces and\n8% of papers (Figure 2). Our comparison across 16 models shows dramatic variation in response to cognitive\nscaffolding (Table 4), but we cannot predict these differences from architecture or training details. Post-hoc\nanalyses reveal that RL induces verification (Gandhi et al., 2025; Snell et al., 2024) but not representational\nrestructuring or meta-cognitive monitoring, while process supervision (Lightman et al., 2023; Uesato et al.,\n2022) and chain-of-thought prompting (Wei et al., 2022b; Kojima et al., 2023; Wang et al., 2022; Yao et al.,\n2023) elicit latent but not spontaneous behaviors. We cannot explain why RL produces verification but not\nmeta-cognitive monitoring, or whether architectural prerequisites exist for specific behaviors versus emerging\nfrom scale (Le et al., 2025; Das et al., 2025).\n\nCognitive science provides explanatory frameworks. Research on skill acquisition shows different capabilities\nemerge under different learning conditions (Flavell, 1979; Nelson, 1990). Procedural skills like verification\nemerge from repeated task performance, while meta-cognitive monitoring requires explicit reflection on\nreasoning processes (Nelson, 1990). Domain-specific strategies require rich within-domain examples, while\ntransferable schemas require diverse, structurally varied training (Gentner, 1983).\n\nThese principles enable predictive theories of capability emergence. If procedural behaviors emerge from\nrepetition while meta-cognitive behaviors require reflection, we can predict which training paradigms will\nproduce which capabilities before running experiments. If transferable reasoning requires structural variation\nacross surface features, we can predict that training on homogeneous problem distributions will fail to produce\nrobust generalization. Our taxonomy provides measurement infrastructure for testing these predictions;\ncognitive theories provide the explanatory framework linking training characteristics to behavioral outcomes.\nThis enables shifting from post-hoc observation to theory-driven experimentation.\n\n**The generalization challenge.** Reasoning behaviors fail to transfer beyond training distributions. Models achieve 80% on story problems but 46% on design problems (Figure 3b). They rely on shallow forward\nchaining that fails when problems demand hierarchical planning and representational restructuring. Our\ntest-time reasoning guidance improves performance through automatically constructed cognitive structure\ntemplates contextualized to each problem type. However, it still requires prior knowledge of a diverse distribution of patterns and their success outcomes. This brittleness reflects a fundamental finding from cognitive\nscience: transfer depends on abstract schema formation. Human reasoning transfers through schemas that\n\n22\n\ncapture structural commonalities across surface-different problems (Gentner, 1983; Gick & Holyoak, 1980).\nThis requires representing problems at multiple levels of abstraction, recognizing when novel situations\ninstantiate known structures, and flexibly adapting strategies (Holyoak & Thagard, 1997). Children develop transferable mathematical understanding through varied examples that highlight structural principles\n(Rittle-Johnson et al., 2001). Adults spontaneously recognize deep structural similarity despite surface differences (Novick & Hmelo, 1994). Crucially, transfer fails when learners encode only surface features without\nextracting underlying structure (Gick & Holyoak, 1980).\n\nLLMs exhibit precisely the failure modes predicted by cognitive theory by succeeding in-distribution but\nfail on superficial variants (McCoy et al., 2019; Berglund et al., 2023; Shi et al., 2022; Shao et al., 2025;\nLi et al., 2025b). If models only deploy desired behaviors under explicit prompting, they may be applying\ncached patterns rather than reasoning about which strategy the problem demandas which is exactly the\nbehavior embodied by surface-level learning without schema abstraction in humans. Applying principles\nof schema-based transfer to training offers a potential technical solution. Cognitive research demonstrates\nthat transfer improves when: (1) training highlights structural similarities across diverse surface forms,\n(2) learners explicitly compare and contrast examples to extract common structure, (3) training includes\nprompts to reflect on _why_ a strategy worked (Gentner, 1983; Gick & Holyoak, 1980). For models, this\nsuggests training procedures that explicitly encourage structural comparison across problem types, reward\nstrategy selection based on problem structure rather than surface features, and potentially use contrastive\nlearning to distinguish structural from surface similarity. Our framework enables measuring whether these\ninterventions produce genuine transferable understanding (flexible behavioral deployment across problem\ntypes) or spurious reasoning shortcuts (rigid strategies that succeed only in-distribution).\n\n**From observable behavior to underlying processes.** Our framework identifies observable behavioral\npatterns, but the same surface behavior can arise from fundamentally different underlying processes (Chomsky, 2014). Our human-LLM comparison illustrates this: both reach correct answers, yet humans employ\nhierarchical nesting and meta-cognitive loops while models use shallow sequential chaining (Figure **??** ). Recent work shows models produce correct reasoning chains while internally representing different processes\n(Turpin et al., 2023) and that chain-of-thought may be post-hoc rationalization (Lanham et al., 2023). These\nalternatives produce similar outputs but fundamentally different robustness and generalization.\n\nCognitive science research on reasoning invariants provides principled validation criteria. Genuine cognitive\ncapabilities exhibit systematic transfer to structurally similar but surface-different contexts, robustness to\nperturbation in irrelevant dimensions, compositional deployment across tasks, and internal consistency when\ncombined with other capabilities (Fodor & Pylyshyn, 1988; Gentner, 1983). These are functional properties\nrequiring testing under manipulation, not mere behavioral observation.\n\nDeveloping validation frameworks that test these signatures requires moving beyond \"does behavior X appear?\" to \"does X transfer systematically, remain robust to perturbation, and compose flexibly?\" This demands systematic probing studies measuring transfer and robustness (Belinkov, 2022), causal interventions\nmanipulating specific capabilities while measuring downstream effects, and mechanistic interpretability connecting internal representations to behavioral function (Elhage et al., 2021; Nanda et al., 2023). Our taxonomy identifies which behaviors to validate; cognitive theories specify what properties distinguish genuine\ncapabilities from spurious shortcuts.\n\n**Expanding behavioral coverage and diversity.** Our analysis of 1,598 LLM reasoning papers (Figure 2)\nreveals concentration on easily quantifiable behaviors: sequential organization and decomposition dominate\n(55%, 60%) while meta-cognitive controls receive minimal attention (self-awareness: 16%, evaluation: 8%).\nYet our empirical findings show diverse behavioral repertoires correlate with success on ill-structured problems where rigid strategies fail (Figure 4), consistent with cognitive science findings that meta-cognitive\nmonitoring enables error detection (Nelson, 1990), representational flexibility predicts success on complex\nproblems (Ohlsson, 1992), and sophisticated operations distinguish experts from novices (Chi et al., 1981).\n\nCurrent RL training faces a fundamental reward specification problem: outcome-based rewards (Lambert\net al., 2024) provide sparse, terminal signals that fail to incentivize intermediate reasoning behaviors predicting success (Li et al., 2025b). Process reward models (Lightman et al., 2023; Uesato et al., 2022) reward\n\n23\n\nintermediate correctness but still optimize for accuracy rather than behavioral diversity enabling transfer.\nMoreover, RL exploration typically relies on distributions learned from pretraining and midtraining that may\nfail to discover diverse reasoning strategies (Shao et al., 2025; Olmo Team et al., 2025). Our cognitive taxonomy offers a structured approach to bootstrap exploration by explicitly targeting underexplored behavioral\npatterns. For instance, seeding rollouts with prompts encouraging backward chaining when models predominantly use forward chaining, or constraining generation to employ spatial organization when sequential\norganization dominates.\n\nThree technical opportunities emerge. First, _reward shaping for meta-cognition_ : augment reward models\nto evaluate error detection, strategy adaptation, and explicit reasoning about problem structure through\nmultiple objectives or explicit architectural modifications (Li et al., 2025c). Second, _curriculum design for_\n_representational diversity_ : developmental psychology shows children acquire flexible reasoning through structured variation in problem presentation (Rittle-Johnson et al., 2001), which can be operationalized in LLMs\nthrough multi-task RL with auxiliary tasks rewarding specific organizational structures, or curricula that\nprogressively require different representations of the same underlying structure. Third, _environment design_\n_penalizing brittleness_ : procedurally create training distributions where rigid strategies fail\u2014problem variants requiring backward chaining after forward-chaining training, or adversarial problems exposing shallow\nheuristics (Zeng et al., 2025). Our taxonomy provides measurement, but the challenge lies in designing\nobjectives and environments that induce these capabilities.\n\n**The Bidirectional Research Opportunity.** The examples above illustrate how cognitive science provides principled frameworks for technical development. The relationship is also bidirectional: models provide\nunprecedented tools for testing cognitive theories at scale. Traditional cognitive research faces severe constraints in experimental control, sample size, and the ability to manipulate internal representations. Models\novercome these limitations.\n\nModels serve as computational implementations of cognitive hypotheses that can be systematically manipulated and tested (Griffiths et al., 2019; Saxe et al., 2021). We can examine how reasoning behaviors emerge\nduring training (Chang & Bergen, 2024; Wei et al., 2022a), ablate architectural components to identify\ntheir functional roles (Sternberg et al., 2009), and test theories of hierarchical planning and meta-cognition\nthrough interventions impossible with human subjects. Recent work uses models to test theories of semantic\ncognition (Grand et al., 2022), conceptual knowledge (Patel et al., 2022), and pragmatic reasoning (Tessler\n& Goodman, 2016) at scales unachievable in traditional experiments.\n\nSystematic differences between human and model reasoning provide constraints for cognitive theories. Our\nfinding that humans deploy meta-cognitive monitoring while models do not, despite both succeeding on\nthe same problems, suggests these behaviors enable generalization or error recovery beyond immediate task\nsuccess. This hypothesis becomes testable through systematic manipulation of models. Recent work has revealed similar divergences in causal reasoning (Lampinen et al., 2022), social cognition (Sap et al., 2022), and\npragmatic inference (Hu et al., 2023), each providing empirical constraints for theories of human cognition.\n\nWhen models succeed through unexpected mechanisms, they challenge assumptions about necessary cognitive structures. Human reasoning patterns have already informed architectural innovations (Graves et al.,\n2016; Nye et al., 2021), while model capabilities have refined theories about what computations are sufficient\nfor intelligent behavior. Our taxonomy enables this synergy by providing shared vocabulary. Cognitive\nscience offers theories of what matters and why. Machine learning offers implementations to test at scale.\nOur framework provides the language connecting them, enabling not just better models but better theories\ntested and refined through computational implementation.\n\n**Acknowledgments**\n\nWe wish to express our sincere gratitude to Anshul Nasery, Kshitish Ghate, Divyansh Pareek, Moe Kayali,\nRunjia Li, Harshita Chopra, Mihir Kavishwar, Ishika Agarwal, and Amruta Parulekar for their help in\ncollecting human reasoning traces.\n\n24\n\n**References**\n\nOrevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora,\nShuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah\nBennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, and Sachin Kumar. Blab: Brutally long audio\nbench, 2025. URL `[https://arxiv.org/abs/2505.03054](https://arxiv.org/abs/2505.03054)` .\n\nJonathan Baron. _Thinking and deciding_ . Cambridge University Press, 2008. URL `[https://www.cambridge.](https://www.cambridge.org/core/books/thinking-and-deciding/8A7447BF6291D2FB365AF3B2F56FB9FB)`\n`[org/core/books/thinking-and-deciding/8A7447BF6291D2FB365AF3B2F56FB9FB](https://www.cambridge.org/core/books/thinking-and-deciding/8A7447BF6291D2FB365AF3B2F56FB9FB)` .\n\nF. C. Bartlett. _Remembering: A Study in Experimental and Social Psychology_ . Cambridge University Press,\nCambridge, UK, 1932.\n\nYonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. _Computational Linguistics_,\n48(1):207\u2013219, 2022.\n\nLukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak,\nand Owain Evans. The reversal curse: Llms trained on\" a is b\" fail to learn\" b is a\". _arXiv preprint_\n_arXiv:2309.12288_, 2023.\n\nMatthew M Botvinick, Yael Niv, and Andew G Barto. Hierarchically organized behavior and its neural\nfoundations: A reinforcement learning perspective. _cognition_, 113(3):262\u2013280, 2009.\n\nRobert Boyd, Peter J Richerson, and Joseph Henrich. The cultural niche: Why social learning is essential for\nhuman adaptation. _Proceedings of the National Academy of Sciences_, 108(supplement_2):10918\u201310925,\n2011.\n\nDaniel A Braun, Carsten Mehring, and Daniel M Wolpert. Structure learning in action. _Behavioural brain_\n_research_, 206(2):157\u2013165, 2010.\n\nBruce K Britton and Abraham Tesser. Effects of prior knowledge on use of cognitive capacity in three\ncomplex cognitive tasks. _Journal of verbal learning and verbal behavior_, 21(4):421\u2013436, 1982.\n\nDonald E. Broadbent. _Perception and Communication_ . Pergamon Press, London, 1958.\n\nTyler A Chang and Benjamin K Bergen. Language model behavior: A comprehensive survey. _Computational_\n_Linguistics_, 50(1):293\u2013350, 2024.\n\nEugene Charniak. _Introduction to artificial intelligence_ . Pearson Education India, 1985.\n\nWilliam G Chase and Herbert A Simon. Perception in chess. _Cognitive psychology_, 4(1):55\u201381, 1973.\n\nYuri Chervonyi, Trieu H Trinh, Miroslav Ol\u0161\u00e1k, Xiaomeng Yang, Hoang Nguyen, Marcelo Menegali, Junehyuk Jung, Vikas Verma, Quoc V Le, and Thang Luong. Gold-medalist performance in solving olympiad\ngeometry with alphageometry2. _arXiv preprint arXiv:2502.03544_, 2025.\n\nMichelene TH Chi, Paul J Feltovich, and Robert Glaser. Categorization and representation of physics\nproblems by experts and novices. _Cognitive science_, 5(2):121\u2013152, 1981.\n\nNoam Chomsky. _Aspects of the Theory of Syntax_ . Number 11. MIT press, 2014.\n\nAllan M Collins and Elizabeth F Loftus. A spreading-activation theory of semantic processing. _Psychological_\n_review_, 82(6):407, 1975.\n\nCathryn S Cortesa, Jonathan D Jones, Gregory D Hager, Sanjeev Khudanpur, Amy L Shelton, and Barbara Landau. Characterizing spatial construction processes: Toward computational tools to understand\ncognition. In _Proceedings of the Annual Meeting of the Cognitive Science Society_, volume 39, 2017.\n\nFiery Cushman and Adam Morris. Habitual control of goal selection in humans. _Proceedings of the National_\n_Academy of Sciences_, 112(45):13817\u201313822, 2015.\n\n25\n\nPayel Das, Ching-Yun Ko, Sihui Dai, Georgios Kollias, Subhajit Chaudhury, and Aurelie Lozano. Can\nmemory-augmented language models generalize on reasoning-in-a-haystack tasks? _arXiv preprint_\n_arXiv:2503.07903_, 2025.\n\nRandall Davis and Jonathan J King. The origin of rule-based systems in ai. _Rule-based expert systems: The_\n_MYCIN experiments of the Stanford Heuristic Programming Project_, 1984.\n\nDeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong\nShao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu,\nChenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang\nLi, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao,\nHanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo,\nJiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni,\nJian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang,\nLecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua\nZhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang,\nQiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J.\nChen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang,\nShuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao\nYun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun\nGao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen,\nXiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng\nLin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song,\nXinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu,\nYao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying\nHe, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan\nWang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang\nZhou, Y. X. Zhu, Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying\nTang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie,\nZhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu,\nZilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen\nZhang. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL\n`[https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)` .\n\nRay J Dolan and Peter Dayan. Goals and habits in the brain. _Neuron_, 80(2):312\u2013325, 2013.\n\nYann Dubois, Bal\u00e1zs Galambosi, Percy Liang, and Tatsunori B Hashimoto. Length-controlled alpacaeval:\nA simple way to debias automatic evaluators. _arXiv preprint arXiv:2404.04475_, 2024.\n\nNouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Sean Welleck,\nPeter West, Chandra Bhagavatula, Ronan Le Bras, et al. Faith and fate: Limits of transformers on\ncompositionality. _Advances in Neural Information Processing Systems_, 36:70293\u201370332, 2023.\n\nHermann Ebbinghaus. _\u00dcber das ged\u00e4chtnis: untersuchungen zur experimentellen psychologie_ . Duncker &\nHumblot, 1885.\n\nNelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell,\nYuntao Bai, Anna Chen, Tom Conerly, et al. A mathematical framework for transformer circuits. _Trans-_\n_former Circuits Thread_, 1(1):12, 2021.\n\nJonathan St. B. T. Evans. In two minds: dual-process accounts of reasoning. _Trends in Cognitive Sciences_,\n7(10):454\u2013459, 2003. doi: 10.1016/j.tics.2003.08.012. URL `[https://doi.org/10.1016/j.tics.2003.08.](https://doi.org/10.1016/j.tics.2003.08.012)`\n\n`[012](https://doi.org/10.1016/j.tics.2003.08.012)` .\n\nJonathan St BT Evans and Keith E Stanovich. Dual-process theories of higher cognition: Advancing the\ndebate. _Perspectives on psychological science_, 8(3):223\u2013241, 2013.\n\n26\n\nEvernote. AI Transcribe by Evernote. URL `[https://evernote.com/ai-transcribe](https://evernote.com/ai-transcribe)` .\n\nLeon Festinger. Cognitive dissonance. _Scientific American_, 207(4):93\u2013106, 1962.\n\nJohn H Flavell. Metacognition and cognitive monitoring: A new area of cognitive\u2013developmental inquiry.\n_American psychologist_, 34(10):906, 1979.\n\nStephen M Fleming. Metacognition and confidence: A review and synthesis. _Annual Review of Psychology_,\n75(1):241\u2013268, 2024.\n\nStephen M Fleming and Nathaniel D Daw. Self-evaluation of decision-making: A general bayesian framework\nfor metacognitive computation. _Psychological review_, 124(1):91, 2017.\n\nJerry Fodor. Language, thought and compositionality. _Royal Institute of Philosophy Supplements_, 48:227\u2013\n242, 2001.\n\nJerry A Fodor. _The language of thought_, volume 5. Harvard university press, 1975.\n\nJerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis.\n_Cognition_, 28(1-2):3\u201371, 1988.\n\nSteven M Frankland and Joshua D Greene. Concepts and compositionality: in search of the brain\u2019s language\nof thought. _Annual review of psychology_, 71(1):273\u2013303, 2020.\n\nChris D Frith and Uta Frith. Social cognition in humans. _Current biology_, 17(16):R724\u2013R732, 2007.\n\nEugene Galanter et al. Plans and the structure of behavior. 1960.\n\nKanishk Gandhi, Ayush Chakravarthy, Anikait Singh, Nathan Lile, and Noah D Goodman. Cognitive\nbehaviors that enable self-improving reasoners, or, four habits of highly effective stars. _arXiv preprint_\n_arXiv:2503.01307_, 2025.\n\nDedre Gentner. Structure-mapping: A theoretical framework for analogy. _Cognitive science_, 7(2):155\u2013170,\n1983.\n\nMary L Gick and Keith J Holyoak. Analogical problem solving. _Cognitive psychology_, 12(3):306\u2013355, 1980.\n\nMary L Gick and Keith J Holyoak. Schema induction and analogical transfer. _Cognitive psychology_, 15(1):\n1\u201338, 1983.\n\nMichael H Goldstein, Heidi R Waterfall, Arnon Lotem, Joseph Y Halpern, Jennifer A Schwade, Luca Onnis,\nand Shimon Edelman. General cognitive principles for learning structure in time and space. _Trends in_\n_cognitive sciences_, 14(6):249\u2013258, 2010.\n\nAlison Gopnik, Clark Glymour, David M Sobel, Laura E Schulz, Tamar Kushnir, and David Danks. A\ntheory of causal learning in children: causal maps and bayes nets. _Psychological review_, 111(1):3, 2004.\n\nGabriel Grand, Idan Asher Blank, Francisco Pereira, and Evelina Fedorenko. Semantic projection recovers\nrich human knowledge of multiple object features from word embeddings. _Nature human behaviour_, 6(7):\n975\u2013987, 2022.\n\nAlex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi\u0144ska,\nSergio G\u00f3mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al. Hybrid computing\nusing a neural network with dynamic external memory. _Nature_, 538(7626):471\u2013476, 2016.\n\nThomas L Griffiths, Frederick Callaway, Michael B Chang, Erin Grant, Paul M Krueger, and Falk Lieder.\nDoing more with less: meta-reasoning and meta-learning in humans and machines. _Current Opinion in_\n_Behavioral Sciences_, 29:24\u201330, 2019.\n\nThomas L Griffiths, Nick Chater, and Joshua B Tenenbaum. _Bayesian models of cognition: Reverse engi-_\n_neering the mind_ . MIT Press, 2024.\n\n27\n\nEtash Guha, Ryan Marten, Sedrick Keh, Negin Raoof, Georgios Smyrnis, Hritik Bansal, Marianna Nezhurina,\nJean Mercat, Trung Vu, Zayne Sprague, Ashima Suvarna, Benjamin Feuer, Liangyu Chen, Zaid Khan, Eric\nFrankel, Sachin Grover, Caroline Choi, Niklas Muennighoff, Shiye Su, Wanjia Zhao, John Yang, Shreyas\nPimpalgaonkar, Kartik Sharma, Charlie Cheng-Jie Ji, Yichuan Deng, Sarah Pratt, Vivek Ramanujan,\nJon Saad-Falcon, Jeffrey Li, Achal Dave, Alon Albalak, Kushal Arora, Blake Wulfe, Chinmay Hegde,\nGreg Durrett, Sewoong Oh, Mohit Bansal, Saadia Gabriel, Aditya Grover, Kai-Wei Chang, Vaishaal\nShankar, Aaron Gokaslan, Mike A. Merrill, Tatsunori Hashimoto, Yejin Choi, Jenia Jitsev, Reinhard\nHeckel, Maheswaran Sathiamoorthy, Alexandros G. Dimakis, and Ludwig Schmidt. Openthoughts: Data\nrecipes for reasoning models, 2025. URL `[https://arxiv.org/abs/2506.04178](https://arxiv.org/abs/2506.04178)` .\n\nGraeme S Halford. Cognitive processing capacity and learning ability: An integration of two areas. _Learning_\n_and Individual Differences_, 1(1):125\u2013153, 1989.\n\nEddie Harmon-Jones and Judson Mills. An introduction to cognitive dissonance theory and an overview of\ncurrent perspectives on the theory. 2019.\n\nGrietjie Haupt. Hierarchical thinking: a cognitive tool for guiding coherent decision making in design problem\nsolving. _International Journal of Technology and Design Education_, 28(1):207\u2013237, 2018.\n\nMarc D Hauser, Noam Chomsky, and W Tecumseh Fitch. The faculty of language: what is it, who has it,\nand how did it evolve? _science_, 298(5598):1569\u20131579, 2002.\n\nFritz Heider. _The Psychology of Interpersonal Relations_ . Wiley, New York, 1958.\n\nChristoph Hoerl and Teresa McCormack. Thinking in and about time: A dual systems perspective on\ntemporal cognition. _Behavioral and Brain Sciences_, 42:e244, 2019.\n\nValentin Hofmann, David Heineman, Ian Magnusson, Kyle Lo, Jesse Dodge, Maarten Sap, Pang Wei Koh,\nChun Wang, Hannaneh Hajishirzi, and Noah A Smith. Fluid language model benchmarking. _arXiv preprint_\n_arXiv:2509.11106_, 2025.\n\nKeith J Holyoak and Paul Thagard. Analogical mapping by constraint satisfaction. _Cognitive science_, 13\n(3):295\u2013355, 1989.\n\nKeith J Holyoak and Paul Thagard. The analogical mind. _American psychologist_, 52(1):35, 1997.\n\nJennifer Hu, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, and Edward Gibson. A fine-grained\ncomparison of pragmatic language understanding in humans and language models. In _Proceedings of_\n_the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp.\n4194\u20134213, 2023.\n\nClark L Hull. Quantitative aspects of evolution of concepts: An experimental study. _Psychological mono-_\n_graphs_, 28(1):i, 1920.\n\nQuentin JM Huys, Neir Eshel, Elizabeth O\u2019Nions, Luke Sheridan, Peter Dayan, and Jonathan P Roiser.\nBonsai trees in your head: how the pavlovian system sculpts goal-directed choices by pruning decision\ntrees. _PLoS computational biology_, 8(3):e1002410, 2012.\n\nRobert A Jacobs and John K Kruschke. Bayesian learning theory applied to human cognition. _Wiley_\n_Interdisciplinary Reviews: Cognitive Science_, 2(1):8\u201321, 2011.\n\nWilliam James, Frederick Burkhardt, Fredson Bowers, and K\u0119stutis Skrupskelis. _The principles of psychology_,\nvolume 1. Macmillan London, 1890.\n\nJuyong Jiang, Fan Wang, Jiasi Shen, Sungju Kim, and Sunghun Kim. A survey on large language models\nfor code generation. _arXiv preprint arXiv:2406.00515_, 2024.\n\nPhilip N Johnson-Laird. Mental models and human reasoning. _Proceedings of the National Academy of_\n_Sciences_, 107(43):18243\u201318250, 2010. URL `[https://www.pnas.org/content/107/43/18243](https://www.pnas.org/content/107/43/18243)` .\n\n28\n\nPhilip Nicholas Johnson-Laird. _Mental models: Towards a cognitive science of language, inference, and_\n_consciousness_ . Number 6. Harvard University Press, 1983.\n\nDavid H Jonassen. Toward a design theory of problem solving. _Educational technology research and devel-_\n_opment_, 48(4):63\u201385, 2000.\n\nDavid H Jonassen and Woei Hung. All problems are not equal: Implications for problem-based learning.\n_Essential readings in problem-based learning: Exploring and extending the legacy of Howard S. Barrows_,\n1741, 2015.\n\nPriyanka Kargupta, Runchu Tian, and Jiawei Han. Beyond true or false: Retrieval-augmented hierarchical\nanalysis of nuanced claims. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher\nPilehvar (eds.), _Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics_\n_(Volume 1: Long Papers)_, pp. 29664\u201329679, Vienna, Austria, July 2025. Association for Computational\nLinguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.1434. URL `[https://aclanthology.](https://aclanthology.org/2025.acl-long.1434/)`\n`[org/2025.acl-long.1434/](https://aclanthology.org/2025.acl-long.1434/)` .\n\nSangeet S Khemlani, Aron K Barbey, and Philip N Johnson-Laird. Causal reasoning with mental models.\n_Frontiers in human neuroscience_, 8:849, 2014.\n\nMarina A Kholodnaya and Elena V Volkova. Conceptual structures, conceptual abilities and productivity\nof cognitive functioning: the ontological approach. _Procedia-Social and Behavioral Sciences_, 217:914\u2013922,\n2016.\n\nG\u00fcnther Knoblich, Stellan Ohlsson, Hilde Haider, and Detlef Rhenius. Constraint relaxation and chunk\ndecomposition in insight problem solving. _Journal of Experimental Psychology: Learning, memory, and_\n_cognition_, 25(6):1534, 1999.\n\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language\nmodels are zero-shot reasoners. _Advances in Neural Information Processing Systems_, 36, 2023. URL\n`[https://arxiv.org/abs/2205.11916](https://arxiv.org/abs/2205.11916)` .\n\nPeter M Krafft and Thomas L Griffiths. Levels of analysis in computational social science. In _Proceedings_\n_of the Annual Meeting of the Cognitive Science Society_, volume 40, 2018.\n\nSonal Kumar, \u0160imon Sedl\u00e1\u010dek, Vaibhavi Lokegaonkar, Fernando L\u00f3pez, Wenyi Yu, Nishit Anand, Hyeonggon\nRyu, Lichang Chen, Maxim Pli\u010dka, Miroslav Hlav\u00e1\u010dek, William Fineas Ellingwood, Sathvik Udupa, Siyuan\nHou, Allison Ferner, Sara Barahona, Cecilia Bola\u00f1os, Satish Rahi, Laura Herrera-Alarc\u00f3n, Satvik Dixit,\nSiddhi Patil, Soham Deshmukh, Lasha Koroshinadze, Yao Liu, Leibny Paola Garcia Perera, Eleni Zanou,\nThemos Stafylakis, Joon Son Chung, David Harwath, Chao Zhang, Dinesh Manocha, Alicia Lozano-Diez,\nSantosh Kesiraju, Sreyan Ghosh, and Ramani Duraiswami. Mmau-pro: A challenging and comprehensive\nbenchmark for holistic evaluation of audio general intelligence. _arXiv preprint arXiv:2508.13992_, 2025.\nURL `[https://arxiv.org/abs/2508.13992](https://arxiv.org/abs/2508.13992)` .\n\nWolfgang K\u00f6hler. _The Mentality of Apes_ . K. Paul, Trench, Trubner & co., ltd., London, 1925.\n\nNathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester\nJames V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, et al. T\u00fclu 3: Pushing frontiers in open language\nmodel post-training. _arXiv preprint arXiv:2411.15124_, 2024. URL `[https://arxiv.org/abs/2411.15124](https://arxiv.org/abs/2411.15124)` .\n\nAndrew Lampinen, Ishita Dasgupta, Stephanie Chan, Kory Mathewson, Mh Tessler, Antonia Creswell,\nJames McClelland, Jane Wang, and Felix Hill. Can language models learn from explanations in context?\nIn _Findings of the Association for Computational Linguistics: EMNLP 2022_, pp. 537\u2013563, 2022.\n\nBarbara Landau and Ray Jackendoff. Whence and whither in spatial language and spatial cognition? _Be-_\n_havioral and brain sciences_, 16(2):255\u2013265, 1993.\n\nTamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez,\nDustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et al. Measuring faithfulness in chain-ofthought reasoning. _arXiv preprint arXiv:2307.13702_, 2023.\n\n29\n\nKarl Spencer Lashley et al. _The problem of serial order in behavior_, volume 21. Bobbs-Merrill Oxford, 1951.\n\nHung Le, Dai Do, Dung Nguyen, and Svetha Venkatesh. Reasoning under 1 billion: Memory-augmented\nreinforcement learning for large language models. _arXiv preprint arXiv:2504.02273_, 2025.\n\nMark R Leary and Nicole R Buttermore. The evolution of the human self: Tracing the natural history of\nself-awareness. _Journal for the theory of Social Behaviour_, 33(4):365\u2013404, 2003.\n\nSeungpil Lee, Woochang Sim, Donghyeon Shin, Wongyu Seo, Jiwon Park, Seokki Lee, Sanha Hwang, Sejin\nKim, and Sundong Kim. Reasoning abilities of large language models: In-depth analysis on the abstraction\nand reasoning corpus. _ACM Transactions on Intelligent Systems and Technology_, 2024.\n\nYanyu Lei. Sociality and self-awareness in animals. _Frontiers in Psychology_, 13:1065638, 2023.\n\nAng Li, Charles Wang, Kaiyu Yue, Zikui Cai, Ollie Liu, Deqing Fu, Peng Guo, Wang Bill Zhu, Vatsal Sharan,\nRobin Jia, Willie Neiswanger, Furong Huang, Tom Goldstein, and Micah Goldblum. Zebra-cot: A dataset\nfor interleaved vision language reasoning, 2025a. URL `[https://arxiv.org/abs/2507.16746](https://arxiv.org/abs/2507.16746)` .\n\nShuyue Stella Li, Avinandan Bose, Faeze Brahman, Simon Shaolei Du, Pang Wei Koh, Maryam Fazel, and\nYulia Tsvetkov. Personalized reasoning: Just-in-time personalization and why llms fail at it. _arXiv preprint_\n_arXiv:2510.00177_, 2025b.\n\nShuyue Stella Li, Melanie Sclar, Hunter Lang, Ansong Ni, Jacqueline He, Puxin Xu, Andrew Cohen,\nChan Young Park, Yulia Tsvetkov, and Asli Celikyilmaz. Prefpalette: Personalized preference modeling with latent attributes, 2025c. URL `[https://arxiv.org/abs/2507.13541](https://arxiv.org/abs/2507.13541)` .\n\nStella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei W Koh, and\nYulia Tsvetkov. Mediq: Question-asking llms and a benchmark for reliable interactive clinical reasoning.\n_Advances in Neural Information Processing Systems_, 37:28858\u201328888, 2024.\n\nFalk Lieder and Thomas L Griffiths. Strategy selection as rational metareasoning. _Psychological review_, 124\n(6):762, 2017.\n\nFalk Lieder and Thomas L Griffiths. Resource-rational analysis: Understanding human cognition as the\noptimal use of limited computational resources. _Behavioral and brain sciences_, 43:e1, 2020.\n\nHunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John\nSchulman, Ilya Sutskever, and Karl Cobbe. Let\u2019s verify step by step. _arXiv preprint arXiv:2305.20050_,\n2023. URL `[https://arxiv.org/abs/2305.20050](https://arxiv.org/abs/2305.20050)` .\n\nTania Lombrozo. Learning by thinking in natural and artificial minds. _Trends in Cognitive Sciences_, 2024.\n\nMichael Luo, Sijun Tan, Justin Wong, Xiaoxiang Shi, William Y. Tang, Manan Roongta, Colin\nCai, Jeffrey Luo, Li Erran Li, Raluca Ada Popa, and Ion Stoica. Deepscaler: Surpassing o1-preview with a 1.5b model by scaling rl. `[https://pretty-radio-b75.notion.site/](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)`\n`[DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)`,\n2025. Notion Blog.\n\nZiyang Ma, Yinghao Ma, Yanqiao Zhu, Chen Yang, Yi-Wen Chao, Ruiyang Xu, Wenxi Chen, Yuanzhe Chen,\nZhuo Chen, Jian Cong, Kai Li, Keliang Li, Siyou Li, Xinfeng Li, Xiquan Li, Zheng Lian, Yuzhe Liang,\nMinghao Liu, Zhikang Niu, Tianrui Wang, Yuping Wang, Yuxuan Wang, Yihao Wu, Guanrou Yang,\nJianwei Yu, Ruibin Yuan, Zhisheng Zheng, Ziya Zhou, Haina Zhu, Wei Xue, Emmanouil Benetos, Kai Yu,\nEng-Siong Chng, and Xie Chen. Mmar: A challenging benchmark for deep reasoning in speech, audio,\nmusic, and their mix. _arXiv preprint arXiv:2505.13032_, 2025. URL `[https://arxiv.org/abs/2505.13032](https://arxiv.org/abs/2505.13032)` .\n\nSara Vera Marjanovi\u0107, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar\nBhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing Han L\u00f9, et al. Deepseek-r1 thoughtology:\nLet\u2019s think about llm reasoning. _arXiv preprint arXiv:2504.07128_, 2025.\n\n30\n\nDavid Marr. _Vision: A Computational Investigation into the Human Representation and Processing of Visual_\n_Information_ . W. H. Freeman, San Francisco, 1982. ISBN 0-7167-1284-9.\n\nRui Mata, Bettina von Helversen, and J\u00f6rg Rieskamp. When easy comes hard: The development of adaptive\nstrategy selection. _Child Development_, 82(2):687\u2013700, 2011.\n\nJames L McClelland, Matthew M Botvinick, David C Noelle, David C Plaut, Timothy T Rogers, Mark S Seidenberg, and Linda B Smith. Letting structure emerge: connectionist and dynamical systems approaches\nto cognition. _Trends in cognitive sciences_, 14(8):348\u2013356, 2010.\n\nR Thomas McCoy, Ellie Pavlick, and Tal Linzen. Right for the wrong reasons: Diagnosing syntactic heuristics\nin natural language inference. _arXiv preprint arXiv:1902.01007_, 2019.\n\nR Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D Hardy, and Thomas L Griffiths. Embers of\nautoregression show how large language models are shaped by the problem they are trained to solve.\n_Proceedings of the National Academy of Sciences_, 121(41):e2322420121, 2024.\n\nDouglas L Medin and Marguerite M Schaffer. Context theory of classification learning. _Psychological review_,\n85(3):207, 1978.\n\nSmitha Milli, Falk Lieder, and Thomas L Griffiths. A rational reinterpretation of dual-process theories.\n_Cognition_, 217:104881, 2021.\n\nMarvin Minsky. A framework for representing knowledge. 1974.\n\nNiklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Cand\u00e8s, and Tatsunori Hashimoto. s1: Simple test-time scaling, 2025.\nURL `[https://arxiv.org/abs/2501.19393](https://arxiv.org/abs/2501.19393)` .\n\nNeel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures for\ngrokking via mechanistic interpretability. _arXiv preprint arXiv:2301.05217_, 2023.\n\nUlric Neisser. Five kinds of self-knowledge. _Philosophical psychology_, 1(1):35\u201359, 1988.\n\nThomas O Nelson. Metamemory: A theoretical framework and new findings. In _Psychology of learning and_\n_motivation_, volume 26, pp. 125\u2013173. Elsevier, 1990.\n\nAllen Newell and Herbert A. Simon. _Human Problem Solving_ . Prentice-Hall, Englewood Cliffs, NJ,\n1972. ISBN 978-0-13-445403-0. URL `[https://www.pearson.com/us/higher-education/program/](https://www.pearson.com/us/higher-education/program/Newell-Human-Problem-Solving/PGM332539.html)`\n`[Newell-Human-Problem-Solving/PGM332539.html](https://www.pearson.com/us/higher-education/program/Newell-Human-Problem-Solving/PGM332539.html)` .\n\nAllen Newell, John C Shaw, and Herbert A Simon. Report on a general problem solving program. In _IFIP_\n_congress_, volume 256, pp. 1959. Pittsburgh, PA, 1959.\n\nNils J. Nilsson. Problem-solving methods in artificial intelligence. In _McGraw-Hill computer science series_,\n1971. URL `[https://api.semanticscholar.org/CorpusID:34428834](https://api.semanticscholar.org/CorpusID:34428834)` .\n\nLaura R Novick and Cindy E Hmelo. Transferring symbolic representations across nonisomorphic problems.\n_Journal of Experimental Psychology: Learning, Memory, and Cognition_, 20(6):1296, 1994.\n\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for\nintermediate computation with language models. 2021.\n\nMike Oaksford and Nick Chater. Pr\u00e9cis of bayesian rationality: The probabilistic approach to human\nreasoning. _Behavioral and Brain Sciences_, 32(1):69\u201384, 2009.\n\nStellan Ohlsson. Information-processing explanations of insight and related phenomena. _Advances in the_\n_psychology of thinking_, pp. 1\u201344, 1992.\n\n31\n\nOlmo Team, Allyson Ettinger, Amanda Bertsch, Bailey Kuehl, David Graham, David Heineman, Dirk\nGroeneveld, Faeze Brahman, Finbarr Timbers, Hamish Ivison, Jacob Morrison, Jake Poznanski, Kyle Lo,\nLuca Soldaini, Matt Jordan, Mayee Chen, Michael Noukhovitch, Nathan Lambert, Pete Walsh, Pradeep\nDasigi, Robert Berry, Saumya Malik, Saurabh Shah, Scott Geng, Shane Arora, Shashank Gupta, Taira\nAnderson, Teng Xiao, Tyler Murray, Tyler Romero, Victoria Graf, Akari Asai, Akshita Bhagia, Alexander\nWettig, Alisa Liu, Aman Rangapur, Chloe Anastasiades, Costa Huang, Dustin Schwenk, Harsh Trivedi,\nIan Magnusson, Jaron Lochner, Jiacheng Liu, Lj Miranda, Maarten Sap, Malia Morgan, Michael Schmitz,\nMichal Guerquin, Michael Wilson, Regan Huff, Ronan Le Bras, Rui Xin, Rulin Shao, Sam Skjonsberg,\nShannon Zejiang Shen, Shuyue Stella Li, Tucker Wilde, Valentina Pyatkin, Will Merrill, Yapei Chang,\nYuling Gu, Zhiyuan Zeng, Ashish Sabharwal, Luke Zettlemoyer, Pang Wei Koh, Ali Farhadi, Noah A.\nSmith, and Hannaneh Hajishirzi. Olmo 3 technical report. 2025.\n\nJooyoung Park, Fang-Chi Lu, and William M Hedgcock. Relative effects of forward and backward planning\non goal pursuit. _Psychological science_, 28(11):1620\u20131630, 2017.\n\nAjay Patel, Bryan Li, Mohammad Sadegh Rasooli, Noah Constant, Colin Raffel, and Chris Callison-Burch.\nBidirectional language models are also few-shot learners. _arXiv preprint arXiv:2209.14500_, 2022.\n\nDavid Peebles and Richard P Cooper. Thirty years after marr\u2019s vision: levels of analysis in cognitive science,\n2015.\n\nJohn Piaget. The origins of intelligence in children. _International Universities_, 1952.\n\nSteven Thomas Piantadosi. _Learning and the language of thought_ . PhD thesis, Massachusetts Institute of\nTechnology, 2011.\n\nMichael I Posner and Steven W Keele. On the genesis of abstract ideas. _Journal of experimental psychology_,\n77(3p1):353, 1968.\n\nTian Qin, David Alvarez-Melis, Samy Jelassi, and Eran Malach. To backtrack or not to backtrack: When\nsequential search limits model reasoning. _arXiv preprint arXiv:2504.07052_, 2025.\n\nM Ross Quillan. Semantic memory. Technical report, 1966.\n\nMarco Ragni, Ilir Kola, and Phil N Johnson-Laird. The wason selection task: A meta-analysis. In _Proceedings_\n_of the Annual Meeting of the Cognitive Science Society_, volume 39, 2017.\n\nLance J Rips. Cognitive processes in propositional reasoning. _Psychol. Rev._, 90(1):38\u201371, January 1983.\n\nBethany Rittle-Johnson, Robert S Siegler, and Martha Wagner Alibali. Developing conceptual understanding\nand procedural skill in mathematics: An iterative process. _Journal of educational psychology_, 93(2):346,\n2001.\n\nPhilippe Rochat. Five levels of self-awareness as they unfold early in life. _Consciousness and cognition_, 12\n(4):717\u2013731, 2003.\n\nEleanor Rosch. Cognitive representations of semantic categories. _Journal of experimental psychology: Gen-_\n_eral_, 104(3):192, 1975.\n\nEleanor Rosch. Principles of categorization. In Eleanor Rosch and Barbara Bloom Lloyd (eds.), _Cognition_\n_and Categorization_, pp. 27\u201348. Lawrence Elbaum Associates, 1978.\n\nEleanor Rosch and Carolyn B Mervis. Family resemblances: Studies in the internal structure of categories.\n_Cognitive psychology_, 7(4):573\u2013605, 1975.\n\nDavid A Rosenbaum, Rajal G Cohen, Steven A Jax, Daniel J Weiss, and Robrecht Van Der Wel. The\nproblem of serial order in behavior: Lashley\u2019s legacy. _Human movement science_, 26(4):525\u2013554, 2007.\n\nJacob Russin, Sam Whitman McGrath, and Danielle J Williams. From frege to chatgpt: Compositionality\nin language, cognition, and deep neural networks. _arXiv preprint arXiv:2405.15164_, 2024.\n\n32\n\nMaarten Sap, Ronan Le Bras, Daniel Fried, and Yejin Choi. Neural theory-of-mind? on the limits of social\nintelligence in large lms. In _Proceedings of the 2022 conference on empirical methods in natural language_\n_processing_, pp. 3762\u20133780, 2022.\n\nAndrew Saxe, Stephanie Nelli, and Christopher Summerfield. If deep learning is the answer, what is the\nquestion? _Nature Reviews Neuroscience_, 22(1):55\u201367, 2021.\n\nAlan H Schoenfeld. _Mathematical problem solving_ . Elsevier, 2014.\n\nO. G. Selfridge. Pandemonium: A paradigm for learning. In _Proceedings of the Symposium on Mechanisation_\n_of Thought Processes_, pp. 513\u2013526, London, 1959. Her Majesty\u2019s Stationery Office.\n\nPatrick Shafto, Charles Kemp, Elizabeth Baraff Bonawitz, John D Coley, and Joshua B Tenenbaum. Inductive reasoning about causally transmitted properties. _Cognition_, 109(2):175\u2013192, 2008.\n\nRulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan\nLambert, Sewon Min, Ranjay Krishna, et al. Spurious rewards: Rethinking training signals in rlvr. _arXiv_\n_preprint arXiv:2506.10947_, 2025.\n\nAmy Lynne Shelton, E Emory Davis, Cathryn S Cortesa, Jonathan D Jones, Gregory D Hager, Sanjeev\nKhudanpur, and Barbara Landau. Characterizing the details of spatial construction: cognitive constraints\nand variability. _Cognitive Science_, 46(1):e13081, 2022.\n\nRoger N Shepard and Jacqueline Metzler. Mental rotation of three-dimensional objects. _Science_, 171(3972):\n701\u2013703, 1971.\n\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won\nChung, Yi Tay, Sebastian Ruder, Denny Zhou, et al. Language models are multilingual chain-of-thought\nreasoners. _arXiv preprint arXiv:2210.03057_, 2022.\n\nDorothea P. Simon and Herbert A. Simon. Individual differences in solving physics problems. In _Children\u2019s_\n_Thinking: What Develops?_, pp. 24, Hillsdale, N.J., 1978. Lawrence Erlbaum Associates.\n\nB. F. Skinner. _Science and Human Behavior_ . Simon & Schuster, New York, 1953.\n\nSteven Sloman and Steven A Sloman. _Causal models: How people think about the world and its alternatives_ .\nOxford University Press, 2009.\n\nCharlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time compute optimally can be\nmore effective than scaling model parameters. _arXiv preprint arXiv:2408.03314_, 2024.\n\nRobert J Sternberg, Karin Sternberg, and Jeff Mio. _Cognitive psychology_ . wadsworth Belmont, CA, 2009.\n\nStanley Smith Stevens. On the theory of scales of measurement. _Science_, 103(2684):677\u2013680, 1946.\n\nMark Steyvers and Joshua B Tenenbaum. The large-scale structure of semantic networks: Statistical analyses\nand a model of semantic growth. _Cognitive science_, 29(1):41\u201378, 2005.\n\nDeborah Stipek, Susan Recchia, Susan McClintic, and Michael Lewis. Self-evaluation in young children.\n_Monographs of the society for research in child development_, pp. i\u201395, 1992.\n\nJohn Sweller. Cognitive load during problem solving: Effects on learning. _Cognitive science_, 12(2):257\u2013285,\n1988.\n\nJohn Sweller. Cognitive load theory. In _Psychology of learning and motivation_, volume 55, pp. 37\u201376.\nElsevier, 2011.\n\nRoss Taylor. Generalthoughtarchive. `[https://huggingface.co/datasets/RJT1990/](https://huggingface.co/datasets/RJT1990/GeneralThoughtArchive)`\n`[GeneralThoughtArchive](https://huggingface.co/datasets/RJT1990/GeneralThoughtArchive)`, 2024. Dataset on Hugging Face; MIT License.\n\nTeknium, Roger Jin, Chen Guang, Jai Suphavadeeprasit, and Jeffrey Quesnelle. Deephermes 3 preview,\n2025.\n\n33\n\nMichael Henry Tessler and Noah D Goodman. A pragmatic theory of generic language. _arXiv preprint_\n_arXiv:1608.02926_, 2016.\n\nPaul Thagard. _Coherence in thought and action_ . MIT press, 2002.\n\nEdward C Tolman. Cognitive maps in rats and men. _Psychological review_, 55(4):189, 1948.\n\nAnne Treisman. Monitoring and storage of irrelevant messages in selective attention. _Journal of Verbal_\n_Learning and Verbal Behavior_, 3(6):449\u2013459, 1964.\n\nMiles Turpin, Julian Michael, Ethan Perez, and Samuel Bowman. Language models don\u2019t always say what\nthey think: Unfaithful explanations in chain-of-thought prompting. _Advances in Neural Information_\n_Processing Systems_, 36:74952\u201374965, 2023.\n\nAmos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases. _Science_, 185\n(4157):1124\u20131131, 1974. doi: 10.1126/science.185.4157.1124. URL `[https://doi.org/10.1126/science.](https://doi.org/10.1126/science.185.4157.1124)`\n\n`[185.4157.1124](https://doi.org/10.1126/science.185.4157.1124)` .\n\nJonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia Creswell,\nGeoffrey Irving, and Irina Higgins. Solving math word problems with process-and outcome-based feedback.\n_arXiv preprint arXiv:2211.14275_, 2022.\n\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and\nDenny Zhou. Self-consistency improves chain of thought reasoning in language models. _arXiv preprint_\n_arXiv:2203.11171_, 2022.\n\nPeter C Wason. Reasoning about a rule. _Quarterly journal of experimental psychology_, 20(3):273\u2013281, 1968.\n\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. _arXiv_\n_preprint arXiv:2206.07682_, 2022a.\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural_\n_Information Processing Systems_, 35:24824\u201324837, 2022b. URL `[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)` .\n\nMax Wertheimer. _Productive Thinking_ . Harper and Brothers, New York, 1945.\n\nRobert A Wicklund. The influence of self-awareness on human behavior: The person who becomes self-aware\nis more likely to act consistently, be faithful to societal norms, and give accurate reports about himself.\n_American scientist_, 67(2):187\u2013193, 1979.\n\nMingqi Wu, Zhihao Zhang, Qiaole Dong, Zhiheng Xi, Jun Zhao, Senjie Jin, Xiaoran Fan, Yuhao Zhou, Huijie\nLv, Ming Zhang, et al. Reasoning or memorization? unreliable results of reinforcement learning due to\ndata contamination. _arXiv preprint arXiv:2507.10532_, 2025.\n\nFangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, Jun Liu, and Erik Cambria. Are large language models\nreally good logical reasoners? a comprehensive evaluation and beyond. _IEEE Transactions on Knowledge_\n_and Data Engineering_, 2025.\n\nAn Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,\nChengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge,\nHaoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang,\nJing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng,\nMei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan\nLiu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang,\nXuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang,\nZeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. Qwen3 technical report, 2025. URL `[https:](https://arxiv.org/abs/2505.09388)`\n`[//arxiv.org/abs/2505.09388](https://arxiv.org/abs/2505.09388)` .\n\n34\n\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan.\nTree of thoughts: Deliberate problem solving with large language models. _Advances in Neural Information_\n_Processing Systems_, 36, 2023. URL `[https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601)` .\n\nNick Yeung and Christopher Summerfield. Metacognition in human decision-making: confidence and error\nmonitoring. _Philos. Trans. R. Soc. Lond. B Biol. Sci._, 367(1594):1310\u20131321, May 2012.\n\nZhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline\nHe, Runlong Zhou, Tong Chen, et al. Rlve: Scaling up reinforcement learning for language models with\nadaptive verifiable environments. _arXiv preprint arXiv:2511.07317_, 2025.\n\n**A** **Appendix**\n\n**A.1** **Prompts for Fine-Grained Cognitive Element Annotation**\n\nWe provide detailed annotation guidelines for each cognitive capability to ensure consistent and reliable\nhuman annotations. Below we present the complete annotation guidelines for _abstraction_ as an illustrative\nexample. The guidelines include: (1) a clear definition of the cognitive capability, (2) specific indicators\nto look for in reasoning traces, (3) a three-level rubric (0=Absent, 1=Partially Present, 2=Present), and\n(4) annotated examples demonstrating each score level. Complete annotation prompts for all cognitive\ncapabilities are available in our repository at `[https://github.com/stellalisy/CognitiveFoundations](https://github.com/stellalisy/CognitiveFoundations)` .\n\n35\n\n![](papers/images/Cognitive-Foundations-for-Reasoning-and-Their-Manifestation-in-LLMs.pdf-35-0.png)\n\nThe guidelines also include three detailed annotated examples demonstrating scores of 0 (Absent), 1 (Partially Present), and 2 (Present), which help annotators calibrate their judgments. Complete examples and\nguidelines for all other cognitive capabilities follow a similar structure and can be found in the repository.\n\n36\n\nBelow we provide the full prompt shown to annotators for this capability.\n\n**A.2** **Typology of Problems**\n\nWe classify cognitive tasks using an extended version of Jonassen\u2019s (2000) problem-solving taxonomy.\nJonassen\u2019s framework characterizes problems along a continuum from well-structured (clear goals, known\nsolution paths, predictable outcomes) to ill-structured (ambiguous goals, multiple solution paths, uncertain\noutcomes), organizing problems into 11 types based on their structural properties and cognitive demands.\n\n**A.2.1** **Extension of Jonassen\u2019s Taxonomy**\n\nWe extend the original 11-category framework with two additional categories to capture tasks outside the\ngoal-directed transformation paradigm:\n\n- **Factual Recall** : Retrieving stored knowledge without requiring reasoning or problem-solving (e.g.,\n\"What is photosynthesis?\" or \"List the causes of WWI\")\n\n- **Creative/Expressive** : Generating novel content judged by originality or aesthetic quality rather than\nconvergence to a predetermined solution (e.g., \"Write a poem\" or \"Draw how you feel\")\n\nThis yields a 13-category taxonomy spanning the full spectrum of cognitive demands in our datasets.\n\n**A.2.2** **Problem Type Definitions**\n\nFollowing Jonassen (2000), we define problem-solving as a goal-directed cognitive activity that transforms\nan initial state into a desired goal state through systematic reasoning. The 11 problem-solving types are\norganized along the structuredness continuum:\n\n**Well-Structured Problems**\n\n1. **Logical** : Abstract reasoning puzzles with optimal solutions and minimal context (e.g., Tower of Hanoi,\nriver crossing puzzles)\n\n2. **Algorithmic** : Fixed procedures applied to similar variable sets, producing correct answers through\nprescribed methods (e.g., solve quadratic equations, convert temperature units)\n\n3. **Story Problems** : Mathematical or scientific problems embedded in narrative contexts, requiring extraction of values and formula application (e.g., distance-rate-time problems)\n\n4. **Rule-Using** : Procedural processes constrained by rules that allow multiple valid approaches to systemconstrained answers (e.g., database searching, theorem proving, recipe modification)\n\n5. **Decision-Making** : Selecting and justifying one option from a finite set of alternatives, weighing benefits\nand limitations (e.g., college selection, route planning, benefits package choice)\n\n**Moderately Structured Problems**\n\n6. **Troubleshooting** : Diagnosing faults in malfunctioning systems by generating and testing hypotheses\n(e.g., car won\u2019t start, network is down, code debugging)\n\n7. **Diagnosis-Solution** : Extending beyond fault identification to recommend and evaluate treatment options (e.g., medical diagnosis and treatment, identifying and treating lawn problems)\n\n8. **Strategic Performance** : Real-time execution of complex tactics while maintaining situational awareness under competing demands (e.g., flying aircraft, teaching live classes, managing portfolios during\ntrading)\n\n**Ill-Structured Problems**\n\n9. **Case Analysis** : Analyzing complex scenarios with multiple stakeholders and perspectives, arguing\npositions in detail-rich situations with ill-defined goals (e.g., business cases, legal judgments, policy\nrecommendations)\n\n37\n\n10. **Design** : Creating new artifacts or systems that satisfy functional requirements, with solutions evaluated\nas better or worse rather than correct or incorrect (e.g., bridge design, curriculum development, marketing\ncampaigns)\n\n11. **Dilemma** : Reconciling contradictory positions with no satisfactory solution that serves all perspectives\n(e.g., abortion policy, international conflicts, wealth redistribution)\n\n**A.2.3** **Classification Methodology**\n\nEach problem is classified through majority voting across three frontier language models (GPT-4o-mini,\nGemini-2.5-Pro, and Claude-Sonnet-4.5). Each model independently classifies the problem using detailed\nannotation guidelines based on Jonassen\u2019s (2000) structural criteria: goal clarity, solution determinacy, and\ndomain constraints. Three-way disagreements occur in under 3% of cases and are adjudicated manually\nusing these structural criteria. The complete classification prompt and guidelines are available in our code\nrepository at `[https://github.com/stellalisy/CognitiveFoundations](https://github.com/stellalisy/CognitiveFoundations)` .\n\n**A.2.4** **Key Distinctions**\n\nSeveral problem types share surface similarities but differ fundamentally in their cognitive demands:\n\n - **Troubleshooting vs. Diagnosis-Solution** : Troubleshooting identifies faults; diagnosis-solution both\nidentifies and treats\n\n - **Story Problem vs. Factual Recall** : Story problems require calculation despite narrative framing;\nfactual recall simply explains information\n\n - **Decision-Making vs. Dilemma** : Decision-making has acceptable solutions; dilemmas have no satisfactory resolution for all parties\n\n - **Design vs.** **Creative/Expressive** : Design has functional requirements and constraints; creative/expressive tasks involve pure expression\n\n - **Algorithmic vs. Design** : Algorithms have one correct procedure; design problems have multiple valid\napproaches with better/worse solutions\n\nThis taxonomy enables systematic analysis of how problem structure affects behavioral manifestation and\nreasoning success across our dataset of 171,485 traces.\n\n**A.3** **Accuracy Analysis**\n\nTable 5 presents the complete accuracy results for all 14 text reasoning models across the 13 problem types\nin our taxonomy. Numbers in parentheses indicate the number of problems evaluated for each modeltype pair. The models span five major architectural families: Qwen3 (Alibaba\u2019s native thinking mode\nintegration), DeepSeek-R1 and its distillations (knowledge transfer from 671B teacher), OpenThinker (dataquality focused), DeepScaleR (efficient RL), s1.1 (Qwen-based efficient training), and DeepHermes-3 (hybrid\nreasoning with user-controlled depth).\n\n**A.3.1** **Key Observations**\n\n**Performance by Problem Structure** Accuracy patterns reveal strong relationships with problem structuredness following Jonassen\u2019s (2000) taxonomy. Well-structured problems show higher average accuracy:\nStory Problems (79.5%), Algorithmic (63.8%), and Factual Recall (61.8%). Moderately-structured problems\nshow intermediate performance: Troubleshooting (54.6%), Rule-Using (54.4%), Decision-Making (55.7%),\nLogical (56.4%). Ill-structured problems show lower accuracy: Diagnosis-Solution (44.7%), Design (46.6%),\nCase Analysis (53.5%). The notable exception is Dilemma (82.4%), which achieves high accuracy despite\nbeing the most ill-structured problem type\u2014suggesting models excel at articulating positions even when no\nobjectively correct solution exists.\n\n38\n\nTable 5: Accuracy by problem type and model for text reasoning tasks (Part 1). Numbers in parentheses\nindicate sample size.\n\n**Problem Type** **Qwen3-32B** **Qwen3-14B** **Qwen3-8B** **R1-Qwen-32B** **R1-Qwen-14B** **R1-Qwen-7B** **R1-Qwen-1.5B**\n\nAlgorithmic 78.4% (6274) 77.4% (6275) 74.8% (6274) 70.1% (6271) 66.1% (6275) 62.1% (6227) 47.7% (6027)\nStory Problem 86.7% (113) 92.0% (113) 87.6% (113) 85.0% (113) 85.0% (113) 74.3% (113) 66.1% (112)\nRule-Using 79.8% (504) 61.9% (504) 61.3% (504) 59.3% (504) 54.2% (504) 50.2% (490) 28.3% (488)\nDecision-Making 70.7% (99) 76.8% (99) 75.8% (99) 57.6% (99) 55.6% (99) 38.4% (99) 23.2% (99)\nTroubleshooting 82.4% (91) 62.6% (91) 65.9% (91) 67.0% (91) 57.1% (91) 18.7% (91) 11.0% (91)\nDiagnosis-Solution 78.3% (83) 67.5% (83) 54.2% (83) 47.0% (83) 47.0% (83) 4.8% (83) 2.4% (83)\nCase Analysis 84.3% (121) 82.6% (121) 74.4% (121) 47.9% (121) 58.7% (121) 18.2% (121) 2.5% (121)\nDesign 75.2% (157) 66.2% (157) 64.3% (157) 50.0% (156) 40.8% (157) 28.2% (156) 9.2% (153)\nDilemma 99.1% (1166) 97.6% (1168) 98.9% (1168) 94.5% (1167) 96.0% (1168) 89.7% (1168) 3.2% (1166)\nLogical 73.3% (60) 78.3% (60) 68.3% (60) 73.3% (60) 68.3% (60) 48.3% (60) 18.2% (55)\nFactual Recall 82.6% (2819) 80.2% (2819) 78.2% (2819) 68.0% (2819) 67.3% (2819) 42.0% (2818) 21.9% (2812)\nCreative/Expressive 85.7% (7) 85.7% (7) 85.7% (7) 57.1% (7) 57.1% (7) 28.6% (7) 0.0% (7)\n\n**Mean** **81.3%** **77.7%** **74.5%** **64.7%** **63.6%** **41.9%** **27.8%**\n\nTable 6: Accuracy by problem type and model (Part 2) and average across all models.\n\n|Problem Type R1-Llama-70B R1-Llama-8B Hermes-8B OpenThinker DeepScaleR s1.1-32B R1-671B|Avg.|\n|---|---|\n|Algorithmic<br>68.3% (6276)<br>50.9% (6269)<br>31.0% (6276)<br>72.4% (6275)<br>50.6% (6195)<br>61.9% (6276)<br>81.6% (6276)<br>Story Problem<br>83.2% (113)<br>73.5% (113)<br>57.5% (113)<br>85.0% (113)<br>77.3% (110)<br>72.6% (113)<br>87.6% (113)<br>Rule-Using<br>57.9% (504)<br>36.1% (504)<br>32.9% (504)<br>75.0% (504)<br>30.5% (502)<br>49.0% (504)<br>85.7% (504)<br>Decision-Making<br>64.6% (99)<br>48.5% (99)<br>40.4% (99)<br>74.7% (99)<br>14.1% (99)<br>57.6% (99)<br>81.2% (85)<br>Troubleshooting<br>70.3% (91)<br>38.5% (91)<br>46.2% (91)<br>76.9% (91)<br>8.8% (91)<br>70.3% (91)<br>88.9% (90)<br>Diagnosis-Solution<br>60.2% (83)<br>24.1% (83)<br>24.1% (83)<br>67.5% (83)<br>3.6% (83)<br>56.6% (83)<br>88.0% (83)<br>Case Analysis<br>72.7% (121)<br>41.3% (121)<br>28.1% (121)<br>83.5% (121)<br>3.3% (121)<br>57.0% (121)<br>94.3% (106)<br>Design<br>51.6% (157)<br>31.0% (155)<br>22.3% (157)<br>68.2% (157)<br>8.4% (155)<br>50.3% (157)<br>87.0% (131)<br>Dilemma<br>95.6% (1168)<br>93.7% (1167)<br>89.6% (1168)<br>98.5% (1168)<br>3.4% (1168)<br>93.8% (1168)<br>100.0% (1)<br>Logical<br>66.7% (60)<br>28.3% (60)<br>25.0% (60)<br>70.0% (60)<br>22.4% (58)<br>60.0% (60)<br>88.3% (60)<br>Factual Recall<br>73.6% (2819)<br>47.3% (2819)<br>46.4% (2819)<br>80.2% (2819)<br>22.0% (2814)<br>67.8% (2819)<br>88.0% (2815)<br>Creative/Expressive<br>57.1% (7)<br>57.1% (7)<br>42.9% (7)<br>57.1% (7)<br>14.3% (7)<br>42.9% (7)<br>85.7% (7)|63.8%<br>79.5%<br>54.4%<br>55.7%<br>54.6%<br>44.7%<br>53.5%<br>46.6%<br>82.4%<br>56.4%<br>61.8%<br>54.1%|\n|**Mean**<br>**68.5%**<br>**47.5%**<br>**40.5%**<br>**75.8%**<br>**21.6%**<br>**61.7%**<br>**88.0%**|**59.0%**|\n\n**Frontier Model Performance** **DeepSeek-R1-671B** (88.0% average) establishes the performance ceiling across nearly all problem types, achieving 81\u201388% on most categories. This 671B parameter MoE model\n(37B activated) underwent extensive multi-stage RL training, demonstrating the capabilities achievable with\nflagship-scale resources. Notably, R1-671B shows smallest gains over smaller models on Dilemma (100.0%\nwith only 1 sample\u2014unreliable) and Story Problems (87.6%), suggesting these problem types saturate more\nquickly with model capability. Largest improvements appear on ill-structured problems: Diagnosis-Solution\n(+43% over average), Case Analysis (+41%), and Design (+40%), confirming that complex multi-step reasoning benefits most from scale and sophisticated training.\n\n**Training Methodology Effects** Performance patterns strongly reflect training approaches. The **Qwen3**\n**series** (32B: 81.3%, 14B: 77.7%, 8B: 74.5%) achieves consistently strong performance approaching R1-671B\u2019s\nfrontier results, with the 32B variant achieving second-highest average accuracy across all models. This stems\nfrom comprehensive 4-stage RL training (cold-start SFT, reasoning RL with GRPO, thinking mode fusion,\ngeneral RL) for the 32B flagship, followed by efficient strong-to-weak distillation for smaller variants. The\nsmooth degradation (32B\u219214B: -3.6%, 14B\u21928B: -3.2%) demonstrates effective knowledge transfer through\nthe two-phase distillation approach.\n\n**OpenThinker-32B** (75.8% average) achieves third-highest performance despite using only 114K verified\nexamples\u201486% less data than DeepSeek\u2019s 800K distillation corpus. This model demonstrates that data\nquality trumps quantity, outperforming all R1 distillations except the 70B Llama variant. OpenThinker\u2019s\nautomated verification process (code execution for programming, LLM judge validation for mathematics)\nfilters incorrect reasoning traces, producing cleaner training signals. Particularly strong on problems with\nobjective correctness criteria: Story Problems (85.0%), Case Analysis (83.5%), Factual Recall (80.2%).\n\n**DeepSeek-R1 distillations** show clear scaling effects. The Qwen-based variants (32B: 64.7%, 14B: 63.6%,\n7B: 41.9%, 1.5B: 27.8%) demonstrate smooth performance degradation with model size under pure knowledge\ntransfer via SFT on 800K teacher-generated examples. The Llama-based variants (70B: 68.5%, 8B: 47.5%)\nrequire substantially more parameters for equivalent performance\u2014R1-Llama-70B needs 2.2\u00d7 the parameters\n\n39\n\nof R1-Qwen-32B to achieve similar accuracy (68.5% vs 64.7%), confirming Qwen2.5\u2019s superior parameter\nefficiency for reasoning tasks.\n\n**Problem Type Variability and Training Robustness** Inter-model variance reveals which problem\ntypes expose training methodology differences. **Dilemma problems** show extreme variance (range: 3.2%\u2013\n100.0%, SD _\u2248_ 38%), with most models achieving high accuracy (90\u201399%) except the smallest distilled\nmodels (R1-Qwen-1.5B: 3.2%, DeepScaleR-1.5B: 3.4%). This suggests dilemma reasoning\u2014requiring articulation and balancing of multiple contradictory positions\u2014collapses catastrophically below critical capacity\nthresholds around 7\u20138B parameters. The 100% score for R1-671B reflects only a single evaluation sample\nand should not be interpreted as reliable.\n\n**Diagnosis-Solution problems** exhibit the largest absolute variance (2.4%\u201388.0%, SD _\u2248_ 28%), with severe\ndegradation in smaller distilled models. R1-Qwen-7B drops precipitously to 4.8%, R1-Qwen-1.5B to 2.4%,\nand DeepScaleR-1.5B to 3.6%, while 30B+ models maintain 47\u201388% accuracy. This problem type requires\ncoordinated fault identification and treatment evaluation\u2014a multi-step reasoning process demanding sustained working memory and systematic hypothesis testing that smaller models cannot maintain coherently.\n\n**Story Problems** show relatively consistent performance (range: 57.5%\u201392.0%, SD _\u2248_ 10%), suggesting these\nwell-structured problems are more robust to model capacity and training methodology differences. Even\nthe smallest models (R1-Qwen-1.5B: 66.1%, DeepHermes-3-8B: 57.5%, DeepScaleR-1.5B: 77.3%) maintain\nreasonable performance.\n\n**Sample Size Considerations** Problem type representation varies dramatically. **Algorithmic problems**\ndominate with 6,027\u20136,276 instances per model (59% of dataset). **Factual Recall** (2,812\u20132,819 instances,\n27%) and **Dilemma** (1\u20131,168 instances, 11%) also show substantial representation for most models, though\nR1-671B\u2019s single Dilemma sample renders its 100% score statistically meaningless. **Creative/Expressive**\nhas only 7 examples, making results for this category unreliable.\n\n40"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves framing large language model (LLM) reasoning as a set of observable behaviors that can be systematically categorized using a cognitive taxonomy, much like defining states in a state machine or objects in an inheritance hierarchy. The paper highlights that current LLM training lacks a predictive mapping function from training data and architecture to emergent capabilities, resembling a black box system without a clear API specification. The proposed solution is to use principles from cognitive science as a theoretical framework to engineer training procedures. For instance, to improve 'generalization' (the ability to transfer learned skills to new, structurally similar problems), the mechanism involves moving LLMs from superficial pattern matching (like a simple string comparison) to abstract schema formation (like recognizing a regular expression or a design pattern). This is achieved by designing training curricula that force explicit comparison of diverse examples to extract common structure, and by rewarding the selection of strategies based on problem structure rather than surface features. This is analogous to teaching a parser to build an abstract syntax tree rather than just matching tokens. To validate 'genuine' capabilities, the mechanism shifts from mere behavioral observation to systematic probing (like unit tests and integration tests) that check for 'invariants' such as systematic transfer, robustness to perturbations, and compositional deployment, akin to verifying function properties beyond just a correct return value.\n\n**Explanation:** The paper essentially argues that LLMs are currently 'overfitting' to the surface features of their training data, leading to brittle reasoning that doesn't transfer well. We don't have a clear 'design document' for how their internal 'code' (reasoning capabilities) is constructed from 'build instructions' (training procedures). Cognitive science offers 'design patterns' or 'established algorithms' for how intelligent systems should learn and generalize. For example, to teach a program to identify abstract patterns, you wouldn't just feed it exact matches; you'd give it varied examples that highlight the underlying commonality and perhaps ask it to explain *why* a particular strategy applies, forcing it to generate a 'mental model' (schema). The paper also proposes 'reward shaping' as a mechanism to encourage specific internal 'computation paths' like meta-cognition. This is like instrumenting your code with multiple assertion points beyond just the final output, and rewarding the program for hitting these intermediate, desired states. This allows 'exploration' to discover more diverse problem-solving strategies, rather than just optimizing for a single, terminal 'correct' flag. The extensive accuracy tables act as a benchmark suite, showing that larger, more complex models, especially those with multi-stage RL training, perform better on 'ill-structured' problems (which require more adaptable 'algorithms'), while models trained with high-quality, verified data can achieve competitive results with less overall data, indicating that 'data quality' can be a more efficient 'compiler' for capability than sheer data 'quantity'."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_for all such j with output 1, Rj < Ri_ **then**\n\n**3** From this point onward, disregard the rest of the algorithm; if `BeenCheated` is\n**true**, then output _\u22a5_, else output 0, in every round where node _i_ is still\n\nUndecided."}, {"role": "assistant", "content": "**Mechanism:** This describes a critical-path override within a looping process. It's a conditional 'goto' or an 'early_exit' flag in a state machine. When a specific pre-condition (the rank comparison Rj < Ri for all relevant j) is met, the system transitions to a simplified, high-priority decision loop. This loop essentially short-circuits the main algorithm, preventing further complex computation.\n\n**Explanation:** The core idea is to establish a hard exit or a fallback state based on a detected condition. Think of a distributed algorithm running in rounds (a 'while' loop, for 'i' being 'Undecided'). If node 'i' observes that its 'rank' (Ri) is higher than all other nodes ('j') that have already committed to a '1' output, it triggers a decisive state. From this moment, all other complex logic for node 'i' is discarded (like a 'return' or 'break' that skips the rest of the function or loop iteration). Node 'i' then enters a simple 'if-else' block: if a 'BeenCheated' flag (a boolean state variable) is true, it outputs an error ('.'), indicating an irrecoverable inconsistency or malicious behavior. Otherwise, it outputs a default 'no decision' ('0'). This continues in subsequent rounds as long as node 'i' hasn't reached a final decision. This mechanism ensures deterministic and resource-efficient termination, especially in the presence of faults or specific synchronization patterns indicated by the rank system."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) \u2208 _\ud835\udf0f_ 0 **then**\n\n**21** vol_sum. _\ud835\udc34\ud835\udc51\ud835\udc51_ (DFSin[ _\ud835\udc63_ ], DFSout[ _\ud835\udc63_ ], vol[ _\ud835\udc63_ ]\u22122 _\ud835\udc5a_ ) ;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism performs a conditional data aggregation. It filters graph nodes based on a membership test (node 'v' and its parent/partner 'p(v)' belonging to set '\u03c40') and, if true, updates a cumulative sum ('vol_sum') with specific numerical properties of 'v'.\n\n**Explanation:** Think of this as a step in a graph traversal algorithm, like a Depth-First Search (DFS). The line `(v, p(v)) \u2208 \u03c40` acts like an `if` statement checking a condition: 'Is the current node `v` and its direct relation `p(v)` part of a special, pre-defined group `\u03c40`?' If that condition is true, we then update a central data structure, `vol_sum`. The `Add` function takes three values related to node `v`: `DFSin[v]` (the 'timestamp' when DFS first visited `v`), `DFSout[v]` (the 'timestamp' when DFS finished processing `v` and all its children), and `vol[v] - 2m` (some calculated 'volume' or 'weight' for `v`, adjusted by a constant `2m`). These DFS timestamps are like pointers indicating an interval in a sequence, and we're adding the adjusted volume to an aggregate that likely manages these intervals, similar to how you'd update values in a Fenwick tree or segment tree based on an index range."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nTo conclude, TLT alleviates the critical long-tail bottleneck\nin reasoning RL training through an adaptive drafter. The\nadaptivity operates on two folds: during training, it adapts to\ntarget model updates; during inference, it adapts to varying\nbatchsizes. As a result, TLT achieves substantial throughput\nimprovements while preserving model quality.\n\n**Acknowledgements**\n\nWe thank MIT-IBM Watson AI Lab, MIT AI Hardware Program, MIT Amazon Science Hub, Hyundai Motor Company,\nand National Science Foundation for supporting this work.\n\n**References**\n\n[1] Arash Ahmadian, Chris Cremer, Matthias Gall\u00e9, Marzieh Fadaee, Julia\nKreutzer, Olivier Pietquin, Ahmet \u00dcst\u00fcn, and Sara Hooker. 2024. Back\nto Basics: Revisiting REINFORCE Style Optimization for Learning from\nHuman Feedback in LLMs. In _Proceedings of the 62nd Annual Meeting_\n_of the Association for Computational Linguistics (ACL \u201924)_ .\n\n[2] Zachary Ankner, Rishab Parthasarathy, Aniruddha Nrusimha, Christopher Rinard, Jonathan Ragan-Kelley, and William Brandon. 2024. Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding. In\n_Conference on Language Modeling (COLM \u201924)_ .\n\n[3] ByteDance. 2025. W&B trace of DAPO Reproduction on\nverl. [https://wandb.ai/verl-org/DAPO%20Reproduction%20on%](https://wandb.ai/verl-org/DAPO%20Reproduction%20on%20verl?nw=u7n2j5sht28)\n[20verl?nw=u7n2j5sht28](https://wandb.ai/verl-org/DAPO%20Reproduction%20on%20verl?nw=u7n2j5sht28)\n\n[4] Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D.\nLee, Deming Chen, and Tri Dao. 2024. Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads. _CoRR_\n[abs/2401.10774 (2024). https://arxiv.org/abs/2401.10774](https://arxiv.org/abs/2401.10774)\n\n[5] Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste\nLespiau, Laurent Sifre, and John Jumper. 2023. Accelerating Large\nLanguage Model Decoding with Speculative Sampling. _CoRR_\n[abs/2302.01318 (2023). https://arxiv.org/abs/2302.01318](https://arxiv.org/abs/2302.01318)\n\n[6] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan,\nPeng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wanxiang Che.\n2025. Towards Reasoning Era: A Survey of Long Chain-of-Thought\nfor Reasoning Large Language Models. _CoRR_ abs/2503.09567 (2025).\n[https://arxiv.org/abs/2503.09567](https://arxiv.org/abs/2503.09567)\n\n[[7] Codeforces. 2025. CodeForces Online Judge. https://codeforces.com/](https://codeforces.com/)\n\n[8] Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, Jiarui Yuan,\nHuayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu\nHan, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou,\nand Ning Ding. 2025. Process Reinforcement through Implicit Rewards.\n_CoRR_ [abs/2502.01456 (2025). https://arxiv.org/abs/2502.01456](https://arxiv.org/abs/2502.01456)\n\n[9] DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song,\nRuoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi,\nXiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong\nShao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang,\nBochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng,\nChenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang\nLi, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen,\nGuowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui\nDing, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi\nLi, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong\nLi, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao,\nKang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang\nZhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang,\nMinghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming\nLi, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu\nChen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang,\nR. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou,\nShuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao\nYun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao,\nWen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang,\nW. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen,\nXiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang,\nXinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin\nShen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song,\nXinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X.\nWei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui\nWang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi\nPiao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang\nGuo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X.\n\n13\n\nZhu, Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu,\nYunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren,\nZhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen\nHao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang,\nZhipeng Xu, Zhongyu Zhang, and Zhen Zhang. 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.\n_CoRR_ [abs/2501.12948 (2025). https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)\n\n[10] Hugging Face. 2025. Open R1: A fully open reproduction of DeepSeek[R1. https://github.com/huggingface/open-r1](https://github.com/huggingface/open-r1)\n\n[11] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.\n2023. GPTQ: Accurate Post-Training Quantization for Generative\nPre-trained Transformers. _CoRR_ abs/2210.17323 (2023). [https:](https://arxiv.org/abs/2210.17323)\n[//arxiv.org/abs/2210.17323](https://arxiv.org/abs/2210.17323)\n\n[12] Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He,\nShusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang\nYuan, and Yi Wu. 2025. AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning. _CoRR_ abs/2505.24298\n[(2025). https://arxiv.org/abs/2505.24298](https://arxiv.org/abs/2505.24298)\n\n[13] Yichao Fu, Peter Bailis, Ion Stoica, and Hao Zhang. 2024. Break the\nsequential dependency of llm inference using lookahead decoding.\n_arXiv preprint arXiv:2402.02057_ (2024).\n\n[14] Xiangxiang Gao, Weisheng Xie, Yiwei Xiang, and Feng Ji. 2025. Falcon:\nFaster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding\nTree. In _Proceedings of the AAAI Conference on Artificial Intelligence_\n_(AAAI \u201925)_ .\n\n[15] Gemini. 2025. Gemini 2.5 Pro Technical Report. [https:](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n[//blog.google/technology/google-deepmind/gemini-model-thinking-](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n[updates-march-2025/#gemini-2-5-pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro)\n\n[16] Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D. Lee, and Di He. 2024.\nREST: Retrieval-Based Speculative Decoding. _CoRR_ abs/2311.08252\n[(2024). https://arxiv.org/abs/2311.08252](https://arxiv.org/abs/2311.08252)\n\n[17] Pieter Hintjens. 2013. _ZeroMQ: messaging for many applications_ . \"\nO\u2019Reilly Media, Inc.\".\n\n[18] Jian Hu, Jason Klein Liu, and Shen Wei. 2025. REINFORCE++: An\nEfficient RLHF Algorithm with Robustness to Both Prompt and Reward\nModels. _CoRR_ [abs/2501.03262 (2025). https://arxiv.org/abs/2501.03262](https://arxiv.org/abs/2501.03262)\n\n[19] Diederik P Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In _International Conference on Learning Representa-_\n_tions (ICLR \u201915)_ .\n\n[20] Mario Michael Krell, Matej Kosec, Sergio P. Perez, and Andrew Fitzgibbon. 2022. Efficient Sequence Packing without Cross-contamination:\nAccelerating Large Language Models without Impacting Performance.\n_CoRR_ [abs/2107.02027 (2022). https://arxiv.org/abs/2107.02027](https://arxiv.org/abs/2107.02027)\n\n[21] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin\nZheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica.\n2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In _Proceedings of the ACM SIGOPS 29th Sym-_\n_posium on Operating Systems Principles (SOSP \u201923)_ .\n\n[22] Yaniv Leviathan, Matan Kalman, and Yossi Matias. 2023. Fast Inference\nfrom Transformers via Speculative Decoding. In _Proceedings of the 40th_\n_International Conference on Machine Learning (ICML \u201923)_ . 19274\u201319286.\n\n[23] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer,\nHenryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil,\nImanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur,\nGuy Gur-Ari, and Vedant Misra. 2022. Solving Quantitative Reasoning\nProblems with Language Models. In _Advances in Neural Information_\n_Processing Systems (NeurIPS \u201922)_ .\n\n[24] Jia LI, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi,\nShengyi Costa Huang, Kashif Rasul, Longhui Yu, Albert Jiang, Ziju\nShen, Zihan Qin, Bin Dong, Li Zhou, Yann Fleureau, Guillaume Lample,\n[and Stanislas Polu. 2025. NuminaMath. https://huggingface.co/AI-](https://huggingface.co/AI-MO/NuminaMath-CoT)\n[MO/NuminaMath-CoT.](https://huggingface.co/AI-MO/NuminaMath-CoT)\n\n[25] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2024.\nEAGLE-2: Faster Inference of Language Models with Dynamic Draft\nTrees. In _Proceedings of the 2024 Conference on Empirical Methods in_\n_Natural Language Processing (EMNLP \u201924)_ .\n\n[26] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2024. EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty.\nIn _Proceedings of the 41st International Conference on Machine Learning_\n_(ICML \u201924)_ .\n\n[27] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. 2025.\nEAGLE-3: Scaling up Inference Acceleration of Large Language Models\nvia Training-Time Test. _CoRR_ [abs/2503.01840 (2025). https://arxiv.org/](https://arxiv.org/abs/2503.01840)\n[abs/2503.01840](https://arxiv.org/abs/2503.01840)\n\n[28] Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang,\nQinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming\nChen, Sean Lai, Xupeng Miao, and Zhihao Jia. 2025. AdaServe: SLOCustomized LLM Serving with Fine-Grained Speculative Decoding.\n_CoRR_ [abs/2501.12162v1 (2025). https://arxiv.org/abs/2501.12162](https://arxiv.org/abs/2501.12162)\n\n[29] Baohao Liao, Yuhui Xu, Hanze Dong, Junnan Li, Christof Monz,\nSilvio Savarese, Doyen Sahoo, and Caiming Xiong. 2025. RewardGuided Speculative Decoding for Efficient LLM Reasoning. _CoRR_\n[abs/2501.19324 (2025). https://arxiv.org/abs/2501.19324](https://arxiv.org/abs/2501.19324)\n\n[30] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen,\nWei-Chen Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, and\nSong Han. 2024. AWQ: Activation-aware Weight Quantization for\nLLM Compression and Acceleration. _CoRR_ abs/2306.00978 (2024).\n[https://arxiv.org/abs/2306.00978](https://arxiv.org/abs/2306.00978)\n\n[31] Xiaoxuan Liu, Lanxiang Hu, Peter Bailis, Alvin Cheung, Zhijie Deng,\nIon Stoica, and Hao Zhang. 2024. Online Speculative Decoding. In\n_International Conference on Learning Representations (ICML \u201924)_ .\n\n[32] Alexander Lyzhov, Yuliya Molchanova, Arsenii Ashukha, Dmitry\nMolchanov, and Dmitry Vetrov. 2020. Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation. In _Proceedings of_\n_the 36th Conference on Uncertainty in Artificial Intelligence (UAI \u201920)_ .\n\n1308\u20131317.\n\n[33] Xinyin Ma, Gongfan Fang, and Xinchao Wang. 2023-12-15. LLMPruner: On the Structural Pruning of Large Language Models. In _Ad-_\n_vances in Neural Information Processing Systems (NeurIPS \u201923)_ .\n\n[34] MAA. 2024. American Invitational Mathematics Examination [AIME. https://artofproblemsolving.com/wiki/index.php/American_](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination)\n[Invitational_Mathematics_Examination](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination)\n\n[35] Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, and\nYi Wu. 2024. ReaLHF: Optimized RLHF Training for Large Language\nModels through Parameter Reallocation. _CoRR_ abs/2406.14088 (2024).\n[https://arxiv.org/abs/2406.14088](https://arxiv.org/abs/2406.14088)\n\n[36] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu\nWang, Zhengxin Zhang, Rae Ying Yee Wong, Alan Zhu, Lijie Yang, Xiaoxiang Shi, Chunan Shi, Zhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao Jia. 2024. SpecInfer: Accelerating Large Language\nModel Serving with Tree-based Speculative Inference and Verification.\nIn _Proceedings of the 29th ACM International Conference on Architectural_\n_Support for Programming Languages and Operating Systems, Volume 3_\n_(ASPLOS \u201924)_ . Association for Computing Machinery.\n\n[37] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov,\nRichard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul,\nMichael I. Jordan, and Ion Stoica. 2018. Ray: A Distributed Framework\nfor Emerging AI Applications. In _13th USENIX Symposium on Operating_\n_Systems Design and Implementation (OSDI \u201918)_ .\n\n[38] Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li FeiFei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel\nCand\u00e8s, and Tatsunori Hashimoto. 2025. s1: Simple test-time scaling.\n_arXiv preprint arXiv:2501.19393_ (2025).\n\n[[39] NVIDIA Corporation. 2025. NVIDIA DGX H100. https://www.nvidia.](https://www.nvidia.com/en-gb/data-center/dgx-h100/)\n[com/en-gb/data-center/dgx-h100/.](https://www.nvidia.com/en-gb/data-center/dgx-h100/)\n\n14\n\n[40] OpenAI, Ahmed El-Kishky, Alexander Wei, Andre Saraiva, Borys\nMinaiev, Daniel Selsam, David Dohan, Francis Song, Hunter Lightman, Ignasi Clavera, Jakub Pachocki, Jerry Tworek, Lorenz Kuhn,\nLukasz Kaiser, Mark Chen, Max Schwarzer, Mostafa Rohaninejad, Nat\nMcAleese, o3 contributors, Oleg M\u00fcrk, Rhythm Garg, Rui Shu, Szymon Sidor, Vineet Kosaraju, and Wenda Zhou. 2025. Competitive\nProgramming with Large Reasoning Models. _CoRR_ abs/2502.06807\n[(2025). https://arxiv.org/abs/2502.06807](https://arxiv.org/abs/2502.06807)\n\n[41] OpenThoughts. 2025. open-thoughts/OpenThoughts2-1M.\nhttps://huggingface.co/datasets/open-thoughts/OpenThoughts2-1M.\n\n[42] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina\nSlama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models\nto follow instructions with human feedback. In _Advances in Neural_\n\n_Information Processing Systems (NeurIPS \u201922)_ .\n\n[43] Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, and\nRavi Netravali. 2025. SpecReason: Fast and Accurate Inference-Time\nCompute via Speculative Reasoning. _CoRR_ pdf/2504.07891 (2025).\n[https://arxiv.org/abs/2504.07891](https://arxiv.org/abs/2504.07891)\n\n[[44] PyTorch Team. 2025. PyTorch FSDP2. https://docs.pytorch.org/docs/](https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html)\n[stable/distributed.fsdp.fully_shard.html.](https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html)\n\n[[45] PyTorch Team. 2025. Torch Distributed Checkpoint Document. https:](https://pytorch.org/docs/stable/distributed.checkpoint.html)\n[//pytorch.org/docs/stable/distributed.checkpoint.html](https://pytorch.org/docs/stable/distributed.checkpoint.html)\n\n[46] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo\nZheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran\nWei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin\nBao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui\nMen, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren,\nXuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong\nLiu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2025. Qwen2.5 Technical\nReport. _CoRR_ [abs/2412.15115 (2025). https://arxiv.org/abs/2412.15115](https://arxiv.org/abs/2412.15115)\n\n[47] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He.\n2020. ZeRO: Memory Optimizations toward Training Trillion Parameter Models. In _Proceedings of the International Conference for High_\n_Performance Computing, Networking, Storage and Analysis (SC \u201920)_ .\n\n[[48] Apoorv Saxena. 2023. Prompt Lookup Decoding. https://github.com/](https://github.com/apoorvumang/prompt-lookup-decoding/)\n[apoorvumang/prompt-lookup-decoding/](https://github.com/apoorvumang/prompt-lookup-decoding/)\n\n[[49] John Schulman. 2020. Approximating KL Divergence. http://joschu.](http://joschu.net/blog/kl-app rox.html)\n[net/blog/kl-approx.html](http://joschu.net/blog/kl-app rox.html)\n\n[50] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and\nOleg Klimov. 2017. Proximal Policy Optimization Algorithms. _CoRR_\n(2017).\n\n[51] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao\nBi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo.\n2024. DeepSeekMath: Pushing the Limits of Mathematical Reasoning\nin Open Language Models. _CoRR_ [abs/2402.03300 (2024). https://arxiv.](https://arxiv.org/abs/2402.03300)\n[org/abs/2402.03300](https://arxiv.org/abs/2402.03300)\n\n[52] Gerald Shen, Zhilin Wang, Olivier Delalleau, Jiaqi Zeng, Yi Dong,\nDaniel Egert, Shengyang Sun, Jimmy J. Zhang, Sahil Jain, Ali\nTaghibakhshi, Markel Sanz Ausin, Ashwath Aithal, and Oleksii\nKuchaiev. 2024. NeMo-Aligner: Scalable Toolkit for Efficient Model\nAlignment. In _Conference on Language Modeling (COLM \u201924)_ .\n\n[53] Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang,\nRu Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. 2025. HybridFlow: A Flexible and Efficient RLHF Framework. In _Proceedings of_\n_the Twentieth European Conference on Computer Systems (EuroSys \u201925)_ .\nAssociation for Computing Machinery.\n\n[54] Aleksandrs Slivkins et al. 2019. Introduction to multi-armed bandits.\n_Foundations and Trends\u00ae in Machine Learning_ 12, 1-2 (2019), 1\u2013286.\n\n[[55] Chang Su. 2025. https://github.com/sgl-project/sglang/pull/4732.](https://github.com/sgl-project/sglang/pull/4732)\n\n[56] Qwen Team. 2025. QwQ-32B: Embracing the Power of Reinforcement\n[Learning. https://qwenlm.github.io/blog/qwq-32b/](https://qwenlm.github.io/blog/qwq-32b/)\n\n[57] Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\nJordan, Ken Goldberg, and Joseph E. Gonzalez. 2021. Resource Allocation in Multi-armed Bandit Exploration: Overcoming Sublinear\nScaling with Adaptive Parallelism. In _Proceedings of the 38th Interna-_\n_tional Conference on Machine Learning (ICML \u201921)_ .\n\n[58] Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou\nDai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng\nXie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen,\nYu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, and Jianfeng Gao.\n2025. A Survey on Post-training of Large Language Models. _CoRR_\n[abs/2503.06072 (2025). https://arxiv.org/abs/2503.06072](https://arxiv.org/abs/2503.06072)\n\n[59] Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching,\nTristan Thrush, Nathan Lambert, Shengyi Huang, Kashif Rasul, and\nQuentin Gallou\u00e9dec. 2025. TRL: Transformer Reinforcement Learning.\n[https://github.com/huggingface/trl.](https://github.com/huggingface/trl)\n\n[60] Hanjing Wang, Man-Kit Sit, Congjie He, Ying Wen, Weinan Zhang,\nJun Wang, Yaodong Yang, and Luo Mai. 2023. GEAR: A GPU-Centric\nExperience Replay System for Large Reinforcement Learning Models.\nIn _Proceedings of the 40th International Conference on Machine Learning_\n_(ICML \u201923)_ .\n\n[61] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. _Machine learning_\n(1992).\n\n[62] Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, and Yiming Yang.\n2025. Inference Scaling Laws: An Empirical Analysis of ComputeOptimal Inference for Problem-Solving with Language Models. _CoRR_\n[abs/2408.00724 (2025). https://arxiv.org/abs/2408.00724](https://arxiv.org/abs/2408.00724)\n\n[63] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike\nLewis. 2024. Efficient Streaming Language Models with Attention\nSinks. In _International Conference on Learning Representations (ICLR_\n_\u201924)_ .\n\n[64] Youshao Xiao, Zhenglei Zhou, Fagui Mao, Weichang Wu, Shangchun\nZhao, Lin Ju, Lei Liang, Xiaolu Zhang, and Jun Zhou. 2024. An Adaptive\nPlacement and Parallelism Framework for Accelerating RLHF Training.\n_CoRR_ [pdf/2312.11819 (2024). https://arxiv.org/abs/2312.11819](https://arxiv.org/abs/2312.11819)\n\n[65] Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang,\nConglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly\nSmith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, and Yuxiong He. 2023. DeepSpeed-Chat: Easy, Fast\nand Affordable RLHF Training of ChatGPT-like Models at All Scales.\n_CoRR_ [abs/2308.01320 (2023). https://arxiv.org/abs/2308.01320](https://arxiv.org/abs/2308.01320)\n\n[66] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu\nYue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi\nLin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan\nZhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen,\nChengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng Wei,\nHao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao,\nYonghui Wu, and Mingxuan Wang. 2025. DAPO: An Open-Source\nLLM Reinforcement Learning System at Scale. _CoRR_ pdf/2503.14476\n[(2025). https://arxiv.org/abs/2503.14476](https://arxiv.org/abs/2503.14476)\n\n[67] Lefan Zhang, Xiaodan Wang, Yanhua Huang, and Ruiwen Xu. 2025.\nLearning Harmonized Representations for Speculative Sampling. In\n_International Conference on Learning Representations (ICLR \u201925)_ .\n\n[68] Yao Zhao, Zhitian Xie, Chen Liang, Chenyi Zhuang, and Jinjie Gu.\n2024. Lookahead: An Inference Acceleration Framework for Large\nLanguage Model with Lossless Generation Accuracy. In _Proceedings of_\n_the 30th ACM SIGKDD Conference on Knowledge Discovery and Data_\n_Mining (KDD \u201924)_ . Association for Computing Machinery.\n\n[69] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P\n\n15\n\nXing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging\nLLM-as-a-judge with MT-Bench and Chatbot Arena. _CoRR_ (2023).\n\n[70] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Sun, Jeff\nHuang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica,\nJoseph E. Gonzalez, Clark Barrett, and Ying Sheng. 2024. SGLang:\nEfficient Execution of Structured Language Model Programs. In _Ad-_\n_vances in Neural Information Processing Systems (NeurIPS \u201924)_ .\n\n[71] Yinmin Zhong, Zili Zhang, Xiaoniu Song, Hanpeng Hu, Chao Jin,\nBingyang Wu, Nuo Chen, Yukun Chen, Yu Zhou, Changyi Wan,\n\nHongyu Zhou, Yimin Jiang, Yibo Zhu, and Daxin Jiang. 2025. StreamRL:\nScalable, Heterogeneous, and Elastic RL for LLMs with Disaggregated\nStream Generation. _CoRR_ [abs/2504.15930 (2025). https://arxiv.org/](https://arxiv.org/abs/2504.15930)\n[abs/2504.15930](https://arxiv.org/abs/2504.15930)\n\n[72] Yinmin Zhong, Zili Zhang, Bingyang Wu, Shengyu Liu, Yukun Chen,\nChangyi Wan, Hanpeng Hu, Lei Xia, Ranchen Ming, Yibo Zhu, and\nXin Jin. 2025. Optimizing RLHF Training for Large Language Models\nwith Stage Fusion. In _22nd USENIX Symposium on Networked Systems_\n_Design and Implementation (NSDI \u201925)_ .\n\n16"}, {"role": "assistant", "content": "**Mechanism:** TLT employs an 'adaptive drafter' to predict and pre-compute subsequent steps in a reasoning RL process. During training, this drafter dynamically adjusts its prediction strategy to align with the main model's evolving parameter updates (target model updates). This is akin to a lookahead buffer whose prediction function is continuously re-tuned based on the primary system's learning trajectory. During inference, the drafter's parallelization or prediction depth adapts to the current batchsize, effectively scaling its speculative execution capabilities to the available workload concurrency.\n\n**Explanation:** The core problem in reasoning Reinforcement Learning is that processing rare but complex states (the 'long-tail bottleneck') can severely slow down the overall training and inference. TLT tackles this with a smart 'drafter' \u2013 a sub-model that speculatively generates a sequence of probable next steps. Crucially, this drafter isn't static. When the main RL model is learning, the drafter observes the main model's policy shifts and refines its own internal rules to make better, more relevant guesses. This is like having a dynamic cache for future computation that always stores the most relevant predictions. When the main model is actually solving problems (inference), the drafter adjusts its guessing parallelism based on how many problems are being solved at once (batch size). If there's a big batch, it guesses more in parallel; if it's a small batch, it conserves resources, ensuring maximum speed without compromising the final answer quality."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each selected tree \ud835\udf0f_ **do**\n\n**6** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ \u02dc [\u2032] \u2212 _\ud835\udc53_ ( _\ud835\udf0f_ )/| _\ud835\udc46_ | _,_ _\ud835\udc46_ [\u2032] \u2190 _\ud835\udc46_ [\u2032] \\ _\ud835\udf0f_ ;\n\n**7** _\ud835\udf0f_ [\u2032] \u2190 wilson ( _\ud835\udc3a_ [\u2032] _,_ ( _\ud835\udc62, \ud835\udc63_ ));\n\n**8** Redirect edges in _\ud835\udf0f_ [\u2032] to point towards _\ud835\udc5f_ ;\n\n**9** _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] ) \u2190DFS ( _\ud835\udc5f,\ud835\udf0f_ [\u2032] _,\ud835\udf0f_ 0 );\n\n**10** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ \u02dc [\u2032] + _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] )/| _\ud835\udc46_ | _,_ _\ud835\udc46_ [\u2032] \u2190 _\ud835\udc46_ [\u2032] \u222a _\ud835\udf0f_ [\u2032] ;\n\n**11 if** _Update is_ Del ( _\ud835\udc62, \ud835\udc63_ ) **then**"}, {"role": "assistant", "content": "**Mechanism:** This mechanism performs an iterative 'replace and update' operation on a collection of graph structures, specifically trees. For each selected tree, its current contribution to a global aggregate metric is subtracted, and the tree is removed from the active set. A new tree is then generated from the underlying graph (likely a spanning tree using Wilson's algorithm), oriented towards a root node, and its specific metric is computed via a depth-first search. Finally, this new tree is added to the collection, and its proportional contribution updates the global aggregate. This ensures the collection and the aggregate metric remain representative of the graph's current state, especially after topology changes.\n\n**Explanation:** At its core, this loop is about maintaining a dynamic sample or collection of 'trees' (subgraphs) within a larger graph. Think of `S` as a dynamic array or hash set holding references to these trees. `\u03ba\u02dc[\u2032]` is a running total or average property across all trees in `S`. When an update is needed (e.g., an edge is deleted, as suggested by line 11), the system iterates through certain trees. For each `\u03c4`, it's removed from `S`, and its `f(\u03c4)` value is proportionally removed from `\u03ba\u02dc[\u2032]`. Then, `wilson(G[\u2032], (u,v))` acts like a constructor, creating a new `\u03c4'` based on the current graph state `G'`. The 'redirect edges' step is crucial for making `\u03c4'` a rooted tree, ensuring a consistent directionality. `DFS` then efficiently computes some property `f(\u03c4')` from this rooted tree. Finally, `\u03c4'` is added to `S`, and its `f(\u03c4')` contribution is added to `\u03ba\u02dc[\u2032]`. This continuous cycle keeps the collection `S` and the aggregate `\u03ba\u02dc[\u2032]` consistent and up-to-date with changes in `G'`, essentially performing a localized rebuild and re-evaluation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Random Walk Computation.** Random walks have long served\nas a fundamental tool in graph analysis, supporting a wide range of\napplications such as recommendation [38, 49, 57], network embedding [16, 40, 60], and complex network analysis [43, 50]. Various random walk-based metrics, personalized PageRank (PPR) [32, 46, 54]\nand effective resistance (ER) [7, 39, 45, 55] have received a lot of\nattention. For both PPR and ER, local algorithms such as push are\ncommonly used in recent studies [3, 28, 46], as they operate efficiently on a small portion of the graph without requiring full access\nto its structure. Although KC is also inherently related to random\nwalks, it represents a fundamentally global measure, distinct from\nthese problems, which makes existing techniques developed for\nPPR and ER unsuitable for direct application to KC computation.\n\n**Algorithms on Dynamic Graphs.** Dynamic graphs, also known\nas evolving graphs or graphs in an incremental setting, naturally\narise in real-world applications where graph data is continuously\nupdated. The design of algorithms for various graph problems\nin dynamic graphs has been an active research area for decades.\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\nIn particular, dynamic algorithms for random walk-based metrics, such as Personalized PageRank, have been extensively studied [19, 26, 53, 59, 61]. Most dynamic algorithms build upon their\ncorresponding static versions. For example, LazyForward [59] and\nTrackingPPR [36] were both developed as extensions of the push\nalgorithm [3]. Similarly, various index update methods for random walks [6, 19, 35] and power iteration-based dynamic algorithms [26, 58] have been explored. Recently, Liao et al. investigated the connection between USTs and both Personalized PageRank [27, 30] and effective resistance [28] successively. These methods provide a foundation for extending our index maintenance\nstrategy, as shown in Section 4, to these problems, facilitating the\ndevelopment of efficient dynamic algorithms."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism involves using random walks to characterize graph structure. For metrics like PageRank, a 'push' algorithm works by diffusing influence locally, like sending out packets that decay over distance. However, for a global metric like Kemeny Constant (KC), this local diffusion isn't sufficient because KC captures an aggregate property across all nodes, requiring a holistic view.\n\n**Explanation:** Think of a graph as a system of interconnected nodes. When we calculate something like Personalized PageRank, it's often like simulating a message spreading from a source, getting weaker as it moves away. We only need to simulate it for a short distance around the source. Kemeny Constant, however, isn't about how easily you get from one specific point to others nearby, but about the *average* time it takes to get *anywhere* from *anywhere else* in the entire graph. This means you can't just look at a small part of the graph; you need to understand the entire network's structure. Existing 'push' algorithms are like a highly optimized local search, great for specific neighborhoods but blind to the overall layout. When the graph changes, like adding or removing a connection, a global metric needs a smart way to update its value without re-calculating everything from scratch, which is where 'dynamic algorithms' come in, aiming to incrementally adjust rather than restart. The connection to Uniform Spanning Trees suggests a more fundamental mathematical perspective that might unlock efficient global updates."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_\ud835\udc5f\ud835\udc61\ud835\udc61_\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ == 0 **and** _\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61\ud835\udc60_\ud835\udc56\ud835\udc5b_\ud835\udc53\ud835\udc59\ud835\udc56\ud835\udc54\u210e\ud835\udc61_ \u2264 _\ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc40\ud835\udc56\ud835\udc5b\ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ **then**\n\n**111** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61_ _ _\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () + _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc37\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ ;\n\n**112** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61_ _ _\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**113** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_ _ _\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ ;"}, {"role": "assistant", "content": "**Mechanism:** This code block initiates or re-arms the 'Probe RTT' phase within the BBR congestion control algorithm. It triggers when a Probe RTT is not currently active and the network's outstanding data (packets_in_flight) is below a minimum, stable threshold (BBRMinPipeCwnd).\n\n**Explanation:** The primary objective here is to periodically re-measure the true, 'bare wire' Round Trip Time (RTT) of the network path, free from queuing delays. This is achieved by intentionally reducing the sender's congestion window to `BBRMinPipeCwnd`, a very small, fixed value designed to empty router buffers. The condition `BBR.probe_rtt_done_stamp == 0` acts as a state flag, indicating that a Probe RTT cycle isn't active, allowing a new one to begin. The second condition, `packets_in_flight <= BBRMinPipeCwnd`, ensures the network is not saturated when the probe starts, guaranteeing a clean measurement. Upon triggering, `BBR.probe_rtt_done_stamp` is set to the current time plus a `ProbeRTTDuration`, scheduling the completion of this low-rate period. `BBR.probe_rtt_round_done` is set to `false` to mark the probe as active, and `BBR.next_round_delivered` captures the current data delivered count, serving as a baseline (like a snapshot variable) to track progress within this specific RTT measurement phase."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n( _\ud835\udc5d_ ( _\ud835\udc63_ ) _, \ud835\udc63_ ) \u2208 _\ud835\udf0f_ 0 **then**\n\n**16** vol_sum. _\ud835\udc34\ud835\udc51\ud835\udc51_ (DFSin[ _\ud835\udc5d_ ( _\ud835\udc63_ )], DFSout[ _\ud835\udc5d_ ( _\ud835\udc63_ )], vol[ _\ud835\udc63_ ]\u22122 _\ud835\udc5a_ ) ;\n\n**17** _\ud835\udf05_ \u02dc \u2190 _\ud835\udc51_ ( _\ud835\udc63_ )\u00b7 vol_sum. _\ud835\udc44\ud835\udc62\ud835\udc52\ud835\udc5f\ud835\udc66_ (DFSin [ _\ud835\udc63_ ]);"}, {"role": "assistant", "content": "**Mechanism:** This code snippet uses an efficient data structure, likely a Fenwick tree (BIT) or Segment tree, operating on a linearized representation of a tree (or graph) using Depth-First Search (DFS) entry and exit times. The mechanism is a range update and point query system.\n\n**Explanation:** The core idea is to map tree substructures to contiguous ranges in a conceptual array. `DFSin[node]` and `DFSout[node]` are indices representing the start and end of a node's subtree when the tree is 'flattened' by a DFS traversal. The `vol_sum.Add` operation performs a range update: it adds a value (`vol[v] - 2m`) to all positions within the `DFSin[p(v)]` to `DFSout[p(v)]` range. This effectively attributes the value `vol[v] - 2m` to the entire subtree of `p(v)`. The `vol_sum.Query` operation then efficiently retrieves the cumulative sum of all values that have been 'added' to the specific point `DFSin[v]`. This is powerful because by querying at `DFSin[v]`, we get the aggregated contribution from all ancestor or relevant parallel subtrees that encompass the entry point of `v`, allowing for fast computation of sums over dynamically changing tree structures without explicit recursion."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n`UndecidedNeighbors` _is empty_ **then**\n\n**9** From this point onward, disregard the rest of the algorithm and Output 1 in\nevery round where node _i_ is still Undecided\n\n18\n\nWe prove Theorem 4.1 in three parts (Theorems 4.4, 4.5, and 4.6). Among these, Theorem 4.4\nrequires intermediate results, which we establish through Lemmas 4.2 and 4.3.\n\n**Lemma 4.2.** _Let the game be at an arbitrary history h with i \u2208_ _P_ ( _h_ ) _, where h \u2208_ _Ii \u2208Ii._\n_Suppose that one of i\u2019s_ _`UndecidedNeighbors`_ _(say, j) has its_ _`BeenCheated`_ _flag set to_ _`true`_ _._\n_Then, regardless of the history h and of i\u2019s strategy from h onward, if all the other nodes follow_\n_Algorithm 3 from h onward, the utility of node i will be at most_ 0 _._\n\n_Proof._ According to Algorithm 3, node _j_ outputs 0 only in Round 5 of an iteration, and even\nthen, only if its `BeenCheated` flag is `false` . Since the `BeenCheated` flag, once set to `true`, is\nnever reset to `false`, a node with `BeenCheated` = `true` will never output 0. Therefore, node _j_\nwill only output 1 or _\u22a5_ . In either case, the utility of _i_ is 0.\n\n**Lemma 4.3.** _Let the game be at an arbitrary history h with i \u2208_ _P_ ( _h_ ) _, where h \u2208_ _Ii \u2208Ii, and let_\n_hi be the local history of node i. Then, provided that all the undecided nodes follow Algorithm 3_\n_from this point onward, the utility of node i is at least_ 0 _._\n\n_Proof._ A node _i_ receives a utility less than zero (i.e., _\u2212\u221e_ ) only in two cases:\n\n1. _i_ outputs 0, and none of its neighbors also outputs 1, or\n\n2. _i_ outputs 1, and at least one of its neighbors also outputs 1.\n\n**Case 1** is not possible under the algorithm: a node is instructed to output 0 only in Round\n4, and only after observing at least one neighbor output 1. Hence, with any history where the\nnode _i_ is undecided in Round 3 outputs 0, it must be the case that a neighbor has already output\n1. Therefore, the first case cannot occur.\n**Case 2** is also prevented by the algorithm: a node outputs 1 only in Round 3 and only if:\n\n  - No neighbor has output 1 or _\u22a5_ in the previous rounds, and\n\n  - _i_ has the least rank compared to all its undecided Neighbors\n\nBecause all Undecided neighbors follow the algorithm, the nodes with rank less than _i_ will not\noutput 1 \u2013 they will either output 0 or _\u22a5_ in later Rounds.\nTherefore, following the algorithm ensures that node _i_ \u2019s utility is never less than 0.\n\n**Theorem 4.4.** _Algorithm 3 constitutes a Belief-Independent Sequential Equilibrium._\n\n_Proof._ Consider an arbitrary history _h_ with _i \u2208_ _P_ ( _h_ ). Let _hi_ denote the local history of node\n_i_, which implies _h \u2208_ _Ii_ ( _hi_ ) _\u2208Ii_ . We show that the continuation strategy prescribed for _i_ by\nAlgorithm 3 from information set _Ii_ ( _hi_ ) is sequentially rational irrespective of the _i_ \u2019s belief over\n_Ii_ ( _hi_ ), i.e., it gives the maximum expected payoff when all other nodes also follow Algorithm 3\nfrom _h_ . It follows that the strategy constitutes a sequential equilibrium for any belief system of\n_i_ . and it follows that the strategy constitutes a Belief-Independent Sequential Equilibrium. As\nwe mentioned in Section 2, we do not consider internal deviations; this indirectly means that\nnode _i_ knows exactly which line/round of the algorithm applies at _hi_ . We distinguish deviations\n\nas\n\n  - _Undetectable deviations:_ for example, choosing internal randomness _ri\u2192i, ri\u2192j_ with nonuniform probabilities. Since every sequence of ranks is still possible under the prescribed\nuniform strategy (albeit with small probability), neighbors can never rule out a deviation\nwith certainty, even after many observations. Similarly, voluntarily outputting 0 or _\u22a5_\nearlier than prescribed may also be indistinguishable, since it could be a valid response to\nanother neighbor having output 1, which remaining neighbors may not observe.\n\n19\n\n  - _Detectable deviations:_ e.g., failing to send a required/valid message, sending inconsistent\nmessages, or outputting 1 when not eligible. Such deviations are caught by at least one\nneighbor, which sets its `BeenCheated` flag to 1.\n\n**Case analysis.**\n\n_Case A: At h, i has a decided neighbor with output_ 1 _or \u22a5._ Then the maximum attainable\npayoff for _i_ is 0. By Lemma 4.3, following the algorithm yields a payoff of at least 0. Hence, no\nprofitable deviation exists, so the prescribed action is a best response.\n\n_Case B: At h, i do not have a decided neighbor with output_ 1 _or \u22a5_ _and there exists an_\n_undecided neighbor that i has cheated._ If the remaining undecided neighbors follow the algorithm,\nLemma 4.2 implies the most _i_ can obtain is 0; following the algorithm also yields payoff 0. Thus,\nno profitable deviation exists.\n\n_Case C: At h, i do not have a decided neighbor with output_ 1 _or \u22a5_ _and i has not cheated any_\n_undecided neighbor._\n\n  - _Detectable deviation by i:_ Some neighbor detects it and sets `BeenCheated` = 1. By\nLemma 4.2, the best payoff _i_ can then secure is 0. By Lemma 4.3, sticking to the algorithm yields payoff at most 0 and at least 0, so no profitable deviation exists.\n\n  - _Undetectable deviation by i:_ (1) Changing RPS mixing probabilities does not improve _i_ \u2019s\nwin probability against neighbors who randomize uniformly; _i_ \u2019s chance of joining the MIS\nis unchanged, so expected payoff is unchanged. (2) Voluntarily outputting 0 or _\u22a5_ can\nyield at most 0, whereas Lemma 4.3 guarantees sticking yields payoff at least 0. Hence,\nno profitable deviation exists.\n\nTherefore, we have shown that for every history _h_ with _i \u2208_ _P_ ( _h_ ), the prescribed strategy for\n_i_ based on _hi_ = proj _i_ ( _h_ ) gives maximum expected utility possible from _h_ when all other node\nare following the algorithm from _h_, which proves the theorem.\n\nWe have shown that Algorithm 3 forms a Belief-Independent Sequential Equilibrium. To\ncomplete the proof of Theorem 3.2, we now assume that all nodes follow the algorithm without\ndeviation. Under this honest execution, we analyze the simplified version of the algorithm (with\ndeviation-handling logic removed) and proceed to prove its correctness, termination, and nonzero\ninclusion probability.\n\n**4.2** **Strategy Algorithm without Deviations**\n\nSince we have established in Theorem 4.4 that Strategy Algorithm 3 constitutes a BeliefIndependent Sequential Equilibrium, no node has a unilateral incentive to deviate. When no\nnode deviates from the Strategy Algorithm 3, its execution is equivalent to running Algorithm 9,\nwhich is simply Strategy Algorithm 3 with the deviation handling logic removed.\nWe now proceed to prove the remaining claims of Theorem 4.1 on this deviation-free execution: namely, correctness (that the output forms a valid MIS), termination (with high probability), and positive inclusion probability (every node has a nonzero chance of joining the MIS).\n\n**Theorem 4.5** (Correctness and Termination) **.** _Algorithm 9 terminates in O_ (log _n_ ) _rounds with_\n_high probability, and the set of nodes that output_ 1 _at termination forms a valid Maximal Inde-_\n_pendent Set (MIS)._\n\n_Proof._ Algorithm 9 simulates the algorithm by M\u00b4etivier et al. [15] through verifiable random\npriority generation and decision-making rounds.\nEach iteration of Algorithm 9 consists of five communication rounds. This five-round process\nmirrors one round of the algorithm by M\u00b4etivier et al. [15]. Since that algorithm terminates in\n_O_ (log _n_ ) rounds with high probability and outputs a correct MIS, our algorithm also inherits\n\n20\n\n**Algorithm 9:** Rank based MIS strategy algorithm for node _i_ under no deviations\n\n**1 Initialization**\n\n**2** `UndecidedNeighbors` _\u2190_ _N_ ( _i_ ); `iteration` ~~`n`~~ `umber` _\u2190_ 0\n\n**3 if** _N_ ( _i_ ) = _\u2205_ **then**\n\n**4** Output 1\n\n**5 while** _i is_ Undecided **do**\n\n**6** `iteration` ~~`n`~~ `umber` _\u2190_ `iteration` `number` + 1;\n```\n   /* Round 1: Opponent Selection */\n```\n\n**7** Choose any _k \u2208_ `UndecidedNeighbors` as the opponent opp( _i_ ), and broadcast this\nchoice to all neighbors.\n```\n   /* Round 2: Priority Computation */\n```\n\n**8** Draw random _c_ log _n_ bit _ri\u2192i \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly at random and broadcast to all\nthe neighbors;"}, {"role": "assistant", "content": "**Mechanism:** The algorithm establishes a 'Belief-Independent Sequential Equilibrium' by rigorously disincentivizing any deviation. This is achieved through a utility function and state management where detectable cheating leads to a permanent 'BeenCheated' flag (a boolean state variable for each neighbor), effectively penalizing the cheater to a maximum utility of zero. Undetectable deviations are shown to either not improve a node's probability of success (e.g., manipulating random ranks) or actively lead to a worse outcome (e.g., voluntarily exiting early when following the algorithm guarantees a non-negative utility). Once game-theoretic stability is proven, the actual MIS formation (Algorithm 9) is shown to work by simulating a known, efficient, and correct distributed algorithm.\n\n**Explanation:** This section proves that no node has a rational incentive to deviate from the prescribed strategy (Algorithm 3). Lemma 4.3 guarantees that if a node follows the algorithm, its utility will never be negative. Conversely, Lemma 4.2 states that if a node has cheated a neighbor, its utility will be at most zero because the cheated neighbor, once its 'BeenCheated' flag is set (a persistent state like a boolean field in an object), will never output a '0', thereby preventing the cheater from gaining any positive utility. This creates a strong Nash Equilibrium where following the algorithm is always a best response. The proof then methodically covers various types of deviations: detectable ones (like sending inconsistent messages) are caught and flagged, leading to zero utility; undetectable ones (like subtly changing internal random number generation or prematurely opting out) are shown not to improve a node's expected payoff compared to following the algorithm. Since Algorithm 3 is stable against deviations, its behavior is equivalent to a simplified version (Algorithm 9) which lacks deviation-handling logic. Algorithm 9 is then proven correct and efficient by showing it functionally mirrors a pre-existing, proven distributed MIS algorithm, meaning it terminates in logarithmic time and correctly identifies an MIS."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn GEMM, symmetric tile buffering uses ( _\ud835\udc47\ud835\udc40,\ud835\udc47\ud835\udc3e,\ud835\udc47\ud835\udc41_ ) to define tile\nsizes for _\ud835\udc34_, _\ud835\udc35_, and _\ud835\udc36_, where _\ud835\udc34_ tile \u2208 R _[\ud835\udc47][\ud835\udc40]_ [\u00d7] _[\ud835\udc47][\ud835\udc3e]_, _\ud835\udc35_ tile \u2208 R _[\ud835\udc47][\ud835\udc3e]_ [\u00d7] _[\ud835\udc47][\ud835\udc41]_, and\n_\ud835\udc36_ tile \u2208 R _[\ud835\udc47][\ud835\udc40]_ [\u00d7] _[\ud835\udc47][\ud835\udc41]_ . Within each tile, consider the canonical loop order\nfor m in _\ud835\udc47\ud835\udc40_ { for n in _\ud835\udc47\ud835\udc41_ { for k in _\ud835\udc47\ud835\udc3e_ {}}}. For a fixed _\ud835\udc5a_,\nthe row _\ud835\udc34_ tile [ _\ud835\udc5a,_ :] is reused across all _\ud835\udc5b_ until the corresponding row\n_\ud835\udc36_ tile [ _\ud835\udc5a,_ :] has been fully accumulated, after which that row of _\ud835\udc34_ is\nno longer needed. In contrast, each row of _\ud835\udc36_ tile must remain live\nfor the entire reduction over _\ud835\udc3e_ (full problem or next-level tile size).\nBecause the lifetimes of _\ud835\udc34_ and _\ud835\udc36_ differ along the dimension _\ud835\udc40_, their\nbuffered extents do not need to be equal. This enables _asymmet-_\n_ric tile buffering_, parameterized by ( _\ud835\udc47\ud835\udc40\ud835\udc34,\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc3e,\ud835\udc47\ud835\udc41_ ), where _\ud835\udc47\ud835\udc40\ud835\udc34_\nbuffers rows of _\ud835\udc34_ and _\ud835\udc47\ud835\udc40\ud835\udc36_ buffers rows of _\ud835\udc36_ (Fig. 2). In this scheme,\n_\ud835\udc34_ tile \u2208 R _[\ud835\udc47][\ud835\udc40\ud835\udc34]_ [\u00d7] _[\ud835\udc47][\ud835\udc3e]_, _\ud835\udc35_ tile \u2208 R _[\ud835\udc47][\ud835\udc3e]_ [\u00d7] _[\ud835\udc47][\ud835\udc41]_, and _\ud835\udc36_ tile \u2208 R _[\ud835\udc47][\ud835\udc40\ud835\udc36]_ [\u00d7] _[\ud835\udc47][\ud835\udc41]_ ( _\ud835\udc47\ud835\udc40\ud835\udc36_ \u2265 _\ud835\udc47\ud835\udc40\ud835\udc34_ ).\n\n**3.1** **Arithmetic Intensity with ATB**\n\nLet _\ud835\udc4e,\ud835\udc4f,\ud835\udc50_ _>_ 0 be per-element byte costs (e.g., 2 for BF16 and 1.25\nfor BFP16) for _\ud835\udc34_, _\ud835\udc35_, and _\ud835\udc36_, and define the asymmetry ratio _\ud835\udf0c_ =\n_\ud835\udc47\ud835\udc40\ud835\udc36_ / _\ud835\udc47\ud835\udc40\ud835\udc34_ ( _\ud835\udf0c_ \u2265 1). We consider an output-stationary schedule: each\noutput tile is fully iterated _\ud835\udc41_ iterk = _\ud835\udc3e_ / _\ud835\udc47\ud835\udc3e_ times (reading _\ud835\udc34, \ud835\udc35_ each\ntime) and written once at the end, where _\ud835\udc3e_ is the problem size\n\nCan Asymmetric Tile Buffering Be Beneficial? Conference\u201917, July 2017, Washington, DC, USA\n\nalong the reduction dimension of the GEMM. For a tile of size\n( _\ud835\udc47\ud835\udc40\ud835\udc34,\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc3e,\ud835\udc47\ud835\udc41_ ), the arithmetic intensity is\n\n[p][erations]\n\n= [O][p][erations ][p][er out][p][ut tile]\nAccesses\n\nAI _\ud835\udf0c_ = [O][p][erations]\n\nAccesses per output tile\n\n= 2 _\ud835\udc47\ud835\udc40\ud835\udc36\ud835\udc47\ud835\udc3e\ud835\udc47\ud835\udc41_ _\ud835\udc41_ iterk\n_\ud835\udc4e\ud835\udc47\ud835\udc40\ud835\udc36\ud835\udc47\ud835\udc3e_ _\ud835\udc41_ iterk + _\ud835\udc4f\ud835\udc47\ud835\udc3e\ud835\udc47\ud835\udc41_ _\ud835\udc41_ iterk + _\ud835\udc50\ud835\udc47\ud835\udc40\ud835\udc36\ud835\udc47\ud835\udc41_\n\n= 2 _\ud835\udc3e\ud835\udc47\ud835\udc40\ud835\udc36\ud835\udc47\ud835\udc41_ = 2\n_\ud835\udc4e\ud835\udc47\ud835\udc40\ud835\udc36_ _\ud835\udc3e_ + _\ud835\udc4f\ud835\udc3e\ud835\udc47\ud835\udc41_ + _\ud835\udc50\ud835\udc47\ud835\udc40\ud835\udc36\ud835\udc47\ud835\udc41_ _\ud835\udc4e_ [+]\n\n_[\ud835\udc50]_ _,_\n\n_\ud835\udc3e_\n\n_\ud835\udc4e_ _\ud835\udc4f_ _[\ud835\udc50]_\n_\ud835\udc47\ud835\udc41_ [+] _\ud835\udc47\ud835\udc40\ud835\udc36_ [+] _\ud835\udc3e_\n\nwhich is bounded by the available buffer capacity _\ud835\udc46_, assuming\ndouble buffering of _\ud835\udc34_, _\ud835\udc35_ and single buffering of _\ud835\udc36_ :\n\n2 _\ud835\udf0c\ud835\udc4e_ _[\ud835\udc47][\ud835\udc40]_ _\ud835\udc36_ _[\ud835\udc47][\ud835\udc3e]_ [+][ 2] _[\ud835\udc4f\ud835\udc47][\ud835\udc3e][\ud835\udc47][\ud835\udc41]_ [+] _[ \ud835\udc50\ud835\udc47][\ud835\udc40]_ _\ud835\udc36_ _[\ud835\udc47][\ud835\udc41]_ [\u2264] _[\ud835\udc46.]_ (1)\n\nAs shown above, AI _\ud835\udf0c_ increases monotonically with _\ud835\udc47\ud835\udc40\ud835\udc36_ and _\ud835\udc47\ud835\udc41_ .\nImportantly, AI _\ud835\udf0c_ does not depend explicitly on _\ud835\udc47\ud835\udc3e_ or _\ud835\udf0c_ ; their effects\nappear only through the buffer constraint (Eq. 1). The smaller _\ud835\udc47\ud835\udc3e_\nand the larger _\ud835\udf0c_ reduce the buffer cost associated with _\ud835\udc47\ud835\udc40\ud835\udc36_ and\n_\ud835\udc47\ud835\udc41_ . This frees more buffer space, allowing larger ( _\ud835\udc47\ud835\udc40\ud835\udc36_ _,\ud835\udc47\ud835\udc41_ ) values\nto be used, which in turn increases AI _\ud835\udf0c_ . The optimal strategy to\nmaximize AI _\ud835\udf0c_ is to choose _\ud835\udc47\ud835\udc3e_ **as small as possible** and _\ud835\udf0c_ **as large**\n**as possible** . In the idealized case, this corresponds to _\ud835\udc47\ud835\udc3e_ = 1 and\n_\ud835\udc47\ud835\udc40\ud835\udc34_ = 1, with _\ud835\udf0c_ = _\ud835\udc47\ud835\udc40\ud835\udc36_ .\n\n**3.2** **From Single Core to Whole Array**\n\nIn XDNA2\u2122, computation is organized in three levels of tiling: from\noff-chip memory to L2, from L2 to L1, and from L1 to registers. As\ndiscussed in Section 2.2, the L2 output tile is the aggregation of the\nL1 output tiles produced by all compute cores. From L2 to L1, one\ninput tile in a memory core can be broadcast to multiple compute\ncores; specifically, L2 _\ud835\udc34_ tiles are broadcast across columns, and L2 _\ud835\udc35_\ntiles are broadcast across rows. We do not apply asymmetric tiling\nat the L2 level, since the L2 tile size is limited by the L1 tile size and\nthe available L2 memory capacity is sufficient to hold symmetric\ntiles. For an array of _\ud835\udc41_ aie_row = 4 rows and _\ud835\udc41_ aie_col = 8 columns,\nthe effective L2 tile sizes are\n\n_\ud835\udc47\ud835\udc40_ _[\ud835\udc3f]_ [2] [=] _[ \ud835\udc41]_ [aie_row][\u00b7] _[\ud835\udc47]_ _\ud835\udc40_ _[\ud835\udc3f]_ _\ud835\udc36_ [1] [=][ 4] _[\ud835\udc47]_ _\ud835\udc40_ _[\ud835\udc3f]_ _\ud835\udc36_ [1] _[, \ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [2] [=] _[ \ud835\udc41]_ [aie_col][\u00b7] _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] [=][ 8] _[\ud835\udc47]_ _\ud835\udc41_ _[\ud835\udc3f]_ [1] _[, \ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [2] [=] _[ \ud835\udc47]_ _\ud835\udc3e_ _[\ud835\udc3f]_ [1] _[.]_\n\nThe modeling of arithmetic intensity for data moved from off-chip\nfor the whole array is therefore:\n\n![](papers/images/Can-Asymmetric-Tile-Buffering-Be-Beneficial.pdf-2-0.png)\n\n**Figure 3: Example schedule of an accumulation chain. As-**\n**sume 3-cycle latency per instruction, and loading one input**\n**takes 1 instruction, accumulator load/store takes 2.**\n\nthese effects, we must incorporate _compute core efficiency_, which itself depends on the tiling factors. We refine this in the next section 5,\nspecifically focusing on AIE\u2019s VLIW cores as a case study."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism exploits the differing 'lifetimes' of data elements in matrix multiplication. When computing an output element C[m,n] by summing products of A[m,k] and B[k,n] across the 'k' dimension, a row of A (A[m,:]) is read and reused across all 'n' computations for a fixed 'm' and current 'k' tile. However, once all 'n' for that specific 'm' are completed for a given 'k' tile, the A[m,:] row is no longer immediately needed. In contrast, C[m,n] acts as an accumulator; its value must persist and be available for updates across *all* 'k' iterations until its final value is computed. This implies that A's data along the M dimension has a significantly shorter temporal locality requirement (a smaller 'live' range) than C's data along the M dimension. Asymmetric Tile Buffering allocates buffer space proportional to these distinct lifetimes, allowing a smaller buffer extent for A (TMA) compared to C (TMC).\n\n**Explanation:** Think of this like managing variable scopes and lifetimes in a highly optimized inner loop. If you have nested loops `for m { for n { for k { ... } } }`, the `A` data for a specific `m` is like a temporary variable that can be discarded or overwritten after the `n` loop completes for a given `k` block. The `C` data, however, is an accumulator that must persist across the entire `k` loop. By recognizing this, we don't need to commit equal buffer resources (like cache lines or registers) to `A` and `C` for their `M` dimension. Specifically, we can choose `TMA` (A's M-dimension tile size) to be much smaller than `TMC` (C's M-dimension tile size). This 'frees up' precious fast memory buffer capacity. The key insight from the arithmetic intensity formula is that performance scales directly with `TMC` and `TN` (N-dimension tile size). By making `TK` (K-dimension tile size) as small as possible and `rho = TMC/TMA` as large as possible, we minimize the buffer cost of `A` and `B` relative to `C`. This allows us to allocate more of the *total* available buffer capacity to larger `TMC` and `TN` values, which directly translates to a higher arithmetic intensity (more operations per byte accessed from slower memory), thereby improving performance without requiring more total buffer space."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**RL Systems for LLMs** . Several systems aim to optimize\nthe training pipeline of Reinforcement Learning from Human Feedback (RLHF) [42]. Frameworks like DeepSpeedChat [65], GEAR [60], VeRL [53], FlexRLHF [64] and NeMoAligner [52] provide scalable end-to-end solutions, supporting various alignment algorithms and parallelism techniques.\nOthers focus on specific optimizations within the pipeline.\nRLHFuse [72] employs fine-grained scheduling and stage\nfusion to improve GPU utilization. ReaLHF [35] introduces\n\n12\n\ndynamic parameter reallocation to flexibly adapt 3D parallelism strategies across RLHF stages. Their optimization\nefforts primarily target the efficient management of multiple\nmodels inherent in the RLHF process. However, they neglect\na critical performance bottleneck in the rollout phase. This\noversight renders existing systems inefficient for reasoning RL tasks. Our work addresses this gap by concentrating\nspecifically on optimizing the rollout bottleneck, utilizing\nadaptive drafter which is orthogonal to prior systems. Recent\nefforts [12, 71] attempt to alleviate the synchronization constraint in RL by allowing stale responses for model updates.\nWhile such asynchronous strategies accelerate training, they\nrisk degrading model quality. In contrast, our approach preserves the original RL algorithm, ensuring lossless training\nperformance while achieving significant efficiency gains.\n**Speculative Decoding** . Speculative decoding [5, 22, 28] accelerates LLM inference by verifying candidate tokens in\nparallel with the target model, effectively increasing the\nnumber of tokens generated per step. Enhancements to speculative decoding encompass diverse strategies. Researchers\nhave explored retrieval-based methods [13, 16, 48], which\navoid the need to train an extra draft model. Others modify\nthe target model directly: Medusa [4] integrates multiple\nprediction heads, an approach refined by Hydra [2] which\nmodels correlations between these predictions. Furthermore,\nSpecInfer [36] innovatively employs tree-based speculative\ndecoding to broaden the candidate search space. OSD [31]\nleverages knowledge distillation for the drafter model so it\nremains aligned with distribution shifts in online serving.\nAdditionally, EAGLE [25\u201327] trains separate, compact autoregressive models as dedicated draft models. Further refining\nthis approach, HASS [67] improves draft model accuracy by\nsimulating multi-step predictions during training, mitigating\nthe training-inference inconsistency issue. Recent work also\nadapts speculative idea for efficient reasoning LLM inference.\nFor example, RSD [29] employs a reward model to guide the\nspeculation, and SpecReason [43] uses a lightweight model\nto speculatively execute intermediate reasoning steps. Unlike\nthese approaches designed for inference with static models,\nwe focus on the dynamic RL training scenario where the\ntarget model is continuously updated."}, {"role": "assistant", "content": "**Mechanism:** The fundamental mechanism addresses the serial inference bottleneck during the 'rollout phase' of Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Traditionally, the LLM (target model) generates one token at a time, making the process computationally expensive and slow for long sequences. This approach leverages a 'draft model' (a smaller, faster LLM) to speculatively generate a sequence of candidate tokens. Instead of the target model inferring each token sequentially, it parallelly verifies the entire speculative sequence produced by the draft model. This shifts the computational load from repeated full-model inferences to a single, efficient verification step per speculative 'batch'. The 'adaptive' aspect implies dynamic tuning of the drafter or its strategies to maintain high accuracy of speculative guesses as the target model evolves during training, optimizing the acceptance rate and thus efficiency. This is akin to a highly optimized, verified lookahead buffer.\n\n**Explanation:** Think of it like this: your main brain (the target model) is incredibly powerful but a bit slow at thinking of each word one by one. You have a super-fast reflex brain (the draft model) that can quickly guess a whole sentence or many words ahead. Instead of your main brain laboriously thinking of each word sequentially, it quickly glances at the reflex brain's entire suggested sentence. If the sentence looks correct, it accepts all those words instantly. If it finds a mistake in the middle, it accepts all the words up to the mistake and then takes over from there, thinking carefully for the rest. This speeds up your 'thinking' dramatically because you're processing many words at once rather than one-by-one. The 'adaptive' part means your reflex brain learns to guess even better as your main brain learns new things, so its guesses are almost always perfect, making the entire process incredibly efficient without losing any thought quality. This directly applies to the 'rollout' where the LLM is generating experience during training."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**5.1** **Quantization for Mixture-of-Experts**\n\nRecent MoE quantization techniques demonstrate that low-bit PTQ\ncan substantially reduce expert memory cost. MoQE [35], QMoE [8],\nand MxMoE [6] show that 2\u20134 bit or sub-1-bit formats can preserve\nexpert functionality, while MoEQuant [12] and EAQuant [10] refine\nsampling and calibration to reduce accuracy loss. However, these\nmethods set expert precision _offline_ and keep it fixed during inference, making them unable to react to dynamic or highly skewed\nexpert activation patterns.\nDynaExq differs by treating precision as a _runtime-managed_\n_resource_ . Expert bit-widths are adjusted online based on EMAsmoothed activation statistics and memory budgets, enabling precision schedules that track long-term workload behavior rather than\nstatic calibration decisions.\n\n**5.2** **MoE Serving Systems and Expert Offloading**\n\nMoE serving frameworks improve expert execution and data movement across heterogeneous memory tiers. DeepSpeed-MoE [23],\nTutel [14], and Megablocks [11] optimize kernel and routing efficiency, while MoE-Infinity [33], ProMoE [26], and ExpertFlow [25]\nmanage SSD/CPU offloading and expert placement.\nThese systems optimize _where_ experts reside, but assume _fixed-_\n_precision_ weights. Thus, bandwidth and memory usage scale with\nthe full-precision representation of each expert, even when their\nactivation rates differ dramatically. DynaExq complements these\napproaches by introducing precision as an additional control dimension: cold experts are aggressively compressed, reducing both HBM\nfootprint and transfer volume, while hot experts retain high-fidelity\nrepresentations.\n\n|7.2|Col2|Col3|Col4|WikiT|Text|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|6.4<br>6.6<br>6.8<br>7.0<br>7.2<br>Perplexity|||||||||\n|6.4<br>6.6<br>6.8<br>7.0<br>7.2<br>Perplexity|||||||||\n|6.4<br>6.6<br>6.8<br>7.0<br>7.2<br>Perplexity|||||||||\n|6.4<br>6.6<br>6.8<br>7.0<br>7.2<br>Perplexity|||||||||\n|6.4<br>6.6<br>6.8<br>7.0<br>7.2<br>Perplexity|||||||||\n\n**(a) Qwen3-30B-A3B**\n\n|6.4|Col2|Col3|Col4|Wik|kiTex|xt|Col8|Col9|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|5.8<br>6.0<br>6.2<br>6.4<br>Perplexity||||||||||\n|5.8<br>6.0<br>6.2<br>6.4<br>Perplexity||||||||||\n|5.8<br>6.0<br>6.2<br>6.4<br>Perplexity||||||||||\n|5.8<br>6.0<br>6.2<br>6.4<br>Perplexity||||||||||\n|5.8<br>6.0<br>6.2<br>6.4<br>Perplexity||||||||||\n\n**(b) Qwen3-80B-A3B**\n\n**Figure 4: Perplexity Impact of Varying Low-Precision Expert**\n**Ratios Across Layers in DynaExq (Qwen3-30B-A3B: FP16 vs.**\n**Int4, Qwen3-80B-A3B: Int4 vs. Int2)**\n\nWe first examine how varying the proportion of low-precision\nexperts affects language modeling quality. Using WikiText-2, we\ntest 128 prompts (2048 input tokens, 256 output tokens) while progressively increasing the number of demoted experts per layer. As\nFigure 4 shows, perplexity increases smoothly rather than abruptly,\nindicating that the model degrades predictably under more aggressive compression.\nCrucially, DynaExq\u2019s demotion policy prioritizes rarely activated\nexperts, yielding significantly flatter perplexity curves relative to\nuniform quantization. This demonstrates that activation-aware\nprecision assignment captures expert salience effectively and avoids\nunnecessary degradation on frequently used experts.\n\n**4.3** **Accuracy Comparison**\n\nTable 1 summarizes end-task accuracy across six benchmarks. For\nQwen3-MoE-30B, FP16 achieves 65.95% accuracy. Static INT4 reduces memory from 57 GB to 17 GB with modest accuracy loss.\nDynaExq closely matches FP16 accuracy on both GPUs (65.15% on\nA6000, 64.37% on RTX 5090), and retains robustness on challenging\ntasks such as HumanEval and MMLU-ProX.\n\nFor Qwen3-MoE-80B, full-precision inference is infeasible due to\nits 152 GB footprint, so we compare against INT4 (41 GB) and INT2\n(21 GB) baselines. While static INT2 compresses aggressively, it\nsuffers substantial degradation on reasoning-heavy evaluations. In\ncontrast, DynaExq attains 76.68% accuracy on A6000 and 73.88% on\nRTX-5090, consistently outperforming static INT2 and approaching\nINT4 performance, demonstrating that runtime precision alignment\nis particularly beneficial at larger scales.\nAcross both models, DynaExq reduces accuracy loss induced by\nstatic low-bit quantization while remaining deployable under tight\nHBM constraints, validating its ability to allocate precision where\nit most impacts task quality.\n\nKexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Lin, and Wei Zhang\n\n**MODEL** **METHOD** **MMLU-Pro** **GPQA** **AIME25** **GSM8K** **Human Eval** **MMLU-ProX** **AVG.**\n\nQwen3-MoE-30B FP16 73.37 54.55 23.33 90.45 84.76 69.29 65.96\n\nInt4 72.84 53.54 20.00 89.39 84.15 68.39 64.72\n\nDynaExq(A6000) 73.09 54.14 20.00 89.91 84.76 68.96 **65.15**\nDynaExq(5090) 72.58 54.54 20.00 89.54 84.48 68.39 64.37\n\nQwen3-MoE-80B Int4 75.92 72.22 70.00 87.04 85.37 75.88 77.74\n\nInt2 72.75 66.67 63.33 80.97 81.71 70.49 72.65\n\nDynaExq(A6000) 75.48 71.21 66.67 86.73 84.76 75.22 **76.68**\nDynaExq(5090) 72.89 68.18 63.33 83.47 82.68 72.73 73.88\n\n**Table 1: The comparison of accuracy across model/method.**\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-5-10.png)\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-5-11.png)\n\n**(a) TTFT**\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-5-33.png)\n\n**(b) TPOP**\n\n![](papers/images/Dynamic-Expert-Quantization-for-Scalable-MixtureofExperts-Inference.pdf-5-31.png)\n\n**(c) Prefill Throughput**\n\n**(d) Decode Throughput**\n\n**Figure 5: The comparison of latency/throughput across model/method.**\n\n**5.3** **Dynamic Quantization and Adaptive**\n**Execution**\n\nDynamic quantization methods (e.g., HAQ [29], AdaQuant [13],\nFlexRound [17]) select bit-widths based on hardware feedback or\nlayer sensitivity, and adaptive inference techniques such as early\nexiting adjust computation depth per input. However, these approaches target dense models, operate at coarse granularity, and\ndo not address expert-level activation skew in MoE architectures.\nSimilarly, MoE offloading systems adapt expert placement but\ntreat weights as static objects with fixed precision. In contrast, DynaExq performs _expert-level precision scheduling_ integrated into the\nserving runtime. By combining online hotness profiling, precision\ntransitions, and a fragmentation-free memory pool, DynaExq enables activation-aware, memory-efficient MoE inference on a single\nGPU."}, {"role": "assistant", "content": "**Mechanism:** DynaExq operates as an adaptive memory management system at the granularity of individual Mixture-of-Experts (MoE) network experts. Fundamentally, it's a feedback control loop: observe expert usage, then adjust its memory representation. Each expert is tracked by an Exponential Moving Average (EMA) of its activation frequency, essentially a 'hotness' score. This hotness score acts like a dynamic priority. A background process, or an event-driven monitor, continuously evaluates these scores against predefined thresholds and a global memory budget. When an expert's hotness drops below a threshold, its associated high-precision weights (e.g., FP16) are re-quantized into a lower-precision format (e.g., INT4 or INT2) in place, or moved to a dedicated low-precision memory pool. This process is like dynamically casting a variable to a different data type to save memory, but for an entire tensor of weights. Conversely, if a 'cold' expert becomes 'hot', it's promoted back to higher precision by loading or converting its weights. This dynamic precision assignment is facilitated by a fragmentation-free memory pool, ensuring efficient allocation and deallocation of varying bit-width tensors without performance penalties.\n\n**Explanation:** At its core, DynaExq is an online, adaptive resource scheduler for expert weights. Instead of traditional static quantization, where you pick a bit-width (like choosing 'int' vs 'short' for a variable) once during compilation or calibration, DynaExq dynamically changes the 'data type' of an expert's weights at runtime. Imagine a 'std::map<ExpertID, ExponentialMovingAverage<double>>' to track how frequently each expert is called. Another 'std::map<ExpertID, BitWidth>' stores its current precision. When a global memory budget constraint is approached, or based on a periodic check, the system iterates through the experts. If an expert's EMA drops below a certain 'cold_threshold', its 'BitWidth' is reduced, meaning its 'float16' weights are converted and stored as 'int4' or 'int2' arrays. This is effectively freeing up 'sizeof(float16) - sizeof(int4)' bytes per weight. This is analogous to a garbage collector freeing up memory, but here, it's freeing up *precision* itself. The reverse happens if a cold expert suddenly gets hot. This dynamic adjustment allows memory (bandwidth and footprint) to be treated as a fluid resource, allocated optimally where the model is actively 'thinking', rather than statically reserving high-fidelity storage for every potential thought."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nUnderstanding the extent to which language models reason requires a theory of what reasoning is. Without\nprincipled criteria distinguishing reasoning from pattern matching, evaluation isn\u2019t possible. Decades of\n\n1Publicly released at `[https://huggingface.co/collections/stellalisy/cognitive-foundations](https://huggingface.co/collections/stellalisy/cognitive-foundations)`\n\n4\n\nTable 1: Taxonomy of cognitive reasoning behaviors, organized along two main dimensions: Cognitive\nProperties (stable internal constraints) and Cognitive Capabilities (deployable context-sensitive abilities).\n\n|A . Reasoning Invariants: \"Always-true\" constraints or quality criteria the system maintains across reasoning steps.|Col2|Col3|\n|---|---|---|\n|`Logical coherence`<br>`Compositionality`<br>`Productivity`<br>`Conceptual processing`|Maintain consistency across reasoning steps and contexts (Fodor & Pylyshyn, 1988).<br>Build complex ideas from simpler components (Fodor, 1975).<br>Formulate an indefnite number of thoughts or solutions using a fnite set of elements (Halford, 1989).<br>Operating over abstract representations before linguistic expression (Halford, 1989).|Maintain consistency across reasoning steps and contexts (Fodor & Pylyshyn, 1988).<br>Build complex ideas from simpler components (Fodor, 1975).<br>Formulate an indefnite number of thoughts or solutions using a fnite set of elements (Halford, 1989).<br>Operating over abstract representations before linguistic expression (Halford, 1989).|\n|**_B. Meta-Cognitive Controls:_**_ Higher-order abilities that select, monitor, and adapt processes._|**_B. Meta-Cognitive Controls:_**_ Higher-order abilities that select, monitor, and adapt processes._|**_B. Meta-Cognitive Controls:_**_ Higher-order abilities that select, monitor, and adapt processes._|\n|`Self-awareness`<br>`Context awareness`<br>`Strategy selection`<br>`Goal management`<br>`Evaluation`|Assess own knowledge state, capabilities, and task solvability (Wicklund, 1979).<br>Perceive, understand, and navigate one\u2019s circumstances (including other agents) (Frith & Frith, 2007).<br>Choose & explore reasoning approaches suited to task and domain demands (Lieder & Grifths, 2017).<br>Establish, maintain, and adjust goals throughout the reasoning process (Grifths et al., 2019).<br>Assess & adapt to the quality, efciency, and progress of one\u2019s reasoning (Fleming & Daw, 2017).|Assess own knowledge state, capabilities, and task solvability (Wicklund, 1979).<br>Perceive, understand, and navigate one\u2019s circumstances (including other agents) (Frith & Frith, 2007).<br>Choose & explore reasoning approaches suited to task and domain demands (Lieder & Grifths, 2017).<br>Establish, maintain, and adjust goals throughout the reasoning process (Grifths et al., 2019).<br>Assess & adapt to the quality, efciency, and progress of one\u2019s reasoning (Fleming & Daw, 2017).|\n|**_C. Reasoning Representations:_**_ The formats and organizational patterns used to encode and relate knowledge and steps._|**_C. Reasoning Representations:_**_ The formats and organizational patterns used to encode and relate knowledge and steps._|**_C. Reasoning Representations:_**_ The formats and organizational patterns used to encode and relate knowledge and steps._|\n|**Structural**<br>**Organization**|`Sequential organization`<br>`Hierarchical organization`<br>`Network organization`|Order steps where sequence matters (Skinner, 1953).<br>Nest concepts in parent\u2013child relationships (Galanter et al., 1960).<br>Link concepts through multiple relationship types (Quillan, 1966).|\n|**Conceptual**<br>**Organization**|`Ordinal organization`<br>`Causal organization`<br>`Temporal organization`<br>`Spatial organization`|Arrange elements by relative order or rank (Stevens, 1946).<br>Connect elements through cause\u2013efect relations (Heider, 1958).<br>Order elements by before\u2013after relations (Ebbinghaus, 1885).<br>Structure elements by spatial relationships (Tolman, 1948).|\n|**_D. Reasoning Operations:_**_ Goal-directed actions that construct, evaluate, modify, and navigate reasoning representations._|**_D. Reasoning Operations:_**_ Goal-directed actions that construct, evaluate, modify, and navigate reasoning representations._|**_D. Reasoning Operations:_**_ Goal-directed actions that construct, evaluate, modify, and navigate reasoning representations._|\n|**Representation**<br>**Selection**|`Context alignment`<br>`Knowledge alignment`|Align to task and situational demands (Gick & Holyoak, 1980).<br>Align to domain-specifc structures & relations (Chi et al., 1981).|\n|**Representation**<br>**Evaluation**|`Verification`|Check reasoning steps against pre-determined criteria (Flavell, 1979).|\n|**Representation**<br>**Modifcation**|`Selective attention`<br>`Adaptive detail mgmt.`<br>`Decomposition and integration`<br>`Representational restructuring`<br>`Pattern recognition`<br>`Abstraction`|Focus on relevant details and fltering noise (Broadbent, 1958).<br>Adjust granularity based on task demands (Rosch, 1978).<br>Divide problems and synthesizing subsolutions (Newell et al., 1959).<br>Reformulate problems for new insights (Wertheimer, 1945).<br>Detect recurring structures across contexts (Selfridge, 1959).<br>Generalize from specifc cases (Hull, 1920).|\n|**Representation**<br>**Navigation**|`Forward chaining`<br>`Backward chaining`<br>`Backtracking`|Reason from known facts toward goals (Huys et al., 2012).<br>Work backward from goals to prerequisites (Park et al., 2017).<br>Revisit and correcting prior reasoning paths (Nilsson, 1971).|\n\nresearch in Cognitive Science on problem-solving, mental representation, and metacognition provide a powerful starting point. The cognitive revolution of the 1950s introduced a powerful framework: the mind as an\ninformation-processing system. Fodor\u2019s (1975) Language of Thought Hypothesis proposed that thinking is\na computational process operating over compositional representations. Complex thoughts comprise simpler\ncomponents combined through systematic rules, enabling humans to generate infinitely many novel thoughts\nfrom finite conceptual primitives. We are not \"hapless tourists bound by a limited phrasebook of ideas\"\n(Frankland & Greene, 2020), but fluent speakers of an internal, compositional language. However, this view\nof the mind as a formal logic engine could not explain empirical findings that emerged from psychology\nlaboratories. Wason (1968) demonstrated a \"content effect\", where people systematically fail to apply logical\nrules in an abstract setting but succeed when the identical task is presented as a familiar social rule. Tversky\n& Kahneman (1974) showed that humans systematically use heuristics and mental shortcuts that violate basic principles of logic and probability theory (Ragni et al., 2017). These results have led to many alternative\ntheoretical accounts. Mental Models Theory proposed that reasoning constructs and manipulates semantic\nsimulations of the world rather than applying syntactic inference rules (Johnson-Laird, 1983; 2010). DualProcess Theory distinguished fast, intuitive processing from slow, deliberative reasoning (Evans, 2003; Evans\n& Stanovich, 2013). Bayesian approaches reframed rationality as probabilistic inference under uncertainty,\n\n5\n\narguing that reasoning updates probabilistic beliefs based on new, ambiguous, and noisy data in ways that\napproximate Bayesian inference (Griffiths et al., 2024; Jacobs & Kruschke, 2011; Oaksford & Chater, 2009).\n\nThis theoretical diversity in cognitive science, while valuable, has contributed to fragmentation in LLM\nreasoning research. Gandhi et al. (2025) characterizes reasoning through verification, subgoal setting, backtracking, and backward chaining, while Lee et al. (2024) focuses on logical coherence, compositionality, and\nproductivity. Models appear capable under one framework yet fail under another, and researchers lack a\nshared vocabulary for diagnosing where and why reasoning breaks down. We address this by organizing cognitive theories using Marr\u2019s (1982) levels of analysis and proposing a unified framework for cognitive elements.\nThe _computational level_ defines the goal of the system: what is being computed and why. The _algorithmic_\n_and representational level_ specifies the process: what representations are used for the input/ouput and what\nalgorithms transform these representations to achieve the computational goals. The _implementation level_\nconcerns the physical realization about how representations and algorithms are instantiated in neural hardware or silicon. For our purposes, we focus on the first two levels. At the computational level, reasoning must\nsatisfy certain fundamental properties to maintain consistency, resolve contradictions, and combine elements\ncompositionally. At the algorithmic level, these goals are realized through specific knowledge structures and\nthe processes that manipulate them (Peebles & Cooper, 2015; Krafft & Griffiths, 2018).\n\nOur proposed framework for cognitive foundations consists of four dimensions (detailed in Table 1). 1.\n_Reasoning invariants_ specify computational goals\u2014properties that must hold for valid reasoning. 2. _Meta-_\n_cognitive controls_ select and monitor processes, determining which strategies to deploy and when to adapt. 3.\n_Reasoning representations_ describe how knowledge is organized. 4. _Reasoning operations_ specify procedures\nthat construct, evaluate, and transform representations. These dimensions span 28 cognitive elements,\nproviding vocabulary for diagnosing which aspects of human reasoning manifest in language models.\n\nA familiar scenario illustrates how these dimensions interact: a child playing with a pile of LEGO\u00ae bricks\nand building something novel, like a \"spaceship\" (Figure 1). This creative process is an example of the\nreasoning invariants of compositionality and productivity, where the goal is to generate a complex, new\nstructure (the spaceship) by combining a finite set of simple components (a few different types of toy bricks).\nThis computational goal is managed by meta-reasoning controls. The child must first decide on a strategy:\n\"Should I have a rough plan first, or go directly into building?\" \"Should I start with the main body or the\nwings?\" Throughout the process, they must constantly monitor their progress and evaluate their spaceship.\nFor instance, they might observe that the wings don\u2019t look sturdy enough, leading them to reinforce the\nstructure with more blocks. This entire cycle of planning, building, and evaluation relies on the child forming\nand manipulating a dynamic 3D mental model of the target spaceship, especially the spatial relationships\nbetween components. This mental model shifts from a vague concept to a concrete plan through a series\nof operations. For instance, the child would try out different combinations of pieces, constantly assembling,\ntesting, and then backtracking to refine their final design.\n\nThis LEGO example illustrates that reasoning arises from the dynamic interplay of all four dimensions,\nbecause the child\u2019s compositional goal requires strategic choices about how to build, which determine what\nrepresentations to construct, which are then transformed through coordinated operations. Current research\ntends to isolate individual behaviors\u2014studying verification independently from representation selection,\nor decomposition separately from meta-cognitive monitoring. However, effective reasoning requires these\ndimensions to work in concert. The computational drives and constraints from invariants are managed by\nmeta-cognitive controls, which in turn direct the algorithmic-level shifts in representation and the operations\nthat enact them. No single dimension suffices. In the following subsections, we will unpack each dimension\nin detail, drawing on research in cognitive science to explain what each dimension contributes and examining\nhow each one manifests in current language models.\n\n**2.1** **Reasoning Invariants: Computational Constraints**\n\nAt Marr\u2019s computational level, we investigate the fundamental constraints that an ideal solution to any\nreasoning problem must satisfy. Fodor\u2019s (1975) language of thought hypothesis identifies these constraints:\nvalid reasoning manipulates structured representations according to compositional rules, producing thoughts\nthat are logically coherent (free from contradiction), compositional (complex meanings built from simpler\n\n6\n\nparts), and productive (capable of generating unbounded novel inferences from finite primitives). We add\nconceptual processing from research on cognitive processing capacity and conceptual structures (Halford,\n1989; Kholodnaya & Volkova, 2016), which requires that reasoning operates over abstract relational structures\nrather than surface forms. These four invariants specify the computational constraints that define valid\nreasoning solutions.\n\n`Logical coherence` maintains consistency across reasoning steps and contexts (Rips, 1983; Thagard, 2002).\nIn the LEGO example, if the child simultaneously believes \"this wing design is stable\" and \"this wing design\nwill collapse,\" reasoning breaks down. The contradiction creates cognitive dissonance that must be resolved\nby revising the stability judgment, reinforcing the structure, or reconsidering the design (Festinger, 1962;\nHarmon-Jones & Mills, 2019). This pressure to restore consistency shapes how reasoners revise mental\nmodels and update inferences. Humans cannot comfortably hold contradictory beliefs simultaneously; the\ndrive to resolve inconsistencies is a defining feature of reasoning.\n\n`Compositionality` enables building complex ideas from simpler components through rule-governed combination (Fodor, 1975; 2001; Fodor & Pylyshyn, 1988). The LEGO spaceship emerges from systematically\ncombining individual bricks. The structure of the whole derives predictably from the properties of its parts\nand how they connect. Understanding \"red cockpit with transparent dome\" requires combining concepts\nof color, component type, and material in ways that preserve each element\u2019s meaning. The meaning of a\ncomplex expression derives from the meanings of its constituents and their mode of combination (Russin\net al., 2024). This property drastically increases the learning efficiency and expressive power of the cognitive\nsystem, allowing finite mental resources to produce unbounded conceptual richness (Frankland & Greene,\n2020; Piantadosi, 2011).\n\n`Productivity` extends compositionality by enabling the generation of infinitely many novel thoughts from\nfinite primitives (Fodor, 1975). This generative power is intrinsically linked to systematicity, the capacity\nto entertain a set of thoughts given the ability to entertain related ones (Fodor & Pylyshyn, 1988). The\nrecursive nature of human cognition provides the mechanism necessary for this unlimited generative power\n(Hauser et al., 2002), Having understood how to build a spaceship, the child can apply the same structural\nprinciples to generate a plane, a castle, or a dinosaur. This capacity to _produce_ and understand unbounded\nthoughts from finite components is central to human reasoning. Once we grasp the compositional structure\nfor combining LEGO blocks to achieve a functional goal, we spontaneously recognize how to apply that\nstructure to new contexts without requiring explicit instruction for each instance. Productivity distinguishes\ngenuine understanding from memorized responses.\n\n`Conceptual processing` operates over abstract semantic relations rather than surface forms (Halford,\n1989; Kholodnaya & Volkova, 2016; Baron, 2008). Having this conceptual depth enables generalization\nbeyond shallow pattern matching of concrete, low-level objects. In the LEGO example, the child is not\njust combining bricks together based on their colors or shapes. Instead, they are operating on the abstract\nconcept of a spaceship. This concept brings with it a set of functional properties that guide the building\nprocess: a spaceship needs a cockpit, a body, and wings.\n\nThese four invariants are interconnected requirements rather than independent properties. Coherence constrains which compositional structures are valid. Productivity depends on compositional structure to generate novel thoughts systematically. Conceptual processing ensures reasoning operates over meaningful\nrelationships rather than surface patterns. Together, these invariants define the computational constraints\nthat valid reasoning must satisfy. However, invariants specify what reasoning must achieve without addressing the mechanisms that recognize when constraints are violated, select appropriate strategies, or monitor\nprogress toward goals. These regulatory mechanisms constitute meta-cognitive controls.\n\n**2.2** **Meta-Cognitive Controls: Executive Regulation**\n\nMeta-cognitive controls constitute the executive functions that select, monitor, and adapt reasoning processes\n(Fleming, 2024). While invariants define validity criteria, controls orchestrate the reasoning process itself.\n\n`Self-awareness` stands as the foundation: the capacity to assess one\u2019s own knowledge state, capabilities,\nand the solvability of a task (Neisser, 1988; Wicklund, 1979; Leary & Buttermore, 2003). Rochat (2003)\n\n7\n\ndescribes this as \"arguably the most fundamental issue in psychology, from both a developmental and evolutionary perspective\". In the LEGO example, the child engages in internal assessment: \"Am I good at\nbuilding spaceships?\" or \"Do I know what a spaceship looks like?\" This metacognitive evaluation enables\nstrategic deployment of cognitive resources.\n\n`Context awareness` perceives and responds to situational demands, environmental constraints, and the\npresence of other agents (Boyd et al., 2011; Frith & Frith, 2007; Lei, 2023). In the LEGO example, context\nfundamentally shapes the task. Building alone for fun permits flexible exploration. Building with a friend\nintroduces social dynamics requiring cooperation and negotiation. Building in a timed contest with limited\nbricks demands prioritizing speed and efficiency over creative exploration. Context awareness determines\nwhich strategies are appropriate and which goals are worth pursuing (Milli et al., 2021).\n\nGiven this awareness of self and context, the child engages in `strategy selection`, choosing an approach\nsuited to task demands (Lieder & Griffiths, 2017; 2020; Mata et al., 2011). They might adopt an exploratory,\nbottom-up strategy, combining bricks and allowing the design to emerge organically. Alternatively, they\ncould choose a planned, top-down strategy, first visualizing the spaceship mentally and then systematically\nfinding bricks to realize each component. With limited bricks, they might adopt a resource-first strategy,\nsorting pieces to assess availability before committing to a design. With time constraints, they might use a\nschema-based strategy, quickly replicating a remembered design.\n\nThese strategic choices are accompanied by `goal management` : the process of setting, sequencing, and\ndynamically adjusting goals throughout reasoning (Griffiths et al., 2019; Dolan & Dayan, 2013; Cushman\n& Morris, 2015). The abstract goal \"build a spaceship\" decomposes into manageable sub-goals: construct\nthe main body, add wings, build the cockpit, and insert pilots. Goal management is inherently dynamic,\ncorresponding to strategy shifts due to changes in context and self-awareness. While working on wings, the\nchild might spot a clear brick perfect for a windshield, pausing the current task to insert a new sub-goal.\nConversely, if attaching wheels proves too difficult, the child abandons this sub-goal to prioritize completing\nthe rest of the ship.\n\nProgress toward these shifting goals is monitored through `evaluation` : assessing the quality, efficiency, and\ncoherence of the emerging solution (Yeung & Summerfield, 2012; Fleming & Daw, 2017; Stipek et al., 1992).\nThe child continuously evaluates: Does the wing design look stable? Is this approach too slow? Should I try\na different configuration? This ongoing assessment determines whether to persist with the current approach\nor adapt strategies and goals.\n\nThese five controls form an integrated executive system operating in coordinated fashion. Self-awareness\ndetects capabilities and limitations. Context awareness identifies situational demands. Strategy selection\nresponds by choosing appropriate approaches. Goal management directs the response through structured\nsub-goals. Evaluation monitors progress and triggers adaptation when needed. In the LEGO example, these\ncontrols work together: the child assesses their skill level (self-awareness), recognizes time and resource\nconstraints (context awareness), selects an appropriate strategy (strategy selection), breaks the task into\nsub-goals (goal management), and monitors whether the emerging structure matches their mental model\n(evaluation). Yet controls alone do not constitute reasoning. They govern processes but do not specify the\nrepresentational structures over which those processes operate. A reasoner must organize knowledge in some\nform, and the choice of structure profoundly shapes reasoning effectiveness.\n\n**2.3** **Reasoning Representations: Organizational Structures**\n\nThe meta-cognitive controls govern processes, but processes must operate over something. Descending to\nMarr\u2019s algorithmic level, we encounter the representational structures that encode knowledge and organize\nreasoning. The effectiveness of reasoning depends critically on how information is structured (Sweller, 1988;\nBritton & Tesser, 1982). This focus on structure has deep roots in psychology, tracing back to the principles\nof associationism and the early study of how ideas become linked in the mind (James et al., 1890). Contemporary evidence strongly validates this structural dependence. Cognitive load theory demonstrates that\nworking memory limitations create severe bottlenecks: poorly structured information overwhelms capacity,\nwhile well-structured information facilitates processing (Sweller, 2011). Various representation structures\nhave been proposed. Production systems represent procedural knowledge via a set of If-Then rules. They\n\n8\n\nform the basis of early cognitive modeling systems like ACT-R (Newell & Simon, 1972). Prototype theory\n(Rosch, 1975; Rosch & Mervis, 1975) represents categories by their most typical member, while exemplar\ntheories (Medin & Schaffer, 1978) represent a collection of all remembered instances of that category. Semantic network theories model human knowledge as nodes connected by typed relations, capturing both\nhierarchical and associative organization (Quillan, 1966; Collins & Loftus, 1975; Steyvers & Tenenbaum,\n2005). More generalized structures, such as frames and schemas, encode stereotyped knowledge about common situations, guiding prediction and inference by providing default expectations (Minsky, 1974; Bartlett,\n1932). Mental models research shows that humans construct internal representations reflecting structural\nand causal relationships in the domains they reason about (Johnson-Laird, 1983). Here, we organize representations along two dimensions: structural organization concerns how elements connect, while conceptual\norganization concerns how meaning is arranged.\n\n**Structural organization** specifies the architecture through which elements relate. The simplest form is\n\n`sequential organization`, which orders steps where sequence matters (Skinner, 1953). The procedure\nfor starting a car, the temporal flow of historical events, and the steps in a recipe all depend on maintaining\nproper order. But many reasoning tasks demand richer connectivity (Lashley et al., 1951; Rosenbaum et al.,\n2007). `Hierarchical organization` nests concepts in parent-child relationships, enabling decomposition\nof complex wholes into manageable parts (Galanter et al., 1960; Botvinick et al., 2009; Haupt, 2018). Biological taxonomies classify organisms into kingdom, phylum, class, and order; problem-solving decomposes\ncomplex tasks into manageable subtasks; and administrative structures organize authority and responsibility through nested levels. This parent-child structure proves so cognitively natural that it appears across\nvirtually every domain of human knowledge organization. Yet even hierarchies have limitations. Many domains resist strict tree structures because elements relate through multiple relationship types simultaneously.\n\n`Network organization` captures this richer connectivity (Quillan, 1966; Shafto et al., 2008). In understanding an ecosystem, organisms connect through predation, competition, symbiosis, and energy flow. No\nsingle hierarchy can represent all these relations; only a network preserves the full relational structure. In\nthe LEGO example, the child\u2019s mental model exhibits hierarchical decomposition of the spaceship into body,\nwings, and cockpit, while simultaneously maintaining network relationships that specify how components\nphysically connect and structurally support each other.\n\n**Conceptual organization** structures meaning rather than architecture, specifying the semantic relationships that give representations their inferential power. When the child reasons about alternative wing designs\nfor their LEGO spaceship, `ordinal organization` allows ranking them from best to worst, most stable\nto least stable (Stevens, 1946). But ranking alone provides no explanatory depth. `Causal organization`\nconnects elements through cause-effect relations, revealing why one design outperforms another (Heider,\n1958; Khemlani et al., 2014). Inadequate wing reinforcement causes structural instability, which prevents\nstable flight. This causal chain guides both diagnosis (why did it fail?) and intervention (how to fix it?).\nCausal reasoning interacts intimately with `temporal organization`, which orders events by before-after\nrelations (Ebbinghaus, 1885; Bartlett, 1932; Hoerl & McCormack, 2019). The child must attach the wings\nbefore adding the cockpit and test stability before declaring the design complete. Temporal constraints\nshape planning, while causal understanding determines which temporal orderings make sense. Finally,\n`spatial organization` structures elements geometrically, capturing relationships like adjacency, containment, and orientation (Tolman, 1948; Shepard & Metzler, 1971; Landau & Jackendoff, 1993). The child\nreasons about which pieces fit where, how rotating a component changes available attachment points, where\nweight distribution affects balance (Shelton et al., 2022; Cortesa et al., 2017). In practice, the LEGO example\nreveals how these conceptual organizations interweave: spatial reasoning determines physical fit, causal reasoning predicts structural stability, and temporal reasoning sequences construction steps. The child fluidly\ntransitions between organizational schemes as task demands shift.\n\nThese structures are not static containers but dynamic scaffolds that reasoning actively constructs and\ntransforms. Reasoning does not simply retrieve and display pre-formed representations. It constructs,\nevaluates, modifies, and navigates them through cognitive operations.\n\n9\n\n**2.4** **Reasoning Operations: Transformation Procedures**\n\nRepresentations provide the scaffolds; operations are the processes that manipulate them. At the algorithmic level, reasoning unfolds through goal-directed procedures that construct new representations, evaluate\nexisting ones, modify them adaptively, and navigate through them strategically (McClelland et al., 2010;\nJohnson-Laird, 1983). These operations are enacted under meta-cognitive control and constrained by reasoning invariants. While humans possess a large repertoire of reasoning operations, we focus on the four\nmost fundamental clusters that characterize reasoning across domains: selection, evaluation, modification,\nand navigation.\n\n**Representation selection** operations align structures to task and domain demands, a process rarely conscious but profoundly shaping subsequent reasoning. `Context alignment` chooses organizational schemas\nfitting the problem (Gick & Holyoak, 1980; 1983; Gentner, 1983): temporal for historical explanation, causal\nfor scientific reasoning, spatial for navigation. `Knowledge alignment` maps problems onto domain-specific\nschemas (Chase & Simon, 1973; Chi et al., 1981; Schoenfeld, 2014). A physician diagnosing symptoms\nactivates medical taxonomies; an auto mechanic activates mechanical systems and failure modes. In the\nLEGO example, the child implicitly selects hierarchical decomposition combined with spatial organization\nas appropriate for the construction task, a choice that determines which reasoning moves become natural.\n\n**Representation evaluation** verifies reasoning steps against predetermined criteria. `Verification` checks\nintermediate inferences for consistency, plausibility, and coherence with known facts (Flavell, 1979; Goldstein\net al., 2010). The child might verify that two pieces actually connect as expected by testing the attachment,\nor recount the number of attachment points to confirm stability. Humans continuously verify their reasoning,\nthough the sophistication and systematicity vary with expertise (Simon & Simon, 1978). Novices may fail\nto catch errors that experts immediately flag.\n\n**Representation** **modification** operations adaptively change representational form.\n`Selective attention` focuses on relevant features while filtering noise. In the LEGO example, the\nchild can attend to wing structure and stability while ignoring piece color or aesthetic details. This ability\nto focus resources and filter irrelevant input is fundamental to information processing, established by\nclassic models demonstrating a bottleneck in early sensory processing that requires a selection mechanism\n(Broadbent, 1958; Treisman, 1964). `Adaptive detail management` adjusts granularity based on task\ndemands (Rosch, 1978). Individuals dynamically shift between fine-grained and global representations\nbased on cognitive goals, zooming in to examine how specific connection points distribute weight or zooming\nout to assess overall balance. `Decomposition and integration` break problems into subproblems and\nsynthesize solutions (Newell et al., 1959). Decomposition is a core mechanism of problem-solving, initially\nformalized through means-ends analysis and the creation of subgoals to manage task complexity. Integration\nrepresents the essential process of synthesizing findings across these subgoals to form a complete solution.\n\n`Representational restructuring` reframes problems for new insight, fundamentally shifting how the\nproblem is conceptualized and often marking breakthrough moments in reasoning (Wertheimer, 1945;\nK\u00f6hler, 1925; Braun et al., 2010). `Pattern recognition` detects recurring structures, enabling reuse\nof solution templates (Selfridge, 1959; Posner & Keele, 1968). This operation is the foundation of expert\nknowledge, enabling fast and accurate classification of novel stimuli by matching them against stored\nprototypes or templates. `Abstraction` generalizes from specific instances, distilling common, invariant\nfeatures from a series of concrete examples and deriving principles from a set of actions or operations (Hull,\n1920; Piaget, 1952). After several construction attempts, the child may abstract the principle that heavier\ncomponents require proportionally more connection points to remain stable.\n\n**Representation navigation** includes operations that traverse knowledge and inference structures.\n\n`Forward chaining` reasons from known facts toward goals: \"These pieces connect this way; therefore this\nstructure is possible\" (Huys et al., 2012). This operation is a key component of early production systems and\nexpert system architectures, where the system begins with facts and applies rules iteratively until a conclusion is reached or a goal state is satisfied (Newell & Simon, 1972; Davis & King, 1984) `Backward chaining`\nworks from goals to prerequisites: \"To make wings stable, I need reinforcement; what pieces provide that?\"\n(Park et al., 2017). This goal-driven approach is highly efficient in situations where the number of possible\noutcomes is large, but the goal is clearly defined (Charniak, 1985; Newell et al., 1959). `Backtracking`\n\n10\n\nrevisits earlier reasoning upon detecting errors (Qin et al., 2025). This crucial cognitive control mechanism\noften relies on depth-first search, where, upon hitting a dead-end, the system returns to the most recent\ndecision point to explore alternatives (Nilsson, 1971). In the LEGO example, the child uses forward chaining\nto build, backward chaining to plan, and backtracking when a design fails. These navigation operations\ndetermine the path through problem space.\n\nThese operations do not occur in isolation. In the LEGO example, representation selection chooses hierarchical decomposition, forward chaining builds the body, verification checks that pieces connect properly,\nbacktracking returns to an earlier design choice when the structure wobbles, restructuring introduces new\ndesign ideas, pattern recognition suggests a previously worked design, and abstraction extracts a principle\nfor future builds. The operations form an integrated toolkit, flexibly deployed under meta-cognitive control\nto manipulate representations while satisfying invariants. Together with the representational structures from\nSection 2.3, they constitute Marr\u2019s algorithmic level. Table 1 presents our complete taxonomy: invariants\ndefine computational constraints, controls select and monitor processes, representations encode knowledge\nstructures, and operations transform those structures. This framework provides the analytical vocabulary\nfor examining how these 28 reasoning behaviors manifest in human versus LLM reasoning. Section 3 presents\nour investigation of behavioral presence, patterns, and their relationship to reasoning success across diverse\nproblem types."}, {"role": "assistant", "content": "**Mechanism:** This paper proposes a comprehensive framework to dissect what 'reasoning' entails for AI, particularly Language Models. It breaks reasoning down into four interconnected layers: computational constraints (the 'what' and 'why'), executive controls (the 'how to manage'), knowledge representations (the 'what data structures'), and manipulative operations (the 'what algorithms'). The core mechanism is that true reasoning emerges from the dynamic interplay and coordination of these distinct yet interdependent components, rather than isolated functionalities.\n\n**Explanation:** Think of an AI system as a complex program. The Reasoning Invariants are like the fundamental assertions or 'unit tests' that any output purporting to be 'reasoned' must pass. Logical coherence is ensuring your program state is always consistent, like an ACID compliant database. Compositionality means your functions are modular: f(g(x)) always behaves predictably from f and g. Productivity is akin to a recursive function or a grammatical parser that can generate an infinite number of valid statements from finite rules. Conceptual processing implies operating on abstract data types or interfaces, not just their string representations. Meta-Cognitive Controls are the 'operating system' or 'process scheduler.' Self-awareness is the system querying its own capabilities and resources (e.g., 'can I reach this server?'). Context awareness is about reading environment variables or external API responses to adapt. Strategy selection is a conditional block: if (urgent_task) use_fast_path() else use_thorough_path(). Goal management is like a call stack, breaking a main function into sub-routines and dynamically adjusting priority. Evaluation is continuous runtime monitoring or assertion checking, triggering error handling or re-planning if a sub-goal fails. Reasoning Representations are the actual data structures. Sequential is a list. Hierarchical is a tree structure, like a nested object or a file system. Network is a graph data structure, perfect for complex interlinked concepts. Ordinal is ranked data, Causal is a directed graph of dependencies, Temporal is a timestamped log, and Spatial involves coordinate systems. The chosen representation critically impacts algorithmic efficiency. Reasoning Operations are the algorithms. Representation selection is choosing the right data parser (e.g., JSON.parse vs. XML.parse). Verification is a validation function. Modification includes: Selective attention (filtering a dataset), Adaptive detail management (changing data resolution), Decomposition and integration (breaking down a task into sub-functions and combining results), Representational restructuring (refactoring code or migrating a database schema), Pattern recognition (regex matching or template detection), and Abstraction (creating a base class or a generalized utility function). Navigation uses graph traversal algorithms: Forward chaining is like a BFS/DFS from inputs to outcomes. Backward chaining is DFS from a desired outcome to find necessary prerequisites. Backtracking is literally unwinding a recursive call stack if a path leads to a dead end, allowing exploration of alternative branches. This framework provides a structured way to analyze how these fundamental programming-like constructs interact to produce 'reasoning'."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_valid signed r_ opp( _i_ ) _\u2192i is recieved from_ opp( _i_ ) _in Round 2_ **then**\n\n**3** _Ri \u2190{ri\u2192i \u2295_ _r_ opp( _i_ ) _\u2192i}_ ;\n\n**4** Broadcast message ( `iteration` ~~`n`~~ `umber` _,_ opp( _i_ ) _, r_ opp( _i_ ) _\u2192i_ ) signed by opp( _i_ ) to all\nneighbors"}, {"role": "assistant", "content": "**Mechanism:** Node 'i' first validates a cryptographic signature on a received data 'r_opp(i)\u2192i' from 'opp(i)', ensuring authenticity and integrity. It then performs a bitwise XOR operation between its own local secret 'ri\u2192i' and the received 'r_opp(i)\u2192i' to generate a new internal state 'Ri'. Subsequently, 'i' broadcasts the *original* received 'r_opp(i)\u2192i' (along with metadata) to all its neighbors, crucially including the original cryptographic signature by 'opp(i)'.\n\n**Explanation:** This mechanism leverages basic cryptographic primitives for secure multi-party interaction. The signature verification is akin to checking a digital certificate, confirming the sender's identity and data's unaltered state. The XOR operation is a fundamental bitwise function often used in cryptography because it's reversible; combining two secrets `A XOR B = C` means if you know `C` and `B`, you can find `A` (`C XOR B = A`). Here, 'i' combines its secret with 'opp(i)'s secret, creating a 'mixed' secret `Ri` that depends on both but doesn't directly reveal either `ri\u2192i` or `r_opp(i)\u2192i`. The final broadcast of 'opp(i)'s signed value is a public commitment or a 'proof of receipt' that other nodes can verify, allowing for distributed verification or further computation without compromising the initial secrecy of `Ri` (which includes 'i's private `ri\u2192i`). It's like 'i' is validating a message, doing a quick, reversible calculation with it and its own data, and then publicly announcing what it *received* (signed by the sender) so others can confirm, while its *own combined result* remains private."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nTo provide theoretical validation of the framework, we study\nthe choice of _E_, which serves as a sort of evaluation budget,\nin our method to ensure accuracy, and then we propose a\ndetailed convergence analysis. We start with adapting the\nfollowing concentration inequality.\n\n**Lemma 1** (Concentration) **.** _Let the policy \u03c0 have per-step_\n_rewards lie in_ [0 _, R_ max] _, so that any trajectory return satisfies_\n0 _\u2264_ _G_ ( _\u03c4_ ) _\u2264_ _B_ _with_ _B_ = _R_ 1max _\u2212\u03b3_ _[.][ Then for any][ \u03f5 >]_ [ 0] _[,]_\n\ni\n\n\u02c6\nP\ufffd\ufffd\ufffd _J_ ( _\u03c0_ ) _\u2212_ _J_ ( _\u03c0_ )\ufffd\ufffd _\u2265_ _\u03f5_ \ufffd _\u2264_ 2 exp\ufffd _\u2212_ [2] _[ E \u03f5]_ _B_ [2] [2] \ufffd _._\n\ni\n\nApplying Lemma 1 with a per-step failure probability of\n_\u03b4_\nget for every _T_ [and then union-bounding over] _t \u2208_ [ _T_ ] empirical estimates satisfies _[ T]_ [ consecutive updates, we] \ufffd\ufffd _J_ \u02c6( _\u03c0t_ ) _\u2212_\n\n_B_ [2] 2 _T_\n_J_ ( _\u03c0t_ )\ufffd\ufffd _\u2264_ _\u03f5_, provided _E \u2265_ 2 _\u03f5_ [2] [ln] \ufffd _\u03b4_ \ufffd, with probability\n\nat least 1 _\u2212_ _\u03b4_ . [2]\n\n**Lemma 2** (Monotonicity) **.** _Let E_ _\u2265_ 2 _B \u03f5_ [2][2] [ln] \ufffd 2 _\u03b4 T_ \ufffd _._\n\n_Then with probability at least_ 1 _\u2212_ _\u03b4, for every update_\n_t_ \u02c6 = 1 _,_ 2 _, . . ., T_ \u02c6 _, whenever the lookback rule accepts (i.e._\n_J_ ( _\u03c0\u03b8t_ +1) _\u2265_ _J_ ( _\u03c0\u03b8t_ ) _), the true returns satisfy_\n\n_J_ \ufffd _\u03c0\u03b8t_ +1\ufffd _\u2265_ _J_ \ufffd _\u03c0\u03b8t_ \ufffd _\u2212_ 2 _\u03f5._\n\nThis implies that, with this choice of _E_, the comparison ensures the accepted updates yield performance improvements,\nand hence the learning can be monotonic and more stable.\nWe then show that when instantiated with the _Lookback_\ndecision rule and REINFORCE algorithm, Algorithm 1 converges to a near-optimal policy at rate _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ) with high\nprobability. The analysis for the mix-up and three-point strategies follows similar lines. We make the following standard\nassumption.\n\n**Assumption 1** (Smoothness) **.** _The policy class \u03c0\u03b8 is smooth_\n_in \u03b8, and there exists \u03c3 \u2265_ 0 _such that_\n\ufffd\ufffdE _d\u03c0\u03b8 \u00d7\u03c0\u03b8_ \ufffd( _\u2207_ log _\u03c0\u03b8_ ( _A|S_ ))( _\u2207_ log _\u03c0\u03b8_ ( _A|S_ )) _[\u22a4]_ [\ufffd\ufffd\ufffd] _\u2264_ _\u03c3,_\n\n_where d_ _[\u03c0][\u03b8]_ ( _s_ ) _is the discounted-state-visitation distribution_\n_under \u03c0\u03b8._\n\n2This requirement is a worst-case bound on the return range. In\nour experiments, the variance observed is much lower with _E_ =\n5 _\u2212_ 10 _,_ only.\n\ni Assumption 1 is standard in policy gradient studies, e.g.,\n\n(Xu, Liu, and Peng 2018; Wang et al. 2024; Ganesh and Aggarwal 2024). There is a rich family of policies that satisfy\nthe conditions, including the Softmax policy and policies\ndefined through neural networks with smooth and Lipschitz\nactivation functions (Tian, Olshevsky, and Paschalidis 2023).\nFinally, we are all set to quote the convergence of our algorithm.\n\n**Theorem 1** (Convergence) **.** _Under Assumption 1, setting_\n_B_ [2] 2 _T_\n_\u03b7_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [2] ) _and E_ = 2 _\u03f5_ [2] [ln] \ufffd _\u03b4_ \ufffd _, results in J_ ( _\u03c0_ _[\u2217]_ ) _\u2212_\n\n_J_ ( _\u03c0\u03b8T_ ) = _O_ \ufffd _T_ _[\u2212]_ [1] _[/]_ [4][\ufffd] _, with probability at least_ 1 _\u2212_ _\u03b4._\n\nThe deterministic PG method (Agarwal et al. 2021; Xiao\n2022) achieves a faster convergence rate than ours because it\nhas access to the true policy gradient without error. In contrast, our algorithm achieves a similar convergence rate when\nthe algorithm is stochastic and the update is based on policy\ngradient estimation, as in actor-critic algorithms (Xu, Liu,\nand Peng 2018; Suttle et al. 2023; Olshevsky and Gharesifard\n2023; Chen, Sun, and Yin 2021; Wang et al. 2024). This\ndemonstrates that the convergence rate of our approach is\nnot slowed down much by our profiling framework. More\nimportantly, unlike previous works, Theorem 1 provides a\nhigh-probability guarantee on the _last_ iteration, whereas prior\nresults typically only guarantee the expectation or the best\npolicy found during the learning process. This framework requires additional trajectories of order _O_ ( _\u03f5_ _[\u2212]_ [2] ln( _T/\u03b4_ )), which\nis still acceptable when the training samples are redundant.\n\n**Remark 1.** _The same convergence guarantee of Theorem 1_\n_holds for the other two cases. We note that the Mixup is a_\n_special case of Lookback. Because \u03b8_ mix = _\u03bb\u03b8_ _[\u2032]_ +(1 _\u2212_ _\u03bb_ ) _\u03b8t_ =\n_\u03b8t_ + _\u03bb\u03b7\u2207_ [\u02c6] _\u03b8J_ ( _\u03c0\u03b8t_ ) _. Three points strategy adds another point_\n_in Lookback and generates a better reward than Lookback in_\n_every iteration._\n\n**Biased Case.** In the above discussions, we consider the case\nwhere we compare performances based on Monte-Carlo estimation. In practice, however, it is often the case that PG\nmethods are utilized in _actor-critic_ algorithms, where the\nvalue functions are estimated based on the _critic_ . Since the\n_critic_ part is generally inaccurate, the resulting gradient estimations can have bias. Thus, it is important to extend our\nframework to the biased case. Given _\u03b8_, we assume that the\ncritic part provides a biased estimation of the value function\u02c6\n_Q_ _[\u03c0]_ _\u03b8_, such that E[ \u02c6 _Q_ _[\u03c0]_ _\u03b8_ ] = _Q_ _[\u03c0]_ _\u03b8_ + _\u03f5\u03b8,_ where _\u03f5\u03b8_ is the bias\nintroduced by the errors of the critic part. Such results can be\nobtained, for instance, when a deep neural network is used\nto estimate value functions, e.g., (Du et al. 2019; Neyshabur\n2017; Miyato et al. 2018), and is widely adapted in actorcritic analysis, e.g., (Wang et al. 2019a; Zhou and Lu 2023;\nChen et al. 2023; Zhang et al. 2020; Qiu et al. 2021; Kumar,\nKoppel, and Ribeiro 2023; Xu, Wang, and Liang 2020b,a;\nSuttle et al. 2023). It can be further shown that when the\nvalue function estimation is biased, the resulting gradient estimation has a bias of _CA\u03f5\u03b8_, as long as _\u2225\u2207\u03c0\u03b8\u2225\u2264_ _C_ (Sutton\net al. 1999) and _A_ = _|A|_ actions. Therefore, without loss of\ngenerality, we assume the bias of zero-th and first order gradient of _Q_ _[\u03c0][\u03b8]_ are both bounded by some _\u03f5\u03b8_ . We then show the\nconvergence of 1, when the Lookback technique is applied\nto REINFORCE.\n\nEnv. Algo Avg. Return ( _\u00b1_ Std) Rounds to 0.95\u00d7Best Variability _\u2193_ (%)\n\nBase LB MU TP Base LB MU TP LB MU TP\n\nBipedal DDPG _\u2212_ 116 _._ 1 _\u00b1_ 13 _._ 5 _\u2212_ 100 _._ 0 _\u00b1_ 6 _._ 9 _\u2212_ **47** _._ **0** _\u00b1_ **27** _._ **1** _\u2212_ 58 _._ 9 _\u00b1_ 34 _._ 4 \u2013 **1** _._ **0** 1 _._ 3 3 _._ 7 _\u2212_ 39 _\u2212_ **34** _\u2212_ 64\nPPO _\u2212_ 51 _._ 9 _\u00b1_ 109 _._ 2 _\u2212_ 3 _._ 1 _\u00b1_ 66 _._ 1 _\u2212_ 13 _._ 4 _\u00b1_ 8 _._ 0 **8** _._ **9** _\u00b1_ **39** _._ **5 6** _._ **8** 9 _._ 0 \u2013 9 _._ 0 66 **68** 59\n\nTRPO **105** _._ **0** _\u00b1_ **57** _._ **0** _\u2212_ 35 _._ 3 _\u00b1_ 11 _._ 1 _\u2212_ 17 _._ 9 _\u00b1_ 7 _._ 2 _\u2212_ 27 _._ 9 _\u00b1_ 16 _._ 1 **7** _._ **7** \u2013 \u2013 \u2013 67 **82** 56\n\nCarRacing DDPG _\u2212_ 84 _._ 7 _\u00b1_ 4 _._ 2 _\u2212_ **17** _._ **6** _\u00b1_ **3** _._ **6** _\u2212_ 17 _._ 6 _\u00b1_ 3 _._ 6 _\u2212_ 17 _._ 6 _\u00b1_ 3 _._ 6 \u2013 **1** _._ **6** 3 _._ 6 3 _._ 0 _\u2212_ 28 _\u2212_ **23** _\u2212_ 26\nPPO _\u2212_ 63 _._ 2 _\u00b1_ 14 _._ 3 21 _._ 7 _\u00b1_ 23 _._ 0 26 _._ 9 _\u00b1_ 21 _._ 8 **30** _._ **7** _\u00b1_ **39** _._ **5** 2 _._ 3 3 _._ 0 4 _._ 6 **2** _._ **0** _\u2212_ **33** _\u2212_ 48 _\u2212_ 45\n\nTRPO _\u2212_ 72 _._ 8 _\u00b1_ 23 _._ 7 _\u2212_ 14 _._ 7 _\u00b1_ 11 _._ 0 31 _._ 1 _\u00b1_ 45 _._ 2 **42** _._ **4** _\u00b1_ **46** _._ **3** 3 _._ 5 \u2013 3 _._ 7 **3** _._"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around ensuring reliable comparisons between successive policy updates. It uses a concentration inequality (Lemma 1) to bound the probability that an estimated policy return (J-hat) deviates significantly from its true return (J), based on an 'evaluation budget' (E). By collecting 'E' samples (like looping 'E' times to get average measurements), the system can statistically guarantee that with high probability (1-delta), the observed estimate is within 'epsilon' of the true value. Lemma 2 then uses this guarantee: if the estimated new policy's performance appears better, the true performance is very likely to be at least as good (minus a small error 2*epsilon). This 'lookback' comparison ensures that accepted updates generally lead to true improvements, preventing performance degradation. Theorem 1 combines this with a 'smoothness' assumption (like ensuring the search space isn't too jagged) to show the algorithm converges to a near-optimal solution, much like an iterative search algorithm reliably approaching a target value, where 'eta' controls the step size of that iteration.\n\n**Explanation:** Think of an algorithm trying to find the best way to do something, like navigating a complex maze. At each step, it tries a new strategy. But evaluating how 'good' that strategy is isn't perfect; it's like a blurry photo. The paper introduces a way to sharpen that photo: by spending an 'evaluation budget' (E). The larger 'E' is, the clearer the picture becomes, meaning we are very confident (high probability, 1-delta) that our measured improvement is real, not just a fluke (within an error margin, epsilon). This is like running a statistical test: the more trials you do, the more certain you are of your conclusion. This certainty allows the algorithm to only accept changes that genuinely improve performance, ensuring it almost always moves towards a better solution (monotonicity). This stable, directional progress, combined with the assumption that the problem space isn't ridiculously chaotic (smoothness), guarantees that the algorithm will eventually get very close to the absolute best solution. Importantly, it ensures this guarantee for the *final* version of the algorithm, not just the best one it stumbled upon during its journey, even if the initial measurements are systematically off (biased), as long as that bias is bounded."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWith the introduction of the _Versal_ family, AMD presents the _Adaptive Compute Acceleration_\n\n_Platform_ (ACAP) [1], a heterogeneous computing architecture designed to provide high perfor\nmance, low latency, and adaptability within a unified system-on-chip. One of the key innovations\n\nwithin this platform is the _AI Engine_, a specialized accelerator array optimized for high-throughput\n\nmultiply-accumulate (MAC) operations on floating-point and fixed-point vector data.\n\nWe acknowledge prior research efforts that efficiently map generalized matrix\u2013matrix (GEMM)\n\noperations onto the AI Engine, such as _MaxEVA_ [2] and _CHARM_ [3]. However, these works\n\nprimarily target throughput optimization in synthetic matrix\u2013matrix computation scenarios, whereas\n\nour focus is on real-time inference under stringent latency constraints. Furthermore, recurrent neural\n\nnetworks (RNNs) are notoriously difficult to parallelize efficiently on hardware, making their low\nlatency implementation a challenging yet valuable objective.\n\nIn this work, we present a proof-of-concept implementation of a latency-constrained Gated\n\nRecurrent Unit on the Versal AI Engine. The design explores several unconventional aspects of the\n\narchitecture, including the use of free-running kernels [4], row-wise matrix\u2013vector operations for\n\nefficient parallelization across hidden-state dimensions, and a novel utilization of the AI Engine\u2019s\n\ninterface tiles [5] as dynamic data aggregators. These techniques collectively aim to demonstrate\n\nthe feasibility of deploying state-of-the-art models under strict latency constraints, paving the way\n\nfor future low-latency adaptive computing applications. We hope that these methods will inspire\n\nfurther exploration and refinement by the broader research community."}, {"role": "assistant", "content": "**Mechanism:** The core challenge is the inherent sequential dependency in Recurrent Neural Networks (RNNs) where the computation for time-step 't' explicitly relies on the result of 't-1'. Standard parallelization techniques struggle with this 'data dependency' bottleneck. This work overcomes it on the Versal AI Engine, which is a specialized SIMD array for MAC operations, by employing three key mechanisms: First, 'free-running kernels' act like continuously polling loops that consume data as soon as it's available, eliminating idle cycles and scheduling overheads often associated with explicit synchronization. Second, 'row-wise matrix-vector operations' enable parallel decomposition of the next hidden state calculation. Instead of waiting for a full matrix multiplication, they distribute the dot product computations for individual output elements across multiple processing units, similar to parallelizing an independent `for` loop where each iteration contributes to a different element of an output array. Third, 'interface tiles as dynamic data aggregators' means the dedicated data movement units are not merely passive conduits but actively perform on-the-fly data merging or reordering, effectively acting as hardware-accelerated buffers or pre-processors that reduce data staging latency for the main computational units.\n\n**Explanation:** At its heart, an RNN computes a new hidden state and output based on the current input and the *previous* hidden state. This creates a chain reaction that historically makes it difficult to fully pipeline or parallelize without latency. The AI Engine is designed for high-throughput parallel multiplies and adds, akin to a highly optimized `sum(A_i * B_i)` loop runner. To achieve low latency, we effectively prevent the pipeline from stalling. Free-running kernels ensure that processing units are always active, akin to threads constantly checking a shared memory location for new work rather than waiting for an explicit 'start' signal. By performing 'row-wise matrix-vector' operations, we break down the larger, sequential computation into smaller, more parallelizable pieces for each output element, allowing different AI Engine tiles to work on different parts of the next hidden state simultaneously. The 'interface tiles' are crucial because they intelligently manage and aggregate data before it enters the core compute array, minimizing delays from data transfer and preparation. This is like having a smart DMA controller or a specialized hardware queue that can quickly assemble fragmented data segments into a coherent block that the processing units can immediately consume, reducing the 'bus waiting' time and making the entire data path more efficient for single-item processing."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**5** From this point onward, disregard the rest of the algorithm and Output _\u22a5_ in\nevery round where node _i_ is still Undecided\n\n**6 else**\n\n**7** Remove all _j \u2208_ `UndecidedNeighbors` who output 0"}, {"role": "assistant", "content": "**Mechanism:** This section outlines a two-pronged control flow for a node in a distributed system. The first part (line 5) describes a 'stuck state' or 'default output' mechanism: if a node 'i' fails to converge on a decision (remains 'Undecided'), it enters a passive mode, consistently broadcasting a 'null' or 'undefined' signal (\u22a5). This effectively removes it from active consideration in the primary algorithm flow, preventing it from producing potentially stale or blocking information. The second part (line 7) is an active filtering step: when a node is *not* in the stuck state, it dynamically prunes its set of 'UndecidedNeighbors' by removing any that explicitly output '0', which likely signifies a rejection or non-support for the current process.\n\n**Explanation:** Think of line 5 like a function that, if a specific condition (`still Undecided`) is met, simply returns a default `null` or `None` value and then bypasses all further complex logic in subsequent calls. It's a graceful exit strategy for non-converging entities. Line 7 is a dynamic list manipulation: it's akin to iterating through a `HashSet` or `ArrayList` of active participants (neighbors) and removing elements (`j`) that satisfy certain criteria (being `Undecided` AND having `output == 0`). This reduces the number of inputs the node needs to consider, making its local processing more efficient by eliminating irrelevant or uncooperative peers."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nSection 3.3.2 established a methodology for extracting consensus subgraphs that encode the optimal hierarchical and temporal sequencing of reasoning behaviors for each problem type. We now investigate whether\nthese empirically-derived cognitive structures can provide effective _test-time reasoning guidance_, steering\nmodels toward statistically successful reasoning patterns and thereby improving task performance.\n\n**Methodology.** To operationalize cognitive structure guidance, we adopt a straightforward approach: automatically converting each problem type\u2019s consensus subgraph into an actionable prompt that contextualizes\nthe reasoning structure and explicitly scaffolds the model\u2019s problem-solving process. We first generate a lin\n\n19\n\nTable 4: Model performance improvement after steering using cognitive structure guidance (nodes in graph\nAfter _\u2212_ Before\n= 7). Values show percentage change: Before _\u00d7_ 100%. Approximately 50 problems per model and\n\nproblem type, sampled equally from previously incorrect and correct answers. Color intensity indicates\nmagnitude: darker green for larger improvements, darker red for larger degradations. Design problems\nshowed catastrophic failure (0% accuracy) across all models after steering and are excluded.\n\n|Model|Avg.|Log Algo Story Rule Decision Troub Diag Case Dilem Fact|\n|---|---|---|\n|**Hermes-3-Llama-3-8B**|-17.5|+0.0<br>-72.0<br>-68.0<br>-72.0<br>-4.0<br>-8.0<br>+41.2<br>+12.0<br>+56.0<br>+44.0|\n|**DeepScaleR-1.5B**|-52.6|-71.4<br>-56.0<br>-87.0<br>-23.9<br>-50.0<br>-57.1<br>+0.0<br>+14.3<br>-33.3<br>-48.0|\n|**R1-Distill-Llama-70B**|+21.9|+26.8 +12.4<br>+18.8<br>+36.0<br>+28.0<br>+36.0<br>+48.0<br>+48.0<br>+54.1<br>+28.0|\n|**R1-Distill-Llama-8B**|+4.0|+16.8<br>+8.4<br>+36.0<br>+0.0<br>-12.0<br>-4.0<br>+16.7<br>+36.0<br>+48.0<br>+4.0|\n|**R1-Distill-Qwen-14B**|+14.6|+31.1 +50.0<br>+20.1<br>+28.0<br>+28.0<br>+12.0<br>+20.0<br>+28.0<br>+40.0<br>+0.0|\n|**R1-Distill-Qwen-32B**|+22.3|+15.6 +36.0<br>+12.5<br>+40.0<br>+20.0<br>+32.0<br>+36.0<br>+56.0<br>+60.0<br>+40.0|\n|**R1-Distill-Qwen-7B**|-6.3|+8.4<br>-12.4<br>+28.0<br>+24.0<br>+0.0<br>-31.2<br>+66.7<br>+4.0<br>+0.0<br>-4.0|\n|**OpenThinker-32B**|-1.3|-9.4<br>-12.0<br>-30.0<br>+28.0<br>+12.0<br>+4.0<br>+6.9<br>+29.6<br>+37.5<br>+12.0|\n|**Qwen3-14B**|+22.5|+16.2 +32.0<br>+7.5<br>+44.0<br>+20.0<br>+44.0<br>+50.0<br>+52.0<br>+60.0<br>+32.0|\n|**Qwen3-32B**|+14.8|+11.8 +24.0<br>+20.6<br>+20.0<br>+24.0<br>+15.2<br>+24.2<br>+41.9<br>+19.5<br>+48.0|\n|**Qwen3-8B**|+13.8|+3.1<br>+36.0<br>+11.1<br>+24.1<br>+16.0<br>+28.0<br>+48.0<br>+36.0<br>+7.9<br>+48.0|\n\nearized representation of each behavioral graph, then apply an automated prompt construction procedure to\nproduce test-time guidance instructions (examples provided in our codebase). This fully automated pipeline,\nrequiring no expert prompt engineering, allows us to assess whether models can leverage structural guidance\nwithout hand-crafted templates.\n\nWe evaluate this approach on a Distribution of Cognitive Elements Considered by Humans vs ~~.~~ LLMs\n\n**90**\n\nstratified sample of approximately"}, {"role": "assistant", "content": "**Mechanism:** The mechanism is the injection of external, structured control flow into the large language model's (LLM) inference process via contextual prompting. Instead of the LLM purely relying on its learned internal associations and inductive biases to generate a reasoning chain, an empirically derived, linearized sequence of optimal reasoning steps ('consensus subgraph') is prepended to the input query. This acts as a programmatic scaffold, guiding the LLM's token generation towards a statistically validated path.\n\n**Explanation:** At its core, this is an advanced form of prompt engineering, but automated and based on observed human behavior. We're not changing the model's weights or architecture; we're providing a highly structured 'algorithm' within the prompt itself. Think of it like giving a program a specific function to execute: the consensus subgraph is serialized into a string of natural language instructions. When the model processes this input, it attempts to 'execute' these instructions as part of its generative process, much like following a script. This constrains the model's vast output space, steering it towards known successful reasoning trajectories. The observed performance improvements (e.g., R1-Distill-Llama-70B) suggest that for certain models and tasks, this explicit guidance can regularize the reasoning process, preventing common 'hallucinations' or inefficient paths. Conversely, degradations indicate that the prescribed structure might conflict with a model's inherent strengths or lead to misinterpretations, effectively providing sub-optimal 'code' for that specific model."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe introduced _Reward Profiling_, a general-purpose wrapper\napplicable to policy gradient-based methods to enforce monotonic improvements. By \u201clooking back\u201d at the pre-update performance after gradient backpropagation and conditionally\naccepting, rejecting, or blending candidate updates, catastrophic collapses are reduced through stable learning. Empirically, across both on-policy ( **PPO**, **TRPO** ) and off-policy\n( **DDPG** ) algorithms with actor-critic frameworks, and across\ndense-reward control tasks and high-DOF locomotion benchmarks, Reward Profiling mostly matched or improved returns\nalong with the variance, sped up convergence relative to\nvanilla baselines. A key trade-off governed by the number of\nevaluation rollouts _E_ for practical implementation: moderate\nvalues of _E_ tend to strike the best balance between stability\nand responsiveness. Watching DDPG\u2019s triumph with it, the integration of reward profiling into the Reacher task demonstrates its effectiveness in a realistic continuous-control setting. Profiling yielded markedly smoother learning curves\nunder DDPG, motivating its use in off-policy, replay-buffer\ncases. While Reward Profiling incurs only _O_ (log _T_ ) rollouts\nover _T_ iterations, the cost may be nontrivial in expensive\nsimulators. On sparse-reward and large discrete-action tasks\n(e.g., Atari), this could be tested, adjusting _E_ dynamically\nbased on some uncertainty measure, or incorporating more\nselective updates for the most informative candidates.\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-6-2.png)\n**Acknowledgment**\n\nThe work of S.A and Y.W is partially supported by DARPA\nunder Agreement No. HR0011-24-9-0427.\n\n**References**\n\nAgarwal, A.; Kakade, S. M.; Lee, J. D.; and Mahajan, G.\n2021. On the theory of policy gradient methods: Optimality,\napproximation, and distribution shift. _Journal of Machine_\n_Learning Research_, 22(98): 1\u201376.\n\nBrockman, G.; Cheung, V.; Pettersson, L.; Schneider, J.;\nSchulman, J.; Tang, J.; and Zaremba, W. 2016. OpenAI\nGym. _arXiv preprint arXiv:1606.01540_ .\n\nChen, T.; Sun, Y.; and Yin, W. 2021. Closing the Gap: Tighter\nAnalysis of Alternating Stochastic Gradient Methods for\nBilevel Problems. In Ranzato, M.; Beygelzimer, A.; Dauphin,\nY.; Liang, P.; and Vaughan, J. W., eds., _Advances in Neural_\n_Information Processing Systems_, volume 34, 25294\u201325307.\nCurran Associates, Inc.\n\nChen, X.; Duan, J.; Liang, Y.; and Zhao, L. 2023. Global\nconvergence of two-timescale actor-critic for solving linear\nquadratic regulator. In _Proceedings of the AAAI Conference_\n_on Artificial Intelligence_, volume 37, 7087\u20137095.\n\nChen, Y.-J.; Huang, N.-C.; Lee, C.-P.; and Hsieh, P.-C. 2024.\nAccelerated Policy Gradient: On the Convergence Rates\nof the Nesterov Momentum for Reinforcement Learning.\narXiv:2310.11897.\n\nChung, W.; Thomas, V.; Machado, M. C.; and Roux, N. L.\n2021. Beyond Variance Reduction: Understanding the True\nImpact of Baselines on Policy Optimization. In Meila, M.;\nand Zhang, T., eds., _Proceedings of the 38th International_\n_Conference on Machine Learning_, volume 139 of _Proceed-_\n_ings of Machine Learning Research_, 1999\u20132009. PMLR.\n\nCohen, A.; Teng, E.; Berges, V.-P.; Dong, R.-P.; Henry, H.;\nMattar, M.; Zook, A.; and Ganguly, S. 2022. On the Use and\nMisuse of Absorbing States in Multi-agent Reinforcement\nLearning. _RL in Games Workshop AAAI 2022_ .\n\nDu, S.; Lee, J.; Li, H.; Wang, L.; and Zhai, X. 2019. Gradient\ndescent finds global minima of deep neural networks. In\n_International conference on machine learning_, 1675\u20131685.\nPMLR.\n\nDutta, A.; Bergou, E. H.; Abdelmoniem, A. M.; Ho, C.-Y.;\nSahu, A. N.; Canini, M.; and Kalnis, P. 2020. On the discrepancy between the theoretical analysis and practical implementations of compressed communication for distributed\ndeep learning. In _Proceedings of the AAAI Conference on_\n_Artificial Intelligence_, volume 34, 3817\u20133824.\n\nDutta, A.; Bergou, E. H.; Boucherouite, S.; Werge, N.; Kandemir, M.; and Li, X. 2023. Demystifying the Myths and\nLegends of Nonconvex Convergence of SGD. _arXiv preprint_\n_arXiv:2310.12969_ .\n\nDutta, A.; Das, S.; Nielsen, J.; Chakraborty, R.; and Shah,\nM. 2024. Multiview Aerial Visual Recognition (MAVREC):\nCan Multi-view Improve Aerial Visual Perception? In _Pro-_\n_ceedings of the IEEE/CVF Conference on Computer Vision_\n_and Pattern Recognition_, 22678\u201322690.\n\nEllenberger, B. 2018\u20132019. PyBullet Gymperium. https:\n//github.com/benelot/pybullet-gym.\n\nFujimoto, S.; van Hoof, H.; and Meger, D. 2018. Addressing Function Approximation Error in Actor-Critic Methods.\nIn Dy, J.; and Krause, A., eds., _Proceedings of the 35th In-_\n_ternational Conference on Machine Learning_, volume 80\nof _Proceedings of Machine Learning Research_, 1587\u20131596.\nPMLR.\n\nGanesh, S.; and Aggarwal, V. 2024. An accelerated multilevel monte carlo approach for average reward reinforcement\nlearning with general policy parametrization. _arXiv e-prints_,\narXiv\u20132407.\n\nHaarnoja, T.; Zhou, A.; Abbeel, P.; and Levine, S. 2018. Soft\nActor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. arXiv:1801.01290.\nHoeffding, W. 1994. Probability inequalities for sums of\nbounded random variables. _The collected works of Wassily_\n_Hoeffding_, 409\u2013426.\nIlyas, A.; Engstrom, L.; Santurkar, S.; Tsipras, D.; Janoos,\nF.; Rudolph, L.; and Madry, A. 2018. A closer look at deep\npolicy gradients. _arXiv preprint arXiv:1811.02553_ .\nIslam, R.; Henderson, P.; Gomrokchi, M.; and Precup, D.\n2017. Reproducibility of Benchmarked Deep Reinforcement\nLearning Tasks for Continuous Control. arXiv:1708.04133.\nJuliani, A.; Berges, V.-P.; Teng, E.; Cohen, A.; Harper, J.;\nElion, C.; Goy, C.; Gao, Y.; Henry, H.; Mattar, M.; and Lange,\nD. 2020. Unity: A general platform for intelligent agents.\n_arXiv preprint arXiv:1809.02627_ .\nKonda, V.; and Tsitsiklis, J. 1999. Actor-critic algorithms.\n_Advances in neural information processing systems_, 12.\n\nKumar, H.; Koppel, A.; and Ribeiro, A. 2023. On the sample\ncomplexity of actor-critic method for reinforcement learning\nwith function approximation. _Machine Learning_, 112(7):\n2433\u20132467.\n\nLehmann, M. 2024. The definitive guide to policy gradients in deep reinforcement learning: Theory, algorithms and\nimplementations. _arXiv preprint arXiv:2401.13662_ .\nLillicrap, T. P.; Hunt, J. J.; Pritzel, A.; Heess, N.; Erez, T.;\nTassa, Y.; Silver, D.; and Wierstra, D. 2015. Continuous\ncontrol with deep reinforcement learning. _arXiv preprint_\n_arXiv:1509.02971_ .\n\nMcCandlish, S.; Kaplan, J.; Amodei, D.; and Team, O. D.\n2018. An empirical model of large-batch training. _arXiv_\n_preprint arXiv:1812.06162_ .\nMiyato, T.; Kataoka, T.; Koyama, M.; and Yoshida, Y. 2018.\nSpectral normalization for generative adversarial networks.\n_arXiv preprint arXiv:1802.05957_ .\n\nMore, J. J.; Garbow, B. S.; and Hillstrom, K. E. 1994. User\u00b4\nManual for MINPACK-2. In _Technical Report ANL-94/21,_\n_Argonne National Laboratory_ .\n\nMuehlebach, M.; and Jordan, M. I. 2021. Optimization with\nMomentum: Dynamical, Control-Theoretic, and Symplectic\nPerspectives. arXiv:2002.12493.\nNeyshabur, B. 2017. Implicit regularization in deep learning.\n_arXiv preprint arXiv:1709.01953_ .\nOlshevsky, A.; and Gharesifard, B. 2023. A Small Gain Analysis of Single Timescale Actor Critic. arXiv:2203.02591.\nOmidshafiei, S.; Pazis, J.; Amato, C.; How, J. P.; and Vian, J.\n2017. Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability. In Precup, D.;\n\nand Teh, Y. W., eds., _Proceedings of the 34th International_\n_Conference on Machine Learning_, volume 70 of _Proceedings_\n_of Machine Learning Research_, 2681\u20132690. PMLR.\n\nPalma, P.; Smith, G.; Kas\u00b8k, M.; and Leite, T. 2018. MultiAgent Reinforcement Learning with Hysteretic Q-Learning.\nIn _Proceedings of the 17th European Conference on Ma-_\n_chine Learning and Principles and Practice of Knowledge_\n_Discovery in Databases (ECML-PKDD)_, 304\u2013319.\n\nPeters, J.; and Schaal, S. 2006. Policy gradient methods\nfor robotics. In _2006 IEEE/RSJ international conference on_\n_intelligent robots and systems_, 2219\u20132225. IEEE.\n\nQiu, S.; Yang, Z.; Ye, J.; and Wang, Z. 2021. On finitetime convergence of actor-critic algorithm. _IEEE Journal on_\n_Selected Areas in Information Theory_, 2(2): 652\u2013664.\n\nRaffin, A.; Hill, A.; Gleave, A.; Kanervisto, A.; Ernestus, M.;\nand Dormann, N. 2021. Stable-Baselines3: Reliable Reinforcement Learning Implementations. _Journal of Machine_\n_Learning Research_, 22(268): 1\u20138.\n\nSchulman, J.; Levine, S.; Abbeel, P.; Jordan, M.; and Moritz,\nP. 2015. Trust region policy optimization. In _International_\n_conference on machine learning_, 1889\u20131897. PMLR.\n\nSchulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and\nKlimov, O. 2017. Proximal policy optimization algorithms.\n_arXiv preprint arXiv:1707.06347_ .\n\nSutskever, I.; Martens, J.; Dahl, G.; and Hinton, G. 2013. On\nthe importance of initialization and momentum in deep learning. In Dasgupta, S.; and McAllester, D., eds., _Proceedings_\n_of the 30th International Conference on Machine Learning_,\nvolume 28 of _Proceedings of Machine Learning Research_,\n1139\u20131147. Atlanta, Georgia, USA: PMLR.\n\nSuttle, W. A.; Bedi, A.; Patel, B.; Sadler, B. M.; Koppel, A.;\nand Manocha, D. 2023. Beyond exponentially fast mixing in\naverage-reward reinforcement learning via multi-level monte\ncarlo actor-critic. In _International Conference on Machine_\n_Learning_, 33240\u201333267. PMLR.\n\nSutton, R. S. 1984. _Temporal credit assignment in reinforce-_\n_ment learning_ . University of Massachusetts Amherst.\n\nSutton, R. S.; Barto, A. G.; et al. 1998. _Reinforcement learn-_\n_ing: An introduction_, volume 1. MIT press Cambridge.\n\nSutton, R. S.; McAllester, D.; Singh, S.; and Mansour, Y.\n1999. Policy gradient methods for reinforcement learning\nwith function approximation. _Advances in neural information_\n_processing systems_, 12.\n\nTian, H.; Olshevsky, A.; and Paschalidis, Y. 2023. Convergence of actor-critic with multi-layer neural networks. _Ad-_\n_vances in neural information processing systems_, 36: 9279\u2013\n9321.\n\nTodorov, E.; Erez, T.; and Tassa, Y. 2012. Mujoco: A physics\nengine for model-based control. In _2012 IEEE/RSJ interna-_\n_tional conference on intelligent robots and systems_, 5026\u2013\n5033. IEEE.\nTowers, M.; Kwiatkowski, A.; Terry, J.; Balis, J. U.; Cola,G. D.; Deleu, T.; Goulao, M.; Kallinteris, A.; Krimmel, M.;\u02dc\nKG, A.; Perez-Vicente, R.; Pierre, A.; Schulhoff, S.; Tai,\u00b4\nJ. J.; Tan, H.; and Younis, O. G. 2024. Gymnasium: A Standard Interface for Reinforcement Learning Environments.\narXiv:2407.17032.\n\nWang, L.; Cai, Q.; Yang, Z.; and Wang, Z. 2019a. Neural policy gradient methods: Global optimality and rates of\nconvergence. _arXiv preprint arXiv:1909.01150_ .\nWang, Y.; He, H.; Tan, X.; and Gan, Y. 2019b. Trust\nRegion-Guided Proximal Policy Optimization. In Wallach,\nH.; Larochelle, H.; Beygelzimer, A.; d'Alche-Buc, F.; Fox,\u00b4\nE.; and Garnett, R., eds., _Advances in Neural Information_\n_Processing Systems_, volume 32. Curran Associates, Inc.\nWang, Y.; Wang, Y.; Zhou, Y.; and Zou, S. 2024. Nonasymptotic analysis for single-loop (natural) actor-critic\nwith compatible function approximation. _arXiv preprint_\n_arXiv:2406.01762_ .\n\nWilliams, R. J. 1992. Simple statistical gradient-following\nalgorithms for connectionist reinforcement learning. _Machine_\n_learning_, 8: 229\u2013256.\nWu, Y.; Mansimov, E.; Grosse, R. B.; Liao, S.; and Ba, J.\n2017. Scalable trust-region method for deep reinforcement\nlearning using kronecker-factored approximation. _Advances_\n_in neural information processing systems_, 30.\nXiao, L. 2022. On the Convergence Rates of Policy Gradient\nMethods. arXiv:2201.07443.\n\nXie, Z.; Zhang, Q.; Yang, F.; Hutter, M.; and Xu, R. 2025.\nSimple Policy Optimization. In Singh, A.; Fazel, M.; Hsu, D.;\nLacoste-Julien, S.; Berkenkamp, F.; Maharaj, T.; Wagstaff,\nK.; and Zhu, J., eds., _Proceedings of the 42nd International_\n_Conference on Machine Learning_, volume 267 of _Proceed-_\n_ings of Machine Learning Research_, 68813\u201368824. PMLR.\nXu, T.; Liu, Q.; and Peng, J. 2018. Stochastic Variance Reduction for Policy Gradient Estimation. arXiv:1710.06034.\nXu, T.; Wang, Z.; and Liang, Y. 2020a. Improving sample\ncomplexity bounds for (natural) actor-critic algorithms. _Ad-_\n_vances in Neural Information Processing Systems_, 33: 4358\u2013\n4369.\n\nXu, T.; Wang, Z.; and Liang, Y. 2020b. Non-asymptotic\nconvergence analysis of two time-scale (natural) actor-critic\nalgorithms. _arXiv preprint arXiv:2005.03557_ .\nZhang, H.; Cisse, M.; Dauphin, Y. N.; and Lopez-Paz, D.\n2017. mixup: Beyond empirical risk minimization. _arXiv_\n_preprint arXiv:1710.09412_ .\nZhang, S.; Liu, B.; Yao, H.; and Whiteson, S. 2020. Provably\nconvergent two-timescale off-policy actor-critic with function\napproximation. In _International Conference on Machine_\n_Learning_, 11204\u201311213. PMLR.\nZhou, M.; and Lu, J. 2023. Single timescale actor-critic\nmethod to solve the linear quadratic regulator with convergence guarantees. _Journal of Machine Learning Research_,\n24(222): 1\u201334.\n\n**APPENDIX**\n\n**Organization.** We organize the Appendix into two main parts. **Section A** presents the theoretical materials used in the main text\nand provide proofs of concentration bounds, monotonicity guarantees, smoothness results, and the convergence theorems stated\nin \u00a75 of the main paper. **Section B** contains implementation and experimental details. We mention the network architectures,\nhyperparameters, and profiling variants, followed by more empirical results, including PPO/TRPO/DDPG/TD3 ablations, full\nreturn trajectories across all environments, and the Unity ML-Agents Reacher setup and integration details reported in \u00a76.\n\n**A** **Theoretical Guarantee**\n\nThis appendix contains complete proofs of all theoretical claims in \u00a75.\n\n**A.1 Concentration Inequality (Proof of Lemma 1)**\nLet _{\u03c4i}_ _[E]_ _i_ =1 [be the] _[ E][ i.i.d.]_ [ trajectories sampled from policy] _[ \u03c0]_ [, and define]\n\n_Xi_ := _G_ ( _\u03c4i_ ) _,_\n\nso that by construction\n0 _\u2264_ _Xi \u2264_ _B,_ E[ _Xi_ ] = _J_ ( _\u03c0_ ) _,_\nwhere _B_ = _R_ max _/_ (1 _\u2212_ _\u03b3_ ) and _J_ ( _\u03c0_ ) = E _\u03c4_ _\u223c\u03c0_ [ _G_ ( _\u03c4_ )] is the true expected return. From Eq. (2) we have\n\n_J_ \u02c6( _\u03c0_ ) = E _E_ [ _X_ ] = _E_ 1\n\n_E_\n\ufffd _Xi._\n\n_i_ =1\n\nApplying Hoeffding\u2019s inequality to the bounded, independent variables _{Xi}_ (Hoeffding 1994) gives for any _\u03f5 >_ 0 the\none-sided tail bounds\n\n\u02c6\nP _J_ ( _\u03c0_ ) _\u2212_ _J_ ( _\u03c0_ ) _\u2265_ _\u03f5_ _\u2264_ exp _\u2212_ [2] _[ E \u03f5]_ _B_ [2] [2] _,_\n\ufffd \ufffd \ufffd \ufffd\n\nA union bound yields\n\n\u02c6\nP\ufffd\ufffd\ufffd _J_ ( _\u03c0_ ) _\u2212_ _J_ ( _\u03c0_ )\ufffd\ufffd _\u2265_ _\u03f5_ \ufffd _\u2264_ 2 exp\ufffd _\u2212_ [2] _[ E \u03f5]_ _B_ [2] [2] \ufffd _,_\n\nas claimed.\n\n**A.2 High-Probability Monotonicity (Proof of Lemma 2)**\n\nFrom Lemma 1, each empirical estimate _J_ [\u02c6] ( _\u03c0_ ) satisfies\n\nP\ufffd _|J_ [\u02c6] ( _\u03c0_ ) _\u2212_ _J_ ( _\u03c0_ ) _| \u2264_ _\u03f5_ \ufffd _\u2265_ 1 _\u2212_ 2 exp\ufffd _\u2212_ [2] _[E \u03f5]_ _B_ [2] [2] \ufffd _._\n\nBy our choice of 2 exp( _\u2212_ 2 _E\u03f5_ [2] _/B_ [2] ) _\u2264_ _\u03b4/T_, each single evaluation errs by at most _\u03f5_ with prob. _\u2265_ 1 _\u2212_ _\u03b4/T_ . At each update _t_\ntwo independent evaluations (the \u201cold\u201d policy, and the \u201cnew\u201d) are performed, so by a union bound over the _T_ updates, with prob.\n_\u2265_ 1 _\u2212_ _\u03b4 all_ 2 _T_ estimates are simultaneously within _\u03f5_ of their true values. Let\u2019s fix any iteration _t \u2208_ [ _T_ ] at which the lookback\nrule accepts: \u02c6\n_J_ \ufffd _\u03c0\u03b8t_ +1\ufffd _\u2265_ _J_ [\u02c6] \ufffd _\u03c0\u03b8t_ \ufffd _._\nSince both estimates deviate from the truth by at most _\u03f5_, we have\n\n_J_ \ufffd _\u03c0\u03b8t_ +1\ufffd _\u2265_ _J_ [\u02c6] \ufffd _\u03c0\u03b8t_ +1\ufffd _\u2212_ _\u03f5 \u2265_ _J_ [\u02c6] \ufffd _\u03c0\u03b8t_ \ufffd _\u2212_ _\u03f5 \u2265_ _J_ \ufffd _\u03c0\u03b8t_ \ufffd _\u2212_ 2 _\u03f5._\n\nSince this holds for every _t \u2208{_ 1 _, . . ., T_ _}_ with prob. 1 _\u2212_ _\u03b4_, the lemma follows.\n\n**A.3 Verification of Assumption 1 (Softmax Policy Class)**\n**Lemma 3.** _If_\n_\u03c0\u03b8_ ( _a | s_ ) _\u221d_ exp\ufffd _\u2212\u03d5_ ( _s, a_ ) _[\u22a4]_ _\u03b8_ \ufffd _with_ _\u2225\u03d5_ ( _s, a_ ) _\u2225\u2264_ 1 _,_\n\n_then for all_ ( _s, a_ ) _,_\n\ufffd\ufffd _\u2207\u03b8_ log _\u03c0\u03b8_ ( _a | s_ )\ufffd\ufffd _\u2264_ 2 _._\nWe have\nlog _\u03c0\u03b8_ ( _a | s_ ) = _\u2212_ _\u03d5_ ( _s, a_ ) _[\u22a4]_ _\u03b8 \u2212_ log\ufffd _e_ _[\u2212][\u03d5]_ [(] _[s,b]_ [)] _[\u22a4][\u03b8]_ _._\n\n_b_\n\nHence\n\n_b_ _[e][\u2212][\u03d5]_ [(] _[s,b]_ [)] _[\u22a4][\u03b8]_ _[\u03d5]_ [(] _[s][,][ b]_ [)]\n~~\ufffd~~ _b_ _[e][\u2212][\u03d5]_ [(] _[s,b]_ [)] _[\u22a4][\u03b8]_\n\n\ufffd\n_\u2207\u03b8_ log _\u03c0\u03b8_ ( _a | s_ ) = _\u2212_ _\u03d5_ ( _s, a_ ) +\n\n_._\n_b_ _[e][\u2212][\u03d5]_ [(] _[s,b]_ [)] _[\u22a4][\u03b8]_\n\nBy the triangle inequality and _\u2225\u03d5_ ( _s, \u00b7_ ) _\u2225\u2264_ 1, _\u2225\u2207_ log _\u03c0\u03b8_ ( _a | s_ ) _\u2225\u2264_ 1 + 1 = 2 _._\n\n**A.4 Smoothness and Descent Properties**\n**Lemma 4** (Smoothness of _J_ ( _\u03b8_ )) **.** _Under Assumption 1, the expected return J_ ( _\u03c0\u03b8_ ) _is L-smooth in \u03b8: for all \u03b8, \u03b8_ _[\u2032]_ _,_\n\n_\u2225\u2207J_ ( _\u03c0\u03b8_ ) _\u2212\u2207J_ ( _\u03c0\u03b8\u2032_ ) _\u2225\u2264_ _L \u2225\u03b8 \u2212_ _\u03b8_ _[\u2032]_ _\u2225._\n\nFollows from standard policy gradient smoothness results (e.g. Lemma D.3 in (Agarwal et al. 2021)), using the bounded\nFisher information in Assumption 1.\n**Lemma 5** (Descent step) **.** _Let Gt be an unbiased estimate of \u2207J_ ( _\u03c0\u03b8t_ ) _with \u2225Gt\u2225\u2264_ _G_ max _. If \u03b8t_ +1 = _\u03b8t_ + _\u03b7 Gt, then_\n\nE\ufffd _J_ ( _\u03c0\u03b8t_ +1) _| \u03b8t_ \ufffd _\u2265_ _J_ ( _\u03c0\u03b8t_ ) + _\u03b7 \u2225\u2207J_ ( _\u03c0\u03b8t_ ) _\u2225_ [2] _\u2212_ _L_ 2 _[\u03b7]_ [2] _[ G]_ max [2] _[.]_\n\nBy the _L_ -smoothness of _J_ ( _\u03c0\u03b8_ ) (Lemma 4), for any _\u03b8, \u03b8_ _[\u2032]_ we have\n\n_J_ \ufffd _\u03c0\u03b8_ _[\u2032]_ [\ufffd] _\u2265_ _J_ \ufffd _\u03c0\u03b8_ \ufffd + _\u2207J_ ( _\u03c0\u03b8_ ) _[\u22a4]_ ( _\u03b8_ _[\u2032]_ _\u2212_ _\u03b8_ ) _\u2212_ _[L]_\n\n2 _[\u2225][\u03b8][\u2032][ \u2212]_ _[\u03b8][\u2225]_ [2] _[.]_\n\nSetting _\u03b8_ = _\u03b8t_ and _\u03b8_ _[\u2032]_ = _\u03b8t_ +1 = _\u03b8t_ + _\u03b7 Gt_ gives\n\n_J_ \ufffd _\u03c0\u03b8t_ +1\ufffd _\u2265_ _J_ \ufffd _\u03c0\u03b8t_ \ufffd + _\u03b7 \u2207J_ ( _\u03c0\u03b8t_ ) _[\u22a4]_ _Gt \u2212_ _[L]_\n\n2 _[\u03b7]_ [2] _[ \u2225][G][t][\u2225]_ [2] _[.]_\n\nTaking the conditional expectation E[ _\u00b7 | \u03b8t_ ] and using linearity of expectation, the unbiasedness E[ _Gt | \u03b8t_ ] = _\u2207J_ ( _\u03c0\u03b8t_ ), and the\nbound _\u2225Gt\u2225\u2264_ _G_ max, we obtain\n\nE\ufffd _J_ ( _\u03c0\u03b8t_ +1) _| \u03b8t_ \ufffd _\u2265_ _J_ \ufffd _\u03c0\u03b8t_ \ufffd + _\u03b7 \u2207J_ ( _\u03c0\u03b8t_ ) _[\u22a4]_ E[ _Gt | \u03b8t_ ] _\u2212_ _[L]_ \ufffd _\u2225Gt\u2225_ [2] _| \u03b8t_ \ufffd\n\n2 _[\u03b7]_ [2][ E]\n\n= _J_ \ufffd _\u03c0\u03b8t_ \ufffd + _\u03b7 \u2225\u2207J_ ( _\u03c0\u03b8t_ ) _\u2225_ [2] _\u2212_ _[L]_ max _[,]_\n\n2 _[\u03b7]_ [2] _[ G]_ [2]\n\nwhich yields the claimed descent inequality.\n\n**A.5 Proof of Theorem 1**\nChoose _\u03b7_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [2] ), _\u03f5_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ), and _E_ = _[B]_ [2][2]\n\n2 _[B]_ _\u03f5_ [2] [ln] \ufffd 2 _\u03b4T_\n\n2 _T_\n\n_\u03b7_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [2] ), _\u03f5_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ), and _E_ = 2 _[B]_ _\u03f5_ [2] [ln] \ufffd _\u03b4_ \ufffd.\n\nBy Lemma 5 and telescoping,\n\n_T \u2212_ 1\n\n1\n_T_ \ufffd E _\u2225\u2207J_ ( _\u03c0_\n\n_T \u2212_ 1\n\ufffd\n\n\ufffd E _\u2225\u2207J_ ( _\u03c0\u03b8t_ ) _\u2225_ [2] = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [2] ) _,_\n\n_t_ =0\n\nso min _t<T \u2225\u2207J_ ( _\u03c0\u03b8t_ ) _\u2225_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ). Lemma 41 of(Agarwal et al. 2021) then gives [\u02d9]\n\n_J_ ( _\u03c0_ _[\u2217]_ ) _\u2212_ max _t<T_ _[J]_ [(] _[\u03c0][\u03b8][t]_ [) =] _[ O]_ [(] _[T][ \u2212]_ [1] _[/]_ [4][)] _[.]_\n\nMeanwhile, Lemma 2 ensures (w.p. _\u2265_ 1 _\u2212_ _\u03b4_ ) each accepted update loses at most 2 _\u03f5_ = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ), so, by immediately reverting\nany worse update, the final policy\u2019s return can never fall more than 2 _\u03f5_ below the best one seen:\n\nmax _t<T_ _[J]_ [(] _[\u03c0][\u03b8][t]_ [)] _[ \u2264]_ _[J]_ [(] _[\u03c0][\u03b8][T]_ [ ) + 2] _[\u03f5.]_\n\nCombining the two,\n_J_ ( _\u03c0_ _[\u2217]_ ) _\u2212_ _J_ ( _\u03c0\u03b8T_ ) = _O_ ( _T_ _[\u2212]_ [1] _[/]_ [4] ) _,_\n\nas claimed.\n\n**A.6 Proof of Theorem 2 (Biased Critic Case)**\n\nIn this section, we assume\nE[ _V_ [\u02dc] _t_ ] = _Vt_ + _\u03f5t,_\n\nwhere _\u03f5t_ is the bias that we assume is also upper bounded as well as its gradient by some _\u03f5 \u2265_ 0, i.e., the estimation of the value\nfunction is accurate in both zero [th] and first order. Such an assumption can be satisfied when a deep neural network is used\nto estimate value functions, e.g., (Du et al. 2019; Neyshabur 2017; Miyato et al. 2018), and is widely assumed in actor-critic\nanalysis, e.g., (Wang et al. 2019a; Zhou and Lu 2023; Chen et al. 2023; Zhang et al. 2020; Qiu et al. 2021; Kumar, Koppel, and\nRibeiro 2023; Xu, Wang, and Liang 2020b,a; Suttle et al. 2023).\n\n**Lemma 6.** _Algorithm 1 produces an monotonic sequence of iterates modulo \u03f5. In the sense that Vt_ +1 _\u2265_ _Vt \u2212_ 2 _\u03f5 given \u03b8t and Gt_\n_for all k \u2265_ 0 _._\n\nWe have by 1: _V_ [\u02dc] _t_ +1 _\u2265_ _V_ [\u02dc] _t._ Now, by taking the conditional expectation of the previous inequality, conditional on _\u03b8t_ and _Gt_, we\nget _Vt_ +1 + _\u03f5t_ +1 _\u2265_ _Vt_ + _\u03f5t._ which implies _Vt_ +1 _\u2265_ _Vt \u2212_ 2 _\u03f5._\n\n**Lemma 7.** _(Lemma D.3 of (Agarwal et al. 2021)) The value functions are L-smooth, i.e., there exists some constant L, such that_\n\n_\u2225\u2207\u03b8V_ [\u02dc] 1 _\u2212\u2207\u03b8V_ [\u02dc] 2 _\u2225\u2264_ _L\u2225\u03b8_ 1 _\u2212_ _\u03b8_ 2 _\u2225._ (4)\n\n**Lemma 8.** _For all k \u2265_ 0 _,_\n\nE [ _Vt_ +1 _|\u03b8t_ ] _\u2265_ _Vt_ + _\u03b7t\u2225\u2207Vt\u2225_ 2 [2] _[\u2212]_ _[L]_ 2 _[\u03b7]_ _t_ [2][E][(] _[\u2225][G][t][\u2225]_ [2] 2 _[|][\u03b8][t]_ [)] _[ \u2212]_ [2] _[\u03f5][ \u2212]_ _[\u03b7][t][\u03f5][\u2225\u2207][V][t][\u2225]_ [2] _[.]_ (5)\n\nWe have\n\n_V_ \u02dc _t_ +1 _\u2265_ _V_ \u02dc ( _\u03b8t_ + _\u03b7Gt_ ) _\u2265_ _V_ \u02dc _t_ + _\u03b7tG_ _[T]_ _t_ _[\u2207][V]_ [\u02dc] _[t]_ _[\u2212]_ _[L]_ 2 _[\u03b7]_ _t_ [2] _[\u2225][G][t][\u2225]_ [2] 2 _[,]_\n\nwhere the algorithm enforces the first inequality, and the second inequality comes from the _L_ -Smoothness of _V_ [\u02dc] .\nNow, by taking the conditional expectation of the previous inequality, conditional on _\u03b8t_ and _Gt_, we get\n\n_Vt_ +1 + _\u03f5t_ +1 _\u2265_ _Vt_ + _\u03f5t_ + _\u03b7tG_ _[T]_ _t_ _[\u2207][V][t]_ [+] _[ \u03b7][t][G][T]_ _t_ _[\u2207][\u03f5][t]_ _[\u2212]_ _[L]_ 2 _[\u03b7]_ _t_ [2] _[\u2225][G][t][\u2225]_ [2] 2 _[.]_\n\nNow, by taking the expectation over the randomness on _Gt_ and the upper bound on _\u03f5t_ we get:\n\nE [ _Vt_ +1 _|\u03b8t_ ] _\u2265_ _Vt_ + _\u03b7t\u2225\u2207Vt\u2225_ 2 [2] _[\u2212]_ _[L]_ 2 _[\u03b7]_ _t_ [2][E][(] _[\u2225][G][t][\u2225]_ [2] 2 _[|][\u03b8][t]_ [)] _[ \u2212]_ [2] _[\u03f5][ \u2212]_ _[\u03b7][t][\u03f5][\u2225\u2207][V][t][\u2225]_ [2] _[.]_\n\nBefore proving our main result, we need another intermediate result as stated below.\n\n**Lemma 9.** _It holds that_\n\nE \ufffd _\u2225Gt\u2225_ [2] _|\u03b8t_ \ufffd _\u2264_ (1 _\u2212\u03c3\u03b3_ ) [4] _[.]_ (6)\n\nNote that when _\u03b8t_ is fixed, the stochastic policy gradient is\n\n1\n_Gt_ = (7)\n1 _\u2212_ _\u03b3_ _[\u2207]_ [log] _[ \u03c0][t]_ [(] _[a][|][s]_ [)] _[Q][t]_ [(] _[s, a]_ [)] _[,]_\n\nwhere ( _s, a_ ) _\u223c_ _d_ _[\u03c0]_ _t_ [(] _[S]_ [)] _[ \u00d7][ \u03c0][t]_ [(] _[A][|][S]_ [)][. Note that]\n\n1\n_\u2225Gt\u2225_ [2] = _\u2225_\n1 _\u2212_ _\u03b3_ _[\u2207]_ [log] _[ \u03c0][t]_ [(] _[a][|][s]_ [)] _[Q][t]_ [(] _[s, a]_ [)] _[\u2225]_ [2]\n\n1\n\n=\n(1 _\u2212_ _\u03b3_ ) [2] _[Q][t]_ [(] _[s, a]_ [)][2] _[\u2225\u2207]_ [log] _[ \u03c0][t]_ [(] _[a][|][s]_ [)] _[\u2225]_ [2]\n\n1\n_\u2264_ (1 _\u2212_ _\u03b3_ ) [4] _[\u2225\u2207]_ [log] _[ \u03c0][t]_ [(] _[a][|][s]_ [)] _[\u2225]_ [2] _[.]_ (8)\n\nNow taking expectation w.r.t. ( _s, a_ ) implies that\n\n1\nE[ _\u2225Gt\u2225_ [2] _|\u03b8t_ ] = (1 _\u2212_ _\u03b3_ ) [4] [E] _[d]_ _t_ _[\u03c0]_ [(] _[S]_ [)] _[,\u03c0][t]_ [(] _[A][|][S]_ [)] \ufffd _\u2225\u2207_ log _\u03c0t_ ( _A|S_ ) _\u2225_ [2][\ufffd]\n\n_\u03c3_\n_\u2264_ (1 _\u2212_ _\u03b3_ ) [4] _[,]_ (9)\n\nwhere the last inequality is from 1.\n**Theorem 3.** _Assume \u03f5 \u2264_ _\u03b7t_ [2] _[for all][ k][, then]_\n\n1\nmin 2 _[} \u2264]_ _[O]_\n_t\u2264T_ [min] _[{]_ [E] _[\u2225\u2207][V][t][\u2225]_ [2] _[,]_ [ E] _[\u2225\u2207][V][t][\u2225]_ [2] \ufffd ~~_\u221a_~~ _T_\n\nFrom Lemma 9 and our assumption on _\u03f5_, we have\n\n_._\n\ufffd\n\n_\u03b7t_ (1 _\u2212_ _\u03f5_ ) min _{_ E _\u2225\u2207Vt\u2225_ 2 _,_ E _\u2225\u2207Vt\u2225_ 2 [2] _[} \u2264]_ [E][ [] _[V][t]_ [+1][]] _[ \u2212]_ [E][ [] _[V][t]_ [] +] _[ \u03b7]_ _t_ [2] _[C,]_\n\nwhere _C >_ 0 is a constant.\nFollowing a similar vanilla SGD analysis (Dutta et al. 2020, 2023), we obtain the results.\n\n**B** **Experimental Settings & Additional Results**\nThis section complements our empirical results in \u00a76. We start with highlighting the implementation details.\n\n**B.1 Hardware and Runtime Details**\n\nAll profiling experiments were executed on a server equipped with NVIDIA Tesla V100 GPUs. Wall-clock times per\n100K timesteps varied between 10\u201330 minutes, depending on the environment and base algorithm. On average, each\nlookback/mixup/three-points variant incurred an overhead of _\u223c_ 20% compared to vanilla training, given that we consider\na minimum of five episodes for the evaluations for the results, resulting in superior training performance in most cases. As we\nnote, increasing _E_ inflates the compute cost without proportional gains in stability or final performance. This sheds light on the\npractical trade-off that a modest number of rollouts suffices to stabilize learning while preserving wall-clock efficiency.\n\n**B.2 Profiling Pseudocode**\nAlgorithm 2 presents the reward-profiling procedure used in all experiments. The framework wraps around any base policygradient update _U_ and augments it with one of three selection strategies: lookback (LB), mixup (MU), or three-points (TP). Each\nvariant compares candidate policies using the empirical return _J_ [\u02c6] _E_ computed from _E_ i.i.d. evaluation rollouts, and retains the\nhighest-performing candidate according to its selection rule.\n\n**Algorithm 2:** Reward Profiling Framework used in implementation\n\n**Input** **:** initial _\u03b8_ 0; iterations _T_ ; rollouts _E_ ; mix weight _\u03bb_ (or _\u03bb_ _\u223c_ Beta( _\u03b1, \u03b2_ )); base update _U_ ; variant _\u2208{_ LB _,_ MU _,_ TP _}_\n**Output :** _\u03b8T_\nLet _J_ [\u02c6] _E_ ( _\u03d5_ ) = _E_ 1 \ufffd _Ei_ =1 _[G]_ [(] _[\u03c4][i]_ [)] _[,]_ _\u03c4i \u223c_ _\u03c0\u03d5_\n**for** _t_ = 0 **to** _T \u2212_ 1 **do**\n\n_\u03b8_ _[\u2032]_ _\u2190U_ ( _\u03b8t_ );\n**if** _variant \u0338_ = _LB_ **then**\n\n_\u03b8_ [mix] _\u2190_ _\u03bb \u03b8_ _[\u2032]_ + (1 _\u2212_ _\u03bb_ ) _\u03b8t_\n\n**if** _variant = LB_ **then**\n\n_C \u2190{\u03b8t, \u03b8_ _[\u2032]_ _}_\n**else if** _variant = MU_ **then**\n\n_C \u2190{\u03b8t, \u03b8_ [mix] _}_\n**else**\n\n_C \u2190{\u03b8t, \u03b8_ _[\u2032]_ _, \u03b8_ [mix] _}_\n\n_\u03b8t_ +1 _\u2190_ arg max _\u03d5\u2208C_ _J_ [\u02c6] _E_ ( _\u03d5_ ) with tie-break to _\u03b8t_ ;\n**return** _\u03b8T_\n\n**B.3 Environments**\n\n**Gymnasium and Bullet** We evaluate our methods on a suite of standard continuous control tasks with PyBullet environments,\nincluding Ant, Humanoid, Hopper, HalfCheetah, and Walker2D. These feature high-dimensional state and action spaces, complex\nmulti-body dynamics, and challenging reward structures, while the Box2D suite provides 2D physics tasks with moderate state\nand action dimensionality.\nAll experiments in these environments use default hyperparameters from Stable Baselines3 unless mentioned otherwise,\nsummarized in Table 2 to ensure fair comparison and reproducibility across all algorithms and tasks.\n\n**Unity ML-Agents Reacher** Here, _20_ independent robotic arms operate in parallel, each receiving a 33-dimensional observation\nvector (joint angles, joint velocities, target position) and producing 4-dimensional continuous torques. At each timestep, an\nagent earns a dense reward of +0.1 for keeping its fingertip within the moving target zone, encouraging precise coordination of\nexploration and control.\nWe wrap our Three-Points (TP) profiling layer around a decentralized DDPG backbone. Every _50_ episodes, we evaluate each\nagent\u2019s policy on _E_ = 5 rollouts and perform consensus voting: the new, old, and mixed candidates are compared across the 5\nagents, and the majority vote selects the next shared policy parameters to strike balances in timely policy correction with scalable\nmulti-agent evaluation. The environment\u2019s deterministic physics and reward structure allow DDPG to achieve target performance\nin fewer than 110 episodes, significantly faster than in MuJoCo or Bullet tasks.\n\nTable 2: Default Hyperparameters for MuJoCo/Bullet Experiments\n\n**Parameter** **PPO** **DDPG** **TRPO**\n\nLearning Rate 3 _\u00d7_ 10 _[\u2212]_ [4] 1 _\u00d7_ 10 _[\u2212]_ [3] 1 _\u00d7_ 10 _[\u2212]_ [3]\nNetwork Architecture [64,64] MLP [400,300] MLP [64,64] MLP\nBatch Size 64 100 128\nDiscount ( _\u03b3_ ) 0.99 0.99 0.99\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-0.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-1.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-2.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-3.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-4.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-5.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-6.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-7.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-8.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-9.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-10.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-11.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-12.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-13.png)\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-13-14.png)\n\nFigure 6: Average return vs. profiling iteration for PPO (top), TRPO (middle), DDPG (3rd row), across CarRacing, BipedalWalker,\nHalfCheetah, and Humanoid. The bottom row shows TD3 performance on three Bullet-locomotion tasks. variants: Vanilla,\nLookback, Mixup, Three-Points\n\nTable 3: DDPG Hyperparameters for Unity Reacher\n\n**Parameter** **Value**\n\nLearning Rate 1 _\u00d7_ 10 _[\u2212]_ [3]\nBatch Size 128\nReplay Buffer Size 1 _\u00d7_ 10 [6]\nTau ( _\u03c4_ ) 0.005\nGamma ( _\u03b3_ ) 0.99\nActor Network [400, 300] MLP\nCritic Network [400, 300] MLP\nOU Noise ( _\u03c3_ ) 0.2\n\n**B.4 Additional Experiments**\nIn the main paper (Figure 2), we showed four continuous-control suites for PPO, TRPO, and DDPG. Here, we complete the\npicture by adding results on two Box2D tasks (CarRacing, BipedalWalker) and two high-DOF Bullet tasks (HalfCheetah,\nHumanoid). We also evaluated our profiling wrapper on the state-of-the-art off-policy actor-critic, TD3 (Fujimoto, van Hoof, and\nMeger 2018), that extends DDPG with clipped-double Q-learning, delayed policy updates, and target-policy smoothing. All of\nTD3\u2019s core improvements\u2014reduced overestimation bias from twin critics, more accurate actor gradients via delayed updates,\nand smoother targets via policy noise\u2014are preserved inside our wrapper while reward profiling yields similar stability gains\nacross both on- and off-policy methods.\n\n**Extension to Off-Policy Actor\u2013Critics** While our main evaluations focused on PPO, TRPO, and DDPG across multiple\nbenchmarks, the reward-profiling wrapper is agnostic to the inner loop. To illustrate, we slot TD3 into our framework and\ntest it on **HumanoidBulletEnv-v0** . No changes to the outer logic are required: the TD3 \u201cStep\u201d call simply replaces DDPG\u2019s.\nFigure 7 repeats the sensitivity analysis for TD3+3P on HumanoidBulletEnv-v0. We observe the same \u201cU-shaped\u201d trade-off in\nevaluation budget _E_ . Comparatively smaller evaluation budgets ( _E_ = 10 _,_ 20) yield highly noisy reward estimates, leading to\nerratic policy corrections and sluggish long-term improvement. At the other extreme, very large budgets ( _E_ = 200) produce\noverly conservative updates: the low variance rarely permits the policy to depart from its initialization, resulting in nearly flat\nlearning curves. Intermediate budgets ( _E_ = 50\u2013100) achieve the best of both worlds, taming erratic decision-making while\nstill allowing sufficient exploration\u2014 _E_ = 50 reaches the highest peak returns, and _E_ = 100 delivers a steadier ascent at only\nmarginally lower peak performance. This empirical pattern echoes our high-probability monotonicity analysis (Appendix A):\nincreasing _E_ shrinks the confidence width on the estimated return at rate _O_ ( _e_ _[\u2212]_ [2] _[E\u03f5]_ [2] _[/B]_ [2] ), but beyond a critical threshold this\nconservatism prevents the sampler from accepting bold, potentially beneficial updates. In practice, we therefore recommend\nmoderate evaluation budgets to balance stability and learning speed.\n\nFigure 7: **TD3 + Three-Points on Humanoid.** Training performance for TD3 wrapped with our Three-Points variant, as the number of eval\nrolls _E_ varies. **E** = **10** _,_ **20** _,_ **50** _,_ **100** _,_ **200** are shown in distinct colors. Small _E_ (10,20) yields erratic updates; large _E_ (200) stabilizes but\ndelays progress; intermediate _E \u2248_ 50\u2013100 offers the best trade-off.\n\n![](papers/images/Stabilizing-Policy-Gradient-Methods-via-Reward-Profiling.pdf-14-0.png)"}, {"role": "assistant", "content": "**Mechanism:** Reward Profiling acts as a meta-controller or a 'unit test' wrapper around existing policy gradient updates. Instead of blindly accepting a policy update (\u03b8' from U(\u03b8t)), it evaluates a small set of candidate policies: the old policy (\u03b8t), the proposed new policy (\u03b8'), and potentially a blend (\u03b8_mix) of the two. This evaluation is done using a fixed number (E) of independent rollouts to get empirical reward estimates (J^E). The algorithm then performs an 'arg max' selection, picking the candidate policy that yielded the highest empirical return for the next iteration. This conditional acceptance/rejection/blending mechanism is designed to enforce high-probability monotonicity, as evidenced by Hoeffding's inequality (Lemma 1) ensuring J^E is close to true J(\u03c0), and Lemma 2 showing that accepted updates lead to a true J(\u03c0) increase (minus a small epsilon). This mechanism directly counters the variance and non-stationarity issues common in policy gradient methods that can lead to 'catastrophic collapses' by ensuring each committed step is empirically validated as an improvement.\n\n**Explanation:** Policy gradient methods try to find the best way for a robot to act by slightly changing its 'policy' (its rules for action) based on how much reward it gets. The problem is, sometimes a small change suggested by the math can make things much worse in the real world, causing the robot to 'collapse' and forget a lot. Reward Profiling adds a crucial check. After the main algorithm calculates a potential new set of rules (call it 'new policy'), this wrapper doesn't just use it. It actually runs a few quick simulations with the 'old policy' rules, a few with the 'new policy' rules, and even a few with a 'mixed policy' (a blend of old and new). It's like having three different versions of a program and running them all a few times to see which one works best. The one that gets the highest average score from these quick tests is the one the robot actually uses for its next steps. The theoretical proofs show that if you do enough of these quick tests (parameter E), you can be very confident that the policy you choose is truly better than before, or at least not significantly worse. This is because the average score from a few runs (J^E) is very likely to be close to the true average score (J(\u03c0)), thanks to probability math like Hoeffding's inequality. The critical trade-off is choosing 'E': too few tests, and the score might be noisy and unreliable; too many, and the checking takes too long, slowing down learning, even if the choices are more accurate. It's a balance between confidence in the 'unit test' and the computational cost of running it."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**13** _\ud835\udc64_ ( _\ud835\udf0f_ ) \u2190 _\ud835\udc64_ ( _\ud835\udf0f_ )/ _\ud835\udc64\ud835\udc60\ud835\udc62\ud835\udc5a_ ( _\ud835\udf0f\ud835\udc62\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc59\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc52\ud835\udc51_ ) \u00b7 (1 \u2212 _\ud835\udc45_ ( _\ud835\udc62, \ud835\udc63_ ));\n\n**14** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ [\u02dc][\u2032] + _\ud835\udc53_ ( _\ud835\udf0f_ ) \u00b7 _\ud835\udc64_ ( _\ud835\udf0f_ );\n\n**15 if** _Update is_ Del ( _\ud835\udc62, \ud835\udc63_ ) **then**\n\n**16** _\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc54_ \u2190 0 ;"}, {"role": "assistant", "content": "**Mechanism:** Dynamic contextual weighting, normalized aggregation, and state reset on deletion.\n\n**Explanation:** This segment outlines how an item's 'weight' (`w(\u03c4)`) is dynamically adjusted based on its context and relationships, and then used to contribute to an aggregate value (`\u03ba`). Line 13 updates `w(\u03c4)`. It first normalizes `w(\u03c4)` against the sum of weights of 'unselected' items, effectively re-distributing influence or ensuring a proportional contribution within a subset. The `(1 - R(u, v))` factor then modulates this weight: if `R(u,v)` (likely a relationship score, similarity, or rejection probability between `u` and `v`) is high, `w(\u03c4)` is dampened; if `R(u,v)` is low, `w(\u03c4)` remains largely intact. This mechanism allows `\u03c4`'s importance to be contextually sensitive to the interaction or state of `u` and `v`. Line 14 then performs a weighted sum: `\u03ba` (which can be thought of as an element in an array or map) accumulates `f(\u03c4)` (some feature of `\u03c4`) scaled by its newly adjusted `w(\u03c4)`. This is a common aggregation pattern where contributions are prioritized by their calculated importance. Finally, lines 15-16 specify a critical state management operation: if an `Update` is a `Delete` operation concerning `u` and `v`, a variable `worg` (presumably an 'original' or baseline weight) is set to zero. This ensures that any persistent state or initial contribution associated with the deleted relationship is explicitly purged, preventing stale data from affecting subsequent computations. This is akin to nullifying a pointer or resetting a counter when an associated resource is deallocated."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**17**\n4.1 The idea of the algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n\n4.3 The first step: No-dense case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.4 Correctness & Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.5 The second step: Avoiding dense case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.6 The Common & Simplify technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.7 Correctness & Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.8 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28"}, {"role": "assistant", "content": "**Mechanism:** The algorithm employs a conditional, two-phase problem-solving strategy, akin to an 'if-else' structure. It first addresses a 'no-dense' scenario, likely a simpler or default case where data distribution permits direct computation. For more challenging 'dense' scenarios, it switches to a specialized approach ('avoiding dense case') to prevent performance bottlenecks, perhaps by using different data structures or a more granular iterative process. The 'Common & Simplify' technique acts as a meta-optimization, identifying and abstracting repeated computational patterns or data transformations to reduce overall complexity and improve efficiency across both cases.\n\n**Explanation:** This algorithm's core mechanism is a refined divide-and-conquer approach, where the 'divide' step is implicit in classifying input conditions as 'no-dense' or 'dense'. Instead of a single, monolithic solution, it uses distinct sub-algorithms for each case. The 'no-dense' case might involve straightforward array traversals or basic graph algorithms. The 'dense' case, however, likely triggers a more sophisticated mechanism, such as specialized hash table lookups, tree-based filtering, or dynamic programming, to manage the increased data interactions without exponential blow-up. The 'Common & Simplify' technique is akin to refactoring code by creating common utility functions or modules that encapsulate frequently used operations or data transformations, thereby reducing redundant code and improving maintainability and performance. The 'Correctness & Analysis' sections confirm that these tailored mechanisms are mathematically sound and perform as expected under their respective conditions."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**51**\n11.1 Algorithm and constraint systems . . . . . . . . . . . . . . . . . . . . . . . . 51\n11.2 Feasibility and time complexity . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n11.3 SoS guarantees for robust optimal boosting . . . . . . . . . . . . . . . . . . . 53\n11.4 Algorithmic guarantees for robust optimal recovery . . . . . . . . . . . . . . 58\n\n**References**"}, {"role": "assistant", "content": "**Mechanism:** These sections outline a systematic approach to designing and validating algorithms. The 'algorithm and constraint systems' define the operational logic and the boundaries within which it must function, akin to a program with defined functions and input validation rules. 'Feasibility and time complexity' then analyze if a solution satisfying these constraints exists and how its computational resource demands scale with problem size, directly mapping to analyzing loop iterations and memory usage. The 'guarantees' sections ('SoS guarantees for robust optimal boosting' and 'Algorithmic guarantees for robust optimal recovery') are crucial. They describe rigorous mathematical proofs, likely using techniques like Sum-of-Squares (SoS) optimization, to demonstrate that the algorithm will consistently achieve the best possible outcome ('optimal') even when faced with noisy or incomplete data ('robust').\n\n**Explanation:** At its core, an algorithm is a procedural blueprint, much like a function in code. 'Constraint systems' are essentially the 'if' statements and data type validations that ensure the function operates within defined boundaries. 'Feasibility' checks if there's *any* valid output possible given the inputs and constraints, while 'time complexity' is like charting how many operations (CPU cycles) that function will perform as its input array grows, often revealing if it's O(N), O(N log N), or O(N^2). The 'guarantees' are where the real engineering happens: these are mathematical proofs that show *why* the algorithm behaves as expected under adverse conditions. For 'robust optimal boosting,' it means proving that even if some input data is slightly wrong, the combined predictive power (think of a stack of 'weak' classifiers acting like a complex decision tree) will still reliably give the best possible answer. For 'robust optimal recovery,' it's about proving that the system can reconstruct or correct data effectively despite corruption, analogous to an advanced error-correction code that reliably reverts to the original clean signal. SoS often provides these guarantees by framing the problem in a way that allows a sequence of convex optimization problems to certify the desired properties of a polynomial system."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**0**\n\nFigure 2: Distribution of cognitive element presence across\n1,598 arXiv LLM Reasoning papers. _Partially present_ indicates that there is evidence that the behavior was considered\nin the design (motivation, method, evaluation) of the paper but\nwas not the primary focus. _Present_ indicates that there is evidence that the behavior was a conscious and significant design\ndecision. Details provided in Section 5.\n\n3\n\nreasoning capabilities (Table 1). This taxonomy represents a theoretical contribution: we synthesize existing\ncognitive science literature into an analytical vocabulary for studying machine reasoning, providing a bridge\nbetween human cognitive research and LLM evaluation.\n\nWith this taxonomy, we conduct the **first large-scale empirical comparison of cognitive elements**\n**in human versus LLM reasoning** across diverse problem types (Jonassen, 2000). We analyze 170K\nreasoning traces from 17 models across text, vision, and audio modalities, complemented by 54 human thinkaloud reasoning traces (Table 2). Using fine-grained span-level annotation validated by human evaluation,\nwe identify which of the 28 cognitive elements appear in each trace, where they occur, and how they are\nsequenced in thought. Our analysis reveals fundamental differences in reasoning presence and structures. We\napply our analysis framework to distinguish between elements that are frequently exhibited by models and\nthose that are most strongly correlated with correct outcomes. Through our analysis, we reveal that _**models**_\n_**consistently employ behaviors which are not the most conducive to success**_ . We specifically observe\nthat as problems become more ill-defined and non-verifiable (e.g., open-ended dilemmas, diagnosing and\nsolving multifaceted problems), models narrow their selection of elements to rigid strategies despite _a broader,_\n_more diverse usage of cognitive elements being empirically shown as a more effective strategy_ . Furthermore,\nwe devise a novel structural representation to encode the structure of cognitive elements within reasoning\ntraces and find that models frequently choose reasoning structures which differ from successful structure.\nFinally, we apply this same analysis framework to comparing humans and LLMs. We observe that humans\nemploy more frequent abstract and conceptual-level processing, while LLMs rely more heavily on shallow\nsequential forward chaining with limited corrective structures based on problem type and structure.\n\nLeveraging these behavioral correlations, we introduce **test-time reasoning guidance** as a targeted intervention to improve model performance by explicitly scaffolding cognitive patterns predictive of reasoning\nsuccess. For instance, on dilemma problems where successful DeepSeek-R1 traces exhibit the behavioral\nsequence of self-awareness followed by hierarchical representation construction and then problem decomposition, we prompt the model to follow this structure. Evaluation demonstrates that test-time reasoning\nguidance improves performance by up to 66.7% on ill-structured problems while maintaining baseline performance on well-structured ones. This improvement confirms that models possess reasoning capabilities not\nspontaneously expressed, and that understanding cognitive behavioral patterns can inform more effective\nmodel interaction strategies.\n\nThis work establishes a taxonomy of cognitive foundations that bridges human reasoning research and LLM\nevaluation, providing a unified vocabulary for characterizing reasoning processes beyond performance metrics.\nBy synthesizing cognitive science theories through Marr\u2019s levels of analysis, we identify 28 reasoning behaviors\nspanning computational constraints, meta-cognitive controls, knowledge representations, and transformation\noperations. We conduct the first large-scale empirical analysis across 170K model and human reasoning\ntraces [1], revealing systematic structural differences: humans employ hierarchical nesting and meta-cognitive\nmonitoring while models rely on shallow sequential forward chaining, with divergence most pronounced on\nill-structured problems. Leveraging these patterns, we introduce cognitively-grounded reasoning guidance to\nthe model that automatically scaffolds successful reasoning structures, improving performance by up to 60%\non complex problems and confirming that models possess latent capabilities not spontaneously expressed.\nOur analysis of 1,598 LLM reasoning papers reveals critical between research emphasis and behavioral\nrequirements. This framework enables researchers to ask targeted questions about LLM reasoning: which\nbehaviors emerge from scale and which require architectural innovation, do different training paradigms\nproduce different cognitive profiles, and how do reasoning structures transfer across domains and modalities?\nThese questions become answerable when we have a shared vocabulary for characterizing reasoning processes.\nOur taxonomy and annotation methodology provide that vocabulary, grounded in decades of cognitive science\nresearch and validated through large-scale empirical analysis of both human and machine reasoning traces."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism relies on treating reasoning as a sequence of discrete operational steps, much like a program's execution flow. By observing vast numbers of successful human and model 'programs' (reasoning traces), we can identify which 'function calls' (cognitive elements) and their specific 'call sequences' (reasoning structures) are most effective for different problem types. The model isn't *learning* new functions; rather, it possesses a library of 'cognitive functions' already. The intervention is like providing a precise execution script or a flow-chart (the 'guidance prompt') that explicitly dictates the order and type of functions to call, thereby coercing the model to follow an empirically validated optimal path rather than its default, often suboptimal, exploratory sequence.\n\n**Explanation:** Imagine a computer program has many small helper functions in its library, like 'planAhead()', 'breakDownProblem()', and 'checkWork()'. When solving complex problems, the computer often just calls these functions in a simple, straightforward order, like a basic 'for' loop, even if that's not the best way to get to the correct answer. This paper created a comprehensive list, or a 'function signature dictionary,' of all these helper functions (the 28 cognitive elements). They then acted like debugging experts, logging millions of 'call stacks' (reasoning traces) from both humans and other computer programs to see *which* functions were called, and in *what specific order*, for successful problem-solving. They found that for tricky problems, successful solutions involved a much richer and often nested sequence of calls, like a complex object-oriented design with inheritance and polymorphic calls, rather than a simple sequential script. The 'test-time reasoning guidance' is effectively a 'macro' or a 'template function' in the prompt. Instead of letting the model generate its own, often inefficient, sequence of function calls, the prompt explicitly instructs it, 'First, call selfAwareness(), then hierarchicalRepresentationConstruction(), then problemDecomposition().' This doesn't change the underlying functions available to the model, but rather provides a verified 'main()' program or execution flow that ensures the latent (already existing) capabilities are invoked in an optimal order, leading to significantly better results."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) \u2208 _\ud835\udf0f_ 0 **then**\n\n**14** vol_sum. _\ud835\udc34\ud835\udc51\ud835\udc51_ (DFSin[ _\ud835\udc63_ ], DFSout[ _\ud835\udc63_ ], 2 _\ud835\udc5a_ \u2212vol[ _\ud835\udc63_ ]) ;"}, {"role": "assistant", "content": "**Mechanism:** This segment implements a conditional summation logic. It functions like a filter followed by an accumulator. The condition `(v, p(v)) \u2208 \u03c40` acts as a predicate that determines if the current element `v` (along with its associated property `p(v)`) is part of a specific subset of interest. If this condition evaluates to true, indicating the element is relevant, then three specific numerical attributes associated with `v` are retrieved and added to a running total. These attributes, `DFSin[v]`, `DFSout[v]`, and `2m - vol[v]`, are effectively features of the element `v`, likely pre-computed during a graph traversal or similar structural analysis.\n\n**Explanation:** Conceptually, `\u03c40` can be thought of as a `HashMap` or a `HashSet` containing specific `(key, value)` pairs, where the existence check is very quick (average O(1)). For each `v` being processed, the algorithm queries this `HashSet`. If the pair `(v, p(v))` is found, it proceeds to gather three values. `DFSin[v]` and `DFSout[v]` often represent discovery and finish times in a Depth-First Search traversal of a graph, effectively defining an interval for `v`'s subtree. `vol[v]` typically signifies the size or weight of the subtree rooted at `v`, and `2m - vol[v]` is a computed metric, perhaps related to the \"complementary volume\" or the total volume excluding `v`'s subtree in some scaled context, where `m` is a global constant. These three distinct numerical values are then passed to an `Add` method, which functions as a simple sum accumulator, akin to `total_sum += (value1 + value2 + value3)` in a standard loop. This process efficiently aggregates specific topological or structural properties for a selected subset of elements."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**9**\n\n2.1 Probability Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n\n2.2 Constructing a Cover with Low Probability Distance Diameter . . . . . . . . . . . . 11"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism revolves around defining a metric (probability distance) to quantify dissimilarity between probability distributions, and then applying an approximation or clustering strategy (constructing a cover) to efficiently represent a larger, potentially infinite, space of distributions.\n\n**Explanation:** At its heart, 'probability distance' is a way to put a number on 'how different' two probability distributions are. Think of it like comparing two histograms or data sets and asking how much 'work' it would take to morph one into the other. It's a generalization of distance for abstract concepts. 'Constructing a cover with low probability distance diameter' is a method to create a compact, representative set of distributions. Imagine you have a vast collection of possible data patterns (each a distribution). Instead of tracking every single one, you identify a small group of 'prototypes' or 'centroids' (your 'cover'). The 'low diameter' part means that every single possible data pattern in your original space is 'close enough' (in terms of probability distance) to at least one of your chosen prototypes. This is essentially a clever form of clustering or data compression for probabilistic information, allowing you to operate on a small, representative subset rather than the entire complex space. It's like building an index or a hash map for distributions, where similar distributions map to nearby 'cover' elements."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nFollowing Runeson _et al._ [30] and Maxwell [21], potential validity\nthreats and mitigation measures are outlined below.\n**Construct Validity.** To ensure participant relevance, experts\nwere purposefully selected from OEMs, Tier-1, Tier-2, and research\ninstitutes. The interview protocol underwent internal review and\ntwo pilot tests for clarity and completeness. Key terms ( _e.g.,_ data\nannotation, perception systems) were clearly defined and supported\nwith visuals to avoid misinterpretation. For expert validation, participants received structured briefings and could seek clarification\n\nbefore evaluation. Researcher bias was minimised through teambased reflexive discussions and peer debriefing.\n\n**Internal Validity.** To mitigate personal or organisational bias,\nparticipants were drawn from six automotive companies and four\nresearch institutes across multiple supply chain tiers. Interviews\nwere recorded, transcribed, and participant-verified for accuracy.\nDual independent coding yielded _\ud835\udf05_ = 0 _._ 8 (Cohen\u2019s Kappa), with\ndiscrepancies resolved during weekly meetings from May to September 2025. Three collaborative workshops with researchers and\nindustry partners refined the themes, while triangulation between\ninterview (RQ1) and validation (RQ2) results enhanced conceptual\nand practical credibility.\n\n**External Validity.** Although not statistically generalisable,\nthe study achieves analytical generalisation through diverse participants, 20 experts from 11 organisations across two European\ncountries and the UK. Coverage across OEMs, Tier-1/Tier-2 suppliers, and research institutions, combined with alignment to international standards (ISO/IEC 5259, IEEE _\ud835\udc43_ 2801, ISO 26262, SAE J3016),\nstrengthens transferability and ensures lifecycle representativeness\nwithin AIePS.\n\n**Reliability.** To ensure transparency and replicability, all instruments (interview guide, codebook, validation questionnaire) are\nopenly available. Interviews were conducted with informed consent, anonymised in accordance with GDPR, and securely stored.\nAll research steps, from data collection to coding logic, were systematically documented to support replication and independent\nverification."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism for building trust in these findings involves a multi-layered approach of data input validation, redundant processing with consistency checks, and comprehensive auditable documentation. This mirrors robust software development practices where data integrity and reproducibility are paramount.\n\n**Explanation:** For 'Construct Validity,' the process acts like an elaborate input validation and API contract definition system. Participants are pre-filtered (expert selection) like type-checking inputs. The interview protocol undergoes unit and integration testing (internal review, pilot tests) to ensure it elicits the intended data. Key terms are strongly typed and documented with visuals to prevent misinterpretation, akin to clear API documentation. Researcher bias is minimized through a continuous feedback loop (reflexive discussions, peer debriefing), similar to iterative code reviews to catch logical flaws. 'Internal Validity' employs cross-validation and redundancy for data processing. Diverse participant sources are like ensuring a distributed dataset isn't skewed by a single node. Recording, transcribing, and participant verification create a robust data integrity pipeline with checksums at each stage. Dual independent coding with Cohen's Kappa (\u03ba=0.8) is a quantitative measure of inter-rater reliability, similar to comparing two independent computations of the same hash for data consistency. Discrepancy resolution is a conflict resolution algorithm. Triangulation between interview and validation results is like comparing outputs from different system modules to ensure they converge on the same truth, enhancing system robustness. For 'External Validity,' it's not statistical generalization (like random sampling for a broad population) but 'analytical generalization.' This is like designing a comprehensive suite of test cases that cover all critical paths and representative archetypes (OEMs, Tier-1/2, research, multiple countries) within the problem domain. Adherence to international standards (ISO, IEEE) is like ensuring the system's design adheres to well-established, industry-accepted interfaces and protocols, making it compatible and transferable to other compliant systems. 'Reliability' is achieved by creating a full audit trail and open-sourcing the methodology. Making instruments openly available is like providing public API documentation and algorithm specifications. Documenting all research steps, data collection, and coding logic is akin to maintaining version control and detailed system logs, allowing independent verification and replication of the 'computation' of the study's results."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_each new unit of product i added from exogenous shock_ **do**\n\n**8** assign this new unit into batch _Bi,hi_ +1"}, {"role": "assistant", "content": "**Mechanism:** This describes a batching mechanism using a type-specific incrementing counter. For each distinct product type 'i', there's an associated counter, 'hi'. When a new unit of 'product i' arrives, the system increments 'hi' by one and then assigns this new unit to the batch identified by the newly incremented 'hi'. This ensures sequential, non-overlapping batch assignment per product type.\n\n**Explanation:** Think of this like having a set of independent counters, one for each 'product type'. If you have 'apples' and 'oranges' (product types), you'd have an 'apple_batch_number' counter and an 'orange_batch_number' counter. When a new apple arrives, you increment 'apple_batch_number' and put that apple into the batch corresponding to the new number. You do the same, independently, for oranges. This is conceptually similar to a hash map (or dictionary) where the keys are product types ('i') and the values are objects that hold both a list of assigned units (the batches) and the current batch counter ('hi') for that specific product type. When an 'exogenous shock' introduces a new unit for 'product i', the system performs a lookup for 'i', retrieves its current 'hi', increments it, and then places the new unit into the 'hi+1' position or group associated with 'i'."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_Dataset Distillation_ aims to synthesize a tiny synthetic dataset of (typically) images that are optimal\nfor training. Unlike previous works designed to produce synthetic samples for training new models\n_from scratch_, our new method, _Linear Gradient Matching_, aims to distill datasets for the purpose of\ntraining **linear classifiers** in the embedding space of **pre-trained feature extractors** .\n\n**3.1** **Linear Gradient Matching**\n\nFormally, given a pre-trained self-supervised feature extractor, _\u03d5_, along with a real dataset _D_ real of\nimages _X_ real and labels _Y_ real, we wish to distill a small synthetic set _D_ syn = _{X_ syn _, Y_ syn _}_ such that\n_D_ syn can be used to train a linear classifier in feature extractor _\u03d5_ \u2019s embedding space that will have\nsimilar test-time performance to one trained on _D_ real.\n\n3\n\nInspired by previous works that aimed to match single-step gradients [55] or multi-step trajectories [6],\nour solution is designed to ensure that training on our synthetic dataset results in similar updates as\ntraining on real data. In other words, the gradients of the classification loss using synthetic images\n(with respect to the linear classifier) should match those using real images.\n\nTo achieve this, we sample a random linear classifier matrix _W \u223cN_ (0 _,_ 1) _[c][\u00d7][f]_ at each distillation step\nwhere _c_ is the number of classes and _f_ is the feature extractor _\u03d5_ \u2019s output dimension. After passing\nthe real and synthetic images through the feature extractor _\u03d5_ and linear classifier _W_, we find the real\nand synthetic classification losses where CE is the multiclass cross-entropy loss:\n\n_\u2113_ real = CE( _W\u03d5_ ( _X_ real); _Y_ real)\n(1)\n_\u2113_ syn = CE( _W\u03d5_ ( _X_ syn); _Y_ syn)\n\nWe then take the gradients of these classification losses with respect to the linear classifier _W_, and\nour _meta loss_ is then the cosine distance between them:\n\n_\u2202\u2113_ real\n_L_ meta = 1 _\u2212_ cos \ufffdvec \ufffd _\u2202W_\n\n_\u2202\u2113_ syn\n\ufffd _,_ vec \ufffd _\u2202W_\n\n(2)\n\ufffd\ufffd\n\nThis meta loss is then back-propagated through the inner gradient computation, linear classifier, and\nfeature extractor to find _\u2202L_ meta _/\u2202X_ syn and update our synthetic images. This process is repeated until\ndistillation is complete. An outline of this _Linear Gradient Matching_ method can be found in Figure 2.\n\n**3.2** **Implicit Regularization**\n\nAs noted in prior works [6, 7, 55], _Dataset Distillation_ tends to yield synthetic images that are _overfit_\nto the model used to perform the distillation. This issue manifests in what appear like adversarial\npatterns and inhibit the images\u2019 usefulness when used to train other models.\n\nOne recent work [15] proposed using a pyramid representation rather than na\u00efve pixels for image optimization problems. While the authors used this technique for CLIP inversion, we find it works remarkably well for our Dataset Distillation task. Rather than simply optimizing pixels, each synthetic sample\nis instead stored as a set of images of different resolutions _\u03c1_ = _{_ 1 _\u00d7_ 1 _,_ 2 _\u00d7_ 2 _,_ 4 _\u00d7_ 4 _, . . .,_ 256 _\u00d7_ 256 _}_ .\n\nBefore each optimization step, the composite images _X_ are \u201crendered\u201d by bilinearly upsampling\neach level of the pyramids _P_ = _{Pr|r \u2208_ _\u03c1}_ to the max resolution (256) and adding them together\nbefore smoothly clamping the pixel values with a sigmoid function:\n\n\ufffd\n\n_X_ = sigmoid\n\n\ufffd\ufffd _r\u2208\u03c1_\n\nresize256( _Pr_ )\n\n_r\u2208\u03c1_\n\n(3)\n\nFurthermore, we progressively optimize our pyramid, starting with just the lowest-resolution component and periodically adding more tiers during distillation. The effects of using the pyramid\nrepresentation are quite dramatic, as seen in Figure 5.\n\nAs an additional step to combat overfitting, we also learn our distilled images in a _decorrelated_ color\nspace, as described in prior feature visualization work [30]. In short, we apply a fixed linear transform\nto the channels of our images after the pyramid reconstruction that brings them back into the standard\ncorrelated color space. This helps ward off any potential color-based biases induced by the model\nused during distillation.\n\n**3.3** **Differentiable Augmentations**\n\nAs first noted in the work on _Differentiable Siamese Augmentation_ [53], applying differentiable\naugmentations to the synthetic images during the distillation process greatly improves the quality of\nthe distilled data. As such, we apply **horizontal flipping**, **random resized cropping**, and **Gaussian**\n**noising** to our distilled images at each step. In practice, we actually apply multiple rounds of this\naugmentation to different copies of the synthetic data at each iteration and concatenate the results.\nWe find this improves distillation since the optimization now encourages all these augmented copies\n_together_ to be the ideal training set rather than attempting to fit all pertinent information into a single\naugmented version of the images.\n\n4\n\nTrain Set ImageNet-100 ImageNet-1k\n(1 Img/Cls)\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nDistilled (Ours) **84.9** _\u00b1_ **0.1 91.5** _\u00b1_ **0.1 89.0** _\u00b1_ **0.0 83.4** _\u00b1_ **0.1 87.2** _\u00b1_ **0.1 63.0** _\u00b1_ **0.0 75.0** _\u00b1_ **0.1 70.3** _\u00b1_ **0.1 63.2** _\u00b1_ **0.0 67.9** _\u00b1_ **0.0**\nNeighbors 67.8 _\u00b1_ 0.3 86.0 _\u00b1_ 0.2 78.8 _\u00b1_ 0.2 77.1 _\u00b1_ 0.1 77.4 _\u00b1_ 0.2 38.8 _\u00b1_ 0.1 67.7 _\u00b1_ 0.1 49.9 _\u00b1_ 0.1 56.4 _\u00b1_ 0.0 53.2 _\u00b1_ 0.1\nCentroids 77.1 _\u00b1_ 0.1 86.9 _\u00b1_ 0.3 80.9 _\u00b1_ 0.2 77.7 _\u00b1_ 0.1 80.6 _\u00b1_ 0.2 53.9 _\u00b1_ 0.0 69.5 _\u00b1_ 0.1 58.1 _\u00b1_ 0.1 57.4 _\u00b1_ 0.0 59.7 _\u00b1_ 0.1\n\nRandom 56.6 _\u00b1_ 1.6 74.8 _\u00b1_ 2.8 64.5 _\u00b1_ 2.7 61.4 _\u00b1_ 2.6 64.3 _\u00b1_ 2.4 31.7 _\u00b1_ 0.5 50.3 _\u00b1_ 0.5 37.7 _\u00b1_ 0.4 38.8 _\u00b1_ 0.6 39.6 _\u00b1_ 0.5\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1 78.7 _\u00b1_ 0.0 83.0 _\u00b1_ 0.0 81.7 _\u00b1_ 0.1 76.5 _\u00b1_ 0.0 80.0 _\u00b1_ 0.0\n\nTable 1: **Linear Probes with One Image-per-Class:** We compare our method (Distilled) to several real-image\nbaselines on ImageNet-100 ( **left** ) and ImageNet-1k ( **right** ). Images are distilled (or selected) using the given\nmodel in each column. \u201cNeighbors\u201d are the real images with embeddings closest to those of our distilled images.\n\u201cCentroids\u201d are the real images with embedding closest to the mean of each class. \u201cRandom\u201d is a random\nselection of real images. Our method outperforms each baseline across all models and both datasets.\n\nDistill ImageNet-100 ImageNet-1k\nModel\n\nCLIP DINO-v2 EVA-02 MoCo-v3 Average CLIP DINO-v2 EVA-02 MoCo-v3 Average\n\nFull Dataset 92.5 _\u00b1_ 0.0 95.2 _\u00b1_ 0.1 94.1 _\u00b1_ 0.1 89.4 _\u00b1_ 0.3 92.8 _\u00b1_ 0.1 78.7 _\u00b1_ 0.0 83.0 _\u00b1_ 0.0 81.7 _\u00b1_ 0.1 76.5 _\u00b1_ 0.0 80.0 _\u00b1_ 0.0\n\nTable 2: **Cross-Model Performance of Distilled Datasets** : Here, we see ImageNet-100 ( **left** ) and ImageNet-1k\n( **right** ) distilled using a given model and then evaluated across all models. We see that images distilled from DINO\nhave the best average cross-model performance for both datasets. The distilled datasets generalize well, aside from\nan outlier pair of CLIP and MoCo. Columns are colored based on percentage of the \u201cFull Dataset\u201d benchmark."}, {"role": "assistant", "content": "**Mechanism:** The core trick, Linear Gradient Matching, works by making sure the \"learning instructions\" for a simple computer teacher (linear classifier) are the same whether it looks at the giant collection of real pictures or our tiny, hand-picked synthetic ones. Imagine the teacher wants to adjust its knowledge (its \"weights,\" like dials on a radio) to better understand pictures. The \"gradient\" is like a precise instruction: \"turn the 'roundness' dial a bit this way.\" We create our fake pictures so that when the teacher looks at them, it gets almost the exact same instructions as if it looked at real pictures. We achieve this by repeatedly generating random teacher configurations and then tweaking our synthetic images until the learning instructions they generate match those from real images. To make sure our fake pictures are good for any teacher, we try this matching with many different random teachers.\n\n**Explanation:** When we create pictures pixel by pixel, they can get \"stuck\" on tiny details that don't help general learning, like drawing a specific scratch on one car that doesn't exist on others. To fix this, we build our synthetic pictures like a layered cake or a series of blueprints. We start with a blurry, low-resolution drawing (the \"bottom layer\") and then add progressively finer details on top. This forces the picture to have a good general shape first before adding specific textures, making it less likely to accidentally encode meaningless patterns. We also process colors in a special \"decorrelated\" way, like adjusting red, green, and blue independently, to prevent odd color combinations that are only useful to our specific picture-making process. Finally, we don't just make one perfect synthetic picture. Instead, we make a picture that, when slightly changed in common ways (like flipping it, zooming in, or adding a little fuzz), still produces the correct learning instructions. This is like making a mold that can produce many slightly varied, yet equally useful, training examples, making the final synthetic data much more robust and versatile."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nIn this work, we introduced asymmetric tile buffering (ATB), a\ngeneral tiling strategy that reduces buffer pressure and improves\narithmetic intensity beyond conventional symmetric buffering on\nNPUs. On AMD XDNA2\u2122AIE, ATB improves GEMM throughput\nby up to 40% even over highly optimized symmetric kernels. We also\npresent kernel design strategies that deliver a 4.54\u00d7 speedup over\nthe state-of-the-art GEMM implementation. In the future, we plan\nto explore automated search and scheduling to make ATB-based\nkernel generation fully automatic.\n\n**References**\n\n[1] AMD. 2023. Adaptive Computing Technology Overview. [https:](https://www.amd.com/content/dam/amd/en/documents/solutions/adaptive-computing-technology-overview.pdf)\n[//www.amd.com/content/dam/amd/en/documents/solutions/adaptive-](https://www.amd.com/content/dam/amd/en/documents/solutions/adaptive-computing-technology-overview.pdf)\n[computing-technology-overview.pdf. Accessed: 2025-11-19.](https://www.amd.com/content/dam/amd/en/documents/solutions/adaptive-computing-technology-overview.pdf)\n\n[[2] AMD. 2024. AMD Ryzen AI 5 340 Processor. https://www.amd.com/en/products/](https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-5-340.html)\n[processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-5-340.html Accessed: 2025-](https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-5-340.html)\n11-18.\n\n[3] AMD. 2024. AMD Ryzen AI 9 HX 370 Processor. [https://www.amd.com/en/](https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-9-hx-370.html)\n[products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-9-hx-370.html](https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-9-hx-370.html)\nAccessed: 2025-11-18.\n\n[4] AMD. 2025. AI Engine API \u2013 Matrix Multiplication (MMUL) Refer[ence. https://download.amd.com/docnav/aiengine/xilinx2025_1/aiengine_api/](https://download.amd.com/docnav/aiengine/xilinx2025_1/aiengine_api/aie_api/doc/group__group__mmul.html)\n[aie_api/doc/group__group__mmul.html. Accessed: 2025-10-01.](https://download.amd.com/docnav/aiengine/xilinx2025_1/aiengine_api/aie_api/doc/group__group__mmul.html)\n\n[[5] AMD. 2025. AMD XDNA Driver for Linux. https://github.com/amd/xdna-driver.](https://github.com/amd/xdna-driver)\nAccessed: 2025-11-16.\n\n[[6] AMD. 2025. BFP16 (Block Floating Point) Quantization Tutorial. https://quark.](https://quark.docs.amd.com/latest/pytorch/tutorial_bfp16.html)\n[docs.amd.com/latest/pytorch/tutorial_bfp16.html. Accessed: 2025-10-01.](https://quark.docs.amd.com/latest/pytorch/tutorial_bfp16.html)\n\n[[7] AMD. 2025. DynamicDispatch. https://github.com/amd/DynamicDispatch. Ac-](https://github.com/amd/DynamicDispatch)\ncessed: 2025-10-01.\n\n[[8] AMD. 2025. Ryzen AI Software. https://github.com/amd/RyzenAI-SW?tab=](https://github.com/amd/RyzenAI-SW?tab=readme-ov-file)\n[readme-ov-file. Accessed: 2025-10-01.](https://github.com/amd/RyzenAI-SW?tab=readme-ov-file)\n\n[9] AMD. 2025. Xilinx MLIR-AIE BFP16 matrix multiplication implementa[tion. https://github.com/Xilinx/mlir-aie/tree/main/programming_examples/ml/](https://github.com/Xilinx/mlir-aie/tree/main/programming_examples/ml/block_datatypes/matrix_multiplication)\n[block_datatypes/matrix_multiplication. Accessed: 2025-10-01.](https://github.com/Xilinx/mlir-aie/tree/main/programming_examples/ml/block_datatypes/matrix_multiplication)\n\n[10] Xiaodong Deng, Shijie Wang, Tianyi Gao, Jing Liu, Longjun Liu, and Nanning\nZheng. 2024. AMA: An Analytical Approach to Maximizing the Efficiency of\nDeep Learning on Versal AI Engine. In _2024 34th International Conference on_\n_Field-Programmable Logic and Applications (FPL)_ [. 227\u2013235. doi:10.1109/FPL64840.](https://doi.org/10.1109/FPL64840.2024.00039)\n[2024.00039](https://doi.org/10.1109/FPL64840.2024.00039)\n\n[11] Michael Gilbert, Yannan Wu, Joel Emer, and Vivienne Sze. 2024. LoopTree:\nExploring the Fused-Layer Dataflow Accelerator Design Space. _IEEE Transactions_\n_on Circuits and Systems for Artificial Intelligence_ [PP (09 2024), 1\u201315. doi:10.1109/](https://doi.org/10.1109/TCASAI.2024.3461716)\n[TCASAI.2024.3461716](https://doi.org/10.1109/TCASAI.2024.3461716)\n\n[12] D. W. Gillies and J. W.-S. Liu. 1990. Scheduling Tasks with AND/OR Precedence Constraints. In _Proceedings of the Second IEEE Symposium on Parallel and_\n_Distributed Processing_ [. 394\u2013401. doi:10.1109/SPDP.1990.143572](https://doi.org/10.1109/SPDP.1990.143572)\n\n[13] Qijing Huang, Po-An Tsai, Joel S. Emer, and Angshuman Parashar. 2024. Mind\nthe Gap: Attainable Data Movement and Operational Intensity Bounds for Tensor\nAlgorithms. In _2024 ACM/IEEE 51st Annual International Symposium on Computer_\n_Architecture (ISCA)_ [. 150\u2013166. doi:10.1109/ISCA59077.2024.00021](https://doi.org/10.1109/ISCA59077.2024.00021)\n\n[14] Erika Hunhoff, Joseph Melber, Kristof Denolf, Andra Bisca, Samuel Bayliss,\nStephen Neuendorffer, Jeff Fifield, Jack Lo, Pranathi Vasireddy, Phil James-Roxby,\nand Eric Keller. 2025. Efficiency, Expressivity, and Extensibility in a Closeto-Metal NPU Programming Interface. In _2025 IEEE 33rd Annual International_\n_Symposium on Field-Programmable Custom Computing Machines (FCCM)_ . 85\u201394.\n[doi:10.1109/FCCM62733.2025.00043](https://doi.org/10.1109/FCCM62733.2025.00043)\n\n[15] Linyan Mei, Pouya Houshmand, Vikram Jain, Sebastian Giraldo, and Marian\nVerhelst. 2020. ZigZag: A Memory-Centric Rapid DNN Accelerator Design Space\n[Exploration Framework. arXiv:2007.11360 [cs.DC] https://arxiv.org/abs/2007.](https://arxiv.org/abs/2007.11360)\n[11360](https://arxiv.org/abs/2007.11360)\n\n[16] Kaustubh Mhatre, Endri Taka, and Aman Arora. 2025. GAMA: HighPerformance GEMM Acceleration on AMD Versal ML-Optimized AI Engines.\n[arXiv:2504.09688 [cs.AR] https://arxiv.org/abs/2504.09688](https://arxiv.org/abs/2504.09688)\n\n[17] Endri Taka, Aman Arora, Kai-Chiang Wu, and Diana Marculescu. 2023. MaxEVA: Maximizing the Efficiency of Matrix Multiplication on Versal AI Engine.\n[arXiv:2311.04980 [cs.AR] https://arxiv.org/abs/2311.04980](https://arxiv.org/abs/2311.04980)\n\n[18] Endri Taka, Dimitrios Gourounas, Andreas Gerstlauer, Diana Marculescu, and\nAman Arora. 2024. Efficient Approaches for GEMM Acceleration on Leading\n\nAI-Optimized FPGAs. In _2024 IEEE 32nd Annual International Symposium on_\n_Field-Programmable Custom Computing Machines (FCCM)_ [. 54\u201365. doi:10.1109/](https://doi.org/10.1109/FCCM60383.2024.00015)\n[FCCM60383.2024.00015](https://doi.org/10.1109/FCCM60383.2024.00015)\n\n[19] Vijay Thakkar, Pradeep Ramani, Cris Cecka, Aniket Shivam, Honghao Lu, Ethan\nYan, Jack Kosaian, Mark Hoemmen, Haicheng Wu, Andrew Kerr, Matt Nicely,\nDuane Merrill, Dustyn Blasig, Fengqi Qiao, Piotr Majcher, Paul Springer, Markus\nHohnerbach, Jin Wang, and Manish Gupta. 2023. _CUTLASS_ [. https://github.com/](https://github.com/NVIDIA/cutlass)\n[NVIDIA/cutlass](https://github.com/NVIDIA/cutlass)\n\n[20] Field G. Van Zee and Robert A. van de Geijn. 2015. BLIS: A Framework for\nRapidly Instantiating BLAS Functionality. _ACM Trans. Math. Software_ 41, 3 (June\n[2015), 14:1\u201314:33. https://doi.acm.org/10.1145/2764454](https://doi.acm.org/10.1145/2764454)\n\n[21] Chengyue Wang, Xiaofan Zhang, Jason Cong, and James C. Hoe. 2025. Reconfigurable Stream Network Architecture. In _Proceedings of the 52nd Annual Interna-_\n_tional Symposium on Computer Architecture (ISCA \u201925)_ . Association for Computing\n[Machinery, New York, NY, USA, 1848\u20131866. doi:10.1145/3695053.3731088](https://doi.org/10.1145/3695053.3731088)\n\n[22] Samuel Williams, Andrew Waterman, and David Patterson. 2009. Roofline: an\ninsightful visual performance model for multicore architectures. _Commun. ACM_\n[52, 4 (April 2009), 65\u201376. doi:10.1145/1498765.1498785](https://doi.org/10.1145/1498765.1498785)\n\n[23] Jinming Zhuang, Jason Lau, Hanchen Ye, Zhuoping Yang, Yubo Du, Jack Lo,\nKristof Denolf, Stephen Neuendorffer, Alex Jones, Jingtong Hu, Deming Chen,\nJason Cong, and Peipei Zhou. 2023. CHARM: Composing Heterogeneous Acceler[ators for Matrix Multiply on Versal ACAP Architecture. arXiv:2301.02359 [cs.AR]](https://arxiv.org/abs/2301.02359)\n[https://arxiv.org/abs/2301.02359](https://arxiv.org/abs/2301.02359)\n\n[24] Jinming Zhuang, Zhuoping Yang, and Peipei Zhou. 2023. AutoMM: EnergyEfficient Multi-Data-Type Matrix Multiply Design on Heterogeneous Pro[grammable System-on-Chip. arXiv:2305.18698 [cs.AR] https://arxiv.org/abs/](https://arxiv.org/abs/2305.18698)\n[2305.18698](https://arxiv.org/abs/2305.18698)"}, {"role": "assistant", "content": "**Mechanism:** Asymmetric Tile Buffering (ATB) reduces buffer pressure and improves arithmetic intensity by dynamically or statically allocating and partitioning on-chip memory (buffers) in a non-uniform way, tailored to the specific data flow and computational requirements of matrix multiplication (GEMM) across different dimensions or stages. Instead of 'symmetrically' allocating equal or predetermined buffer sizes for input/output matrices (e.g., A, B, and C in C=A*B), ATB recognizes that the access patterns, data reuse, and compute-to-memory ratios can vary significantly between these data streams.\n\n**Explanation:** In essence, conventional 'tiling' breaks large computations into smaller, cache-friendly blocks, similar to iterating over nested loops on smaller data chunks that fit into fast local memory. 'Symmetric' buffering might assign, for instance, equal-sized temporary storage for the rows of matrix A and columns of matrix B. However, ATB allows for 'asymmetric' buffer sizing and tiling strategies. This is like a smart compiler recognizing that one input matrix (say, A) might have higher data reuse or different access patterns than another (say, B), and thus allocates a larger or differently shaped buffer to A's tiles, or fetches them in an uneven manner. By doing so, it minimizes stalls due to memory access (reducing 'buffer pressure' \u2013 akin to fewer cache misses or memory bus contention) and ensures the arithmetic logic units ('arithmetic intensity' \u2013 more operations per byte fetched) remain busy doing useful computation, rather than waiting for data. This fine-grained, non-uniform optimization of data movement and storage is key to the performance gains, especially on architectures like NPUs where memory hierarchies and specialized units are critical."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ == _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc35\ud835\udc4a_ **then**\n\n**175** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc52\ud835\udc61_ _ _\ud835\udc43\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc45\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc4a\ud835\udc56\ud835\udc61\u210e_ _ _\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b_ (1) ;\n\n**Save and Restore cwnd function definitions:**\n\n**176** BBR_Save_Cwnd():"}, {"role": "assistant", "content": "**Mechanism:** This section describes a state-conditional action combined with state preservation. When the BBR state machine transitions to or is in the 'ProbeBW' state, it triggers a control mechanism to incrementally adjust its output. Following this adjustment, a critical parameter is explicitly saved.\n\n**Explanation:** This code acts like an `if` statement within a larger control system: if the system is currently in its 'bandwidth probing' phase, it executes a command to increase its data sending rate (pacing rate) by a specific 'gain' factor (here, '1' suggests a default or initial increment). This is akin to a feedback loop where the system tests the network by pushing more data. Immediately after this rate adjustment, it calls `BBR_Save_Cwnd()`, which functions like copying a variable's current value to a temporary memory location or a designated 'save' register. This ensures that the congestion window's current state is preserved, either for later restoration, comparison, or as a baseline before further operations that might alter it."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_there exists a neighbor j with output 1 and rpsi,j_ ( _si_ ( _j_ ) _, sj_ ( _i_ )) _\u0338_ = _j_ **then**\n\n**24** `BeenCheated` _\u2190_ true;\n\n**25** From this point onward, disregard the rest of the algorithm and output _\u22a5_ if\n`BeenCheated` is **true**, and output 0 otherwise, in every round where node _i_ is\nstill Undecided;"}, {"role": "assistant", "content": "**Mechanism:** This mechanism acts as an immediate circuit-breaker for fraud detection in a distributed setting. It checks a neighbor's declared 'output' (a value like '1') against a cryptographic or integrity verification function, `rpsi,j`. If `rpsi,j` (which takes node `j`'s local state `si(j)` and node `i`'s local state `sj(i)`) fails to confirm `j`'s identity or the validity of its claim (meaning the result is not `j`), a 'BeenCheated' flag is set. This flag then triggers an early exit, causing node `i` to halt its participation in the current round and signal an error state.\n\n**Explanation:** Consider a system where nodes are exchanging information to reach a consensus. Node `i` observes its neighbor `j`. If `j` announces a significant outcome, like 'I've committed to value 1,' node `i` performs a quick integrity check. The `rpsi,j` function is akin to a digital signature verification or a hash check that uses specific secret shares or state information from both `j` (`si(j)`) and `i` (`sj(i)`). If this verification does *not* confirm that `j` is the legitimate source of the '1' claim (i.e., `rpsi,j(...) \u2260 j`), it means `j` is either malicious, faulty, or corrupted. This failure immediately flips a boolean `BeenCheated` flag to true. Once this flag is set, node `i` stops processing any further steps of the algorithm for this round. Instead of attempting to reconcile or participate further, it outputs a failure signal (`\u22a5`), effectively saying, 'I've detected foul play, I'm opting out of this round to maintain my own integrity.' If no such anomaly is detected, `i` continues to output `0` if it's still undecided, indicating normal, albeit incomplete, operation. This prevents a single malicious actor from poisoning the entire consensus process for node `i`."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nModern digital devices, from laptops and cell phones to large data centers, are usually equipped with multiple network\n\ninterfaces (e.g., Ethernet, WiFi, LTE/5G, optical, Bluetooth, etc.). Multipath TCP (MPTCP) protocol [36], which builds\n\nupon and extends standard TCP, emerged from the necessity to provide data communication services over multiple\n\npaths, by jointly using the available network interfaces of a multi-homed device. Although new protocols arise (e.g,\n\n_QUIC_ [26, 52] along with its multipath extension _MPQUIC_ [65]), TCP is still the predominant protocol for critical\n\napplications, as well as the default standard in all operating systems. MPTCP enables the exchange of data traffic over\n\nmultiple disjoint or common-bottleneck links allowing the communicating hosts to reach specific application goals;\n\nbe it higher data rate, lower flow completion time, or resilience in case of link failure. To this end, MPTCP provides a\n\nclear benefit to the application between two communicating systems. However, the simultaneous use of paths with\n\ninherently different network characteristics poses a challenge on MPTCP\u2019s performance. In fact, network links are\n\naffected either by the constantly fluctuating demand in shared network resources (e.g., in the Internet) which often\n\nleads to network congestion, increased intermediate buffer queues and packet drops, or by the nature of the physical\n\n[Authors\u2019 Contact Information: Dimitrios Dimopoulos, Lenovo Research, Athens, Greece and Department of Informatics and Telecommunications,](https://orcid.org/0000-0002-3722-2825)\n\n[National and Kapodistrian University of Athens, Ilisia, Athens, Greece, ddimopoulos@lenovo.com, ddimopoulos@di.uoa.gr; Apostolis K. Salkintzis,](https://orcid.org/0000-0002-8147-3285)\n\n[Lenovo Research, Athens, Greece, salki@motorola.com; Dimitris Tsolkas, Department of Informatics and Telecommunications, National and Kapodistrian](https://orcid.org/0000-0003-0301-3950)\n\n[University of Athens, Ilisia, Athens, Greece, dtsolkas@di.uoa.gr; Nikos Passas, Department of Informatics and Telecommunications, National and](https://orcid.org/0000-0002-2112-899X)\n\n[Kapodistrian University of Athens, Ilisia, Athens, Greece, passas@di.uoa.gr; Lazaros Merakos, Department of Informatics and Telecommunications,](https://orcid.org/0000-0003-4822-2393)\n\nNational and Kapodistrian University of Athens, Ilisia, Athens, Greece, merakos@di.uoa.gr.\n\n1\n\n2 D. Dimopoulos, et al.\n\nmedium (e.g., the 5G wireless interface) which is susceptible to random packet loss. The presence of path heterogeneity,\n\nin conjunction with MPTCP\u2019s adherence to TCP principles for reliable and in-order bytestream delivery, may lead\n\nto head-of-line (HoL) blocking at the receiver, stalling the connection and degrading the overall performance. In an\n\nattempt to tackle the functional and performance issues arising by the presence of heterogeneous paths, research\n\nefforts focus on providing enhanced congestion control and optimal packet scheduling algorithms that increase the\n\noverall performance and are tailored to application demands. In this direction, we hereby provide a comprehensible\n\nguide on MPTCP protocol structure and functionality, analyze the theoretical aspects behind the operation of the\n\nstate-of-art packet scheduling and congestion control algorithms, construct and present the detailed algorithmic steps\n\nin pseudo-code, and finally, perform an extensive performance assessment of the algorithms\u2019 combined operation under\n\nhomogeneous and asymmetric path conditions. The remainder of the paper is structured as follows. Section 2 provides\n\nthe necessary background on MPTCP protocol aspects and analyzes the best to date packet scheduling and congestion\n\ncontrol algorithms. Going beyond theory, an extensive experimental evaluation has been conducted, providing insight\n\non how MPTCP performs under different packet scheduling and congestion control mechanism combinations. To this\n\nend, Section 3 describes the experimentation methodology, while Section 4 presents the produced results. Section 5\n\ndiscusses the performance results and provides insight on the best-performing congestion control and packet scheduling\n\nschemes, while Section 6 is dedicated to the corresponding works available in literature. Finally, Section 7 concludes the\n\nmanuscript."}, {"role": "assistant", "content": "**Mechanism:** MPTCP fundamentally transforms a single logical TCP connection into multiple, concurrent sub-connections or 'subflows', each capable of traversing a distinct network path. Data is segmented and assigned sequence numbers, then distributed across these subflows. The core mechanism is concurrent, path-agnostic data transport combined with receiver-side reassembly.\n\n**Explanation:** The 'why' is to exploit all available network resources for a given communication, offering higher aggregate throughput or increased resilience. The primary intuitive challenge arises from path heterogeneity: if segments sent on a fast path arrive before earlier segments sent on a slow or lossy path, the receiver's reassembly buffer stalls. This is a head-of-line blocking issue, similar to how a queue-based system can only process items in order, even if later items are ready. MPTCP attempts to mitigate this by employing sophisticated congestion control (regulating sending rates on each subflow) and packet scheduling (intelligently deciding which data segment goes over which subflow) to minimize reordering delays and maximize overall efficiency, effectively balancing the disparate capacities and latencies of the underlying physical links."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe now analyse how fast the Gaussian score approximation from Eq. (7) converges to the true Gaussian\nES matrix gradient in Eq. (4). We introduce the following formal regularity assumption for the fitness\nfunction:\n**Assumption 2.** _Assume that f_ ( _M_ ) _is bounded, that is_ sup _M |f_ ( _M_ ) _| < \u221e._\n\nDenote the true full-rank Gaussian ES gradient as _g_ True := _\u2207\u00b5J_ ( _\u00b5_ ). Our key theoretical result characterises\nthe error rate between the Gaussian score approximator in the low-rank update \u02c6 _g_ LR _[r]_ [from Eq. (][5][) and the true]\ngradient using the matrix Frobenius norm:\n**Theorem 2.** _Let Assumptions 1 and 2 hold and set \u03c3_ 0 = 1 _, then:_\n\n\u02c6 1\n_\u2225g_ LR _[r]_ _[\u2212]_ _[g]_ [True] _[\u2225][F]_ [=] _[ O]_\n\ufffd _r_\n\n_._ (9)\n\ufffd\n\n_r_\n\nThe convergence rate in Eq. (9) is faster than the\ntypical _O_ ( [1] _/_ ~~_[\u221a]_~~ _r_ ) rate dictated by the general parametric central limit theorem. Our analysis shows that\nthis is due to the symmetry in our problem under\nAssumption 1. To obtain our results, we make an\nEdgeworth expansion (Bhattacharya & Ranga Rao,\n1976) of the density _p_ ( _Z_ _[r]_ ), which expands _p_ ( _Z_ _[r]_ )\nas the limiting Gaussian distribution plus a sum of\ndecaying terms that are controlled by the 3rd order\nand higher cumulants of _p_ ( _Z_ _[r]_ ). Each _i_ th order cumulant term is multiplied by a factor that decays at\nrate _O_ _r_ _[\u2212]_ _[i][\u2212]_ 2 [2] . For symmetric zero-mean distribu\ufffd \ufffd\n\n|r=1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|~~r=2~~<br>r=3<br>r=5<br>r=10||||||\n|r=50<br>r=100<br>r||||||\n|||||||\n|||||||\n|||||||\n\nFigure 3: Plot of Marginal Score Multiplied by Density for\nIncreasing _r_\n\nrate _O_ _r_ _[\u2212]_ _[i][\u2212]_ 2 [2] . For symmetric zero-mean distribu\ufffd \ufffd Figure 3: Plot of Marginal Score Multiplied by Density for\n\ntions, all odd cumulants are zero (for the same reason Increasing _r_\nthat all odd moments of a symmetric distribution are\nzero). Hence, the rate of convergence to the limiting distribution is controlled by the 4th order term, which has\nrate _O_ \ufffd _r_ _[\u2212]_ [1][\ufffd] .\n\nAlthough the full distribution _p_ ( _Z_ _[r]_ ) has no general closed-form solution, the distribution over marginals\n_p_ ( _zi,j_ ) is more amenable to analysis. We derive _p_ ( _zi,j_ ) for generalised Gaussian distributed _ai,j_ and _bi,j_ in\nSection B. To illustrate the fast converge rate, we plot the negative density _\u00d7_ score function _p_ ( _zi,j_ ) _zi,j_ for the\nmarginal distribution _p_ ( _zi,j_ ) in Fig. 3 using Gaussian distributed _ai,j_ and _bi,j_ with _\u03c3_ 0 [2] [= 1][ (see Theorem][ 4][ for]\n\n2\n\na derivation). The figure shows that _p_ ( _zi,j_ ) _zi,j_ quickly converges to the limiting function ~~_\u221a_~~ _[z][i]_ 2 _[,j]_ _\u03c0_ [exp] \ufffd _\u2212_ _[z][i]_ 2 _[,j]_ \ufffd,\n\nrecovering the Gaussian form from the true natural policy gradient update. Even at _r_ = 1, the function is not a\npoor approximation. After _r_ = 10, the function has nearly converged and after _r_ = 50, the function is visually\nindistinguishable from the limit, providing evidence for the hypothesis that the low-rank approximation is\naccurate even for very low rank regimes _r \u226a_ min( _m, n_ ).\n\n2\n\n_[,j]_ _\u2212_ _[z][i][,j]_\n\n2 _\u03c0_ [exp] \ufffd 2\n\na derivation). The figure shows that _p_ ( _zi,j_ ) _zi,j_ quickly converges to the limiting function ~~_\u221a_~~ _[z][i]_ 2 _[,j]_\n\n8"}, {"role": "assistant", "content": "**Mechanism:** The accelerated convergence rate (O(1/r) instead of O(1/\u221ar)) is achieved because the problem's inherent symmetry causes all odd-order error terms in the Edgeworth expansion of the distribution to vanish, leaving the faster-decaying even-order terms to dominate the error rate.\n\n**Explanation:** We are approximating a true, complex gradient with a much simpler, low-rank version. Think of this as compressing a detailed image into a smaller file size ('r' being the compression level). Typically, when you simplify or sample data, the accuracy of your approximation improves proportionally to the square root of how much data or complexity you retain (O(1/\u221ar)). This is a standard statistical outcome, similar to how the error in estimating a mean decreases with more samples. However, in this specific case, the underlying system (governed by Assumption 1) possesses a critical symmetry. When we analyze the error using an Edgeworth expansion \u2013 which is like adding successive 'correction' terms to a basic Gaussian approximation \u2013 this symmetry causes all the 'lopsided' or odd-numbered correction terms (like the 3rd, 5th, etc. cumulants) to become zero. It's like having a perfectly balanced seesaw; there's no force pushing it unevenly. Because these dominant odd-order error terms (which would normally decay slower, like O(r^(-3/2)) from the 3rd cumulant) vanish, the error is instead controlled by the next available, faster-decaying even-order terms (like the 4th cumulant, which decays at O(r^(-1))). This effectively 'skips' the slower convergence regime and jumps straight to a much faster one, meaning you need far less complexity ('r') to achieve high accuracy."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] = 0 **or** _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] _> \ud835\udc5e_ **then**\n\n**21** _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc5e_ ;"}, {"role": "assistant", "content": "**Mechanism:** This snippet implements a minimum tracking operation for an indexed value. It sets a new value 'q' only if 'q' is smaller than the currently recorded value for index 'r', or if the current value is 0 (acting as an uninitialized or 'infinite' placeholder).\n\n**Explanation:** Think of `_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ]` as an element in an array or hash map, where `r` is a specific key or index, and its value represents the current 'best' or 'minimum' observed queue delay for that `r`. The code is performing an `update_minimum` operation. If `_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ]` is 0, it means no valid delay has been recorded yet, so any incoming `_\ud835\udc5e_` value is accepted. Otherwise, it checks if the *new* delay `_\ud835\udc5e_` is strictly less than the *current* recorded `_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ]`. If it is, the new, smaller `_\ud835\udc5e_` replaces the old value. This efficiently maintains the smallest delay seen so far for each `r` without extra comparisons or storage for previous values."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Design Principles & Goals** . To facilitate practical adoption,\nTLT adheres to four key design principles:\n(a) _Lossless Guarantee_ . System optimizations must be lossless,\npreserving the mathematical equivalence in both rollout and\ntraining stages compared to the original algorithm, thereby\navoiding asynchronous staleness or lossy approximations.\n(b) _Interference-Free_ . The adaptive drafter workload must not\ninterfere with the primary RL workload. Drafter updates\nare performed opportunistically (as spot tasks) and can be\nsmoothly preempted to minimize impact on the RL workload.\n(c) _Automatic and Simple_ . Manually setting up the draft model\nand configuring its speculative hyperparameters are burdensome and often lead to suboptimal performance. Thus, TLT\nfeatures an automated workflow for ease of use.\n\n(d) _Generalizable and Scalable_ . The design must be adaptable\nto various popular reasoning RL algorithms (e.g., GRPO [51],\nRLOO [1]). Furthermore, TLT should scale effectively and deliver continuous system performance improvements across\ndifferent model sizes, architectures, and cluster scales.\nIn addition, TLT has three primary objectives: (1) Mitigate\nthe long-tail problem to accelerate reasoning RL training; (2)\nEnhance cluster utilization and minimize resource waste; (3)\nProduce a high-performance draft model for future deployment with speculative decoding at no extra cost.\n\n4\n\n**Architecture & Workflow** . Figure 6 illustrates the overall\narchitecture of TLT and its workflow. The system is composed of two tightly integrated components: the Adaptive\nDrafter (\u00a74) and the Adaptive Rollout Engine (\u00a75).\nThe rollout process exhibits two key characteristics: a\nlong-tail distribution of sequence lengths and progressively\nshrinking batch sizes as responses complete. To adapt to\nthese dynamics, the Adaptive Rollout Engine maintains a\npool of pre-captured CUDAGraphs for both target and draft\nmodels, managed by the Adaptive SD Manager. This manager\nleverages the proposed BEG-MAB tuner to automatically\nselect appropriate SD strategies for each input batch. As\nshown in the top of Figure 6, the selected drafter CUDAGraph\ngenerates candidate tokens (\u2460), which are then passed to the\ncorresponding target CUDAGraph for parallel verification\n\n  (\u2461 \u2462). The engine measures acceptance length and step\nlatency (\u2463), feeding these signals back to the SD Manager\n(\u2464) to refine strategy selection in real time.\nMeanwhile, the Adaptive Drafter module is responsible for\ncontinuously updating the lightweight draft model without\ninterfering with the main rollout workload. A centralized\nWorker Coordinator monitors the state of rollout workers.\n\nWhen idle resources appear during the long-tail stage, the\ncoordinator opportunistically launches Spot Trainer tasks.\nThe training tasks use the Online DataBuffer, which caches\nhidden states and input embeddings from ongoing and prior\nsteps\u2019 rollout. The draft model receives efficient updates\nusing techniques such as zero-padding packing and selective asynchronous checkpointing. This design ensures that\ndrafter updates can be preempted and resumed seamlessly,\nexploiting wasted bubbles.\nBy systematically combining adaptive rollout with opportunistic drafter training, TLT achieves substantial speedups\nfor reasoning RL without compromising model quality, yielding a valuable draft model as a free by-product."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a form of 'speculative execution' coupled with opportunistic background computation. A lightweight 'draft model' makes multiple predictions for a sequence of future steps, which are then batch-verified in parallel by a more accurate 'target model'. This bypasses the sequential cost of generating each step with the target model. The draft model itself is continually improved by training during periods when the primary RL rollout workload has spare capacity, effectively turning 'idle' computational cycles (e.g., during varying sequence lengths or when batch sizes shrink) into productive work to refine the helper model.\n\n**Explanation:** The challenge is that RL training often involves generating sequences of varying lengths, leading to computational inefficiencies like long-tail distributions of sequence lengths and progressively shrinking batch sizes. This system addresses this by introducing two closely integrated components. First, an 'Adaptive Rollout Engine' uses pre-compiled computation graphs (like cached, optimized functions) for both the fast 'draft' model and the accurate 'target' model. It adaptively selects strategies to make the draft model generate multiple candidate steps (like pre-fetching instructions in a CPU pipeline). These candidates are then passed to the target model for rapid, parallel verification. Second, an 'Adaptive Drafter' component acts like a low-priority background process. It monitors the main RL workload and, when it detects periods of underutilization or 'bubbles' in the processing pipeline, it launches 'spot tasks' to train the draft model. This training uses cached data from ongoing and prior rollouts. By updating the draft model during these otherwise wasted cycles, it continuously improves the draft model's ability to make accurate multi-step predictions without adding any overhead to the main RL task. This simultaneous guessing and verifying, combined with opportunistic self-improvement, significantly accelerates overall training."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ [ _\ud835\udc5f_ ] \u2260 0 **then**\n\n**30** _\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 _\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ [ _\ud835\udc5f_ ]/ _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ ;\n\n**On packet loss for subflow** _\ud835\udc5f_ **:**\n\n**31** _\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc4f\ud835\udc5f\ud835\udc56\ud835\udc62\ud835\udc5a_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 0 ;\n\n**32** _\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc66\ud835\udc60_ [ _\ud835\udc5f_ ] \u2190 0 ;\n\nThe theoretical aspects of _wVegas_ congestion control algorithm are provided in 2.3.5.\n\n52 D. Dimopoulos, et al.\n\n**Algorithm 12:** Bottleneck Bandwidth and Round-trip propagation time (BBR) - [theoretical part in 2.3.6]\n\n**1 Initialization:**\n\n**2** BBR_On_Connection_Init():\n\n**3** BBR_Init();\n\n**On ACK arrival:**\n\n**4** BBR_Update_On_ACK():\n\n**5** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc40\ud835\udc5c\ud835\udc51\ud835\udc52\ud835\udc59_ _ _\ud835\udc34\ud835\udc5b\ud835\udc51_ _ _\ud835\udc46\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ () ;\n\n**6** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc5c\ud835\udc59_ _ _\ud835\udc43\ud835\udc4e\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc52\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc60_ () ;\n\n**7** BBR_Update_Model_And_State():\n\n**8** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64_ () ;\n\n**9** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc36\u210e\ud835\udc52\ud835\udc50\ud835\udc58_ _ _\ud835\udc36\ud835\udc66\ud835\udc50\ud835\udc59\ud835\udc52_ _ _\ud835\udc43\u210e\ud835\udc4e\ud835\udc60\ud835\udc52_ () ;\n\n**10** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc36\u210e\ud835\udc52\ud835\udc50\ud835\udc58_ _ _\ud835\udc39\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52_ () ;\n\n**11** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc36\u210e\ud835\udc52\ud835\udc50\ud835\udc58_ _ _\ud835\udc37\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b_ () ;\n\n**12** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ () ;\n\n**13** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc36\u210e\ud835\udc52\ud835\udc50\ud835\udc58_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**14** BBR_Update_Control_Parameters():\n\n**15** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc52\ud835\udc61_ _ _\ud835\udc43\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc45\ud835\udc4e\ud835\udc61\ud835\udc52_ () ;\n\n**16** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc52\ud835\udc61_ _ _\ud835\udc46\ud835\udc52\ud835\udc5b\ud835\udc51_ _ _\ud835\udc44\ud835\udc62\ud835\udc4e\ud835\udc5b\ud835\udc61\ud835\udc62\ud835\udc5a_ () ;\n\n**17** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc52\ud835\udc61_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ () ;\n\n**On packet transmission:**\n\n**18** BBR_On_Transmit():\n\n**19** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3b\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc52_ _ _\ud835\udc45\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ _ _\ud835\udc39\ud835\udc5f\ud835\udc5c\ud835\udc5a_ _ _\ud835\udc3c\ud835\udc51\ud835\udc59\ud835\udc52_ () ;\n\n**Initialization function definitions:**\n\n**20** BBR_Init():\n\n**21** _\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61_ _ _\ud835\udc64\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc51_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _ _\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f_ ( _\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc35\ud835\udc61\ud835\udc59\ud835\udc35\ud835\udc64\ud835\udc39\ud835\udc56\ud835\udc59\ud835\udc61\ud835\udc52\ud835\udc5f, \ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52_ = 0 _, \ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52_ = 0) ;\n\n**22** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ = _\ud835\udc46\ud835\udc45\ud835\udc47\ud835\udc47_ ? _\ud835\udc46\ud835\udc45\ud835\udc47\ud835\udc47_ : _\ud835\udc3c\ud835\udc5b\ud835\udc53_ ;\n\n**23** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = _\ud835\udc41\ud835\udc5c\ud835\udc64_ () ;\n\n**24** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61_ _ _\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = 0 ;\n\n**25** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61_ _ _\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**26** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc61_ _ _\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**27** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f_ _ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ = 0 ;\n\n**28** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc56\ud835\udc51\ud835\udc59\ud835\udc52_ _ _\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**29** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61_ _ _\ud835\udc45\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc36\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54_ () ;\n\n**30** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61_ _ _\ud835\udc39\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52_ () ;\n\n**31** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61_ _ _\ud835\udc43\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc45\ud835\udc4e\ud835\udc61\ud835\udc52_ () ;\n\n**32** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc38\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f_ _ _\ud835\udc46\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc62\ud835\udc5d_ () ;\n\n**33** BBR_Init_Round_Counting():\n\n**34** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_ _ _\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc51\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc51_ = 0 ;\n\n**35** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**36** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ = 0 ;\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 53\n\n**Initialization function definitions (cont.):**\n\n**37** BBR_Init_Full_Pipe():\n\n**38** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_ _ _\ud835\udc5d\ud835\udc56\ud835\udc5d\ud835\udc52_ = _\ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52_ ;\n\n**39** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc4f\ud835\udc64_ = 0 ;\n\n**40** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc53\ud835\udc62\ud835\udc59\ud835\udc59_ _ _\ud835\udc4f\ud835\udc64_ _ _\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61_ = 0 ;\n\n**41** BBR_Init_Pacing_Rate():\n\n**42** _\ud835\udc5b\ud835\udc5c\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc4f\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc64\ud835\udc56\ud835\udc51\ud835\udc61\u210e_ = _\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ /( _\ud835\udc46\ud835\udc45\ud835\udc47\ud835\udc47_ ? _\ud835\udc46\ud835\udc45\ud835\udc47\ud835\udc47_ : 1 _\ud835\udc5a\ud835\udc60_ ) ;\n\n**43** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ \u2217 _\ud835\udc5b\ud835\udc5c\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_ _ _\ud835\udc4f\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc64\ud835\udc56\ud835\udc51\ud835\udc61\u210e_ ;\n\n**44** BBR_Enter_Startup():\n\n**45** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ = _\ud835\udc46\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc62\ud835\udc5d_ ;\n\n**46** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc5b\ud835\udc54_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = _\ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc3b\ud835\udc56\ud835\udc54\u210e\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b_ ;\n\n**47** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ _ _\ud835\udc54\ud835\udc4e\ud835\udc56\ud835\udc5b_ = _\ud835\udc35\ud835\udc35\ud835\udc45\ud835\udc3b\ud835\udc56\ud835\udc54\u210e\ud835\udc3a\ud835\udc4e\ud835\udc56\ud835\udc5b_ ;\n\n**ACK-arrival function definitions (1/4):**\n\n**48** BBR_Update_BtlBw():\n\n**49** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc48\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52_ _ _\ud835\udc45\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51_ () ;"}, {"role": "assistant", "content": "**Mechanism:** The 'wVegas' snippet implements a reactive reset mechanism: upon detecting packet loss for a specific subflow ('r'), it zeroes out the subflow's equilibrium rate and queue delay. This effectively pauses or aggressively curtails traffic for that subflow, forcing a recalculation or restart of its sending behavior. The BBR algorithm, conversely, operates on a proactive, model-based approach. On ACK arrival, it continuously updates its internal model of the network path by measuring 'Bottleneck Bandwidth' (BtlBw) and 'Round-trip propagation time' (RTprop). It uses a 'windowed max filter' (similar to a moving average, but tracking the maximum value over a recent period) to estimate BtlBw and a minimum tracker for RTprop. Based on these estimations, it adjusts its 'pacing rate' (how quickly it sends new packets) and 'congestion window' (how many packets can be in flight) using 'gain' factors, which are essentially multipliers that determine aggressiveness. The initialization phase sets up these trackers and state variables, entering a 'Startup' mode where higher gain factors are used to rapidly explore the network's capacity. This iterative feedback loop on ACK arrival allows BBR to dynamically converge on the optimal sending parameters for a given network path.\n\n**Explanation:** At its core, the wVegas behavior described is a simple conditional reset: `if (packet_loss_for_subflow_r) then reset_subflow_r_state`. This means if a data chunk doesn't make it, that particular data stream effectively hits a 'pause and forget' button for its rate and delay metrics. BBR, on the other hand, is a control system that uses continuous observation to infer network characteristics and then adjust its output. Think of `BBR_Update_BtlBw()` and `BBR_Update_RTprop()` as functions that maintain running 'min' and 'max' values for throughput and latency. `BBR.BtlBwFilter` is like a data structure that keeps a small history of throughput measurements and constantly gives you the highest throughput seen recently, allowing it to adapt to changing bottleneck capacities. `BBR.rtprop` stores the absolute minimum round-trip time, representing the pure transmission delay without queuing. The `gain` factors (`BBRHighGain`) are like tuning parameters that increase or decrease how aggressively BBR pushes data. For example, in `Startup` mode, high gains mean BBR will quickly try to send more data to find the true bottleneck bandwidth. The `BBR_Init_Pacing_Rate()` function uses an initial `Cwnd` (like a maximum number of outstanding tasks) and `SRTT` (smoothed average round-trip time) to make an initial guess for how fast to send, essentially setting an initial `loop_delay` for packet transmission. All these functions together form a continuous feedback loop where acknowledgements (ACKs) are the sensor input, and the pacing rate and congestion window are the actuator outputs."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udf0f_ _is updated_ **then**\n\n**24** _\ud835\udc64_ ( _\ud835\udf0f_ ) \u2190 _\ud835\udc64_ ( _\ud835\udf0f_ )/ _\ud835\udc64\ud835\udc60\ud835\udc62\ud835\udc5a_ ( _\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51_ ) \u00b7 _\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc54_ ;\n\n**25** _\ud835\udf05_ \u02dc [\u2032] \u2190 _\ud835\udf05_ \u02dc [\u2032] + _\ud835\udc53_ ( _\ud835\udf0f_ ) \u00b7 _\ud835\udc64_ ( _\ud835\udf0f_ );\n\n**26 return** \u02dc _\ud835\udf05_ [\u2032] _,\ud835\udc46_ [\u2032] ;\n\nProof Sketch. The proof is similar to that of Theorem 4.4. By\nusing the definition of expectation and the properties of the bipartite\ngraph B, we can derive the desired result. \n\nThe implementation of improved sample maintenance (ISM)\nalgorithm is shown in Algorithm 3. The main distinction lies in the\nfact that the new spanning tree is obtained directly through the\nlink-cut process, which ensures that only a portion of the nodes\nin the original tree are affected. Updates of _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] ) are performed\nexclusively for these affected nodes, and the corresponding weights\nare computed (Lines 6\u20138, 19\u201321). Additionally, after each update,\nthe weights of all trees need to be normalized (Lines 10\u201313, 23\u201324).\nInitially, the weight of each tree is set to 1/| _\ud835\udf14_ |, so there is no need\nto divide by | _\ud835\udf14_ | again when calculating KC in the final step.\n\nTheorem 4.6 (Correctness and Time Complexity of ISM).\nISM _returns an estimate_ \u02dc _\ud835\udf05_ [\u2032] _that satisfies the relative-error guarantee._\n_The overall time complexity_ ISM _is_\n\n_\ud835\udc42_ ( _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udf14_      - ( _\ud835\udc5a_ + _\ud835\udc5b_ min(\u0394 _,_ log _\ud835\udc5b_ ))) _,_\n\n_where \ud835\udc52_ _denotes the inserted (or deleted) edge, and \ud835\udc45_ ( _\ud835\udc52_ ) _represents the_\n_effective resistance of edge \ud835\udc52_ _in the graph that includes \ud835\udc52._\n\nProof. By combining Theorem 4.4 and Theorem 4.5, we substitute them into Theorem 4.1 and Theorem 4.2, respectively. ISM\n\n_\ud835\udc45_ ( _\ud835\udc52_ )\nE E\n_\ud835\udf0f_ \u223c _\ud835\udc48_ (\u0393) [[] _[\ud835\udc53]_ [(] _[\ud835\udf0f]_ [)]][ =] 1 \u2212 _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udf0f\ud835\udc52_ \u223c _\ud835\udc48_ (\u0393 _\ud835\udc52_ [\u2032] )\n\nE\n\ufffd _\ud835\udf0f_ \u223c _\ud835\udc48_ (N _\ud835\udc35_ ( _\ud835\udf0f\ud835\udc52_ ))\n\nScalable and Provable Kemeny Constant Computation on Static and Dynamic Graphs: A 2-Forest Sampling Approach\n\n**Table 2: Detailed statistics of datasets (** \u0394 **denotes the graph**\n**diameter,** _\ud835\udf19_ **is the expected time of sampling a UST, and** _\ud835\udc45_ [\u00af] ( _\ud835\udc52_ )\n**represents the average effective resistance of each edge)**\n\n**Dataset** _\ud835\udc5b_ _\ud835\udc5a_ \u0394 _\ud835\udf19_ _\ud835\udc45_ \u00af( _\ud835\udc52_ )\n\nPowerGrid 4,941 6,594 46 4 _._ 4 \u00d7 10 [4] 0.749\nHep-th 8,638 24,806 17 1 _._ 7 \u00d7 10 [4] 0.348\nAstro-ph 17,903 196,972 14 2 _._ 3 \u00d7 10 [4] 0.091\nEmail-enron 33,696 180,811 11 5 _._ 0 \u00d7 10 [4] 0.186\nAmazon 334,863 925,872 44 9 _._ 0 \u00d7 10 [5] 0.362\nDBLP 317,080 1,049,866 21 5 _._ 9 \u00d7 10 [5] 0.302\nYoutube 1,134,890 2,987,624 20 1 _._ 8 \u00d7 10 [6] 0.380\nroadNet-PA 1,087,562 1,541,514 786 1 _._ 7 \u00d7 10 [7] 0.706\nroadNet-CA 1,957,027 2,760,388 849 3 _._ 5 \u00d7 10 [7] 0.709\nOrkut 3,072,441 117,185,083 9 3 _._ 1 \u00d7 10 [6] 0.026\n\nproduces an estimator for KC on the updated graph while maintaining a relative-error guarantee, under the assumption that the\nrequired sample size remains at the same level even if the maximum\nvalue of _\ud835\udc53_ ( _\ud835\udf0f_ ) changes.\nFor any _\ud835\udf0f_ \u2208 \u0393, its degree _\ud835\udc51_ ( _\ud835\udf0f_ ) in B can be computed in _\ud835\udc42_ ( _\ud835\udc5b_ ) time\nby counting the length of the unique path between the endpoints\nof the inserted edge _\ud835\udc52_ . Similarly, for _\ud835\udf0f\ud835\udc52_ \u2208 \u0393 _\ud835\udc52_ [\u2032][, its degree] _[ \ud835\udc51]_ [(] _[\ud835\udf0f][\ud835\udc52]_ [)][ is]\ndetermined by the number of trees that can be transformed into _\ud835\udf0f\ud835\udc52_\nvia a link-cut operation, which is equivalent to the number of trees\nthat can be obtained from _\ud835\udf0f_ 0 via a cut-link operation. Consequently,\n_\ud835\udc51_ ( _\ud835\udf0f\ud835\udc52_ ) equals the number of edges in _\ud835\udc3a_ that cross between _\ud835\udc47_ 1 and _\ud835\udc47_ 2,\nwhere _\ud835\udc47_ 1 \u222a _\ud835\udc47_ 2 = _\ud835\udf0f\ud835\udc52_ \\ _\ud835\udc52_ . This computation has a time complexity of\n_\ud835\udc42_ ( _\ud835\udc5b_ ). Therefore, the overall complexity of updating for each tree is\n_\ud835\udc42_ ( _\ud835\udc5b_ ).\nThe time complexity for updating _\ud835\udc53_ ( _\ud835\udf0f_ [\u2032] ) remains _\ud835\udc42_ ( _\ud835\udc5b_ log _\ud835\udc5b_ ), as\nits worst case requires recomputing the function for the entire\ntree. Hence, the overall time complexity of ISM is _\ud835\udc42_ ( _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udc47_ ( _\ud835\udc5a_ +\n_\ud835\udc5b_ log _\ud835\udc5b_ )). In the case of scale-free graphs, where _\ud835\udc5a_ = _\ud835\udc42_ ( _\ud835\udc5b_ log _\ud835\udc5b_ ), this\ncomplexity simplifies to _\ud835\udc42_ ( _\ud835\udc45_ ( _\ud835\udc52_ ) _\ud835\udc47\ud835\udc5b_ log _\ud835\udc5b_ ), representing a significant\nimprovement over its static counterpart. \n\n**Discussion.** ISM further accelerates the UST sampling process\ncompared to BSM. By leveraging _link-cut_ and _cut-link_ operations,\nit can construct the required spanning tree more efficiently than\nWilson\u2019s algorithm. Although computing the weights introduces\nan _\ud835\udc42_ ( _\ud835\udc5a_ ) time complexity, in practice, it is significantly faster than\nsampling USTs. Furthermore, since the tree structure changes only\nslightly, previously computed results of _\ud835\udc53_ ( _\ud835\udf0f_ ) can be partially reused,\nwhich reduces the overall computational cost."}, {"role": "assistant", "content": "**Mechanism:** The algorithm's core mechanism revolves around dynamic connectivity structures, specifically 'link-cut' and 'cut-link' operations on spanning trees. When an edge is inserted or deleted, it directly modifies a Uniform Spanning Tree (UST) by performing a localized structural change rather than re-sampling an entirely new tree from the graph. This is analogous to a pointer-based update in a linked list or tree data structure where you only re-link specific nodes instead of copying the entire structure. The `f(\u03c4)` values, which are essentially feature calculations over these trees, are then only updated for the specific affected nodes along the paths modified by the link-cut operation, acting like a targeted cache invalidation or partial memoization. Finally, the weights `w(\u03c4)` of the updated trees are normalized using a simple multiplicative adjustment to maintain a consistent probability distribution, similar to re-scaling an array of values so they sum to one.\n\n**Explanation:** At its heart, this method bypasses the computationally expensive process of re-sampling or re-evaluating all possible spanning trees every time an edge changes in a graph. Instead, it maintains a representative set of spanning trees and, when an edge 'e' is added or removed, it intelligently updates these trees. The 'link-cut' operation means that if adding an edge 'e' creates a cycle in a current spanning tree, it can efficiently 'cut' an edge from that cycle to restore tree properties while incorporating 'e'. This is a fast, logarithmic-time operation (O(log n)) in many cases for dynamic trees. Because only a small portion of the tree structure changes, the algorithm only recomputes `f(\u03c4)` for those specific affected nodes. This is akin to having a large spreadsheet where you only update the cells whose values directly depend on a changed input, rather than recalculating the entire sheet. The final weights are then normalized to ensure the probabilities remain valid, effectively re-balancing the 'importance' of each updated tree proportional to the change."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nWe focus exclusively on the row-wise implementation. In this application, the Gated Recurrent\n\nUnit (GRU) model exhibits a computational dependency on its previous hidden state and thus,\n\nthe overall latency of the model and the iteration interval (the time between consecutive forward\n\npasses) should be identical, since each iteration must await the completion of the preceding one.\n\nThe kernels responsible for performing the **W** - _\ud835\udc65_ matrix\u2013vector multiplication are decoupled from\n\nthe rest of the computational pipeline, allowing them to prefetch and process new input data as long\n\nas they do not experience backpressure from downstream kernels.\n\n**Figure 3** : Latency results for a GRU using the PL kernel called \"Hybrid\" and the GRU implemen\ntation completely inside the AI Engine called \"AIE\".\n\nThe latency measurement is performed directly in hardware. We monitor two consecutive\n\nTVALID signal activations on the selected output stream interface, measuring the elapsed time\n\nbetween the assertion of the signal for the first valid datum and its subsequent activation for the\n\nnext iteration. This interval corresponds to the true latency of a complete forward pass through the\n\nmodel.\n\nThe key features of Fig. 3 are: 1) The better latency of the Hybrid model scaling up with the\n\nhidden state dimension. 2) The plateau in latency with respect to the input size showcasing the\n\ndecoupling of the **W** - _\ud835\udc65_ computing kernels. Once the computation starts taking more time than the\n\nforward pass of the model itself, it adds latency linearly.\n\n\u2013 6 \u2013\n\n![](papers/images/A-LatencyConstrained-Gated-Recurrent-Unit-GRU-Implementation-in-the-Versal-AI-Engine.pdf-5-0.png)\nIf we allow a hidden state dimension larger than 32 we suffer limitations in the number of\n\navailable AIE tiles, interface tiles, and packet merge connections. In this case, the same architecture\n\ncan be used by allowing the kernels to compute more matrix rows and reuse the same data transfer\n\npaths.\n\n**References**\n\n[1] AMD, _Versal Adaptive SoCs_, 2025.\n\n[2] E. Taka, A. Arora, K.-C. Wu and D. Marculescu, _Maxeva: Maximizing the efficiency of matrix_\n_multiplication on versal ai engine_, 2023.\n\n[3] J. Zhuang, J. Lau, H. Ye, Z. Yang, Y. Du, J. Lo et al., _Charm: Composing heterogeneous accelerators_\n_for matrix multiply on versal acap architecture_, 2023.\n\n[4] AMD, _Free-Running AI Engine Kernel \u2014 UG1079 AI Engine Kernel and Graph Programming_\n\n_Guide_, 2024.\n\n[5] AMD, _PL Interface Tile Capabilities \u2014 UG1079 AI Engine Kernel and Graph Programming Guide_,\n\n2024.\n\n[6] R.M. Schmidt, _Recurrent neural networks (rnns): A gentle introduction and overview_, _CoRR_\n**abs/1912.05911** [(2019) [1912.05911].](https://arxiv.org/abs/1912.05911)\n\n[7] J. Chung, C. Gulcehre, K. Cho and Y. Bengio, _Empirical evaluation of gated recurrent neural_\n_networks on sequence modeling_, 2014.\n\n[8] S. Hochreiter and J. Schmidhuber, _Long short-term memory_, _[Neural Computation](https://doi.org/10.1162/neco.1997.9.8.1735)_ **9** (1997) 1735.\n\n[9] C. Holmes, D. Mawhirter, Y. He, F. Yan and B. Wu, _Grnn: Low-latency and scalable rnn inference on_\n_gpus_, in _Proceedings of the Fourteenth EuroSys Conference 2019_, EuroSys \u201919, (New York, NY,\n[USA), Association for Computing Machinery, 2019, DOI.](https://doi.org/10.1145/3302424.3303949)\n\n[10] Advanced Micro Devices, Inc., _AI Engine API User Guide (AIE-API) 2024.1 \u2013 API Reference_ .\n\nAdvanced Micro Devices, Inc., 2024.\n\n[11] Advanced Micro Devices, Inc., _Vitis High-Level Synthesis User Guide (UG1399) \u2013 HLS_\n_Programmer\u2019s Guide_ . Advanced Micro Devices, Inc., 2024.\n\n\u2013 7 \u2013"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism optimizes sequential recurrent computations by decoupling and asynchronously pre-computing the most computationally intensive input-dependent operation (W*x matrix-vector multiplication) from the core recurrent state update. This establishes a pipelined producer-consumer model where the W*x kernels act as a producer populating a buffer, allowing the GRU core (consumer) to retrieve pre-computed results without incurring their real-time calculation latency.\n\n**Explanation:** A GRU model's inherent dependency on its previous hidden state (h_t needing h_{t-1}) creates a critical path, meaning the iteration interval is bounded by the longest sequential operation. This paper mitigates this by identifying the W*x multiplication, which processes the current input, as a primary bottleneck. Instead of a synchronous execution where W*x must complete before the GRU core can proceed, dedicated kernels perform W*x operations for future time steps in parallel. This is akin to a separate CPU thread pre-calculating data and pushing it into a FIFO queue. The GRU core then pulls pre-computed W*x results from this queue, hiding the W*x latency as long as the pre-computation is faster than, or equal to, the GRU core's processing time. The observed 'plateau' in latency confirms this: beyond a certain input size, increasing the input doesn't increase overall latency because the W*x component is already being processed 'ahead of time' and the GRU core becomes the limiting factor. If the W*x pre-computation eventually takes longer than the GRU core, it then becomes the bottleneck, and latency increases linearly, effectively stalling the pipeline. The 'Hybrid' approach likely leverages the Versal's Programmable Logic (PL) for these W*x kernels, providing more dedicated hardware resources and parallelism compared to a purely AI Engine (AIE) implementation, enabling better scaling for larger hidden state dimensions."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nTo address the functional errors in the HDL design generated by\nLLMs, an effective approach is to use a reference HDL design to guide\nthe code generation process of LLMs. Such a functional reference\nshould be able to establish the mapping from a high-level description\nto HDL that accurately reflects the intended circuit behavior. The\nperformance, power, and area (PPA) of such a reference are not\ncritical, because only the HDL generated by LLMs is used in real\ncircuit design. To create such a reference, the appropriate format of\nthe high-level description and a verified toolchain that can generate\nan HDL design from this description should be identified.\nOver the past decades, the EDA community has proposed a wide\nrange of solutions for circuit design based on abstract behavioral or\nalgorithmic descriptions, among which high-level synthesis (HLS)\nhas emerged as the most prominent approach for translating C/C++\nprograms into HDL designs [2, 3]. Modern HLS toolchains are mature and highly reliable, achieving notable success in both industry\nand academia [4, 5]. Unlike direct software-level simulation, the\nHLS-generated circuit reference preserves precise hardware semantics, accurately handling customized bit widths, type conversions,\nbit truncation/rounding modes. This eliminates the semantic ambiguities inherent in software simulation. However, the underlying\ncompilation flows of HLS tools typically rely on fixed templates and\ncoarse-grained pragma tuning, leading to suboptimal area and power\nefficiency of the synthesized circuit [44, 45]. In addition, the HDL designs generated by HLS are often difficult to interpret, which makes\nlate-stage Engineering Change Orders (ECOs) challenging in ASICoriented physical design [46]. Consequently, for high-performance\ndesigns, engineers still prefer to manually craft HDL based on the\nalgorithm descriptions to meet stringent PPA requirements [48].\nGiven the ability of HLS to generate functionally correct HDL\ndesigns, our agentic design framework, _CorrectHDL_, takes advantage of the results of HLS to guide LLMs in automatic HDL generation. In this framework, the generative capabilities of LLMs are\nleveraged to produce flexible HDL, while the HLS tool provides a\nbit-accurate golden reference to guide the functional correctness\nof LLM-generated HDL. Since LLMs do not use predefined circuit\ntemplates but rely on abstracted design knowledge, they can flexibly\ncreate circuits that outperform HLS-generated designs in terms of\nPPA and approach the quality of human-engineered circuits.\n\n**Figure 3: Examples of HDL Generation via LLM and HLS.**\n\nThe concept of _CorrectHDL_ is illustrated in Fig. 2. The circuit\nspecification written in C/C++ is first processed by an HLS tool,\nwhich produces a functionally correct HDL design that serves as the\ngolden reference. The functional behavior of the HDL generated by\nthe LLM is then compared with that of the reference design from\nHLS. The discrepancy is used to guide the LLM to iteratively enhance\nthe HDL designs to achieve functional correctness.\nThe input to the _CorrectHDL_ framework consists of circuit descriptions expressed in C/C++, which provide a more detailed specification than the natural language inputs used in many state-ofthe-art solutions [22\u201330]. This choice makes the framework directly\napplicable to system design engineers who typically work at the\nalgorithm level. Meanwhile, natural language specifications can\nbe automatically translated into C/C++ using LLMs, which have\ndemonstrated high accuracy in code generation within the software\ncommunity [41, 42]. Accordingly, the proposed _CorrectHDL_ effectively bridges an important gap in LLM-based circuit design.\nThe output of the _CorrectHDL_ framework is a circuit generated by\nthe LLM. Its functionality is iteratively improved by comparing its\nbehavior against a reference HDL produced by HLS. The correctness\nof this reference HDL is validated using a testbench that the HLS tool\nautomatically derives from the original C/C++ testbench. However,\nthis converted testbench is coupled to the tool-specific interfaces of\nthe synthesized design, so it cannot be directly used to simulate the\ncircuit generated by the LLM agent. To address this issue, we also\nemploy LLMs to translate the original C/C++ testbench into an HDL\ntestbench that is compatible with the LLM-generated HDL. Limited\nhuman effort is still required during this process to ensure the quality\nof the resulting testbench. Functional comparison is then performed\nby evaluating the output data of the LLM-generated circuit against\nthat of the HLS reference under the same test stimuli.\n\nFig. 3(b) illustrates an example of an LLM-generated HDL design\nfrom the C/C++ program in Fig. 3(a), which exhibits good readability.\nHowever, limited hardware-oriented training data and LLM hallucinations often lead to functional errors (line 7). On the contrary, the\ncode in Fig. 3(c) generated by HLS is functionally correct, but it has\nfar inferior readability and PPA. The objective of _CorrectHDL_ is thus\nto enhance the functional correctness of the LLM-generated HDL\ndesign using the HLS-generated HDL design as a reference.\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-3.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-10.png)\n\n|LLM-Generated HDL (DUT)|Col2|\n|---|---|\n|< / >LLM-Generated HDL(DUT)||\n|**`module`**` aes256(`**`input`**` start\u2026);`<br>`function [7:0] xt;`<br>`begin xt = x<<1; reg [7:0] tmp;\u2026`|**`module`**` aes256(`**`input`**` start\u2026);`<br>`function [7:0] xt;`<br>`begin xt = x<<1; reg [7:0] tmp;\u2026`|\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-11.png)\n\n**(1)** LLM-Aided HDL Generation\n\nwith C/C++ Decomposition\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-12.png)\n\n**Output:** Functionally Correct HDL Design\n\n**Figure 4: Proposed HDL design agent.**\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-15.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-13.png)\n\n![](papers/images/CorrectHDL-Agentic-HDL-Design-with-LLMs-Leveraging-HighLevel-Synthesis-as-Reference.pdf-2-14.png)\n\n**Figure 5: LLM-assisted HDL generation.**"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is an iterative refinement loop where a generative model (LLM) is guided by a functionally verified reference (HLS output). This creates a feedback system akin to a closed-loop control system, ensuring functional convergence.\n\n**Explanation:** Consider a C/C++ description as a high-level specification for a digital circuit. We employ two distinct paths to generate hardware description language (HDL) from this specification. The first path utilizes High-Level Synthesis (HLS) tools. HLS acts as a highly disciplined compiler, translating C/C++ constructs into predefined, functionally verified hardware templates. This process guarantees functional correctness down to the bit-level, much like a software compiler ensures a program executes as intended, but often results in suboptimal hardware in terms of performance, power, and area (PPA) due to its fixed structural mappings. The second path involves an LLM, which leverages its learned patterns from vast datasets to generate HDL. Unlike HLS, the LLM is not constrained by fixed templates, allowing it to explore a broader design space and potentially generate HDL with superior PPA. However, the LLM's generative nature is prone to functional errors. The 'CorrectHDL' framework introduces a critical feedback loop to rectify these errors. Both the HLS-generated HDL (the 'golden reference') and the LLM-generated HDL are simulated with identical test stimuli derived from the original C/C++ testbench (with LLMs translating the testbench for compatibility). The outputs of these two HDL designs are then compared. Any discrepancy indicates a functional error in the LLM's output. This difference signal is then used to iteratively refine the LLM's HDL generation. In essence, the HLS provides a 'ground truth' for functional behavior, acting as an oracle to correct the LLM's exploratory, PPA-driven designs. This approach combines the functional reliability of template-based synthesis with the flexible, potentially PPA-optimized generation capabilities of LLMs, much like a software developer using unit tests to guide refactoring towards a more efficient but still correct implementation."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n\u02dc _\ud835\udf05_ ;\n\nSimilar equation holds for the reverse path mapping,\n\u2211\ufe01 \u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01 (2 _\ud835\udc5a_ \u2212 vol( _Sub_\n\n\u2211\ufe01\n\n(2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ ))) _._\n\n_\ud835\udc62_ \u2260 _\ud835\udc5f_\n\n\u2211\ufe01 vol( _\ud835\udc47_ 1) = \u2211\ufe01\n\n_\ud835\udc47_ 1\u222a _\ud835\udc47_ 2 \u2208F [P\u2032] _[\ud835\udc62]_ ( _\ud835\udf0f_ ) ( _\ud835\udc5d_ ( _\ud835\udc63_ ) _,\ud835\udc63_\n\n( _\ud835\udc5d_ ( _\ud835\udc63_ ) _,\ud835\udc63_ ) \u2208 _\ud835\udf0f_ 0\n_\ud835\udc62_ \u2208 _\ud835\udc46_ 2\n\n                     \n\nThe pseudo-code of TTF is presented in Algorithm 1. Given a\ngraph _\ud835\udc3a_, a root node _\ud835\udc5f_, and a sample size _\ud835\udf14_, the algorithm begins\nby constructing a fixed spanning tree _\ud835\udf0f_ 0 using breadth-first search\n(BFS), followed by computing its DFN (Lines 2\u20133). An auxiliary\ndata structure vol_sum is initialized as a BIT of length | _\ud835\udc49_ | (Line\n4). It then samples _\ud835\udf14_ USTs using Wilson algorithm [48] (Line 6).\nFor each sampled UST _\ud835\udf0f\ud835\udc56_, the algorithm first computes the volume\nfor all subtrees (Lines 7\u20138), and then invokes the DFS function to\naccumulate contributions to the KC estimator (Line 9). Finally, the\nalgorithm returns \u02dc _\ud835\udf05_ /(2 _\ud835\udc5a_ - _\ud835\udf14_ ) as the approximation of KC (Line 10).\nThe core procedure DFS operates as follows. Let _\ud835\udc5d_ ( _\ud835\udc63_ ) denote\nthe parent node of the visited node _\ud835\udc63_ in _\ud835\udf0f_ . The algorithm checks\nwhether the edge ( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) exists in _\ud835\udf0f_ 0. If so, it increments vol_sum\nfor all nodes in the of _\ud835\udf0f_ 0 rooted at _\ud835\udc63_ by 2 _\ud835\udc5a_ \u2212 vol[ _\ud835\udc63_ ] (Lines 13\u201314).\nConversely, if the reverse edge ( _\ud835\udc5d_ ( _\ud835\udc63_ ) _, \ud835\udc63_ ) exists in _\ud835\udf0f_ 0, it decrements\nvol_sum for all nodes in _\ud835\udc46\ud835\udc62\ud835\udc4f_ ( _\ud835\udf0f_ 0 _, \ud835\udc5d_ ( _\ud835\udc63_ )) by 2 _\ud835\udc5a_ \u2212 vol[ _\ud835\udc63_ ] (Lines 15\u2013\n16). After these updates, the algorithm queries vol_sum[ _\ud835\udc63_ ] and\nincorporates its value into the KC estimation (Line 17). Then, it\nrecursively invokes DFS on each child node of _\ud835\udc63_ (Lines 18\u201319). Before returning from DFS, related changes made to vol_sum must be\n\nrevert to maintain correctness for subsequent computations (lines\n20-23).\n\n**Implementation Details.** We describe the key implementation\ndetails of our approach, including the traversal strategy and efficient\nmanagement of the auxiliary structure vol_sum.\n**1. Why Use DFS.** Based on Theorem 3.7, in principle, any traversal method can be used to visit all nodes. For each node _\ud835\udc63_, if\nthe edge ( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) connecting _\ud835\udc63_ to its parent also exists in the fixed\nspanning tree _\ud835\udf0f_ 0, we need to identify the intersection of the subtrees\nrooted at _\ud835\udc63_ in _\ud835\udf0f_ and _\ud835\udf0f_ 0, and update the vol_sum for these nodes by\n2 _\ud835\udc5a_ \u2212 vol( _Sub_ ( _\ud835\udf0f, \ud835\udc63_ )), or decrease it if the edge ( _\ud835\udc63, \ud835\udc5d_ ( _\ud835\udc63_ )) has opposite\ndirections in the two trees. Explicitly comparing subtrees to find\ntheir intersection is costly, with potential complexity _\ud835\udc42_ ( _\ud835\udc5b_ ), which\nmotivates the choice of DFS traversal. By using DFS, we can update\nthe vol_sum values for all nodes in the subtree of _\ud835\udc63_ in _\ud835\udf0f_ 0 without explicitly identifying intersection nodes. While this may temporarily\nupdate some nodes incorrectly, these nodes are not visited during\nthe DFS call for _\ud835\udc63_ in _\ud835\udf0f_, and restoring vol_sum after DFS ensures\ncorrectness when each node is visited.\n\n**2. Implementation of Auxiliary Structure vol_sum.** To efficiently implement these updates, we combine Depth-First Numbering (DFN) with Binary Index Tree (BIT, or Fenwick Tree [14]).\n_2.1 Depth-First Numbering._ DFN records the entry and exit times\nof each node during DFS traversal, denoted as DFSin and DFSout.\nWith this notation, the set of nodes in a subtree rooted at _\ud835\udc62_ can\nbe precisely characterized by the interval [DFSin [ _\ud835\udc62_ ] _,_ DFSout [ _\ud835\udc62_ ]].\nConsequently, updating all nodes within a subtree is equivalent\nto updating the nodes corresponding to a contiguous interval of\nDFN. For instance, as illustrated in Fig. 4, the first column shows\nthe entry and exit times of nodes _\ud835\udc63_ 2 _, \ud835\udc63_ 3 _,_ and _\ud835\udc63_ 4. The DFN of the tree\n_\ud835\udf0f_ 0 is _\ud835\udc63_ 1 \u2192 _\ud835\udc63_ 4 \u2192 _\ud835\udc63_ 2 \u2192 _\ud835\udc63_ 3. The subtree rooted at _\ud835\udc63_ 2 corresponds to\nthe interval [3 _,_ 4], which exactly covers the nodes _\ud835\udc63_ 2 and _\ud835\udc63_ 3.\n_2.2 Binary Index Tree._ For each visited node, two updates (lines 13\u2013\n16 and lines 20\u201323) and one query (line 17) are required. Standard\narrays allow _\ud835\udc42_ (1) queries but _\ud835\udc42_ ( _\ud835\udc5b_ ) updates, while difference arrays\nallow _\ud835\udc42_ (1) interval updates but _\ud835\udc42_ ( _\ud835\udc5b_ ) queries. The BIT makes a balance so that when storing a difference array using BIT, it supports\ninterval updates and point queries in _\ud835\udc42_ (log _\ud835\udc5b_ ) time:\n\n - _Add_ ( _\ud835\udc59,\ud835\udc5f, \ud835\udc63_ ): add value _\ud835\udc63_ to all elements in the range [ _\ud835\udc59,\ud835\udc5f_ ].\n\n - _Query_ ( _\ud835\udc56_ ): query the _\ud835\udc56_ -th element value.\n\nThis combination of DFS traversal, DFN ordering, and BIT enables\nefficient and correct maintenance of the vol_sum auxiliary structure\nthroughout the traversal process.\n\nExample 4. _Fig. 4 illustrates how_ DFS _and_ BIT _efficiently maintain_\nvol_sum _and compute \ud835\udc53_ ( _\ud835\udf0f_ ) _for sampled USTs. The first column shows_\n_the fixed tree \ud835\udf0f_ 0 _with its_ DFN _(_ 1 \u2212 4 \u2212 2 \u2212 3 _), the second column_\n_displays the sampled tree \ud835\udf0f_ _along with its subtree volumes._\n_Beginning the DFS from \ud835\udc63_ 4 _, we examine its outgoing edges_ ( _\ud835\udc63_ 4 _, \ud835\udc63_ 1)\n_and find it also appears in \ud835\udf0f_ 0 _. Using the_ BIT _, we efficiently update_\nvol_sum _by adding_ 2 _\ud835\udc5a_ \u2212vol[4] _to all nodes in subtree of \ud835\udc63_ 4 _in \ud835\udf0f_ 0 _, us-_\n_ing \ud835\udc42_ (log _\ud835\udc5b_ ) _time. After updating_ vol_sum _, we query_ vol_sum[ _\ud835\udc63_ 4] _,_\n_which corresponds to the second element in_ DFN _. Since_ vol_sum _is_\n_maintained as a differential array, the actual value is computed as a_\n_prefix sum using_ BIT _, also in \ud835\udc42_ (log _\ud835\udc5b_ ) _time._\n\nCheng Li, Meihao Liao, Rong-Hua Li, Guoren Wang\n\n```\n DFS\n\nSTACK\n\n```\n\n\ud835\udc97\ud835\udc97\ud835\udfd2\ud835\udfd2\n\n```\n DFS\n\nSTACK\n\n```\n\n\ud835\udc97\ud835\udc97\ud835\udfd1\ud835\udfd1\n\n\ud835\udc97\ud835\udc97\ud835\udfd2\ud835\udfd2\n\n```\n-(2m-vol[2])\n\n```\n\n```\nvol_sum\n\n```\n\n```\nvol_sum\n\n```\n\n```\n  f += d(4)\u00b7vol_sum[4] f += d(2)\u00b7vol_sum[2] f += d(3)\u00b7vol_sum[3]\n\n|DFSin[2]=3|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\u2460DFS(\ud835\udc97\ud835\udc97 \ud835\udfd2)<br>\ud835\udfd2|\u2461DFS(\ud835\udc97\ud835\udc97 \ud835\udfd0)<br>\ud835\udfd0<br>\ud835\udc97\ud835\udc97 \ud835\udfd0\ud835\udfd0 \ud835\udc93\ud835\udc93 SD TAF CS<br>\ud835\udc97\ud835\udfd0\ud835\udc97<br>\ud835\udfd0<br>\ud835\udc97\ud835\udc97 \ud835\udfd1\ud835\udfd1 \ud835\udc97\ud835\udc97 \ud835\udfd2\ud835\udfd2 \ud835\udc97\ud835\udfd2\ud835\udc97 \ud835\udfd2<br>+(2m-vol[2]<br>vol sum 0 1 6 0<br>_<br>DFN 1 4 2 3<br>f += d(2)\u00b7vol _sum[2|\n|---|---|---|---|---|---|---|---|---|---|\n|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|`DFSin[2]=3`|\n|`DFSout[2]=4`|`DFSout[2]=4`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol[4]=7`<br>`vol[3]=2`<br>`vol[2]=2`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol_sum`<br>**1**<br>**4**<br>**2**<br>**3**<br>**DFN**<br>`0`<br>`1`<br>`0`<br>`0`<br>`+(2m-vol[4])`<br>\ud835\udc97\ud835\udfd2<br>`DFS`<br>`STACK`<br>`f += d(4)\u00b7vol_sum[4]`|\ud835\udc93<br>\ud835\udc97\ud835\udfd2<br>\ud835\udc97\ud835\udfd1<br>\ud835\udc97\ud835\udfd0<br>`vol_sum`<br>**1**<br>**4**<br>**2**<br>**3**<br>**DFN**<br>`0`<br>`1`<br>`0`<br>`0`<br>`+(2m-vol[4])`<br>\ud835\udc97\ud835\udfd2<br>`DFS`<br>`STACK`<br>`f += d(4)\u00b7vol_sum[4]`|\n|`DFSout[2]=4`|`DFSout[2]=4`|`vol[3]=2`|`vol[3]=2`|`vol[4]=7`|`vol[4]=7`|`vol[4]=7`|`vol[4]=7`|`vol[4]=7`|`vol[4]=7`|\n|`DFSout[2]=4`|`DFSin[4]=2`|`DFSin[4]=2`|`DFSin[4]=2`|`DFSin[4]=2`|`DFSin[4]=2`|||||\n|`DFSout[2]=4`|`DFSout[4]=4`|`vol_sum`<br>**1**<br>**4**<br>**2**<br>**3**<br>**DFN**<br>`0`<br>`0`<br>`0`<br>`0`<br>`sampled tree`\ud835\udf49|`0`|`0`|`0`|`0`|`0`|`0`|`0`|\n\n```\n\n**Figure 4: Illustration of the DFS process**\n\n**DFN**"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is transforming subtree operations into efficient range operations on a linear array, then employing a specialized data structure (BIT) to perform these range updates and point queries quickly. This avoids computationally expensive explicit subtree intersection comparisons.\n\n**Explanation:** The TTF algorithm requires accumulating 'volume' contributions for subtrees within sampled Uniform Spanning Trees (USTs). A naive approach to compare subtrees and update values for intersecting nodes would be O(N) per operation. This is made efficient by a three-part synergy: 1. Depth-First Search (DFS): This traversal method naturally explores subtrees. By updating a `vol_sum` value for the entire subtree of a node `v` in a *fixed* reference tree (\ud835\udf0f0) whenever `v` is visited in a *sampled* tree (\ud835\udf0f), we avoid explicit subtree intersection logic. Temporary 'over-updates' are correctly reverted upon DFS backtracking. 2. Depth-First Numbering (DFN): Before any traversal, a pre-computed DFN assigns entry (`DFSin`) and exit (`DFSout`) times to each node in \ud835\udf0f0. This crucial step maps any subtree in \ud835\udf0f0 to a contiguous numerical interval `[DFSin[u], DFSout[u]]` on a flattened array. Now, operations on a subtree become operations on a range. 3. Binary Index Tree (BIT) / Fenwick Tree: This data structure is then used to manage the `vol_sum` array. When configured to store a difference array, the BIT efficiently supports both interval updates (adding a value to a range `[l, r]`) and point queries (getting the sum up to index `i`) in O(log N) time. Thus, each time the DFS needs to update a subtree's `vol_sum` or query a node's `vol_sum`, these operations are performed in O(log N) rather than O(N), making the overall algorithm far more scalable."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc50\ud835\udc5b\ud835\udc61_ _> \ud835\udc5a\ud835\udc4e\ud835\udc65_\ud835\udc50\ud835\udc5b\ud835\udc61_ **then** _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 _\ud835\udc5a\ud835\udc4e\ud835\udc65_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_\n\n**38** _\ud835\udc50\ud835\udc62\ud835\udc4f\ud835\udc56\ud835\udc50_ _ _\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc52\ud835\udc61_ () :\n**begin**\n\n**39** _\ud835\udc4a\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5a\ud835\udc4e\ud835\udc65_ \u2190\u2212 0 _, \ud835\udc52\ud835\udc5d\ud835\udc5c\ud835\udc50\u210e_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ \u2190\u2212 0 _, \ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b_ _ _\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61_ \u2190\u2212 0\n\n**40** _\ud835\udc51\ud835\udc40\ud835\udc56\ud835\udc5b_ \u2190\u2212 0 _, \ud835\udc4a\ud835\udc61\ud835\udc50\ud835\udc5d_ \u2190\u2212 0 _, \ud835\udc3e_ \u2190\u2212 0 _, \ud835\udc4e\ud835\udc50\ud835\udc58_ _ _\ud835\udc50\ud835\udc5b\ud835\udc61_ \u2190\u2212 0\n\nThe theoretical aspects of _Cubic_ congestion control algorithm are provided in 2.3.1.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 49\n\n**Algorithm 8:** Coupled (LIA) - Congestion Avoidance phase (AIMD)\n\n**Input:** Set of subflows: S, set of paths: R, _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S _, \ud835\udc56_ \u2208R _, \ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56, \ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59, \ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc56, \ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc56_\n\n**Output:** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_\n\n**1 for** _\ud835\udc60\ud835\udc53\ud835\udc56_ \u2208S **do**\n\n**On each ACK received on** _\ud835\udc60\ud835\udc53\ud835\udc56_ :\n\n**2** _\ud835\udefc_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ \u2217 _\ud835\udc5a\ud835\udc4e\ud835\udc65_ ( _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ / _\ud835\udc45\ud835\udc47\ud835\udc47\ud835\udc56_ [2] [)]\n( ~~[\ufffd]~~ _\ud835\udc56_ [(] _[\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51]_ _\ud835\udc56_ [/] _[\ud835\udc45\ud835\udc47\ud835\udc47]_ _\ud835\udc56_ [))][2]\n\n**3** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ \u2190\u2212 _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ + min( _[\ud835\udefc]_ [\u2217] _[\ud835\udc4f][\ud835\udc66][\ud835\udc61\ud835\udc52\ud835\udc60]_ [_] _[\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc51]_ [\u2217] _[\ud835\udc40\ud835\udc46\ud835\udc46][\ud835\udc56]_\n\n_\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ _[\ud835\udc56]_ )\n\n_[\ud835\udc61\ud835\udc52\ud835\udc60]_ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ [_] _[\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc51]_ _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ [\u2217] _[\ud835\udc40\ud835\udc46\ud835\udc46][\ud835\udc56]_ _,_ _[\ud835\udc4f][\ud835\udc66][\ud835\udc61\ud835\udc52\ud835\udc60]_ [_] _[\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc51]_ _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ [\u2217] _[\ud835\udc40\ud835\udc46\ud835\udc46][\ud835\udc56]_\n\n/* in the above min(A, B) computation, A:\n\ndenotes the computed increase of the\n\nmultipath subflow, B: denotes the increase\n\nTCP would get on the same path i */\n\n**On packet loss event on** _\ud835\udc60\ud835\udc53\ud835\udc56_ :\n\n**4** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_ \u2190\u2212 _[\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51]_ 2 _[\ud835\udc56]_\n\n**5** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60\ud835\udc5a\ud835\udc56\ud835\udc61_ (); /* legacy TCP NewReno */\n\n**6** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_ ();\n\n**7 return** _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51\ud835\udc56_\n\nThe theoretical aspects of _Coupled (LIA)_ congestion control algorithm are provided in 2.3.2.\n\n**Algorithm 9:** Opportunistic Linked-Increases Algorithm (OLIA) - Congestion Avoidance phase (AIMD)\n\n**Input:**\n\nset of paths available to user u: _\ud835\udc45\ud835\udc62_, _\ud835\udc5f_ \u2208 _\ud835\udc45\ud835\udc62_ /* _\ud835\udc45\ud835\udc62_ : the set of **all_paths**, | _\ud835\udc45\ud835\udc62_ |: the number\n\nof paths available to user _\ud835\udc62_ at time _\ud835\udc61_ */\n\nset of paths with the largest window sizes: M, /* M: the set of **max_w_paths** of user _\ud835\udc62_ at\n\ntime _\ud835\udc61_, |M|: the number of paths in M */\n\nset of presumably best paths: B, /* B: the set of presumably **best_paths** for\n\nuser _\ud835\udc62_ at time _\ud835\udc61_, |B|: the number of paths\n\nin B */\n\nset of collected paths: B\\M, /* B\\M: the set of **collected_paths** for user\n\n_\ud835\udc62_ at time _\ud835\udc61_ \u2013 all paths belonging to\n\nbest_paths, but not among those with\n\nlargest _\ud835\udc50\ud835\udc64\ud835\udc5b\ud835\udc51_ */\n\ncongestion window of path _\ud835\udc5f_ : _\ud835\udc64\ud835\udc5f_\n\nround-trip time of path _\ud835\udc5f_ : _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_\n\na subflow established over path _\ud835\udc5f_ : _\ud835\udc60\ud835\udc53\ud835\udc5f_\n\nset of subflows established: _\ud835\udc46_, where _\ud835\udc60\ud835\udc53\ud835\udc5f_ \u2208 _\ud835\udc46_\n\n50 D. Dimopoulos, et al.\n\n**Output:** _\ud835\udc64\ud835\udc5f_\n\n**1 for** _\ud835\udc60\ud835\udc53\ud835\udc5f_ \u2208 _\ud835\udc46_ **do**\n\n**On each ACK received on** _\ud835\udc60\ud835\udc53\ud835\udc5f_ :\n\n/* calculate the increase parameter _\ud835\udc4e\ud835\udc5f_ //\n\nalso note that _\ud835\udc4e\ud835\udc5f_ = 0 */\n\u2211\ufe01\n\n_\ud835\udc5f_ \u2208 _\ud835\udc45\ud835\udc62_\n\n/* window increase measured in packets //\nmultiply by ( _\ud835\udc40\ud835\udc46\ud835\udc46\ud835\udc5f_ \u2217 _\ud835\udc4f\ud835\udc66\ud835\udc61\ud835\udc52\ud835\udc60_ _ _\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc52\ud835\udc51_ ) to measure\nin bytes */\n\n|B\\M|1/| _\ud835\udc45\ud835\udc62_ | _[,]_ if _\ud835\udc5f_ \u2208B\\M \u2260 \u2205\n\n\u2212 [1][/|] |M| _[\ud835\udc45][\ud835\udc62]_ [|] _[,]_ if _\ud835\udc5f_ \u2208M and B\\M \u2260 \u2205\n\n0 _,_ otherwise.\n\n**2** _\ud835\udc4e\ud835\udc5f_ =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\n2 [+] _[\ud835\udc4e][\ud835\udc5f]_\n\n**3** _\ud835\udc64\ud835\udc5f_ \u2190\u2212 _\ud835\udc64\ud835\udc5f_ +\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\n\n\ufffd\ufffd\ufffd\n\ufffd\n\n\ufffd\ufffd\ufffd \u2211\ufe01 _\ud835\udc64\ud835\udc5d_ / _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5d_ \ufffd\ufffd\ufffd\n\ufffd _\ud835\udc5d_ \u2208 _\ud835\udc45\ud835\udc62_ \ufffd\n\n_\ud835\udc64\ud835\udc5f_ / _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_ [2]\n\n_\ud835\udc64\ud835\udc5f_\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\n\n\u2211\ufe01\n\n**On packet loss event on** _\ud835\udc60\ud835\udc53\ud835\udc5f_ :\n\n**4** _\ud835\udc64\ud835\udc5f_ \u2190\u2212 _[\ud835\udc64]_ 2 _[\ud835\udc5f]_\n\n**5** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60\ud835\udc5a\ud835\udc56\ud835\udc61_ (); /* legacy TCP NewReno */\n\n**6** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_ ();\n\n**7 return** _\ud835\udc64\ud835\udc5f_\n\nThe theoretical aspects of _OLIA_ congestion control algorithm are provided in 2.3.3.\n\n**Algorithm 10:** Balanced Linked Adaptation (BALIA) - Congestion Avoidance phase (AIMD)\n\n**Input:**\n\nset of available paths: _\ud835\udc45_, _\ud835\udc5f_ \u2208 _\ud835\udc45_\n\ncongestion window of path _\ud835\udc5f_ : _\ud835\udc64\ud835\udc5f_\n\nround-trip time of path _\ud835\udc5f_ : _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_\n\na subflow established over path _\ud835\udc5f_ : _\ud835\udc60\ud835\udc53\ud835\udc5f_\n\nset of subflows established: _\ud835\udc46_, where _\ud835\udc60\ud835\udc53\ud835\udc5f_ \u2208 _\ud835\udc46_\n\n**Output:** _\ud835\udc64\ud835\udc5f_\n\n**1 for** _\ud835\udc60\ud835\udc53\ud835\udc5f_ \u2208 _\ud835\udc46_ **do**\n\n**On each ACK received on** _\ud835\udc60\ud835\udc53\ud835\udc5f_ :\n\n**2** _\ud835\udc4e\ud835\udc5f_ \u2254 [max] _\ud835\udc65_ [{] _\ud835\udc5f_ _[\ud835\udc65][\ud835\udc58]_ [}] /* calculate the increase parameter _\ud835\udc65\ud835\udc5f_ \u2254 _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc64\ud835\udc5f\ud835\udc5f_ [// also note that in case of] _\ud835\udc4e\ud835\udc5f_ //\n\nsingle path _\ud835\udc4e\ud835\udc5f_ = 1 */\n\n**3** _\ud835\udc64\ud835\udc5f_ \u2190\u2212 _\ud835\udc64\ud835\udc5f_ + _\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5f_ ( _\ud835\udc65_ ~~[\ufffd]~~ _\ud835\udc5f_ _\ud835\udc65\ud835\udc58_ ) [2] \ufffd 1 +2 _\ud835\udc4e\ud835\udc5f_\n\n_\ud835\udc4e\ud835\udc5f_ 4 + _\ud835\udc4e\ud835\udc5f_\n\n2 \ufffd\ufffd 5\n\n_\ud835\udc4e\ud835\udc5f_\n\n5 \ufffd\n\n**On packet loss event on** _\ud835\udc60\ud835\udc53\ud835\udc5f_ :\n\n**4** _\ud835\udc64\ud835\udc5f_ \u2190\u2212 _\ud835\udc64\ud835\udc5f_ \u2212 _[\ud835\udc64]_ 2 _[\ud835\udc5f]_ [min][{] _[\ud835\udc4e][\ud835\udc5f]_ _[,]_ [ 1] _[.]_ [5][}]\n\n**5** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60\ud835\udc5a\ud835\udc56\ud835\udc61_ (); /* legacy TCP NewReno */\n\n**6** _\ud835\udc53\ud835\udc4e\ud835\udc60\ud835\udc61_ _ _\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc66_ ();\n\n**7 return** _\ud835\udc64\ud835\udc5f_\n\nThe theoretical aspects of _BALIA_ congestion control algorithm are provided in 2.3.4.\n\nEvaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over\nHeterogeneous Networks 51\n\n**Algorithm 11:** Weighted Vegas (wVegas)\n\n**1 Initialization:**\n\n**3** _\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59_ _ _\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e_ \u2190 10 ; /* namely _\ud835\udefc\ud835\udc60_ : preconfigured parameter coupling subflows of flow _\ud835\udc60_ */"}, {"role": "assistant", "content": "**Mechanism:** These algorithms implement variations of the Additive Increase, Multiplicative Decrease (AIMD) control loop, specifically adapted for Multipath TCP (MPTCP). The core mechanism is to adjust the 'congestion window' (cwnd or wr) for each individual subflow (path) based on network feedback, primarily successful acknowledgements (ACKs) and packet loss events.\n\n**Explanation:** At its heart, each algorithm is an iterative loop, like a `for` loop in programming, that processes each subflow when an ACK is received or a packet is lost. When an ACK arrives for a subflow, the algorithm attempts to 'additively increase' its `cwnd`. This increase isn't uniform: Coupled LIA links the increase to the overall flow's `cwnd_total` and the subflow's throughput ratio (`cwnd_i / RTT_i`), using a `min` function to prevent excessive individual growth. OLIA introduces a more complex, conditional 'increase parameter' (`ar`) that dynamically weights paths based on categories like 'max_w_paths' (paths with largest windows) or 'best_paths', often giving negative weighting to already large windows to encourage balancing, before applying a window increase proportional to `wr / rtt_r` across all paths. BALIA uses a `max` function to calculate its `ar` (representing a path's 'goodness' based on `wr/rttr`) and applies a more elaborate formula for window increase. Upon packet loss, the `cwnd` is 'multiplicatively decreased', usually by halving it (`cwnd_i / 2` or `wr / 2`). However, BALIA implements a more nuanced decrease, reducing `wr` by `wr/2 * min(ar, 1.5)`, meaning the reduction is also modulated by the path's 'goodness'. The `wVegas` reference implies an RTT-based congestion control, which proactively adjusts `cwnd` based on estimated network capacity changes rather than solely reacting to loss, potentially reducing latency and preventing losses in the first place, using parameters like `alpha` to control aggressiveness. These `cwnd` values are essentially state variables (like fields in a struct) for each subflow, updated on an event-driven basis."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52_ ! = _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52\ud835\udc45\ud835\udc47\ud835\udc47_ **and** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5f\ud835\udc61\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc56\ud835\udc5f\ud835\udc52\ud835\udc51_ **and not** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc56\ud835\udc51\ud835\udc59\ud835\udc52_\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc61_ **then**\n\n**98** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc38\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f_ _ _\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc45\ud835\udc47\ud835\udc47_ () ;\n\n**99** _\ud835\udc35\ud835\udc35\ud835\udc45_ _ _\ud835\udc46\ud835\udc4e\ud835\udc63\ud835\udc52_ _ _\ud835\udc36\ud835\udc64\ud835\udc5b\ud835\udc51_ () ;\n\n**100** _\ud835\udc35\ud835\udc35\ud835\udc45.\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc52_ _ _\ud835\udc5f\ud835\udc61\ud835\udc61_ _ _\ud835\udc51\ud835\udc5c\ud835\udc5b\ud835\udc52_ _ _\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d_ = 0 ;"}, {"role": "assistant", "content": "**Mechanism:** This segment describes the logical entry point for BBR to perform a periodic 'Round Trip Time' (RTT) re-evaluation. To accurately measure the network's minimum propagation delay (min_rtt), BBR must intentionally reduce its sending rate to drain any existing network queues, which is achieved by entering the 'ProbeRTT' state.\n\n**Explanation:** The conditional statement acts as a gatekeeper. First, it ensures BBR is not already in the `ProbeRTT` state (a simple boolean flag check). Second, it verifies that the current `rtprop` (round-trip propagation time) estimate has 'expired', meaning it's been a set amount of time since the last good measurement, signaling a need for an update (a timer check). Third, it prevents this probing from happening right after the connection restarts from being idle, as idle periods often naturally yield low RTTs that don't require an active probe. If all conditions are met, BBR transitions into the `ProbeRTT` state (like calling a `setState()` method), saves its current congestion window (like pushing a value onto a stack) so it can restore it later, and resets a timestamp to indicate a new probe RTT measurement is beginning (a flag reset)."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**6.1** **Experimental Setup**\n\n**Implementation** . We implement TLT on top of VeRL [53]\nand utilizes Ray [37] for distributed execution. The Worker\nCoordinator is realized with a centralized controller that\n\nemploys ZeroMQ [17] messaging. The Adaptive Drafter\u2019s\nimplementation is based on training pipelines from EAGLE\nand trained with FSDP2 [44]. For asynchronous checkpointing, we leverage PyTorch DCP [45]. To further improve generation efficiency, we employ SGLang [70] as the rollout\nbackend, with implementing adaptive enabling of SD, drafter\nweight update and the BEG-MAB tuner following [55]. We\nadditionally use [68] as our model-free drafter.\n**Testbed** . We conduct experiments on a cluster of 8 NVIDIA\nDGX H100 [39] servers, totaling 64 GPUs. Each server is\nequipped with 8 NVIDIA H100 GPUs, 2 Intel Xeon Platinum\n8480C (112 cores) CPUs and 2TB memory. GPUs are interconnected to each other by 900GB/s NVLink, and inter-node\ncommunication is achieved via NVIDIA Mellanox 400Gb/s\nInfiniBand. To evaluate system\u2019s performance across heterogeneous hardware, we also conduct experiments on a\ndifferent cluster equipped with NVIDIA DGX A100 servers.\nUnless otherwise specified, experiments are conducted on\nH100 GPUs by default.\n**Models** . Following the training procedure introduced in\nDeepSeek-R1 [9], the reasoning RL process can begin either from a fine-tuned model or directly from a base model\nwithout additional fine-tuning. To demonstrate that TLT robustly accommodates different model architectures, scales,\nand training paradigms, we evaluate the following models:\n\n(1) _Qwen2.5-7B_ (Qwen2.5-7B): a popular base model;\n(2) _DeepSeek-R1-Distill-Qwen-7B_ (DeepSeek-7B): a distilled\nmodel exhibiting good initial reasoning capabilities;\n(3) _Qwen2.5-32B_ (Qwen-32B): a larger base model without\nany additional fine-tuning, as in [66];\n(4) _Llama-3.3-70B-Instruct_ (Llama-70B): a larger instructiontuned model to assess scalability.\n**Datasets** . For the primary RL training dataset, we use a\nsubset from Eurus-2-RL [8], a comprehensive dataset curated\nfor reasoning RL. This dataset contains mathematics and\ncoding problems equipped with verifiers (LaTeX answers and\n\ntest cases, respectively). The coding problems originate from\ncompetitive programming sources (e.g., CodeContests [23],\nCodeforces [7]), while the math problems range from high\nschool to olympiad-level difficulty [24]. For drafter training,\nwe use a subset from OpenThoughts2-1M [41] as the warmup dataset.\n**RL Settings** . We primarily follow the reasoning RL algorithm GRPO proposed by DeepSeek [9, 51]. Specifically, for\neach prompt, we set the temperature=0.9, with a maximum\ngeneration length of 32K tokens, consistent with common RL\ntraining settings. We apply TP= 2, 4, or 8 depending on model\nscale for the rollout engine. Additionally, all experiments utilize mixed-precision training with the Adam optimizer [19],\nwhere BF16 precision is employed during both model rollout\nand inference stages.\n**Baselines** . We consider the following baselines.\n\n(1) _Open-R1_ [10]: a popular RL training framework built\nupon TRL[59], integrating vLLM [21] for rollouts and\nDeepSpeed [47] for training. Currently, it only supports\nseparate model placement, requiring serving and training to be performed on distinct nodes.\n(2) _VeRL_ [53]: the state-of-the-art open-source RL training\nframework by ByteDance. It enables colocation of models on shared devices by utilizing GPU time-sharing.\n(3) _TLT-Base_ : Our base implementation with vanilla speculative decoding support. Specifically, we disable adaptive drafter and use the model-free drafter instead.\n\n**Metrics** . Following [53], we use token throughput (tokens/sec)\nfor end-to-end evaluation. This metric is calculated by dividing the total number of tokens in both prompts and responses\nwithin a global batch by the duration of a single RL step. We\naverage results over three training steps following an initial\nwarm-up step and use a trained draft model for evaluation.\n\n**6.2** **End-to-End Evaluation**\n\nWe evaluate TLT against popular RL training frameworks,\nincluding Open-R1 [10] and VeRL [53], across multiple GPU\nplatforms (NVIDIA H100 and A100) and various LLM scales.\nFigure 11 demonstrates that TLT consistently outperforms\nVeRL. Open-R1 consistently underperforms, primarily because it struggles to fully utilize all available GPUs concurrently and suffers from a tight coupling between its rollout\nand training batch size. Similar substantial gains are observed\non the A100 platform, highlighting its effectiveness across\ndifferent hardware generations. We also present results for\nTLT-Base, which utilizes a model-free drafter and yields good\nbenefits, demonstrating that the TLT framework provides\ncontinuous efficiency gains throughout the entire training\nprocess. These end-to-end performance gains stem directly\nfrom TLT\u2019s ability to mitigate the long-tail rollout bottleneck\nof reasoning RL training.\nMoreover, Figure 12 illustrates the average reward curves\nduring RL training for both VeRL and TLT using Qwen2.57B and Qwen2.5-32B models. It is evident that two curves\n\n9\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-0.png)\n\n**Figure 11. End-to-end Training Speed Evaluation.** The y-axis indicates the relative training throughput of each system\nrunning GRPO [51] RL algorithm. TLT achieves 1.7-2.1\u00d7 speedup over the state-of-the-art RL training system VeRL [53].\n\n0.6\n\n0.5\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-1.png)\n\n0.4\n\n0.3\n\n0.2\n\n20 40 60 80 100\nRL Step\n\n20 40 60 80 100\nRL Step\n\n**Figure 12. End-to-end Training Curves.** Average reward curves for VeRL and TLT using the Qwen2.5 7B and 32B models.\n\n**Table 1. Effect of topK for speculative decoding.** Results\nare benchmarked using Qwen-32B on H100 GPUs (TP=4),\nwith Draft_Depth=12 and Tokens_to_Verify=64.\n\nTopK 4 6 8 10 12 16\n\nAccept Length 8.29 8.66 8.67 8.67 8.60 8.42\n\nSpeedup 3.51\u00d7 **3.65** \u00d7 3.64\u00d7 3.64\u00d7 3.56\u00d7 3.47\u00d7\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-2.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-4.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-9-3.png)\n\n**Figure 13. Effect of hyperparameters for speculative**\n**decoding.** Measurements performed with Qwen-32B (TP=4).\n\noverlap closely, indicating that TLT preserves model quality.\nThis confirms that TLT\u2019s adaptive drafter and rollout engine\neffectively accelerate training without compromising the\nlearning dynamics of the underlying RL algorithm.\n\n**6.3** **Evaluation of Adaptive SD**\n\nIn this section, we provide in-depth analysis on the effectiveness of our design for adaptive speculative decoding.\n**Effect of Adaptive SD Strategy** . Tuning the SD configuration is crucial for achieving optimal speedups. Figure 13\nillustrates how Draft_Depth and Tokens_to_Verify influence speculative decoding performance with batch size = 1,\ntopK=8 and CUDA Graph enabled. For more stable accept\nlength in the grid search, we set temperature=0. Increasing\nthe draft depth generally raises the average accept length\n(a), though this benefit tapers off once the draft depth becomes sufficiently large. (b) reports the resulting speedups\nover the non-speculative baseline. This demonstrates that\n\nmaximizing accept length alone is insufficient; drafting parameters must be tuned to optimize real performance rather\nthan intermediate metrics.\n\nRegarding topK, we find that efficiency is relatively insensitive to the value used during drafting (Table 1). To balance\noverall efficiency with framework simplicity, we fix this hyperparameter for our MAB auto-tuner.\nMoreover, the optimal configurations for speculative decoding also vary with input batch size (Table 2). Although\nthe speedup decreases as batch size grows, the model still\nbenefits substantially from SD even at batch size 32. Another\nkey observation is that Tokens_to_Verify should be adjusted based on the batch size: larger batches achieve optimal\nperformance when fewer tokens are verified. These findings\nfurther demonstrate the effectiveness of our BEG MAB Selec\ntor in identifying appropriate configurations across dynamic\nrunning request numbers.\n**Case Study for Adaptive SD** . Figure 14 presents a case\nstudy of the rollout profile during an RL step with 128 requests using Qwen-32B on H100 GPUs. Instead of consistently applying SD throughout the entire rollout process,\nleading to potential slowdown during the early phase when\n\n10\n\n**Table 2. Effect of batch sizes on speculative decoding.**\nSpeedup numbers are benchmarked using Qwen-32B on\nH100 GPUs (TP=4), with Draft_Depth=10 and topK=8.\n\n**# Tokens to Verify**\n**Speedup**\n\n16 32 48 64\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-10-1.png)\n\nBatch Size = 1 3.22\u00d7 3.46\u00d7 3.56\u00d7 **3.62** \u00d7\n\n|Col1|Col2|Col3|\n|---|---|---|\n||Baseline<br>||\n||Rollout Ends<br>~~Adaptive SD (Ours)~~||\n||||\n|138<br>337<br>~~**SD starts**~~|138<br>337<br>~~**SD starts**~~|138<br>337<br>~~**SD starts**~~|\n||||\n\n**Figure 14. Rollout running-request profiling.** Example\nof processing 128 requests with and without adaptive decoding using Qwen-32B (TP=4).\n\nthe number of running requests is high, TLT switches to SD\nonly when the number of remaining requests drops below a\nthreshold (default 32), where SD becomes beneficial. Within\nthese SD-enabled regions, TLT further dynamically adapts\nSD configurations based on the current request count to\nmaximize throughput. Overall, TLT delivers a 2.44\u00d7 speedup\nover the baseline system without speculative decoding.\n**Bucketed CUDAGraph Capturing** . Preparing CUDAGraph\nfor multiple SD strategies can be memory-intensive. As\nshown in Table 3, naively capturing a separate graph for\neach of the four candidate strategies inflates memory usage from 7.81 GB to 30.39 GB. Our Bucketed CUDAGraph\ndesign addresses this problem by reducing graph memory\nconsumption to just 10.69 GB, a 2.8\u00d7 reduction compared\nto the naive method and only a marginal increase over the\nsingle static strategy, allowing the adaptive tuner to flexibly\nswitch between SD configurations for maximized efficiency.\n\n**6.4** **Evaluation of Spot Trainer**\n\n**Training Adaptive Drafter** . Figure 15 presents an example\ntraining curve illustrating the adaptive drafter\u2019s training\nprocess. After initial warm-up, the drafter\u2019s top-3 next-token\nprediction accuracy increases significantly. When the target\nmodel is updated after an RL step, the drafter\u2019s accuracy\ntemporarily dips due to the distribution shift caused by the\nupdate. However, this accuracy is rapidly recovered within\na few subsequent drafter training iterations, demonstrating\nthe effectiveness and robustness of our adaptive method.\n\n**Table 3. Bucketed CUDAGraph reduces memory foot-**\n**print.** Numbers measured using Llama-3-8B on H100 GPUs\n(TP=4). Search space includes 4 different strategies.\n\n**Method** **Memory Footprint**\n\nSingle Strategy 7.81 GB\n\n100\n\n# Drafter Training Steps\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy||\n|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy|Draft Model Accuracy|\n||Target Model Training Step<br>Target Model Update|||\n|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|2K<br>4K<br>6K<br>8K<br>10K<br>12K<br>14K<br>|\n\n**Figure 15. Accuracy of the draft model during adaptive**\n**training.** The adaptive drafter\u2019s top-3 accuracy shows a\nconsistent upward trend. While target model updates cause\nminor dips, the drafter quickly adapts and recovers.\n\n**Effectiveness of Adaptive Drafter** . Table 4 highlights the\neffectiveness of adaptively training the draft model. With\nthis adaptive training mechanism, TLT consistently achieves\nhigher average accept lengths for the Target-R model across\nboth RL- ~~trainin~~ g tasks and downstream evaluations, demonstrating improved alignment and performance.\nFigure 16 further corroborates this finding, which shows\nthe acceptance probability at different token positions within\nthe drafted sequence. Due to the output distribution shift of\nthe target model and error accumulation, the vanilla draft\nmodel struggles to accurately predict tokens several steps\nahead, severely limiting the effective accept length. The adaptive drafter, however, sustains higher acceptance probabilities across these positions, showcasing its ability to mitigate\nevolving target model and maintain longer accept lengths.\n**Efficient Spot Trainer** . Spot Trainer achieves preemptible,\nhigh-throughput training with negligible runtime overheads.\nAmong its optimizations, Selective Asynchronous Checkpointing (Figure 17 (a)) facilitates the trainer\u2019s preemptible\ndesign without significant work loss. Compared to the vanilla\nsynchronous design, our approach reduces the checkpointing latency by 9.2 \u00d7 through both offloading the save process\nto a background thread and selectively dumping only the\ntrainable parameters of the draft model. Figure 17 (b) demonstrates the effectiveness of sequence packing. This technique\neliminates wasteful computation on padding tokens by concatenating variable-length sequences, improving training\nthroughput by 2.2\u00d7 over vanilla batching.\n**System Overhead Analysis** . We identify three primary\nsources of overhead in TLT: (1) Stage-transition overhead,\nintroduced by additional the drafter-weight update and optimizer offloading compared to VeRL [53]. This accounts for\nless than 1% of the RL-step duration due to the much smaller\n\n11\n\n**Table 4. Effectiveness of Adaptive Drafter.** Adaptive\ndrafter maintains alignment with the target model. TargetBase denotes Qwen2.5-7B; and Target-R denotes the model\nafter RL. Downstream indicates the collection of math, coding and reasoning domains in MTBench [69].\n\n**RL Training** **Downstream**\n\nTarget-Base Target-R Target-Base Target-R\n\nAccept Length 4.59 6.53 3.76 5.15\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-0.png)\n\n|280|ms|893|ms<br>32|Col5|Col6|\n|---|---|---|---|---|---|\n|**280**|**ms**||**92**<br>**.x**|||\n||||**.x**|||\n\n|893|ms|22x|Col4|\n|---|---|---|---|\n|** sam**|** ples/sec**|**.**||\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-2.png)\n\n![](papers/images/Taming-the-LongTail-Efficient-Reasoning-RL-Training-with-Adaptive-Drafter.pdf-11-1.png)\n\n**Figure 16. Token accept rate of different draft models** .\nOur adaptive draft model achieves prominently higher accept\nrate when predicting distant tokens in rollout scenario.\n\nmodel size. (2) SD switch overhead, incurred when switching from normal decoding to SD. Because the draft model is\ninitially inactive for large batch sizes, we perform a reprefill step to activate SD, which completes within 3 seconds.\n(3) Drafter-training coordination overhead, caused by occasional contention during spot-trainer execution. However,\nwe find that it is unnecessary to train the drafter every RL\nstep, performing once every 10 steps is sufficient to maintain accuracy. Overall, the performance gains of TLT far\noutweigh this overhead, yielding end-to-end speedups."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism for accelerating AI training is a predictive 'speculative decoding' pipeline, where a smaller, faster 'drafter' model generates a sequence of speculative tokens. The main, larger 'target' model then simultaneously verifies these 'drafted' tokens. If a token matches the target model's prediction, it's accepted. If not, the target model's output is used, and the subsequent draft tokens are discarded. This operates like a highly effective cache: successful draft predictions (cache hits) allow multiple tokens to be processed in a single main model forward pass, reducing the number of expensive target model inferences. The 'adaptive drafter' mechanism introduces a feedback loop: the drafter model is continually retrained on the target model's actual outputs. This mitigates 'distribution shift', ensuring the drafter's predictions remain relevant as the target model evolves, which is crucial for maintaining high 'accept length' (number of correctly predicted tokens) and thus high efficiency. Furthermore, efficient GPU utilization is achieved through 'Bucketed CUDAGraph Capturing', which pre-compiles GPU kernel sequences for various common input shapes. This is akin to having a library of pre-optimized functions for different data structures, which reduces CPU overhead and memory footprint compared to dynamic execution or compiling for every unique shape, allowing flexible switching between speculative decoding strategies.\n\n**Explanation:** The system speeds up training large AI models by having a fast, smaller AI (the 'drafter') make educated guesses about the next few words. The main AI then quickly checks these guesses. Instead of the main AI thinking hard for every single word, it just checks a whole bunch of words guessed by the drafter at once. If the guesses are good, the main AI accepts them quickly and moves on. If not, it corrects them. This is efficient because checking is much faster than thinking up words from scratch. The clever part is that the drafter isn't static; it constantly learns from the main AI's actual outputs, like a student learning from a teacher. This ensures the drafter's guesses stay relevant even as the main AI itself gets smarter. To make the computer hardware run even smoother, especially the GPU, they pre-package common computational tasks. This is like pre-compiling frequently used functions or setting up efficient data processing pipelines in advance, so the computer doesn't have to figure it out every time, which saves processing power and memory. This combination of intelligent guessing, continuous learning for the guesser, and optimized hardware usage makes the entire AI training process much faster without sacrificing the quality of what the AI learns."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n_j \u2208_ `UndecidedNeighbors` _which broadcasted_ opp( _j_ ) = _i in previous round_\n**do**\n\n**5** Draw a random _c_ log _n_ bit _ri\u2192j \u2208{_ 0 _,_ 1 _}_ _[c]_ [ log] _[ n]_ uniformly at random and broadcast\nsigned message ( `iteration` `number` _, i, j, ri\u2192j_ ) to all neighbors;\n\n**6 foreach** _j \u2208_ `UndecidedNeighbors` _that did not broadcast an opponent in Round 1_ **do**\n\n**7** Node _i_ sets _Rj \u2190{_ 1 _}_ _[c]_ [ log] _[ n]_ and `BeenCheated` _\u2190_ true; `/* as` _j_ `deviated */`\n\n**Algorithm 6:** Forward Opponent\u2019s random input\n\n**1 if** _i broadcasted ID of_ opp( _i_ ) _as its opponent in Round 1_ **then**"}, {"role": "assistant", "content": "**Mechanism:** Commitment checking and cryptographic nonce generation.\n\n**Explanation:** This mechanism enforces a commitment from participating nodes and generates unique cryptographic seeds. When node 'i' is ready to engage with a neighbor 'j', it first checks if 'i' itself has already committed to an opponent. If 'i' played by the rules, it then generates a random bit string, 'ri\u2192j', for its neighbor 'j'. This 'ri\u2192j' acts as a unique, unguessable 'nonce' for this specific interaction, ensuring unpredictability and preventing replay attacks or pre-computation. The length 'c log n' bits guarantees a very low probability of collision in a network of size 'n', similar to how a strong hash function works. Crucially, node 'i' then iterates through its 'UndecidedNeighbors'. If a neighbor 'j' *still* hasn't declared an opponent from the first round, 'i' flags 'j' as having 'deviated' or 'cheated'. This acts as an early-warning system: if 'j' isn't following the protocol by declaring its opponent, 'i' stops processing for 'j' and marks it as untrustworthy, preventing further resource expenditure or potential exploits. It's akin to a network protocol's handshake where if one party fails to send a required SYN/ACK, the connection is dropped."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nEvolution Strategies (ES) (Rechenberg, 1978; Beyer, 1995; Beyer & Schwefel, 2002) are an attractive\nalternative to first-order methods based on gradient backpropagation, for several reasons. First, ES does not\nrequire differentiability, so it can optimise a broader class of models, like models with discrete parametrisation\nspaces (cellular automata), and can optimize objectives where gradients are unavailable or noisy, like outcomeonly rewards in LLM fine-tuning (Qiu et al., 2025). Second, ES is more robust to noisy and ill-conditioned\noptimisation landscapes (Wierstra et al., 2011; Xue et al., 2021). Unlike gradients, population-based exploration\nsmooths irregularities (Salimans et al., 2017), tolerates discontinuities, and mitigates issues like ill-conditioned\ncurvature or vanishing and exploding gradients in long-range or recurrent settings (Hansen, 2023). Third,\nES is highly amenable to scaling through parallelisation, since fitness evaluations are independent across\npopulation members and require only the communication of scalar fitnesses, which maps cleanly onto modern\ninference infrastructure and yields near-linear speedups on large clusters (Salimans et al., 2017). By contrast,\nbackpropagation requires communicating and aggregating gradients across devices, yielding updates with high\nmemory and computation costs. Additionally, backpropagation requires special care when training models\nwith low-precision datatypes, whereas ES can directly optimize any model with the same datatypes used\nat inference time. Together, these properties position ES as a potentially powerful foundation for training\nlarge, discrete, or hybrid architectures, and end-to-end systems with non-differentiable components, including\nlarge language models (LLMs) (Brown et al., 2020; Chowdhery et al., 2023; Du et al., 2022; Fedus et al.,\n2022).\n\nDespite this potential, there are practical obstacles to employing ES at scale. In deep learning architectures\n(Goodfellow et al., 2016), the majority of trainable parameters form linear mappings represented by matrices\n(Rosenblatt, 1962; Hochreiter & Schmidhuber, 1996; Bengio et al., 2000; Krizhevsky et al., 2012; Goodfellow\net al., 2014; Kingma & Welling, 2014; Vaswani et al., 2017); na\u00efvely adapting ES therefore requires generating\nfull-rank matrix perturbations that replicate the entire parameter set for every population member. This inflates\nmemory costs and forces frequent movement of large weight tensors. Evaluating these perturbations then\nrequires a separate sequence of matrix multiplications per member, so the total compute and wall-clock\ntime scale roughly with the population size and sequence length. In billion-parameter regimes, these two\ncosts dominate, making it difficult to scale ES beyond small models or small populations (Qiu et al., 2025;\nKorotyshova et al., 2025).\n\nTo mitigate both memory and computational bottlenecks, we introduce Evolution Guided General Optimization\nvia Low-rank Learning (EGGROLL), an ES algorithm that allows for the efficient training of neural network\narchitectures with billions of parameters. Analogous to LoRA\u2019s low-rank adapters in gradient-based training\n(Hu et al., 2022), EGGROLL generates _low-rank_ parameter-space perturbations for ES: instead of sampling\na full-rank matrix _E \u2208_ R _[m][\u00d7][n]_, we sample _A \u2208_ R _[m][\u00d7][r]_ and _B \u2208_ R _[n][\u00d7][r]_ with _r \u226a_ min( _m, n_ ) and form\n_E_ = ~~_\u221a_~~ 1 _r_ _AB_ _[\u22a4]_ . This reduces auxiliary perturbation matrix storage from _mn_ to ( _m_ + _n_ ) _r_ per layer, and\nproportionally reduces tensor movement. Moreover, we use a counter-based deterministic random number\ngenerator (RNG) (Salmon et al., 2011; Bradbury et al., 2018) to reconstruct noise on demand, so matrix\n\n2\n\nperturbations need not persist in memory. When evaluating the fitness of members of multiple perturbations\nin parallel, EGGROLL batches a population of low-rank adapters and shares the base activations, enabling\na single forward pass that applies all _AB_ _[\u22a4]_ updates via specialized batched matrix multiplications. The\ncompute required beyond standard batched inference scales with _O_ ( _r_ ( _n_ + _m_ ) _N_ ), where _N_ is the population\nsize, instead of _O_ ( _nmN_ ) for standard ES, yielding substantial memory and inference savings and making\nEGGROLL efficient for extremely large models. We emphasise that our method does not restrict the updates\nto be low-rank: the overall EGGROLL update is an average of rank _r_ matrices across the population, making\nthe matrix parameter update rank min( _Nr, m, n_ ) .\n\nEGGROLL is described in detail in Section 4. We provide a rigorous theoretical analysis of the low-rank\napproximation accuracy in Section 5, proving that EGGROLL updates converge to the full rank Gaussian\nES updates at an _O_ ( [1] _/r_ ) rate. This fast convergence rate suggests that low-rank updates are sufficient to\ntrain large-scale architectures, even with _r \u226a_ min( _m, n_ ). In our extensive empirical evaluation, we test this\nhypothesis across a wide range of domains in Section 6. In tabula rasa and multi-agent RL (MARL) settings,\nwe show that EGGROLL does not compromise performance compared to na\u00efve ES despite being faster.\nTo demonstrate the scalability of our method for LLM fine-tuning, we conduct experiments on pretrained\nRWKV7 (Peng et al., 2025) models, modern recurrent language models that enable large batch inference\ndue to their constant state size. Finally, we develop a nonlinear RNN language model that operates purely in\ninteger datatypes, and demonstrate that EGGROLL can stably pretrain this language model, a feat which is\nonly feasible due to the large population sizes enabled by EGGROLL."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism addresses the memory and computational inefficiency of traditional Evolution Strategies (ES) when applied to large models, which often represent parameters as vast matrices. Naive ES generates full-rank perturbation matrices for each population member, essentially requiring a complete copy of the model's 'change' space. EGGROLL mitigates this through three key innovations: First, it generates 'low-rank' perturbations. Instead of a large M x N perturbation matrix, it constructs it from two much smaller matrices (M x r and N x r, where r is tiny). This works because the optimal 'change' direction often lies in a low-dimensional subspace, meaning that not every single connection needs independent adjustment. Second, instead of storing these perturbation matrices for every population member, EGGROLL uses a deterministic random number generator (RNG) with a unique 'seed' for each member. This allows the perturbations to be recreated on-the-fly, reducing memory footprint to just storing the small seeds, akin to a hash function reliably regenerating its output from a key. Third, it batches the fitness evaluations. Instead of performing separate computations for each perturbed model in the population, EGGROLL groups all the low-rank additions together. It performs the base model's computation once and then efficiently applies the low-rank updates for the entire population in a single, specialized batched matrix multiplication pass, similar to how GPUs process many parallel operations.\n\n**Explanation:** When a computer program learns, it changes its internal numbers (parameters), often arranged in big tables called matrices. Evolution Strategies (ES) tries to find the best numbers by making many slightly different versions of the program's numbers and seeing which version performs best. The problem with very big programs (like ones with billions of numbers) is that each 'different version' means storing a whole new huge set of numbers, which consumes enormous memory and makes computations slow, like copying a massive spreadsheet just to change one cell. EGGROLL solves this by making only 'small changes' to these huge tables of numbers. Instead of generating a full new table of changes, it finds a way to describe that change using two much smaller tables. Think of it like this: if you have a huge digital photo, instead of storing a full new copy for every small edit, you just store the 'recipe' for the edit (e.g., 'increase brightness by 5%', which is a tiny instruction). This dramatically reduces memory needed. Furthermore, EGGROLL doesn't even keep these 'recipes' in memory for all the different versions simultaneously; it uses a trick (a deterministic random number generator, like a unique password) to instantly create the specific 'recipe' for any version whenever it's needed. Finally, instead of testing each different version of the program one by one, EGGROLL cleverly combines all the small 'recipes' and applies them all at once during the program's calculation, using highly optimized 'batched' operations, much like a factory line processing many similar items simultaneously. This drastically speeds up how quickly it can try out all the different versions and find the best one, even for programs with billions of numbers."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThe task of _Dataset Distillation_ involves the synthesis of a small set of synthetic samples such that a\nmodel trained _from scratch_ on this synthetic set will achieve test-time performance comparable to\nthat of a model trained on the full real dataset. Since this problem\u2019s first introduction and proposed\nsolution in the self-titled paper [47], many new methods [6, 27, 51, 54\u201356] and extensions thereof [7,\n11, 16, 25, 28, 40, 46, 53] have made strides towards the lofty goal of learning a high-quality model\nfrom just a handful of synthetic images.\n\nMeanwhile, computer vision has increasingly adopted a paradigm of using the representations of large,\npre-trained self-supervised vision models for downstream tasks, either via fine-tuning or by using these\nmodels as feature extraction backbones. Given this trend, in this work, we explore dataset distillation\nin the regime of training models _on top of_ features extracted by pre-trained vision foundation models.\nSpecifically, we study **linear classification** on top of a **pre-trained feature representation** .\n\nIn our new method, _Linear Gradient Matching_, we distill synthetic datasets by optimizing such\nthat their representations extracted by pre-trained feature extractors induce _gradients_ in a linear\nclassifier similar to those obtained from real images. We find that a single synthetic image per class\nsuffices to train linear classifiers to competitive performance across a wide variety of large vision\n\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-0.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-1.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-2.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-3.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-4.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-5.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-6.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-17.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-18.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-19.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-20.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-21.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-22.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-23.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-24.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-33.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-34.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-35.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-36.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-37.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-38.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-39.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-40.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-51.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-52.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-53.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-54.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-55.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-56.png)\n\n![](papers/images/Dataset-Distillation-for-PreTrained-SelfSupervised-Vision-Models.pdf-1-57.png)\n\nFigure 1: **ImageNet-1k Distilled for Self-Supervised Models:** Using our method of _Linear Gradient Matching_,\nwe distill vision datasets to just one synthetic image per class using different pre-trained self-supervised backbone\nmodels. These learned images can then be used to train linear probes that achieve high accuracy on unseen test\ndata, outperforming all real-image baselines. Furthermore, each backbone model seems to yield its own \u201cstyle\u201d of\ndistilled image, giving insights into the aspects on which these models tend to focus (structure, texture, color, etc.).\n\nmodel backbones, outperforming all real-image baselines. Figure 1 shows samples distilled from\nImageNet-1k [12] with our method using various self-supervised feature extractors.\n\nMotivated by recent hypotheses that different large models converge to similar representations\neven when trained on different modalities [20], we investigate whether distilled datasets transfer\n_across architectures_ . We find that a gradient matching objective alone leads to images that are\noverfit to a particular model architecture and do not yield competitive performance across foundation models. However, we overcome this issue through differentiable augmentations and a simple\nre-parameterization of images via a multi-scale pyramid. Compared to those retrieved via na\u00efve\npixel optimization, the resulting distilled images not only look remarkably realistic but also readily\ntransfer across foundation models, such that a dataset distilled using, for example, a DINO backbone\nyields competitive performance when used to train a linear classifier on top of a different model\u2019s\nrepresentation, such as CLIP\u2019s.\n\nWe also observe that our distilled datasets offer several interesting interpretability results, including\npredicting alignment between different models, explaining susceptibility (or robustness) to spurious\ncorrelations in adversarial datasets, and highlighting out-of-distribution capabilities.\n\nExtensive experiments and ablations validate our _Linear Gradient Matching_ method\u2019s effectiveness\non this new dataset distillation task and highlight its potential as an interpretability tool."}, {"role": "assistant", "content": "**Mechanism:** The core mechanism, 'Linear Gradient Matching', works by generating synthetic images such that the 'feedback signals' (gradients) produced during the training of a simple linear classifier on their extracted features are as close as possible to the average feedback signals generated by the full real dataset. When a linear classifier learns, it adjusts its internal parameters (weights) based on these gradients, which indicate the direction and magnitude of change needed to reduce error. By matching these gradients, we ensure that the synthetic data effectively replicates the 'learning guidance' of the much larger real dataset. For transferability, differentiable augmentations introduce variability, making the synthetic images less specific to one feature extractor, while a multi-scale image representation helps capture robust, generalizable features across different foundation models. This is analogous to creating a universal 'training recipe' that works for multiple kitchen appliances, despite their internal differences.\n\n**Explanation:** Imagine you have a highly skilled, fixed 'feature extractor' function (the pre-trained model) that converts any image into a unique numerical fingerprint. Our goal is to train a very simple 'fingerprint sorter' (a linear classifier) on these fingerprints. Instead of feeding it millions of real fingerprints, we want to create a few fake images whose fingerprints, when processed by the sorter, teach it just as effectively. When the sorter tries to learn, it generates an internal 'adjustment vector' (gradient) indicating how it should change its sorting rules. Our method generates synthetic images, feeds them through the feature extractor to get their fingerprints, and then calculates the adjustment vector that would be produced. We then continuously tweak these synthetic images until their generated adjustment vectors closely match the *average* adjustment vector that the real dataset would produce for the sorter. This ensures that the synthetic images provide the same 'learning direction' to the sorter as the full real dataset. The added magic for making these synthetic images work across different feature extractors (like different fingerprint machines) involves using randomized transformations on the images during creation (differentiable augmentations) and representing the images in a way that captures information at various levels of detail (multi-scale pyramid), which makes them robust and less 'overfit' to the quirks of any single extractor."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**Algorithmic framework and results** **23**\n5.1 Robust bisection algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n5.2 Robust initialization for symmetry breaking . . . . . . . . . . . . . . . . . . . 25\n5.3 Boosting via pairwise majority voting . . . . . . . . . . . . . . . . . . . . . . 25"}, {"role": "assistant", "content": "**Mechanism:** The methods involve systematic search refinement, initial state diversification, and ensemble decision-making.\n\n**Explanation:** The 'Robust bisection algorithm' works by repeatedly halving the search space, similar to a binary search. Its 'robustness' likely comes from handling noise or uncertainty in evaluating potential solutions within the bisection steps, possibly by examining a small region or using statistical checks rather than a single point comparison. It's essentially an iterative loop that narrows down a range. 'Robust initialization for symmetry breaking' addresses the problem where algorithms start from identical conditions and might converge to similar or suboptimal solutions. It introduces controlled, small initial perturbations (like unique offsets or random seeds) to ensure distinct starting points. 'Robust' implies these initial differences are stable enough to guide the algorithm to different, potentially better, solutions. This is akin to providing unique, small initial values to an array of pointers. 'Boosting via pairwise majority voting' builds a stronger decision system by having multiple 'voters' compare every possible pair of items. Each comparison yields a 'winner' for that pair. The final overall decision or ranking is derived by aggregating these pairwise wins, effectively counting how many times each item was preferred over others. This is a common pattern in ranking algorithms or ensemble methods."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\nThis section presents the Adaptive Rollout Engine, which\ndynamically adjusts SD strategies in response to real-time\nworkload characteristics. It supports both learning-based\n\n|B1|B2|Col3|B3|Col5|B4|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n|8|16|16|32|32|48|4<br>6<br>|\n\n**Figure 10. Memory footprint of CUDA Graph for SD** .\nS1\u223cS4 denote different SD strategies, B1\u223cB4 represent batchsize buckets. Memory and throughput values are illustrative.\n\nand model-free SD, and incorporates a bucketed multi-armed\nbandit (MAB) tuner to automatically configure strategies.\n\n**5.1** **Adaptive SD Manager**\n\n**Tree-based Drafting** . Unlike linear drafting, which processes a single sequence, tree-based drafting extends this\nsingle-branch paradigm by enabling parallel exploration of\nmultiple speculative paths. Following [25, 36], we build the\ncandidate tree based on the draft model\u2019s confidence score\n\n(token probability), as illustrated in Figure 9. Starting from\nthe input prompt (\"Climate\"), the draft model predicts potential next tokens. The tree-based approach explores the\ntopK most likely options at each step (e.g., topK=2 yields\n\"change\" and \"control\"), and this branching continues for\nDraft_Depth steps, creating a tree of candidate sequences.\nFinally, the Tokens_to_Verify=8 highest-confidence tokens\nwithin the tree are chosen and submitted to the target model\nfor parallel verification. By exploring and verifying multiple potential sequences simultaneously, tree-based drafting substantially increases the number of accepted tokens\nper verification step, thereby improving overall generation\nthroughput with more effective utilization of parallel compute resources.\n**Adaptivity is Necessary** . While the SD is primarily designed to accelerate the long-tail stage, we observe that SD\ncan also deliver speedups at moderate batch sizes (Table 2).\nHowever, this requires adaptive adjustment of SD strategies\naccording to the decoding batch size and workload characteristics. Prior work [25, 26, 67] mainly focuses on batchsize=1\nscenarios, which limits its applicability in real-world scenarios. RL rollout naturally involve highly dynamic batch sizes:\nthey begin large and then shrink rapidly as short responses\ncomplete. Static SD strategies are therefore both inefficient\nand unsafe, as they may cause Out-of-Memory (OOM) failures under large batches. To address this, the Adaptive SD\nManager continuously tunes SD parameters\u2014choosing safe\nstrategies to prevent OOM, maximizing throughput by learning effective strategies for each workload, and balancing\n\n7\n\nspeculative gains against computational overhead. In addition, to handle large batch sizes where SD offers little benefit,\nit employs an elastic mechanism that activates SD only when\nthe remaining request count drops below a configurable\nthreshold (default: 32).\n**Memory-Efficient CUDAGraph Capture** . To accelerate\nLLM decoding, CUDAGraph is commonly adopted, providing substantial speedup by recording CUDA operations and\nreplaying them as a single unit, which reduces per-kernel\nlaunch costs during inference. However, CUDAGraph requires capturing a separate static graph for each batch size\nand strategy, including both target and draft models. This inflexible paradigm leads to a considerable memory footprint.\nUnder the Multiple-Strategy setting (Figure 10 (b)), memory\nusage grows linearly with the number of strategies, leaving\ninsufficient space for model weights and KV caches, which\nis unacceptable in practice.\nTo accommodate more SD strategies without incurring\nprohibitive memory costs, we propose Bucketed CUDAGraph\nCapture (Figure 10 (c)), which incorporates three key optimizations: (1) Bucketed batch sizes. Instead of capturing a\nstatic graph for every possible batch size, we exploit strategyspecific characteristics (e.g., larger batch sizes typically require verifying fewer tokens) and group batch sizes into\n\n\u223c\nseveral buckets (e.g., B1 B4). (2) Disaggregated capture for\ntarget and draft models. Since some configurations affect\nonly one model (e.g., topK impacts only the drafter, while\nTokens_to_Verify affects only the target), we capture graphs\nfor target and draft models separately to avoid multiplicative\nmemory consumption. (3) Merged captures across strategies. When different strategies share identical parameter\nsettings, we merge their batchsize buckets into a single captured graph, eliminating redundant memory overhead. By\nintegrating these optimizations, we substantially reduce the\nCUDAGraph memory footprint (Table 3) while improving\nrollout throughput. The throughput gain stems from leveraging prior knowledge to avoid evaluating suboptimal strategies that are unsuitable for specific batch sizes.\n\n**5.2** **Auto-Tune Algorithm**\n\n**Bucketed** _\ud835\udf16_ **-Greedy MAB** . Multi-Armed Bandit (MAB) algorithms are a classical framework for online decision-making,\nexcelling at maximizing cumulative gains when selecting\nactions (\u201carms\u201d) with uncertain rewards [54, 57]. Each \"arm\"\ncorresponds to a specific speculative decoding configuration\ntuple: (Draft_Depth, topK, Tokens_to_Verify), and the \"reward\" reflects the efficiency within the generation step (i.e.,\naccepted_token_num/step_latency).\nTo automate the selection of SD strategies, we design\na new online tuning algorithm, Bucketed-Epsilon-Greedy\n(BEG) MAB Selector (Algorithm 1). BEG adopts an _\ud835\udf16_ -greedy\npolicy tailored to speculative decoding workloads. It buckets\nstrategies according to their Tokens_to_Verify and dynamically match them to batchsize ranges. Specifically, strategies\n\n**Algorithm 1** Bucketed-Epsilon-Greedy (BEG) MAB Selector\n\n**Input: Strategies:** S, **Batch Thresholds:** T = { _\ud835\udc61_ 1 _, . . .,\ud835\udc61\ud835\udc5a_ }, **Ex-**\n**ploration:** _\ud835\udf16_, **Window Size:** _\ud835\udc64_\n**Output:** Selected strategy _\ud835\udc60_ [\u2217]\n\n1: **procedure** Initialize(S _,_ T _,\ud835\udf16,\ud835\udc64_ )\n2: GroupByVerifyTokens(S) \u2192{S1 _, . . .,_ S _\ud835\udc5a_ } (sorted by Tokens_to_Verify, descending)\n3: Define buckets B _\ud835\udc56_ = [ _\ud835\udc61\ud835\udc56,\ud835\udc61\ud835\udc56_ +1\u22121] for _\ud835\udc56_ _< \ud835\udc5a_ and B _\ud835\udc5a_ = [ _\ud835\udc61\ud835\udc5a,_ \u221e)\n4: Map bucket B _\ud835\udc56_ \u21a6\u2192 group S _\ud835\udc56_\n5: **for all** _\ud835\udc60_ \u2208S **do**\n\n6: _\ud835\udc45\ud835\udc60,\ud835\udc34\ud835\udc60_ \u2190 deque ( _\ud835\udc64_ ) \u25b7 _init double-ended queue (size \ud835\udc64)_\n\n7: **procedure** Record( elapsed_time, accept_lens, batch_size)\n8: ~~_\ud835\udc4e_~~ \u2190 [\ufffd\ufffd] accept_lens [\ufffd] /batch_size + 1\n9: _\ud835\udc5f\ud835\udc60_ \u2190 ~~_\ud835\udc4e_~~ \u00d7 batch_size/elapsed_time\n10: Append _\ud835\udc5f\ud835\udc60_ to _\ud835\udc45\ud835\udc60_ ; Append ~~_\ud835\udc4e_~~ to _\ud835\udc34\ud835\udc60_ - _reward & acc_len_\n\n11: **procedure** SelectStrategy(batch_size)\n12: _\ud835\udc49_ \u2190{ _\ud835\udc60_ \u2208S _\ud835\udc56_ | batch_size \u2208B _\ud835\udc56_ } - _candidate strategies_\n13: **if** | _\ud835\udc49_ | = 1 **then**\n14: **return** the unique _\ud835\udc60_ \u2208 _\ud835\udc49_\n\n15: Draw _\ud835\udc62_ \u223c Uniform(0 _,_ 1)\n16: **if** _\ud835\udc62_ _< \ud835\udf16_ **then**\n\n17: **return** random _\ud835\udc60_ \u2208 _\ud835\udc49_ - _explore_\n18: **else**\n\n19: **return** arg max _\ud835\udc60_ \u2208 _\ud835\udc49_ Median( _\ud835\udc45\ud835\udc60_ ) - _exploit_\n\nS are grouped by Tokens_to_Verify into S1 _, . . .,_ S _\ud835\udc5a_, and\neach group is mapped to a batch-size bucket B _\ud835\udc56_ . During rollout, the current batch size determines the relevant candidate\nset _\ud835\udc49_ . If | _\ud835\udc49_ | = 1, the strategy is fixed; otherwise, BEG selects\nbetween exploration and exploitation. With probability _\ud835\udf16_, a\nstrategy is drawn uniformly at random from _\ud835\udc49_ (exploration).\nWith probability 1 \u2212 _\ud835\udf16_, BEG selects the strategy maximizing\nthe median reward over a sliding window of size _\ud835\udc64_ (exploitation). The reward (line: 9) balances accept rate and latency\ncost. Maintaining deques of recent rewards ensures adaptation to non-stationary dynamics across RL training.\nBy combining bucketed strategy selection, lightweight _\ud835\udf16_  greedy exploration, and sliding-window reward estimation,\nBEG reduces the overhead of exhaustive exploration while\nadapting efficiently to workload variations. This enables TLT\nto scale across diverse batchsizes and speculative decoding\nstrategies without manual tuning.\n\n**5.3** **Model-free Drafter**\n\n**Leveraging Similarity across Rollouts** . During the RL\nrollout stage, candidate responses generated for the same\nprompt often exhibit evident _sequence similarity_ and contain repetitive patterns, such as common mathematical notation or code syntax structures. This observation suggests\nthat frequent, short-range token dependencies can be predicted effectively using retrieval methods. To leverage this,\nTLT incorporates a complementary, non-parametric drafting\nstrategy alongside the primary learning-based drafter. This\nmodel-free drafter operates by dynamically building an ngram retrieval database populated from the rollout responses\n\n8\n\nspecific to each prompt. Based on the immediate context (the\npreceding n-grams), it efficiently predicts common subsequent token sequences by querying this database.\nWithin TLT, the model-free drafter serves as both a robust\nbaseline and an essential fallback mechanism. The Strategy\nSelector dynamically activates this retrieval-based drafter\nwhenever the learning-based drafter is unavailable (e.g., during initial training steps) or predicted to be inefficient. This\ndual-drafter approach ensures that speculative decoding acceleration remains active throughout all stages of the RL\nprocess, contributing to persistent efficiency gains."}, {"role": "assistant", "content": "**Mechanism:** The system acts as a dynamic scheduler and resource manager for speculative decoding (SD). It employs a tree-based search for candidate tokens, adaptive parameter tuning based on real-time batch sizes, memory optimization for runtime execution graphs, and an online learning algorithm for strategy selection, complemented by a retrieval-based fallback.\n\n**Explanation:** Instead of predicting tokens linearly, 'tree-based drafting' performs a multi-branch exploration like a tree traversal algorithm, generating `topK` candidate tokens at each step for `Draft_Depth` steps. This allows collecting `Tokens_to_Verify` high-confidence tokens from various paths for parallel verification by the target model, effectively vectorizing the verification step and reducing sequential inference calls. 'Adaptivity' is a runtime conditional logic that monitors batch size. If the batch size is too large, it dynamically switches to a safer SD strategy or disables SD entirely, preventing 'Out-of-Memory' (OOM) errors, which are analogous to segmentation faults. 'Memory-efficient CUDAGraph Capture' addresses the overhead of CUDAGraphs (pre-compiled CUDA kernel sequences). Instead of capturing a distinct graph for every batch size and strategy combination, it uses 'bucketing' (grouping batch sizes into ranges, akin to a lookup table), 'disaggregation' (separating graphs for target and draft models like different compiled functions), and 'merging' (deduplicating graphs for identical parameter sets, similar to a hash map pointing to shared resources). This significantly reduces GPU memory footprint. The 'Auto-Tune Algorithm' uses a 'Bucketed \u03b5-Greedy Multi-Armed Bandit' (MAB) approach. Strategies (arms) are tuples like (Draft_Depth, topK, Tokens_to_Verify). The current `batch_size` maps to a 'bucket', which pre-filters candidate strategies. With probability \u03b5, it randomly explores a new strategy from the bucket; otherwise (1-\u03b5), it exploits by selecting the strategy with the highest median 'reward' (accepted_token_num/step_latency) over a sliding window (`deque`). This balances exploration and exploitation while adapting to changing workloads. The 'Model-free Drafter' is a non-parametric fallback, acting as an n-gram `cache` or `lookup table`. For a given prompt, it builds a database of frequent token sequences from prior rollouts, providing rapid, pre-computed suggestions for common patterns, bypassing computationally intensive neural network inference when the main drafter is unavailable or inefficient."}]}
{"messages": [{"role": "user", "content": "Explain the intuition behind this:\n**1**\n\n1.1 Our contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n\n1.2 Overview of our techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2.1 _\ud835\udc58_ \u2265 5 case, Theorem 1.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n\n1.2.2 _\ud835\udc58_ = 4 case, Theorem 1.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2.3 _\ud835\udc58_ = 2 case upper bound, Theorem 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.4 _\ud835\udc58_ = 2 case lower bound, Theorem 1.4 . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3 Organization of this paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5"}, {"role": "assistant", "content": "**Mechanism:** The core mechanism is a case-based analysis, where the problem's mathematical structure or algorithmic approach changes significantly based on the value of a parameter 'k'. This is analogous to a 'switch' statement in programming, where different blocks of code are executed depending on a variable's value. For the 'k=2' case, they are establishing the boundaries of a potential solution space, defining both the minimal (lower bound) and maximal (upper bound) performance or values achievable.\n\n**Explanation:** The paper tackles a problem by segmenting its solution space according to the discrete values or ranges of a critical parameter 'k'. Instead of a single generalized approach, distinct analytical techniques and theorems are presented for specific 'k' values (e.g., k >= 5, k = 4, k = 2). This implies that the underlying mathematical properties or computational complexity shift drastically, necessitating tailored solutions. For k=2, the authors are providing a theoretical envelope, indicating the worst-case (upper bound) and best-case (lower bound) scenarios, which is crucial for understanding the performance limits or existence of solutions under those specific conditions. This modular breakdown simplifies the overall problem by allowing focused investigation into each regime."}]}
